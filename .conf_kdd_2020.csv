doi,title,abstract,authors,references
https://doi.org/10.1145/3394486.3407096,AI for Intelligent Financial Services: Examples and Discussion,"There are many opportunities to pursue AI and ML in the financial domain. In this talk, I will overview several research directions we are pursuing in engagement with the lines of business, ranging from data and knowledge, learning from experience, reasoning and planning, multi agent systems, and secure and private AI. I will offer concrete examples of projects, and conclude with the many challenges and opportunities that AI can offer in the financial domain.","[{""name"":""Manuela Veloso"",""id"":""/profile/81100032034""},{""name"":""Manuela Veloso"",""id"":""/profile/81100032034""}]","[""Visit jpmorgan.com/ai to view complete list of publications.Google Scholar"",""Model-Agnostic Characterization of Fairness Trade-offs. Joon Sik Kim, Jiahao Chen, Ameet Talwalkar. In Proceedings of ICML'20, July, 2020.Google Scholar"",""Heuristics for Link Prediction in Multiplex Networks. Robert E. Tillman, Vamsi Potluru, Jiahao Chen, Prashant Reddy, Manuela Veloso. In Proceedings of ECAI'20, European Conference on Artificial Intelligence, June, 2020.Google Scholar"",""Classifying and Understand Financial Data Using Graph Neural Network. Xiaoxiao Li, Joao Saude, Prashant Reddy, Manuela Veloso. AAAI-20 Workshop on Knowledge Discovery from Unstructured Data in Financial Services, February, 2020.Google Scholar"",""Reinforcement Learning for Market Making in a Multi-agent Dealer Market. Sumitra Ganesh; Nelson Vadori; Mengda Xu; Prashant Reddy; Manuela Veloso. NeurIPS'19 Workshop on Robust AI in Financial Services, December, 2019.Google Scholar"",""AI pptX: Robust Continuous Learning for Document Generation with AI Insights. Vineeth Ravi; Sélim Amrouni; Andrea Stefanucci; Prashant Reddy; Manuela Veloso. NeurIPS'19 Workshop on Robust AI in Financial Services, December, 2019.Google Scholar"",""Towards Explaining Exchange Traded Funds' Impact on Market Volatility Using an Agent-based Model. Megan J Shearer; David Byrd; Tucker Balch. NeurIPS'19 Workshop on Robust AI in Financial Services, December, 2019.Google Scholar"",""Generating Synthetic Data in Finance: Opportunities, Challenges and Pitfalls Samuel Assefa, Danial Dervovic, Mahmoud Mahfouz, Tucker Balch, Prashant Reddy, Manuela Veloso NeurIPS'19 Workshop on Robust AI in Financial Services, December, 2019.Google Scholar"",""SMPAI: Secure Multi-Party Computation for Federated Learning Antigoni Polychroniadou; Vaikkunth Mugunthan; David Byrd; Tucker Balch NeurIPS'19 Workshop on Robust AI in Financial Services, December, 2019.Google Scholar"",""Multi-Agent Simulation for Pricing and Hedging in a Dealer Sumitra Ganesh; Nelson Vadori*; Mengda Xu; Hua Zheng; Prashant Reddy; Manuela Veloso ICML'19 Workshop on AI in Finance, June, 2019.Google Scholar"",""Trading via Image Classification. Naftali Cohen, Tucker Balch, Manuela Veloso. arXiv:1907.10046 [cs.CV], October, 2019.Google Scholar""]"
https://doi.org/10.1145/3394486.3407093,Keynote Speaker: Emery N. Brown,"Emery Brown, M.D., Ph.D. is an American statistician, neuroscientist, and anesthesiologist. He is the Warren M. Zapol Professor of Anesthesia at Harvard Medical School and at Massachusetts General Hospital(MGH), and a practicing anesthesiologist at MGH. At MIT he is the Edward Hood Taplin Professor of Medical Engineering and professor of computational neuroscience, the Associate Director of the Institute for Medical Engineering and Science, and the Director of the Harvard-MIT Program in Health Sciences and Technology. Brown is one of only 19 individuals who has been elected to all three branches of the National Academies of Sciences, Engineering, and Medicine, Brown is also the first African American and first anesthesiologist to be elected to all three National Academies.","[{""name"":""Emery N. Brown"",""id"":""/profile/81100012802""},{""name"":""Emery N. Brown"",""id"":""/profile/81100012802""}]",null
https://doi.org/10.1145/3394486.3407094,Keynote Speaker: Yolanda Gil,"Dr. Yolanda Gil Dr. Yolanda Gil is Director of Knowledge Technologies and Associate Division Director at the Information Sciences Institute of the University of Southern California, and Research Professor in Computer Science and in Spatial Sciences. She is also Associate Director of Interdisciplinary Programs in Informatics. She received her M.S. and Ph. D. degrees in Computer Science from Carnegie Mellon University, with a focus on artificial intelligence. Her research is on intelligent interfaces for knowledge capture and discovery, which she investigates in a variety of projects concerning knowledge-based planning and problem solving, information analysis and assessment of trust, semantic annotation and metadata, and community-wide development of knowledge bases. Dr. Gil collaborates with scientists in different domains on semantic workflows and metadata capture, social knowledge collection, computer-mediated collaboration, and automated discovery. Dr. Gil has served in the Advisory Committee of the Computer Science and Engineering Directorate of the National Science Foundation. She initiated and chaired the W3C Provenance Group that led to a community standard in this area. Dr. Gil is a Fellow of the Association for Computing Machinery (ACM), and Past Chair of its Special Interest Group in Artificial Intelligence. She is also Fellow of the Association for the Advancement of Artificial Intelligence (AAAI), and was elected as its 24th President in 2016.","[{""name"":""Yolanda Gil"",""id"":""/profile/81556556256""},{""name"":""Yolanda Gil"",""id"":""/profile/81556556256""}]",null
https://doi.org/10.1145/3394486.3407097,Keynote Speaker: Alessandro Vespignani,"Alessandro Vespignani research activity is focused on the study of ""techno-social"" systems, where infrastructures composed of different technological layers are interoperating within the social component that drives their use and development. In this context we aim at understanding how the very same elements assembled in large number can give rise - according to the various forces and elements at play - to different macroscopic and dynamical behaviors, opening the path to quantitative computational approaches and forecasting power. The main research lines pursued at the moment are: Develop analytical and computational models for the co-evolution and interdependence of large-scale social, technological and biological networks. Modeling contagion processes in structured populations. Developing predictive computational tools for the analysis of the spatial spread of emerging diseases. Analyze the dynamics and evolution of information and social networks. Model the adaptive behavior of social systems. Prof. Vespignani is a joint appointment between the College of Science, the College of Computer and Information Science, and the Bouvé College of Health Sciences.","[{""name"":""Alessandro Vespignani"",""id"":""/profile/81100422294""},{""name"":""Alessandro Vespignani"",""id"":""/profile/81100422294""}]",null
https://doi.org/10.1145/3394486.3403043,Learning Effective Road Network Representation with Hierarchical Graph Neural Networks,"Road network is the core component of urban transportation, and it is widely useful in various traffic-related systems and applications. Due to its important role, it is essential to develop general, effective, and robust road network representation models. Although several efforts have been made in this direction, they cannot fully capture the complex characteristics of road networks.In this paper, we propose a novel Hierarchical Road Network Representation model, named HRNR, by constructing a three-level neural architecture, corresponding to ""functional zone"", ""structural regions"" and ""road segments"", respectively. To associate the three kinds of nodes, we introduce two matrices consisting of probability distributions for modeling segment-to-region assignment or region-to-zone assignment. Based on the two assignment matrices, we carefully devise two reconstruction tasks, either based on network structure or human moving patterns. In this way, our node presentations are able to capture both structural and functional characteristics. Finally, we design a three-level hierarchical update mechanism for learning the node embeddings through the entire network. Extensive experiment results on three real-world datasets for four tasks have shown the effectiveness of the proposed model.","[{""name"":""Ning Wu"",""id"":""/profile/99659455312""},{""name"":""Xin Wayne Zhao"",""id"":""/profile/82459030757""},{""name"":""Jingyuan Wang"",""id"":""/profile/82258925857""},{""name"":""Dayan Pan"",""id"":""/profile/99659573766""},{""name"":""Ning Wu"",""id"":""/profile/99659455312""},{""name"":""Xin Wayne Zhao"",""id"":""/profile/82459030757""},{""name"":""Jingyuan Wang"",""id"":""/profile/82258925857""},{""name"":""Dayan Pan"",""id"":""/profile/99659573766""}]","[""Ge Cui, Jun Luo, and Xin Wang. 2018. Personalized travel route recommendation using collaborative filtering based on GPS trajectories. IJED, Vol. 11, 3 (2018), 284--307.Google Scholar"",""J. Dai, B. Yang, C. Guo, and Z. Ding. 2015. Personalized route recommendation using big trajectory data. In ICDE. 543--554.Google Scholar"",""Yuxiao Dong, Nitesh V Chawla, and Ananthram Swami. 2017. metapath2vec: Scalable representation learning for heterogeneous networks. In SIGKDD.Google Scholar"",""Jie Feng, Yong Li, Chao Zhang, Funing Sun, Fanchao Meng, Ang Guo, and Depeng Jin. 2018. DeepMove: Predicting Human Mobility with Attentional Recurrent Networks. In WWW. 1459--1468.Google Scholar"",""Tobias Skovgaard Jepsen, Christian S Jensen, and Thomas Dyhre Nielsen. 2019. Graph convolutional networks for road networks. In SIGSPATIAL. 460--463.Google Scholar"",""Evangelos Kanoulas, Yang Du, Tian Xia, and Donghui Zhang. 2006. Finding fastest paths on a road network with speed patterns. In ICDE. IEEE, 10--10.Google Scholar"",""Thomas N Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional networks. ICLR (2017).Google Scholar"",""Vlaho Kostov, Jun Ozawa, Mototaka Yoshioka, and Takahiro Kudoh. 2005. Travel destination prediction using frequent crossing pattern from driving history. In Proceedings. 2005 IEEE Intelligent Transportation Systems, 2005. IEEE, 343--350.Google ScholarCross Ref"",""Takeshi Kurashima, Tomoharu Iwata, Go Irie, and Ko Fujimura. 2010. Travel route recommendation using geotags in photo sharing sites. In CIKM. 579--588.Google Scholar"",""Xiucheng Li, Gao Cong, Aixin Sun, and Yun Cheng. 2019. Learning travel time distributions with deep generative model. In WWW. 1017--1027.Google Scholar"",""Yaguang Li, Kun Fu, Zheng Wang, Cyrus Shahabi, Jieping Ye, and Yan Liu. 2018. Multi-task representation learning for travel time estimation. In SIGKDD.Google Scholar"",""Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. 2017. Diffusion convolutional recurrent neural network: Data-driven traffic forecasting. ICLR (2017).Google Scholar"",""Kwan Hui Lim, Jeffrey Chan, Christopher Leckie, and Shanika Karunasekera. 2015. Personalized Tour Recommendation Based on User Interests and Points of Interest Visit Durations.. In IJCAI, Vol. 15. 1778--1784.Google ScholarDigital Library"",""Qiang Liu, Shu Wu, Liang Wang, and Tieniu Tan. 2016. Predicting the next location: a recurrent model with spatial and temporal contexts. In AAAI.Google Scholar"",""Paul Newson and John Krumm. 2009. Hidden Markov map matching through noise and sparseness. In SIGSPATIAL. 336--343.Google Scholar"",""Andrew Y Ng, Michael I Jordan, and Yair Weiss. 2002. On spectral clustering: Analysis and an algorithm. In Advances in neural information processing systems. 849--856.Google Scholar"",""Takayuki Osogami and Rudy Raymond. 2013. Map matching with inverse reinforcement learning. In IJCAI.Google Scholar"",""Hongbin Pei, Bingzhe Wei, Chen-Chuan Chang, Yu Lei, and Bo Yang. 2020. Geom-GCN: Geometric Graph Convolutional Networks. In ICLR. 4800--4810.Google Scholar"",""Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph attention networks. ICLR, Vol. 1, 2 (2017).Google Scholar"",""Jingyuan Wang, Chao Chen, Junjie Wu, and Zhang Xiong. 2017. No longer sleeping with a bomb: a duet system for protecting urban safety from dangerous goods. In SIGKDD. 1673--1681.Google Scholar"",""Jingyuan Wang, Xu He, Ze Wang, Junjie Wu, Nicholas Jing Yuan, Xing Xie, and Zhang Xiong. 2018a. CD-CNN: a partially supervised cross-domain deep learning model for urban resident recognition. In AAAI.Google Scholar"",""Jingyuan Wang, Xiaojian Wang, and Junjie Wu. 2018b. Inferring metapopulation propagation network for intra-city epidemic control and prevention. In SIGKDD.Google Scholar"",""Jingyuan Wang, Junjie Wu, Ze Wang, Fei Gao, and Zhang Xiong. 2019 c. Understanding urban dynamics via context-aware tensor factorization with neighboring regularization. IEEE Transactions on Knowledge and Data Engineering (2019).Google Scholar"",""Jingyuan Wang, Ning Wu, Wayne Xin Zhao, Fanzhang Peng, and Xin Lin. 2019 d. Empowering A* Search Algorithms with Neural Networks for Personalized Route Recommendation. In SIGKDD. 539--547.Google Scholar"",""Meng-xiang Wang, Wang-Chien Lee, Tao-yang Fu, and Ge Yu. 2019 b. Learning Embeddings of Intersections on Road Networks. In SIGSPATIAL. 309--318.Google Scholar"",""Pu Wang, Timothy Hunter, Alexandre M Bayen, Katja Schechtner, and Marta C González. 2012. Understanding road usage patterns in urban areas. Scientific reports, Vol. 2 (2012), 1001.Google Scholar"",""Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, and Philip S Yu. 2019 a. Heterogeneous graph attention network. In WWW. 2022--2032.Google Scholar"",""Ling Yin Wei, Yu Zheng, and Wen Chih Peng. 2012. Constructing popular routes from uncertain trajectories. In SIGKDD. 195--203.Google Scholar"",""Hao Wu, Ziyang Chen, Weiwei Sun, Baihua Zheng, and Wei Wang. 2017. Modeling Trajectories with Recurrent Neural Networks. In ICJAI. 3083--3090.Google Scholar"",""Hao Wu, Jiangyun Mao, Weiwei Sun, Baihua Zheng, Hanyuan Zhang, Ziyang Chen, and Wei Wang. 2016. Probabilistic Robust Route Recovery with Spatio-Temporal Dynamics. In SIGKDD. 1915--1924.Google Scholar"",""Ning Wu, Jingyuan Wang, Wayne Xin Zhao, and Yang Jin. 2019. Learning to Effectively Estimate the Travel Time for Fastest Route Recommendation. In CIKM. 1923--1932.Google Scholar"",""Andy Yuan Xue, Jianzhong Qi, Xing Xie, Rui Zhang, Jin Huang, and Yuan Li. 2015. Solving the data sparsity problem in destination prediction. The VLDB Journal, Vol. 24, 2 (2015), 219--243.Google ScholarDigital Library"",""Andy Yuan Xue, Rui Zhang, Yu Zheng, Xing Xie, Jin Huang, and Zhenghua Xu. 2013. Destination prediction by sub-trajectory synthesis and privacy protection against such prediction. In ICDE. IEEE, 254--265.Google Scholar"",""Can Yang and Gyozo Gidofalvi. 2018. Fast map matching, an algorithm integrating hidden Markov model with precomputation. IJGIS, Vol. 32, 3 (2018), 547--570.Google ScholarCross Ref"",""Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, and Jure Leskovec. 2018. Hierarchical graph representation learning with differentiable pooling. In Advances in neural information processing systems. 4800--4810.Google Scholar"",""Jing Yuan, Yu Zheng, and Xing Xie. 2012. Discovering regions of different functions in a city using human mobility and POIs. In SIGKDD. 186--194.Google Scholar"",""Jing Yuan, Yu Zheng, Xing Xie, and Guangzhong Sun. 2011a. Driving with knowledge from the physical world. In SIGKDD. 316--324.Google Scholar"",""Jing Yuan, Yu Zheng, Xing Xie, and Guangzhong Sun. 2011b. T-drive: Enhancing driving directions with taxi drivers' intelligence. IEEE TKDE, Vol. 25, 1 (2011), 220--232.Google Scholar"",""Jing Yuan, Yu Zheng, Chengyang Zhang, Wenlei Xie, Xing Xie, Guangzhong Sun, and Yan Huang. 2010. T-drive: driving directions based on taxi trajectories. In SIGSPATIAL. ACM, 99--108.Google Scholar"",""Nicholas Jing Yuan, Yu Zheng, Xing Xie, Yingzi Wang, Kai Zheng, and Hui Xiong. 2014. Discovering urban functional zones using latent activity trajectories. IEEE Transactions on Knowledge and Data Engineering, Vol. 27, 3 (2014), 712--725.Google ScholarCross Ref"",""Chuxu Zhang, Dongjin Song, Chao Huang, Ananthram Swami, and Nitesh V Chawla. 2019. Heterogeneous graph neural network. In SIGKDD. 793--803.Google Scholar"",""Kai Zheng, Yu Zheng, Xing Xie, and Xiaofang Zhou. 2012. Reducing Uncertainty of Low-Sampling-Rate Trajectories. In ICDE. 1144--1155.Google Scholar""]"
https://doi.org/10.1145/3394486.3403044,Interpretability is a Kind of Safety: An Interpreter-based Ensemble for Adversary Defense,"While having achieved great success in rich real-life applications, deep neural network (DNN) models have long been criticized for their vulnerability to adversarial attacks. Tremendous research efforts have been dedicated to mitigating the threats of adversarial attacks, but the essential trait of adversarial examples is not yet clear, and most existing methods are yet vulnerable to hybrid attacks and suffer from counterattacks. In light of this, in this paper, we first reveal a gradient-based correlation between sensitivity analysis-based DNN interpreters and the generation process of adversarial examples, which indicates the Achilles's heel of adversarial attacks and sheds light on linking together the two long-standing challenges of DNN: fragility and unexplainability. We then propose an interpreter-based ensemble framework called X-Ensemble for robust adversary defense. X-Ensemble adopts a novel detection-rectification process and features in building multiple sub-detectors and a rectifier upon various types of interpretation information toward target classifiers. Moreover, X-Ensemble employs the Random Forests (RF) model to combine sub-detectors into an ensemble detector for adversarial hybrid attacks defense. The non-differentiable property of RF further makes it a precious choice against the counterattack of adversaries. Extensive experiments under various types of state-of-the-art attacks and diverse attack scenarios demonstrate the advantages of X-Ensemble to competitive baseline methods.","[{""name"":""Jingyuan Wang"",""id"":""/profile/82258925857""},{""name"":""Yufan Wu"",""id"":""/profile/99659573363""},{""name"":""Mingxuan Li"",""id"":""/profile/99659574162""},{""name"":""Xin Lin"",""id"":""/profile/99659455297""},{""name"":""Junjie Wu"",""id"":""/profile/81375612119""},{""name"":""Chao Li"",""id"":""/profile/81363599210""},{""name"":""Jingyuan Wang"",""id"":""/profile/82258925857""},{""name"":""Yufan Wu"",""id"":""/profile/99659573363""},{""name"":""Mingxuan Li"",""id"":""/profile/99659574162""},{""name"":""Xin Lin"",""id"":""/profile/99659455297""},{""name"":""Junjie Wu"",""id"":""/profile/81375612119""},{""name"":""Chao Li"",""id"":""/profile/81363599210""}]","[""Naveed Akhtar and Ajmal Mian. 2018. Threat of adversarial attacks on deep learning in computer vision: A survey. IEEE Access, Vol. 6 (2018), 14410--14430.Google ScholarCross Ref"",""Jacob Buckman, Aurko Roy, Colin Raffel, and Ian J. Goodfellow. 2018. Thermometer Encoding: One Hot Way To Resist Adversarial Examples. In ICLR'18.Google Scholar"",""Nicholas Carlini and David Wagner. 2017a. Adversarial examples are not easily detected: Bypassing ten detection methods. In 10th ACM Workshop on Artificial Intelligence and Security. ACM, 3--14.Google ScholarDigital Library"",""Nicholas Carlini and David Wagner. 2017b. Towards evaluating the robustness of neural networks. In IEEE SP'17. IEEE, 39--57.Google ScholarCross Ref"",""J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. 2009. ImageNet: A Large-Scale Hierarchical Image Database. In CVPR'09.Google Scholar"",""Christian Etmann, Sebastian Lunz, Peter Maass, and Carola Schoenlieb. 2019. On the Connection Between Adversarial Robustness and Saliency Map Interpretability. In ICML. 1823--1832.Google Scholar"",""Ian Goodfellow, Jonathon Shlens, and Christian Szegedy. 2015. Explaining and Harnessing Adversarial Examples. In ICLR.Google Scholar"",""Jindong Gu and Volker Tresp. 2019. Saliency methods for explaining adversarial attacks. arXiv preprint arXiv:1908.08413 (2019).Google Scholar"",""Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Franco Turini, Fosca Giannotti, and Dino Pedreschi. 2019. A survey of methods for explaining black box models. ACM CSUR, Vol. 51, 5 (2019), 93.Google ScholarDigital Library"",""Chuan Guo, Mayank Rana, Moustapha Cissé, and Laurens van der Maaten. 2017. Countering Adversarial Images using Input Transformations. CoRR, Vol. abs/1711.00117 (2017). arxiv: 1711.00117 http://arxiv.org/abs/1711.00117Google Scholar"",""Chuan Guo, Mayank Rana, Moustapha Cissé, and Laurens van der Maaten. 2018. Countering Adversarial Images using Input Transformations. In ICLR'18.Google Scholar"",""Suiming Guo, Chao Chen, Jingyuan Wang, Yaxiao Liu, Xu Ke, Zhiwen Yu, Daqing Zhang, and Dah-Ming Chiu. 2019. ROD-Revenue: Seeking Strategies Analysis and Revenue Prediction in Ride-on-demand Service Using Multi-source Urban Data. IEEE Transactions on Mobile Computing (2019).Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep Residual Learning for Image Recognition. In CVPR'. 770--778. https://doi.org/10.1109/CVPR.2016.90Google Scholar"",""Shengyuan Hu, Tao Yu, Chuan Guo, Wei-Lun Chao, and Kilian Q Weinberger. 2019. A New Defense Against Adversarial Images: Turning a Weakness into a Strength. In NeurIPS'19. 1633--1644.Google Scholar"",""Alex Krizhevsky et al. 2009. Learning multiple layers of features from tiny images. Technical Report.Google Scholar"",""Kimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin. 2018. A simple unified framework for detecting out-of-distribution samples and adversarial attacks. In NeurIPS'18. 7167--7177.Google Scholar"",""Yanpei Liu, Xinyun Chen, Chang Liu, and Dawn Song. 2016. Delving into transferable adversarial examples and black-box attacks. arXiv preprint arXiv:1611.02770 (2016).Google Scholar"",""Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. 2018. Towards deep learning models resistant to adversarial attacks. In ICLR.Google Scholar"",""Dongyu Meng and Hao Chen. 2017. MagNet: A Two-Pronged Defense against Adversarial Examples. In SIGSAC'17. 135--147.Google ScholarDigital Library"",""Grégoire Montavon, Alexander Binder, Sebastian Lapuschkin, Wojciech Samek, and Klaus-Robert Müller. 2019. Layer-wise relevance propagation: an overview. In Explainable AI: Interpreting, Explaining and Visualizing Deep Learning. Springer, 193--209.Google Scholar"",""Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard. 2016. Deepfool: a simple and accurate method to fool deep neural networks. In CVPR. 2574--2582.Google Scholar"",""Jérôme Rony, Luiz G Hafemann, Luiz S Oliveira, Ismail Ben Ayed, Robert Sabourin, and Eric Granger. 2019. Decoupling direction and norm for efficient gradient-based l2 adversarial attacks and defenses. In CVPR. 4322--4330.Google Scholar"",""Karen Simonyan and Andrew Zisserman. 2015. Very Deep Convolutional Networks for Large-Scale Image Recognition. In ICLR'15.Google Scholar"",""Yang Song, Taesup Kim, Sebastian Nowozin, Stefano Ermon, and Nate Kushman. 2017. Pixeldefend: Leveraging generative models to understand and defend against adversarial examples. arXiv preprint arXiv:1710.10766.Google Scholar"",""Jost Tobias Springenberg, Alexey Dosovitskiy, Thomas Brox, and Martin Riedmiller. 2014. Striving for simplicity: The all convolutional net. arXiv preprint arXiv:1412.6806 (2014).Google Scholar"",""Jiawei Su, Danilo Vasconcellos Vargas, and Kouichi Sakurai. 2019. One pixel attack for fooling deep neural networks. IEEE T-EC, Vol. 23, 5 (2019), 828--841.Google Scholar"",""Mukund Sundararajan, Ankur Taly, and Qiqi Yan. 2017. Axiomatic attribution for deep networks. In ICML. JMLR. org, 3319--3328.Google Scholar"",""Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. 2013. Intriguing properties of neural networks. arxiv: 1312.6199 [cs.CV]Google Scholar"",""Jingyuan Wang, Chao Chen, Junjie Wu, and Zhang Xiong. 2017. No longer sleeping with a bomb: a duet system for protecting urban safety from dangerous goods. In Proceedings of the 23rd ACM SIGKDD. ACM, 1673--1681.Google ScholarDigital Library"",""Jingyuan Wang, Qian Gu, Junjie Wu, Guannan Liu, and Zhang Xiong. 2016. Traffic speed prediction and congestion source exploration: A deep learning method. In 2016 IEEE 16th ICDM. IEEE, 499--508.Google Scholar"",""Jingyuan Wang, Ze Wang, Jianfeng Li, and Junjie Wu. 2018. Multilevel wavelet decomposition network for interpretable time series analysis. In Proceedings of the 24th ACM SIGKDD. ACM, 2437--2446.Google ScholarDigital Library"",""Jingyuan Wang, Ning Wu, Wayne Xin Zhao, Fanzhang Peng, and Xin Lin. 2019 a. Empowering a* search algorithms with neural networks for personalized route recommendation. In Proceedings of the 25th ACM SIGKDD. 539--547.Google ScholarDigital Library"",""Jingyuan Wang, Yang Zhang, Ke Tang, Junjie Wu, and Zhang Xiong. 2019 b. AlphaStock: A Buying-Winners-and-Selling-Losers Investment Strategy using Interpretable Deep Reinforcement Attention Networks. In SIGKDD. 1900--1908.Google Scholar"",""Han Xiao, Kashif Rasul, and Roland Vollgraf. 2018. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. (2018).Google Scholar"",""Xiaoyong Yuan, Pan He, Qile Zhu, and Xiaolin Li. 2019. Adversarial examples: Attacks and defenses for deep learning. IEEE T-NNLS (2019).Google Scholar"",""Wei Emma Zhang, Quan Z Sheng, AHOUD Alhazmi, and CHENLIANG LI. 2019. Adversarial attacks on deep learning models in natural language processing: A survey. arXiv preprint arXiv:1901.06796 (2019).Google Scholar""]"
https://doi.org/10.1145/3394486.3403045,Higher-order Clustering in Complex Heterogeneous Networks,"Heterogeneous networks are seemingly ubiquitous in the real world. Yet, most graph mining methods such as clustering have mostly focused on homogeneous graphs by ignoring semantic information in real-world systems. Moreover, most methods are based on first-order connectivity patterns (edges) despite that higher-order connectivity patterns are known to be important in understanding the structure and organization of such networks. In this work, we propose a framework for higher-order spectral clustering in heterogeneous networks through the notions of typed graphlets and typed-graphlet conductance. The proposed method builds clusters that preserve the connectivity of higher-order structures built up from typed graphlets. The approach generalizes previous work on higher-order spectral clustering. We theoretically prove a number of important results including a Cheeger-like inequality for typed-graphlet conductance that shows near-optimal bounds for the method. The theoretical results greatly simplify previous work while providing a unifying theoretical framework for analyzing higher-order spectral methods. Empirically, we demonstrate the effectiveness of the framework quantitatively for three important applications including clustering, compression, and link prediction.","[{""name"":""Aldo G. Carranza"",""id"":""/profile/99659574856""},{""name"":""Ryan A. Rossi"",""id"":""/profile/81484653761""},{""name"":""Anup Rao"",""id"":""/profile/99659454930""},{""name"":""Eunyee Koh"",""id"":""/profile/81310489834""},{""name"":""Aldo G. Carranza"",""id"":""/profile/99659574856""},{""name"":""Ryan A. Rossi"",""id"":""/profile/81484653761""},{""name"":""Anup Rao"",""id"":""/profile/99659454930""},{""name"":""Eunyee Koh"",""id"":""/profile/81310489834""}]","[""N. Ahmed, J. Neville, R. Rossi, and N. Duffield. Efficient graphlet counting for large networks. In ICDM, 2015.Google ScholarDigital Library"",""N. K. Ahmed, T. L. Willke, and R. A. Rossi. Estimation of local subgraph counts. In BigData, 2016.Google ScholarCross Ref"",""H. Almeida, D. Guedes, W. Meira, and M. Zaki. Is there a best quality metric for graph clusters? In ECML, 2011.Google ScholarDigital Library"",""A. Arenas, A. Fernandez, S. Fortunato, and S. Gomez. Motif-based communities in complex networks. J. of Physics A: Math. and Theo., 41(22):224001, 2008.Google ScholarCross Ref"",""A. Banerjee, S. Basu, and S. Merugu. Multi-way clustering on relation graphs. In SDM, pages 145--156. SIAM, 2007.Google Scholar"",""V. Batagelj, A. Ferligoj, and P. Doreian. Indirect blockmodeling of 3-way networks. Data Analysis, 2007.Google Scholar"",""A. R. Benson, D. F. Gleich, and J. Leskovec. Higher-order organization of complex networks. Sci., 353(6295), 2016.Google Scholar"",""V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefebvre. Fast unfolding of communities in large networks. JSTAT, 2008(10):P10008, 2008.Google ScholarCross Ref"",""P. Boldi and S. Vigna. The webgraph framework i: compression techniques. In WWW, pages 595--602, 2004.Google ScholarDigital Library"",""S. Cao, W. Lu, and Q. Xu. GraRep: learning graph representations with global structural information. In CIKM, pages 891--900, 2015.Google ScholarDigital Library"",""F. R. Chung. Laplacians of graphs and cheeger's inequalities. Combinatorics, 2(157--172):13--2, 1996.Google Scholar"",""F. R. Chung. Spectral graph theory. AMS, 1997.Google Scholar"",""I. S. Dhillon. Co-clustering documents and words using bipartite spectral graph partitioning. In SIGKDD, 2001.Google ScholarDigital Library"",""Y. Dong, N. V. Chawla, and A. Swami. metapath2vec: Scalable representation learning for heterogeneous networks. In KDD, pages 135--144, 2017.Google ScholarDigital Library"",""P. Doreian, V. Batagelj, and A. Ferligoj. Generalized blockmodeling of two-mode network data. Social networks, 26(1):29--53, 2004.Google ScholarCross Ref"",""S. Fortunato. Community detection in graphs. Phys. Rep., 486(3):75--174, 2010.Google ScholarCross Ref"",""D. F. Gleich and C. Seshadhri. Vertex neighborhoods, low conductance cuts, and good seeds for local community methods. In SIGKDD, pages 597--605, 2012.Google ScholarDigital Library"",""A. Grover and J. Leskovec. node2vec: Scalable feature learning for networks. In KDD, pages 855--864, 2016.Google ScholarDigital Library"",""R. Kannan, S. Vempala, and A. Vetta. On Clusterings: Good, Bad and Spectral. J. ACM, 51(3):497--515, 2004.Google ScholarDigital Library"",""C. Karande, K. Chellapilla, and R. Andersen. Speeding up algorithms on compressed web graphs. Internet Mathematics, 6(3):373--398, 2009.Google ScholarCross Ref"",""S. Khuller and B. Saha. On finding dense subgraphs. In ICALP, pages 597--608, 2009.Google ScholarDigital Library"",""X. Liu, W. Liu, T. Murata, and K. Wakita. A framework for community detection in heterogeneous multi-relational networks. Adv. in Comp. Sys., 17(06), 2014.Google Scholar"",""B. Long, Z. (mark Zhang, X. Wu, and P. S. Yu. Spectral clustering for multi-type relational data. In ICML, 2006.Google ScholarDigital Library"",""R. Milo, S. Shen-Orr, S. Itzkovitz, N. Kashtan, D. Chklovskii, and U. Alon. Network motifs: Simple building blocks of complex networks. Science, 298, 2002.Google Scholar"",""A. Paranjape, A. R. Benson, and J. Leskovec. Motifs in Temporal Networks. In WSDM, pages 601--610, 2017.Google ScholarDigital Library"",""B. Perozzi, R. Al-Rfou, and S. Skiena. Deepwalk: Online learning of social representations. In KDD, 2014.Google ScholarDigital Library"",""U. N. Raghavan, R. Albert, and S. Kumara. Near linear time algorithm to detect community structures in large-scale networks. Physical Review E, 76(3):036106, 2007.Google ScholarCross Ref"",""R. A. Rossi and N. K. Ahmed. Role Discovery in Networks. TKDE, 27(4):1112--1131, 2015.Google Scholar"",""R. A. Rossi and N. K. Ahmed. An interactive data repository with visual analytics. SIGKDD Exp., 2016.Google ScholarDigital Library"",""R. A. Rossi, N. K. Ahmed, A. Carranza, D. Arbour, A. Rao, S. Kim, and E. Koh. Heterogeneous graphlets. In MLG KDD, page 8, 2019.Google Scholar"",""R. A. Rossi, D. F. Gleich, and A. H. Gebremedhin. Parallel maximum clique algorithms with applications to network analysis. SISC, 37(5):28, 2015.Google ScholarCross Ref"",""R. A. Rossi, D. Jin, S. Kim, N. K. Ahmed, D. Koutra, and J. B. Lee. From community to role-based graph embeddings. In arXiv:1908.08572, 2019.Google Scholar"",""R. A. Rossi, A. Rao, T. Mai, and N. K. Ahmed. Fast and accurate estimation of typed graphlets. In Proceedings of The Web Conference (WWW), 2020.Google ScholarDigital Library"",""S. E. Schaeffer. Graph clustering. Comp. Sci. Rev., 2007.Google ScholarDigital Library"",""C. Shi, Y. Li, J. Zhang, Y. Sun, and P. S. Yu. A survey of heterogeneous information network analysis. TKDE, 29(1):17--37, 2017.Google ScholarDigital Library"",""J. Shi and J. Malik. Normalized cuts and image segmentation. TPAMI, 22(8):888--905, 2000.Google ScholarDigital Library"",""Y. Shi, X. He, N. Zhang, C. Yang, and J. Han. Higher-order clustering in heterogeneous information networks. arXiv preprint arXiv:1811.11320, 2018.Google Scholar"",""K. Shin, T. Eliassi-Rad, and C. Faloutsos. CoreScope: graph mining using k-core analysis--patterns, anomalies and algorithms. In ICDM, pages 469--478, 2016.Google ScholarCross Ref"",""L. Sun, L. He, Z. Huang, B. Cao, C. Xia, X. Wei, and S. Y. Philip. Joint embedding of meta-path and meta-graph for heterogeneous information networks. In 2018 IEEE International Conference on Big Knowledge (ICBK), pages 131--138, 2018.Google ScholarCross Ref"",""Y. Sun and J. Han. Mining heterogeneous information networks: a structural analysis approach. SIGKDD Explorations, 14(2):20--28, 2013.Google ScholarDigital Library"",""Y. Sun, Y. Yu, and J. Han. Ranking-based clustering of heterogeneous information networks with star network schema. In SIGKDD, pages 797--806, 2009.Google ScholarDigital Library"",""J. Tang, M. Qu, M. Wang, M. Zhang, J. Yan, and Q. Mei. LINE: large-scale information network embedding. In WWW, 2015.Google ScholarDigital Library"",""L. Trevisan. Lecture notes on expansion, sparsest cut, and spectral graph theory, 2013.Google Scholar"",""C. E. Tsourakakis, J. Pachocki, and M. Mitzenmacher. Scalable motif-aware graph clustering. In WWW, 2017.Google Scholar"",""S. Vishwanathan, N. Schraudolph, R. Kondor, and K. Borgwardt. Graph kernels. JMLR, 11:1201--1242, 2010.Google ScholarDigital Library"",""K. Voevodski, S.-H. Teng, and Y. Xia. Finding local communities in protein networks. BMC, 10(1):297, 2009.Google Scholar"",""H. Yin, A. R. Benson, and J. Leskovec. Higher-order clustering in networks. Physical Review E, 97(5):52306, May 2018.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403046,Preserving Dynamic Attention for Long-Term Spatial-Temporal Prediction,"Effective long-term predictions have been increasingly demanded in urban-wise data mining systems. Many practical applications, such as accident prevention and resource pre-allocation, require an extended period for preparation. However, challenges come as long-term prediction is highly error-sensitive, which becomes more critical when predicting urban-wise phenomena with complicated and dynamic spatial-temporal correlation. Specifically, since the amount of valuable correlation is limited, enormous irrelevant features introduce noises that trigger increased prediction errors. Besides, after each time step, the errors can traverse through the correlations and reach the spatial-temporal positions in every future prediction, leading to significant error propagation. To address these issues, we propose a Dynamic Switch-Attention Network (DSAN) with a novel Multi-Space Attention (MSA) mechanism that measures the correlations between inputs and outputs explicitly. To filter out irrelevant noises and alleviate the error propagation, DSAN dynamically extracts valuable information by applying self-attention over the noisy input and bridges each output directly to the purified inputs via implementing a switch-attention mechanism. Through extensive experiments on two spatial-temporal prediction tasks, we demonstrate the superior advantage of DSAN in both short-term and long-term predictions. The source code can be obtained from https://github.com/hxstarklin/DSAN.","[{""name"":""Haoxing Lin"",""id"":""/profile/99659573016""},{""name"":""Rufan Bai"",""id"":""/profile/99659574595""},{""name"":""Weijia Jia"",""id"":""/profile/99659559710""},{""name"":""Xinyu Yang"",""id"":""/profile/99659575161""},{""name"":""Yongjian You"",""id"":""/profile/99659575082""},{""name"":""Haoxing Lin"",""id"":""/profile/99659573016""},{""name"":""Rufan Bai"",""id"":""/profile/99659574595""},{""name"":""Weijia Jia"",""id"":""/profile/99659559710""},{""name"":""Xinyu Yang"",""id"":""/profile/99659575161""},{""name"":""Yongjian You"",""id"":""/profile/99659575082""}]","[""D. Bahdanau, K. Cho, and Y. Bengio. 2015. Neural Machine Translation by Jointly Learning to Align and Translate. In ICLR.Google Scholar"",""J. Bruna, W. Zaremba, A. Szlam, and Y. Lecun. 2013. Spectral Networks and Locally Connected Networks on Graphs. In ICLR.Google Scholar"",""J. Chung, C. Gulcehre, K. Cho, and Y. Bengio. 2014. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling.arXiv preprint arXiv:1412.3555(2014).Google Scholar"",""Z. Cui, R. Ke, and Y. Wang. 2016. Deep Bidirectional and Unidirectional LSTM Recurrent Neural Network for Network-wide Traffic Speed Prediction. arXiv preprint arXiv:1801.02143(2016).Google Scholar"",""Z. Dai, Z. Yang, Y. Yang, J. Carbonell, Q. Le, and R. Salakhutdinov. 2019. Transformer-XL: Attentive Language Models beyond a Fixed-Length Context. In ACL. 2978--2988.Google Scholar"",""J. Devlin, M. Chang, K. Lee, and K. Toutanova. 2018. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv preprint arXiv:1810.04805(2018).Google Scholar"",""S. Fang, Q. Zhang, G. Meng, S. Xiang, and C. Pan. 2019. GSTNet: Global Spatial-Temporal Network for Traffic Flow Prediction. In IJCAI. 2286--2293.Google Scholar"",""X. Geng, Y. Li, L. Wang, L. Zhang, Q. Yang, J. Ye, and Y. Liu. 2019. Spatiotemporal Multi-Graph Convolution Network for Ride-Hailing Demand Forecasting. In AAAI. 3656--3663.Google Scholar"",""K. He, X. Zhang, S. Ren, and J. Sun. 2016. Deep Residual Learning for Image Recognition. In IEEE CVPR. 770--778.Google Scholar"",""M. Henaff, J. Bruna, and Y. Lecun. 2015. Deep Convolutional Networks on Graph-Structured Data. arXiv preprint arXiv:1506.05163(2015).Google Scholar"",""S. Hochreiter and J. Schmidhuber. 1997. Long Short-Term Memory. Neural Computation 9, 8 (1997), 1735--1780.Google Scholar"",""J. Ke, H. Zheng, H. Yang, and X. Chen. 2017. Short-Term Forecasting of Passenger Demand under On-Demand Ride Services: A Spatio-Temporal Deep Learning Approach. arXiv preprint arXiv:1706.06279(2017).Google Scholar"",""Y. Kim, C. Denton, L. Hoang, and A. M. Rush. 2017. Structured Attention Networks. In ICLR.Google Scholar"",""J. Li, Z. Han, H. Cheng, J. Su, P. Wang, J. Zhang, and L. Pan. 2019. Predicting Path Failure In Time-Evolving Graphs. In ACM SIGKDD. 1279--1289.Google Scholar"",""Y. Li, R. Yu, C. Shahabi, and Y. Liu. 2017. Graph Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting.arXiv preprint arXiv:1707.01926(2017).Google Scholar"",""Z. Lin, M. Feng, C. N. dos Santos, M. Yu, B. Xiang, B. Zhou, and Y. Bengio. 2017. A Structured Self-attentive Sentence Embedding. (2017). arXiv:arXiv preprint arXiv:1703.03130Google Scholar"",""S. Luan, M. Zhao, X. Chang, and D. Precup. 2019. Break the Ceiling: Stronger Multi-scale Deep Graph Convolutional Networks. In NeurIPS. 10945--10955.Google Scholar"",""Z. Lv, J. Xu, K. Zheng, H. Yin, P. Zhao, and X. Zhou. 2018. LC-RNN: A Deep Learning Model for Traffic Speed Prediction. In IJCAI. 3470--3476.Google Scholar"",""X. Ma, Z. Tao, Y. Wang, H. Yu, and Y. Wang. 2015. Long Short-Term Memory Neural Network for Traffic Speed Prediction Using Remote Microwave Sensor Data. Transportation Research Part C: Emerging Technologies54 (2015), 187--197.Google Scholar"",""A. V. D. Oord, S. Dieleman, H. Zen, K. Simonyan, O. Vinyals, A. Graves, N. Kalchbrenner, A. Senior, and K. Kavukcuoglu. 2016. WaveNet: A Generative Model for Raw Audio. arXiv preprint arXiv:1609.03499(2016).Google Scholar"",""A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever. 2019. Language Models are Unsupervised Multitask Learners. Open AI(2019).Google Scholar"",""X. SHI, Z. Chen, H. Wang, D. Yeung, W. Wong, and W. WOO. 2015. Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting. In NeurIPS. 802--810.Google Scholar"",""X. Shi, Z. Gao, L. Lausen, H. Wang, D. Yeung, W. Wong, and W. WOO. 2017. Deep Learning for Precipitation Nowcasting: A Benchmark and A New Model. In NeurIPS. 5617--5627.Google Scholar"",""X. Song, H. Kanasugi, and R. Shibasaki. 2016. Deep Transport: Prediction and Simulation of Human Mobility and Transportation Mode at a Citywide Level. In IJCAI. 2618--2624.Google Scholar"",""A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, ?. Kaiser,and I. Polosukhin. 2017. Attention is All you Need. In NeurIPS. 5998--6008.Google Scholar"",""Y. Wu and H. Tan. 2016. Short-Term Traffic Flow Forecasting with Spatial-Temporal Correlation in a Hybrid Deep Learning Framework. arXiv preprint arXiv:1612.01022(2016).Google Scholar"",""Z. Yang, Z. Dai, Y. Yang, J. Carbonell, R. Salakhutdinov, and Q. V. Le. 2019. XLNet: Generalized Autoregressive Pretraining for Language Understanding. arXiv preprint arXiv:1906.08237(2019).Google Scholar"",""H. Yao, X. Tang, H. Wei, G. Zheng, and Y. Yu. 2019. Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction. In AAAI. 227--234.Google Scholar"",""H. Yao, F. Wu, J. Ke, X. Tang, Y. Jia, S. Lu, P. Gong, J. Ye, and Z. Li. 2018. Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction. In AAAI.Google Scholar"",""B. Yu, H. Yin, and Z. Zhu. 2018. Spatio-Temporal Graph Convolutional Networks:A Deep Learning Framework for Traffic Forecasting. In IJCAI. 3634--3640.Google Scholar"",""J. Zhang, Y. Zheng, and D. Qi. 2017. Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction. In AAAI. 1655--1661.Google Scholar"",""J. Zhang, Y. Zheng, D. Qi, R. Li, and X. Yi. 2016. DNN-based Prediction Model for Spatio-temporal Data. In ACM SIGSPATIAL. 92:1--92:4.Google Scholar"",""J. Zhang, Y. Zheng, J. Sun, and D. Qi. 2019. Flow Prediction in Spatio-Temporal Networks Based on Multitask Deep Learning. IEEE Trans. on Knowledge and Date Engineering Early Access (2019).Google Scholar"",""C. Zheng, X. Fan, C. Wang, and J. Qi. 2020. GMAN: A Graph Multi-Attention Network for Traffic Prediction. In AAAI.Google Scholar"",""C. Zheng, X. Fan, C. Wen, L. Chen, C. Wang, and J. Li. 2019. DeepSTD: Mining Spatio-Temporal Disturbances of Multiple Context Factors for Citywide Traffic Flow Prediction.IEEE Trans. on Intelligent Transportation Systems Early Access(2019).Google Scholar""]"
https://doi.org/10.1145/3394486.3403047,Learning to Extract Attribute Value from Product via Question Answering: A Multi-task Approach,"Attribute value extraction refers to the task of identifying values of an attribute of interest from product information. It is an important research topic which has been widely studied in e-Commerce and relation learning. There are two main limitations in existing attribute value extraction methods: scalability and generalizability. Most existing methods treat each attribute independently and build separate models for each of them, which are not suitable for large scale attribute systems in real-world applications. Moreover, very limited research has focused on generalizing extraction to new attributes.In this work, we propose a novel approach for Attribute Value Extraction via Question Answering (AVEQA) using a multi-task framework. In particular, we build a question answering model which treats each attribute as a question and identifies the answer span corresponding to the attribute value in the product context. A unique BERT contextual encoder is adopted and shared across all attributes to encode both the context and the question, which makes the model scalable. A distilled masked language model with knowledge distillation loss is introduced to improve the model generalization ability. In addition, we employ a no-answer classifier to explicitly handle the cases where there are no values for a given attribute in the product context. The question answering, distilled masked language model and the no answer classification are then combined into a unified multi-task framework. We conduct extensive experiments on a public dataset. The results demonstrate that the proposed approach outperforms several state-of-the-art methods with large margin.","[{""name"":""Qifan Wang"",""id"":""/profile/81490675990""},{""name"":""Li Yang"",""id"":""/profile/99659574636""},{""name"":""Bhargav Kanagal"",""id"":""/profile/81435608860""},{""name"":""Sumit Sanghai"",""id"":""/profile/99659574608""},{""name"":""D. Sivakumar"",""id"":""/profile/81100106716""},{""name"":""Bin Shu"",""id"":""/profile/99659572979""},{""name"":""Zac Yu"",""id"":""/profile/99659574284""},{""name"":""Jon Elsas"",""id"":""/profile/81309488205""},{""name"":""Qifan Wang"",""id"":""/profile/81490675990""},{""name"":""Li Yang"",""id"":""/profile/99659574636""},{""name"":""Bhargav Kanagal"",""id"":""/profile/81435608860""},{""name"":""Sumit Sanghai"",""id"":""/profile/99659574608""},{""name"":""D. Sivakumar"",""id"":""/profile/81100106716""},{""name"":""Bin Shu"",""id"":""/profile/99659572979""},{""name"":""Zac Yu"",""id"":""/profile/99659574284""},{""name"":""Jon Elsas"",""id"":""/profile/81309488205""}]","[""R. Baradaran, R. Ghiasi, and H. Amirkhani. A survey on machine reading comprehension systems. CoRR, abs/2001.01582, 2020.Google Scholar"",""D. Carmel, L. Lewin-Eytan, and Y. Maarek. Product question answering using customer generated content - research challenges. In SIGIR, pages 1349--1350, 2018.Google ScholarDigital Library"",""K. Chen, L. Feng, Q. Chen, G. Chen, and L. Shou. EXACT: attributed entity extraction by annotating texts. In SIGIR, pages 1349--1352, 2019.Google ScholarDigital Library"",""L. Chiticariu, R. Krishnamurthy, Y. Li, F. Reiss, and S. Vaithyanathan. Domain adaptation of rule-based annotators for named-entity recognition tasks. In EMNLP, pages 1002--1012, 2010.Google ScholarDigital Library"",""J. P. C. Chiu and E. Nichols. Named entity recognition with bidirectional lstm-cnns. TACL, 4:357--370, 2016.Google ScholarCross Ref"",""R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. P. Kuksa. Natural language processing (almost) from scratch. J. Mach. Learn. Res., 12:2493--2537, 2011.Google ScholarDigital Library"",""J. Devlin, M. Chang, K. Lee, and K. Toutanova. BERT: pre-training of deep bidirectional transformers for language understanding. In NAACL-HLT, pages 4171--4186, 2019.Google Scholar"",""R. Ghani, K. Probst, Y. Liu, M. Krema, and A. E. Fano. Text mining for product attribute extraction. SIGKDD Explorations, 8(1):41--48, 2006.Google ScholarDigital Library"",""V. Gopalakrishnan, S. P. Iyengar, A. Madaan, R. Rastogi, and S. H. Sengamedu. Matching product titles using web-based enrichment. In CIKM, pages 605--614, 2012.Google ScholarDigital Library"",""G. Hinton, O. Vinyals, and J. Dean. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531, 2015.Google Scholar"",""S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural Computation, 9(8):1735--1780, 1997.Google ScholarDigital Library"",""E. Hoffer, I. Hubara, and D. Soudry. Train longer, generalize better: closing the generalization gap in large batch training of neural networks. In NIPS, pages 1731--1741, 2017.Google Scholar"",""Z. Huang, W. Xu, and K. Yu. Bidirectional LSTM-CRF models for sequence tagging. CoRR, abs/1508.01991, 2015.Google Scholar"",""K. S. D. Ishwari, A. K. R. R. Aneeze, S. Sudheesan, H. J. D. A. Karunaratne, A. Nugaliyadde, and Y. Mallawarachchi. Advances in natural language question answering: A review. CoRR, abs/1904.05276, 2019.Google Scholar"",""A. Ittycheriah, M. Franz, W. Zhu, A. Ratnaparkhi, and R. J. Mammone. Ibm's statistical question answering system. In TREC, 2000.Google Scholar"",""N. S. Keskar, D. Mudigere, J. Nocedal, M. Smelyanskiy, and P. T. P. Tang. On large-batch training for deep learning: Generalization gap and sharp minima. In ICLR, 2017.Google Scholar"",""D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. In ICLR, 2015.Google Scholar"",""L. Kodra and E. K. Mecc e. Question answering systems: A review on present developments, challenges and trends. International Journal of Advanced Computer Science and Applications, 8(10.14569), 2017.Google ScholarCross Ref"",""Z. Kozareva, Q. Li, K. Zhai, and W. Guo. Recognizing salient entities in shopping queries. In ACL, 2016.Google ScholarCross Ref"",""T. Kwiatkowski, J. Palomaki, O. Redfield, M. Collins, A. P. Parikh, C. Alberti, D. Epstein, I. Polosukhin, J. Devlin, K. Lee, K. Toutanova, L. Jones, M. Kelcey, M. Chang, A. M. Dai, J. Uszkoreit, Q. Le, and S. Petrov. Natural questions: a benchmark for question answering research. TACL, 7:452--466, 2019.Google ScholarCross Ref"",""G. Lample, M. Ballesteros, S. Subramanian, K. Kawakami, and C. Dyer. Neural architectures for named entity recognition. In NAACL-HLT, pages 260--270, 2016.Google ScholarCross Ref"",""O. Levy, M. Seo, E. Choi, and L. Zettlemoyer. Zero-shot relation extraction via reading comprehension. In CoNLL, pages 333--342, 2017.Google ScholarCross Ref"",""Z. Li and D. Hoiem. Learning without forgetting. TPAMI, 40(12):2935--2947, 2018.Google ScholarDigital Library"",""X. Ling and D. S. Weld. Fine-grained entity recognition. In AAAI, 2012.Google ScholarDigital Library"",""C. Lockard, X. L. Dong, P. Shiralkar, and A. Einolghozati. CERES: distantly supervised relation extraction from the semi-structured web. PVLDB, 2018.Google ScholarDigital Library"",""X. Ma and E. H. Hovy. End-to-end sequence labeling via bi-directional lstm-cnns-crf. In ACL, 2016.Google ScholarCross Ref"",""A. Mikheev, M. Moens, and C. Grover. Named entity recognition without gazetteers. In EACL, pages 1--8, 1999.Google ScholarDigital Library"",""T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. Distributed representations of words and phrases and their compositionality. In NIPS, pages 3111--3119, 2013.Google ScholarDigital Library"",""A. More. Attribute extraction from product titles in ecommerce. CoRR, abs/1608.04670, 2016.Google Scholar"",""D. Nadeau and S. Sekine. A survey of named entity recognition and classification. Lingvisticae Investigationes, 30(1):3--26, 2007.Google ScholarCross Ref"",""A. Nugaliyadde, K. W. Wong, F. Sohel, and H. Xie. Reinforced memory network for question answering. In ICONIP, 2017.Google ScholarCross Ref"",""S. Pawar, G. K. Palshikar, and P. Bhattacharyya. Relation extraction : A survey. CoRR, abs/1712.05191, 2017.Google Scholar"",""N. Peng, H. Poon, C. Quirk, K. Toutanova, and W. Yih. Cross-sentence n-ary relation extraction with graph lstms. TACL, 5:101--115, 2017.Google ScholarCross Ref"",""P. Petrovski and C. Bizer. Extracting attribute-value pairs from product specifications on the web. In ICWI, pages 558--565, 2017.Google ScholarDigital Library"",""D. Putthividhya and J. Hu. Bootstrapped named entity recognition for product attribute extraction. In EMNLP, pages 1557--1567, 2011.Google ScholarDigital Library"",""D. Qiu, L. Barbosa, X. L. Dong, Y. Shen, and D. Srivastava. DEXTER: large-scale discovery and extraction of product specifications on the web. PVLDB, 8(13):2194--2205, 2015.Google ScholarDigital Library"",""P. Rajpurkar, J. Zhang, K. Lopyrev, and P. Liang. Squad: 100,000+ questions for machine comprehension of text. In EMNLP, pages 2383--2392, 2016.Google ScholarCross Ref"",""S. Riedel, L. Yao, and A. McCallum. Modeling relations and their mentions without labeled text. In ECML/PKDD, pages 148--163, 2010.Google ScholarDigital Library"",""E. Riloff and M. Thelen. A rule-based question answering system for reading comprehension tests. In ANLP/NAACL Workshop, pages 13--19, 2000.Google ScholarDigital Library"",""K. Shinzato and S. Sekine. Unsupervised extraction of attributes and their values from product description. In IJCNLP, pages 1339--1347, 2013.Google Scholar"",""F. M. Suchanek, G. Ifrim, and G. Weikum. Combining linguistic and statistical analysis to extract relations from web documents. In SIGKDD, 2006.Google ScholarDigital Library"",""M. Tan, B. Xiang, and B. Zhou. Lstm-based deep learning models for non-factoid answer selection. CoRR, abs/1511.04108, 2015.Google Scholar"",""D. Vandic, J. van Dam, and F. Frasincar. Faceted product search powered by the semantic web. Decision Support Systems, 53(3):425--437, 2012.Google ScholarDigital Library"",""A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin. Attention is all you need. In NIPS, pages 5998--6008, 2017.Google ScholarDigital Library"",""Q. Wang, B. Kanagal, V. Garg, and D. Sivakumar. Constructing a comprehensive events database from the web. In CIKM, pages 229--238, 2019.Google ScholarDigital Library"",""Y. W. Wong, D. Widdows, T. Lokovic, and K. Nigam. Scalable attribute-value extraction from semi-structured text. In ICDM Workshops, pages 302--307, 2009.Google ScholarDigital Library"",""S. Wu, L. Hsiao, X. Cheng, B. Hancock, T. Rekatsinas, P. Levis, and C. Ré . Fonduer: Knowledge base construction from richly formatted data. In SIGMOD, pages 1301--1316, 2018.Google Scholar"",""Y. Xian, C. H. Lampert, B. Schiele, and Z. Akata. Zero-shot learning - A comprehensive evaluation of the good, the bad and the ugly. TPAMI, 2019.Google ScholarCross Ref"",""C. Xiong, S. Merity, and R. Socher. Dynamic memory networks for visual and textual question answering. In ICML, pages 2397--2406, 2016.Google ScholarDigital Library"",""H. Xu, W. Wang, X. Mao, X. Jiang, and M. Lan. Scaling up open tagging from tens to thousands: Comprehension empowered attribute value extraction from product title. In ACL, pages 5214--5223, 2019.Google ScholarCross Ref"",""Z. Yang, Z. Dai, Y. Yang, J. G. Carbonell, R. Salakhutdinov, and Q. V. Le. Xlnet: Generalized autoregressive pretraining for language understanding. In NIPS, pages 5754--5764, 2019.Google Scholar"",""D. Zeng, K. Liu, S. Lai, G. Zhou, and J. Zhao. Relation classification via convolutional deep neural network. In COLING, pages 2335--2344, 2014.Google Scholar"",""J. Zhao, Z. Guan, and H. Sun. Riker: Mining rich keyword representations for interpretable product question answering. In SIGKDD, pages 1389--1398, 2019.Google ScholarDigital Library"",""G. Zheng, S. Mukherjee, X. L. Dong, and F. Li. Opentag: Open attribute value extraction from product profiles. In SIGKDD, pages 1049--1058, 2018.Google ScholarDigital Library"",""Y. Zhu, R. Kiros, R. S. Zemel, R. Salakhutdinov, R. Urtasun, A. Torralba, and S. Fidler. Aligning books and movies: Towards story-like visual explanations by watching movies and reading books. In ICCV, pages 19--27, 2015.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403048,Kernel Assisted Learning for Personalized Dose Finding,"An individualized dose rule recommends a dose level within a continuous safe dose range based on patient level information such as physical conditions, genetic factors and medication histories. Traditionally, personalized dose finding process requires repeating clinical visits of the patient and frequent adjustments of the dosage. Thus the patient is constantly exposed to the risk of underdosing and overdosing during the process. Statistical methods for finding an optimal individualized dose rule can lower the costs and risks for patients. In this article, we propose a kernel assisted learning method for estimating the optimal individualized dose rule. The proposed methodology can also be applied to all other continuous decision-making problems. Advantages of the proposed method include robustness to model misspecification and capability of providing statistical inference for the estimated parameters. In the simulation studies, we show that this method is capable of identifying the optimal individualized dose rule and produces favorable expected outcomes in the population. Finally, we illustrate our approach using data from a warfarin dosing study for thrombosis patients.","[{""name"":""Liangyu Zhu"",""id"":""/profile/99659574757""},{""name"":""Wenbin Lu"",""id"":""/profile/99659573130""},{""name"":""Michael R. Kosorok"",""id"":""/profile/81100036987""},{""name"":""Rui Song"",""id"":""/profile/99659287828""},{""name"":""Liangyu Zhu"",""id"":""/profile/99659574757""},{""name"":""Wenbin Lu"",""id"":""/profile/99659573130""},{""name"":""Michael R. Kosorok"",""id"":""/profile/81100036987""},{""name"":""Rui Song"",""id"":""/profile/99659287828""}]","[""Guanhua Chen, Donglin Zeng, and Michael R Kosorok. 2016. Personalized dose finding using outcome weighted learning. J. Amer. Statist. Assoc., Vol. 111, 516 (2016), 1509--1521.Google ScholarCross Ref"",""Jingxiang Chen, Haoda Fu, Xuanyao He, Michael R Kosorok, and Yufeng Liu. 2018. Estimating individualized treatment rules for ordinal treatments. Biometrics, Vol. 74, 3 (2018), 924--933.Google ScholarCross Ref"",""Sylvie Chevret. 2006. Statistical methods for dose-finding experiments. Vol. 24. Wiley Online Library.Google Scholar"",""International Warfarin Pharmacogenetics Consortium. 2009. Estimation of the warfarin dose with clinical and pharmacogenetic data. New England Journal of Medicine, Vol. 360, 8 (2009), 753--764.Google ScholarCross Ref"",""Tarn Duong and Martin L Hazelton. 2005. Cross-validation bandwidth matrices for multivariate kernel density estimation. Scandinavian Journal of Statistics, Vol. 32, 3 (2005), 485--506.Google ScholarCross Ref"",""Caiyun Fan, Wenbin Lu, Rui Song, and Yong Zhou. 2017. Concordance-assisted learning for estimating optimal individualized treatment regimes. Journal of the Royal Statistical Society: Series B (Statistical Methodology), Vol. 79, 5 (2017), 1565--1582.Google ScholarCross Ref"",""Robin Henderson, Phil Ansell, and Deyadeen Alshibani. 2010. Regret-regression for optimal dynamic treatment regimes. Biometrics, Vol. 66, 4 (2010), 1192--1201.Google ScholarCross Ref"",""Julie A Johnson, Li Gong, Michelle Whirl-Carrillo, Brian F Gage, Stuart A Scott, CM Stein, JL Anderson, Stephen E Kimmel, Ming Ta Michael Lee, M Pirmohamed, et al. 2011. Clinical Pharmacogenetics Implementation Consortium Guidelines for CYP2C9 and VKORC1 genotypes and warfarin dosing. Clinical Pharmacology \u0026 Therapeutics, Vol. 90, 4 (2011), 625--629.Google ScholarCross Ref"",""Suhyun Kang, Wenbin Lu, and Jiajia Zhang. 2018. On estimation of the optimal treatment regime with the additive hazards model. Statistica Sinica, Vol. 28, 3 (2018), 1539.Google Scholar"",""Michael R Kosorok. 2008. Introduction to empirical processes and semiparametric inference. Springer.Google Scholar"",""EB Laber and YQ Zhao. 2015. Tree-based methods for individualized treatment regimes. Biometrika, Vol. 102, 3 (2015), 501--514.Google ScholarCross Ref"",""Shuhan Liang, Wenbin Lu, and Rui Song. 2018. Deep advantage learning for optimal dynamic treatment regime. Statistical theory and related fields, Vol. 2, 1 (2018), 80--88.Google Scholar"",""Susan A Murphy. 2003. Optimal dynamic treatment regimes. Journal of the Royal Statistical Society: Series B (Statistical Methodology), Vol. 65, 2 (2003), 331--355.Google ScholarCross Ref"",""Min Qian and Susan A Murphy. 2011. Performance guarantees for individualized treatment rules. Annals of statistics, Vol. 39, 2 (2011), 1180.Google ScholarCross Ref"",""Benjamin Rich, Erica EM Moodie, and David A Stephens. 2014. Simulating sequential multiple assignment randomized trials to generate optimal personalized warfarin dosing strategies. Clinical Trials, Vol. 11, 4 (2014), 435--444.Google ScholarCross Ref"",""James M Robins. 2004. Optimal structural nested models for optimal sequential decisions. In Proceedings of the second seattle Symposium in Biostatistics. Springer, 189--326.Google ScholarCross Ref"",""Donald B Rubin. 1978. Bayesian inference for causal effects: The role of randomization. The Annals of statistics (1978), 34--58.Google Scholar"",""Eugene F Schuster et al. 1969. Estimation of a probability density function and its derivatives. The Annals of Mathematical Statistics, Vol. 40, 4 (1969), 1187--1195.Google ScholarCross Ref"",""Chengchun Shi, Alin Fan, Rui Song, and Wenbin Lu. 2018. High-dimensional a-learning for optimal dynamic treatment regimes. Annals of statistics, Vol. 46, 3 (2018), 925.Google ScholarCross Ref"",""Chengchun Shi, Rui Song, and Wenbin Lu. 2019. Concordance and value information criteria for optimal treatment decision. Annals of Statistics (2019).Google Scholar"",""Rui Song, Shikai Luo, Donglin Zeng, Hao Helen Zhang, Wenbin Lu, and Zhiguo Li. 2017. Semiparametric single-index model for estimating optimal individualized treatment strategy. Electronic journal of statistics, Vol. 11, 1 (2017), 364.Google Scholar"",""Christopher JCH Watkins and Peter Dayan. 1992. Q-learning. Machine learning, Vol. 8, 3--4 (1992), 279--292.Google Scholar"",""Wei Xiao, Hao Helen Zhang, and Wenbin Lu. 2019. Robust regression for optimal individualized treatment rules. Statistics in medicine, Vol. 38, 11 (2019), 2059--2073.Google Scholar"",""Baqun Zhang, Anastasios A Tsiatis, Marie Davidian, Min Zhang, and Eric Laber. 2012a. Estimating optimal treatment regimes from a classification perspective. Stat, Vol. 1, 1 (2012a), 103--114.Google ScholarCross Ref"",""Baqun Zhang, Anastasios A Tsiatis, Eric B Laber, and Marie Davidian. 2012b. A robust method for estimating optimal treatment regimes. Biometrics, Vol. 68, 4 (2012b), 1010--1018.Google Scholar"",""Yufan Zhao, Michael R Kosorok, and Donglin Zeng. 2009. Reinforcement learning design for cancer clinical trials. Statistics in medicine, Vol. 28, 26 (2009), 3294--3315.Google Scholar"",""Yingqi Zhao, Donglin Zeng, A John Rush, and Michael R Kosorok. 2012. Estimating individualized treatment rules using outcome weighted learning. J. Amer. Statist. Assoc., Vol. 107, 499 (2012), 1106--1118.Google ScholarCross Ref"",""Jie Zhou, Jiajia Zhang, Wenbin Lu, and Xiaoming Li. 2019. On restricted optimal treatment regime estimation for competing risks data. Biostatistics (2019).Google Scholar""]"
https://doi.org/10.1145/3394486.3403049,Graph Structure Learning for Robust Graph Neural Networks,"Graph Neural Networks (GNNs) are powerful tools in representation learning for graphs. However, recent studies show that GNNs are vulnerable to carefully-crafted perturbations, called adversarial attacks. Adversarial attacks can easily fool GNNs in making predictions for downstream tasks. The vulnerability to adversarial attacks has raised increasing concerns for applying GNNs in safety-critical applications. Therefore, developing robust algorithms to defend adversarial attacks is of great significance. A natural idea to defend adversarial attacks is to clean the perturbed graph. It is evident that real-world graphs share some intrinsic properties. For example, many real-world graphs are low-rank and sparse, and the features of two adjacent nodes tend to be similar. In fact, we find that adversarial attacks are likely to violate these graph properties. Therefore, in this paper, we explore these properties to defend adversarial attacks on graphs. In particular, we propose a general framework Pro-GNN, which can jointly learn a structural graph and a robust graph neural network model from the perturbed graph guided by these properties. Extensive experiments on real-world graphs demonstrate that the proposed framework achieves significantly better performance compared with the state-of-the-art defense methods, even when the graph is heavily perturbed. We release the implementation of Pro-GNN to our DeepRobust repository for adversarial attacks and defenses. The specific experimental settings to reproduce our results can be found in https://github.com/ChandlerBang/Pro-GNN.","[{""name"":""Wei Jin"",""id"":""/profile/99659535601""},{""name"":""Yao Ma"",""id"":""/profile/99659241966""},{""name"":""Xiaorui Liu"",""id"":""/profile/99659224041""},{""name"":""Xianfeng Tang"",""id"":""/profile/99659343290""},{""name"":""Suhang Wang"",""id"":""/profile/99659577116""},{""name"":""Jiliang Tang"",""id"":""/profile/81496640622""},{""name"":""Wei Jin"",""id"":""/profile/99659535601""},{""name"":""Yao Ma"",""id"":""/profile/99659241966""},{""name"":""Xiaorui Liu"",""id"":""/profile/99659224041""},{""name"":""Xianfeng Tang"",""id"":""/profile/99659343290""},{""name"":""Suhang Wang"",""id"":""/profile/99659577116""},{""name"":""Jiliang Tang"",""id"":""/profile/81496640622""}]","[""Rie K Ando and Tong Zhang. 2007. Learning on graph with Laplacian regularization. In NeurIPS.Google Scholar"",""James Atwood and Don Towsley. 2016. Diffusion-convolutional neural networks. In NeurIPS.Google Scholar"",""Peter W Battaglia, Jessica B Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, et al. 2018. Relational inductive biases, deep learning, and graph networks. arXiv preprint arXiv:1806.01261 (2018).Google Scholar"",""Amir Beck and Marc Teboulle. 2009. A fast iterative shrinkage-thresholding algorithm for linear inverse problems. SIAM journal on imaging sciences (2009).Google Scholar"",""Aleksandar Bojchevski and Stephan Günnemann. 2019. Adversarial Attacks on Node Embeddings via Graph Poisoning. In ICML.Google Scholar"",""Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. 2013. Spectral Networks and Locally Connected Networks on Graphs. arxiv: cs.LG/1312.6203Google Scholar"",""Emmanuel J Candès and Benjamin Recht. 2009. Exact matrix completion via convex optimization. Foundations of Computational mathematics, Vol. 9, 6 (2009), 717.Google Scholar"",""Jie Chen, Tengfei Ma, and Cao Xiao. 2018. Fastgcn: fast learning with graph convolutional networks via importance sampling. In ICLR.Google Scholar"",""Patrick L Combettes and Jean-Christophe Pesquet. 2011. Proximal splitting methods in signal processing. In Fixed-point algorithms for inverse problems in science and engineering. Springer, 185--212.Google Scholar"",""Hanjun Dai, Hui Li, Tian Tian, Xin Huang, Lin Wang, Jun Zhu, and Le Song. 2018. Adversarial attack on graph structured data. In ICML.Google Scholar"",""Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolutional neural networks on graphs with fast localized spectral filtering. In NeurIPS.Google Scholar"",""Negin Entezari, Saba A Al-Sayouri, Amirali Darvishzadeh, and Evangelos E Papalexakis. 2020. All You Need Is Low (Rank) Defending Against Adversarial Attacks on Graphs. In WSDM.Google Scholar"",""Santo Fortunato. 2010. Community detection in graphs. Physics reports (2010).Google Scholar"",""Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. 2017. Neural message passing for quantum chemistry. 1263--1272.Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In NeurIPS.Google Scholar"",""Bo Jiang, Ziyan Zhang, Doudou Lin, Jin Tang, and Bin Luo. 2019. Semi-supervised learning with graph learning-convolutional networks. In CVPR.Google Scholar"",""Wei Jin, Yaxin Li, Han Xu, Yiqi Wang, and Jiliang Tang. 2020. Adversarial Attacks and Defenses on Graphs: A Review and Empirical Study. arxiv: cs.LG/2003.00653Google Scholar"",""Thomas N Kipf and Max Welling. 2016a. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).Google Scholar"",""Thomas N Kipf and Max Welling. 2016b. Variational graph auto-encoders. arXiv preprint arXiv:1611.07308 (2016).Google Scholar"",""Vladimir Koltchinskii, Karim Lounici, Alexandre B Tsybakov, et al. 2011. Nuclear-norm penalization and optimal rates for noisy low-rank matrix completion. The Annals of Statistics, Vol. 39, 5 (2011), 2302--2329.Google ScholarCross Ref"",""Yaxin Li, Wei Jin, Han Xu, and Jiliang Tang. 2020. DeepRobust: A PyTorch Library for Adversarial Attacks and Defenses. arxiv: cs.LG/2005.06149Google Scholar"",""Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. 2015. Gated graph sequence neural networks. arXiv preprint arXiv:1511.05493 (2015).Google Scholar"",""Xuanqing Liu, Si Si, Jerry Zhu, Yang Li, and Cho-Jui Hsieh. 2019. A Unified Framework for Data Poisoning Attack to Graph-based Semi-supervised Learning. In NeurIPS.Google Scholar"",""Yao Ma, Suhang Wang, Lingfei Wu, and Jiliang Tang. 2019. Attacking Graph Convolutional Networks via Rewiring. arXiv preprint arXiv:1906.03750 (2019).Google Scholar"",""Miller McPherson, Lynn Smith-Lovin, and James M Cook. 2001. Birds of a feather: Homophily in social networks. Annual review of sociology, Vol. 27, 1 (2001), 415--444.Google Scholar"",""Hugo Raguet, Jalal Fadili, and Gabriel Peyré. 2013. A generalized forward-backward splitting. SIAM Journal on Imaging Sciences, Vol. 6, 3 (2013), 1199--1226.Google ScholarCross Ref"",""Emile Richard, Pierre-André Savalle, and Nicolas Vayatis. 2012. Estimation of simultaneously sparse and low rank matrices. In ICML.Google Scholar"",""Xianfeng Tang, Yandong Li, Yiwei Sun, Huaxiu Yao, Prasenjit Mitra, and Suhang Wang. 2019. Robust Graph Neural Network Against Poisoning Attacks via Transfer Learning. arXiv preprint arXiv:1908.07558 (2019).Google Scholar"",""Liwen Vaughan, Margaret EI Kipp, and Yijun Gao. 2007. Why are websites co-linked? The case of Canadian universities. Scientometrics, Vol. 72, 1 (2007), 81--92.Google ScholarCross Ref"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2018. Graph attention networks. ICLR.Google Scholar"",""Felix Wu, Tianyi Zhang, Amauri Holanda de Souza Jr, Christopher Fifty, Tao Yu, and Kilian Q Weinberger. 2019 c. Simplifying graph convolutional networks. arXiv preprint arXiv:1902.07153 (2019).Google Scholar"",""Huijun Wu, Chen Wang, Yuriy Tyshetskiy, Andrew Docherty, Kai Lu, and Liming Zhu. 2019 b. Adversarial examples for graph data: deep insights into attack and defense. In IJCAI.Google Scholar"",""Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and Philip S Yu. 2019 a. A comprehensive survey on graph neural networks. arXiv preprint arXiv:1901.00596 (2019).Google Scholar"",""Han Xu, Yao Ma, Haochen Liu, Debayan Deb, Hui Liu, Jiliang Tang, and Anil Jain. 2019. Adversarial attacks and defenses in images, graphs and text: A review. arXiv preprint arXiv:1909.08072 (2019).Google Scholar"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale recommender systems. In KDD.Google Scholar"",""Jie Zhou, Ganqu Cui, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, and Maosong Sun. 2018. Graph neural networks: A review of methods and applications. arXiv preprint arXiv:1812.08434 (2018).Google Scholar"",""Ke Zhou, Hongyuan Zha, and Le Song. 2013. Learning social infectivity in sparse low-rank networks using multi-dimensional hawkes processes. In Artificial Intelligence and Statistics. 641--649.Google Scholar"",""Dingyuan Zhu, Ziwei Zhang, Peng Cui, and Wenwu Zhu. 2019. Robust graph convolutional networks against adversarial attacks. In KDD.Google Scholar"",""Daniel Zügner, Amir Akbarnejad, and Stephan Günnemann. 2018. Adversarial attacks on neural networks for graph data. In KDD. ACM.Google Scholar"",""Daniel Zügner and Stephan Günnemann. 2019 a. Adversarial attacks on graph neural networks via meta learning. arXiv preprint arXiv:1902.08412 (2019).Google Scholar"",""Daniel Zügner and Stephan Günnemann. 2019 b. Certifiable robustness and robust training for graph convolutional networks. In KDD.Google Scholar""]"
https://doi.org/10.1145/3394486.3403050,An Efficient Neighborhood-based Interaction Model for Recommendation on Heterogeneous Graph,"There is an influx of heterogeneous information network (HIN) based recommender systems in recent years since HIN is capable of characterizing complex graphs and contains rich semantics. Although the existing approaches have achieved performance improvement, while practical, they still face the following problems. On one hand, most existing HIN-based methods rely on explicit path reachability to leverage path-based semantic relatedness between users and items, e.g., metapath-based similarities. These methods are hard to use and integrate since path connections are sparse or noisy, and are often of different lengths. On the other hand, other graph-based methods aim to learn effective heterogeneous network representations by compressing node together with its neighborhood information into single embedding before prediction. This weakly coupled manner in modeling overlooks the rich interactions among nodes, which introduces an early summarization issue. In this paper, we propose an end-to-end Neighborhood-based Interaction Model for Recommendation (NIRec) to address above problems. Specifically, we first analyze the significance of learning interactions in HINs and then propose a novel formulation to capture the interactive patterns between each pair of nodes through their metapath-guided neighborhoods. Then, to explore complex interactions between metapaths and deal with the learning complexity on large-scale networks, we formulate interaction in a convolutional way and learn efficiently with fast Fourier transform. The extensive experiments on four different types of heterogeneous graphs demonstrate the performance gains of NIRec comparing with state-of-the-arts. To the best of our knowledge, this is the first work providing an efficient neighborhood-based interaction model in the HIN-based recommendations.","[{""name"":""Jiarui Jin"",""id"":""/profile/99659478559""},{""name"":""Jiarui Qin"",""id"":""/profile/99659451540""},{""name"":""Yuchen Fang"",""id"":""/profile/99659316785""},{""name"":""Kounianhua Du"",""id"":""/profile/99659572943""},{""name"":""Weinan Zhang"",""id"":""/profile/81555923456""},{""name"":""Yong Yu"",""id"":""/profile/81548005779""},{""name"":""Zheng Zhang"",""id"":""/profile/99659535130""},{""name"":""Alexander J. Smola"",""id"":""/profile/81100243402""},{""name"":""Jiarui Jin"",""id"":""/profile/99659478559""},{""name"":""Jiarui Qin"",""id"":""/profile/99659451540""},{""name"":""Yuchen Fang"",""id"":""/profile/99659316785""},{""name"":""Kounianhua Du"",""id"":""/profile/99659572943""},{""name"":""Weinan Zhang"",""id"":""/profile/81555923456""},{""name"":""Yong Yu"",""id"":""/profile/81548005779""},{""name"":""Zheng Zhang"",""id"":""/profile/99659535130""},{""name"":""Alexander J. Smola"",""id"":""/profile/81100243402""}]","[""Ting Chen and Yizhou Sun. 2017. Task-guided and path-augmented heterogeneous network embedding for author identification. In WSDM.Google Scholar"",""Yuxiao Dong, Nitesh V Chawla, and Ananthram Swami. 2017. metapath2vec: Scalable representation learning for heterogeneous networks. In KDD.Google Scholar"",""Wei Feng and Jianyong Wang. 2012. Incorporating heterogeneous information for personalized tag recommendation in social tagging systems. In KDD.Google Scholar"",""Tao-yang Fu, Wang-Chien Lee, and Zhen Lei. 2017. Hin2vec: Explore meta-paths in heterogeneous information networks for representation learning. In CIKM.Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In KDD.Google Scholar"",""Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: a factorization-machine based neural network for CTR prediction. IJCAI (2017).Google Scholar"",""Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In WWW.Google Scholar"",""Binbin Hu, Chuan Shi,Wayne Xin Zhao, and Tianchi Yang. 2018. Local and global information fusion for top-n recommendation in heterogeneous information network. In CIKM.Google Scholar"",""Binbin Hu, Chuan Shi, Wayne Xin Zhao, and Philip S Yu. 2018. Leveraging meta-path based context for top-n recommendation with a neural co-attention model. In KDD.Google Scholar"",""Xiao Huang, Jundong Li, and Xia Hu. 2017. Label informed attributed network embedding. In WSDM.Google Scholar"",""Thomas N Kipf and MaxWelling. 2016. Semi-supervised classification with graph convolutional networks. ICLR (2016).Google Scholar"",""Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix factorization techniques for recommender systems. Computer 42, 8 (2009), 30--17.Google ScholarDigital Library"",""Zemin Liu, Vincent W Zheng, Zhou Zhao, Zhao Li, Hongxia Yang, Minghui Wu, and Jing Ying. 2018. Interactive paths embedding for semantic proximity search on heterogeneous graphs. In KDD.Google Scholar"",""Chen Luo, Wei Pang, Zhe Wang, and Chenghua Lin. 2014. Hete-cf: Social-based collaborative filtering recommendation using heterogeneous relations. In ICDM.Google Scholar"",""Michael Mathieu, Mikael Henaff, and Yann LeCun. 2013. Fast training of convolutional networks through ffts. ICLR (2013).Google Scholar"",""Alan V Oppenheim. 1999. Discrete-time signal processing. Pearson Education India.Google Scholar"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In KDD.Google ScholarDigital Library"",""Yanru Qu, Ting Bai, Weinan Zhang, Jianyun Nie, and Jian Tang. 2019. An End-to-End Neighborhood-based Interaction Model for Knowledge-enhanced Recommendation. KDD Workshop.Google Scholar"",""Yanru Qu, Bohui Fang, Weinan Zhang, Ruiming Tang, Minzhe Niu, Huifeng Guo, Yong Yu, and Xiuqiang He. 2018. Product-based neural networks for user response prediction over multi-field categorical data. TOIS (2018).Google Scholar"",""Xiang Ren, Jialu Liu, Xiao Yu, Urvashi Khandelwal, Quanquan Gu, Lidan Wang, and Jiawei Han. 2014. Cluscite: Effective citation recommendation by information network-based clustering. In KDD.Google ScholarDigital Library"",""Leonardo FR Ribeiro, Pedro HP Saverese, and Daniel R Figueiredo. 2017. struc2vec: Learning node representations from structural identity. In KDD.Google Scholar"",""Chuan Shi, Binbin Hu, Wayne Xin Zhao, and S Yu Philip. 2018. Heterogeneous information network embedding for recommendation. TKDE (2018).Google Scholar"",""Chuan Shi, Yitong Li, Jiawei Zhang, Yizhou Sun, and S Yu Philip. 2016. A survey of heterogeneous information network analysis. TKDE (2016).Google Scholar"",""Chuan Shi, Jian Liu, Fuzhen Zhuang, S Yu Philip, and Bin Wu. 2016. Integrating heterogeneous information via flexible regularization framework for recommendation. KAIS (2016).Google Scholar"",""Chuan Shi, Zhiqiang Zhang, Ping Luo, Philip S Yu, Yading Yue, and BinWu. 2015. Semantic path based personalized recommendation on weighted heterogeneous information networks. In CIKM.Google Scholar"",""Yizhou Sun, Jiawei Han, Charu C Aggarwal, and Nitesh V Chawla. 2012. When will it happen?: relationship prediction in heterogeneous information networks. In WSDM.Google Scholar"",""Yizhou Sun, Jiawei Han, Xifeng Yan, Philip S Yu, and Tianyi Wu. 2011. Pathsim: Meta path-based top-k similarity search in heterogeneous information networks. VLDB (2011).Google ScholarDigital Library"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. In WWW.Google ScholarDigital Library"",""Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph attention networks. ICLR (2017).Google Scholar"",""Daixin Wang, Peng Cui, and Wenwu Zhu. 2016. Structural deep network embedding. In KDD.Google Scholar"",""Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, and Philip S Yu. 2019. Heterogeneous Graph Attention Network. In WWW.Google Scholar"",""Linchuan Xu, Xiaokai Wei, Jiannong Cao, and Philip S Yu. 2017. Embedding of embedding (eoe): Joint embedding for coupled heterogeneous networks. In WSDM.Google Scholar"",""Xiao Yu, Xiang Ren, Yizhou Sun, Quanquan Gu, Bradley Sturt, Urvashi Khandelwal, Brandon Norick, and Jiawei Han. 2014. Personalized entity recommendation: A heterogeneous information network approach. In WSDM.Google Scholar"",""Xiao Yu, Xiang Ren, Yizhou Sun, Bradley Sturt, Urvashi Khandelwal, Quanquan Gu, Brandon Norick, and Jiawei Han. 2013. Recommendation in heterogeneous information networks with implicit user feedback. In RecSys.Google Scholar"",""Chuxu Zhang, Dongjin Song, Chao Huang, Ananthram Swami, and Nitesh V Chawla. 2019. Heterogeneous graph neural network. In KDD.Google Scholar"",""Yizhou Zhang, Yun Xiong, Xiangnan Kong, Shanshan Li, Jinhong Mi, and Yangyong Zhu. 2018. Deep collective classification in heterogeneous information networks. In WWW.Google Scholar""]"
https://doi.org/10.1145/3394486.3403051,Directional Multivariate Ranking,"User-provided multi-aspect evaluations manifest users' detailed feedback on the recommended items and enable fine-grained understanding of their preferences. Extensive studies have shown that modeling such data greatly improves the effectiveness and explainability of the recommendations. However, as ranking is essential in recommendation, there is no principled solution yet for collectively generating multiple item rankings over different aspects.In this work, we propose a directional multi-aspect ranking criterion to enable a holistic ranking of items with respect to multiple aspects. Specifically, we view multi-aspect evaluation as an integral effort from a user that forms a vector of his/her preferences over aspects. Our key insight is that the direction of the difference vector between two multi-aspect preference vectors reveals the pairwise order of comparison. Hence, it is necessary for a multi-aspect ranking criterion to preserve the observed directions from such pairwise comparisons. We further derive a complete solution for the multi-aspect ranking problem based on a probabilistic multivariate tensor factorization model. Comprehensive experimental analysis on a large TripAdvisor multi-aspect rating dataset and a Yelp review text dataset confirms the effectiveness of our solution.","[{""name"":""Nan Wang"",""id"":""/profile/99659281331""},{""name"":""Hongning Wang"",""id"":""/profile/81466648782""},{""name"":""Nan Wang"",""id"":""/profile/99659281331""},{""name"":""Hongning Wang"",""id"":""/profile/81466648782""}]","[""Claus Bahlmann. 2006. Directional Features in Online Handwriting Recognition. Pattern Recogn., Vol. 39, 1 (Jan. 2006).Google ScholarDigital Library"",""Kayhan Batmanghelich, Ardavan Saeedi, Karthik Narasimhan, and Sam Gershman. 2016. Nonparametric Spherical Topic Modeling with Word Embeddings.Google Scholar"",""Konstantin Bauman, Bing Liu, and Alexander Tuzhilin. 2017. Aspect Based Recommendations: Recommending Items with the Most Valuable Aspects Based on User Reviews. In Proceedings of the 23rd SIGKDD (KDD '17).Google ScholarDigital Library"",""Qiming Diao, Minghui Qiu, Chao-Yuan Wu, Alexander J. Smola, Jing Jiang, and Chong Wang. 2014. Jointly Modeling Aspects, Ratings and Sentiments for Movie Recommendation (JMARS). In Proceedings of the 20th SIGKDD (KDD '14).Google ScholarDigital Library"",""John Duchi, Elad Hazan, and Yoram Singer. 2010. Adaptive Subgradient Methods for Online Learning and Stochastic Optimization. Technical Report. EECS Department, University of California, Berkeley.Google Scholar"",""Theodoros Evgeniou and Massimiliano Pontil. 2004. Regularized Multi--task Learning. In Proceedings of the 10th SIGKDD (SIGKDD '04).Google ScholarDigital Library"",""Peter Fayers. 2004. Item Response Theory for Psychologists. Quality of Life Research (2004).Google Scholar"",""Ronald Fisher. 1953. Dispersion on a Sphere. The Royal Society of London. (1953).Google Scholar"",""L Haff. 1979. An identity for the Wishart distribution with applications. J. Multivar. Anal., Vol. 9 (1979).Google ScholarCross Ref"",""Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural Collaborative Filtering. In Proceedings of the 26th WWW (WWW '17).Google ScholarDigital Library"",""Thorsten Joachims, Adith Swaminathan, and Tobias Schnabel. 2017. Unbiased Learning-to-Rank with Biased Feedback. In Proceedings of the 10th WSDM (WSDM '17). ACM, 9.Google ScholarDigital Library"",""Changsung Kang, Xuanhui Wang, Yi Chang, and Belle Tseng. 2012. Learning to Rank with Multi-aspect Relevance for Vertical Search. In Proceedings of the 5th WSDM (WSDM '12).Google ScholarDigital Library"",""Lu Lin, Lin Gong, and Hongning Wang. 2019. Learning Personalized Topical Compositions with Item Response Theory. In Proceedings of the 12th WSDM (WSDM '19).Google ScholarDigital Library"",""Yue Lu, Malu Castellanos, Umeshwar Dayal, and ChengXiang Zhai. [n.d.]. Automatic Construction of a Context-aware Sentiment Lexicon: An Optimization Approach. In Proceedings of the 20th WWW (WWW'11).Google Scholar"",""R. Timothy Marler and Jasbir S. Arora. 2010. The weighted sum method for multi-objective optimization: new insights. Structural and Multidisciplinary Optimization (2010).Google Scholar"",""Julian McAuley and Jure Leskovec. 2013. Hidden Factors and Hidden Topics: Understanding Rating Dimensions with Review Text. In Proceedings of the 7th RecSys (RecSys '13).Google ScholarDigital Library"",""Julian J. McAuley, Jure Leskovec, and Dan Jurafsky. 2012. Learning Attitudes and Attributes from Multi-Aspect Reviews. CoRR, Vol. abs/1210.3926 (2012).Google Scholar"",""Hiroki Morise, Satoshi Oyama, and Masahito Kurihara. 2019. Bayesian Probabilistic Tensor Factorization for Recommendation and Rating Aggregation with Multicriteria Evaluation Data. Expert Systems with Applications, Vol. 131 (2019).Google ScholarCross Ref"",""Kevin Murphy. 2007. Conjugate Bayesian analysis of the Gaussian distribution. (2007).Google Scholar"",""Alexandre Navarro, Jes Frellsen, and Richard Turner. 2016. The Multivariate Generalised von Mises: Inference and applications. (02 2016).Google Scholar"",""Whitney K. Newey and Kenneth D. West. 1987. A Simple, Positive Semi-Definite, Heteroskedasticity and Autocorrelation Consistent Covariance Matrix. Econometrica, Vol. 55, 3 (1987), 703--708.Google Scholar"",""Piyush Rai, Changwei Hu, Matthew Harding, and Lawrence Carin. 2015. Scalable Probabilistic Tensor Factorization for Binary and Count Data. In Proceedings of the 24th IJCAI (IJCAI'15).Google Scholar"",""Zhaochun Ren, Shangsong Liang, Piji Li, Shuaiqiang Wang, and Maarten de Rijke. [n.d.]. Social Collaborative Viewpoint Regression with Explainable Recommendations. In Proceedings of the 10th WSDM (WSDM '17).Google Scholar"",""Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian Personalized Ranking from Implicit Feedback. In Proceedings of the 25th UAI (UAI '09).Google Scholar"",""Sebastian Ruder. 2017. An Overview of Multi-Task Learning in Deep Neural Networks. CoRR, Vol. abs/1706.05098 (2017).Google Scholar"",""Nachiketa Sahoo, Ramayya Krishnan, George Duncan, and Jamie Callan. 2008. On Multi-component Rating and Collaborative Filtering for Recommender Systems: The Case of Yahoo ! Movies. Info. Sys. Research.Google Scholar"",""Ruslan Salakhutdinov and Andriy Mnih. 2007. Probabilistic Matrix Factorization. In Proceedings of the 20th International Conference on NeurIPS (NIPS'07).Google Scholar"",""Dharahas Tallapally, Rama Syamala Sreepada, Bidyut Kr. Patra, and Korra Sathya Babu. 2018. User Preference Learning in Multi-criteria Recommendations Using Stacked Auto Encoders. In Proceedings of the 12th Recsys (RecSys '18).Google ScholarDigital Library"",""Kwong Tin Tang. 2007. Mathematical Methods for Engineers and Scientists 2 : Vector Analysis, Ordinary Differential Equations and Laplace Transforms. Springer Berlin (2007).Google Scholar"",""Yiyi Tao, Yiling Jia, Nan Wang, and Hongning Wang. 2019. The FacT: Taming Latent Factor Models for Explainability with Factorization Trees. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR'19). 295--304.Google ScholarDigital Library"",""Hongning Wang, Yue Lu, and Chengxiang Zhai. 2010. Latent aspect rating analysis on review text data: a rating regression approach. In Proceedings of the 16th SIGKDD (SIGKDD '10).Google ScholarDigital Library"",""Hongning Wang, Yue Lu, and ChengXiang Zhai. 2011. Latent aspect rating analysis without aspect keyword supervision. In Proceedings of the 17th SIGKDD (SIGKDD '11). 618--626.Google ScholarDigital Library"",""Nan Wang and Hongning Wang. 2019. BPMR: Bayesian Probabilistic Multivariate Ranking. arxiv: cs.IR/1909.08737Google Scholar"",""Nan Wang, Hongning Wang, Yiling Jia, and Yue Yin. 2018. Explainable Recommendation via Multi-Task Learning in Opinionated Text Data. In The 41st International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '18). 165--174.Google ScholarDigital Library"",""Liang Xiong, Xi Chen, Tzu-Kuo Huang, Jeff Schneider, and Jaime G. Carbonell. [n.d.]. Temporal Collaborative Filtering with Bayesian Probabilistic Tensor Factorization. In 2010 SIAM International Conference on Data Mining.Google Scholar"",""Yongfeng Zhang, Guokun Lai, Min Zhang, Yi Zhang, Yiqun Liu, and Shaoping Ma. 2014. Explicit Factor Models for Explainable Recommendation Based on Phrase-level Sentiment Analysis. In Proceedings of the 37th SIGIR (SIGIR '14).Google ScholarDigital Library"",""Yong Zheng. 2017. Criteria Chains: A Novel Multi-Criteria Recommendation Approach. In Proceedings of the 22nd IUI (IUI '17).Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403052,Truth Discovery against Strategic Sybil Attack in Crowdsourcing,"Crowdsourcing is an information system for recruiting online workers to perform human intelligent tasks (HITs) that are hard for computers. Due to the openness of crowdsourcing, dynamic online workers with different knowledge backgrounds might give conflicting labels to a task. With the assumption that workers provide their labels independently, most existing works aggregate worker labels in a voting manner, which is vulnerable to Sybil attack where the attacker earns easy rewards by coordinating several Sybil workers to share a randomized label on each task for dominating the aggregation result. A strategic Sybil attacker also attempts to evade Sybil detection. In this paper, we propose a novel approach, called TDSSA (Truth Discovery against Strategic Sybil Attack), to defend against strategic Sybil attack. Experimental results on real-world and synthetic datasets indicate that TDSSA ensures more accurate inference of true labels under various Sybil attacking scenarios, as compared to state-of-the-art methods.","[{""name"":""Yue Wang"",""id"":""/profile/99659574545""},{""name"":""Ke Wang"",""id"":""/profile/81553476956""},{""name"":""Chunyan Miao"",""id"":""/profile/81329490717""},{""name"":""Yue Wang"",""id"":""/profile/99659574545""},{""name"":""Ke Wang"",""id"":""/profile/81553476956""},{""name"":""Chunyan Miao"",""id"":""/profile/81329490717""}]","[""Jonathan Bragg, Daniel S Weld, et al. 2013. Crowdsourcing multi-label classification for taxonomy creation. In First AAAI conference on human computation and crowdsourcing.Google Scholar"",""Arthur P Dempster, Nan M Laird, and Donald B Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. Journal of the royal statistical society. Series B (methodological) (1977), 1--38.Google Scholar"",""Xin Luna Dong, Laure Berti-Equille, and Divesh Srivastava. 2009. Integrating conflicting data: the role of source dependence. VLDB, Vol. 2, 1 (2009), 550--561.Google ScholarDigital Library"",""John R Douceur. 2002. The sybil attack. In International workshop on peer-to-peer systems. Springer, 251--260.Google ScholarDigital Library"",""Xiaoni Duan and Keishi Tajima. 2019. Improving multiclass classification in crowdsourcing by using hierarchical schemes. In WWW. 2694--2700.Google Scholar"",""Ju Fan, Guoliang Li, Beng Chin Ooi, Kian-lee Tan, and Jianhua Feng. 2015. icrowd: An adaptive crowdsourcing framework. In SIGMOD. ACM, 1015--1030.Google Scholar"",""Chien-Ju Ho, Shahin Jabbari, and Jennifer Wortman Vaughan. 2013. Adaptive task assignment for crowdsourced classification. In ICML. 534--542.Google Scholar"",""Srikanth Jagabathula, Lakshminarayanan Subramanian, and Ashwin Venkataraman. 2014. Reputation-based worker filtering in crowdsourcing. In Advances in Neural Information Processing Systems. 2492--2500.Google Scholar"",""Parisa Kaghazgaran, James Caverlee, and Anna Squicciarini. 2018. Combating crowdsourced review manipulators: a neighborhood-based approach. In WSDM. ACM, 306--314.Google Scholar"",""Qi Li, Yaliang Li, Jing Gao, Bo Zhao, Wei Fan, and Jiawei Han. 2014. Resolving conflicts in heterogeneous data by truth discovery and source reliability estimation. In SIGMOD. ACM, 1187--1198.Google Scholar"",""Xian Li, Xin Luna Dong, Kenneth B Lyons, Weiyi Meng, and Divesh Srivastava. 2015. Scaling up copy detection. In ICDE. IEEE, 89--100.Google Scholar"",""Yaliang Li, Jing Gao, Chuishi Meng, Qi Li, Lu Su, Bo Zhao, Wei Fan, and Jiawei Han. 2016. A survey on truth discovery. ACM Sigkdd Explorations Newsletter, Vol. 17, 2 (2016), 1--16.Google ScholarDigital Library"",""Xuan Liu, Meiyu Lu, Beng Chin Ooi, Yanyan Shen, Sai Wu, and Meihui Zhang. 2012. Cdas: a crowdsourcing data analytics system. VLDB, Vol. 5, 10 (2012), 1040--1051.Google ScholarDigital Library"",""Fenglong Ma, Yaliang Li, Qi Li, Minghui Qiu, Jing Gao, Shi Zhi, Lu Su, Bo Zhao, Heng Ji, and Jiawei Han. 2015. Faitcrowd: Fine grained truth discovery for crowdsourced data aggregation. In SIGKDD. ACM, 745--754.Google ScholarDigital Library"",""Adam Marcus, David Karger, Samuel Madden, Robert Miller, and Sewoong Oh. 2012. Counting with the crowd. In VLDB, Vol. 6. VLDB Endowment, 109--120.Google ScholarDigital Library"",""Adam Marcus, Eugene Wu, David R Karger, Samuel Madden, and Robert C Miller. 2011. Crowdsourced databases: query processing with people. In CIDR. CIDR.Google Scholar"",""Chenglin Miao, Qi Li, Lu Su, Mengdi Huai, Wenjun Jiang, and Jing Gao. 2018. Attack under disguise: an intelligent data poisoning attack mechanism in crowdsourcing. In WWW. IW3C2, 13--22.Google Scholar"",""David Oleson, Alexander Sorokin, Greg Laughlin, Vaughn Hester, John Le, and Lukas Biewald. 2011. Programmatic gold: Targeted and scalable quality assurance in crowdsourcing. In Workshops at the Twenty-Fifth AAAI Conference on Artificial Intelligence.Google Scholar"",""Matteo Venanzi, John Guiver, Gabriella Kazai, Pushmeet Kohli, and Milad Shokouhi. 2014. Community-based bayesian aggregation models for crowdsourcing. In WWW. ACM, 155--164.Google Scholar"",""Gang Wang, Bolun Wang, Tianyi Wang, Ana Nika, Haitao Zheng, and Ben Y Zhao. 2016. Defending against sybil devices in crowdsourced mapping services. In Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services. ACM, 179--191.Google ScholarDigital Library"",""Gang Wang, Bolun Wang, Tianyi Wang, Ana Nika, Haitao Zheng, and Ben Y Zhao. 2018. Ghost Riders: Sybil attacks on crowdsourced mobile mapping services. IEEE/ACM transactions on networking (2018).Google Scholar"",""Peter Welinder, Steve Branson, Pietro Perona, and Serge J Belongie. 2010. The multidimensional wisdom of crowds. In Advances in neural information processing systems. 2424--2432.Google Scholar"",""Jacob Whitehill, Ting-fan Wu, Jacob Bergsma, Javier R Movellan, and Paul L Ruvolo. 2009. Whose vote should count more: Optimal integration of labels from labelers of unknown expertise. In Advances in neural information processing systems. 2035--2043.Google Scholar"",""Dong Yuan, Guoliang Li, Qi Li, and Yudian Zheng. 2017. Sybil defense in crowdsourcing platforms. In CIKM. ACM, 1529--1538.Google Scholar"",""Hengtong Zhang, Qi Li, Fenglong Ma, Houping Xiao, Yaliang Li, Jing Gao, and Lu Su. 2016. Influence-aware truth discovery. In CIKM. ACM, 851--860.Google Scholar"",""Haizhong Zheng, Minhui Xue, Hao Lu, Shuang Hao, Haojin Zhu, Xiaohui Liang, and Keith Ross. 2017b. Smoke screener or straight shooter: detecting elite Sybil attacks in user-review social networks. arXiv preprint arXiv:1709.06916 (2017).Google Scholar"",""Yudian Zheng, Guoliang Li, and Reynold Cheng. 2016. Docs: a domain-aware crowdsourcing system using knowledge bases. VLDB, Vol. 10, 4 (2016), 361--372.Google ScholarDigital Library"",""Yudian Zheng, Guoliang Li, Yuanbing Li, Caihua Shan, and Reynold Cheng. 2017a. Truth inference in crowdsourcing: Is the problem solved? VLDB, Vol. 10, 5 (2017), 541--552.Google ScholarDigital Library"",""Yudian Zheng, Jiannan Wang, Guoliang Li, Reynold Cheng, and Jianhua Feng. 2015. QASCA: A quality-aware task assignment system for crowdsourcing applications. In SIGMOD. ACM, 1031--1046.Google ScholarDigital Library"",""Dengyong Zhou, Sumit Basu, Yi Mao, and John C Platt. 2012. Learning from the wisdom of crowds by minimax entropy. In Advances in neural information processing systems. 2195--2203.Google Scholar""]"
https://doi.org/10.1145/3394486.3403053,Partial Multi-Label Learning via Probabilistic Graph Matching Mechanism,"Partial Multi-Label learning (PML) learns from the ambiguous data where each instance is associated with a candidate label set, where only a part is correct. The key to solve such problem is to disambiguate the candidate label sets and identify the correct assignments between instances and their ground-truth labels. In this paper, we interpret such assignments as instance-to-label matchings, and formulate the task of PML as a matching selection problem. To model such problem, we propose a novel grapH mAtching based partial muLti-label lEarning (HALE) framework, where Graph Matching scheme is incorporated owing to its good performance of exploiting the instance and label relationship. Meanwhile, since conventional one-to-one graph matching algorithm does not satisfy the constraint of PML problem that multiple instances may correspond to multiple labels, we extend the traditional probabilistic graph matching algorithm from one-to-one constraint to many-to-many constraint, and make the proposed framework to accommodate to the PML problem. Moreover, to improve the performance of predictive model, both the minimum error reconstruction and k-nearest-neighbor weight voting scheme are employed to assign more accurate labels for unseen instances. Extensive experiments on various data sets demonstrate the superiority of our proposed method.","[{""name"":""Gengyu Lyu"",""id"":""/profile/99659514760""},{""name"":""Songhe Feng"",""id"":""/profile/81442597781""},{""name"":""Yidong Li"",""id"":""/profile/81456622151""},{""name"":""Gengyu Lyu"",""id"":""/profile/99659514760""},{""name"":""Songhe Feng"",""id"":""/profile/81442597781""},{""name"":""Yidong Li"",""id"":""/profile/81456622151""}]","[""M. Boutell, J. Luo, X. Shen, and C. Brown. 2004. Learning multi-label scene classification. Pattern Recognition, Vol. 37, 9 (2004), 1757--1771.Google ScholarCross Ref"",""S. Burkhardt and S. Kramer. 2018. Online multi-label dependency topic models for text classification. Machine Learning, Vol. 107, 5 (2018), 859--886.Google ScholarDigital Library"",""M. Chertok and Y. Keller. 2010. Spectral symmetry analysis. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 32, 7 (2010), 1227--1238.Google ScholarDigital Library"",""T. Cour, B. Sapp, and B. Taskar. 2011. Learning from partial labels. IEEE Transactions on Knowledge and Data Engineering, Vol. 12, 5 (2011), 1501--1536.Google Scholar"",""J. Demvs ar. 2006. Statistical comparisons of classifiers over multiple data sets. Journal of Machine Learning Research, Vol. 7, Jan (2006), 1--30.Google ScholarDigital Library"",""A. Egozi, Y. Keller, and H Guterman. 2013. A probabilistic approach to spectral graph matching. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 35, 1 (2013), 18--27.Google ScholarDigital Library"",""André Elisseeff and Jason Weston. 2002. A kernel method for multi-labelled classification. In Advances in Neural Information Processing Systems. 681--687.Google Scholar"",""J. Fang and M. Zhang. 2019. Partial multi-label learning via credible label elicitation. In AAAI Conference on Artificial Intelligence. 3518--3525.Google Scholar"",""L. Feng and B. An. 2018. Leveraging latent label distributions for partial label learning. In International Joint Conference on Artificial Intelligence. 2107--2113.Google Scholar"",""L. Feng and B. An. 2019. Partial label learning with self-guided retraining. In AAAI Conference on Artificial Intelligence. 3542--3549.Google Scholar"",""J. Fürnkranz, E. Hüllermeier, E. Menc'ia, and K. Brinker. 2008. Multi label classification via calibrated label ranking. Machine Learning, Vol. 73, 2 (2008), 133--153.Google ScholarDigital Library"",""E. Gibaja and S. Ventura. 2015. A tutorial on multi label learning. ACM Computing Surveys (CSUR), Vol. 47, 3 (2015), 52.Google ScholarDigital Library"",""C. Gong, T. Liu, Y. Tang, J. Yang, J. Yang, and D. Tao. 2017. A regularization approach for instance-based superset label learning. IEEE Transactions on Cybernetics, Vol. 48, 3 (2017), 967--978.Google ScholarCross Ref"",""J. Huang, G. Li, Q. Huang, and X. Wu. 2016. Learning label-specific features and class-dependent labels for multi-label classification. IEEE Transactions on Knowledge and Data Engineering (2016), 3309--3323.Google Scholar"",""R. Hummel and S. Zucker. 1983. On the foundations of relaxation labeling processes. IEEE Transactions on Pattern Analysis and Machine Intelligence 3 (1983), 267--287.Google ScholarDigital Library"",""R. Jin and Z. Ghahramani. 2003. Learning with multiple labels. In Advances in Neural Information Processing Systems. 921--928.Google Scholar"",""L. Jing, L. Yang, J. Yu, and M. Ng. 2015. Semi-supervised low-rank mapping learning for multi-label classification. In IEEE Conference on Computer Vision and Pattern Recognition. 1483--1491.Google Scholar"",""M. Leardeanu and M. Hebert. 2005. A spectral technique for correspondence problems using pairwise constraints. In International Conference on Computer Vision. 1482--1489.Google Scholar"",""Y. Li, Y. Song, and J. Luo. 2017. Improving pairwise ranking for multi-label image classification. In IEEE Conference on Computer Vision and Pattern Recognition. 3617--3625.Google Scholar"",""L. Liu and T. Dietterich. 2012. A conditional multinomial mixture model for superset label learning. In Advances in Neural Information Processing Systems. 548--556.Google Scholar"",""W. Liu and S. Chang. 2009. Robust multi-class transductive learning with graphs. In 2009 IEEE Conference on Computer Vision and Pattern Recognition. 381--388.Google Scholar"",""Z. Liu and H. Qiao. 2013. Gnccp graduated non convexity and concavity procedure. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 36, 6 (2013), 1258--1267.Google ScholarDigital Library"",""G. Lyu, S. Feng, T. Wang, and C. Lang. 2020. A self-paced regularization framework for partial label learning. IEEE Transactions on Cybernetics (2020), 1--13. https://doi.org/10.1109/TCYB.2020.2990908Google Scholar"",""G. Lyu, S. Feng, T. Wang, C. Lang, and Y Li. 2019. GM-PLL: graph matching based partial label learning. IEEE Transactions on Knowledge and Data Engineering (2019), 1--14. https://doi.org/10.1109/TKDE.2019.2933837Google Scholar"",""L. Sun, S. Feng, T. Wang, C. Lang, and Y. Jin. 2019. Partial multi-label learning via low-rank and sparse decomposition. In AAAI Conference on Artificial Intelligence. 5016--5023.Google Scholar"",""D. Thibaut, M. Nazanin, and M. Greg. 2019. Learning a deep convNet for multi-label classification with partial labels. In IEEE Conference on Computer Vision and Pattern Recognition. in press.Google Scholar"",""H. Wang, W. Liu, Y. Zhao, C. Zhang, T. Hu, and G. Chen. 2019. Discriminative and correlative partial multi label learning. In International Joint Conference on Artificial Intelligence. 3691--3697.Google Scholar"",""B. Wu, F. Jia, W. Liu, B. Ghanem, and S. Lyu. 2018. Multi-label learning with missing labels using mixed dependency graphs. International Journal of Computer Vision, Vol. 126, 8 (2018), 875--896.Google ScholarDigital Library"",""X. Wu and M. Zhang. 2018. Towards enabling binary decomposition for partial label learning.. In International Joint Conference on Artificial Intelligence. 2868--2874.Google Scholar"",""M. Xie and S. Huang. 2018. Partial multi-label learning. In AAAI Conference on Artificial Intelligence. 4302--4309.Google Scholar"",""M. Xie and S. Huang. 2020. Partial multi-label learning with noisy label identification. In AAAI Conference on Artificial Intelligence. 1--8.Google Scholar"",""C. Xu, D. Tao, and C. Xu. 2016. Robust extreme multi-label learning. In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 1275--1284.Google Scholar"",""M. Zhang, Y. Li, X. Liu, and X. Geng. 2018. Binary relevance for multi-label learning: an overview. Frontiers of Computer Science, Vol. 12, 2 (2018), 191--202.Google ScholarDigital Library"",""M. Zhang and F. Yu. 2015. Solving the partial label learning problem: an instance-based approach. In International Joint Conference on Artificial Intelligence. 4048--4054.Google Scholar"",""M. Zhang, F. Yu, and C. Tang. 2017. Disambiguation-free partial label learning. IEEE Transactions on Knowledge and Data Engineering, Vol. 29, 10 (2017), 2155--2167.Google ScholarCross Ref"",""M. Zhang and Z. Zhou. 2007. ML-KNN: a lazy learning approach to multi-label learning. Pattern Recognition, Vol. 40, 7 (2007), 2038--2048.Google ScholarDigital Library"",""M. Zhang and Z. Zhou. 2013. A review on multi-label learning algorithms. IEEE Transactions on Knowledge and Data Engineering, Vol. 26, 8 (2013), 1819--1837.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403054,Spectrum-Guided Adversarial Disparity Learning,"It has been a significant challenge to portray intraclass disparity precisely in the area of activity recognition, as it requires a robust representation of the correlation between subject-specific variation for each activity class. In this work, we propose a novel end-to-end knowledge directed adversarial learning framework, which portrays the class-conditioned intraclass disparity using two competitive encoding distributions and learns the purified latent codes by denoising learned disparity. Furthermore, the domain knowledge is incorporated in an unsupervised manner to guide the optimization and further boosts the performance. The experiments on four HAR benchmark datasets demonstrate the robustness and generalization of our proposed methods over a set of state-of-the-art. We further prove the effectiveness of automatic domain knowledge incorporation in performance enhancement.","[{""name"":""Zhe Liu"",""id"":""/profile/99659573434""},{""name"":""Lina Yao"",""id"":""/profile/81500655260""},{""name"":""Lei Bai"",""id"":""/profile/99659470568""},{""name"":""Xianzhi Wang"",""id"":""/profile/99658736431""},{""name"":""Can Wang"",""id"":""/profile/99658642610""},{""name"":""Zhe Liu"",""id"":""/profile/99659573434""},{""name"":""Lina Yao"",""id"":""/profile/81500655260""},{""name"":""Lei Bai"",""id"":""/profile/99659470568""},{""name"":""Xianzhi Wang"",""id"":""/profile/99658736431""},{""name"":""Can Wang"",""id"":""/profile/99658642610""}]","[""Dmitrijs Balabka. 2019. Semi-supervised learning for human activity recognition using adversarial autoencoders. In Proceedings of the 2019 ACM International Joint Conference on Pervasive and Ubiquitous Computing. ACM, 685--688.Google ScholarDigital Library"",""Oresti Banos, Rafael Garcia, Juan A Holgado-Terriza, Miguel Damas, Hector Pomares, Ignacio Rojas, Alejandro Saez, and Claudia Villalonga. 2014. mHealthDroid: a novel framework for agile development of mobile health applications. In International workshop on ambient assisted living. Springer, 91--98.Google ScholarCross Ref"",""Billur Barshan and Murat Cihan Yüksek. 2014. Recognizing daily and sports activities in two open source machine learning environments using body-worn sensor units. Comput. J., Vol. 57, 11 (2014), 1649--1667.Google ScholarCross Ref"",""Jun Cai, Jing Chen, and Xing Liang. 2015. Single-sample face recognition based on intra-class differences in a variation model. Sensors, Vol. 15, 1 (2015), 1071--1087.Google ScholarCross Ref"",""Kaixuan Chen, Dalin Zhang, Lina Yao, Bin Guo, Zhiwen Yu, and Yunhao Liu. 2020. Deep learning for sensor-based human activity recognition: overview, challenges and opportunities. arXiv preprint arXiv:2001.07416 (2020).Google Scholar"",""Antonia Creswell and Anil Anthony Bharath. 2018. Denoising adversarial autoencoders. IEEE transactions on neural networks and learning systems, Vol. 30, 4 (2018), 968--984.Google Scholar"",""WeiWang Dong-DongChen and Zhi-HuaZhou WeiGao. 2018. Tri-net for semi-supervised deep learning. In Proceedings of Twenty-Seventh International Joint Conference on Artificial Intelligence. 2014--2020.Google Scholar"",""Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial nets. In Advances in neural information processing systems. 2672--2680.Google Scholar"",""Yu Guan and Thomas Plötz. 2017. Ensembles of deep lstm learners for activity recognition using wearables. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, 2 (2017), 11.Google ScholarDigital Library"",""Nils Y Hammerla, Shane Halloran, and Thomas Plötz. 2016. Deep, convolutional, and recurrent models for human activity recognition using wearables. In Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence. AAAI Press, 1533--1540.Google Scholar"",""Nils Y Hammerla, Reuben Kirkham, Peter Andras, and Thomas Ploetz. 2013. On preserving statistical characteristics of accelerometry data using their empirical cumulative distribution. In Proceedings of the 2013 International Symposium on Wearable Computers. ACM, 65--68.Google ScholarDigital Library"",""Daniel Im Jiwoong Im, Sungjin Ahn, Roland Memisevic, and Yoshua Bengio. 2017. Denoising criterion for variational auto-encoding framework. In Thirty-First AAAI Conference on Artificial Intelligence.Google Scholar"",""Majid Janidarmian, Atena Roshan Fekr, Katarzyna Radecka, and Zeljko Zilic. 2017. A comprehensive analysis on wearable acceleration sensors in human activity recognition. Sensors, Vol. 17, 3 (2017), 529.Google ScholarCross Ref"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Diederik P Kingma and Max Welling. 2013. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 (2013).Google Scholar"",""Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow, and Brendan Frey. 2015. Adversarial autoencoders. arXiv preprint arXiv:1511.05644 (2015).Google Scholar"",""Vishvak S Murahari and Thomas Plötz. 2018. On attention models for human activity recognition. In Proceedings of the 2018 ACM International Symposium on Wearable Computers. ACM, 100--103.Google ScholarDigital Library"",""Francisco Ordónez and Daniel Roggen. 2016. Deep convolutional and lstm recurrent neural networks for multimodal wearable activity recognition. Sensors, Vol. 16, 1 (2016), 115.Google ScholarCross Ref"",""Attila Reiss and Didier Stricker. 2012. Introducing a new benchmarked dataset for activity monitoring. In 2012 16th International Symposium on Wearable Computers. IEEE, 108--109.Google ScholarDigital Library"",""Haibing Ren, Guangyou Xu, and SeokCheol Kee. 2004. Subject-independent natural action recognition. In Sixth IEEE International Conference on Automatic Face and Gesture Recognition, 2004. Proceedings. IEEE, 523--528.Google Scholar"",""Daniel Roggen, Alberto Calatroni, Mirco Rossi, Holleczek, et al. 2010. Collecting complex activity datasets in highly rich networked sensor environments. In The 7th International conference on networked sensing systems (INSS). IEEE, 233--240.Google ScholarCross Ref"",""Sadiq Sani, Nirmalie Wiratunga, Stewart Massie, and Kay Cooper. 2018. Matching networks for personalised human activity recognition. CEUR Workshop Proceedings.Google ScholarCross Ref"",""Steven W Smith et al. 1997. The scientist and engineer's guide to digital signal processing. (1997).Google Scholar"",""Nagender K Suryadevara and Subhas C Mukhopadhyay. 2014. Determining wellness through an ambient assisted living environment. IEEE Intelligent Systems, Vol. 29, 3 (2014), 30--37.Google ScholarCross Ref"",""Emmanuel Munguia Tapia, Stephen S Intille, William Haskell, and Larson et al. 2007. Real-time recognition of physical activities and their intensities using wireless accelerometers and a heart rate monitor. In The 11th IEEE international symposium on wearable computers. IEEE, 37--40.Google Scholar"",""Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine Manzagol. 2008. Extracting and composing robust features with denoising autoencoders. In Proceedings of the 25th international conference on Machine learning. ACM, 1096--1103.Google ScholarDigital Library"",""Andrew J Viterbi and Jim K Omura. 2013. Principles of digital communication and coding .Courier Corporation.Google Scholar"",""Jianbo Yang, Minh Nhut Nguyen, Phyo Phyo San, Xiao Li Li, and Shonali Krishnaswamy. 2015. Deep convolutional neural networks on multichannel time series for human activity recognition. In Twenty-Fourth International Joint Conference on Artificial Intelligence.Google ScholarDigital Library"",""Lina Yao, Quan Z Sheng, Xue Li, and Li et al. 2017. Compressive representation for device-free activity recognition with passive RFID signal strength. IEEE Transactions on Mobile Computing (TMC), Vol. 17, 2 (2017), 293--306.Google ScholarDigital Library"",""Xiang Zhang, Lina Yao, and Feng Yuan. 2019. Adversarial Variational Embedding for Robust Semi-supervised Learning. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403055,Attention and Memory-Augmented Networks for Dual-View Sequential Learning,"In recent years, sequential learning has been of great interest due to the advance of deep learning with applications in time-series forecasting, natural language processing, and speech recognition. Recurrent neural networks (RNNs) have achieved superior performance in single-view and synchronous multi-view sequential learning comparing to traditional machine learning models. However, the method remains less explored in asynchronous multi-view sequential learning, and the unalignment nature of multiple sequences poses a great challenge to learn the inter-view interactions. We develop an AMANet (Attention and Memory-Augmented Networks) architecture by integrating both attention and memory to solve asynchronous multi-view learning problem in general, and we focus on experiments in dual-view sequences in this paper. Self-attention and inter-attention are employed to capture intra-view interaction and inter-view interaction, respectively. History attention memory is designed to store the historical information of a specific object, which serves as local knowledge storage. Dynamic external memory is used to store global knowledge for each view. We evaluate our model in three tasks: medication recommendation from a patient's medical records, diagnosis-related group (DRG) classification from a hospital record, and invoice fraud detection through a company's taxation behaviors. The results demonstrate that our model outperforms all baselines and other state-of-the-art models in all tasks. Moreover, the ablation study of our model indicates that the inter-attention mechanism plays a key role in the model and it can boost the predictive power by effectively capturing the inter-view interactions from asynchronous views.","[{""name"":""Yong He"",""id"":""/profile/99659575204""},{""name"":""Cheng Wang"",""id"":""/profile/99659574449""},{""name"":""Nan Li"",""id"":""/profile/99659573216""},{""name"":""Zhenyu Zeng"",""id"":""/profile/99659573301""},{""name"":""Yong He"",""id"":""/profile/99659575204""},{""name"":""Cheng Wang"",""id"":""/profile/99659574449""},{""name"":""Nan Li"",""id"":""/profile/99659573216""},{""name"":""Zhenyu Zeng"",""id"":""/profile/99659573301""}]","[""D. Bahdanau, K. Cho, and Y. Bengio. 2015. Neural machine translation by jointly learning to align and translate. In 3rd International Conference on Learning Representations (ICLR).Google Scholar"",""T. Baltruaitis, C. Ahuja, and L. P. Morency. 2019. Multimodal machine learning: A survey and taxonomy. In IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), Vol. 41(2). 423--443.Google ScholarDigital Library"",""K. Cho, B. Merrienboer, C. Gulcehre, F. Bougares, H. Schwenk, and Y. Bengio. 2014. Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). 1724--1734.Google Scholar"",""E. Choi, M. T. Bahadori, J. Sun, J. Kulas, A. Schuetz, and W. Stewart. 2016. Dipole: Diagnosis prediction in healthcare via attention-based bidirectional recurrent neural networks. In Advances in Neural Information Processing Systems (NeurIPS). 3504--3512.Google Scholar"",""Daniel Gartner, Rainer Kolisch, Daniel B Neill, and Rema Padman. 2015. Machine learning approaches for early DRG classification and resource allocation. INFORMS Journal on Computing, Vol. 27, 4 (2015), 718--734.Google ScholarDigital Library"",""A. Graves, G. Wayne, M. Reynolds, T. Harley, I. Danihelka, A. Grabska-Barwi'ska, and et al. 2016. Hybrid computing using a neural network with dynamic external memory. In Nature, Vol. 538(7626). 471.Google ScholarCross Ref"",""S. Hochreiter and J. Schmidhuber. 1997. Long short-term memory. In Neural Computation, Vol. 9(8). 1735--1780.Google ScholarDigital Library"",""B. Jin, H. Yang, L. Sun, C. Liu, Y. Qu, and J. Tong. 2018. A Treatment Engine by Predicting Next-Period Prescriptions. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining (KDD). 1608--1616.Google Scholar"",""A. E. Johnson, T. J. Pollard, L. Shen, H. L. Li-wei, M. Feng, M. Ghassemi, and et al. 2016. MIMIC-III, a freely accessible critical care database. In Scientific Data, Vol. (3). 160035.Google Scholar"",""D. P. Kingma and J. Ba. 2015. Adam: A method for stochastic optimization. In International Conference on Learning Representations (ICLR).Google Scholar"",""T. N. Kipf and M. Welling. 2017. Semi-supervised classification with graph convolutional networks. In 5th International Conference on Learning Representations (ICLR).Google Scholar"",""H. Le, T. Tran, and S. Venkatesh. 2018. Memory fusion network for multi-view sequential learning. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining (KDD). 1637--1645.Google Scholar"",""T. Y. Lin, P. Goyal, R. Girshick, K. He, and P. Dollár. 2017. Focal loss for dense object detection. In Proceedings of the IEEE International Conference on Computer Vision (ICCV). 2980--2988.Google Scholar"",""F. Ma, R. Chitta, J. Zhou, Q. You, T. Sun, and J. Gao. 2017. Dipole: Diagnosis prediction in healthcare via attention-based bidirectional recurrent neural networks. In Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining (KDD). 1903--1911.Google Scholar"",""S. S. Rajagopalan, L. P. Morency, T. Baltrusaitis, and R. Goecke. 2016. Extending long short-term memory for multi-view structured learning. In European Conference on Computer Vision (ECCV). 338--353.Google Scholar"",""J. Shang, C. Xiao, T. Ma, H. Li, and J. Sun. 2019. Graph augmented memory networks for recommending medication combination. In Thirty-Third AAAI Conference on Artificial Intelligence (AAAI). 1126--1133.Google Scholar"",""H. Song, D. Rajan, J. J. Thiagarajan, and A. Spanias. 2018. Attend and diagnose: Clinical time series analysis using attention models. In Thirty-Second AAAI Conference on Artificial Intelligence. 4091--4098.Google Scholar"",""A. Vaswani, N. Shazeer, N. Shazeer, J. Uszkoreit, L. Jones, A. N. Gomez, and et al. 2017. Attention is all you need. In Advances in Neural Information Processing Systems (NeurIPS). 5998--6008.Google Scholar"",""Zhaoxin Wang, Rui Liu, Ping Li, and Chenghua Jiang. 2014. Exploring the transition to DRGs in developing countries: a case study in Shanghai, China. Pakistan journal of medical sciences, Vol. 30, 2 (2014), 250.Google Scholar"",""J. Weston, S. Chopra, and A. Bordes. 2015. Memory networks. In 3rd International Conference on Learning Representations (ICLR).Google Scholar"",""C. Xu, D. Tao, and C. Xu. 2013. A survey on multi-view learning. In ArXiv. arXiv:1304.5634.Google Scholar"",""Y. Xu, S. Biswal, S. R. Biswal, K. O. Maher, and J. Sun. 2018. RAIM: Recurrent Attentive and Intensive Model of Multimodal Patient Monitoring Data. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining (KDD). 2565--2573.Google Scholar"",""Z. Yang, D. Yang, C. Dyer, X. He, A. Smola, and E. Hovy. 2016. Hierarchical attention networks for document classification. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT). 1480--1489.Google Scholar"",""A. Zadeh, P. P. Liang, N. Mazumder, S. Poria, E. Cambria, and L. P. Morency. 2018. Memory fusion network for multi-view sequential learning. In Thirty-Second AAAI Conference on Artificial Intelligence (AAAI). 5634--5641.Google Scholar"",""Y. Zhang, R. Chen, J. Tang, W. F. Stewart, and J. Sun. 2017. LEAP: learning to prescribe effective and safe treatment combinations for multimorbidity. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD). 1315--1324.Google Scholar"",""J. Zhao, X. Xie, X. Xu, and S. Sun. 2017. Multi-view learning overview: Recent progress and new challenges. In Information Fusion, Vol. 38. 43--54.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403056,Semantic Search in Millions of Equations,"Given the increase of publications, search for relevant papers becomes tedious. In particular, search across disciplines or schools of thinking is not supported. This is mainly due to the retrieval with keyword queries: technical terms differ in different sciences or at different times. Relevant articles might better be identified by their mathematical problem descriptions. Just looking at the equations in a paper already gives a hint to whether the paper is relevant. Hence, we propose a new approach for retrieval of mathematical expressions based on machine learning. We design an unsupervised representation learning task that combines embedding learning with self-supervised learning. Using graph convolutional neural networks we embed mathematical expression into low-dimensional vector spaces that allow efficient nearest neighbor queries. To train our models, we collect a huge dataset with over 29 million mathematical expressions from over 900,000 publications published on arXiv.org. The math is converted into an XML format, which we view as graph data. Our empirical evaluations involving a new dataset of manually annotated search queries show the benefits of using embedding models for mathematical retrieval.","[{""name"":""Lukas Pfahler"",""id"":""/profile/99659575211""},{""name"":""Katharina Morik"",""id"":""/profile/81100595925""},{""name"":""Lukas Pfahler"",""id"":""/profile/99659575211""},{""name"":""Katharina Morik"",""id"":""/profile/81100595925""}]","[""JM. Á lvaro Mu n oz, F.; Sá nchez Peiró, JA.; Benedí Ruiz. 2014. Recognition of On-line Handwritten Mathematical Expressions Using 2D Stochastic Context-Free Grammars and Hidden Markov Models. Pattern Recognition Letters (2014), 58--67.Google Scholar"",""Vassileios Balntas, Edgar Riba, Daniel Ponsa, and Krystian Mikolajczyk. 2016. Learning local feature descriptors with triplets and shallow convolutional neural networks. In Proceedings of the British Machine Vision Conference (BMVC), Richard C. Wilson, Edwin R. Hancock, and William A. P. Smith (Eds.). BMVA Press, 119.1--119.11.Google ScholarCross Ref"",""Stephan Clé mencc on, Igor Colin, and Auré lien Bellet. 2016. Scaling-up Empirical Risk Minimization: Optimization of Incomplete U-statistics. Journal of Machine Learning Research, Vol. 17 (2016), 1--36. arxiv: arXiv:1501.02629v4Google Scholar"",""Yuntian Deng, Anssi Kanervisto, Jeffrey Ling, and Alexander M Rush. 2017. Image-to-Markup Generation with Coarse-to-Fine Attention. In Proceedings of the 34th International Conference on Machine Learning. 980---989.Google ScholarDigital Library"",""Jacob Devlin, Ming-Wei Chang, Lee Kenton, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of NAACL-HLT 2019. Association for Computational Linguistics, 4171--4186.Google Scholar"",""Shengyong Ding, Liang Lin, Guangrun Wang, and Hongyang Chao. 2015. Deep feature learning with relative distance comparison for person re-identification. Pattern Recognition, Vol. 48, 10 (2015), 2993--3003.Google ScholarDigital Library"",""David K. Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Alán Aspuru-Guzik, and Ryan P. Adams. 2015. Convolutional networks on graphs for learning molecular fingerprints. In Advances in neural information processing systems. 2224--2232.Google Scholar"",""Torsten A. Enßlin, Mona Frommert, and Francisco S. Kitaura. 2009. Information field theory for cosmological perturbation reconstruction and nonlinear signal analysis. Phys. Rev. D, Vol. 80, 10 (nov 2009), 105005.Google ScholarCross Ref"",""Matthias Fey and Jan Eric Lenssen. 2019. Fast Graph Representation Learning with PyTorch Geometric. In ICLR Workshop on Representation Learning on Graphs and Manifolds.Google Scholar"",""Spyros Gidaris, Praveer Singh, and Nikos Komodakis. 2018. Unsupervised Representation Learning by Predicting Image Rotations. In ICLR 2018. 1--16.Google Scholar"",""Ferruccio Guidi and Claudio Sacerdoti Coen. 2016. A survey on retrieval of mathematical knowledge. Mathematics in Computer Science, Vol. 10, 4 (2016), 409--427.Google ScholarCross Ref"",""Wassily Hoeffding. 1948. A class of statistics with asymptotically normal distribution. Annals of Statistics (1948).Google Scholar"",""Sergey Ioffe and Christian Szegedy. 2015. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. In Proceedings of the 32nd International Conference on Machine Learning (Proceedings of Machine Learning Research), Francis Bach and David Blei (Eds.), Vol. 37. PMLR, Lille, France, 448--456.Google ScholarDigital Library"",""Svante Janson. 2003. Large Deviations for Sums of Partly Dependent Random Variables. Random Structures \u0026 Algorithms, Vol. 24, 3 (2003), 234--248.Google ScholarCross Ref"",""Mahshad Mahdavi, Richard Zanibbi, Harold Mouch, and Christian Viard-gaudin. 2019. ICDAR 2019 CROHME+TFD: Competition on Recognition of Handwritten Mathematical Expressions and Typeset Formula Detection. In 15th IAPR International Conference on Document Analysis and Recognition (ICDAR 2019).Google Scholar"",""Behrooz Mansouri, Douglas W Oard, C Lee Giles, and Richard Zanibbi. 2019. Tangent-CFT : An Embedding Model for Mathematical Formulas. In Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval.Google ScholarDigital Library"",""Andreas Maurer. 2008. Learning similarity with operator-valued large-margin classifiers. Journal of Machine Learning Research, Vol. 9 (2008), 1049--1082.Google ScholarDigital Library"",""Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean, Kai Chen, and Jeffrey Dean. 2013. Efficient Estimation of Word Representations in Vector Space. In 1st International Conference on Learning Representations.Google Scholar"",""Christopher Morris, Martin Ritzert, Matthias Fey, William L Hamilton, Jan Eric Lenssen, Gaurav Rattan, and Martin Grohe. 2019. Weisfeiler and leman go neural: Higher-order graph neural networks. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 4602--4609.Google ScholarCross Ref"",""Lukas Pfahler, Jonathan Schill, and Katharina Morik. 2019. The Search for Equations - Learning to Identify Similarities between Mathematical Expressions. In Machine Learning and Knowledge Discovery in Databases. ECML PKDD 2019.Google Scholar"",""Richard M Timoney. 1999. OpenMath LaTeX to OpenMath Converter. Technical Report. 1--9 pages. https://www.maths.tcd.ie/ richardt/openmath/ml2om.pdfGoogle Scholar"",""Trieu H Trinh, Minh-thang Luong, Quoc V Le, and Google Brain. 2019. Selfie : Self-supervised Pretraining for Image Embedding. (2019).Google Scholar"",""Evgeniya Ustinova and Victor Lempitsky. 2016. Learning Deep Embeddings with Histogram Loss. In Advances In Neural Information Precessing Systems 2016.Google Scholar"",""Vladimir N. Vapnik. 2000. The Nature of Statistical Learning Theory second ed.). Springer. https://doi.org/10.1109/TNN.1997.641482Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention Is All You Need. Advances in Neural Information Processing Systems (2017).Google Scholar"",""Lei Wang, Yan Wang, Deng Cai, Dongxiang Zhang, and Xiaojiang Liu. 2018. Translating Math Word Problem to Expression Tree. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 31 - November 4, 2018. 1064--1069.Google ScholarCross Ref"",""Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E Sarma, Michael M Bronstein, and Justin M Solomon. 2019. Dynamic graph cnn for learning on point clouds. ACM Transactions on Graphics (TOG), Vol. 38, 5 (2019), 1--12.Google ScholarDigital Library"",""Richard Zanibbi, Kenny Davila, Andrew Kane, and Frank Wm. Tompa. 2016a. Multi-Stage Math Formula Search: Using Appearance-Based Similarity Metrics at Scale. In Proc. of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM, New York, NY, USA, 145---154.Google ScholarDigital Library"",""Richard Zanibbi, Goran Topi, Michael Kohlhase, and Kenny Davila. 2016b. NTCIR-12 MathIR Task Overview. In Proceedings of the 12th NTCIR Conference on Evaluation of Information Access Technologies. Tokyo, Japan.Google Scholar"",""Wei Zhong and Richard Zanibbi. 2019. Structural Similarity Search for Formulas using Leaf-Root Paths in Operator Subtrees. In European Conference on Information Retrieval. Springer, 116--129.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403057,SSumM: Sparse Summarization of Massive Graphs,"Given a graph G and the desired size k in bits, how can we summarize G within k bits, while minimizing the information loss?Large-scale graphs have become omnipresent, posing considerable computational challenges. Analyzing such large graphs can be fast and easy if they are compressed sufficiently to fit in main memory or even cache. Graph summarization, which yields a coarse-grained summary graph with merged nodes, stands out with several advantages among graph compression techniques. Thus, a number of algorithms have been developed for obtaining a concise summary graph with little information loss or equivalently small reconstruction error. However, the existing methods focus solely on reducing the number of nodes, and they often yield dense summary graphs, failing to achieve better compression rates. Moreover, due to their limited scalability, they can be applied only to moderate-size graphs.In this work, we propose SSumM, a scalable and effective graph-summarization algorithm that yields a sparse summary graph. SSumM not only merges nodes together but also sparsifies the summary graph, and the two strategies are carefully balanced based on the minimum description length principle. Compared with state-of-the-art competitors, SSumM is (a) Concise: yields up to 11.2X smaller summary graphs with similar reconstruction error, (b) Accurate: achieves up to 4.2X smaller reconstruction error with similarly concise outputs, and (c) Scalable: summarizes 26X larger graphs while exhibiting linear scalability. We validate these advantages through extensive experiments on 10 real-world graphs.","[{""name"":""Kyuhan Lee"",""id"":""/profile/99659573782""},{""name"":""Hyeonsoo Jo"",""id"":""/profile/99659574055""},{""name"":""Jihoon Ko"",""id"":""/profile/99659439562""},{""name"":""Sungsu Lim"",""id"":""/profile/99659572962""},{""name"":""Kijung Shin"",""id"":""/profile/99658999309""},{""name"":""Kyuhan Lee"",""id"":""/profile/99659573782""},{""name"":""Hyeonsoo Jo"",""id"":""/profile/99659574055""},{""name"":""Jihoon Ko"",""id"":""/profile/99659439562""},{""name"":""Sungsu Lim"",""id"":""/profile/99659572962""},{""name"":""Kijung Shin"",""id"":""/profile/99658999309""}]","[""Ankit Aggarwal, Amit Deshpande, and Ravi Kannan. 2009. Adaptive sampling for k-means clustering. In Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques. Springer, 15--28.Google Scholar"",""Alberto Apostolico and Guido Drovandi. 2009. Graph compression by BFS. Algorithms, Vol. 2, 3 (2009), 1031--1044.Google ScholarCross Ref"",""Maham Anwar Beg, Muhammad Ahmad, Arif Zaman, and Imdadullah Khan. 2018. Scalable approximation algorithm for graph summarization. In PAKDD.Google Scholar"",""Manuel Blum, Robert W. Floyd, Vaughan R. Pratt, Ronald L. Rivest, and Robert Endre Tarjan. 1973. Time bounds for selection. JCSS, Vol. 7, 4 (1973), 448--461.Google ScholarDigital Library"",""Paolo Boldi and Sebastiano Vigna. 2004. The webgraph framework I: compression techniques. In WWW.Google Scholar"",""Gregory Buehrer and Kumar Chellapilla. 2008. A scalable pattern mining approach to web graph compression with communities. In WSDM.Google Scholar"",""Flavio Chierichetti, Ravi Kumar, Silvio Lattanzi, Michael Mitzenmacher, Alessandro Panconesi, and Prabhakar Raghavan. 2009. On compressing social networks. In KDD.Google Scholar"",""Avery Ching, Sergey Edunov, Maja Kabiljo, Dionysios Logothetis, and Sambavi Muthukrishnan. 2015. One trillion edges: graph processing at Facebook-scale. PVLDB, Vol. 8, 12 (2015), 1804--1815.Google ScholarDigital Library"",""Graham Cormode and Shan Muthukrishnan. 2005. An improved data stream summary: the count-min sketch and its applications. Journal of Algorithms, Vol. 55, 1 (2005), 58--75.Google ScholarDigital Library"",""Cody Dunne and Ben Shneiderman. 2013. Motif simplification: improving network visualization readability with fan, connector, and clique glyphs. In SIGCHI.Google Scholar"",""Piotr Indyk. 2006. Stable distributions, pseudorandom generators, embeddings, and data stream computation. JACM, Vol. 53, 3 (2006), 307--323.Google ScholarDigital Library"",""Kifayat Ullah Khan, Waqas Nawaz, and Young-Koo Lee. 2014. Set-based unified approach for attributed graph summarization. In CBDCom.Google Scholar"",""Kifayat Ullah Khan, Waqas Nawaz, and Young-Koo Lee. 2015. Set-based approximate approach for lossless graph summarization. Computing, Vol. 97, 12 (2015), 1185--1207.Google ScholarDigital Library"",""Scott Kirkpatrick, C Daniel Gelatt, and Mario P Vecchi. 1983. Optimization by simulated annealing. Science, Vol. 220, 4598 (1983), 671--680.Google Scholar"",""Bryan Klimt and Yiming Yang. 2004. Introducing the Enron corpus. In CEAS.Google Scholar"",""DE Knuth. 1969. Seminymerical Algorithms. The Art of Computer Programming, Vol. 2.Google Scholar"",""Jihoon Ko, Yunbum Kook, and Kijung Shin. 2020. Incremental Lossless Graph Summarization. In KDD.Google Scholar"",""Danai Koutra, U Kang, Jilles Vreeken, and Christos Faloutsos. 2014. VoG: Summarizing and understanding large graphs. In SDM.Google Scholar"",""Kristen LeFevre and Evimaria Terzi. 2010. GraSS: Graph structure summarization. In SDM.Google Scholar"",""Jure Leskovec, Lada A Adamic, and Bernardo A Huberman. 2007. The dynamics of viral marketing. TWEB, Vol. 1, 1 (2007), 5.Google ScholarDigital Library"",""Jure Leskovec, Jon Kleinberg, and Christos Faloutsos. 2005. Graphs over time: densification laws, shrinking diameters and possible explanations. In KDD.Google Scholar"",""Jure Leskovec and Julian J Mcauley. 2012. Learning to discover social circles in ego networks. In NIPS.Google Scholar"",""Yu Ru Lin, Hari Sundaram, and Aisling Kelliher. 2008. Summarization of social activity over time: People, actions and concepts in dynamic networks. In CIKM.Google Scholar"",""Yike Liu, Tara Safavi, Abhilash Dighe, and Danai Koutra. 2018. Graph summarization methods and applications: A survey. CSUR, Vol. 51, 3 (2018), 62.Google ScholarDigital Library"",""Robert Meusel, Sebastiano Vigna, Oliver Lehmberg, and Christian Bizer. 2015. The Graph Structure in the Web - Analyzed on Different Aggregation Levels. The Journal of Web Science, Vol. 1, 1 (2015), 33--47.Google ScholarCross Ref"",""Saket Navlakha, Rajeev Rastogi, and Nisheeth Shrivastava. 2008. Graph summarization with bounded error. In SIGMOD.Google Scholar"",""Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. 1999. The PageRank citation ranking: Bringing order to the web. Technical Report. Stanford InfoLab.Google Scholar"",""Matteo Riondato, David Garc'ia-Soriano, and Francesco Bonchi. 2017. Graph summarization with quality guarantees. DMKD, Vol. 31, 2 (2017), 314--349.Google ScholarDigital Library"",""Jorma Rissanen. 1978. Modeling by shortest data description. Automatica, Vol. 14, 5 (1978), 465--471.Google ScholarDigital Library"",""Neil Shah, Danai Koutra, Tianmin Zou, Brian Gallagher, and Christos Faloutsos. 2015. Timecrunch: Interpretable dynamic graph summarization. In KDD.Google ScholarDigital Library"",""Claude E Shannon and Warren Weaver. 1998. The mathematical theory of communication .University of Illinois Press.Google Scholar"",""Zeqian Shen, Kwan-Liu Ma, and Tina Eliassi-Rad. 2006. Visual analysis of large heterogeneous social networks by semantic and structural abstraction. IEEE TVCG, Vol. 12, 6 (2006), 1427--1439.Google Scholar"",""Kijung Shin, Amol Ghoting, Myunghwan Kim, and Hema Raghavan. 2019. SWeG: Lossless and lossy summarization of web-scale graphs. In WWW.Google Scholar"",""Yuanyuan Tian, Richard A. Hankins, and Jignesh M. Patel. 2008. Efficient aggregation for graph summarization. In SIGMOD.Google Scholar"",""Hannu Toivonen, Fang Zhou, Aleksi Hartikainen, and Atte Hinkka. 2011. Compression of weighted graphs. In KDD.Google Scholar"",""Charalampos Tsourakakis. 2015. The k-clique densest subgraph problem. In WWW.Google Scholar"",""Jaewon Yang and Jure Leskovec. 2015. Defining and evaluating network communities based on ground-truth. KAIS, Vol. 42, 1 (2015), 181--213.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403058,Rethinking Pruning for Accelerating Deep Inference At the Edge,"There is a growing trend to deploy deep neural networks at the edge for high-accuracy, real-time data mining and user interaction. Applications such as speech recognition and language understanding often apply a deep neural network to encode an input sequence and then use a decoder to generate the output sequence. A promising technique to accelerate these applications on resource-constrained devices is network pruning, which compresses the size of the deep neural network without severe drop in inference accuracy. However, we observe that although existing network pruning algorithms prove effective to speed up the prior deep neural network, they lead to dramatic slowdown of the subsequent decoding and may not always reduce the overall latency of the entire application. To rectify such drawbacks, we propose entropy-based pruning, a new regularizer that can be seamlessly integrated into existing network pruning algorithms. Our key theoretical insight is that reducing the information entropy of the deep neural network outputs decreases the upper bound of the subsequent decoding search space. We validate our solution with two state-of-the-art network pruning algorithms on two model architectures. Experimental results show that compared with existing network pruning algorithms, our entropy-based pruning method notably suppresses and even eliminates the increase of decoding time, and achieves shorter overall latency with only negligible extra accuracy loss in the applications.","[{""name"":""Dawei Gao"",""id"":""/profile/99659574500""},{""name"":""Xiaoxi He"",""id"":""/profile/99659358339""},{""name"":""Zimu Zhou"",""id"":""/profile/99659574512""},{""name"":""Yongxin Tong"",""id"":""/profile/81507682062""},{""name"":""Ke Xu"",""id"":""/profile/81548031869""},{""name"":""Lothar Thiele"",""id"":""/profile/81100389521""},{""name"":""Dawei Gao"",""id"":""/profile/99659574500""},{""name"":""Xiaoxi He"",""id"":""/profile/99659358339""},{""name"":""Zimu Zhou"",""id"":""/profile/99659574512""},{""name"":""Yongxin Tong"",""id"":""/profile/81507682062""},{""name"":""Ke Xu"",""id"":""/profile/81548031869""},{""name"":""Lothar Thiele"",""id"":""/profile/81100389521""}]","[""Yunji Chen, Tianshi Chen, Zhiwei Xu, Ninghui Sun, and Olivier Temam. 2016. DianNao family: energy-efficient hardware accelerators for machine learning. Commun. ACM, Vol. 59, 11 (2016), 105--112.Google Scholar"",""Bin Dai, Chen Zhu, Baining Guo, and David Wipf. 2018. Compressing neural networks using the variational information bottleneck. In Proceedings of International Conference on Machine Learning. ACM, New York, NY, USA, 1143--1152.Google Scholar"",""Misha Denil, Babak Shakibi, Laurent Dinh, Nando De Freitas, et al. 2013. Predicting parameters in deep learning. In Proceedings of Advances In Neural Information Processing Systems. Curran Associates Inc., Red Hook, NY, USA, 2148--2156.Google Scholar"",""Xin Dong, Shangyu Chen, and Sinno Pan. 2017. Learning to prune deep neural networks via layer-wise optimal brain surgeon. In Proceedings of Advances in Neural Information Processing Systems. Curran Associates Inc., Red Hook, NY, USA, 4860--4874.Google Scholar"",""Sadaoki Furui. 1986. Speaker-independent isolated word recognition based on emphasized spectral dynamics. In Proceedings of International Conference on Acoustics, Speech, and Signal Processing, Vol. 11. IEEE Press, Piscataway, NJ, USA, 1991--1994.Google Scholar"",""Petko Georgiev, Nicholas D Lane, Cecilia Mascolo, and David Chu. 2017. Accelerating mobile audio sensing algorithms through on-chip gpu offloading. In Proceedings of Annual International Conference on Mobile Systems, Applications, and Services. ACM, New York, NY, USA, 306--318.Google Scholar"",""Alex Graves. 2012. Supervised sequence labelling. In Supervised sequence labelling with recurrent neural networks. Springer, 5--13.Google Scholar"",""Song Han, Xingyu Liu, Huizi Mao, Jing Pu, Ardavan Pedram, Mark A Horowitz, and William J Dally. 2016a. EIE: efficient inference engine on compressed deep neural network. In Proceedings of Annual International Symposium on Computer Architecture. ACM, New York, NY, USA, 243--254.Google Scholar"",""Song Han, Huizi Mao, and William J Dally. 2016b. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. In Proceedings of International Conference on Learning Representations.Google Scholar"",""Awni Hannun, Carl Case, Jared Casper, Bryan Catanzaro, Greg Diamos, Erich Elsen, Ryan Prenger, Sanjeev Satheesh, Shubho Sengupta, Adam Coates, et al. 2014. Deep speech: scaling up end-to-end speech recognition. arxiv: 1412.5567Google Scholar"",""Geoffrey Hinton, Li Deng, Dong Yu, George Dahl, Abdel-rahman Mohamed, Navdeep Jaitly, Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Brian Kingsbury, et al. 2012. Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups. IEEE Signal Processing Magazine, Vol. 29, 6 (2012), 82--97.Google Scholar"",""Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirectional LSTM-CRF Models for Sequence Tagging. arxiv: 1508.01991Google Scholar"",""Yiping Kang, Johann Hauswald, Cao Gao, Austin Rovinski, Trevor Mudge, Jason Mars, and Lingjia Tang. 2017. Neurosurgeon: collaborative intelligence between the cloud and mobile edge. In Proceedings of International Conference on Architectural Support for Programming Languages and Operating Systems. ACM, New York, NY, USA, 615--629.Google Scholar"",""Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Optimization. In Proceedings of International Conference on Learning Representations.Google Scholar"",""Nicholas D Lane, Sourav Bhattacharya, Petko Georgiev, Claudio Forlivesi, Lei Jiao, Lorena Qendro, and Fahim Kawsar. 2016. DeepX: A software accelerator for low-power deep learning inference on mobile devices. In Proceedings of International Conference on Information Processing in Sensor Networks. ACM, New York, NY, USA, 1--12.Google Scholar"",""Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans Peter Graf. 2017. Pruning filters for efficient convnets. In Proceedings of International Conference on Learning Representations.Google Scholar"",""Sparsh Mittal. 2019. A Survey on optimized implementation of deep learning models on the NVIDIA Jetson platform. Journal of Systems Architecture - Embedded Systems Design, Vol. 97 (2019), 428--442.Google Scholar"",""Mehryar Mohri, Fernando Pereira, and Michael Riley. 2002. Weighted finite-state transducers in speech recognition. Computer Speech \u0026 Language, Vol. 16, 1 (2002), 69--88.Google Scholar"",""Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur. 2015. Librispeech: An ASR corpus based on public domain audio books. In Proceedings of International Conference on Acoustics, Speech and Signal Processing. IEEE Press, Piscataway, NJ, USA, 5206--5210.Google Scholar"",""Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. Glove: Global Vectors for Word Representation. In Proceedings of Conference on Empirical Methods in Natural Language Processing. 1532--1543.Google Scholar"",""Daniel Povey, Arnab Ghoshal, Gilles Boulianne, Lukas Burget, Ondrej Glembek, Nagendra Goel, Mirko Hannemann, Petr Motlicek, Yanmin Qian, Petr Schwarz, Jan Silovsky, Georg Stemmer, and Karel Vesely. 2011. The Kaldi Speech Recognition Toolkit. In Proceedings of Workshop on Automatic Speech Recognition and Understanding. IEEE Press, Piscataway, NJ, USA.Google Scholar"",""Rohit Prabhavalkar, Kanishka Rao, Tara N. Sainath, Bo Li, Leif Johnson, and Navdeep Jaitly. 2017. A Comparison of Sequence-to-Sequence Models for Speech Recognition. In Proceedings of Interspeech. 939--943.Google Scholar"",""Mirco Ravanelli, Titouan Parcollet, and Yoshua Bengio. 2019. The Pytorch-kaldi Speech Recognition Toolkit. In Proceedings of International Conference on Acoustics, Speech and Signal Processing. IEEE Press, Piscataway, NJ, USA, 6465--6469.Google Scholar"",""Erik F. Tjong Kim Sang and Fien De Meulder. 2003. Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition. In Proceedings of Conference on Natural Language Learning at HLT-NAACL. ACL, Stroudsburg, PA, USA, 142--147.Google Scholar"",""Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Sequence to sequence learning with neural networks. In Proceedings of Advances in Neural Information Processing Systems. Curran Associates Inc., Red Hook, NY, USA, 3104--3112.Google Scholar"",""Vivienne Sze, Yu-Hsin Chen, Tien-Ju Yang, and Joel S Emer. 2017. Efficient processing of deep neural networks: A tutorial and survey. Proc. IEEE, Vol. 105, 12 (2017), 2295--2329.Google Scholar"",""Subhashini Venugopalan, Marcus Rohrbach, Jeffrey Donahue, Raymond Mooney, Trevor Darrell, and Kate Saenko. 2015. Sequence to sequence-video to text. In Proceedings of International Conference on Computer Vision. IEEE Press, Piscataway, NJ, USA, 4534--4542.Google Scholar"",""Wayne Xiong, Jasha Droppo, Xuedong Huang, Frank Seide, Michael Seltzer, Andreas Stolcke, Dong Yu, and Geoffrey Zweig. 2017. The microsoft 2016 conversational speech recognition system. In Proceedings of International Conference on Acoustics, Speech and Signal Processing. IEEE Press, Piscataway, NJ, USA, 5934--5938.Google Scholar"",""Vikas Yadav and Steven Bethard. 2018. A Survey on Recent Advances in Named Entity Recognition from Deep Learning models. In Proceedings of International Conference on Computational Linguistics. ACL, Santa Fe, NM, USA, 2145--2158.Google Scholar"",""Reza Yazdani, Marc Riera, Jose-Maria Arnau, and Antonio González. 2018. The dark side of DNN pruning. In Proceedings of Annual International Symposium on Computer Architecture. ACM, New York, NY, USA, 790--801.Google Scholar"",""Shiliang Zhang, Ming Lei, Zhijie Yan, and Lirong Dai. 2018. Deep-FSMN for Large Vocabulary Continuous Speech Recognition. In Proceedings of International Conference on Acoustics, Speech and Signal Processing. IEEE Press, Piscataway, NJ, USA, 5869--5873.Google Scholar"",""Zhi Zhou, Xu Chen, En Li, Liekang Zeng, Ke Luo, and Junshan Zhang. 2019. Edge Intelligence: Paving the Last Mile of Artificial Intelligence With Edge Computing. Proc. IEEE, Vol. 107, 8 (2019), 1738--1762.Google Scholar""]"
https://doi.org/10.1145/3394486.3403060,Structural Patterns and Generative Models of Real-world Hypergraphs,"Graphs have been utilized as a powerful tool to model pairwise relationships between people or objects. Such structure is a special type of a broader concept referred to as hypergraph, in which each hyperedge may consist of an arbitrary number of nodes, rather than just two. A large number of real-world datasets are of this form - for example, lists of recipients of emails sent from an organization, users participating in a discussion thread or subject labels tagged in an online question. However, due to complex representations and lack of adequate tools, little attention has been paid to exploring the underlying patterns in these interactions.In this work, we empirically study a number of real-world hypergraph datasets across various domains. In order to enable thorough investigations, we introduce the multi-level decomposition method, which represents each hypergraph by a set of pairwise graphs. Each pairwise graph, which we refer to as a k-level decomposed graph, captures the interactions between pairs of subsets of k nodes. We empirically find that at each decomposition level, the investigated hypergraphs obey five structural properties. These properties serve as criteria for evaluating how realistic a hypergraph is, and establish a foundation for the hypergraph generation problem. We also propose a hypergraph generator that is remarkably simple but capable of fulfilling these evaluation metrics, which are hardly achieved by other baseline generator models.","[{""name"":""Manh Tuan Do"",""id"":""/profile/99659574197""},{""name"":""Se-eun Yoon"",""id"":""/profile/99659534632""},{""name"":""Bryan Hooi"",""id"":""/profile/99658996373""},{""name"":""Kijung Shin"",""id"":""/profile/99658999309""},{""name"":""Manh Tuan Do"",""id"":""/profile/99659574197""},{""name"":""Se-eun Yoon"",""id"":""/profile/99659534632""},{""name"":""Bryan Hooi"",""id"":""/profile/99658996373""},{""name"":""Kijung Shin"",""id"":""/profile/99658999309""}]","[""2020. Supplementary results, code and datasets. Available online: https://github.com/manhtuando97/KDD-20-Hypergraph.Google Scholar"",""James Abello, Adam L Buchsbaum, and Jeffery R Westbrook. 1998. A functional approach to external graph algorithms. In ESA.Google Scholar"",""James Abello, Panos M Pardalos, and Mauricio GC Resende. 2013. Handbook of massive data sets. Vol. 4. Springer.Google Scholar"",""Leman Akoglu, Mary McGlohon, and Christos Faloutsos. 2008. RTM: Laws and a recursive generator for weighted time-evolving graphs. In ICDM.Google Scholar"",""Leman Akoglu, Mary McGlohon, and Christos Faloutsos. 2010. Oddball: Spotting anomalies in weighted graphs. In PAKDD.Google Scholar"",""Réka Albert, Hawoong Jeong, and Albert-László Barabási. 1999. Internet: Diameter of the world-wide web. Nature, Vol. 401, 6749 (1999), 130.Google Scholar"",""Réka Albert, Hawoong Jeong, and Albert-László Barabási. 2002. Statistical mechanics of complex networks. Rev. Mod. Phys (2002).Google Scholar"",""Jeff Alstott and Dietmar Plenz Bullmore. 2014. powerlaw: a Python package for analysis of heavy-tailed distributions. PloS one, Vol. 9, 1 (2014).Google Scholar"",""Albert-László Barabási and Réka Albert. 1999. Emergence of scaling in random networks. Science, Vol. 286, 5439 (1999), 509--512.Google Scholar"",""Austin R Benson, Rediet Abebe, Michael T Schaub, Ali Jadbabaie, and Jon Kleinberg. 2018a. Simplicial closure and higher-order link prediction. Proc. Natl. Acad. Sci. U.S.A, Vol. 115, 48 (2018), E11221--E11230.Google ScholarCross Ref"",""Austin R Benson, David F Gleich, and Jure Leskovec. 2016. Higher-order organization of complex networks. Science, Vol. 353, 6295 (2016), 163--166.Google Scholar"",""Austin R Benson, Ravi Kumar, and Andrew Tomkins. 2018b. Sequences of sets. In KDD.Google Scholar"",""Béla Bollobás and Oliver Riordan. 2004. The diameter of a scale-free random graph. Combinatorica, Vol. 24, 1 (2004), 5--34.Google ScholarDigital Library"",""Phillip Bonacich, Annie Cody Holdren, and Michael Johnston. 2004. Hyper-edges and multi-dimensional centrality. Soc. Netw, Vol. 26, 3 (2004), 189--203.Google ScholarCross Ref"",""Andrei Broder, Ravi Kumar, Farzin Maghoul, Prabhakar Raghavan, Sridhar Rajagopalan, Raymie Stata, Andrew Tomkins, and Janet Wiener. 2000. Graph structure in the web. Computer networks, Vol. 33, 1--6 (2000), 309--320.Google Scholar"",""Berge C. 2013. Hypergraphs. Vol. 45. North Holland, Amsterdam.Google Scholar"",""Philip S Chodrow. 2019. Configuration Models of Random Hypergraphs and their Applications. arXiv preprint arXiv:1902.09302 (2019).Google Scholar"",""Fan Chung and Linyuan Lu. 2002. The average distances in random graphs with given expected degrees. Proc. Natl. Acad. Sci. U.S.A, Vol. 99, 25 (2002), 15879--15882.Google ScholarCross Ref"",""Aaron Clauset, Cosma Rohilla Shalizi, and Mark EJ Newman. 2009. Power-law distributions in empirical data. SIAM review, Vol. 51, 4 (2009), 661--703.Google Scholar"",""Colin Cooper and Alan Frieze. 2003. A general model of web graphs. Random Struct. Algorithms, Vol. 22, 3 (2003), 311--335.Google ScholarDigital Library"",""David Easley, Jon Kleinberg, et al. 2010. Networks, crowds, and markets. Vol. 8. Cambridge university press Cambridge.Google Scholar"",""Sergey Edunov, Dionysios Logothetis, Cheng Wang, Avery Ching, and Maja Kabiljo. 2016. Darwini: Generating realistic large-scale social graphs. arXiv:1610.00664 (2016).Google Scholar"",""Nicole Eikmeier and David F Gleich. 2017. Revisiting power-law distributions in spectra of real world networks. In KDD.Google Scholar"",""Michalis Faloutsos, Petros Faloutsos, and Christos Faloutsos. 1999. On power-law relationships of the internet topology. In ACM SIGCOMM computer communication review, Vol. 29. ACM, 251--262.Google Scholar"",""M. Girvan and M. E. J. Newman. 2002. Community structure in social and biological networks. Proc. Natl. Acad. Sci. U.S.A, Vol. 99 (2002).Google ScholarCross Ref"",""U Kang, Mary McGlohon, Leman Akoglu, and Christos Faloutsos. 2010. Patterns on the Connected Components of TerabyteScale Graphs. In ICDM.Google Scholar"",""Jon M Kleinberg. 2002. Small-world phenomena and the dynamics of information. In NIPS.Google Scholar"",""Jon M Kleinberg, Ravi Kumar, Prabhakar Raghavan, Sridhar Rajagopalan, and Andrew S Tomkins. 1999. The web as a graph: measurements, models, and methods. In COCOON.Google Scholar"",""Tamara G Kolda, Ali Pinar, Todd Plantenga, and Comandur Seshadhri. 2014. A scalable generative graph model with community structure. SIAM J. Sci. Comput, Vol. 36, 5 (2014), C424--C452.Google ScholarCross Ref"",""R. Kumar, P. Raghavan, S. Rajagopalan, D. Sivakumar, A. Tomkins, and E. Uptal. 2000. Stochastic models for the web graph. In FOCS.Google Scholar"",""Jure Leskovec, Lars Backstrom, Ravi Kumar, and Andrew Tomkins. 2008. Microscopic evolution of social networks. In KDD.Google Scholar"",""Jure Leskovec, Deepayan Chakrabarti, Jon Kleinberg, Christos Faloutsos, and Zoubin Ghahramani. 2010. Kronecker Graphs: An Approach to Modeling Networks. J. Mach. Learn. Res, Vol. 11 (2010), 985--1042.Google ScholarDigital Library"",""Jure Leskovec, Jon Kleinberg, and Christos Faloutsos. 2005. Graphs over time: densification laws, shrinking diameters and possible explanations. In KDD.Google Scholar"",""Hubert W Lilliefors. 1969. On the Kolmogorov-Smirnov test for the exponential distribution with mean unknown. J. Amer. Statist. Assoc., Vol. 64 (1969), 387--389.Google ScholarCross Ref"",""Paul Liu, Austin Benson, and Moses Charikar. 2019. A sampling framework for counting temporal motifs. In WSDM.Google Scholar"",""Priya Mahadevan, Dmitri Krioukov, Kevin Fall, and Amin Vahdat. 2006. Systematic topology analysis and generation using degree correlations. In SIGCOMM.Google Scholar"",""Stanley Milgram. 1967. The small-world problem. Psychology Today, Vol. 2, 1 (1967), 60--67.Google Scholar"",""Ron Milo, Shai Shen-Orr, Shalev Itzkovitz, Nadav Kashtan, Dmitri Chklovskii, and Uri Alon. 2002. Network motifs: simple building blocks of complex networks. Science, Vol. 298, 5594 (2002), 824--827.Google Scholar"",""Michael Mitzenmacher. 2004. A brief history of generative models for power law and lognormal distributions. Internet Mathematics, Vol. 1, 2 (2004), 226--251.Google ScholarCross Ref"",""Mark EJ Newman. 2001. Clustering and preferential attachment in growing networks. Physical review E, Vol. 64, 2 (2001), 025102.Google Scholar"",""Ashwin Paranjape, Austin R Benson, and Jure Leskovec. 2017. Motifs in temporal networks. In WSDM.Google Scholar"",""Alessandra Sala, Lili Cao, Christo Wilson, Robert Zablit, Haitao Zheng, and Ben Y Zhao. 2010. Measurement-calibrated graph models for social network experiments. In WWW.Google Scholar"",""Kijung Shin. 2017. Wrs: Waiting room sampling for accurate triangle counting in real graph streams. In ICDM.Google Scholar"",""Kijung Shin, Tina Eliassi-Rad, and Christos Faloutsos. 2018. Patterns and anomalies in k-cores of real-world graphs with applications. Knowl. Inf. Syst, Vol. 54, 3 (2018), 677--710.Google ScholarDigital Library"",""Arnab Sinha, Zhihong Shen, Yang Song, Hao Ma, Darrin Eide, Bo-June (Paul) Hsu, and Kuansan Wang. 2015. An Overview of Microsoft Academic Service (MAS) and Applications. In WWW.Google Scholar"",""Despina Stasi, Kayvan Sadeghi, Alessandro Rinaldo, Sonja Petrović, and Stephen E Fienberg. 2014. β models for random hypergraphs with a given degree sequence. arXiv preprint arXiv:1407.1004 (2014).Google Scholar"",""Alexei Vázquez. 2003. Growing network with local rules: Preferential attachment, clustering hierarchy, and degree correlations. Physical Review E, Vol. 67, 5 (2003), 056104.Google ScholarCross Ref"",""Duncan J Watts and Steven H Strogatz. 1998. Collective dynamics of ?small-world'networks. Nature, Vol. 393, 6684 (1998), 440.Google Scholar"",""Ye Xu, Dan Rockmore, and Adam M Kleinbaum. 2013. Hyperlink prediction in hypernetworks using latent social features. In DS.Google Scholar"",""Hao Yin, Austin R Benson, Jure Leskovec, and David F Gleich. 2017. Local higher-order graph clustering. In KDD.Google Scholar"",""Se-eun Yoon, Hyungseok Song, Kijung Shin, and Yung Yi. 2020. How Much and When Do We Need Higher-order Information in Hypergraphs? A Case Study on Hyperedge Prediction. In WWW.Google Scholar"",""Dengyong Zhou, Jiayuan Huang, and Bernhard Scholkopf. 2006. Learning with Hypergraphs: Clustering, Classification, and Embedding. In NIPS.Google Scholar""]"
https://doi.org/10.1145/3394486.3403061,Efficient Algorithm for the b-Matching Graph,"The b-matching graph is a useful approach to computing a graph from high-dimensional data. Unlike the k-NN graph that greedily connects each data point to its k nearest neighbors and typically has more than k edges, each data point in the b-matching graph uniformly has b edges; the idea is reduce edges between cross-clusters that have different semantics. In addition, edge weights are obtained from regression results of each data pointand restricted to be non-negative to improve the robustness for data noise. The b-matching graph can more effectively model high-dimensional data than the traditional k-NN graph. However, the construction cost of the b-matching graph is impractical for large-scale data sets. This is because, to determine edges in the graph, it needs to iteratively update messages between all pairs of data points until convergence, and it computes non-negative edge weights of each data point by applying a solver intended for quadratic programming problems. Our proposal, b-dash, can efficiently construct a b-matching graph because of its two key techniques: (1) it prunes unnecessary update messages in determining edges and (2) it incrementally computes edge weights by exploiting the Sherman-Morrison formula. Experiments show that our approach is up to 58.6 times faster than the previous approaches while guaranteeing result optimality.","[{""name"":""Yasuhiro Fujiwara"",""id"":""/profile/81367593789""},{""name"":""Atsutoshi Kumagai"",""id"":""/profile/99659087021""},{""name"":""Sekitoshi Kanai"",""id"":""/profile/99659477669""},{""name"":""Yasutoshi Ida"",""id"":""/profile/99658733121""},{""name"":""Naonori Ueda"",""id"":""/profile/81100364194""},{""name"":""Yasuhiro Fujiwara"",""id"":""/profile/81367593789""},{""name"":""Atsutoshi Kumagai"",""id"":""/profile/99659087021""},{""name"":""Sekitoshi Kanai"",""id"":""/profile/99659477669""},{""name"":""Yasutoshi Ida"",""id"":""/profile/99658733121""},{""name"":""Naonori Ueda"",""id"":""/profile/81100364194""}]","[""Christopher M. Bishop. 2004. Pattern Recognition and Machine Learning. Springer.Google Scholar"",""Olivier Chapelle, Bernhard Schölkopf, and Alexander Zien (Eds.). 2006. Semi-Supervised Learning .The MIT Press.Google Scholar"",""Thomas H. Cormen, Charles E. Leiserson Ronald L. Rivest, and Clifford Stein. 2009. Introduction to Algorithms. The MIT Press.Google Scholar"",""Ehsan Elhamifar and René Vidal. 2013. Sparse Subspace Clustering: Algorithm, Theory, and Applications. IEEE Trans. Pattern Anal. Mach. Intell., Vol. 35, 11 (2013), 2765--2781.Google ScholarDigital Library"",""Yasuhiro Fujiwara, Yasutoshi Ida, Hiroaki Shiokawa, and Sotetsu Iwamura. 2016. Fast Lasso Algorithm via Selective Coordinate Descent. In AAAI. 1561--1567.Google Scholar"",""Yasuhiro Fujiwara, Go Irie, Shari Kuroyama, and Makoto Onizuka. 2014. Scaling Manifold Ranking Based Image Retrieval. Proc. VLDB Endow., Vol. 8, 4 (2014), 341--352.Google ScholarDigital Library"",""Yasuhiro Fujiwara, Naoki Marumo, Mathieu Blondel, Koh Takeuchi, Hideaki Kim, Tomoharu Iwata, and Naonori Ueda. 2017. Scaling Locally Linear Embedding. In SIGMOD. 1479--1492.Google Scholar"",""Yasuhiro Fujiwara, Makoto Nakatsuji, Hiroaki Shiokawa, Yasutoshi Ida, and Machiko Toyoda. 2015. Adaptive Message Update for Fast Affinity Propagation. In SIGKDD. 309--318.Google Scholar"",""Yasuhiro Fujiwara and Dennis E. Shasha. 2015. Quiet: Faster Belief Propagation for Images and Related Applications. In IJCAI. 3497--3503.Google Scholar"",""Harold N. Gabow and Robert Endre Tarjan. 1989. Faster Scaling Algorithms for Network Problems. SIAM J. Comput., Vol. 18, 5 (1989), 1013--1036.Google ScholarDigital Library"",""Brian Gallagher, Hanghang Tong, Tina Eliassi-Rad, and Christos Faloutsos. 2008. Using Ghost Edges for Classification in Sparsely Labeled Networks. In KDD. 256--264.Google Scholar"",""Donald Goldfarb and Shucheng Liu. 1991. An O(n(^3 )L) Primal Interior Point Aalgorithm for Convex Quadratic Programming. Math. Program., Vol. 49 (1991), 325--340.Google ScholarDigital Library"",""Nathan Halko, Per-Gunnar Martinsson, and Joel A. Tropp. 2011. Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions. SIAM Rev., Vol. 53, 2 (2011), 217--288.Google ScholarDigital Library"",""Bert Huang and Tony Jebara. 2007. Loopy Belief Propagation for Bipartite Maximum Weight b-Matching. In AISTATS. 195--202.Google Scholar"",""Bert Huang and Tony Jebara. 2011. Fast b-matching via Sufficient Selection Belief Propagation. In AISTATS. 361--369.Google Scholar"",""Tony Jebara, Jun Wang, and Shih-Fu Chang. 2009. Graph Construction and b-matching for Semi-supervised Learning. In ICML. 441--448.Google Scholar"",""Pilsung Kang and Sungzoon Cho. 2008. Locally Linear Reconstruction for Instance-based Learning. Pattern Recognition, Vol. 41, 11 (2008), 3507--3518.Google ScholarDigital Library"",""Arif M. Khan, Alex Pothen, Md. Mostofa Ali Patwary, Nadathur Rajagopalan Satish, Narayanan Sundaram, Fredrik Manne, Mahantesh Halappanavar, and Pradeep Dubey. 2016. Efficient Approximation Algorithms for Weighted b-Matching. SIAM J. Scientific Computing , Vol. 38, 5 (2016).Google ScholarCross Ref"",""Yuancheng Li, Rui Xiao, Jingang Feng, and Liujun Zhao. 2013. A Semi-supervised Learning Approach for Detection of Phishing Webpages. Optik, Vol. 124, 23 (2013), 6027 -- 6033.Google ScholarCross Ref"",""Makoto Nakatsuji, Yasuhiro Fujiwara, Hiroyuki Toda, Hiroshi Sawada, Jinguang Zheng, and James A. Hendler. 2014. Semantic Data Representation for Improving Tensor Factorization. In AAAI. 2004--2012.Google Scholar"",""Kohei Ozaki, Masashi Shimbo, Mamoru Komachi, and Yuji Matsumoto. 2011. Using the Mutual k-Nearest Neighbor Graphs for Semi-supervised Classification on Natural Language Data. In CoNLL. 154--162.Google Scholar"",""John Platt. 1998. Sequential Minimal Optimization: a Fast Algorithm for Training Support Vector Machines. MSR-TR 98--14 (1998).Google Scholar"",""Piotr Sankowski. 2009. Maximum weight bipartite matching in matrix multiplication time. Theor. Comput. Sci., Vol. 410, 44 (2009), 4480--4488.Google ScholarDigital Library"",""Lawrence K. Saul and Sam T. Roweis. 2001. An Introduction to Locally Linear Embedding.Google Scholar"",""Dennis Shasha and Yunyue Zhu. 2004. High Performance Discovery In Time Series: Techniques And Case Studies. SpringerVerlag.Google Scholar"",""J. Michael Steele. 2004. The Cauchy-Schwarz Master Class: An Introduction to the Art of Mathematical Inequalities. The Mathematical Association of America.Google Scholar"",""Yusuke Tanaka, Takeshi Kurashima, Yasuhiro Fujiwara, Tomoharu Iwata, and Hiroshi Sawada. 2016. Inferring Latent Triggers of Purchases with Consideration of Social Effects and Media Advertisements. In WSDM. 543--552.Google Scholar"",""Ulrike von Luxburg. 2007. A Tutorial on Spectral Clustering. Statistics and Computing , Vol. 17, 4 (2007), 395--416.Google ScholarDigital Library"",""Ming-Bo Zhao, Rosa H. M. Chan, Tommy W. S. Chow, and Peng Tang. 2014. Compact Graph based Semi-Supervised Learning for Medical Diagnosis in Alzheimer's Disease. IEEE Signal Process. Lett., Vol. 21, 10 (2014), 1192--1196.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403062,Isolation Distributional Kernel: A New Tool for Kernel based Anomaly Detection,"We introduce Isolation Distributional Kernel as a new way to measure the similarity between two distributions. Existing approaches based on kernel mean embedding, which converts a point kernel to a distributional kernel, have two key issues: the point kernel employed has a feature map with intractable dimensionality; and it is data independent. This paper shows that Isolation Distributional Kernel (IDK), which is based on a data dependent point kernel, addresses both key issues. We demonstrate IDK's efficacy and efficiency as a new tool for kernel based anomaly detection. Without explicit learning, using IDK alone outperforms existing kernel based anomaly detector OCSVM and other kernel mean embedding methods that rely on Gaussian kernel. We reveal for the first time that an effective kernel based anomaly detector based on kernel mean embedding must employ a characteristic kernel which is data dependent.","[{""name"":""Kai Ming Ting"",""id"":""/profile/81100367824""},{""name"":""Bi-Cun Xu"",""id"":""/profile/99659455151""},{""name"":""Takashi Washio"",""id"":""/profile/99659575045""},{""name"":""Zhi-Hua Zhou"",""id"":""/profile/81451593001""},{""name"":""Kai Ming Ting"",""id"":""/profile/81100367824""},{""name"":""Bi-Cun Xu"",""id"":""/profile/99659455151""},{""name"":""Takashi Washio"",""id"":""/profile/99659575045""},{""name"":""Zhi-Hua Zhou"",""id"":""/profile/81451593001""}]","[""Charu C. Aggarwal and Saket Sathe. 2017. Outlier Ensembles: An Introduction .Springer International Publishing.Google Scholar"",""Tharindu R. Bandaragoda, Kai Ming Ting, David Albrecht, Fei Tony Liu, Ye Zhu, and Jonathan R. Wells. 2018. Isolation-based Anomaly Detection using nearest neighbour ensembles. Computational Intelligence, Vol. 34, 4 (2018), 968--998.Google ScholarCross Ref"",""Vasili Baranau and Ulrich Tallarek. 2014. Random-close packing limits for monodisperse and polydisperse hard spheres. Soft Matter, Vol. 10 (2014), 3826--3841.Google ScholarCross Ref"",""Liefeng Bo and Cristian Sminchisescu. 2009. Efficient Match Kernels Between Sets of Features for Visual Recognition. In Proceedings of the 22nd International Conference on Neural Information Processing Systems. 135--143.Google Scholar"",""Janez Demvsar. 2006. Statistical Comparisons of Classifiers over Multiple Data Sets. Journal of Machine Learning Research (2006), 1--30.Google Scholar"",""Andrew Emmott, Shubhomoy Das, Thomas G. Dietterich, Alan Fern, and Weng-Keen Wong. 2016. A Meta-Analysis of the Anomaly Detection Problem. CoRR, Vol. abs/1503.01158 (2016).Google Scholar"",""Fukunaga Keinosuke. 1990. Introduction to Statistical Pattern Recognition .Academic Press, Chapter 6, 268--270.Google Scholar"",""Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. 2008. Isolation forest. In Proceedings of the IEEE International Conference on Data Mining. 413--422.Google ScholarDigital Library"",""Krikamol Muandet, Kenji Fukumizu, Francesco Dinuzzo, and Bernhard Scholkopf. 2012. Learning from Distributions via Support Measure Machines. Advances in Neural Information Processing Systems. 10--18.Google Scholar"",""Krikamol Muandet, Kenji Fukumizu, Bharath Sriperumbudur, and Bernhard Schölkopf. 2017. Kernel Mean Embedding of Distributions: A Review and Beyond. Foundations and Trends in Machine Learning, Vol. 10 (1--2) (2017), 1--141.Google ScholarCross Ref"",""Krikamol Muandet and Bernhard Schölkopf. 2013. One-class Support Measure Machines for Group Anomaly Detection. In Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence. 449--458.Google ScholarDigital Library"",""Cameron Musco and Christopher Musco. 2017. Recursive sampling for the nystrom method. In Advances in Neural Information Processing Systems. 3833--3845.Google Scholar"",""Xiaoyu Qin, Kai Ming Ting, Ye Zhu, and Vincent Cheng Siong Lee. 2019. Nearest-Neighbour-Induced Isolation Similarity and Its Impact on Density-Based Clustering. In Proceedings of The Thirty-Third AAAI Conference on Artificial Intelligence.Google ScholarCross Ref"",""Ali Rahimi and Benjamin Recht. 2007. Random Features for Large-scale Kernel Machines. Proceedings of the 20th International Conference on Neural Information Processing Systems. 1177--1184.Google Scholar"",""Bernhard Schölkopf, John C. Platt, John C. Shawe-Taylor, Alex J. Smola, and Robert C. Williamson. 2001. Estimating the Support of a High-Dimensional Distribution. Neural Computing, Vol. 13, 7 (2001), 1443--1471.Google ScholarDigital Library"",""Alex Smola, Arthur Gretton, Le Song, and Bernhard Schölkopf. 2007. A Hilbert Space Embedding for Distributions. In Algorithmic Learning Theory, Marcus Hutter, Rocco A. Servedio, and Eiji Takimoto (Eds.). Springer, 13--31.Google Scholar"",""Chaoming Song, Ping Wang, and Hernan A. Makse. 2008. A phase diagram for jammed matter. Nature, Vol. 453, 7195 (2008), 629--632.Google Scholar"",""Bharath K. Sriperumbudur, Arthur Gretton, Kenji Fukumizu, Bernhard Schölkopf, and Gert R.G. Lanckriet. 2010. Hilbert Space Embeddings and Metrics on Probability Measures. Journal of Machine Learning Research, Vol. 11 (2010), 1517--1561.Google ScholarDigital Library"",""Dougal J. Sutherland. 2016. Scalable, Flexible and Active Learning on Distributions .PhD Thesis, School of Computer Science, Carnegie Mellon University.Google Scholar"",""Kai Ming Ting, Yue Zhu, and Zhi-Hua Zhou. 2018. Isolation Kernel and its effect on SVM. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 2329--2337.Google ScholarDigital Library"",""Kilian Q. Weinberger and Lawrence K. Saul. 2009. Distance metric learning for large margin nearest neighbor classification. Journal of Machine Learning Research, Vol. 10, 2 (2009), 207--244.Google ScholarDigital Library"",""Christopher K. I. Williams and Matthias Seeger. 2001. Using the Nyström Method to Speed Up Kernel Machines. Advances in Neural Information Processing Systems 13, T. K. Leen, T. G. Dietterich, and V. Tresp (Eds.). 682--688.Google Scholar"",""Eric P. Xing, Andrew Y. Ng, Michael I. Jordan, and Stuart Russell. 2002. Distance Metric Learning, with Application to Clustering with Side-information. In Proceedings of the 15th International Conference on Neural Information Processing Systems. 521--528.Google ScholarDigital Library"",""Tianbao Yang, Yu-Feng Li, Mehrdad Mahdavi, Rong Jin, and Zhi-Hua Zhou. 2012. Nyström Method vs Random Fourier Features: A Theoretical and Empirical Comparison. In Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1 (NIPS'12). Curran Associates Inc., USA, 476--484.Google Scholar"",""Pourya Zadeh, Reshad Hosseini, and Suvrit Sra. 2016. Geometric mean metric learning. In International Conference on Machine Learning. 2464--2471.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403063,NodeAug: Semi-Supervised Node Classification with Data Augmentation,"By using Data Augmentation (DA), we present a new method to enhance Graph Convolutional Networks (GCNs), that are the state-of-the-art models for semi-supervised node classification. DA for graph data remains under-explored. Due to the connections built by edges, DA for different nodes influence each other and lead to undesired results, such as uncontrollable DA magnitudes and changes of ground-truth labels. To address this issue, we present the NodeAug (Node-Parallel Augmentation) scheme, that creates a 'parallel universe' for each node to conduct DA, to block the undesired effects from other nodes. NodeAug regularizes the model prediction of every node (including unlabeled) to be invariant with respect to changes induced by Data Augmentation (DA), so as to improve the effectiveness. To augment the input features from different aspects, we propose three DA strategies by modifying both node attributes and the graph structure. In addition, we introduce the subgraph mini-batch training for the efficient implementation of NodeAug. The approach takes the subgraph corresponding to the receptive fields of a batch of nodes as the input per iteration, rather than the whole graph that the prior full-batch training takes. Empirically, NodeAug yields significant gains for strong GCN models on the Cora, Citeseer, Pubmed, and two co-authorship networks, with a more efficient training process thanks to the proposed subgraph mini-batch training approach.","[{""name"":""Yiwei Wang"",""id"":""/profile/99659218057""},{""name"":""Wei Wang"",""id"":""/profile/99658652029""},{""name"":""Yuxuan Liang"",""id"":""/profile/99659140812""},{""name"":""Yujun Cai"",""id"":""/profile/99659574206""},{""name"":""Juncheng Liu"",""id"":""/profile/99659573652""},{""name"":""Bryan Hooi"",""id"":""/profile/99658996373""},{""name"":""Yiwei Wang"",""id"":""/profile/99659218057""},{""name"":""Wei Wang"",""id"":""/profile/99658652029""},{""name"":""Yuxuan Liang"",""id"":""/profile/99659140812""},{""name"":""Yujun Cai"",""id"":""/profile/99659574206""},{""name"":""Juncheng Liu"",""id"":""/profile/99659573652""},{""name"":""Bryan Hooi"",""id"":""/profile/99658996373""}]","[""David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver, and Colin A Raffel. 2019. Mixmatch: A holistic approach to semi-supervised learning. In Advances in Neural Information Processing Systems. 5050--5060.Google Scholar"",""Marcus D Bloice, Christof Stocker, and Andreas Holzinger. 2017. Augmentor: An Image Augmentation Library for Machine Learning. arXiv preprint arXiv:1708.04680 (2017).Google Scholar"",""Andreas Buja, Dianne Cook, and Deborah F Swayne. 1996. Interactive high-dimensional data visualization. Journal of computational and graphical statistics, Vol. 5, 1 (1996), 78--99.Google Scholar"",""Aydin Bulucc and Kamesh Madduri. 2011. Parallel breadth-first search on distributed memory systems. In Proceedings of 2011 International Conference for High Performance Computing, Networking, Storage and Analysis. 1--12.Google Scholar"",""Olivier Chapelle and Alexander Zien. 2005. Semi-supervised classification by low density separation. In AISTATS, Vol. 2005. Citeseer, 57--64.Google Scholar"",""Kevin Clark, Minh-Thang Luong, Christopher D Manning, and Quoc V Le. 2018. Semi-supervised sequence modeling with cross-view training. arXiv preprint arXiv:1809.08370 (2018).Google Scholar"",""Zhijie Deng, Yinpeng Dong, and Jun Zhu. 2019. Batch virtual adversarial training for graph convolutional networks. arXiv preprint arXiv:1902.09192 (2019).Google Scholar"",""Terrance DeVries and Graham W Taylor. 2017. Improved Regularization of Convolutional Neural Networks with Cutout. arXiv preprint arXiv:1708.04552 (2017).Google Scholar"",""Ming Ding, Jie Tang, and Jie Zhang. 2018. Semi-supervised learning on graphs with generative adversarial nets. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management. 913--922.Google ScholarDigital Library"",""Holger Ebel, Lutz-Ingo Mielsch, and Stefan Bornholdt. 2002. Scale-free topology of e-mail networks. Physical review E, Vol. 66, 3 (2002), 035103.Google Scholar"",""Fuli Feng, Xiangnan He, Jie Tang, and Tat-Seng Chua. 2019. Graph adversarial training: Dynamically regularizing based on graph structure. IEEE Transactions on Knowledge and Data Engineering (2019).Google Scholar"",""Hongyang Gao and Shuiwang Ji. 2019. Graph U-Nets. arXiv preprint arXiv:1905.05178 (2019).Google Scholar"",""Hongyang Gao, Zhengyang Wang, and Shuiwang Ji. 2018. Large-Scale Learnable Graph Convolutional Networks. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 1416--1424.Google ScholarDigital Library"",""Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. Deep learning .MIT press.Google Scholar"",""James M Joyce. 2011. Kullback-leibler divergence. International encyclopedia of statistical science (2011), 720--722.Google Scholar"",""Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping Tak Peter Tang. 2016. On large-batch training for deep learning: Generalization gap and sharp minima. arXiv preprint arXiv:1609.04836 (2016).Google Scholar"",""Thomas N Kipf and Max Welling. 2016. Semi-supervised Classification With Graph Convolutional Networks. arXiv preprint arXiv:1609.02907 (2016).Google Scholar"",""Samuli Laine and Timo Aila. 2016. Temporal ensembling for semi-supervised learning. arXiv preprint arXiv:1610.02242 (2016).Google Scholar"",""Ben London and Lise Getoor. 2014. Collective Classification of Network Data. Data Classification: Algorithms and Applications, Vol. 399 (2014).Google Scholar"",""Lijuan Luo, Martin Wong, and Wen-mei Hwu. 2010. An effective GPU implementation of breadth-first search. In Design Automation Conference. IEEE, 52--55.Google ScholarDigital Library"",""Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. 2018. Virtual adversarial training: a regularization method for supervised and semi-supervised learning. IEEE transactions on pattern analysis and machine intelligence, Vol. 41, 8 (2018), 1979--1993.Google Scholar"",""Meng Qu, Yoshua Bengio, and Jian Tang. 2019. Gmnn: Graph markov neural networks. arXiv preprint arXiv:1905.06214 (2019).Google Scholar"",""Pei Quan, Yong Shi, Minglong Lei, Jiaxu Leng, Tianlin Zhang, and Lingfeng Niu. 2019. A Brief Review of Receptive Fields in Graph Convolutional Networks. In IEEE/WIC/ACM International Conference on Web Intelligence-Volume 24800. ACM, 106--110.Google ScholarDigital Library"",""Oleksandr Shchur, Maximilian Mumme, Aleksandar Bojchevski, and Stephan Günnemann. 2018. Pitfalls of graph neural network evaluation. arXiv preprint arXiv:1811.05868 (2018).Google Scholar"",""Krishna Kumar Singh, Hao Yu, Aron Sarmasi, Gautam Pradeep, and Yong Jae Lee. 2018. Hide-and-Seek: A Data Augmentation Technique for Weakly-Supervised Localization and Beyond. arXiv preprint arXiv:1811.02545 (2018).Google Scholar"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph Attention Networks. arXiv preprint arXiv:1710.10903 (2017).Google Scholar"",""Vikas Verma, Alex Lamb, Juho Kannala, Yoshua Bengio, and David Lopez-Paz. 2019 a. Interpolation consistency training for semi-supervised learning. arXiv preprint arXiv:1903.03825 (2019).Google Scholar"",""Vikas Verma, Meng Qu, Alex Lamb, Yoshua Bengio, Juho Kannala, and Jian Tang. 2019 b. GraphMix: Regularized Training of Graph Neural Networks for Semi-Supervised Learning. arXiv preprint arXiv:1909.11715 (2019).Google Scholar"",""Xiaoyun Wang, Joe Eaton, Cho-Jui Hsieh, and Felix Wu. 2018. Attack Graph Convolutional Networks by Adding Fake Nodes. arXiv preprint arXiv:1810.10751 (2018).Google Scholar"",""Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and Philip S Yu. 2019. A Comprehensive Survey on Graph Neural Networks. arXiv preprint arXiv:1901.00596 (2019).Google Scholar"",""Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Luong, and Quoc V Le. 2019. Unsupervised Data Augmentation. arXiv preprint arXiv:1904.12848 (2019).Google Scholar"",""Zhilin Yang, William W Cohen, and Ruslan Salakhutdinov. 2016. Revisiting semi-supervised learning with graph embeddings. arXiv preprint arXiv:1603.08861 (2016).Google Scholar"",""Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. 2017. mixup: Beyond empirical risk minimization. arXiv preprint arXiv:1710.09412 (2017).Google Scholar"",""Zhun Zhong, Liang Zheng, Guoliang Kang, Shaozi Li, and Yi Yang. 2017. Random erasing data augmentation. arXiv preprint arXiv:1708.04896 (2017).Google Scholar""]"
https://doi.org/10.1145/3394486.3403064,An Embarrassingly Simple Approach for Trojan Attack in Deep Neural Networks,"With the widespread use of deep neural networks (DNNs) in high-stake applications, the security problem of the DNN models has received extensive attention. In this paper, we investigate a specific security problem called trojan attack, which aims to attack deployed DNN systems relying on the hidden trigger patterns inserted by malicious hackers. We propose a training-free attack approach which is different from previous work, in which trojaned behaviors are injected by retraining model on a poisoned dataset. Specifically, we do not change parameters in the original model but insert a tiny trojan module (TrojanNet) into the target model. The infected model with a malicious trojan can misclassify inputs into a target label when the inputs are stamped with the special trigger. The proposed TrojanNet has several nice properties including (1) it activates by tiny trigger patterns and keeps silent for other signals, (2) it is model-agnostic and could be injected into most DNNs, dramatically expanding its attack scenarios, and (3) the training-free mechanism saves massive training efforts comparing to conventional trojan attack methods. The experimental results show that TrojanNet can inject the trojan into all labels simultaneously (all-label trojan attack) and achieves 100% attack success rate without affecting model accuracy on original tasks. Experimental analysis further demonstrates that state-of-the-art trojan detection algorithms fail to detect TrojanNet attack. The code is available at https://github.com/trx14/TrojanNet.","[{""name"":""Ruixiang Tang"",""id"":""/profile/99659573022""},{""name"":""Mengnan Du"",""id"":""/profile/99659286475""},{""name"":""Ninghao Liu"",""id"":""/profile/99659230760""},{""name"":""Fan Yang"",""id"":""/profile/99659368666""},{""name"":""Xia Hu"",""id"":""/profile/99659128094""},{""name"":""Ruixiang Tang"",""id"":""/profile/99659573022""},{""name"":""Mengnan Du"",""id"":""/profile/99659286475""},{""name"":""Ninghao Liu"",""id"":""/profile/99659230760""},{""name"":""Fan Yang"",""id"":""/profile/99659368666""},{""name"":""Xia Hu"",""id"":""/profile/99659128094""}]","[""[n.d.]. Amazon Machine Learning. https://aws.amazon.com/machine-learning/.Accessed: 2019-01-31.Google Scholar"",""[n.d.]. BigML. https://bigml.com/. Accessed: 2019-01-31.Google Scholar"",""[n.d.]. Speech Recognition with the Caffe deep learning framework. https://github.com/pannous/caffe-speech-recognition. Accessed: 2019-01-31.Google Scholar"",""Yossi Adi, Carsten Baum, Moustapha Cisse, Benny Pinkas, and Joseph Keshet. 2018. Turning your weakness into a strength: Watermarking deep neural networks by backdooring. In 27th USENIX Security Symposium ($$USENIX$$ Security 18). 1615--1631.Google Scholar"",""Yoshua Bengio, Jérôme Louradour, Ronan Collobert, and Jason Weston. 2009. Curriculum learning. In Proceedings of the 26th annual international conference on machine learning. 41--48.Google ScholarDigital Library"",""Bryant Chen, Wilka Carvalho, Nathalie Baracaldo, Heiko Ludwig, Benjamin Edwards, Taesung Lee, Ian Molloy, and Biplav Srivastava. 2018. Detecting backdoor attacks on deep neural networks by activation clustering. arXiv preprint arXiv:1811.03728 (2018).Google Scholar"",""Chenyi Chen, Ari Seff, Alain Kornhauser, and Jianxiong Xiao. 2015. Deepdriving: Learning affordance for direct perception in autonomous driving. In Proceedings of the IEEE International Conference on Computer Vision. 2722--2730.Google ScholarDigital Library"",""Huili Chen, Cheng Fu, Jishen Zhao, and Farinaz Koushanfar. 2019. Deepinspect: A black-box trojan detection and mitigation framework for deep neural networks. In Proceedings of the 28th International Joint Conference on Artificial Intelligence. AAAI Press. 4658--4664.Google ScholarCross Ref"",""Xinyun Chen, Chang Liu, Bo Li, Kimberly Lu, and Dawn Song. 2017. Targeted backdoor attacks on deep learning systems using data poisoning. arXiv preprint arXiv:1712.05526 (2017).Google Scholar"",""Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition. Ieee, 248--255.Google ScholarCross Ref"",""Mengnan Du, Ninghao Liu, and Xia Hu. 2019. Techniques for interpretable machine learning. Commun. ACM, Vol. 63, 1 (2019), 68--77.Google ScholarDigital Library"",""Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2014. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572 (2014).Google Scholar"",""Alex Graves, Abdel-rahman Mohamed, and Geoffrey Hinton. 2013. Speech recognition with deep recurrent neural networks. In 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 6645--6649.Google ScholarCross Ref"",""Tianyu Gu, Brendan Dolan-Gavitt, and Siddharth Garg. 2017. Badnets: Identifying vulnerabilities in the machine learning model supply chain. arXiv preprint arXiv:1708.06733 (2017).Google Scholar"",""David Gunning. 2017. Explainable artificial intelligence (xai). Defense Advanced Research Projects Agency (DARPA), nd Web, Vol. 2 (2017).Google Scholar"",""Wenbo Guo, Lun Wang, Xinyu Xing, Min Du, and Dawn Song. 2019. Tabor: A highly accurate approach to inspecting and restoring trojan backdoors in ai systems. arXiv preprint arXiv:1908.01763 (2019).Google Scholar"",""Xijie Huang, Moustafa Alzantot, and Mani Srivastava. 2019. NeuronInspect: Detecting Backdoors in Neural Networks via Output Explanations. arXiv preprint arXiv:1911.07399 (2019).Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Neeraj Kumar, Alexander C Berg, Peter N Belhumeur, and Shree K Nayar. 2009. Attribute and simile classifiers for face verification. In 2009 IEEE 12th international conference on computer vision. IEEE, 365--372.Google ScholarCross Ref"",""Alexey Kurakin, Ian Goodfellow, and Samy Bengio. 2016. Adversarial examples in the physical world. arXiv preprint arXiv:1607.02533 (2016).Google Scholar"",""Christophe Leys, Christophe Ley, Olivier Klein, Philippe Bernard, and Laurent Licata. 2013. Detecting outliers: Do not use standard deviation around the mean, use absolute deviation around the median. Journal of Experimental Social Psychology, Vol. 49, 4 (2013), 764--766.Google ScholarCross Ref"",""Shaofeng Li, Benjamin Zi Hao Zhao, Jiahao Yu, Minhui Xue, Dali Kaafar, and Haojin Zhu. 2019. Invisible Backdoor Attacks Against Deep Neural Networks. arXiv preprint arXiv:1909.02742 (2019).Google Scholar"",""Cong Liao, Haoti Zhong, Anna Squicciarini, Sencun Zhu, and David Miller. 2018. Backdoor embedding in convolutional neural network models via invisible perturbation. arXiv preprint arXiv:1808.10307 (2018).Google Scholar"",""Kang Liu, Brendan Dolan-Gavitt, and Siddharth Garg. 2018. Fine-pruning: Defending against backdooring attacks on deep neural networks. In International Symposium on Research in Attacks, Intrusions, and Defenses. Springer, 273--294.Google ScholarCross Ref"",""Yingqi Liu, Shiqing Ma, Yousra Aafer, Wen-Chuan Lee, Juan Zhai, Weihang Wang, and Xiangyu Zhang. 2017. Trojaning attack on neural networks. (2017).Google Scholar"",""Riccardo Miotto, Fei Wang, Shuang Wang, Xiaoqian Jiang, and Joel T Dudley. 2018. Deep learning for healthcare: review, opportunities and challenges. Briefings in bioinformatics, Vol. 19, 6 (2018), 1236--1246.Google Scholar"",""NHTSA. 2016. Tesla Crash Preliminary Evaluation Report. Technical report. National Highway Traffic Safety Administration,U.S. Department of Transportation.Google Scholar"",""Omkar M Parkhi, Andrea Vedaldi, and Andrew Zisserman. 2015. Deep face recognition. (2015).Google Scholar"",""Nicolas Pinto, Zak Stone, Todd Zickler, and David Cox. 2011. Scaling up biologically-inspired computer vision: A case study in unconstrained face recognition on facebook. In CVPR 2011 WORKSHOPS. IEEE, 35--42.Google ScholarCross Ref"",""Wojciech Samek, Thomas Wiegand, and Klaus-Robert Müller. 2017. Explainable artificial intelligence: Understanding, visualizing and interpreting deep learning models. arXiv preprint arXiv:1708.08296 (2017).Google Scholar"",""Ali Shafahi, W Ronny Huang, Mahyar Najibi, Octavian Suciu, Christoph Studer, Tudor Dumitras, and Tom Goldstein. 2018. Poison frogs! targeted clean-label poisoning attacks on neural networks. In Advances in Neural Information Processing Systems. 6103--6113.Google Scholar"",""J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel. 2012. Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition. Neural Networks 0 (2012), --. https://doi.org/10.1016/j.neunet.2012.02.016Google Scholar"",""Brandon Tran, Jerry Li, and Aleksander Madry. 2018. Spectral signatures in backdoor attacks. In Advances in Neural Information Processing Systems. 8000--8010.Google Scholar"",""Bolun Wang, Yuanshun Yao, Shawn Shan, Huiying Li, Bimal Viswanath, Haitao Zheng, and Ben Y Zhao. 2019. Neural cleanse: Identifying and mitigating backdoor attacks in neural networks. In 2019 IEEE Symposium on Security and Privacy (SP). IEEE, 707--723.Google ScholarCross Ref"",""Lior Wolf, Tal Hassner, and Itay Maoz. 2011. Face recognition in unconstrained videos with matched background similarity. In CVPR 2011. IEEE, 529--534.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403065,Kronecker Attention Networks,"Attention operators have been applied on both 1-D data like texts and higher-order data such as images and videos. Use of attention operators on high-order data requires flattening of the spatial or spatial-temporal dimensions into a vector, which is assumed to follow a multivariate normal distribution. This not only incurs excessive requirements on computational resources, but also fails to preserve structures in data. In this work, we propose to avoid flattening by assuming the data follow matrix-variate normal distributions. Based on this new view, we develop Kronecker attention operators (KAOs) that operate on high-order tensor data directly. More importantly, the proposed KAOs lead to dramatic reductions in computational resources. Experimental results show that our methods reduce the amount of required computational resources by a factor of hundreds, with larger factors for higher-dimensional and higher-order data. Results also show that networks with KAOs outperform models without attention, while achieving competitive performance as those with original attention operators.","[{""name"":""Hongyang Gao"",""id"":""/profile/99659287317""},{""name"":""Zhengyang Wang"",""id"":""/profile/99659364282""},{""name"":""Shuiwang Ji"",""id"":""/profile/81333489125""},{""name"":""Hongyang Gao"",""id"":""/profile/99659287317""},{""name"":""Zhengyang Wang"",""id"":""/profile/99659364282""},{""name"":""Shuiwang Ji"",""id"":""/profile/81333489125""}]","[""Mart'in Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et almbox. 2016. Tensorflow: a system for large-scale machine learning.. In OSDI, Vol. 16. 265--283.Google ScholarDigital Library"",""Genevera I Allen and Robert Tibshirani. 2010. Transposable regularized covariance models with an application to missing data imputation. The Annals of Applied Statistics , Vol. 4, 2 (2010), 764.Google ScholarCross Ref"",""Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural machine translation by jointly learning to align and translate. International Conference on Learning Representations (2015).Google Scholar"",""Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L Yuille. 2018. Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. IEEE transactions on pattern analysis and machine intelligence , Vol. 40, 4 (2018), 834--848.Google Scholar"",""J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. 2009. ImageNet: A Large-Scale Hierarchical Image Database. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition .Google Scholar"",""Mark Everingham, Luc Van Gool, Christopher KI Williams, John Winn, and Andrew Zisserman. 2010. The pascal visual object classes (voc) challenge. International journal of computer vision , Vol. 88, 2 (2010), 303--338.Google Scholar"",""Hongyang Gao and Shuiwang Ji. 2019. Graph representation learning via hard and channel-wise attention networks. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 741--749.Google ScholarDigital Library"",""Hongyang Gao, Zhengyang Wang, and Shuiwang Ji. 2018a. ChannelNets: Compact and Efficient Convolutional Neural Networks via Channel-Wise Convolutions. In Advances in Neural Information Processing Systems. 5203--5211.Google Scholar"",""Hongyang Gao, Zhengyang Wang, and Shuiwang Ji. 2018b. Large-scale learnable graph convolutional networks. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining . 1416--1424.Google ScholarDigital Library"",""Xavier Glorot and Yoshua Bengio. 2010. Understanding the difficulty of training deep feedforward neural networks. In Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics. 249--256.Google Scholar"",""Alexander Graham. 2018. Kronecker products and matrix calculus with applications .Courier Dover Publications.Google Scholar"",""Arjun K Gupta and Daya K Nagar. 2018. Matrix variate distributions .Chapman and Hall/CRC.Google Scholar"",""Bharath Hariharan, Pablo Arbeláez, Lubomir Bourdev, Subhransu Maji, and Jitendra Malik. 2011. Semantic contours from inverse detectors. In Computer Vision (ICCV), 2011 IEEE International Conference on. IEEE, 991--998.Google ScholarDigital Library"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition. 770--778.Google ScholarCross Ref"",""Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. 2017. Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861 (2017).Google Scholar"",""Zilong Huang, Xinggang Wang, Lichao Huang, Chang Huang, Yunchao Wei, and Wenyu Liu. 2018. CCNet: Criss-Cross Attention for Semantic Segmentation. arXiv preprint arXiv:1811.11721 (2018).Google Scholar"",""Forrest N Iandola, Song Han, Matthew W Moskewicz, Khalid Ashraf, William J Dally, and Kurt Keutzer. 2016. SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and \u003c 0.5 MB model size. arXiv preprint arXiv:1602.07360 (2016).Google Scholar"",""Sergey Ioffe and Christian Szegedy. 2015. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. In International Conference on Machine Learning . 448--456.Google ScholarDigital Library"",""Rie Johnson and Tong Zhang. 2015. Semi-supervised convolutional neural networks for text categorization via region embedding. In Advances in neural information processing systems. 919--927.Google Scholar"",""Alfredo Kalaitzis, John Lafferty, Neil Lawrence, and Shuheng Zhou. 2013. The bigraphical lasso. In International Conference on Machine Learning . 1229--1237.Google Scholar"",""Tamara G. Kolda and Brett W. Bader. 2009. Tensor Decompositions and Applications. SIAM Rev. , Vol. 51, 3 (2009), 455--500.Google ScholarDigital Library"",""Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. 1998. Gradient-based learning applied to document recognition. Proc. IEEE , Vol. 86, 11 (1998), 2278--2324.Google ScholarCross Ref"",""Guanbin Li, Xiang He, Wei Zhang, Huiyou Chang, Le Dong, and Liang Lin. 2018. Non-locally Enhanced Encoder-Decoder Network for Single Image De-raining. In 2018 ACM Multimedia Conference on Multimedia Conference. ACM, 1056--1064.Google Scholar"",""Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C Lawrence Zitnick. 2014. Microsoft coco: Common objects in context. In European conference on computer vision. Springer, 740--755.Google ScholarCross Ref"",""Wei Liu, Andrew Rabinovich, and Alexander C Berg. 2015. Parsenet: Looking wider to see better. arXiv preprint arXiv:1506.04579 (2015).Google Scholar"",""Jiasen Lu, Jianwei Yang, Dhruv Batra, and Devi Parikh. 2016. Hierarchical question-image co-attention for visual question answering. In Advances In Neural Information Processing Systems. 289--297.Google Scholar"",""Mateusz Malinowski, Carl Doersch, Adam Santoro, and Peter Battaglia. 2018. Learning Visual Question Answering by Bootstrapping Hard Attention. In Proceedings of the European Conference on Computer Vision (ECCV). 3--20.Google ScholarCross Ref"",""Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. 2018. Mobilenetv2: Inverted residuals and linear bottlenecks. In 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. IEEE, 4510--4520.Google ScholarCross Ref"",""Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: A simple way to prevent neural networks from overfitting. Journal of Machine Learning Research , Vol. 15, 1 (2014), 1929--1958.Google ScholarDigital Library"",""Ilya Sutskever, James Martens, George Dahl, and Geoffrey Hinton. 2013. On the importance of initialization and momentum in deep learning. In International conference on machine learning. 1139--1147.Google ScholarDigital Library"",""Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky. 2016. Instance Normalization: The Missing Ingredient for Fast Stylization. arXiv preprint arXiv:1607.08022 (2016).Google Scholar"",""Charles F Van Loan. 2000. The ubiquitous Kronecker product. Journal of computational and applied mathematics , Vol. 123, 1--2 (2000), 85--100.Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems. 5998--6008.Google Scholar"",""Petar Velivc ković , Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. 2017. Graph Attention Networks. arXiv preprint arXiv:1710.10903 (2017).Google Scholar"",""Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He. 2018. Non-local neural networks. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Vol. 1. 4.Google ScholarCross Ref"",""Zhengyang Wang and Shuiwang Ji. 2018. Smoothed Dilated Convolutions for Improved Dense Prediction. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 2486--2495.Google ScholarDigital Library"",""Zhengyang Wang, Hao Yuan, and Shuiwang Ji. 2019. Spatial Variational Auto-Encoding via Matrix-Variate Normal Distributions. In Proceedings of the 2019 SIAM International Conference on Data Mining. SIAM, 648--656.Google ScholarCross Ref"",""Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhudinov, Rich Zemel, and Yoshua Bengio. 2015. Show, attend and tell: Neural image caption generation with visual attention. In International conference on machine learning. 2048--2057.Google ScholarDigital Library"",""Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, and Jian Sun. 2017. Shufflenet: An extremely efficient convolutional neural network for mobile devices. arXiv preprint arXiv:1707.01083 (2017).Google Scholar"",""Hengshuang Zhao, Yi Zhang, Shu Liu, Jianping Shi, Chen Change Loy, Dahua Lin, and Jiaya Jia. 2018. PSANet: Point-wise Spatial Attention Network for Scene Parsing. In Proceedings of the European Conference on Computer Vision (ECCV). 267--283.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403066,GRACE: Generating Concise and Informative Contrastive Sample to Explain Neural Network Model's Prediction,"Despite the recent development in the topic of explainable AI/ML for image and text data, the majority of current solutions are not suitable to explain the prediction of neural network models when the datasets are tabular and their features are in high-dimensional vectorized formats. To mitigate this limitation, therefore, we borrow two notable ideas (i.e., ""explanation by intervention"" from causality and ""explanation are contrastive"" from philosophy) and propose a novel solution, named as GRACE, that better explains neural network models' predictions for tabular datasets. In particular, given a model's prediction as label X, GRACE intervenes and generates a minimally-modified contrastive sample to be classified as Y, with an intuitive textual explanation, answering the question of ""Why X rather than Y?"" We carry out comprehensive experiments using eleven public datasets of different scales and domains (e.g., # of features ranges from 5 to 216) and compare GRACE with competing baselines on different measures: fidelity, conciseness, info-gain, and influence. The user-studies show that our generated explanation is not only more intuitive and easy-to-understand but also facilitates end-users to make as much as 60% more accurate post-explanation decisions than that of Lime.","[{""name"":""Thai Le"",""id"":""/profile/99659574694""},{""name"":""Suhang Wang"",""id"":""/profile/99659577116""},{""name"":""Dongwon Lee"",""id"":""/profile/81452592724""},{""name"":""Thai Le"",""id"":""/profile/99659574694""},{""name"":""Suhang Wang"",""id"":""/profile/99659577116""},{""name"":""Dongwon Lee"",""id"":""/profile/81452592724""}]","[""Sercan O Arik and Tomas Pfister. 2019. TabNet: Attentive Interpretable Tabular Learning. arXiv preprint arXiv:1908.07442 (2019).Google Scholar"",""Björn Barz and Joachim Denzler. 2019. Deep Learning on Small Datasets without Pre-Training using Cosine Loss. arXiv preprint arXiv:1901.09054 (2019).Google Scholar"",""Babak Ehteshami Bejnordi, Mitko Veta, Van Diest, et al. 2017. Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer. Jama, Vol. 318, 22 (2017), 2199--2210.Google ScholarCross Ref"",""Lingyang Chu, Xia Hu, Juhua Hu, Lanjun Wang, and Jian Pei. 2018. Exact and consistent interpretation for piecewise linear neural networks: A closed form solution. In ACM SIGKDD/KDD. ACM, 1244--1253.Google Scholar"",""Anupam Datta, Shayak Sen, and Yair Zick. 2016. Algorithmic transparency via quantitative input influence: Theory and experiments with learning systems. In 2016 IEEE SP. IEEE, 598--617.Google Scholar"",""Matthew F Dixon, Nicholas G Polson, and Vadim O Sokolov. [n. d.]. Deep learning for spatio-temporal modeling: Dynamic traffic flows and high frequency trading. Applied Stochastic Models in Business and Industry ([n. d.]).Google Scholar"",""Dheeru Dua and Casey Graff. 2017. UCI Machine Learning Repository.Google Scholar"",""Usama Fayyad and Keki Irani. 1993. Multi-interval discretization of continuous-valued attributes for classification learning. (1993).Google Scholar"",""Thomas Fischer and Christopher Krauss. [n. d.]. Deep learning with long short-term memory networks for financial market predictions. EJOR, Vol. 270 ([n. d.]).Google Scholar"",""Brian P Flannery, Saul A Teukolsky, William H Press, and William T Vetterling. 1988. Numerical recipes in C: The art of scientific computing. Vol. 2.Google Scholar"",""Xavier Glorot and Yoshua Bengio. 2010. Understanding the difficulty of training deep feedforward neural networks. In AISTATS. 249--256.Google Scholar"",""Andrej Karpathy, Justin Johnson, and Li Fei-Fei. 2015. Visualizing and understanding recurrent networks. arXiv preprint arXiv:1506.02078 (2015).Google Scholar"",""Rajiv Khanna, Ethan Elenberg, Alexandros G Dimakis, Sahand Negahban, and Joydeep Ghosh. 2017. Scalable greedy feature selection via weak submodularity. arXiv preprint arXiv:1703.02723 (2017).Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Michal Kosinski, David Stillwell, and Thore Graepel. 2013. Private traits and attributes are predictable from digital records of human behavior. National Academy of Sciences, Vol. 110, 15 (2013), 5802--5805.Google ScholarCross Ref"",""David Lewis. 2013. Counterfactuals .John Wiley \u0026 Sons.Google Scholar"",""Jiwei Li, Xinlei Chen, Eduard Hovy, and Dan Jurafsky. 2015. Visualizing and understanding neural models in nlp. arXiv preprint arXiv:1506.01066 (2015).Google Scholar"",""Zachary C Lipton. [n. d.]. The mythos of model interpretability. Queue ([n. d.]).Google Scholar"",""Samaneh Mahdavifar and Ali A Ghorbani. 2019. Application of deep learning to cybersecurity: A survey. (2019).Google Scholar"",""Xudong Mao, Qing Li, Haoran Xie, Raymond YK Lau, Zhen Wang, and Stephen Paul Smolley. [n. d.]. Least squares generative adversarial networks. In CVPR.Google Scholar"",""Jan André Marais. 2019. Deep learning for tabular data: an exploratory study. Ph.D. Dissertation. Stellenbosch: Stellenbosch University.Google Scholar"",""Alexandra Meliou, Sudeepa Roy, and Dan Suciu. 2014. Causality and explanations in databases. VLDB Endowment, Vol. 7, 13 (2014), 1715--1716.Google ScholarDigital Library"",""Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard. 2016. Deepfool: a simple and accurate method to fool deep neural networks. In IEEE CVPR. 2574--2582.Google Scholar"",""Vitali Petsiuk, Abir Das, and Kate Saenko. 2018. Rise: Randomized input sampling for explanation of black-box models. In BMVC.Google Scholar"",""Daniele Rav`i, Charence Wong, Fani Deligianni, Melissa Berthelot, Javier Andreu-Perez, Benny Lo, and Guang-Zhong Yang. 2016. Deep learning for health informatics. IEEE journal of biomedical and health informatics, Vol. 21, 1 (2016), 4--21.Google Scholar"",""Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. [n. d.]. \""Why Should I Trust You?\"": Explaining the Predictions of Any Classifier. In KDD.Google Scholar"",""Sudeepa Roy and Dan Suciu. 2014. A formal approach to finding explanations for database queries. In ACM SIGMOD. ACM, 1579--1590.Google Scholar"",""Ira Shavitt and Eran Segal. 2018. Regularization learning networks: deep learning for tabular datasets. In NIPS. 1379--1389.Google Scholar"",""Craig Silverstein, Sergey Brin, Rajeev Motwani, and Jeff Ullman. 2000. Scalable techniques for mining causal structures. (2000).Google Scholar"",""Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. 2013. Deep inside convolutional networks: Visualising image classification models and saliency maps. arXiv preprint arXiv:1312.6034 (2013).Google Scholar"",""Jasper van der Waa, Marcel Robeer, Jurriaan van Diggelen, Matthieu Brinkhuis, and Mark Neerincx. 2018. Contrastive explanations with local foil trees. arXiv preprint arXiv:1806.07470 (2018).Google Scholar"",""Sandra Wachter, Brent Mittelstadt, and Chris Russell. 2017. Counterfactual explanations without opening the black box: Automated decisions and the GDPR. Harv. JL \u0026 Tech., Vol. 31 (2017), 841.Google Scholar"",""Eugene Wu and Samuel Madden. 2013. Scorpion: Explaining away outliers in aggregate queries. Proceedings of the VLDB Endowment, Vol. 6, 8 (2013), 553--564.Google ScholarDigital Library"",""Xiaojun Xu, Chang Liu, Qian Feng, Heng Yin, Le Song, and Dawn Song. 2017. Neural network-based graph embedding for cross-platform binary code similarity detection. In ACM SIGSAC CCS. 363--376.Google Scholar"",""Lei Yu and Huan Liu. 2003. Feature selection for high-dimensional data: A fast correlation-based filter solution. In ICML. 856--863.Google Scholar"",""Matthew D Zeiler and Rob Fergus. 2014. Visualizing and understanding convolutional networks. In ECCV. Springer, 818--833.Google Scholar"",""Xin Zhang, Armando Solar-Lezama, and Rishabh Singh. 2018. Interpreting neural network judgments via minimal, stable, and symbolic corrections. In NIPS.Google Scholar"",""Daniel John Zizzo, Daniel Sgroi, et al. 2000. Bounded-rational behavior by neural networks in normal form games .Nuffield College.Google Scholar""]"
https://doi.org/10.1145/3394486.3403067,Hierarchical Attention Propagation for Healthcare Representation Learning,"Medical ontologies are widely used to represent and organize medical terminologies. Examples include ICD-9, ICD-10, UMLS etc. The ontologies are often constructed in hierarchical structures, encoding the multi-level subclass relationships among different medical concepts, allowing very fine distinctions between concepts. Medical ontologies provide a great source for incorporating domain knowledge into a healthcare prediction system, which might alleviate the data insufficiency problem and improve predictive performance with rare categories. To incorporate such domain knowledge, Gram, a recent graph attention model, represents a medical concept as a weighted sum of its ancestors' embeddings in the ontology using an attention mechanism. Although showing improved performance, Gram only considers the unordered ancestors of a concept, which does not fully leverage the hierarchy thus having limited expressibility. In this paper, we propose Hierarchical Attention Propagation (HAP), a novel medical ontology embedding model that hierarchically propagate attention across the entire ontology structure, where a medical concept adaptively learns its embedding from all other concepts in the hierarchy instead of only its ancestors. We prove that HAP learns more expressive medical concept embeddings -- from any medical concept embedding we are able to fully recover the entire ontology structure. Experimental results on two sequential procedure/diagnosis prediction tasks demonstrate HAP's better embedding quality than Gram and other baselines. Furthermore, we find that it is not always best to use the full ontology. Sometimes using only lower levels of the hierarchy outperforms using all levels.","[{""name"":""Muhan Zhang"",""id"":""/profile/99659193028""},{""name"":""Christopher R. King"",""id"":""/profile/99659574326""},{""name"":""Michael Avidan"",""id"":""/profile/99659334371""},{""name"":""Yixin Chen"",""id"":""/profile/81452602016""},{""name"":""Muhan Zhang"",""id"":""/profile/99659193028""},{""name"":""Christopher R. King"",""id"":""/profile/99659574326""},{""name"":""Michael Avidan"",""id"":""/profile/99659334371""},{""name"":""Yixin Chen"",""id"":""/profile/81452602016""}]","[""Olivier Bodenreider. 2004. The unified medical language system (UMLS): integrating biomedical terminology. Nucleic acids research, Vol. 32, suppl_1 (2004), D267--D270.Google Scholar"",""Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. 2013. Spectral networks and locally connected networks on graphs. arXiv preprint arXiv:1312.6203 (2013).Google Scholar"",""Ines Chami, Zhitao Ying, Christopher Ré, and Jure Leskovec. 2019. Hyperbolic graph convolutional neural networks. In Advances in Neural Information Processing Systems. 4869--4880.Google Scholar"",""Edward Choi, Mohammad Taha Bahadori, Andy Schuetz, Walter F Stewart, and Jimeng Sun. 2016a. Doctor ai: Predicting clinical events via recurrent neural networks. In Machine Learning for Healthcare Conference. 301--318.Google Scholar"",""Edward Choi, Mohammad Taha Bahadori, Le Song, Walter F Stewart, and Jimeng Sun. 2017. GRAM: graph-based attention model for healthcare representation learning. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 787--795.Google ScholarDigital Library"",""Edward Choi, Mohammad Taha Bahadori, Jimeng Sun, Joshua Kulas, Andy Schuetz, and Walter Stewart. 2016b. Retain: An interpretable predictive model for healthcare using reverse time attention mechanism. In Advances in Neural Information Processing Systems. 3504--3512.Google Scholar"",""Edward Choi, Cao Xiao, Walter Stewart, and Jimeng Sun. 2018. Mime: Multilevel medical embedding of electronic health records for predictive healthcare. In Advances in Neural Information Processing Systems. 4547--4557.Google Scholar"",""Jan K Chorowski, Dzmitry Bahdanau, Dmitriy Serdyuk, Kyunghyun Cho, and Yoshua Bengio. 2015. Attention-based models for speech recognition. In Advances in neural information processing systems. 577--585.Google Scholar"",""Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolutional neural networks on graphs with fast localized spectral filtering. In Advances in Neural Information Processing Systems. 3837--3845.Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 855--864.Google ScholarDigital Library"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In Advances in Neural Information Processing Systems. 1024--1034.Google Scholar"",""Kurt Hornik, Maxwell Stinchcombe, and Halbert White. 1989. Multilayer feedforward networks are universal approximators. Neural networks, Vol. 2, 5 (1989), 359--366.Google Scholar"",""Fei Jiang, Yong Jiang, Hui Zhi, Yi Dong, Hao Li, Sufeng Ma, Yilong Wang, Qiang Dong, Haipeng Shen, and Yongjun Wang. 2017. Artificial intelligence in healthcare: past, present and future. Stroke and vascular neurology, Vol. 2, 4 (2017), 230--243.Google Scholar"",""Wengong Jin, Regina Barzilay, and Tommi Jaakkola. 2018. Junction Tree Variational Autoencoder for Molecular Graph Generation. In Proceedings of the 35th International Conference on Machine Learning. 2323--2332.Google Scholar"",""Alistair EW Johnson, Tom J Pollard, Lu Shen, H Lehman Li-wei, Mengling Feng, Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G Mark. 2016. MIMIC-III, a freely accessible critical care database. Scientific data, Vol. 3 (2016), 160035.Google Scholar"",""Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).Google Scholar"",""Hian Chye Koh, Gerald Tan, et al. 2011. Data mining applications in healthcare. Journal of healthcare information management, Vol. 19, 2 (2011), 65.Google Scholar"",""Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. 2015. Gated graph sequence neural networks. arXiv preprint arXiv:1511.05493 (2015).Google Scholar"",""Qi Liu, Maximilian Nickel, and Douwe Kiela. 2019. Hyperbolic graph neural networks. In Advances in Neural Information Processing Systems. 8228--8239.Google Scholar"",""Fenglong Ma, Radha Chitta, Jing Zhou, Quanzeng You, Tong Sun, and Jing Gao. 2017. Dipole: Diagnosis prediction in healthcare via attention-based bidirectional recurrent neural networks. In Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. ACM, 1903--1911.Google ScholarDigital Library"",""Fenglong Ma, Quanzeng You, Houping Xiao, Radha Chitta, Jing Zhou, and Jing Gao. 2018. Kame: Knowledge-based attention model for diagnosis prediction in healthcare. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management. ACM, 743--752.Google ScholarDigital Library"",""Maximillian Nickel and Douwe Kiela. 2017. Poincaré embeddings for learning hierarchical representations. In Advances in neural information processing systems. 6338--6347.Google Scholar"",""Maximilian Nickel and Douwe Kiela. 2018. Learning continuous hierarchies in the lorentz model of hyperbolic geometry. arXiv preprint arXiv:1806.03417 (2018).Google Scholar"",""World Health Organization. 2004. International statistical classification of diseases and related health problems. Vol. 1. World Health Organization.Google Scholar"",""Judea Pearl. 1982. Reverend Bayes on inference engines: A distributed hierarchical approach.Google Scholar"",""Jeffrey Pennington, Richard Socher, and Christopher Manning. 2014. Glove: Global vectors for word representation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP). 1532--1543.Google ScholarCross Ref"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 701--710.Google ScholarDigital Library"",""Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. 2009. The graph neural network model. IEEE Transactions on Neural Networks, Vol. 20, 1 (2009), 61--80.Google ScholarDigital Library"",""Michael Q Stearns, Colin Price, Kent A Spackman, and Amy Y Wang. 2001. SNOMED clinical terms: overview of the development process and project status.. In Proceedings of the AMIA Symposium. American Medical Informatics Association, 662.Google Scholar"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. In Proceedings of the 24th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 1067--1077.Google ScholarDigital Library"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998--6008.Google Scholar"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph attention networks. arXiv preprint arXiv:1710.10903 (2017).Google Scholar"",""Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhudinov, Rich Zemel, and Yoshua Bengio. 2015. Show, attend and tell: Neural image caption generation with visual attention. In International conference on machine learning. 2048--2057.Google ScholarDigital Library"",""Muhan Zhang and Yixin Chen. 2018. Link prediction based on graph neural networks. In Advances in Neural Information Processing Systems. 5165--5175.Google Scholar"",""Muhan Zhang, Zhicheng Cui, Marion Neumann, and Yixin Chen. 2018. An End-to-End Deep Learning Architecture for Graph Classification. In AAAI. 4438--4445.Google Scholar"",""Muhan Zhang, Shali Jiang, Zhicheng Cui, Roman Garnett, and Yixin Chen. 2019. D-VAE: A variational autoencoder for directed acyclic graphs. In Advances in Neural Information Processing Systems. 1586--1598.Google Scholar""]"
https://doi.org/10.1145/3394486.3403068,SCE: Scalable Network Embedding from Sparsest Cut,"Large-scale network embedding is to learn a latent representation for each node in an unsupervised manner, which captures inherent properties and structural information of the underlying graph. In this field, many popular approaches are influenced by the skip-gram model from natural language processing. Most of them use a contrastive objective to train an encoder which forces the embeddings of similar pairs to be close and embeddings of negative samples to be far. A key of success to such contrastive learning methods is how to draw positive and negative samples. While negative samples that are generated by straightforward random sampling are often satisfying, methods for drawing positive examples remains a hot topic.In this paper, we propose SCE for unsupervised network embedding only using negative samples for training. Our method is based on a new contrastive objective inspired by the well-known sparsest cut problem. To solve the underlying optimization problem, we introduce a Laplacian smoothing trick, which uses graph convolutional operators as low-pass filters for smoothing node representations. The resulting model consists of a GCN-type structure as the encoder and a simple loss function. Notably, our model does not use positive samples but only negative samples for training, which not only makes the implementation and tuning much easier, but also reduces the training time significantly.Finally, extensive experimental studies on real world data sets are conducted. The results clearly demonstrate the advantages of our new model in both accuracy and scalability compared to strong baselines such as GraphSAGE, G2G and DGI.","[{""name"":""Shengzhong Zhang"",""id"":""/profile/99659574631""},{""name"":""Zengfeng Huang"",""id"":""/profile/99659436273""},{""name"":""Haicang Zhou"",""id"":""/profile/99659573169""},{""name"":""Ziang Zhou"",""id"":""/profile/99659574510""},{""name"":""Shengzhong Zhang"",""id"":""/profile/99659574631""},{""name"":""Zengfeng Huang"",""id"":""/profile/99659436273""},{""name"":""Haicang Zhou"",""id"":""/profile/99659573169""},{""name"":""Ziang Zhou"",""id"":""/profile/99659574510""}]","[""Sami Abu-El-Haija, Amol Kapoor, Bryan Perozzi, and Joonseok Lee. 2018. N-gcn: Multi-scale graph convolution for semi-supervised node classification. arXiv preprint arXiv:1802.08888 (2018).Google Scholar"",""Sami Abu-El-Haija, Bryan Perozzi, Amol Kapoor, Nazanin Alipourfard, Kristina Lerman, Hrayr Harutyunyan, Greg Ver Steeg, and Aram Galstyan. 2019. MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing. In International Conference on Machine Learning. 21--29.Google Scholar"",""Sanjeev Arora, Nadav Cohen, Wei Hu, and Yuping Luo. 2019. Implicit regularization in deep matrix factorization. In Advances in Neural Information Processing Systems. 7411--7422.Google Scholar"",""Sanjeev Arora, Elad Hazan, and Satyen Kale. 2010. O(sqrt log n) Approximation to SPARSEST CUT in ~O(n2) Time. SIAM J. Comput., Vol. 39, 5 (2010), 1748--1771.Google ScholarDigital Library"",""Sanjeev Arora, Satish Rao, and Umesh Vazirani. 2009. Expander flows, geometric embeddings and graph partitioning. Journal of the ACM (JACM), Vol. 56, 2 (2009), 1--37.Google ScholarDigital Library"",""James Atwood and Don Towsley. 2016. Diffusion-convolutional neural networks. In Advances in Neural Information Processing Systems. 1993--2001.Google Scholar"",""Mohamed Ishmael Belghazi, Aristide Baratin, Sai Rajeshwar, Sherjil Ozair, Yoshua Bengio, Aaron Courville, and Devon Hjelm. 2018. Mutual Information Neural Estimation. In Proceedings of the 35th International Conference on Machine Learning (Proceedings of Machine Learning Research, Vol. 80), Jennifer Dy and Andreas Krause (Eds.). PMLR, Stockholmsmässan, Stockholm Sweden, 531--540.Google Scholar"",""Aleksandar Bojchevski and Stephan Günnemann. 2018. Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking. In International Conference on Learning Representations.Google Scholar"",""Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. 2014. Spectral networks and locally connected networks on graphs. In International Conference on Learning Representations.Google Scholar"",""Moses Charikar and Vaggos Chatziafratis. 2017. Approximate hierarchical clustering via sparsest cut and spreading metrics. In Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms. SIAM, 841--854.Google ScholarDigital Library"",""Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolutional neural networks on graphs with fast localized spectral filtering. In Advances in Neural Information Processing Systems. 3844--3852.Google Scholar"",""David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Alán Aspuru-Guzik, and Ryan P Adams. 2015. Convolutional networks on graphs for learning molecular fingerprints. In Advances in neural information processing systems. 2224--2232.Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 855--864.Google ScholarDigital Library"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In Advances in Neural Information Processing Systems. 1024--1034.Google Scholar"",""Ajitesh Srivastava Rajgopal Kannan Hanqing Zeng, Hongkuan Zhou and Viktor Prasanna. 2020. GraphSAINT: Graph Sampling Based Inductive Learning Method. In International Conference on Learning Representations.Google Scholar"",""Mikael Henaff, Joan Bruna, and Yann LeCun. 2015. Deep convolutional networks on graph-structured data. arXiv preprint arXiv:1506.05163 (2015).Google Scholar"",""R Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil Bachman, Adam Trischler, and Yoshua Bengio. 2018. Learning deep representations by mutual information estimation and maximization. arXiv preprint arXiv:1808.06670 (2018).Google Scholar"",""NT Hoang and Takanori Maehara. 2019. Revisiting graph neural networks: All we have is low-pass filters. arXiv preprint arXiv:1905.09550 (2019).Google Scholar"",""Thomas N Kipf and Max Welling. 2016. Variational graph auto-encoders. arXiv preprint arXiv:1611.07308 (2016).Google Scholar"",""Thomas N Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional networks. In International Conference on Learning Representations.Google Scholar"",""Tom Leighton and Satish Rao. 1999. Multicommodity max-flow min-cut theorems and their use in designing approximation algorithms. Journal of the ACM (JACM), Vol. 46, 6 (1999), 787--832.Google ScholarDigital Library"",""Qimai Li, Zhichao Han, and Xiao-Ming Wu. 2018. Deeper insights into graph convolutional networks for semi-supervised learning. In Thirty-Second AAAI Conference on Artificial Intelligence.Google Scholar"",""Sitao Luan, Mingde Zhao, Xiao-Wen Chang, and Doina Precup. 2019. Break the Ceiling: Stronger Multi-scale Deep Graph Convolutional Networks. In Advances in Neural Information Processing Systems. 10943--10953.Google Scholar"",""David W Matula and Farhad Shahrokhi. 1990. Sparsest cuts and bottlenecks in graphs. Discrete Applied Mathematics, Vol. 27, 1--2 (1990), 113--123.Google ScholarDigital Library"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems. 3111--3119.Google Scholar"",""Mark Newman. 2018. Networks .Oxford university press.Google Scholar"",""Mingdong Ou, Peng Cui, Jian Pei, Ziwei Zhang, and Wenwu Zhu. 2016. Asymmetric transitivity preserving graph embedding. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. 1105--1114.Google ScholarDigital Library"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 701--710.Google ScholarDigital Library"",""Jiezhong Qiu, Yuxiao Dong, Hao Ma, Jian Li, Kuansan Wang, and Jie Tang. 2018. Network embedding as matrix factorization: Unifying deepwalk, line, pte, and node2vec. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. 459--467.Google ScholarDigital Library"",""Oleksandr Shchur, Maximilian Mumme, Aleksandar Bojchevski, and Stephan Günnemann. 2018. Pitfalls of graph neural network evaluation. arXiv preprint arXiv:1811.05868 (2018).Google Scholar"",""Daniel A Spielman and Nikhil Srivastava. 2011. Graph sparsification by effective resistances. SIAM J. Comput., Vol. 40, 6 (2011), 1913--1926.Google ScholarDigital Library"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. In Proceedings of the 24th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 1067--1077.Google ScholarDigital Library"",""Gabriel Taubin. 1995. A signal processing approach to fair surface design. In Proceedings of the 22nd annual conference on Computer graphics and interactive techniques. 351--358.Google ScholarDigital Library"",""Anton Tsitsulin, Davide Mottin, Panagiotis Karras, and Emmanuel Müller. 2018. Verse: Versatile graph embeddings from similarity measures. In Proceedings of the 2018 World Wide Web Conference. 539--548.Google ScholarDigital Library"",""Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2018. Graph attention networks. In International Conference on Learning Representations.Google Scholar"",""Petar Velivc ković, William Fedus, William L Hamilton, Pietro Liò, Yoshua Bengio, and R Devon Hjelm. 2018. Deep graph infomax. In International Conference on Learning Representations.Google Scholar"",""Daixin Wang, Peng Cui, and Wenwu Zhu. 2016. Structural deep network embedding. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 1225--1234.Google ScholarDigital Library"",""Felix Wu, Tianyi Zhang, Amaur Holanda de Souza, Christopher Fifty, Tao Yu, and Kilian Q Weinberger. 2019. Simplifying graph convolutional networks. In International Conference on Machine Learning.Google Scholar"",""Keyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi, and Stefanie Jegelka. 2018. Representation Learning on Graphs with Jumping Knowledge Networks. In International Conference on Machine Learning.Google Scholar"",""Zhilin Yang, William Cohen, and Ruslan Salakhudinov. 2016. Revisiting Semi-Supervised Learning with Graph Embeddings. In International Conference on Machine Learning. 40--48.Google Scholar"",""Yuan Yin and Zhewei Wei. 2019. Scalable graph embeddings via sparse transpose proximities. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1429--1437.Google ScholarDigital Library"",""Ziwei Zhang, Peng Cui, Xiao Wang, Jian Pei, Xuanrong Yao, and Wenwu Zhu. 2018. Arbitrary-order proximity preserved network embedding. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 2778--2786.Google ScholarDigital Library"",""Chang Zhou, Yuqiong Liu, Xiaofei Liu, Zhongyi Liu, and Jun Gao. 2017. Scalable graph embedding for asymmetric proximity. In Thirty-First AAAI Conference on Artificial Intelligence.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403069,Local Community Detection in Multiple Networks,"Local community detection aims to find a set of densely-connected nodes containing given query nodes. Most existing local community detection methods are designed for a single network. However, a single network can be noisy and incomplete. Multiple networks are more informative in real-world applications. There are multiple types of nodes and multiple types of node proximities. Complementary information from different networks helps to improve detection accuracy. In this paper, we propose a novel RWM (Random Walk in Multiple networks) model to find relevant local communities in all networks for a given query node set from one network. RWM sends a random walker in each network to obtain the local proximity w.r.t. the query nodes (i.e., node visiting probabilities).Walkers with similar visiting probabilities reinforce each other. They restrict the probability propagation around the query nodes to identify relevant subgraphs in each network and disregard irrelevant parts. We provide rigorous theoretical foundations for RWM and develop two speeding-up strategies with performance guarantees. Comprehensive experiments are conducted on synthetic and real-world datasets to evaluate the effectiveness and efficiency of RWM.","[{""name"":""Dongsheng Luo"",""id"":""/profile/99659369498""},{""name"":""Yuchen Bian"",""id"":""/profile/99659085448""},{""name"":""Yaowei Yan"",""id"":""/profile/99658981574""},{""name"":""Xiao Liu"",""id"":""/profile/99659520078""},{""name"":""Jun Huan"",""id"":""/profile/81479644488""},{""name"":""Xiang Zhang"",""id"":""/profile/99659242445""},{""name"":""Dongsheng Luo"",""id"":""/profile/99659369498""},{""name"":""Yuchen Bian"",""id"":""/profile/99659085448""},{""name"":""Yaowei Yan"",""id"":""/profile/99658981574""},{""name"":""Xiao Liu"",""id"":""/profile/99659520078""},{""name"":""Jun Huan"",""id"":""/profile/81479644488""},{""name"":""Xiang Zhang"",""id"":""/profile/99659242445""}]","[""Morteza Alamgir and Ulrike Von Luxburg. 2010. Multi-agent random walks for local clustering on graphs. In ICDM. 18--27.Google Scholar"",""Reid Andersen, Fan Chung, and Kevin Lang. 2006. Local graph partitioning using pagerank vectors. In FOCS. 475--486.Google Scholar"",""Nicola Barbieri, Francesco Bonchi, Edoardo Galimberti, and Francesco Gullo. 2015. Efficient and effective community search. Data mining and knowledge discovery, Vol. 29, 5 (2015), 1406--1433.Google Scholar"",""Yuchen Bian, Dongsheng Luo, Yaowei Yan, Wei Cheng, Wei Wang, and Xiang Zhang. 2019 a. Memory-based random walk for multi-query local community detection. Knowledge and Information Systems (2019), 1--35.Google Scholar"",""Yuchen Bian, Jingchao Ni, Wei Cheng, and Xiang Zhang. 2017. Many heads are better than one: Local community detection by the multi-walker chain. In ICDM. 21--30.Google Scholar"",""Yuchen Bian, Jingchao Ni, Wei Cheng, and Xiang Zhang. 2019 b. The multi-walker chain and its application in local community detection. Knowledge and Information Systems, Vol. 60, 3 (2019), 1663--1691.Google ScholarCross Ref"",""Yuchen Bian, Yaowei Yan, Wei Cheng, Wei Wang, Dongsheng Luo, and Xiang Zhang. 2018. On multi-query local community detection. In ICDM. 9--18.Google Scholar"",""Manlio De Domenico, Andrea Lancichinetti, Alex Arenas, and Martin Rosvall. 2015. Identifying modular flows on multilayer networks reveals highly overlapping organization in interconnected systems. Physical Review X, Vol. 5, 1 (2015), 011027.Google ScholarCross Ref"",""Xin Huang, Hong Cheng, Lu Qin, Wentao Tian, and Jeffrey Xu Yu. 2014. Querying k-truss community in large and dynamic graphs. In SIGMOD. 1311--1322.Google Scholar"",""Xin Huang, Laks VS Lakshmanan, and Jianliang Xu. 2019. Community Search over Big Graphs. Synthesis Lectures on Data Management, Vol. 14, 6 (2019), 1--206.Google ScholarCross Ref"",""Xin Huang, Laks VS Lakshmanan, Jeffrey Xu Yu, and Hong Cheng. 2015. Approximate closest community search in networks. PVLDB, Vol. 9, 4 (2015), 276--287.Google ScholarDigital Library"",""Roberto Interdonato, Andrea Tagarelli, Dino Ienco, Arnaud Sallaberry, and Pascal Poncelet. 2017. Local community detection in multilayer networks. Data Mining and Knowledge Discovery, Vol. 31, 5 (2017), 1444--1479.Google ScholarDigital Library"",""Jungeun Kim and Jae-Gil Lee. 2015. Community detection in multi-layer graphs: A survey. ACM SIGMOD Record, Vol. 44, 3 (2015), 37--48.Google ScholarDigital Library"",""Mikko Kivel\""a, Alex Arenas, Marc Barthelemy, James P Gleeson, Yamir Moreno, and Mason A Porter. 2014. Multilayer networks. Journal of complex networks, Vol. 2, 3 (2014), 203--271.Google ScholarCross Ref"",""Kyle Kloster and David F Gleich. 2014. Heat kernel based community detection. In SIGKDD. 1386--1395.Google Scholar"",""Andrea Lancichinetti and Santo Fortunato. 2009. Benchmarks for testing community detection algorithms on directed and weighted graphs with overlapping communities. Physical Review E (2009).Google Scholar"",""Yixuan Li, Kun He, David Bindel, and John E Hopcroft. 2015. Uncovering the small community structure in large networks: A local spectral approach. In WWW. 658--668.Google Scholar"",""Kar Wai Lim and Wray Buntine. 2016. Bibliographic analysis on research publications using authors, categorical labels and the citation network. Machine Learning, Vol. 103, 2 (2016), 185--213.Google ScholarDigital Library"",""Daqian Lu and Hao Zhang. 1986. Stochastic process and applications. Tsinghua University Press.Google Scholar"",""Dongsheng Luo, Jingchao Ni, Suhang Wang, Yuchen Bian, Xiong Yu, and Xiang Zhang. 2020. Deep Multi-Graph Clustering via Attentive Cross-Graph Association. In WSDM. 393--401.Google Scholar"",""Peter J Mucha, Thomas Richardson, Kevin Macon, Mason A Porter, and Jukka-Pekka Onnela. 2010. Community structure in time-dependent, multiscale, and multiplex networks. Science, Vol. 328, 5980 (2010), 876--878.Google Scholar"",""Jingchao Ni, Shiyu Chang, Xiao Liu, Wei Cheng, Haifeng Chen, Dongkuan Xu, and Xiang Zhang. 2018. Co-regularized deep multi-network embedding. In WWW. 469--478.Google Scholar"",""Satu Elisa Schaeffer. 2005. Stochastic local clustering for massive graphs. In PAKDD. 354--360.Google Scholar"",""Jing Shan, Derong Shen, Tiezheng Nie, Yue Kou, and Ge Yu. 2016. Searching overlapping communities for group query. World Wide Web, Vol. 19, 6 (2016), 1179--1202.Google ScholarDigital Library"",""Jie Tang, Jing Zhang, Limin Yao, Juanzi Li, Li Zhang, and Zhong Su. 2008. Arnetminer: extraction and mining of academic social networks. In SIGKDD. 990--998.Google Scholar"",""Hanghang Tong, Christos Faloutsos, and Jia-Yu Pan. 2006. Fast random walk with restart and its applications. In ICDM. 613--622.Google Scholar"",""David C Van Essen, Stephen M Smith, Deanna M Barch, Timothy EJ Behrens, Essa Yacoub, Kamil Ugurbil, Wu-Minn HCP Consortium, et al. 2013. The WU-Minn human connectome project: an overview. Neuroimage, Vol. 80 (2013), 62--79.Google ScholarCross Ref"",""Twan Van Laarhoven and Elena Marchiori. 2016. Local network community detection with continuous optimization of conductance and weighted kernel k-means. The Journal of Machine Learning Research, Vol. 17, 1 (2016), 5148--5175.Google Scholar"",""Nate Veldt, Christine Klymko, and David F Gleich. 2019. Flow-based local graph clustering with better seed set inclusion. In SDM. 378--386.Google Scholar"",""Yubao Wu, Yuchen Bian, and Xiang Zhang. 2016. Remember where you came from: on the second-order random walk based proximity measures. Proceedings of the VLDB Endowment, Vol. 10, 1 (2016), 13--24.Google ScholarDigital Library"",""Yubao Wu, Ruoming Jin, Jing Li, and Xiang Zhang. 2015. Robust local community detection: on free rider effect and its elimination. PVLDB, Vol. 8, 7 (2015), 798--809.Google ScholarDigital Library"",""Yubao Wu, Xiang Zhang, Yuchen Bian, Zhipeng Cai, Xiang Lian, Xueting Liao, and Fengpan Zhao. 2018. Second-order random walk-based proximity measures in graph analysis: formulations and algorithms. The VLDB Journal, Vol. 27, 1 (2018), 127--152.Google ScholarDigital Library"",""Yaowei Yan, Yuchen Bian, Dongsheng Luo, Dongwon Lee, and Xiang Zhang. 2019. Constrained Local Graph Clustering by Colored Random Walk. In WWW. 2137--2146.Google Scholar"",""Yaowei Yan, Dongsheng Luo, Jingchao Ni, Hongliang Fei, Wei Fan, Xiong Yu, John Yen, and Xiang Zhang. 2018. Local Graph Clustering by Multi-network Random Walk with Restart. In PAKDD. 490--501.Google Scholar"",""Hao Yin, Austin R Benson, Jure Leskovec, and David F Gleich. 2017. Local higher-order graph clustering. In SIGKDD. 555--564.Google Scholar"",""Long Yuan, Lu Qin, Wenjie Zhang, Lijun Chang, and Jianye Yang. 2017. Index-based densest clique percolation community search in networks. IEEE Transactions on Knowledge and Data Engineering, Vol. 30, 5 (2017), 922--935.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403070,A Block Decomposition Algorithm for Sparse Optimization,"Sparse optimization is a central problem in machine learning and computer vision. However, this problem is inherently NP-hard and thus difficult to solve in general. Combinatorial search methods find the global optimal solution but are confined to small-sized problems, while coordinate descent methods are efficient but often suffer from poor local minima. This paper considers a new block decomposition algorithm that combines the effectiveness of combinatorial search methods and the efficiency of coordinate descent methods. Specifically, we consider a random strategy or/and a greedy strategy to select a subset of coordinates as the working set, and then perform a global combinatorial search over the working set based on the original objective function. We show that our method finds stronger stationary points than Amir Beck et al.'s coordinate-wise optimization method. In addition, we establish the convergence rate of our algorithm. Our experiments on solving sparse regularized and sparsity constrained least squares optimization problems demonstrate that our method achieves state-of-the-art performance in terms of accuracy. For example, our method generally outperforms the well-known greedy pursuit method.","[{""name"":""Ganzhao Yuan"",""id"":""/profile/81508688348""},{""name"":""Li Shen"",""id"":""/profile/99659326788""},{""name"":""Wei-Shi Zheng"",""id"":""/profile/81322510979""},{""name"":""Ganzhao Yuan"",""id"":""/profile/81508688348""},{""name"":""Li Shen"",""id"":""/profile/99659326788""},{""name"":""Wei-Shi Zheng"",""id"":""/profile/81322510979""}]","[""Michal Aharon, Michael Elad, and Alfred Bruckstein. 2006. K-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation. IEEE Transactions on Signal Processing, Vol. 54, 11 (2006), 4311--4322.Google ScholarDigital Library"",""Chenglong Bao, Hui Ji, Yuhui Quan, and Zuowei Shen. 2016. Dictionary Learning for Sparse Coding: Algorithms and Convergence Analysis. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), Vol. 38, 7 (2016), 1356--1369.Google ScholarCross Ref"",""Amir Beck and Yonina C Eldar. 2013. Sparsity constrained nonlinear optimization: Optimality conditions and algorithms. SIAM Journal on Optimization (SIOPT), Vol. 23, 3 (2013), 1480--1509.Google ScholarCross Ref"",""Amir Beck and Nadav Hallak. 2019. Optimization problems involving group sparsity terms. Mathematical Programming, Vol. 178, 1--2 (2019), 39--67.Google ScholarCross Ref"",""Amir Beck and Nadav Hallak. 2020. On the Minimization Over Sparse Symmetric Sets: Projections, Optimality Conditions, and Algorithms. Mathematics of Operations Research (2020).Google Scholar"",""Amir Beck and Marc Teboulle. 2009. A fast iterative shrinkage-thresholding algorithm for linear inverse problems. SIAM Journal on Imaging Sciences (SIIMS), Vol. 2, 1 (2009), 183--202.Google ScholarDigital Library"",""Amir Beck and Yakov Vaisbourd. 2016. The Sparse Principal Component Analysis Problem: Optimality Conditions and Algorithms. Journal of Optimization Theory and Applications, Vol. 170, 1 (2016), 119--143.Google ScholarDigital Library"",""Shujun Bi, Xiaolan Liu, and Shaohua Pan. 2014. Exact Penalty Decomposition Method for Zero-Norm Minimization Based on MPEC Formulation. SIAM Journal on Scientific Computing (SISC), Vol. 36, 4 (2014).Google Scholar"",""Thomas Blumensath and Mike E Davies. 2008. Gradient pursuits. IEEE Trans. on Signal Processing, Vol. 56, 6 (2008), 2370--2382.Google ScholarDigital Library"",""Thomas Blumensath and Mike E. Davies. 2009. Iterative hard thresholding for compressed sensing. Applied and Computational Harmonic Analysis, Vol. 27, 3 (2009), 265 -- 274.Google ScholarCross Ref"",""Emmanuel J Candes and Terence Tao. 2005. Decoding by linear programming. IEEE Transactions on Information Theory, Vol. 51, 12 (2005), 4203--4215.Google ScholarDigital Library"",""Kai-Wei Chang, Cho-Jui Hsieh, and Chih-Jen Lin. 2008. Coordinate descent method for large-scale l2-loss linear support vector machines. J. of Machine Learning Research, Vol. 9 (2008), 1369--1398.Google ScholarDigital Library"",""Michele Conforti, Gérard Cornuéjols, and Giacomo Zambelli. 2014. Integer programming. Vol. 271. Springer.Google Scholar"",""Wei Dai and Olgica Milenkovic. 2009. Subspace pursuit for compressive sensing signal reconstruction. IEEE Transactions on Information Theory, Vol. 55, 5 (2009), 2230--2249.Google ScholarDigital Library"",""David L. Donoho. 2006. Compressed sensing. IEEE Transactions on Information Theory, Vol. 52, 4 (2006), 1289--1306.Google ScholarDigital Library"",""Ehsan Elhamifar and Rene Vidal. 2013. Sparse subspace clustering: Algorithm, theory, and applications. IEEE Trans. on Pattern Analysis and Machine Intelligence, Vol. 35, 11 (2013), 2765--2781.Google ScholarDigital Library"",""Mingyi Hong, Xiangfeng Wang, Meisam Razaviyayn, and Zhi-Quan Luo. 2013. Iteration complexity analysis of block coordinate descent methods. Mathematical Programming (2013), 1--30.Google Scholar"",""Cho-Jui Hsieh, Kai-Wei Chang, Chih-Jen Lin, S Sathiya Keerthi, and Sellamanickam Sundararajan. 2008. A dual coordinate descent method for large-scale linear SVM. In International Conference on Machine Learning (ICML). 408--415.Google ScholarDigital Library"",""Cho-Jui Hsieh and Inderjit S Dhillon. 2011. Fast coordinate descent methods with variable selection for non-negative matrix factorization. In ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD). 1064--1072.Google ScholarDigital Library"",""Prateek Jain, Ambuj Tewari, and Purushottam Kar. 2014. On iterative hard thresholding methods for high-dimensional m-estimation. In Neural Information Processing Systems. 685--693.Google Scholar"",""Rie Johnson and Tong Zhang. 2013. Accelerating stochastic gradient descent using predictive variance reduction. In Advances in Neural Information Processing Systems (NeurIPS). 315--323.Google Scholar"",""Xingguo Li, Tuo Zhao, Raman Arora, Han Liu, and Jarvis D. Haupt. 2016. Stochastic Variance Reduced Optimization for Nonconvex Sparse Learning. In Proceedings of the 33nd International Conference on Machine Learning (ICML), Vol. 48. 917--925.Google Scholar"",""Ji Liu, Stephen J Wright, Christopher Ré, Victor Bittorf, and Srikrishna Sridhar. 2015. An asynchronous parallel stochastic coordinate descent algorithm. Journal of Machine Learning Research (JMLR), Vol. 16, 285--322 (2015), 1--5.Google ScholarDigital Library"",""Zhaosong Lu. 2014. Iterative hard thresholding methods for $ell_0$ regularized convex cone programming. Mathematical Programming, Vol. 147, 1--2 (2014), 125--154.Google ScholarDigital Library"",""Zhaosong Lu and Lin Xiao. 2015. On the complexity analysis of randomized block-coordinate descent methods. Mathematical Programming, Vol. 152, 1--2 (2015), 615--642.Google ScholarDigital Library"",""Zhaosong Lu and Yong Zhang. 2013. Sparse Approximation via Penalty Decomposition Methods. SIAM Journal on Optimization (SIOPT), Vol. 23, 4 (2013), 2448--2478.Google ScholarCross Ref"",""Deanna Needell and Joel A Tropp. 2009. CoSaMP: Iterative signal recovery from incomplete and inaccurate samples. Applied and Computational Harmonic Analysis, Vol. 26, 3 (2009), 301--321.Google ScholarCross Ref"",""Deanna Needell and Roman Vershynin. 2010. Signal recovery from incomplete and inaccurate measurements via regularized orthogonal matching pursuit. IEEE Journal of Selected Topics in Signal Processing, Vol. 4, 2 (2010), 310--316.Google ScholarCross Ref"",""Yu Nesterov. 2012. Efficiency of coordinate descent methods on huge-scale optimization problems. SIAM Journal on Optimization (SIOPT), Vol. 22, 2 (2012), 341--362.Google ScholarCross Ref"",""Yurii Nesterov. 2013. Introductory lectures on convex optimization: A basic course. Vol. 87. Springer Science \u0026 Business Media.Google Scholar"",""Andrei Patrascu and Ion Necoara. 2015a. Efficient random coordinate descent algorithms for large-scale structured nonconvex optimization. J. of Global Optimization, Vol. 61, 1 (2015), 19--46.Google ScholarDigital Library"",""Andrei Patrascu and Ion Necoara. 2015b. Random Coordinate Descent Methods for l0 Regularized Convex Optimization. IEEE Trans. Automat. Control, Vol. 60, 7 (2015), 1811--1824.Google ScholarCross Ref"",""M. J. D. Powell. 1973. On search directions for minimization algorithms. Mathematical Programming, Vol. 4, 1 (1973), 193--201.Google ScholarCross Ref"",""Meisam Razaviyayn, Mingyi Hong, and Zhi-Quan Luo. 2013. A unified convergence analysis of block successive minimization methods for nonsmooth optimization. SIAM Journal on Optimization (SIOPT), Vol. 23, 2 (2013), 1126--1153.Google ScholarCross Ref"",""Benjamin Recht, Christopher Re, Stephen Wright, and Feng Niu. 2011. Hogwild: A lock-free approach to parallelizing stochastic gradient descent. In Neural Information Processing Systems (NeurIPS). 693--701.Google Scholar"",""Joel A Tropp and Anna C Gilbert. 2007. Signal recovery from random measurements via orthogonal matching pursuit. IEEE Transactions on Information Theory, Vol. 53, 12 (2007), 4655--4666.Google ScholarDigital Library"",""Paul Tseng and Sangwoon Yun. 2009. A coordinate gradient descent method for nonsmooth separable minimization. Mathematical Programming, Vol. 117, 1 (2009), 387--423.Google ScholarDigital Library"",""Lin Xiao and Tong Zhang. 2014. A proximal stochastic gradient method with progressive variance reduction. SIAM Journal on Optimization (SIOPT), Vol. 24, 4 (2014), 2057--2075.Google ScholarCross Ref"",""Yangyang Xu and Wotao Yin. 2013. A block coordinate descent method for regularized multiconvex optimization with applications to nonnegative tensor factorization and completion. SIAM Journal on Imaging Sciences (SIIMS), Vol. 6, 3 (2013), 1758--1789.Google ScholarCross Ref"",""Zongben Xu, Xiangyu Chang, Fengmin Xu, and Hai Zhang. 2012. L1/2 regularization: A thresholding representation theory and a fast solver. IEEE Transactions on Neural Networks and Learning Systems, Vol. 23, 7 (2012), 1013--1027.Google ScholarCross Ref"",""Ganzhao Yuan and Bernard Ghanem. 2016. Sparsity Constrained Minimization via Mathematical Programming with Equilibrium Constraints. In arXiv:1608.04430 .Google Scholar"",""Ganzhao Yuan and Bernard Ghanem. 2019. l0TV: A Sparse Optimization Method for Impulse Noise Image Restoration. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), Vol. 41, 2 (2019), 352--364.Google ScholarDigital Library"",""Ganzhao Yuan, Li Shen, and Wei-Shi Zheng. 2019. A Decomposition Algorithm for the Sparse Generalized Eigenvalue Problem. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 6113--6122.Google ScholarCross Ref"",""Ganzhao Yuan, Li Shen, and Wei-Shi Zheng. June, 2017 b. A Hybrid Method of Combinatorial Search and Coordinate Descent for Discrete Optimization. arXiv:1706.06493 ( June, 2017).Google Scholar"",""Xiao-Tong Yuan, Ping Li, and Tong Zhang. 2017a. Gradient Hard Thresholding Pursuit. Journal of Machine Learning Research, Vol. 18 (2017), 166:1--166:43.Google Scholar"",""Aston Zhang and Quanquan Gu. 2016. Accelerated Stochastic Block Coordinate Descent with Optimal Sampling. In ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD). 2035--2044.Google Scholar"",""Tong Zhang. 2010. Analysis of Multi-stage Convex Relaxation for Sparse Regularization. Journal of Machine Learning Research (JMLR), Vol. 11, 35 (2010), 1081--1107.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403071,Adversarial Infidelity Learning for Model Interpretation,"Model interpretation is essential in data mining and knowledge discovery. It can help understand the intrinsic model working mechanism and check if the model has undesired characteristics. A popular way of performing model interpretation is Instance-wise Feature Selection (IFS), which provides an importance score of each feature representing the data samples to explain how the model generates the specific output. In this paper, we propose a Model-agnostic Effective Efficient Direct (MEED) IFS framework for model interpretation, mitigating concerns about sanity, combinatorial shortcuts, model identifiability, and information transmission. Also, we focus on the following setting: using selected features to directly predict the output of the given model, which serves as a primary evaluation metric for model-interpretation methods. Apart from the features, we involve the output of the given model as an additional input to learn an explainer based on more accurate information. To learn the explainer, besides fidelity, we propose an Adversarial Infidelity Learning (AIL) mechanism to boost the explanation learning by screening relatively unimportant features. Through theoretical and experimental analysis, we show that our AIL mechanism can help learn the desired conditional distribution between selected features and targets. Moreover, we extend our framework by integrating efficient interpretation methods as proper priors to provide a warm start. Comprehensive empirical evaluation results are provided by quantitative metrics and human evaluation to demonstrate the effectiveness and superiority of our proposed method. Our code is publicly available online at https://github.com/langlrsw/MEED.","[{""name"":""Jian Liang"",""id"":""/profile/99659573706""},{""name"":""Bing Bai"",""id"":""/profile/99659573560""},{""name"":""Yuren Cao"",""id"":""/profile/99659573158""},{""name"":""Kun Bai"",""id"":""/profile/99659567987""},{""name"":""Fei Wang"",""id"":""/profile/99658710924""},{""name"":""Jian Liang"",""id"":""/profile/99659573706""},{""name"":""Bing Bai"",""id"":""/profile/99659573560""},{""name"":""Yuren Cao"",""id"":""/profile/99659573158""},{""name"":""Kun Bai"",""id"":""/profile/99659567987""},{""name"":""Fei Wang"",""id"":""/profile/99658710924""}]","[""Mart'in Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al. 2016. Tensorflow: a system for large-scale machine learning.. In OSDI, Vol. 16. 265--283.Google ScholarDigital Library"",""Julius Adebayo, Justin Gilmer, Ian Goodfellow, and Been Kim. 2018a. Local explanation methods for deep neural networks lack sensitivity to parameter values. arXiv preprint arXiv:1810.03307 (2018).Google Scholar"",""Julius Adebayo, Justin Gilmer, Michael Muelly, Ian Goodfellow, Moritz Hardt, and Been Kim. 2018b. Sanity checks for saliency maps. In Advances in Neural Information Processing Systems. 9505--9515.Google Scholar"",""Marco Ancona, Enea Ceolini, Cengiz Öztireli, and Markus Gross. 2017. A unified view of gradient-based attribution methods for deep neural networks. In NIPS 2017-Workshop on Interpreting, Explaining and Visualizing Deep Learning. ETH Zurich.Google Scholar"",""Robert Andrews, Joachim Diederich, and Alan B Tickle. 1995. Survey and critique of techniques for extracting rules from trained artificial neural networks. Knowledge-based systems, Vol. 8, 6 (1995), 373--389.Google Scholar"",""Sebastian Bach, Alexander Binder, Grégoire Montavon, Frederick Klauschen, Klaus-Robert Müller, and Wojciech Samek. 2015. On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation. PloS one, Vol. 10, 7 (2015), e0130140.Google ScholarCross Ref"",""Seojin Bang, Pengtao Xie, Wei Wu, and Eric Xing. 2019. Explaining a black-box using Deep Variational Information Bottleneck Approach. arXiv preprint arXiv:1902.06918 (2019).Google Scholar"",""Tathagata Chakraborti, Anagha Kulkarni, Sarath Sreedharan, David E Smith, and Subbarao Kambhampati. 2019. Explicability? legibility? predictability? transparency? privacy? security? the emerging landscape of interpretable agent behavior. In Proceedings of the International Conference on Automated Planning and Scheduling, Vol. 29. 86--96.Google Scholar"",""Jianbo Chen, Le Song, Martin Wainwright, and Michael Jordan. 2018. Learning to Explain: An Information-Theoretic Perspective on Model Interpretation. In International Conference on Machine Learning. 883--892.Google Scholar"",""Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition. Ieee, 248--255.Google ScholarCross Ref"",""Ann-Kathrin Dombrowski, Maximillian Alber, Christopher Anders, Marcel Ackermann, Klaus-Robert Müller, and Pan Kessel. 2019. Explanations can be manipulated and geometry is to blame. In Advances in Neural Information Processing Systems 32, H. Wallach, H. Larochelle, A. Beygelzimer, F. dtextquotesingle Alché-Buc, E. Fox, and R. Garnett (Eds.). Curran Associates, Inc., 13567--13578. http://papers.nips.cc/paper/9511-explanations-can-be-manipulated-and-geometry-is-to-blame.pdfGoogle Scholar"",""Mengnan Du, Ninghao Liu, and Xia Hu. 2019. Techniques for interpretable machine learning. Commun. ACM, Vol. 63, 1 (2019), 68--77.Google ScholarDigital Library"",""Satoshi Hara, Koichi Ikeno, Tasuku Soma, and Takanori Maehara. 2019. Feature Attribution As Feature Selection. https://openreview.net/forum?id=H1lS8oA5YQGoogle Scholar"",""Juyeon Heo, Sunghwan Joo, and Taesup Moon. 2019. Fooling Neural Network Interpretations via Adversarial Model Manipulation. In Advances in Neural Information Processing Systems 32, H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett (Eds.). Curran Associates, Inc., 2921--2932. http://papers.nips.cc/paper/8558-fooling-neural-network-interpretations-via-adversarial-model-manipulation.pdfGoogle Scholar"",""Sara Hooker, Dumitru Erhan, Pieter-Jan Kindermans, and Been Kim. 2019. A benchmark for interpretability methods in deep neural networks. In Advances in Neural Information Processing Systems. 9734--9745.Google Scholar"",""Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. 2017. Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861 (2017).Google Scholar"",""Sarthak Jain and Byron C Wallace. 2019. Attention is not Explanation. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). 3543--3556.Google Scholar"",""Alexia Jolicoeur-Martineau. 2018. The relativistic discriminator: a key element missing from standard GAN. arXiv preprint arXiv:1807.00734 (2018).Google Scholar"",""Ashkan Khakzar, Soroosh Baselizadeh, Saurabh Khanduja, Seong Tae Kim, and Nassir Navab. 2019. Explaining Neural Networks via Perturbing Important Learned Features. arXiv preprint arXiv:1911.11081 (2019).Google Scholar"",""Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. 1998. Gradient-based learning applied to document recognition. Proc. IEEE, Vol. 86, 11 (1998), 2278--2324.Google ScholarCross Ref"",""Chen-Yu Lee, Tanmay Batra, Mohammad Haris Baig, and Daniel Ulbricht. 2019. Sliced wasserstein discrepancy for unsupervised domain adaptation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 10285--10295.Google ScholarCross Ref"",""Zachary C Lipton. 2018. The mythos of model interpretability. Queue, Vol. 16, 3 (2018), 31--57.Google ScholarDigital Library"",""Scott M Lundberg and Su-In Lee. 2017. A unified approach to interpreting model predictions. In Advances in Neural Information Processing Systems. 4765--4774.Google Scholar"",""Andrew L Maas, Raymond E Daly, Peter T Pham, Dan Huang, Andrew Y Ng, and Christopher Potts. 2011. Learning word vectors for sentiment analysis. In Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies-volume 1. Association for Computational Linguistics, 142--150.Google ScholarDigital Library"",""Seongsik Park, Seijoon Kim, Hyeokjun Choe, and Sungroh Yoon. 2019. Fast and efficient information transmission with burst spikes in deep spiking neural networks. In 2019 56th ACM/IEEE Design Automation Conference (DAC). IEEE, 1--6.Google ScholarDigital Library"",""Gregory Plumb, Denali Molitor, and Ameet S Talwalkar. 2018. Model agnostic supervised local explanations. In Advances in Neural Information Processing Systems. 2515--2524.Google Scholar"",""Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. Why should i trust you?: Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. ACM, 1135--1144.Google ScholarDigital Library"",""Olaf Ronneberger, Philipp Fischer, and Thomas Brox. 2015. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computer-assisted intervention. Springer, 234--241.Google ScholarCross Ref"",""Patrick Schwab and Helmut Hlavacs. 2015. Capturing the essence: Towards the automated generation of transparent behavior models. In Eleventh Artificial Intelligence and Interactive Digital Entertainment Conference .Google Scholar"",""Patrick Schwab and Walter Karlen. 2019. CXPlain: Causal explanations for model interpretation under uncertainty. In Advances in Neural Information Processing Systems. 10220--10230.Google Scholar"",""Avanti Shrikumar, Peyton Greenside, and Anshul Kundaje. 2017. Learning important features through propagating activation differences. In Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 3145--3153.Google ScholarDigital Library"",""Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. 2013. Deep inside convolutional networks: Visualising image classification models and saliency maps. arXiv preprint arXiv:1312.6034 (2013).Google Scholar"",""Daniel Smilkov, Nikhil Thorat, Been Kim, Fernanda Viégas, and Martin Wattenberg. 2017. Smoothgrad: removing noise by adding noise. arXiv preprint arXiv:1706.03825 (2017).Google Scholar"",""J Springenberg, Alexey Dosovitskiy, Thomas Brox, and M Riedmiller. 2015. Striving for Simplicity: The All Convolutional Net. In ICLR (workshop track) .Google Scholar"",""Mukund Sundararajan, Ankur Taly, and Qiqi Yan. 2017. Axiomatic attribution for deep networks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 3319--3328.Google ScholarDigital Library"",""Fei Wang, Rainu Kaushal, and Dhruv Khullar. 2019. Should Health Care Demand Interpretable Artificial Intelligence or Accept \""Black Box\"" Medicine? Annals of Internal Medicine (2019).Google Scholar"",""Sarah Wiegreffe and Yuval Pinter. 2019. Attention is not not Explanation. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 11--20.Google ScholarCross Ref"",""Han Xiao, Kashif Rasul, and Roland Vollgraf. 2017. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. arXiv preprint arXiv:1708.07747 (2017).Google Scholar"",""Chih-Kuan Yeh, Cheng-Yu Hsieh, Arun Suggala, David I Inouye, and Pradeep K Ravikumar. 2019. On the (In) fidelity and Sensitivity of Explanations. In Advances in Neural Information Processing Systems. 10965--10976.Google Scholar"",""Xinyang Zhang, Ningfei Wang, Shouling Ji, Hua Shen, and Ting Wang. 2018. Interpretable Deep Learning under Fire. arXiv preprint arXiv:1812.00891 (2018).Google Scholar"",""Suyang Zhu, Shoushan Li, and Guodong Zhou. 2019. Adversarial Attention Modeling for Multi-dimensional Emotion Regression. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. 471--480.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403072,Grounding Visual Concepts for Zero-Shot Event Detection and Event Captioning,"The flourishing of social media platforms requires techniques for understanding the content of media on a large scale. However, state-of-the art video event understanding approaches remain very limited in terms of their ability to deal with data sparsity, semantically unrepresentative event names, and lack of coherence between visual and textual concepts. Accordingly, in this paper, we propose a method of grounding visual concepts for large-scale Multimedia Event Detection (MED) and Multimedia Event Captioning (MEC) in zero-shot setting. More specifically, our framework composes the following: (1) deriving the novel semantic representations of events from their textual descriptions, rather than event names; (2) aggregating the ranks of grounded concepts for MED tasks. A statistical mean-shift outlier rejection model is proposed to remove the outlying concepts which are incorrectly grounded; and (3) defining MEC tasks and augmenting the MEC training set by the videos detected in MED in a zero-shot setting. To the best of our knowledge, this work is the first time to define and solve the MEC task, which is a further step towards understanding video events. We conduct extensive experiments and achieve state-of-the-art performance on the TRECVID MEDTest dataset, as well as our newly proposed TRECVID-MEC dataset.","[{""name"":""Zhihui Li"",""id"":""/profile/99659232066""},{""name"":""Xiaojun Chang"",""id"":""/profile/99658727663""},{""name"":""Lina Yao"",""id"":""/profile/81500655260""},{""name"":""Shirui Pan"",""id"":""/profile/81549268756""},{""name"":""Ge Zongyuan"",""id"":""/profile/99659574030""},{""name"":""Huaxiang Zhang"",""id"":""/profile/81339539922""},{""name"":""Zhihui Li"",""id"":""/profile/99659232066""},{""name"":""Xiaojun Chang"",""id"":""/profile/99658727663""},{""name"":""Lina Yao"",""id"":""/profile/81500655260""},{""name"":""Shirui Pan"",""id"":""/profile/81549268756""},{""name"":""Ge Zongyuan"",""id"":""/profile/99659574030""},{""name"":""Huaxiang Zhang"",""id"":""/profile/81339539922""}]","[""Hrishikesh B. Aradhye, George Toderici, and Jay Yagnik. 2009. Video2Text: Learning to Annotate Video Content. In ICDM Workshops 2009.Google ScholarDigital Library"",""Ioannis Caragiannis, Xenophon Chatzigeorgiou, George A. Krimpas, and Alexandros A. Voudouris. 2019. Optimizing positional scoring rules for rank aggregation. Artif. Intell., Vol. 267 (2019), 58--77.Google ScholarCross Ref"",""Xiaojun Chang, Zhigang Ma, Yi Yang, Zhiqiang Zeng, and Alexander G. Hauptmann. 2017a. Bi-Level Semantic Representation Analysis for Multimedia Event Detection. IEEE Trans. Cybernetics, Vol. 47, 5 (2017), 1180--1197.Google ScholarCross Ref"",""Xiaojun Chang, Yi Yang, Alexander G. Hauptmann, Eric P. Xing, and Yaoliang Yu. 2015a. Semantic Concept Discovery for Large-Scale Zero-Shot Event Detection. In IJCAI.Google Scholar"",""Xiaojun Chang, Yi Yang, Guodong Long, Chengqi Zhang, and Alexander G. Hauptmann. 2016a. Dynamic Concept Composition for Zero-Example Event Detection. In AAAI, Dale Schuurmans and Michael P. Wellman (Eds.).Google Scholar"",""Xiaojun Chang, Yi Yang, Eric P. Xing, and Yaoliang Yu. 2015b. Complex Event Detection using Semantic Saliency and Nearly-Isotonic SVM. In ICML, Francis R. Bach and David M. Blei (Eds.).Google Scholar"",""Xiaojun Chang, Yaoliang Yu, Yi Yang, and Alexander G. Hauptmann. 2015c. Searching Persuasively: Joint Event Detection and Evidence Recounting with Limited Supervision. In ACM MM, Xiaofang Zhou, Alan F. Smeaton, Qi Tian, Dick C. A. Bulterman, Heng Tao Shen, Ketan Mayer-Patel, and Shuicheng Yan (Eds.).Google Scholar"",""Xiaojun Chang, Yaoliang Yu, Yi Yang, and Eric P. Xing. 2016b. They are Not Equally Reliable: Semantic Event Search Using Differentiated Concept Classifiers. In CVPR.Google Scholar"",""Xiaojun Chang, Yaoliang Yu, Yi Yang, and Eric P. Xing. 2017b. Semantic Pooling for Complex Event Analysis in Untrimmed Videos. IEEE Trans. Pattern Anal. Mach. Intell., Vol. 39, 8 (2017), 1617--1632.Google ScholarCross Ref"",""David L. Chen and William B. Dolan. [n.d.]. Collecting Highly Parallel Data for Paraphrase Evaluation. In ACL.Google Scholar"",""Wenqing Chu, Hongyang Xue, Chengwei Yao, and Deng Cai. 2019. Sparse Coding Guided Spatiotemporal Feature Learning for Abnormal Event Detection in Large Videos. IEEE Trans. Multimedia, Vol. 21, 1 (2019), 246--255.Google ScholarDigital Library"",""Shumin Deng, Ningyu Zhang, Jiaojian Kang, Yichi Zhang, Wei Zhang, and Huajun Chen. 2020. Meta-Learning with Dynamic-Memory-Based Prototypical Network for Few-Shot Event Detection. In WSDM.Google Scholar"",""Michael J. Denkowski and Alon Lavie. 2014. Meteor Universal: Language Specific Translation Evaluation for Any Target Language. In [email protected]Google Scholar"",""Í caro Cavalcante Dourado, Daniel Carlos Guimar a es Pedronette, and Ricardo da Silva Torres. 2019. Unsupervised graph-based rank aggregation for improved retrieval. Inf. Process. Manage., Vol. 56, 4 (2019), 1260--1279.Google ScholarCross Ref"",""Elise Epaillard and Nizar Bouguila. 2019. Variational Bayesian Learning of Generalized Dirichlet-Based Hidden Markov Models Applied to Unusual Events Detection. IEEE Trans. Neural Netw. Learning Syst., Vol. 30, 4 (2019), 1034--1047.Google ScholarCross Ref"",""Hehe Fan, Xiaojun Chang, De Cheng, Yi Yang, Dong Xu, and Alexander G. Hauptmann. 2017. Complex Event Detection by Identifying Reliable Shots from Untrimmed Videos. In ICCV.Google Scholar"",""Andrea Frome, Gregory S. Corrado, Jonathon Shlens, Samy Bengio, Jeffrey Dean, Marc'Aurelio Ranzato, and Tomas Mikolov. 2013. DeViSE: A Deep Visual-Semantic Embedding Model. In NIPS.Google Scholar"",""Yanwei Fu, Timothy M. Hospedales, Tao Xiang, and Shaogang Gong. 2012. Attribute Learning for Understanding Unstructured Social Activity. In ECCV.Google Scholar"",""AmirHossein Habibian, Thomas Mensink, and Cees G. M. Snoek. 2014. Composite Concept Discovery for Zero-Shot Video Event Detection. In ICMR.Google Scholar"",""Ryuhei Hamaguchi, Ken Sakurada, and Ryosuke Nakamura. 2019. Rare Event Detection Using Disentangled Representation Learning. In CVPR.Google Scholar"",""Haiqi Huang, Yueming Lu, Fangwei Zhang, and Songlin Sun. 2012. A Multi-modal Clustering Method for Web Videos. In ISCTCS.Google Scholar"",""Radu Tudor Ionescu, Fahad Shahbaz Khan, Mariana-Iuliana Georgescu, and Ling Shao. 2019. Object-Centric Auto-Encoders and Dummy Anomalies for Abnormal Event Detection in Video. In CVPR.Google Scholar"",""Lu Jiang, Deyu Meng, Shoou-I Yu, Zhen-Zhong Lan, Shiguang Shan, and Alexander G. Hauptmann. [n.d.]. Self-Paced Learning with Diversity. In NIPS.Google Scholar"",""Andrej Karpathy, George Toderici, Sanketh Shetty, Thomas Leung, Rahul Sukthankar, and Fei-Fei Li. 2014. Large-Scale Video Classification with Convolutional Neural Networks. In CVPR.Google Scholar"",""John G Kemeny. 1959. Mathematics without numbers. Daedalus, Vol. 88, 4 (1959), 577--591.Google Scholar"",""Christoph H. Lampert, Hannes Nickisch, and Stefan Harmeling. 2014. Attribute-Based Classification for Zero-Shot Visual Object Categorization. IEEE Trans. Pattern Anal. Mach. Intell., Vol. 36, 3 (2014), 453--465.Google ScholarDigital Library"",""Sangmin Lee, Hak Gu Kim, and Yong Man Ro. 2020. BMAN: Bidirectional Multi-Scale Aggregation Networks for Abnormal Event Detection. IEEE Trans. Image Processing, Vol. 29 (2020), 2395--2408.Google ScholarDigital Library"",""Yonggang Li, Rui Ge, Yi Ji, Shengrong Gong, and Chunping Liu. 2019 a. Trajectory-Pooled Spatial-Temporal Architecture of Deep Convolutional Neural Networks for Video Event Detection. IEEE Trans. Circuits Syst. Video Techn., Vol. 29, 9 (2019), 2683--2692.Google ScholarDigital Library"",""Zhihui Li, Lina Yao, Xiaojun Chang, Kun Zhan, Jiande Sun, and Huaxiang Zhang. 2019 b. Zero-shot event detection via event-adaptive concept relevance mining. Pattern Recognit., Vol. 88 (2019), 595--603.Google ScholarCross Ref"",""Huan Liu, Qinghua Zheng, Minnan Luo, Dingwen Zhang, Xiaojun Chang, and Cheng Deng. 2017. How Unlabeled Web Videos Help Complex Event Detection?. In IJCAI, Carles Sierra (Ed.).Google Scholar"",""Jian Liu, Yubo Chen, and Kang Liu. 2019. Exploiting the Ground-Truth: An Adversarial Imitation Based Knowledge Distillation Approach for Event Detection. In AAAI.Google Scholar"",""Masoud Mazloom, Efstratios Gavves, Koen E. A. van de Sande, and Cees Snoek. [n.d.]. Searching informative concept banks for video event detection. In ICMR.Google Scholar"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S. Corrado, and Jeffrey Dean. 2013. Distributed Representations of Words and Phrases and their Compositionality. In NIPS.Google Scholar"",""Joe Yue-Hei Ng, Matthew J. Hausknecht, Sudheendra Vijayanarasimhan, Oriol Vinyals, Rajat Monga, and George Toderici. 2015. Beyond short snippets: Deep networks for video classification. In CVPR.Google Scholar"",""Mark Palatucci, Dean Pomerleau, Geoffrey E. Hinton, and Tom M. Mitchell. 2009. Zero-shot Learning with Semantic Output Codes. In NIPS.Google Scholar"",""Pingbo Pan, Zhongwen Xu, Yi Yang, Fei Wu, and Yueting Zhuang. 2016b. Hierarchical Recurrent Neural Encoder for Video Representation with Application to Captioning. In CVPR.Google Scholar"",""Yingwei Pan, Tao Mei, Ting Yao, Houqiang Li, and Yong Rui. 2016a. Jointly Modeling Embedding and Translation to Bridge Video and Language. In CVPR.Google Scholar"",""Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a Method for Automatic Evaluation of Machine Translation. In ACL.Google Scholar"",""JC Platt. 1999. Probabilities for SV Machines, Advances in Large Margin Classifiers.Google Scholar"",""Arun Rajkumar and Shivani Agarwal. 2014. A Statistical Convergence Perspective of Algorithms for Rank Aggregation from Pairwise Data. In ICML.Google Scholar"",""Mohammad Rastegari, Ali Diba, Devi Parikh, and Ali Farhadi. 2013. Multi-attribute Queries: To Merge or Not to Merge?. In CVPR.Google Scholar"",""Ali Sharif Razavian, Hossein Azizpour, Josephine Sullivan, and Stefan Carlsson. 2014. CNN Features Off-the-Shelf: An Astounding Baseline for Recognition. In CVPR Workshops.Google Scholar"",""Jorge Sánchez, Florent Perronnin, Thomas Mensink, and Jakob J. Verbeek. 2013. Image Classification with the Fisher Vector: Theory and Practice. International Journal of Computer Vision, Vol. 105, 3 (2013), 222--245.Google ScholarDigital Library"",""Yiyuan She and Art B. Owen. 2010. Outlier Detection Using Nonconvex Penalized Regression. CoRR, Vol. abs/1006.2592 (2010).Google Scholar"",""Lei-Lei Shi, Lu Liu, Yan Wu, Liang Jiang, Muhammad Kazim, Haider Ali, and John Panneerselvam. 2019. Human-Centric Cyber Social Computing Model for Hot-Event Detection and Propagation. IEEE Trans. Comput. Social Systems, Vol. 6, 5 (2019), 1042--1050.Google ScholarCross Ref"",""Karen Simonyan and Andrew Zisserman. 2014. Two-Stream Convolutional Networks for Action Recognition in Videos. In NIPS.Google Scholar"",""Khurram Soomro, Amir Roshan Zamir, and Mubarak Shah. 2012. UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild. CoRR, Vol. abs/1212.0402 (2012).Google Scholar"",""Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. [n.d.]. Sequence to Sequence Learning with Neural Networks. In NIPS.Google Scholar"",""Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott E. Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. 2015. Going deeper with convolutions. In CVPR.Google Scholar"",""Bart Thomee, David A. Shamma, Gerald Friedland, Benjamin Elizalde, Karl Ni, Douglas Poland, Damian Borth, and Li-Jia Li. 2015. The New Data and New Challenges in Multimedia Research. CoRR, Vol. abs/1503.01817 (2015).Google Scholar"",""Subhashini Venugopalan, Marcus Rohrbach, Jeffrey Donahue, Raymond J. Mooney, Trevor Darrell, and Kate Saenko. 2015a. Sequence to Sequence - Video to Text. In ICCV.Google Scholar"",""Subhashini Venugopalan, Huijuan Xu, Jeff Donahue, Marcus Rohrbach, Raymond J. Mooney, and Kate Saenko. 2015b. Translating Videos to Natural Language Using Deep Recurrent Neural Networks. In NAACL.Google Scholar"",""Zuxuan Wu, Yanwei Fu, Yu-Gang Jiang, and Leonid Sigal. 2016. Harnessing Object and Scene Semantics for Large-Scale Video Understanding. In CVPR.Google Scholar"",""Xianjun Xia, Roberto Togneri, Ferdous Sohel, and Defeng Huang. 2019. Auxiliary Classifier Generative Adversarial Network With Soft Labels in Imbalanced Acoustic Event Detection. IEEE Trans. Multimedia, Vol. 21, 6 (2019), 1359--1371.Google ScholarDigital Library"",""Haoran Yan, Xiaolong Jin, Xiangbin Meng, Jiafeng Guo, and Xueqi Cheng. 2019. Event Detection with Multi-Order Graph Convolution and Aggregated Attention. In EMNLP-IJCNLP.Google Scholar"",""Li Yao, Atousa Torabi, Kyunghyun Cho, Nicolas Ballas, Christopher J. Pal, Hugo Larochelle, and Aaron C. Courville. 2015. Describing Videos by Exploiting Temporal Structure. In ICCV.Google Scholar"",""Shoou-I Yu, Lu Jiang, and Alexander G. Hauptmann. 2014. Instructional Videos for Unsupervised Harvesting and Learning of Action Examples. In ACM MM.Google Scholar"",""Dingwen Zhang, Junwei Han, Lu Jiang, Senmao Ye, and Xiaojun Chang. 2017. Revealing Event Saliency in Unconstrained Video Collection. IEEE Trans. Image Processing, Vol. 26, 4 (2017), 1746--1758.Google ScholarDigital Library"",""Hao Zhang and Chong-Wah Ngo. 2019. A Fine Granularity Object-Level Representation for Event Detection and Recounting. IEEE Trans. Multimedia, Vol. 21, 6 (2019), 1450--1463.Google ScholarDigital Library"",""Lingling Zhang, Jun Liu, Minnan Luo, Xiaojun Chang, and Qinghua Zheng. 2018. Deep Semisupervised Zero-Shot Learning with Maximum Mean Discrepancy. Neural Computation, Vol. 30, 5 (2018).Google ScholarDigital Library"",""Yu Zhao, Zhenhui Shi, Jingyang Zhang, Dong Chen, and Lixu Gu. 2019. A novel active learning framework for classification: Using weighted rank aggregation to achieve multiple query criteria. Pattern Recognition, Vol. 93 (2019), 581--602.Google ScholarCross Ref"",""Zhicheng Zhao, Xuanchong Li, Xingzhong Du, Qi Chen, Yanyun Zhao, Fei Su, Xiaojun Chang, and Alexander G. Hauptmann. 2018. A unified framework with a benchmark dataset for surveillance event detection. Neurocomputing, Vol. 278 (2018), 62--74.Google ScholarCross Ref"",""Yuke Zhu, Oliver Groth, Michael S. Bernstein, and Li Fei-Fei. 2016. Visual7W: Grounded Question Answering in Images. In CVPR.Google Scholar""]"
https://doi.org/10.1145/3394486.3403073,"How to Count Triangles, without Seeing the Whole Graph","Triangle counting is a fundamental problem in the analysis of large graphs. There is a rich body of work on this problem, in varying streaming and distributed models, yet all these algorithms require reading the whole input graph. In many scenarios, we do not have access to the whole graph, and can only sample a small portion of the graph (typically through crawling). In such a setting, how can we accurately estimate the triangle count of the graph?We formally study triangle counting in the random walk access model introduced by Dasgupta et al (WWW '14) and Chierichetti et al (WWW '16). We have access to an arbitrary seed vertex of the graph, and can only perform random walks. This model is restrictive in access and captures the challenges of collecting real-world graphs. Even sampling a uniform random vertex is a hard task in this model.Despite these challenges, we design a provable and practical algorithm, TETRIS, for triangle counting in this model. TETRIS is the first provably sublinear algorithm (for most natural parameter settings) that approximates the triangle count in the random walk model, for graphs with low mixing time. Our result builds on recent advances in the theory of sublinear algorithms. The final sample built by TETRIS is a careful mix of random walks and degree-biased sampling of neighborhoods. Empirically, TETRIS accurately counts triangles on a variety of large graphs, getting estimates within 5% relative error by looking at 3% of the number of edges.","[{""name"":""Suman K. Bera"",""id"":""/profile/81458647200""},{""name"":""C. Seshadhri"",""id"":""/profile/81384613020""},{""name"":""Suman K. Bera"",""id"":""/profile/81458647200""},{""name"":""C. Seshadhri"",""id"":""/profile/81384613020""}]","[""Nesreen K Ahmed, Nick Duffield, Jennifer Neville, and Ramana Kompella. 2014a. Graph sample and hold: A framework for big-graph analytics. In SIGKDD. ACM, ACM, 1446--1455.Google Scholar"",""Nesreen K Ahmed, Jennifer Neville, and Ramana Kompella. 2014b. Network sampling: From static to streaming graphs. ACM Transactions on Knowledge Discovery from Data (TKDD), Vol. 8, 2 (2014), 7.Google Scholar"",""Shaikh Arifuzzaman, Maleq Khan, and Madhav Marathe. 2013. Patric: A parallel algorithm for counting triangles in massive networks. In Conference on Information and Knowledge Management (CIKM). ACM, 529--538.Google ScholarDigital Library"",""Ariful Azad, Aydin Bulucc, and John Gilbert. 2015. Parallel triangle counting and enumeration using matrix algebra. In 2015 IEEE International Parallel and Distributed Processing Symposium Workshop. IEEE, 804--811.Google ScholarDigital Library"",""Ziv Bar-Yossef, Ravi Kumar, and D. Sivakumar. 2002. Reductions in Streaming Algorithms, with an Application to Counting Triangles in Graphs. In Proc. 13th Symposium on Discrete Algorithms (SODA). 623--632.Google Scholar"",""Luca Becchetti, Paolo Boldi, Carlos Castillo, and Aristides Gionis. 2008. Efficient semi-streaming algorithms for local triangle counting in massive graphs. In Knowledge Data and Discovery (KDD). ACM, 16--24.Google Scholar"",""Suman K Bera and Amit Chakrabarti. 2017. Towards tighter space bounds for counting triangles and other substructures in graph streams. In Proc. 34th International Symposium on Theoretical Aspects of Computer Science.Google Scholar"",""Suman K. Bera and C. Seshadhri. 2020. How the Degeneracy Helps for Triangle Counting in Graph Streams. In Proceedings of the 39th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems. 457 -- 467.Google Scholar"",""Luciana S. Buriol, Gereon Frahling, Stefano Leonardi, Alberto Marchetti-Spaccamela, and Christian Sohler. 2006. Counting Triangles in Data Streams. In Proc. 25th ACM Symposium on Principles of Database Systems. 253--262.Google ScholarDigital Library"",""Xiaowei Chen, Yongkun Li, Pinghui Wang, and John CS Lui. 2016. A General Framework for Estimating Graphlet Statistics via Random Walk. Proceedings of the VLDB Endowment, Vol. 10, 3 (2016).Google ScholarDigital Library"",""Norishige Chiba and Takao Nishizeki. 1985. Arboricity and Subgraph Listing Algorithms. SIAM J. Comput., Vol. 14, 1 (1985), 210--223.Google ScholarDigital Library"",""F. Chierichetti, A. Dasgupta, R. Kumar, S. Lattanzi, and T. Sarlos. 2016. On Sampling Nodes in a Network. In Conference on the World Wide Web (WWW).Google Scholar"",""Flavio Chierichetti and Shahrzad Haddadan. 2018. On the Complexity of Sampling Vertices Uniformly from a Graph. In Proc. 45th International Colloquium on Automata, Languages and Programming.Google Scholar"",""Jonathan Cohen. 2009. Graph twiddling in a mapreduce world. Computing in Science \u0026 Engineering, Vol. 11, 4 (2009), 29.Google ScholarDigital Library"",""Colin Cooper, Tomasz Radzik, and Yiannis Siantos. 2014. Estimating network parameters using random walks. Social Network Analysis and Mining, Vol. 4, 1 (2014), 168.Google ScholarCross Ref"",""A. Dasgupta, R. Kumar, and T. Sarlos. 2014. On estimating the average degree. In Conference on the World Wide Web (WWW). 795--806.Google Scholar"",""T. Eden, A. Levi, D. Ron, and C. Seshadhri. 2015. Approximately Counting Triangles in Sublinear Time. In Annual IEEE Symposium on Foundations of Computer Science, GRS11 (Ed.). 614--633.Google Scholar"",""T. Eden, D. Ron, and C. Seshadhri. 2017. Sublinear Time Estimation of Degree Distribution Moments: The Degeneracy Connection. In International Colloquium on Automata, Languages and Programming, GRS11 (Ed.). 614--633.Google Scholar"",""Talya Eden, Dana Ron, and C Seshadhri. 2020. Faster sublinear approximations of $ k $-cliques for low arboricity graphs. In Symposium on Discrete Algorithms (SODA).Google ScholarCross Ref"",""Roohollah Etemadi, Jianguo Lu, and Yung H Tsin. 2016. Efficient estimation of triangles in very large graphs. In Conference on Information and Knowledge Management (CIKM). ACM, 1251--1260.Google ScholarDigital Library"",""Oded Green, Pavan Yalamanchili, and Llu'is-Miquel Mungu'ia. 2014. Fast triangle counting on the GPU. In Proceedings of the 4th Workshop on Irregular Applications: Architectures and Algorithms. IEEE Press, 1--8.Google ScholarDigital Library"",""Stephen James Hardiman, Peter Richmond, and Stefan Hutzler. 2009. Calculating statistics of complex networks through random walks with an application to the on-line social network Bebo. The European Physical Journal B, Vol. 71, 4 (2009), 611.Google ScholarCross Ref"",""Xiaocheng Hu, Yufei Tao, and Chin-Wan Chung. 2014. I/O-efficient algorithms on triangle listing and counting. ACM Transactions on Database Systems (TODS), Vol. 39, 4 (2014), 27.Google ScholarDigital Library"",""Joseph J. Pfeiffer III, Timothy La Fond, Sebastiá n Moreno, and Jennifer Neville. 2012. Fast Generation of Large Scale Social Networks While Incorporating Transitive Closures. In International Conference on Privacy, Security, Risk and Trust (PASSAT). 154--165.Google Scholar"",""Alon Itai and Michael Rodeh. 1978. Finding a minimum circuit in a graph. SIAM J. Comput., Vol. 7, 4 (1978), 413--423.Google ScholarCross Ref"",""Madhav Jha, Ali Pinar, and C Seshadhri. 2015. Counting triangles in real-world graph streams: Dealing with repeated edges and time windows. In 2015 49th Asilomar Conference on Signals, Systems and Computers. IEEE, 1507--1514.Google ScholarCross Ref"",""Madhav Jha, C Seshadhri, and Ali Pinar. 2013. A space efficient streaming algorithm for triangle counting using the birthday paradox. In SIGKDD. ACM, 589--597.Google Scholar"",""Hossein Jowhari and Mohammad Ghodsi. 2005. New streaming algorithms for counting triangles in graphs. In Computing and Combinatorics. Springer, 710--716.Google Scholar"",""Liran Katzir and Stephen J Hardiman. 2015. Estimating clustering coefficients and size of social networks via random walk. ACM Transactions on the Web (TWEB), Vol. 9, 4 (2015), 19.Google Scholar"",""Liran Katzir, Edo Liberty, and Oren Somekh. 2011. Estimating sizes of social networks via biased sampling. In Proceedings of the 20th international conference on World wide web. ACM, 597--606.Google ScholarDigital Library"",""Arijit Khan, Nan Li, Xifeng Yan, Ziyu Guan, Supriyo Chakraborty, and Shu Tao. 2011. Neighborhood based fast graph search in large networks. In Proceedings of the 2011 ACM SIGMOD International Conference on Management of data. 901--912.Google ScholarDigital Library"",""Hyeonji Kim, Juneyoung Lee, Sourav S Bhowmick, Wook-Shin Han, JeongHoon Lee, Seongyun Ko, and Moath HA Jarrah. 2016. DUALSIM: Parallel subgraph enumeration in a massive graph on a single machine. In Proceedings of the 2016 International Conference on Management of Data. ACM, 1231--1245.Google ScholarDigital Library"",""Tamara G Kolda, Ali Pinar, Todd Plantenga, C Seshadhri, and Christine Task. 2014. Counting triangles in massive graphs with MapReduce. SIAM Journal on Scientific Computing, Vol. 36, 5 (2014), S48--S77.Google ScholarCross Ref"",""Mihail N Kolountzakis, Gary L Miller, Richard Peng, and Charalampos E Tsourakakis. 2012. Efficient triangle counting in large graphs via degree-based vertex partitioning. Internet Mathematics, Vol. 8, 1--2 (2012), 161--185.Google ScholarCross Ref"",""Jure Leskovec and Christos Faloutsos. 2006. Sampling from large graphs. In Knowledge Data and Discovery (KDD). ACM, 631--636.Google Scholar"",""Arun S Maiya and Tanya Y Berger-Wolf. 2011. Benefits of bias: Towards better characterization of network sampling. In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 105--113.Google ScholarDigital Library"",""Andrew McGregor, Sofya Vorotnikova, and Hoa T. Vu. 2016. Better Algorithms for Counting Triangles in Data Streams. In ACM Symposium on Principles of Database Systems. 401--411.Google Scholar"",""Ron Milo, Shai Shen-Orr, Shalev Itzkovitz, Nadav Kashtan, Dmitri Chklovskii, and Uri Alon. 2002. Network motifs: simple building blocks of complex networks. Science, Vol. 298, 5594 (2002), 824--827.Google Scholar"",""M. E. J. Newman. 2003. The Structure and Function of Complex Networks. SIAM Rev., Vol. 45, 2 (2003), 167--256. https://doi.org/10.1137/S003614450342480Google ScholarDigital Library"",""A. Pavan, Kanat Tangwongsan, Srikanta Tirthapura, and Kun-Lung Wu. 2013. Counting and Sampling Triangles from a Graph Stream. PVLDB, Vol. 6, 14 (2013), 1870--1881.Google ScholarDigital Library"",""Mahmudur Rahman and Mohammad Al Hasan. 2014. Sampling triples from restricted networks using MCMC strategy. In Proceedings of the 23rd ACM International Conference on Information and Knowledge Management. 1519--1528.Google ScholarDigital Library"",""Dana Ron and Gilad Tsur. 2016. The Power of an Example: Hidden Set Size Approximation Using Group Queries and Conditional Sampling. ACM Transactions on Computation Theory, Vol. 8, 4 (2016), 15:1--15:19.Google ScholarDigital Library"",""Ryan Rossi and Nesreen Ahmed. 2013. Network Repository. http://networkrepository.comGoogle Scholar"",""Thomas Schank and Dorothea Wagner. 2005. Finding, counting and listing all triangles in large graphs, an experimental study. In International workshop on experimental and efficient algorithms. Springer, 606--609.Google ScholarDigital Library"",""C. Seshadhri, Tamara G. Kolda, and Ali Pinar. 2012. Community structure and scale-free collections of Erdös-Rényi graphs. Physical Review E, Vol. 85, 5 (May 2012), 056109. https://doi.org/10.1103/PhysRevE.85.056109Google ScholarCross Ref"",""C. Seshadhri, Ali Pinar, and Tamara G Kolda. 2014. Wedge sampling for computing clustering coefficients and triangle counts on large graphs. Statistical Analysis and Data Mining, Vol. 7, 4 (2014), 294--307.Google ScholarDigital Library"",""C. Seshadhri and Srikanta Tirthapura. 2019. Scalable Subgraph Counting: The Methods Behind The Madness: WWW 2019 Tutorial. In Conference on the World Wide Web (WWW).Google Scholar"",""Lorenzo De Stefani, Alessandro Epasto, Matteo Riondato, and Eli Upfal. 2017. Triest: Counting local and global triangles in fully dynamic streams with fixed memory size. ACM Transactions on Knowledge Discovery from Data (TKDD), Vol. 11, 4 (2017), 43.Google ScholarDigital Library"",""Siddharth Suri and Sergei Vassilvitskii. 2011. Counting triangles and the curse of the last reducer. In Conference on the World Wide Web (WWW). 607--614.Google ScholarDigital Library"",""Kanat Tangwongsan, Aduri Pavan, and Srikanta Tirthapura. 2013. Parallel triangle counting in massive streaming graphs. In Knowledge Data and Discovery (KDD). ACM, 781--786.Google Scholar"",""Charalampos E Tsourakakis, U Kang, Gary L Miller, and Christos Faloutsos. 2009. Doulion: counting triangles in massive graphs with a coin. In Knowledge Data and Discovery (KDD). ACM, 837--846.Google Scholar"",""Ata Turk and Duru Turkoglu. 2019. Revisiting Wedge Sampling for Triangle Counting. In Conference on the World Wide Web (WWW). 1875--1885.Google Scholar"",""Duru Türkoglu and Ata Turk. 2017. Edge-based wedge sampling to estimate triangle counts in very large graphs. In International Conference on Data Mining (ICDM). 455--464.Google ScholarCross Ref"",""Stanley Wasserman and Katherine Faust. 1994. Social network analysis: Methods and applications. Vol. 8. Cambridge university press.Google Scholar"",""Duncan J Watts and Steven H Strogatz. 1998. Collective dynamics of 'small-world' networks. nature, Vol. 393, 6684 (1998), 440.Google Scholar"",""Bin Wu, Ke Yi, and Zhenguo Li. 2016. Counting triangles in large graphs by random sampling. IEEE Transactions on Knowledge and Data Engineering, Vol. 28, 8 (2016), 2013--2026.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403074,Incremental Lossless Graph Summarization,"Given a fully dynamic graph, represented as a stream of edge insertions and deletions, how can we obtain and incrementally update a lossless summary of its current snapshot? As large-scale graphs are prevalent, concisely representing them is inevitable for efficient storage and analysis. Lossless graph summarization is an effective graph-compression technique with many desirable properties. It aims to compactly represent the input graph as (a) a summary graph consisting of supernodes (i.e., sets of nodes) and superedges (i.e., edges between supernodes), which provide a rough description, and (b) edge corrections which fix errors induced by the rough description. While a number of batch algorithms, suited for static graphs, have been developed for rapid and compact graph summarization, they are highly inefficient in terms of time and space for dynamic graphs, which are common in practice.In this work, we propose MoSSo, the first incremental algorithm for lossless summarization of fully dynamic graphs. In response to each change in the input graph, MoSSo updates the output representation by repeatedly moving nodes among supernodes. MoSSo decides nodes to be moved and their destinations carefully but rapidly based on several novel ideas. Through extensive experiments on 10 real graphs, we show MoSSo is (a) Fast and 'any time': processing each change in near-constant time (less than 0.1 millisecond), up to 7 orders of magnitude faster than running state-of-the-art batch methods, (b) Scalable: summarizing graphs with hundreds of millions of edges, requiring sub-linear memory during the process, and (c) Effective: achieving comparable compression ratios even to state-of-the-art batch methods.","[{""name"":""Jihoon Ko"",""id"":""/profile/99659439562""},{""name"":""Yunbum Kook"",""id"":""/profile/99659574583""},{""name"":""Kijung Shin"",""id"":""/profile/99658999309""},{""name"":""Jihoon Ko"",""id"":""/profile/99659439562""},{""name"":""Yunbum Kook"",""id"":""/profile/99659574583""},{""name"":""Kijung Shin"",""id"":""/profile/99658999309""}]","[""Réka Albert and Albert-László Barabási. 2002. Statistical mechanics of complex networks. Reviews of modern physics, Vol. 74, 1 (2002), 47.Google Scholar"",""Maham Anwar Beg, Muhammad Ahmad, Arif Zaman, and Imdadullah Khan. 2018. Scalable Approximation Algorithm for Graph Summarization. In PAKDD.Google Scholar"",""Eric Temple Bell. 1938. The iterated exponential integers. Annals of Mathematics (1938), 539--557.Google Scholar"",""Paolo Boldi and Sebastiano Vigna. 2004. The webgraph framework I: compression techniques. In WWW.Google Scholar"",""Andrei Z Broder, Moses Charikar, Alan M Frieze, and Michael Mitzenmacher. 2000. Min-wise independent permutations. JCSS, Vol. 60, 3 (2000), 630--659.Google ScholarDigital Library"",""Gregory Buehrer and Kumar Chellapilla. 2008. A scalable pattern mining approach to web graph compression with communities. In WSDM.Google Scholar"",""Flavio Chierichetti, Ravi Kumar, Silvio Lattanzi, Michael Mitzenmacher, Alessandro Panconesi, and Prabhakar Raghavan. 2009. On compressing social networks. In KDD.Google Scholar"",""Laxman Dhulipala, Igor Kabiljo, Brian Karrer, Giuseppe Ottaviano, Sergey Pupyrev, and Alon Shalita. 2016. Compressing graphs and indexes with recursive graph bisection. In KDD.Google Scholar"",""Xiangyang Gou, Lei Zou, Chenxingyu Zhao, and Tong Yang. 2019. Fast and Accurate Graph Stream Summarization. In ICDE.Google Scholar"",""W Keith Hastings. 1970. Monte Carlo sampling methods using Markov chains and their applications. (1970).Google Scholar"",""Edward Kao, Vijay Gadepally, Michael Hurley, Michael Jones, Jeremy Kepner, Sanjeev Mohindra, Paul Monticciolo, Albert Reuther, Siddharth Samsi, William Song, et al. 2017. Streaming graph challenge: Stochastic block partition. In HPEC.Google Scholar"",""Arijit Khan and Charu Aggarwal. 2017. Toward query-friendly compression of rapid graph streams. SNAM, Vol. 7, 1 (2017), 23.Google Scholar"",""Kifayat Ullah Khan, Waqas Nawaz, and Young-Koo Lee. 2015. Set-based approximate approach for lossless graph summarization. Computing, Vol. 97, 12 (2015), 1185--1207.Google ScholarDigital Library"",""Jon M Kleinberg, Ravi Kumar, Prabhakar Raghavan, Sridhar Rajagopalan, and Andrew S Tomkins. 1999. The web as a graph: measurements, models, and methods. In COCOON.Google Scholar"",""Kyuhan Lee, Hyeonsoo Jo, Jihoon Ko, Sungsu Lim, and Kijung Shin. 2020. SSumM: Sparse Summarization of Massive Graphs. In KDD.Google Scholar"",""Kristen LeFevre and Evimaria Terzi. 2010. GraSS: Graph structure summarization. In SDM.Google Scholar"",""Jure Leskovec, Jon Kleinberg, and Christos Faloutsos. 2007. Graph evolution: Densification and shrinking diameters. TKDD, Vol. 1, 1 (2007), 2.Google ScholarDigital Library"",""Yike Liu, Tara Safavi, Abhilash Dighe, and Danai Koutra. 2018. Graph Summarization Methods and Applications: A Survey. CSUR, Vol. 51, 3 (2018), 62.Google ScholarDigital Library"",""Michael Mathioudakis, Francesco Bonchi, Carlos Castillo, Aristides Gionis, and Antti Ukkonen. 2011. Sparsification of influence networks. In KDD.Google Scholar"",""Yasir Mehmood, Nicola Barbieri, Francesco Bonchi, and Antti Ukkonen. 2013. Csi: Community-level social influence analysis. In ECML/PKDD.Google Scholar"",""Saket Navlakha, Rajeev Rastogi, and Nisheeth Shrivastava. 2008. Graph summarization with bounded error. In SIGMOD.Google Scholar"",""Huazhong Ning, Wei Xu, Yun Chi, Yihong Gong, and Thomas Huang. 2007. Incremental spectral clustering with application to monitoring of evolving blog communities. In SDM.Google Scholar"",""Tiago P Peixoto. 2014. Efficient Monte Carlo and greedy heuristic for the inference of stochastic block models. Physical Review E, Vol. 89, 1 (2014), 012804.Google ScholarCross Ref"",""Matteo Riondato, David Garc'ia-Soriano, and Francesco Bonchi. 2017. Graph summarization with quality guarantees. DMKD, Vol. 31, 2 (2017), 314--349.Google ScholarDigital Library"",""Jorma Rissanen. 1978. Modeling by shortest data description. Automatica, Vol. 14, 5 (1978), 465--471.Google ScholarDigital Library"",""Neil Shah, Danai Koutra, Tianmin Zou, Brian Gallagher, and Christos Faloutsos. 2015. Timecrunch: Interpretable dynamic graph summarization. In KDD.Google ScholarDigital Library"",""Kijung Shin, Amol Ghoting, Myunghwan Kim, and Hema Raghavan. 2019. Sweg: Lossless and lossy summarization of web-scale graphs. In WWW.Google Scholar"",""Julian Shun, Laxman Dhulipala, and Guy E Blelloch. 2015. Smaller and faster: Parallel processing of compressed graphs with Ligra+. In DCC.Google Scholar"",""Mansoureh Takaffoli, Reihaneh Rabbany, and Osmar R Zaiane. 2013. Incremental local community identification in dynamic social networks. In ASONAM.Google Scholar"",""Nan Tang, Qing Chen, and Prasenjit Mitra. 2016. Graph stream summarization: From big bang to big crunch. In SIGMOD.Google Scholar"",""Ioanna Tsalouchidou, Gianmarco De Francisci Morales, Francesco Bonchi, and Ricardo Baeza-Yates. 2016. Scalable dynamic graph summarization. In Big Data.Google Scholar"",""Peixiang Zhao, Charu C Aggarwal, and Min Wang. 2011. gSketch: on query estimation in graph streams. PVLDB, Vol. 5, 3 (2011), 193--204.Google ScholarDigital Library"",""Zhongying Zhao, Chao Li, Xuejian Zhang, Francisco Chiclana, and Enrique Herrera Viedma. 2019. An incremental method to detect communities in dynamic evolving social networks. Knowledge-Based Systems, Vol. 163 (2019), 404--415.Google ScholarCross Ref"",""Yang Zhou, Hong Cheng, and Jeffrey Xu Yu. 2010. Clustering large attributed graphs: An efficient incremental approach. In ICDM.Google Scholar""]"
https://doi.org/10.1145/3394486.3403075,From Online to Non-i.i.d. Batch Learning,"This paper initializes the study of online-to-batch conversion when the samples in batch learning are not i.i.d. Our motivation originated from two facts. First, sample sets in reality are seldom i.i.d., thus preventing the application of the existing conversions. Second, the online model of learning permits an adversarial stream of samples that almost for sure violates the i.i.d. assumption, raising the possibility of adapting an online algorithm effectively to learn from a non-i.i.d. sample set. We present a set of techniques to utilize an online algorithm as a black box to perform batch learning in the absence of the i.i.d. assumption. Our techniques are generic, and are applicable to virtually any online algorithms on classification. This provides strong evidence that the great variety of known algorithms in the online-learning literature can indeed be harnessed to learn from sufficiently-representative non-i.i.d. samples.","[{""name"":""Yufei Tao"",""id"":""/profile/81100159515""},{""name"":""Shangqi Lu"",""id"":""/profile/99659575037""},{""name"":""Yufei Tao"",""id"":""/profile/81100159515""},{""name"":""Shangqi Lu"",""id"":""/profile/99659575037""}]","[""Dana Angluin. 1987. Queries and Concept Learning. Machine Learning, Vol. 2, 4 (1987), 319--342.Google ScholarDigital Library"",""Arnab Bhattacharyya, Ameet Gadekar, and Ninad Rajgopal. 2015. On learning k-parities with and without noise. CoRR, Vol. abs/1502.05375 (2015).Google Scholar"",""Arnab Bhattacharyya, Ameet Gadekar, and Ninad Rajgopal. 2018. Improved Learning of k-Parities. In Proceedings of International Conference on Computing and Combinatorics (COCOON). 542--553.Google ScholarCross Ref"",""Avrim Blum. 1994. Separating Distribution-Free and Mistake-Bound Learning Models over the Boolean Domain., Vol. 23, 5 (1994), 990--1000.Google Scholar"",""Avrim Blum. 1996. On-line Algorithms in Machine Learning. In Online Algorithms, The State of the Art. 306--325.Google Scholar"",""Avrim Blum, Lisa Hellerstein, and Nick Littlestone. 1995. Learning in the Presence of Finitely or Infinitely Many Irrelevant Attributes. JCSS, Vol. 50, 1 (1995), 32--40.Google ScholarDigital Library"",""Avrim Blum, John Hopcroft, and Ravindran Kannan. 2018. Foundations of Data Science .Book available at http://www.cs.cornell.edu/jeh/book.pdf.Google Scholar"",""Harry Buhrman, David Garc'i a-Soriano, and Arie Matsliah. 2010. Learning parities in the mistake-bound model. IPL, Vol. 111, 1 (2010), 16--21.Google ScholarDigital Library"",""Nicolo Cesa-Bianchi, Alex Conconi, and Claudio Gentile. 2004. On the Generalization Ability of On-Line Learning Algorithms. IEEE Trans. Information Theory, Vol. 50, 9 (2004), 2050--2057.Google ScholarDigital Library"",""Nicolo Cesa-Bianchi and Claudio Gentile. 2008. Improved Risk Tail Bounds for On-Line Algorithms. IEEE Trans. Information Theory, Vol. 54, 1 (2008), 386--390.Google ScholarDigital Library"",""Ofer Dekel. 2008. From Online to Batch Learning with Cutoff-Averaging. In NIPS. 377--384.Google Scholar"",""Ofer Dekel and Yoram Singer. 2005. Data-Driven Online to Batch Conversions. In NIPS. 267--274.Google Scholar"",""Yoav Freund and Robert E. Schapire. 1999. Large Margin Classification Using the Perceptron Algorithm. Machine Learning, Vol. 37, 3 (1999), 277--296.Google ScholarDigital Library"",""S.I. Gallant. 1986. Optimal linear discriminants. In International Conference on Pattern Recognition. 849--852.Google Scholar"",""Wei Gao, Xin-Yi Niu, and Zhi-Hua Zhou. 2016. Learnability of Non-I.I.D. In Proceedings of Asian Conference on Machine Learning (ACML). 158--173.Google Scholar"",""Claudio Gentile. 2001. A New Approximate Maximal Margin Classification Algorithm. JMLR, Vol. 2 (2001), 213--242.Google ScholarDigital Library"",""David Haussler. 1988. Quantifying Inductive Bias: AI Learning Algorithms and Valiant's Learning Framework. Artif. Intell., Vol. 36, 2 (1988), 177--221.Google ScholarDigital Library"",""David P. Helmbold, Robert H. Sloan, and Manfred K. Warmuth. 1990. Learning Nested Differences of Intersection-Closed Concept Classes. Machine Learning, Vol. 5 (1990), 165--196.Google ScholarDigital Library"",""David P. Helmbold and Manfred K. Warmuth. 1995. On Weak Learning. JCSS, Vol. 50, 3 (1995), 551--573.Google ScholarDigital Library"",""Steven C. H. Hoi, Doyen Sahoo, Jing Lu, and Peilin Zhao. 2018. Online Learning: A Comprehensive Survey. CoRR, Vol. abs/1802.02871 (2018).Google Scholar"",""Lakhmi C. Jain, Manjeevan Seera, Chee Peng Lim, and Pagavathigounder Balasubramaniam. 2014. A review of online learning in supervised neural networks. Neural Computing and Applications, Vol. 25, 3--4 (2014), 491--509.Google ScholarDigital Library"",""Rajeeva L Karandikar and M. Vidyasagar. 2002. Rates of uniform convergence of empirical means with mixing processes. Statistics \u0026 Probability Letters, Vol. 58, 3 (2002), 297--307.Google ScholarCross Ref"",""Norbert Klasner and Hans Ulrich Simon. 1995. From Noise-Free to Noise-Tolerant and from On-line to Batch Learning. In COLT. 250--257.Google Scholar"",""Adam R. Klivans and Rocco A. Servedio. 2006. Toward Attribute Efficient Learning of Decision Lists and Parities. JMLR, Vol. 7 (2006), 587--602.Google ScholarDigital Library"",""Vitaly Kuznetsov and Mehryar Mohri. 2017. Generalization bounds for non-stationary mixing processes. Machine Learning, Vol. 106, 1 (2017), 93--117.Google ScholarDigital Library"",""Yi Li and Philip M. Long. 2002. The Relaxed Online Maximum Margin Algorithm. Machine Learning, Vol. 46, 1--3 (2002), 361--387.Google ScholarDigital Library"",""Nick Littlestone. 1987. Learning Quickly When Irrelevant Attributes Abound: A New Linear-threshold Algorithm. Machine Learning, Vol. 2, 4 (1987), 285--318.Google ScholarCross Ref"",""Nick Littlestone. 1989. From On-Line to Batch Learning. In COLT. 269--284.Google Scholar"",""Philip M. Long and Rocco A. Servedio. 2006. Attribute-efficient learning of decision lists and linear threshold functions under unconcentrated distributions. In NIPS. 921--928.Google Scholar"",""Viktor Losing, Barbara Hammer, and Heiko Wersing. 2018. Incremental on-line learning: A review and comparison of state of the art algorithms. Neurocomputing, Vol. 275 (2018), 1261--1274.Google ScholarDigital Library"",""Dharmendra S. Modha and Elias Masry. 1998. Memory-Universal Prediction of Stationary Random Processes. IEEE Trans. Information Theory, Vol. 44, 1 (1998), 117--133.Google ScholarDigital Library"",""Mehryar Mohri and Afshin Rostamizadeh. 2007. Stability Bounds for Non-i.i.d. Processes. In NIPS. 1025--1032.Google Scholar"",""Mehryar Mohri and Afshin Rostamizadeh. 2008. Rademacher Complexity Bounds for Non-I.I.D. Processes. In NIPS. 1097--1104.Google Scholar"",""Mehryar Mohri and Afshin Rostamizadeh. 2010. Stability Bounds for Stationary phi-mixing and beta-mixing Processes. JMLR, Vol. 11 (2010), 789--814.Google ScholarDigital Library"",""Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. 2018. Foundations of machine learning .MIT Press.Google Scholar"",""Ziv Nevo and Ran El-Yaniv. 2002. On Online Learning of Decision Lists. JMLR, Vol. 3 (2002), 271--301.Google Scholar"",""Frank Rosenblatt. 1958. The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain. Psychological Review, Vol. 65, 6 (1958), 386--408.Google ScholarDigital Library"",""Rocco A. Servedio. 2000. Computational Sample Complexity and Attribute-Efficient Learning. JCSS, Vol. 60, 1 (2000), 161--178.Google ScholarDigital Library"",""Shai Shalev-Shwartz. 2012. Online Learning and Online Convex Optimization. Foundations and Trends in Machine Learning, Vol. 4, 2 (2012), 107--194.Google ScholarDigital Library"",""Shai Shalev-Shwartz and Yoram Singer. 2005. A New Perspective on an Old Perceptron Algorithm. In COLT. 264--278.Google Scholar"",""Ingo Steinwart and Andreas Christmann. 2009. Fast Learning from Non-i.i.d. Observations. In NIPS. 1768--1776.Google Scholar"",""Ingo Steinwart, Don R. Hush, and Clint Scovel. 2009. Learning from dependent observations. J. Multivariate Analysis, Vol. 100, 1 (2009), 175--194.Google ScholarDigital Library"",""Ryuhei Uehara, Kensei Tsuchida, and Ingo Wegener. 1997. Optimal Attribute-Efficient Learning of Disjunction, Parity and Threshold Functions. In Proceedings of European Conference on Computational Learning Theory. 171--184.Google ScholarCross Ref"",""Mathukumalli Vidyasagar. 2002. A theory of learning and generalization: with applications to neural networks 2nd ed.). Springer.Google Scholar"",""Bin Yu. 1994. Rates of Convergence for Empirical Processes of Stationary Mixing Sequences. Annals of Probability, Vol. 22, 1 (1994), 94--116.Google ScholarCross Ref"",""Tong Zhang. 2005. Data Dependent Concentration Bounds for Sequential Prediction Algorithms. In COLT. 173--187.Google Scholar""]"
https://doi.org/10.1145/3394486.3403076,Towards Deeper Graph Neural Networks,"Graph neural networks have shown significant success in the field of graph representation learning. Graph convolutions perform neighborhood aggregation and represent one of the most important graph operations. Nevertheless, one layer of these neighborhood aggregation methods only consider immediate neighbors, and the performance decreases when going deeper to enable larger receptive fields. Several recent studies attribute this performance deterioration to the over-smoothing issue, which states that repeated propagation makes node representations of different classes indistinguishable. In this work, we study this observation systematically and develop new insights towards deeper graph neural networks. First, we provide a systematical analysis on this issue and argue that the key factor compromising the performance significantly is the entanglement of representation transformation and propagation in current graph convolution operations. After decoupling these two operations, deeper graph neural networks can be used to learn graph node representations from larger receptive fields. We further provide a theoretical analysis of the above observation when building very deep models, which can serve as a rigorous and gentle description of the over-smoothing issue. Based on our theoretical and empirical analysis, we propose Deep Adaptive Graph Neural Network (DAGNN) to adaptively incorporate information from large receptive fields. A set of experiments on citation, co-authorship, and co-purchase datasets have confirmed our analysis and insights and demonstrated the superiority of our proposed methods.","[{""name"":""Meng Liu"",""id"":""/profile/99659573968""},{""name"":""Hongyang Gao"",""id"":""/profile/99659287317""},{""name"":""Shuiwang Ji"",""id"":""/profile/81333489125""},{""name"":""Meng Liu"",""id"":""/profile/99659573968""},{""name"":""Hongyang Gao"",""id"":""/profile/99659287317""},{""name"":""Shuiwang Ji"",""id"":""/profile/81333489125""}]","[""Lei Cai and Shuiwang Ji. 2020. A Multi-Scale Approach for Graph Link Prediction. In Thirty-Four AAAI Conference on Artificial Intelligence.Google ScholarCross Ref"",""Olivier Chapelle, Bernhard Scholkopf, and Alexander Zien. 2009. Semi-supervised learning (chapelle, o. et al., eds.; 2006)[book reviews]. IEEE Transactions on Neural Networks, Vol. 20, 3 (2009), 542--542.Google ScholarDigital Library"",""Deli Chen, Yankai Lin, Wei Li, Peng Li, Jie Zhou, and Xu Sun. 2020. Measuring and Relieving the Over-smoothing Problem for Graph Neural Networks from the Topological View. In Thirty-Four AAAI Conference on Artificial Intelligence.Google ScholarCross Ref"",""Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolutional neural networks on graphs with fast localized spectral filtering. In Advances in neural information processing systems. 3844--3852.Google Scholar"",""Matthias Fey and Jan E. Lenssen. 2019. Fast Graph Representation Learning with PyTorch Geometric. In ICLR Workshop on Representation Learning on Graphs and Manifolds.Google Scholar"",""Hongyang Gao and Shuiwang Ji. 2019. Graph U-Nets. In International Conference on Machine Learning. 2083--2092.Google Scholar"",""Hongyang Gao, Zhengyang Wang, and Shuiwang Ji. 2018. Large-scale learnable graph convolutional networks. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1416--1424.Google ScholarDigital Library"",""Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. 2017. Neural message passing for quantum chemistry. In International Conference on Machine Learning. 1263--1272.Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In Advances in Neural Information Processing Systems. 1024--1034.Google Scholar"",""Kurt Hornik, Maxwell Stinchcombe, Halbert White, et al. 1989. Multilayer feedforward networks are universal approximators. IEEE Transactions on Neural Networks, Vol. 2, 5 (1989), 359--366.Google ScholarCross Ref"",""Thomas N Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional networks. In International Conference on Learning Representations.Google Scholar"",""Johannes Klicpera, Aleksandar Bojchevski, and Stephan Günnemann. 2019. Predict then propagate: Graph neural networks meet personalized pagerank. In International Conference on Learning Representations.Google Scholar"",""Panqanamala Ramana Kumar and Pravin Varaiya. 2015. Stochastic systems: Estimation, identification, and adaptive control. Vol. 75. SIAM.Google Scholar"",""Junhyun Lee, Inyeop Lee, and Jaewoo Kang. 2019. Self-Attention Graph Pooling. In International Conference on Machine Learning. 3734--3743.Google Scholar"",""Qimai Li, Zhichao Han, and Xiao-Ming Wu. 2018. Deeper insights into graph convolutional networks for semi-supervised learning. In Thirty-Second AAAI Conference on Artificial Intelligence.Google Scholar"",""Meng Liu, Zhengyang Wang, and Shuiwang Ji. 2020. Non-Local Graph Neural Networks. arXiv preprint arXiv:2005.14612 (2020).Google Scholar"",""László Lovász et al. 1993. Random walks on graphs: A survey. Combinatorics, Paul erdos is eighty, Vol. 2, 1 (1993), 1--46.Google Scholar"",""Yao Ma, Suhang Wang, Charu C Aggarwal, and Jiliang Tang. 2019. Graph convolutional networks with eigenpooling. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 723--731.Google ScholarDigital Library"",""Laurens van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE. Journal of machine learning research, Vol. 9, Nov (2008), 2579--2605.Google Scholar"",""Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van Den Hengel. 2015. Image-based recommendations on styles and substitutes. In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval. 43--52.Google ScholarDigital Library"",""Federico Monti, Davide Boscaini, Jonathan Masci, Emanuele Rodola, Jan Svoboda, and Michael M Bronstein. 2017. Geometric deep learning on graphs and manifolds using mixture model cnns. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 5115--5124.Google ScholarCross Ref"",""Vinod Nair and Geoffrey E Hinton. 2010. Rectified linear units improve restricted boltzmann machines. In International Conference on Machine Learning. 807--814.Google ScholarDigital Library"",""Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. 1999. The PageRank citation ranking: Bringing order to the web. Technical Report. Stanford InfoLab.Google Scholar"",""Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. 2017. Automatic differentiation in pytorch. In Proceedings of Neural Information Processing Systems Autodiff Workshop.Google Scholar"",""Hongbin Pei, Bingzhe Wei, Kevin Chen-Chuan Chang, Yu Lei, and Bo Yang. 2020. Geom-gcn: Geometric graph convolutional networks. In International Conference on Learning Representations.Google Scholar"",""Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, and Tina Eliassi-Rad. 2008. Collective classification in network data. AI magazine, Vol. 29, 3 (2008), 93--93.Google Scholar"",""Eugene Seneta. 2006. Non-negative matrices and Markov chains .Springer Science \u0026 Business Media.Google Scholar"",""Oleksandr Shchur, Maximilian Mumme, Aleksandar Bojchevski, and Stephan Günnemann. 2018. Pitfalls of graph neural network evaluation. arXiv preprint arXiv:1811.05868 (2018).Google Scholar"",""Gabriel Taubin. 1995. A signal processing approach to fair surface design. In Proceedings of the 22nd annual conference on Computer graphics and interactive techniques. ACM, 351--358.Google ScholarDigital Library"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2018. Graph attention networks. In International Conference on Learning Representation.Google Scholar"",""Felix Wu, Amauri Souza, Tianyi Zhang, Christopher Fifty, Tao Yu, and Kilian Weinberger. 2019. Simplifying Graph Convolutional Networks. In International Conference on Machine Learning. 6861--6871.Google Scholar"",""Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2019. How powerful are graph neural networks?. In International Conference on Learning Representations.Google Scholar"",""Keyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi, and Stefanie Jegelka. 2018. Representation Learning on Graphs with Jumping Knowledge Networks. In International Conference on Machine Learning. 5449--5458.Google Scholar"",""Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, and Jure Leskovec. 2018. Hierarchical graph representation learning with differentiable pooling. In Advances in neural information processing systems. 4800--4810.Google Scholar"",""Hao Yuan and Shuiwang Ji. 2020. StructPool: Structured Graph Pooling via Conditional Random Fields. In International Conference on Learning Representations.Google Scholar"",""Muhan Zhang and Yixin Chen. 2017. Weisfeiler-lehman neural machine for link prediction. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 575--583.Google ScholarDigital Library"",""Muhan Zhang and Yixin Chen. 2018. Link prediction based on graph neural networks. In Advances in Neural Information Processing Systems. 5165--5175.Google Scholar"",""Muhan Zhang, Zhicheng Cui, Marion Neumann, and Yixin Chen. 2018. An end-to-end deep learning architecture for graph classification. In Thirty-Second AAAI Conference on Artificial Intelligence.Google Scholar""]"
https://doi.org/10.1145/3394486.3403077,Laplacian Change Point Detection for Dynamic Graphs,"Dynamic and temporal graphs are rich data structures that are used to model complex relationships between entities over time. In particular, anomaly detection in temporal graphs is crucial for many real world applications such as intrusion identification in network systems, detection of ecosystem disturbances and detection of epidemic outbreaks. In this paper, we focus on change point detection in dynamic graphs and address two main challenges associated with this problem: I) how to compare graph snapshots across time, II) how to capture temporal dependencies. To solve the above challenges, we propose Laplacian Anomaly Detection (LAD) which uses the spectrum of the Laplacian matrix of the graph structure at each snapshot to obtain low dimensional embeddings. LAD explicitly models short term and long term dependencies by applying two sliding windows. In synthetic experiments, LAD outperforms the state-of-the-art method. We also evaluate our method on three real dynamic networks: UCI message network, US senate co-sponsorship network and Canadian bill voting network. In all three datasets, we demonstrate that our method can more effectively identify anomalous time points according to significant real world events.","[{""name"":""Shenyang Huang"",""id"":""/profile/99659574288""},{""name"":""Yasmeen Hitti"",""id"":""/profile/99659574690""},{""name"":""Guillaume Rabusseau"",""id"":""/profile/99659218227""},{""name"":""Reihaneh Rabbany"",""id"":""/profile/81479661942""},{""name"":""Shenyang Huang"",""id"":""/profile/99659574288""},{""name"":""Yasmeen Hitti"",""id"":""/profile/99659574690""},{""name"":""Guillaume Rabusseau"",""id"":""/profile/99659218227""},{""name"":""Reihaneh Rabbany"",""id"":""/profile/81479661942""}]","[""Michal Aharon, Michael Elad, and Alfred Bruckstein. 2006. K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation. IEEE Transactions on signal processing, Vol. 54, 11 (2006), 4311--4322.Google ScholarDigital Library"",""Leman Akoglu and Christos Faloutsos. 2010. Event detection in time series of mobile communication graphs. In Army science conference, Vol. 1.Google Scholar"",""N Benjamin Erichson, Steven L Brunton, and J Nathan Kutz. 2017. Compressed singular value decomposition for image and video processing. In Proceedings of the IEEE International Conference on Computer Vision Workshops. 1880--1888.Google ScholarCross Ref"",""Michael W Berry. 1992. Large-scale sparse singular value computations. The International Journal of Supercomputing Applications, Vol. 6, 1 (1992), 13--49.Google ScholarDigital Library"",""Phillip Bonacich. 1987. Power and centrality: A family of measures. American journal of sociology, Vol. 92, 5 (1987), 1170--1182.Google Scholar"",""Markus M Breunig, Hans-Peter Kriegel, Raymond T Ng, and Jörg Sander. 2000. LOF: identifying density-based local outliers. In Proceedings of the 2000 ACM SIGMOD international conference on Management of data. 93--104.Google ScholarDigital Library"",""Rasmus Bro. 1997. PARAFAC. Tutorial and applications. Chemometrics and intelligent laboratory systems, Vol. 38, 2 (1997), 149--171.Google Scholar"",""Anna D Broido and Aaron Clauset. 2019. Scale-free networks are rare. Nature communications, Vol. 10, 1 (2019), 1017.Google Scholar"",""Zhengzhang Chen, William Hendrix, and Nagiza F Samatova. 2012. Community-based anomaly detection in evolutionary networks. Journal of Intelligent Information Systems, Vol. 39, 1 (2012), 59--85.Google ScholarDigital Library"",""Fan RK Chung and Fan Chung Graham. 1997. Spectral graph theory. Number 92. American Mathematical Soc.Google Scholar"",""Our Commons. [n.d.]. In the House. https://www.ourcommons.ca/en Retrieved February 9, 2020 fromGoogle Scholar"",""Richard S Conley. 2011. Legislative Activity in the Canadian House of Commons: Does Majority or Minority Government Matter? American Review of Canadian Studies, Vol. 41, 4 (2011), 422--437.Google ScholarCross Ref"",""William Cross. 2016. The Importance of Local Party Activity in Understanding Canadian Politics: Winning from the Ground Up in the 2015 Federal Election: Presidential Address to the Canadian Political Science Association Calgary, 31 May 2016. Canadian Journal of Political Science/Revue canadienne de science politique, Vol. 49, 4 (2016), 601--620.Google Scholar"",""Dhivya Eswaran, Christos Faloutsos, Sudipto Guha, and Nina Mishra. 2018. Spotlight: Detecting anomalies in streaming graphs. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1378--1386.Google ScholarDigital Library"",""James H Fowler. 2006. Legislative cosponsorship networks in the US House and Senate. Social Networks, Vol. 28, 4 (2006), 454--465.Google ScholarCross Ref"",""Mostafa Reisi Gahrooei and Kamran Paynabar. 2018. Change detection in a dynamic stream of attributed networks. Journal of Quality Technology, Vol. 50, 4 (2018), 418--430.Google ScholarCross Ref"",""Christopher Garner and Natalia Letki. 2005. Party structure and backbench dissent in the Canadian and British Parliaments. Canadian Journal of Political Science/Revue canadienne de science politique, Vol. 38, 2 (2005), 463--482.Google Scholar"",""K-I Goh, Byungnam Kahng, and Doochul Kim. 2001. Universal behavior of load distribution in scale-free networks. Physical review letters, Vol. 87, 27 (2001), 278701.Google Scholar"",""Gene H Golub and Christian Reinsch. 1971. Singular value decomposition and least squares solutions. In Linear Algebra. Springer, 134--151.Google Scholar"",""Lars Hagen and Andrew B Kahng. 1992. New spectral methods for ratio cut partitioning and clustering. IEEE transactions on computer-aided design of integrated circuits and systems, Vol. 11, 9 (1992), 1074--1085.Google Scholar"",""Nathan Halko, Per-Gunnar Martinsson, and Joel A Tropp. 2011. Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions. SIAM review, Vol. 53, 2 (2011), 217--288.Google Scholar"",""Richard A Harshman et al. 1970. Foundations of the PARAFAC procedure: Models and conditions for an\"" explanatory\"" multimodal factor analysis. (1970).Google Scholar"",""Paul W Holland, Kathryn Blackmond Laskey, and Samuel Leinhardt. 1983. Stochastic blockmodels: First steps. Social networks, Vol. 5, 2 (1983), 109--137.Google Scholar"",""Tsuyoshi Idé and Hisashi Kashima. 2004. Eigenspace-based anomaly detection in computer systems. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 440--449.Google ScholarDigital Library"",""Tamara G Kolda and Brett W Bader. 2009. Tensor decompositions and applications. SIAM review, Vol. 51, 3 (2009), 455--500.Google Scholar"",""Jean Kossaifi, Yannis Panagakis, Anima Anandkumar, and Maja Pantic. 2019. Tensorly: Tensor learning in python. The Journal of Machine Learning Research, Vol. 20, 1 (2019), 925--930.Google ScholarDigital Library"",""Danai Koutra, Evangelos E Papalexakis, and Christos Faloutsos. 2012. Tensorsplat: Spotting latent anomalies in time. In 2012 16th Panhellenic Conference on Informatics. IEEE, 144--149.Google ScholarDigital Library"",""Danai Koutra, Neil Shah, Joshua T Vogelstein, Brian Gallagher, and Christos Faloutsos. 2016. Deltacon: Principled massive-graph similarity function with attribution. ACM Transactions on Knowledge Discovery from Data (TKDD), Vol. 10, 3 (2016), 1--43.Google ScholarDigital Library"",""Xiaolei Li, Zhenhui Li, Jiawei Han, and Jae-Gil Lee. 2009. Temporal outlier detection in vehicle traffic data. In 2009 IEEE 25th International Conference on Data Engineering. IEEE, 1319--1322.Google ScholarDigital Library"",""Emmett Macfarlane. 2019. The Renewed Canadian Senate: Organizational Challenges and Relations with the Government .Institute for Research on Public Policy.Google Scholar"",""Alex Marland. 2013. What is a political brand?: Justin Trudeau and the theory of political branding. In annual meeting of the Canadian Communication Association and the Canadian Political Science Association, University of Victoria, British Columbia, June, Vol. 6.Google Scholar"",""Benjamin A Miller, Nicholas Arcolano, Michelle S Beard, Jeremy Kepner, Matthew C Schmidt, Nadya T Bliss, and Patrick J Wolfe. 2012. A scalable signal processing architecture for massive graph analysis. In 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 5329--5332.Google ScholarCross Ref"",""Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. 1999. The pagerank citation ranking: Bringing order to the web. Technical Report. Stanford InfoLab.Google Scholar"",""Pietro Panzarasa, Tore Opsahl, and Kathleen M Carley. 2009. Patterns and dynamics of users' behavior and interaction: Network analysis of an online community. Journal of the American Society for Information Science and Technology, Vol. 60, 5 (2009), 911--932.Google ScholarDigital Library"",""F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011. Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, Vol. 12 (2011), 2825--2830.Google ScholarDigital Library"",""Leto Peel and Aaron Clauset. 2015. Detecting change points in the large-scale structure of evolving networks. In Twenty-Ninth AAAI Conference on Artificial Intelligence .Google ScholarDigital Library"",""Stephen Ranshous, Shitian Shen, Danai Koutra, Steve Harenberg, Christos Faloutsos, and Nagiza F Samatova. 2015. Anomaly detection in dynamic networks: a survey. Wiley Interdisciplinary Reviews: Computational Statistics, Vol. 7, 3 (2015), 223--247.Google ScholarDigital Library"",""Awwal Mohammed Rufai, Gholamreza Anbarjafari, and Hasan Demirel. 2014. Lossy image compression using singular value decomposition and wavelet difference reduction. Digital signal processing, Vol. 24 (2014), 117--123.Google Scholar"",""Neil Shah, Danai Koutra, Tianmin Zou, Brian Gallagher, and Christos Faloutsos. 2015. Timecrunch: Interpretable dynamic graph summarization. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 1055--1064.Google ScholarDigital Library"",""Jianbo Shi and Jitendra Malik. 2000. Normalized cuts and image segmentation. IEEE Transactions on pattern analysis and machine intelligence, Vol. 22, 8 (2000), 888--905.Google ScholarDigital Library"",""Brian Thompson and Tina Eliassi-Rad. 2009. Dapa-v10: Discovery and analysis of patterns and anomalies in volatile time-evolving networks. Technical Report. Lawrence Livermore National Lab.(LLNL), Livermore, CA (United States).Google Scholar"",""Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, Stéfan J. van der Walt, Matthew Brett, Joshua Wilson, K. Jarrod Millman, Nikolay Mayorov, Andrew R. J. Nelson, Eric Jones, Robert Kern, Eric Larson, CJ Carey, .Ilhan Polat, Yu Feng, Eric W. Moore, Jake Vand erPlas, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen, E. A. Quintero, Charles R Harris, Anne M. Archibald, Antônio H. Ribeiro, Fabian Pedregosa, Paul van Mulbregt, and SciPy 1. 0 Contributors. 2020. SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python. Nature Methods (2020). https://doi.org/10.1038/s41592-019-0686--2Google Scholar"",""Ulrike Von Luxburg. 2007. A tutorial on spectral clustering. Statistics and computing, Vol. 17, 4 (2007), 395--416.Google Scholar"",""Yu Wang, Aniket Chakrabarti, David Sivakoff, and Srinivasan Parthasarathy. 2017. Fast change point detection on dynamic social networks. arXiv preprint arXiv:1705.07325 (2017).Google Scholar"",""Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2018. How powerful are graph neural networks? arXiv preprint arXiv:1810.00826 (2018).Google Scholar"",""Rose Yu, Huida Qiu, Zhen Wen, ChingYung Lin, and Yan Liu. 2016. A survey on social media anomaly detection. ACM SIGKDD Explorations Newsletter, Vol. 18, 1 (2016), 1--14.Google ScholarDigital Library"",""Wenchao Yu, Wei Cheng, Charu C Aggarwal, Kai Zhang, Haifeng Chen, and Wei Wang. 2018. Netwalk: A flexible deep embedding approach for anomaly detection in dynamic networks. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 2672--2681.Google ScholarDigital Library"",""Sina Zamani, Tejaswi Nanjundaswamy, and Kenneth Rose. 2017. Frequency domain singular value decomposition for efficient spatial audio coding. In 2017 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA). IEEE, 126--130.Google ScholarCross Ref"",""Xiao-Dong Zhang. 2011. The Laplacian eigenvalues of graphs: a survey. arXiv preprint arXiv:1111.2897 (2011).Google Scholar"",""Li Zheng, Zhenpeng Li, Jian Li, Zhao Li, and Jun Gao. 2019. Addgraph: anomaly detection in dynamic graph using attention-based temporal GCN. In Proceedings of the 28th International Joint Conference on Artificial Intelligence. AAAI Press, 4419--4425.Google ScholarCross Ref"",""Eric R Ziegel. 2001. Standard probability and statistics tables and formulae. Technometrics, Vol. 43, 2 (2001), 249.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403078,Learning Transferrable Parameters for Long-tailed Sequential User Behavior Modeling,"Sequential user behavior modeling plays a crucial role in online user-oriented services, such as product purchasing, news feed consumption, and online advertising. The performance of sequential modeling heavily depends on the scale and quality of historical behaviors. However, the number of user behaviors inherently follows a long-tailed distribution, which has been seldom explored. In this work, we argue that focusing on tail users could bring more benefits and address the long tails issue by learning transferrable parameters from both optimization and feature perspectives. Specifically, we propose a gradient alignment optimizer and adopt an adversarial training scheme to facilitate knowledge transfer from the head to the tail. Such methods can also deal with the cold-start problem of new users. Moreover, it could be directly adaptive to various well-established sequential models. Extensive experiments on four real-world datasets verify the superiority of our framework compared with the state-of-the-art baselines.","[{""name"":""Jianwen Yin"",""id"":""/profile/99659573438""},{""name"":""Chenghao Liu"",""id"":""/profile/99659081852""},{""name"":""Weiqing Wang"",""id"":""/profile/99658741487""},{""name"":""Jianling Sun"",""id"":""/profile/81479656758""},{""name"":""Steven C.H. Hoi"",""id"":""/profile/81501646172""},{""name"":""Jianwen Yin"",""id"":""/profile/99659573438""},{""name"":""Chenghao Liu"",""id"":""/profile/99659081852""},{""name"":""Weiqing Wang"",""id"":""/profile/99658741487""},{""name"":""Jianling Sun"",""id"":""/profile/81479656758""},{""name"":""Steven C.H. Hoi"",""id"":""/profile/81501646172""}]","[""Alex Beutel, Ed H Chi, Zhiyuan Cheng, Hubert Pham, and John Anderson. 2017. Beyond globally optimal: Focused learning for improved recommendations. In Proceedings of the 26th International Conference on World Wide Web. 203--212.Google ScholarDigital Library"",""Sebastian Flennerhag, Pablo G Moreno, Neil D Lawrence, and Andreas Damianou. 2018. Transferring knowledge across learning processes. arXiv preprint arXiv:1812.01054 (2018).Google Scholar"",""Chengyue Gong, Di He, Xu Tan, Tao Qin, Liwei Wang, and Tie-Yan Liu. 2018. Frage: Frequency-agnostic word representation. In Advances in neural information processing systems. 1334--1345.Google Scholar"",""Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014a. Generative adversarial nets. In Advances in neural information processing systems. 2672--2680.Google Scholar"",""Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2014b. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572 (2014).Google Scholar"",""Ruining He and Julian McAuley. 2016. Fusing similarity models with markov chains for sparse sequential recommendation. In 2016 IEEE 16th International Conference on Data Mining (ICDM). IEEE, 191--200.Google ScholarCross Ref"",""Xiangnan He, Hanwang Zhang, Min-Yen Kan, and Tat-Seng Chua. 2016. Fast matrix factorization for online recommendation with implicit feedback. In Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval. 549--558.Google ScholarDigital Library"",""Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2015. Session-based recommendations with recurrent neural networks. arXiv preprint arXiv:1511.06939 (2015).Google Scholar"",""Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recommendation. In 2018 IEEE International Conference on Data Mining (ICDM). IEEE, 197--206.Google ScholarCross Ref"",""Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix factorization techniques for recommender systems. Computer 8 (2009), 30--37.Google ScholarDigital Library"",""Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, and Jun Ma. 2017. Neural attentive session-based recommendation. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management. 1419--1428.Google ScholarDigital Library"",""Chenghao Liu, Steven CH Hoi, Peilin Zhao, Jianling Sun, and Ee-Peng Lim. 2016. Online adaptive passive-aggressive methods for non-negative matrix factorization and its applications. In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management. ACM, 1161--1170.Google ScholarDigital Library"",""Chenghao Liu, Tao Jin, Steven CH Hoi, Peilin Zhao, and Jianling Sun. 2017. Collaborative topic regression for online recommender systems: an online and Bayesian approach. Machine Learning, Vol. 106, 5 (2017), 651--670.Google ScholarDigital Library"",""Chen Ma, Peng Kang, and Xue Liu. 2019. Hierarchical gating networks for sequential recommendation. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 825--833.Google ScholarDigital Library"",""Andriy Mnih and Russ R Salakhutdinov. 2008. Probabilistic matrix factorization. In Advances in neural information processing systems. 1257--1264.Google Scholar"",""Alex Nichol, Joshua Achiam, and John Schulman. 2018. On first-order meta-learning algorithms. arXiv preprint arXiv:1803.02999 (2018).Google Scholar"",""James R Norris. 1998. Markov chains. Number 2. Cambridge university press.Google Scholar"",""Yanru Qu, Han Cai, Kan Ren, Weinan Zhang, Yong Yu, Ying Wen, and Jun Wang. 2016. Product-based neural networks for user response prediction. In 2016 IEEE 16th International Conference on Data Mining (ICDM). IEEE, 1149--1154.Google ScholarCross Ref"",""Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Factorizing personalized markov chains for next-basket recommendation. In Proceedings of the 19th international conference on World wide web. ACM, 811--820.Google ScholarDigital Library"",""Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu, Irina Rish, Yuhai Tu, and Gerald Tesauro. 2018. Learning to learn without forgetting by maximizing transfer and minimizing interference. arXiv preprint arXiv:1810.11910 (2018).Google Scholar"",""Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. 2016. Improved techniques for training gans. In Advances in neural information processing systems. 2234--2242.Google Scholar"",""Robert Sanders. 1987. The Pareto principle: its use and abuse. Journal of Services Marketing (1987).Google Scholar"",""Guy Shani, David Heckerman, and Ronen I Brafman. 2005. An MDP-based recommender system. Journal of Machine Learning Research, Vol. 6, Sep (2005), 1265--1295.Google ScholarDigital Library"",""Mohit Sharma and George Karypis. 2019. Adaptive matrix completion for the users and the items in tail. In The World Wide Web Conference. 3223--3229.Google ScholarDigital Library"",""Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. 2013. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199 (2013).Google Scholar"",""Jiaxi Tang and Ke Wang. 2018. Personalized top-n sequential recommendation via convolutional sequence embedding. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. ACM, 565--573.Google ScholarDigital Library"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998--6008.Google Scholar"",""Pengfei Wang, Jiafeng Guo, Yanyan Lan, Jun Xu, Shengxian Wan, and Xueqi Cheng. 2015. Learning hierarchical representation model for nextbasket recommendation. In Proceedings of the 38th International ACM SIGIR conference on Research and Development in Information Retrieval. ACM, 403--412.Google ScholarDigital Library"",""Shoujin Wang, Liang Hu, Longbing Cao, Xiaoshui Huang, Defu Lian, and Wei Liu. 2018a. Attention-based transactional context embedding for next-item recommendation. In Thirty-Second AAAI Conference on Artificial Intelligence .Google Scholar"",""Weiqing Wang, Hongzhi Yin, Ling Chen, Yizhou Sun, Shazia Sadiq, and Xiaofang Zhou. 2017. ST-SAGE: A spatial-temporal sparse additive generative model for spatial item recommendation. ACM Transactions on Intelligent Systems and Technology (TIST), Vol. 8, 3 (2017), 1--25.Google ScholarDigital Library"",""Weiqing Wang, Hongzhi Yin, Xingzhong Du, Quoc Viet Hung Nguyen, and Xiaofang Zhou. 2018b. Tpm: A temporal personalized model for spatial item recommendation. ACM Transactions on Intelligent Systems and Technology (TIST), Vol. 9, 6 (2018), 1--25.Google ScholarDigital Library"",""Jianwen Yin, Chenghao Liu, Jundong Li, BingTian Dai, Yun-chen Chen, Min Wu, and Jianling Sun. 2019. Online Collaborative Filtering with Implicit Feedback. In International Conference on Database Systems for Advanced Applications. Springer, 433--448.Google Scholar"",""Lu Yu, Chuxu Zhang, Shangsong Liang, and Xiangliang Zhang. 2019. Multi-order Attentive Ranking Model for Sequential Recommendation. (2019).Google Scholar"",""Fajie Yuan, Alexandros Karatzoglou, Ioannis Arapakis, Joemon M Jose, and Xiangnan He. 2018. A Simple but Hard-to-Beat Baseline for Session-based Recommendations. arXiv preprint arXiv:1808.05163 (2018).Google Scholar"",""Michael Zhang, James Lucas, Jimmy Ba, and Geoffrey E Hinton. 2019 a. Lookahead Optimizer: k steps forward, 1 step back. In Advances in Neural Information Processing Systems. 9593--9604.Google Scholar"",""Shuai Zhang, Yi Tay, Lina Yao, Aixin Sun, and Jake An. 2019 b. Next Item Recommendation with Self-Attentive Metric Learning. (2019).Google Scholar"",""Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through rate prediction. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1059--1068.Google ScholarDigital Library"",""Andrew Zimdars, David Maxwell Chickering, and Christopher Meek. 2001. Using temporal data for making recommendations. In Proceedings of the Seventeenth conference on Uncertainty in artificial intelligence. Morgan Kaufmann Publishers Inc., 580--588.Google Scholar""]"
https://doi.org/10.1145/3394486.3403079,TranSlider: Transfer Ensemble Learning from Exploitation to Exploration,"In transfer learning, what and where to transfer has been widely studied. Nevertheless, the learned transfer strategies are at high risk of over-fitting, especially when only a few annotated instances are available in the target domain. In this paper, we introduce the concept of transfer ensemble learning, a new direction to tackle the over-fitting of transfer strategies. Intuitively, models with different transfer strategies offer various perspectives on what and where to transfer. Therefore a core problem is to search these diversely transferred models for ensemble so as to achieve better generalization. Towards this end, we propose the Transferability Slider (TranSlider) for transfer ensemble learning. By decreasing the transferability, we obtain a spectrum of base models ranging from pure exploitation of the source model to unconstrained exploration for the target domain. Furthermore, the manner of decreasing transferability with parameter sharing guarantees fast optimization at no additional training cost. Finally, we conduct extensive experiments with various analyses, which demonstrate that TranSlider achieves the state-of-the-art on comprehensive benchmark datasets.","[{""name"":""Kuo Zhong"",""id"":""/profile/99659574406""},{""name"":""Ying Wei"",""id"":""/profile/99659370054""},{""name"":""Chun Yuan"",""id"":""/profile/81100116471""},{""name"":""Haoli Bai"",""id"":""/profile/99659316710""},{""name"":""Junzhou Huang"",""id"":""/profile/99659260108""},{""name"":""Kuo Zhong"",""id"":""/profile/99659574406""},{""name"":""Ying Wei"",""id"":""/profile/99659370054""},{""name"":""Chun Yuan"",""id"":""/profile/81100116471""},{""name"":""Haoli Bai"",""id"":""/profile/99659316710""},{""name"":""Junzhou Huang"",""id"":""/profile/99659260108""}]","[""Firoj Alam, Shafiq Joty, and Muhammad Imran. 2018. Domain Adaptation with Adversarial Training and Graph Embeddings. In ACL. 1077--1087.Google Scholar"",""Antreas Antoniou, Harrison Edwards, and Amos Storkey. 2018. How to train your MAML. In ICLR.Google Scholar"",""Leo Breiman. 1996. Bagging predictors. Machine learning, Vol. 24, 2 (1996), 123--140.Google Scholar"",""Rich Caruana, Alexandru Niculescu-Mizil, Geoff Crew, and Alex Ksikes. 2004. Ensemble selection from libraries of models. In ICML. 18.Google Scholar"",""Thomas G Dietterich. 2000. Ensemble methods in machine learning. In International workshop on multiple classifier systems. Springer, 1--15.Google ScholarDigital Library"",""Zi-Yi Dou, Junjie Hu, Antonios Anastasopoulos, and Graham Neubig. 2019 a. Unsupervised Domain Adaptation for Neural Machine Translation with Domain-Aware Feature Embeddings. In EMNLP. 1417--1422.Google Scholar"",""Zi-Yi Dou, Keyi Yu, and Antonios Anastasopoulos. 2019 b. Investigating Meta-Learning Algorithms for Low-Resource Natural Language Understanding Tasks. In EMNLP. 1192--1197.Google Scholar"",""Mathias Eitz, James Hays, and Marc Alexa. 2012. How Do Humans Sketch Objects? ACM Trans. Graph. (Proc. SIGGRAPH), Vol. 31, 4 (2012), 44:1--44:10.Google ScholarDigital Library"",""Tommaso Furlanello, Zachary Lipton, Michael Tschannen, Laurent Itti, and Anima Anandkumar. 2018. Born Again Neural Networks. In ICML. 1607--1616.Google Scholar"",""AD. Perona P Griffin, G. Holub. 2007. The Caltech 256. (2007).Google Scholar"",""Yunhui Guo, Honghui Shi, Abhishek Kumar, Kristen Grauman, Tajana Rosing, and Rogerio Feris. 2019. SpotTune: transfer learning through adaptive fine-tuning. In CVPR. 4805--4814.Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In CVPR. 770--778.Google Scholar"",""Byeongho Heo, Minsik Lee, Sangdoo Yun, and Jin Young Choi. 2019. Knowledge Transfer via Distillation of Activation Boundaries Formed by Hidden Neurons. In AAAI, Vol. 33. 3779--3787.Google ScholarCross Ref"",""Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531 (2015).Google Scholar"",""Gao Huang, Yixuan Li, Geoff Pleiss, Zhuang Liu, John E Hopcroft, and Kilian Q Weinberger. 2017. Snapshot ensembles: Train 1, get m for free. In ICLR.Google Scholar"",""Yunhun Jang, Hankook Lee, Sung Ju Hwang, and Jinwoo Shin. 2019. Learning What and Where to Transfer. In ICML. 3030--3039.Google Scholar"",""Aditya Khosla, Nityananda Jayadevaprakash, Bangpeng Yao, and Li Fei-Fei. 2011. Novel Dataset for Fine-Grained Image Categorization. In First Workshop on Fine-Grained Visual Categorization, CVPR.Google Scholar"",""Sasi Kiran Yelamarthi, Shiva Krishna Reddy, Ashish Mishra, and Anurag Mittal. 2018. A zero-shot framework for sketch based image retrieval. In ECCV. 300--317.Google Scholar"",""Alex Krizhevsky. 2014. One weird trick for parallelizing convolutional neural networks. arXiv preprint arXiv:1404.5997 (2014).Google Scholar"",""Alex Krizhevsky, Geoffrey Hinton, et al. 2009. Learning multiple layers of features from tiny images. (2009).Google Scholar"",""Xuhong Li, Yves Grandvalet, and Franck Davoine. 2018. Explicit inductive bias for transfer learning with convolutional networks. In ICML. 2825--2834.Google Scholar"",""Xingjian Li, Haoyi Xiong, Hanchao Wang, Yuxuan Rao, Liping Liu, and Jun Huan. 2019. DELTA: DEep Learning Transfer using Feature Map with Attention for Convolutional Networks. In ICLR.Google Scholar"",""Hong Liu, Mingsheng Long, Jianmin Wang, and Michael I Jordan. 2019. Towards Understanding the Transferability of Deep Representations. arXiv preprint arXiv:1909.12031 (2019).Google Scholar"",""Ilya Loshchilov and Frank Hutter. 2016. Sgdr: Stochastic gradient descent with warm restarts. In ICLR.Google Scholar"",""David JC MacKay. 1992. A practical Bayesian framework for backpropagation networks. Neural computation, Vol. 4, 3 (1992), 448--472.Google Scholar"",""Ishan Misra, Abhinav Shrivastava, Abhinav Gupta, and Martial Hebert. 2016. Cross-Stitch Networks for Multi-Task Learning. In CVPR. 3994--4003.Google Scholar"",""Pramod Kaushik Mudrakarta, Mark Sandler, Andrey Zhmoginov, and Andrew Howard. 2018. K for the Price of 1: Parameter-efficient Multi-task and Transfer Learning. In ICLR.Google Scholar"",""Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. 2011. Reading digits in natural images with unsupervised feature learning. (2011).Google Scholar"",""Sinno Jialin Pan and Qiang Yang. 2009. A survey on transfer learning. IEEE Transactions on knowledge and data engineering, Vol. 22, 10 (2009), 1345--1359.Google ScholarDigital Library"",""Hanyu Peng, Jiaxiang Wu, Shifeng Chen, and Junzhou Huang. 2019. Collaborative channel pruning for deep networks. In ICML. 5113--5122.Google Scholar"",""Ariadna Quattoni and Antonio Torralba. 2009. Recognizing indoor scenes. In CVPR. 413--420.Google Scholar"",""Adriana Romero, Nicolas Ballas, Samira Ebrahimi Kahou, Antoine Chassang, Carlo Gatta, and Yoshua Bengio. 2015. Fitnets: Hints for thin deep nets. In ICLR.Google Scholar"",""Sebastian Ruder12, Joachim Bingel, Isabelle Augenstein, and Anders Søgaard. 2017. Sluice networks: Learning what to share between loosely related tasks. STAT, Vol. 1050 (2017), 23.Google Scholar"",""Ali Sharif Razavian, Hossein Azizpour, Josephine Sullivan, and Stefan Carlsson. 2014. CNN features off-the-shelf: an astounding baseline for recognition. In CVPR. 806--813.Google Scholar"",""Suraj Srinivas and Francois Fleuret. 2018. Knowledge Transfer with Jacobian Matching. In ICML. 4723--4731.Google Scholar"",""C. Wah, S. Branson, P. Welinder, P. Perona, and S. Belongie. 2011. The Caltech-UCSD Birds-200--2011 Dataset. Technical Report CNS-TR-2011-001. California Institute of Technology.Google Scholar"",""Chenglin Yang, Lingxi Xie, Chi Su, and Alan L Yuille. 2019. Snapshot distillation: Teacher-student optimization in one generation. In CVPR. 2859--2868.Google Scholar"",""Junho Yim, Donggyu Joo, Jihoon Bae, and Junmo Kim. 2017. A gift from knowledge distillation: Fast optimization, network minimization and transfer learning. In CVPR. 4133--4141.Google Scholar"",""Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson. 2014. How transferable are features in deep neural networks?. In NeurIPS. 3320--3328.Google Scholar"",""Sergey Zagoruyko and Nikos Komodakis. 2016. Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer. In ICLR.Google Scholar"",""Yinghua Zhang, Yu Zhang, and Qiang Yang. 2019. Parameter Transfer Unit for Deep Neural Networks. In PAKDD. 82--95.Google Scholar"",""Bolei Zhou, Agata Lapedriza, Aditya Khosla, Aude Oliva, and Antonio Torralba. 2017. Places: A 10 million image database for scene recognition. IEEE transactions on pattern analysis and machine intelligence, Vol. 40, 6 (2017), 1452--1464.Google Scholar""]"
https://doi.org/10.1145/3394486.3403080,InFoRM: Individual Fairness on Graph Mining,"Algorithmic bias and fairness in the context of graph mining have largely remained nascent. The sparse literature on fair graph mining has almost exclusively focused on group-based fairness notation. However, the notion of individual fairness, which promises the fairness notion at a much finer granularity, has not been well studied. This paper presents the first principled study of Individual Fairness on gRaph Mining (InFoRM). First, we present a generic definition of individual fairness for graph mining which naturally leads to a quantitative measure of the potential bias in graph mining results. Second, we propose three mutually complementary algorithmic frameworks to mitigate the proposed individual bias measure, namely debiasing the input graph, debiasing the mining model and debiasing the mining results. Each algorithmic framework is formulated from the optimization perspective, using effective and efficient solvers, which are applicable to multiple graph mining tasks. Third, accommodating individual fairness is likely to change the original graph mining results without the fairness consideration. We conduct a thorough analysis to develop an upper bound to characterize the cost (i.e., the difference between the graph mining results with and without the fairness consideration). We perform extensive experimental evaluations on real-world datasets to demonstrate the efficacy and generality of the proposed methods.","[{""name"":""Jian Kang"",""id"":""/profile/99659479568""},{""name"":""Jingrui He"",""id"":""/profile/81540269856""},{""name"":""Ross Maciejewski"",""id"":""/profile/81363590851""},{""name"":""Hanghang Tong"",""id"":""/profile/81337494052""},{""name"":""Jian Kang"",""id"":""/profile/99659479568""},{""name"":""Jingrui He"",""id"":""/profile/81540269856""},{""name"":""Ross Maciejewski"",""id"":""/profile/81363590851""},{""name"":""Hanghang Tong"",""id"":""/profile/81337494052""}]","[""Punam Bedi and Chhavi Sharma. 2016. Community detection in social networks. WIREs DMKD (2016).Google Scholar"",""Asia J Biega, Krishna P Gummadi, and Gerhard Weikum. 2018. Equity of attention: Amortizing individual fairness in rankings. In SIGIR. 405--414.Google Scholar"",""Avishek Joey Bose and William L. Hamilton. 2019. Compositional Fairness Constraints for Graph Embeddings. In ICML.Google Scholar"",""Flavio Chierichetti, Ravi Kumar, Silvio Lattanzi, and Sergei Vassilvitskii. 2017. Fair clustering through fairlets. In NIPS. 5029--5037.Google Scholar"",""Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. 2012. Fairness through awareness. In ITCS. 214--226.Google Scholar"",""Michael Feldman, Sorelle A Friedler, John Moeller, Carlos Scheidegger, and Suresh Venkatasubramanian. 2015. Certifying and removing disparate impact. In KDD.Google Scholar"",""Gene H. Golub and Charles F. Van Loan. 1996. Matrix Computations third ed.). The Johns Hopkins University Press.Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In KDD. 855--864.Google Scholar"",""Moritz Hardt, Eric Price, Nati Srebro, et al. 2016. Equality of opportunity in supervised learning. In NIPS. 3315--3323.Google Scholar"",""Glen Jeh and Jennifer Widom. 2002. SimRank: a measure of structural-context similarity. In KDD. 538--543.Google Scholar"",""Toshihiro Kamishima, Shotaro Akaho, Hideki Asoh, and Jun Sakuma. 2012. Enhancement of the Neutrality in Recommendation.Google Scholar"",""Jian Kang and Hanghang Tong. 2019. N2N: Network Derivative Mining. In CIKM. 861--870.Google Scholar"",""Jian Kang, Meijia Wang, Nan Cao, Yinglong Xia, Wei Fan, and Hanghang Tong. 2018. AURORA: Auditing PageRank on Large Graphs. In Big Data. 713--722.Google Scholar"",""Michael Kim, Omer Reingold, and Guy Rothblum. 2018. Fairness through computationally-bounded awareness. In NeurIPS. 4842--4852.Google Scholar"",""Matthaus Kleindessner, Samira Samadi, Pranjal Awasthi, and Jamie Morgenstern. 2019. Guarantees for Spectral Clustering with Fairness Constraints. In ICML.Google Scholar"",""Danai Koutra, Ankur Parikh, Aaditya Ramdas, and Jing Xiang. 2011. Algorithms for graph similarity and subgraph matching.Google Scholar"",""Preethi Lahoti, Krishna P Gummadi, and Gerhard Weikum. 2019. Operationalizing Individual Fairness with Pairwise Fair Representations. PVLDB (2019).Google Scholar"",""Jure Leskovec and Andrej Krevl. 2014. SNAP Datasets: Stanford Large Network Dataset Collection. http://snap.stanford.edu/data.Google Scholar"",""Shike Mei and Xiaojin Zhu. 2015. Using machine teaching to identify optimal training-set attacks on machine learners. In AAAI.Google Scholar"",""Andrew Y Ng, Michael I Jordan, and Yair Weiss. 2002. On spectral clustering: Analysis and an algorithm. In NIPS. 849--856.Google Scholar"",""Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. 1999. The PageRank citation ranking: Bringing order to the web. Technical Report. Stanford InfoLab.Google Scholar"",""John Palowitch and Bryan Perozzi. 2019. MONET: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit. arXiv preprint arXiv:1909.11793 (2019).Google Scholar"",""Jiezhong Qiu, Yuxiao Dong, Hao Ma, Jian Li, Kuansan Wang, and Jie Tang. 2018. Network embedding as matrix factorization: Unifying deepwalk, line, pte, and node2vec. In WSDM. 459--467.Google Scholar"",""Tahleen Rahman, Bartlomiej Surma, Michael Backes, and Yang Zhang. 2019. Fairwalk: Towards Fair Graph Embedding. In IJCAI.Google Scholar"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. In WWW. 1067--1077.Google ScholarDigital Library"",""Sahil Verma and Julia Rubin. 2018. Fairness definitions explained. In FairWare.Google Scholar"",""S Vichy N Vishwanathan, Nicol N Schraudolph, Risi Kondor, and Karsten M Borgwardt. 2010. Graph kernels. JMLR, Vol. 11, Apr (2010), 1201--1242.Google Scholar"",""Fei Wang, Tao Li, and Changshui Zhang. 2008. Semi-Supervised Clustering via Matrix Factorization. In SDM.Google Scholar"",""Jianshu Weng, Ee-Peng Lim, Jing Jiang, and Qi He. 2010. Twitterrank: finding topic-sensitive influential twitterers. In WSDM. ACM, 261--270.Google Scholar"",""Yongkai Wu, Lu Zhang, Xintao Wu, and Hanghang Tong. 2019. PC-Fairness: A Unified Framework for Measuring Causality-Based Fairness. In NeurIPS.Google Scholar"",""Sirui Yao and Bert Huang. 2017. Beyond parity: Fairness objectives for collaborative filtering. In NIPS. 2921--2930.Google Scholar"",""Yuan Yao, Hanghang Tong, Guo Yan, Feng Xu, Xiang Zhang, Boleslaw K Szymanski, and Jian Lu. 2014. Dual-regularized one-class collaborative filtering. In CIKM.Google Scholar"",""Gal Yona and Guy N. Rothblum. 2018. Probably Approximately Metric-Fair Learning. In ICML. 5666--5674.Google Scholar"",""Rich Zemel, Yu Wu, Kevin Swersky, Toni Pitassi, and Cynthia Dwork. 2013. Learning fair representations. In ICML. 325--333.Google Scholar"",""Rui Zhang and Hanghang Tong. 2019. Robust Principal Component Analysis with Adaptive Neighbors. In NeurIPS. 6959--6967.Google Scholar"",""Si Zhang, Hanghang Tong, Jiejun Xu, and Ross Maciejewski. 2019. Graph convolutional networks: a comprehensive review. Computational Social Networks (2019).Google Scholar"",""Dawei Zhou, Jingrui He, Hongxia Yang, and Wei Fan. 2018. Sparc: Self-paced network representation for few-shot rare category characterization. In KDD.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403081,Local Motif Clustering on Time-Evolving Graphs,"Graph motifs are subgraph patterns that occur in complex networks, which are of key importance for gaining deep insights into the structure and functionality of the graph. Motif clustering aims at finding clusters consisting of dense motif patterns. It is commonly used in various application domains, ranging from social networks to collaboration networks, from market-basket analysis to neuroscience applications. More recently, local clustering techniques have been proposed for motif-aware clustering, which focuses on a small neighborhood of the input seed node instead of the entire graph. However, most of these techniques are designed for static graphs and may render sub-optimal results when applied to large time-evolving graphs. To bridge this gap, in this paper, we propose a novel framework, Local Motif Clustering on Time-Evolving Graphs (L-MEGA), which provides the evolution pattern of the local motif cluster in an effective and efficient way. The core of L-MEGA is approximately tracking the temporal evolution of the local motif cluster via novel techniques such as edge filtering, motif push operation, and incremental sweep cut. Furthermore, we theoretically analyze the efficiency and effectiveness of these techniques on time-evolving graphs. Finally, we evaluate the L-MEGA framework via extensive experiments on both synthetic and real-world temporal networks.","[{""name"":""Dongqi Fu"",""id"":""/profile/99659574008""},{""name"":""Dawei Zhou"",""id"":""/profile/99658744761""},{""name"":""Jingrui He"",""id"":""/profile/81540269856""},{""name"":""Dongqi Fu"",""id"":""/profile/99659574008""},{""name"":""Dawei Zhou"",""id"":""/profile/99658744761""},{""name"":""Jingrui He"",""id"":""/profile/81540269856""}]","[""Reid Andersen, Fan R. K. Chung, and Kevin J. Lang. 2006. Local Graph Partitioning using PageRank Vectors. In IEEE FOCS 2006.Google Scholar"",""Ana Paula Appel, Renato Luiz de Freitas Cunha, Charu C. Aggarwal, and Marcela Megumi Terakado. 2018. Temporally Evolving Community Detection and Prediction in Content-Centric Networks. In ECML PKDD 2018.Google Scholar"",""Yikun Ban, Xin Liu, Ling Huang, Yitao Duan, Xue Liu, and Wei Xu. 2019. No Place to Hide: Catching Fraudulent Entities in Tensors. In WWW 2019.Google Scholar"",""Austin R. Benson, David F. Gleich, and Jure Leskovec. 2015. Tensor Spectral Clustering for Partitioning Higher-order Network Structures. In SIAM SDM 2015.Google Scholar"",""Austin R. Benson, David F. Gleich, and Jure Leskovec. 2016. Higher-order organization of complex networks. Science (2016).Google Scholar"",""Austin R. Benson, David F. Gleich, and Lek-Heng Lim. 2017. The Spacey Random Walk: A Stochastic Process for Higher-Order Data. SIAM Rev. (2017).Google Scholar"",""Deepayan Chakrabarti, Ravi Kumar, and Andrew Tomkins. 2006. Evolutionary Clustering. In ACM SIGKDD 2006.Google Scholar"",""Edsger W. Dijkstra. 1959. A Note on Two Problems in Connexion with Graphs. Numerische mathematik (1959).Google Scholar"",""Nurcan Durak, Ali Pinar, Tamara G. Kolda, and C. Seshadhri. 2012. Degree Relations of Triangles in Real-world Networks and Graph Models. In ACM CIKM 2012.Google Scholar"",""David F. Gleich, Lek-Heng Lim, and Yongyang Yu. 2015. Multilinear PageRank. SIAM J. Matrix Anal. Appl. (2015).Google Scholar"",""Mark S. Granovetter. 1973. The Strength of Weak Ties. Amer. J. Sociology (1973).Google Scholar"",""Chris Jay Hoofnagle. 2007. Identity theft: Making the known unknowns known. Harv. JL \u0026 Tech. (2007).Google Scholar"",""Brian Kulis, Sugato Basu, Inderjit S. Dhillon, and Raymond J. Mooney. 2005. Semi-supervised Graph Clustering: A Kernel Approach. In ICML 2005.Google Scholar"",""Srijan Kumar, Bryan Hooi, Disha Makhija, Mohit Kumar, Christos Faloutsos, and V. S. Subrahmanian. 2018. REV2: Fraudulent User Prediction in Rating Platforms. In ACM WSDM 2018.Google Scholar"",""Srijan Kumar, Francesca Spezzano, V. S. Subrahmanian, and Christos Faloutsos. 2016. Edge Weight Prediction in Weighted Signed Networks. In IEEE ICDM 2016.Google Scholar"",""Wen Li and Michael K. Ng. 2014. On the limiting probability distribution of a transition probability tensor. Linear and Multilinear Algebra (2014).Google Scholar"",""Xu Liu, Jingrui He, Sam Duddy, and Liz O'Sullivan. 2019. Convolution-Consistent Collective Matrix Completion. In ACM CIKM 2019.Google Scholar"",""Ron Milo, Shai Shen-Orr, Shalev Itzkovitz, Nadav Kashtan, Dmitri Chklovskii, and Uri Alon. 2002. Network motifs: simple building blocks of complex networks. Science (2002).Google Scholar"",""Andrew Y. Ng, Michael I. Jordan, and Yair Weiss. 2001. On Spectral Clustering: Analysis and an algorithm. In NeurIPS 2001.Google Scholar"",""Huazhong Ning, Wei Xu, Yun Chi, Yihong Gong, and Thomas S. Huang. 2010. Incremental Spectral Clustering by Efficiently Updating the Eigen-System. Pattern Recognition (2010).Google Scholar"",""Naoto Ohsaka, Takanori Maehara, and Ken-ichi Kawarabayashi. 2015. Efficient PageRank Tracking in Evolving Networks. In ACM SIGKDD 2015.Google Scholar"",""Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. 1999. The PageRank Citation Ranking: Bringing Order to the Web. Technical Report.Google Scholar"",""Ashwin Paranjape, Austin R. Benson, and Jure Leskovec. 2017. Motifs in Temporal Networks. In ACM WSDM 2017.Google Scholar"",""Arnau Prat-Pérez, David Dominguez-Sal, Josep M Brunat, and Josep-Lluis Larriba-Pey. 2012. Shaping Communities out of Triangles. In ACM CIKM 2012.Google ScholarDigital Library"",""Ryan A. Rossi and Nesreen K. Ahmed. 2015. The Network Data Repository with Interactive Graph Analytics and Visualization. In AAAI 2015.Google Scholar"",""Martin Rosvall, Alcides Viamontes Esquivel, Andrea Lancichinetti, Jevin West, and Renaud Lambiotte. 2014. Memory in network flows and its effects on spreading dynamics and community detection. Nature communications (2014).Google Scholar"",""Jir'i S'i ma and Satu Elisa Schaeffer. 2006. On the NP-Completeness of Some Graph Cluster Measures. In SOFSEM 2006.Google Scholar"",""Daniel A. Spielman and Shang-Hua Teng. 2013. A Local Clustering Algorithm for Massive Graphs and Its Application to Nearly Linear Time Graph Partitioning. SIAM J. Comput. (2013).Google Scholar"",""Jimeng Sun, Christos Faloutsos, Spiros Papadimitriou, and Philip S. Yu. 2007. GraphScope: Parameter-free Mining of Large Time-evolving Graphs. In ACM SIGKDD 2007.Google Scholar"",""Hanghang Tong, Spiros Papadimitriou, Philip S. Yu, and Christos Faloutsos. 2008. Proximity Tracking on Time-Evolving Bipartite Graphs. In SIAM SDM 2008.Google Scholar"",""Konstantin Voevodski, Shang-Hua Teng, and Yu Xia. 2009. Spectral affinity in protein networks. BMC Systems Biology (2009).Google Scholar"",""Tao Wu, Austin R. Benson, and David F. Gleich. 2016. General Tensor Spectral Co-clustering for Higher-Order Data. In NeurIPS 2016.Google Scholar"",""Hao Yin, Austin R. Benson, Jure Leskovec, and David F. Gleich. 2017. Local Higher-Order Graph Clustering. In ACM SIGKDD 2017.Google Scholar"",""Hongyang Zhang, Peter Lofgren, and Ashish Goel. 2016. Approximate Personalized PageRank on Dynamic Graphs. In ACM SIGKDD 2016.Google Scholar"",""Dawei Zhou, Jingrui He, Hasan Davulcu, and Ross Maciejewski. 2018. Motif-Preserving Dynamic Local Graph Cut. In IEEE Big Data 2018.Google Scholar"",""Dawei Zhou, Si Zhang, Mehmet Yigit Yildirim, Scott Alcorn, Hanghang Tong, Hasan Davulcu, and Jingrui He. 2017b. A Local Algorithm for Structure-Preserving Graph Cut. In ACM SIGKDD 2017.Google ScholarDigital Library"",""Yao Zhou and Jingrui He. 2017. A Randomized Approach for Crowdsourcing in the Presence of Multiple Views. In IEEE ICDM 2017.Google ScholarCross Ref"",""Yao Zhou, Lei Ying, and Jingrui He. 2017a. MultiC(2): an Optimization Framework for Learning from Task and Worker Dual Heterogeneity. In SIAM SDM 2017.Google Scholar""]"
https://doi.org/10.1145/3394486.3403082,A Data-Driven Graph Generative Model for Temporal Interaction Networks,"Deep graph generative models have recently received a surge of attention due to its superiority of modeling realistic graphs in a variety of domains, including biology, chemistry, and social science. Despite the initial success, most, if not all, of the existing works are designed for static networks. Nonetheless, many realistic networks are intrinsically dynamic and presented as a collection of system logs (i.e., timestamped interactions/edges between entities), which pose a new research direction for us: how can we synthesize realistic dynamic networks by directly learning from the system logs? In addition, how can we ensure the generated graphs preserve both the structural and temporal characteristics of the real data?To address these challenges, we propose an end-to-end deep generative framework named TagGen. In particular, we start with a novel sampling strategy for jointly extracting structural and temporal context information from temporal networks. On top of that, TagGen parameterizes a bi-level self-attention mechanism together with a family of local operations to generate temporal random walks. At last, a discriminator gradually selects generated temporal random walks, that are plausible in the input data, and feeds them to an assembling module for generating temporal networks. The experimental results in seven real-world data sets across a variety of metrics demonstrate that (1) TagGen outperforms all baselines in the temporal interaction network generation problem, and (2) TagGen significantly boosts the performance of the prediction models in the tasks of anomaly detection and link prediction.","[{""name"":""Dawei Zhou"",""id"":""/profile/99658744761""},{""name"":""Lecheng Zheng"",""id"":""/profile/99659534965""},{""name"":""Jiawei Han"",""id"":""/profile/81548005096""},{""name"":""Jingrui He"",""id"":""/profile/81540269856""},{""name"":""Dawei Zhou"",""id"":""/profile/99658744761""},{""name"":""Lecheng Zheng"",""id"":""/profile/99659534965""},{""name"":""Jiawei Han"",""id"":""/profile/81548005096""},{""name"":""Jingrui He"",""id"":""/profile/81540269856""}]","[""Steven P. Abney. 2002. Bootstrapping. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics.Google Scholar"",""Leman Akoglu and Christos Faloutsos. 2009. RTG: a recursive realistic graph generator using random typing. Data Min. Knowl. Discov.Google Scholar"",""Ré ka Albert and Albert-Lá szló Barabá si. 2001. Statistical mechanics of complex networks. CoRR, Vol. cond-mat/0106096 (2001).Google Scholar"",""Yikun Ban, Xin Liu, Ling Huang, Yitao Duan, Xue Liu, and Wei Xu. 2019. No Place to Hide: Catching Fraudulent Entities in Tensors. In The World Wide Web Conference.Google Scholar"",""Aleksandar Bojchevski, Oleksandr Shchur, Daniel Zü gner, and Stephan Gü nnemann. 2018. NetGAN: Generating Graphs via Random Walks. In Proceedings of the 35th International Conference on Machine Learning.Google Scholar"",""Lé on Bottou. 2010. Large-Scale Machine Learning with Stochastic Gradient Descent. In 19th International Conference on Computational Statistics, COMPSTAT.Google Scholar"",""Dean V Buonomano and Michael M Merzenich. 1995. Temporal Information Transformed into a Spatial Code by a Neural Network with Realistic Properties. Science (1995).Google Scholar"",""Deepayan Chakrabarti, Yiping Zhan, and Christos Faloutsos. 2004. R-MAT: A Recursive Model for Graph Mining. In Proceedings of the Fourth SIAM International Conference on Data Mining.Google ScholarCross Ref"",""Paul Erdös and Alfréd Rényi. 1959. On random graphs, I. Publicationes Mathematicae (Debrecen) (1959).Google Scholar"",""Frank Fischer and Christoph Helmberg. 2014. Dynamic graph generation for the shortest path problem in time expanded networks. Math. Program. (2014).Google Scholar"",""Anna Goldenberg, Alice X. Zheng, Stephen E. Fienberg, and Edoardo M. Airoldi. 2009. A Survey of Statistical Network Models. Foundations and Trends in Machine Learning (2009).Google Scholar"",""Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron C. Courville, and Yoshua Bengio. 2014. Generative Adversarial Nets. In Advances in Neural Information Processing Systems.Google Scholar"",""Palash Goyal, Sujit Rokka Chhetri, and Arquimedes Canedo. 2020. dyngraph2vec: Capturing network dynamics using dynamic graph representation learning.Google Scholar"",""Carsten Grabow, Stefan Grosskinsky, Jü rgen Kurths, and Marc Timme. 2015. Collective Relaxation Dynamics of Small-World Networks. CoRR, Vol. abs/1507.04624 (2015). arxiv: 1507.04624Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable Feature Learning for Networks. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.Google ScholarDigital Library"",""Jian Kang and Hanghang Tong. 2019. N2N: Network Derivative Mining. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management.Google ScholarDigital Library"",""Diederik P. Kingma and Max Welling. 2014. Auto-Encoding Variational Bayes. (2014).Google Scholar"",""Thomas N. Kipf and Max Welling. 2016. Variational Graph Auto-Encoders. CoRR, Vol. abs/1611.07308 (2016). arxiv: 1611.07308Google Scholar"",""Jon M. Kleinberg, Ravi Kumar, Prabhakar Raghavan, Sridhar Rajagopalan, and Andrew Tomkins. 1999. The Web as a Graph: Measurements, Models, and Methods. In 5th Annual International Conference of Computing and Combinatorics.Google ScholarCross Ref"",""Srijan Kumar, Francesca Spezzano, V. S. Subrahmanian, and Christos Faloutsos. 2016. Edge Weight Prediction in Weighted Signed Networks. In IEEE 16th International Conference on Data Mining.Google Scholar"",""Srijan Kumar, Xikun Zhang, and Jure Leskovec. 2019. Predicting Dynamic Embedding Trajectory in Temporal Interaction Networks. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.Google ScholarDigital Library"",""Jure Leskovec, Deepayan Chakrabarti, Jon M. Kleinberg, Christos Faloutsos, and Zoubin Ghahramani. 2010. Kronecker Graphs: An Approach to Modeling Networks. J. Mach. Learn. Res. (2010).Google Scholar"",""Jure Leskovec and Andrej Krevl. 2015. $$SNAP Datasets$$:$$Stanford$$ Large Network Dataset Collection. (2015).Google Scholar"",""Taisong Li, Jiawei Zhang, Philip S. Yu, Yan Zhang, and Yonghong Yan. 2018. Deep Dynamic Network Embedding for Link Prediction. IEEE Access (2018).Google Scholar"",""Xu Liu, Jingrui He, Sam Duddy, and Liz O'Sullivan. 2019 a. Convolution-Consistent Collective Matrix Completion. In International Conference on Information and Knowledge Management.Google Scholar"",""Zhining Liu, Dawei Zhou, and Jingrui He. 2019 b. Towards Explainable Representation of Time-Evolving Graphs via Spatial-Temporal Graph Attention Networks. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management.Google ScholarDigital Library"",""Giang Hoang Nguyen, John Boaz Lee, Ryan A. Rossi, Nesreen K. Ahmed, Eunyee Koh, and Sungchul Kim. 2018. Continuous-Time Dynamic Network Embeddings. In Companion of the The Web Conference 2018 on The Web Conference 2018.Google Scholar"",""Pietro Panzarasa, Tore Opsahl, and Kathleen M. Carley. 2009. Patterns and dynamics of users' behavior and interaction: Network analysis of an online community. J. Assoc. Inf. Sci. Technol. (2009).Google Scholar"",""Ashwin Paranjape, Austin R. Benson, and Jure Leskovec. 2017. Motifs in Temporal Networks. In Proceedings of the Tenth ACM International Conference on Web Search and Data Mining.Google ScholarDigital Library"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. DeepWalk: online learning of social representations. In The 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.Google ScholarDigital Library"",""Sumit Purohit, Lawrence B Holder, and George Chin. 2018. Temporal Graph Generation Based on a Distribution of Temporal Motifs. In Proceedings of the 14th International Workshop on Mining and Learning with Graphs.Google Scholar"",""Garry Robins, Pip Pattison, Yuval Kalish, and Dean Lusher. 2007. An introduction to exponential random graph (p(^* )) models for social networks. Soc. Networks (2007).Google Scholar"",""Huajie Shao, Dachun Sun, Jiahao Wu, Zecheng Zhang, Aston Zhang, Shuochao Yao, Shengzhong Liu, Tianshi Wang, Chao Zhang, and Tarek F. Abdelzaher. 2020. paper2repo: GitHub Repository Recommendation for Academic Papers. In The Web Conference.Google Scholar"",""Huajie Shao, Shuochao Yao, Yiran Zhao, Chao Zhang, Jinda Han, Lance M. Kaplan, Lu Su, and Tarek F. Abdelzaher. 2018. A Constrained Maximum Likelihood Estimator for Unguided Social Sensing. In IEEE Conference on Computer Communications.Google Scholar"",""George R Terrell and David W Scott. 1992. Variable Kernel Density Estimation. The Annals of Statistics (1992).Google Scholar"",""Hanghang Tong, Spiros Papadimitriou, Philip S. Yu, and Christos Faloutsos. 2008. Proximity Tracking on Time-Evolving Bipartite Graphs. In Proceedings of the SIAM International Conference on Data Mining.Google ScholarCross Ref"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In Advances in Neural Information Processing Systems.Google Scholar"",""Bernard M. Waxman. 1988. Routing of multipoint connections. IEEE J. Sel. Areas Commun. (1988).Google Scholar"",""Jiaxuan You, Bowen Liu, Zhitao Ying, Vijay S. Pande, and Jure Leskovec. 2018a. Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation. In Advances in Neural Information Processing Systems.Google Scholar"",""Jiaxuan You, Rex Ying, Xiang Ren, William L. Hamilton, and Jure Leskovec. 2018b. GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models. In Proceedings of the 35th International Conference on Machine Learning.Google Scholar"",""Bing Yu, Haoteng Yin, and Zhanxing Zhu. 2018. Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting. (2018).Google Scholar"",""Si Zhang, Dawei Zhou, Mehmet Yigit Yildirim, Scott Alcorn, Jingrui He, Hasan Davulcu, and Hanghang Tong. 2017. HiDDen: Hierarchical Dense Subgraph Detection with Application to Financial Fraud Detection. In Proceedings of the 2017 SIAM International Conference on Data Mining.Google ScholarCross Ref"",""Dawei Zhou, Jingrui He, Hongxia Yang, and Wei Fan. 2018. SPARC: Self-Paced Network Representation for Few-Shot Rare Category Characterization. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.Google ScholarDigital Library"",""Dawei Zhou, Kangyang Wang, Nan Cao, and Jingrui He. 2015. Rare Category Detection on Time-Evolving Graphs. In IEEE International Conference on Data Mining.Google Scholar"",""Yuan Zuo, Guannan Liu, Hao Lin, Jia Guo, Xiaoqian Hu, and Junjie Wu. 2018. Embedding Temporal Network via Neighborhood Formation. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403083,Recurrent Networks for Guided Multi-Attention Classification,"Attention-based image classification has gained increasing popularity in recent years. State-of-the-art methods for attention-based classification typically require a large training set and operate under the assumption that the label of an image depends solely on a single object (i.e. region of interest) in the image. However, in many real-world applications (e.g. medical imaging), it is very expensive to collect a large training set. Moreover, the label of each image is usually determined jointly by multiple regions of interest (ROIs). Fortunately, for such applications, it is often possible to collect the locations of the ROIs in each training image. In this paper, we study the problem of guided multi-attention classification, the goal of which is to achieve high accuracy under the dual constraints of (1) small sample size, and (2) multiple ROIs for each image. We propose a model, called Guided Attention Recurrent Network (GARN), for multi-attention classification. Different from existing attention-based methods, GARN utilizes guidance information regarding multiple ROIs thus allowing it to work well even when sample size is small. Empirical studies on three different visual tasks show that our guided attention approach can effectively boost model performance for multi-attention image classification.","[{""name"":""Xin Dai"",""id"":""/profile/99659574411""},{""name"":""Xiangnan Kong"",""id"":""/profile/81466643630""},{""name"":""Tian Guo"",""id"":""/profile/99659479290""},{""name"":""John Boaz Lee"",""id"":""/profile/99659259475""},{""name"":""Xinyue Liu"",""id"":""/profile/99659082393""},{""name"":""Constance Moore"",""id"":""/profile/99659573954""},{""name"":""Xin Dai"",""id"":""/profile/99659574411""},{""name"":""Xiangnan Kong"",""id"":""/profile/81466643630""},{""name"":""Tian Guo"",""id"":""/profile/99659479290""},{""name"":""John Boaz Lee"",""id"":""/profile/99659259475""},{""name"":""Xinyue Liu"",""id"":""/profile/99659082393""},{""name"":""Constance Moore"",""id"":""/profile/99659573954""}]","[""Bogdan Alexe, Thomas Deselaers, and Vittorio Ferrari. 2010. What is an object?. In Proc. 2010 IEEE Conf. Computer Vision and Pattern Recognition (CVPR'10). 73--80.Google Scholar"",""Bogdan Alexe, Nicolas Heess, Yee W Teh, and Vittorio Ferrari. 2012. Searching for objects driven by context. In Advances in Neural Information Processing Systems 25 (NeurIPS'12). 881--889.Google Scholar"",""Jimmy Ba, Volodymyr Mnih, and Koray Kavukcuoglu. 2015. Multiple object recognition with visual attention. Proc. 3rd Int. Conf. Learning Representations (ICLR'15).Google Scholar"",""Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural machine translation by jointly learning to align and translate. In Proc. 3rd Int. Conf. Learning Representations (ICLR'15).Google Scholar"",""Diangarti Bhalang Tarianga, Prithviraj Senguptab, Aniket Roy, Rajat Subhra Chakraborty, and Ruchira Naskar. 2019. Classification of Computer Generated and Natural Images based on Efficient Deep Convolutional Recurrent Attention Model. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops.Google Scholar"",""Tom Brosch, Roger Tam, Alzheimers Disease Neuroimaging Initiative, et al. 2013. Manifold learning of brain MRIs by deep learning. In Proc. 16th Int. Conf. Medical Image Computing and Computer-Assisted Intervention (MICCAI'13). 633--640.Google Scholar"",""Ed Bullmore and Olaf Sporns. 2009. Complex brain networks: graph theoretical analysis of structural and functional systems. Nature reviews neuroscience, Vol. 10, 3 (2009), 186--198.Google Scholar"",""Nicholas J Butko and Javier R Movellan. 2009. Optimal scanning for faster object detection. In Proc. 2009 IEEE Conf. Computer Vision and Pattern Recognition (CVPR'09). 2751--2758.Google Scholar"",""Misha Denil, Loris Bazzani, Hugo Larochelle, and Nando de Freitas. 2012. Learning where to attend with deep architectures for image tracking. Neural Computation, Vol. 24, 8 (2012), 2151--2184.Google Scholar"",""Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra Malik. 2014. Rich feature hierarchies for accurate object detection and semantic segmentation. In Proc. 2014 IEEE Conf. Computer Vision and Pattern Recognition (CVPR'14). 580--587.Google Scholar"",""Ian J Goodfellow, Yaroslav Bulatov, Julian Ibarz, Sacha Arnoud, and Vinay Shet. 2014. Multi-digit number recognition from street view imagery using deep convolutional neural networks. In Proc. 2nd Int. Conf. Learning Representations (ICLR'14).Google Scholar"",""Albert Haque, Alexandre Alahi, and Li Fei-Fei. 2016. Recurrent attention models for depth-based person identification. In Proc. 2016 IEEE Conf. Computer Vision and Pattern Recognition (CVPR'16). 1229--1238.Google Scholar"",""Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012. Imagenet classification with deep convolutional neural networks. In Advances in Neural Information Processing Systems 25 (NeurIPS'12). 1097--1105.Google Scholar"",""Hugo Larochelle and Geoffrey E Hinton. 2010. Learning to combine foveal glimpses with a third-order Boltzmann machine. In Advances in Neural Information Processing Systems 23 (NeurIPS'10). 1243--1251.Google Scholar"",""John Boaz Lee, Xiangnan Kong, Yihan Bao, and Constance Moore. 2017. Identifying Deep Contrasting Networks from Time Series Data: Application to Brain Network Analysis. In Proc. 17th SIAM Int. Conf. Data Mining (SDM'17). 543--551.Google Scholar"",""Jun Liu, Gang Wang, Ping Hu, Ling-Yu Duan, and Alex C Kot. 2017. Global context-aware attention LS™ networks for 3D action recognition. In Proc. 2017 IEEE Conf. Computer Vision and Pattern Recognition (CVPR'17).Google Scholar"",""Arthur Mensch, Gaël Varoquaux, and Bertrand Thirion. 2016. Compressed online dictionary learning for fast resting-state fMRI decomposition. In Proc. 13th IEEE Int. Symposium on Biomedical Imaging (ISBI'16). 1282--1285.Google Scholar"",""Simon Mezgec and Barbara Korouvsić Seljak. 2017. NutriNet: A Deep Learning Food and Drink Image Recognition System for Dietary Assessment. Nutrients, Vol. 9, 7 (2017), 657.Google Scholar"",""Volodymyr Mnih, Nicolas Heess, Alex Graves, and Koray Kavukcuoglu. 2014. Recurrent models of visual attention. In Advances in Neural Information Processing Systems 27 (NeurIPS'14). 2204--2212.Google Scholar"",""Dong Nie, Han Zhang, Ehsan Adeli, Luyan Liu, and Dinggang Shen. 2016. 3D deep learning for multi-modal imaging-guided survival time prediction of brain tumor patients. In Proc. 19th Int. Conf. Medical Image Computing and Computer-Assisted Intervention (MICCAI'16). 212--220.Google Scholar"",""Charlie Tang, Nitish Srivastava, and Russ R Salakhutdinov. 2014. Learning generative models with visual attention. Advances in Neural Information Processing Systems 27 (NeurIPS'14). 1808--1816.Google Scholar"",""Nathalie Tzourio-Mazoyer, Brigitte Landeau, Dimitri Papathanassiou, Fabrice Crivello, Olivier Etard, Nicolas Delcroix, Bernard Mazoyer, and Marc Joliot. 2002. Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain. Neuroimage, Vol. 15, 1 (2002), 273--289.Google Scholar"",""Ronald J Williams. 1992. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine Learning, Vol. 8 (1992), 229--256.Google Scholar"",""Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhudinov, Rich Zemel, and Yoshua Bengio. 2015. Show, attend and tell: Neural image caption generation with visual attention. In Proc. 32nd Int. Conf. Machine Learning (ICML'15). 2048--2057.Google Scholar"",""Jingyuan Zhang, Bokai Cao, Sihong Xie, Chun-Ta Lu, Philip S. Yu, and Ann B. Ragin. 2016. Identifying Connectivity Patterns for Brain Diseases via Multi-side-view Guided Deep Architectures. In Proc. 16th SIAM Int. Conf. Data Mining (SDM'16). 36--44.Google Scholar"",""Yudong Zhang, Zhengchao Dong, Preetha Phillips, Shuihua Wang, Genlin Ji, Jiquan Yang, and Ti-Fei Yuan. 2015. Detection of subjects and brain regions related to Alzheimer's disease using 3D MRI scans based on eigenbrain and machine learning. Frontiers in Computational Neuroscience, Vol. 9 (2015), 66.Google Scholar"",""Xin Zhao, Liufang Sang, Guiguang Ding, Jungong Han, Na Di, and Chenggang Yan. 2019. Recurrent attention model for pedestrian attribute recognition. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 9275--9282.Google Scholar"",""Luping Zhou, Lei Wang, Lingqiao Liu, Philip Ogunbona, and Dinggang Shen. 2013. Discriminative brain effective connectivity analysis for Alzheimer's disease: a kernel learning approach upon sparse Gaussian Bayesian network. In Proc. 2013 IEEE Conf. Computer Vision and Pattern Recognition (CVPR'13). 2243--2250.Google Scholar"",""Zhen Zhou, Yan Huang, Wei Wang, Liang Wang, and Tieniu Tan. 2017. See the forest for the trees: Joint spatial and temporal recurrent neural networks for video-based person re-identification. Proc. 2017 IEEE Conf. Computer Vision and Pattern Recognition (CVPR'17). 6776--6785.Google Scholar"",""Lei Zhu, Zijun Deng, Xiaowei Hu, Chi-Wing Fu, Xuemiao Xu, Jing Qin, and Pheng-Ann Heng. 2018. Bidirectional feature pyramid network with recurrent attention residual modules for shadow detection. In Proceedings of the European Conference on Computer Vision (ECCV). 121--136.Google Scholar""]"
https://doi.org/10.1145/3394486.3403084,Vulnerability vs. Reliability: Disentangled Adversarial Examples for Cross-Modal Learning,"The vulnerability of deep neural networks has gained a great upsurge of research attention, which engages well-designed examples through adding little perturbations to fool a well-performed network. Meanwhile, a progress has been made in leveraging adversarial examples to boost the robustness of deep cross-modal networks. However, for cross-modal learning, both the causes of adversarial examples and their latent advantages in learning cross-modal correlations are under-explored. In this paper, we propose novel Disentangled Adversarial examples for Cross-Modal learning, dubbed DACM. Specifically, we first divide cross-modal data into two aspects, namely modality-related component and modality-unrelated counterpart, and then learn to improve the reliability of network using the modality-related component. To achieve this goal, we apply the generation of adversarial perturbations to strengthen cross-modal correlations, wherein the modality-related component is acquired through gradually detaching the modality-unrelated component. Finally, the proposed DACM is employed to create modality-related examples towards the application of cross-modal hashing retrieval. Extensive experiments carried out on two cross-modal benchmarks show that the adversarial examples learned by DACM are efficient at fooling a target deep cross-modal hashing network. On the other hand, training this target model by merely leveraging our created modality-related examples in turn significantly promotes the robustness of this model itself.","[{""name"":""Chao Li"",""id"":""/profile/99659251726""},{""name"":""Haoteng Tang"",""id"":""/profile/99659574854""},{""name"":""Cheng Deng"",""id"":""/profile/81418593531""},{""name"":""Liang Zhan"",""id"":""/profile/99659192991""},{""name"":""Wei Liu"",""id"":""/profile/81375601156""},{""name"":""Chao Li"",""id"":""/profile/99659251726""},{""name"":""Haoteng Tang"",""id"":""/profile/99659574854""},{""name"":""Cheng Deng"",""id"":""/profile/81418593531""},{""name"":""Liang Zhan"",""id"":""/profile/99659192991""},{""name"":""Wei Liu"",""id"":""/profile/81375601156""}]","[""Mart'in Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al. 2016. Tensorflow: A system for large-scale machine learning. In OSDI. 265--283.Google Scholar"",""Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C Lawrence Zitnick, and Devi Parikh. 2015. Vqa: Visual question answering. In ICCV. 2425--2433.Google Scholar"",""Juan C Caicedo and Svetlana Lazebnik. 2015. Active object localization with deep reinforcement learning. In CVPR. 2488--2496.Google Scholar"",""Yue Cao, Bin Liu, Mingsheng Long, and Jianmin Wang. 2018. Cross-Modal Hamming Hashing. In ECCV. 207--223.Google Scholar"",""Yue Cao, Mingsheng Long, Jianmin Wang, Qiang Yang, and Philip S. Yu. 2016. Deep Visual-Semantic Hashing for Cross-Modal Retrieval. In KDD. 1445--1454.Google Scholar"",""Nicholas Carlini and David Wagner. 2017. Towards evaluating the robustness of neural networks. In SP. 39--57.Google Scholar"",""Hongge Chen, Huan Zhang, Pin-Yu Chen, Jinfeng Yi, and Cho-Jui Hsieh. 2017. Attacking Visual Language Grounding with Adversarial Examples: A Case Study on Neural Image Captioning. arXiv preprint arXiv:1712.02051 (2017).Google Scholar"",""Zerui Chen, Yan Huang, and Liang Wang. 2019. Augmented Visual-Semantic Embeddings for Image and Sentence Matching. In ICIP. 290--294.Google Scholar"",""Tat-Seng Chua, Jinhui Tang, Richang Hong, Haojie Li, Zhiping Luo, and Yantao Zheng. 2009. NUS-WIDE: a real-world web image database from National University of Singapore. In CIVR. 48.Google Scholar"",""Cheng Deng, Zhaojia Chen, Xianglong Liu, Xinbo Gao, and Dacheng Tao. 2018. Triplet-based deep hashing network for cross-modal retrieval. IEEE Transactions on Image Processing, Vol. 27, 8 (2018), 3893--3903.Google ScholarCross Ref"",""Cheng Deng, Erkun Yang, Tongliang Liu, Jie Li, Wei Liu, and Dacheng Tao. 2019 b. Unsupervised semantic-preserving adversarial hashing for image search. IEEE Transactions on Image Processing, Vol. 28, 8 (2019), 4032--4044.Google ScholarCross Ref"",""Cheng Deng, Erkun Yang, Tongliang Liu, and Dacheng Tao. 2019 a. Two-stream deep hashing with class-specific centers for supervised image search. IEEE Transactions on Neural Networks and Learning Systems (2019).Google Scholar"",""Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin Hu, and Jianguo Li. 2018. Boosting adversarial attacks with momentum. In CVPR. 9185--9193.Google Scholar"",""Vijetha Gattupalli, Yaoxin Zhuo, and Baoxin Li. 2019. Weakly Supervised Deep Image Hashing through Tag Embeddings. In CVPR. 10375--10384.Google Scholar"",""Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial nets. In NeurIPS. 2672--2680.Google Scholar"",""Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2015. Explaining and harnessing adversarial examples. In ICLR.Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In CVPR. 770--778.Google Scholar"",""Mark J Huiskes and Michael S Lew. 2008. The MIR flickr retrieval evaluation. In MIPR. 39--43.Google Scholar"",""Qing-Yuan Jiang and Wu-Jun Li. 2017. Deep cross-modal hashing. In CVPR. 3232--3240.Google Scholar"",""Qing-Yuan Jiang and Wu-Jun Li. 2019. Discrete Latent Factor Model for Cross-Modal Hashing. IEEE Transactions on Image Processing, Vol. 28, 7 (2019), 3490--3501.Google ScholarDigital Library"",""Andrej Karpathy, Armand Joulin, and Li F Fei-Fei. 2014. Deep fragment embeddings for bidirectional image sentence mapping. In NeurIPS. 1889--1897.Google Scholar"",""Alexey Kurakin, Ian Goodfellow, and Samy Bengio. 2017. Adversarial examples in the physical world. In ICLR workshop.Google Scholar"",""Chao Li, Cheng Deng, Shangqian Gao, De Xie, and Wei Liu. 2019. Cross-Modal Learning with Adversarial Samples. In NeurIPS. 10791--10801.Google Scholar"",""Chao Li, Cheng Deng, Ning Li, Wei Liu, Xinbo Gao, and Dacheng Tao. 2018a. Self-Supervised Adversarial Hashing Networks for Cross-Modal Retrieval. In CVPR. 4242--4251.Google Scholar"",""Maosen Li, Cheng Deng, Tengjiao Li, Junchi Yan, Xinbo Gao, and Heng Huang. 2020. Towards Transferable Targeted Attack. In CVPR. 641--649.Google Scholar"",""Yeqing Li, Wei Liu, and Junzhou Huang. 2018b. Sub-Selective Quantization for Learning Binary Codes in Large-Scale Image Search. IEEE transactions on pattern analysis and machine intelligence, Vol. 40, 6 (2018), 1526--1532.Google Scholar"",""Zijia Lin, Guiguang Ding, Mingqing Hu, and Jianmin Wang. 2015. Semantics-Preserving Hashing for Cross-View Retrieval. In CVPR.Google Scholar"",""Wei Liu, Cun Mu, Sanjiv Kumar, and Shih-Fu Chang. 2014. Discrete graph hashing. In NIPS. 3419--3427.Google Scholar"",""Wei Liu, Jun Wang, Rongrong Ji, Yu-Gang Jiang, and Shih-Fu Chang. 2012a. Supervised hashing with kernels. In CVPR. IEEE, 2074--2081.Google Scholar"",""Wei Liu, Jun Wang, Sanjiv Kumar, and Shih-Fu Chang. 2011. Hashing with graphs. In ICML. 1--8.Google Scholar"",""Wei Liu, Jun Wang, Yadong Mu, Sanjiv Kumar, and Shih-Fu Chang. 2012b. Compact hyperplane hashing with bilinear functions. In ICML. 467--474.Google Scholar"",""Wei Liu and Tongtao Zhang. 2016. Multimedia hashing and networking. IEEE MultiMedia, Vol. 23, 3 (2016), 75--79.Google ScholarDigital Library"",""Xuanwu Liu, Guoxian Yu, Carlotta Domeniconi, Jun Wang, Yazhou Ren, and Maozu Guo. 2019. Ranking-based Deep Cross-modal Hashing. In AAAI.Google Scholar"",""Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. 2017. Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083 (2017).Google Scholar"",""Junhua Mao, Wei Xu, Yi Yang, Jiang Wang, Zhiheng Huang, and Alan Yuille. 2015. Deep captioning with multimodal recurrent neural networks (m-rnn). In ICLR.Google Scholar"",""Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, and Pascal Frossard. 2017. Universal adversarial perturbations. In CVPR. 1765--1773.Google Scholar"",""Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard. 2016. Deepfool: a simple and accurate method to fool deep neural networks. In CVPR. 2574--2582.Google Scholar"",""Anh Nguyen, Jason Yosinski, and Jeff Clune. 2015. Deep neural networks are easily fooled: High confidence predictions for unrecognizable images. In CVPR. 427--436.Google Scholar"",""Vicente Ordonez, Girish Kulkarni, and Tamara L Berg. 2011. Im2text: Describing images using 1 million captioned photographs. In NeurIPS. 1143--1151.Google Scholar"",""Jose Costa Pereira, Emanuele Coviello, Gabriel Doyle, Nikhil Rasiwasia, Gert RG Lanckriet, Roger Levy, and Nuno Vasconcelos. 2013. On the role of correlation and abstraction in cross-modal multimedia retrieval. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 36, 3 (2013), 521--535.Google ScholarDigital Library"",""Scott Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt Schiele, and Honglak Lee. 2016. Generative adversarial text to image synthesis. In ICML. 1060--1069.Google Scholar"",""Fumin Shen, Chunhua Shen, Wei Liu, and Heng Tao Shen. 2015. Supervised discrete hashing. In CVPR. 37--45.Google Scholar"",""Chao Zhang Shupeng Su, Zhisheng Zhong. 2019. Deep Joint-Semantics Reconstructing Hashing for Large-Scale Unsupervised Cross-Modal Retrieval. In ICCV.Google Scholar"",""Karen Simonyan and Andrew Zisserman. 2015. Very deep convolutional networks for large-scale image recognition. In ICLR.Google Scholar"",""Jiawei Su, Danilo Vasconcellos Vargas, and Kouichi Sakurai. 2019. One pixel attack for fooling deep neural networks. IEEE Transactions on Evolutionary Computation (2019).Google Scholar"",""Mengying Sun, Fengyi Tang, Jinfeng Yi, Fei Wang, and Jiayu Zhou. 2018. Identify susceptible locations in medical records via adversarial attacks on deep predictive models. In ACM SIGKDD. ACM, 793--801.Google Scholar"",""Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. 2013. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199 (2013).Google Scholar"",""Bokun Wang, Yang Yang, Xing Xu, Alan Hanjalic, and Heng Tao Shen. 2017. Adversarial cross-modal retrieval. In ACM MM. 154--162.Google Scholar"",""D. Xie, C. Deng, C. Li, X. Liu, and D. Tao. 2020. Multi-Task Consistency-Preserving Adversarial Hashing for Cross-Modal Retrieval. IEEE Transactions on Image Processing, Vol. 29 (2020), 3626--3637.Google ScholarDigital Library"",""Peixi Xiong, Huayi Zhan, Xin Wang, Baivab Sinha, and Ying Wu. 2019. Visual Query Answering by Entity-Attribute Graph Matching and Reasoning. In CVPR. 8357--8366.Google Scholar"",""Tao Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, and Xiaodong He. 2018b. Attngan: Fine-grained text to image generation with attentional generative adversarial networks. In CVPR. 1316--1324.Google Scholar"",""Xiaojun Xu, Xinyun Chen, Chang Liu, Anna Rohrbach, Trevor Darell, and Dawn Song. 2017. Can you fool AI with adversarial examples on a visual turing test. arXiv preprint arXiv:1709.08693 (2017).Google Scholar"",""Xiaojun Xu, Xinyun Chen, Chang Liu, Anna Rohrbach, Trevor Darrell, and Dawn Song. 2018a. Fooling Vision and Language Models Despite Localization and Attention Mechanism. In CVPR. 4951--4961.Google Scholar"",""Yan Xu, Baoyuan Wu, Fumin Shen, Yanbo Fan, Yong Zhang, Heng Tao Shen, and Wei Liu. 2019. Exact Adversarial Attack to Image Captioning via Structured Output Learning with Latent Variables. In CVPR. 4135--4144.Google Scholar"",""Erkun Yang, Cheng Deng, Chao Li, Wei Liu, Jie Li, and Dacheng Tao. 2018. Shared predictive cross-modal deep quantization. IEEE Transactions on Neural Networks and Learning Systems, Vol. 29, 11 (2018), 5292--5303.Google ScholarCross Ref"",""Erkun Yang, Cheng Deng, Wei Liu, Xianglong Liu, Dacheng Tao, and Xinbo Gao. 2017. Pairwise relationship guided deep hashing for cross-modal retrieval. In AAAI.Google Scholar"",""Erkun Yang, Tongliang Liu, Cheng Deng, Wei Liu, and Dacheng Tao. 2019. DistillHash: Unsupervised Deep Hashing by Distilling Data Pairs. In CVPR. 2946--2955.Google Scholar"",""Xi Zhang, Hanjiang Lai, and Jiashi Feng. 2018. Attention-Aware Deep Adversarial Hashing for Cross-Modal Retrieval. In ECCV. 591--606.Google Scholar""]"
https://doi.org/10.1145/3394486.3403085,XGNN: Towards Model-Level Explanations of Graph Neural Networks,"Graphs neural networks (GNNs) learn node features by aggregating and combining neighbor information, which have achieved promising performance on many graph tasks. However, GNNs are mostly treated as black-boxes and lack human intelligible explanations. Thus, they cannot be fully trusted and used in certain application domains if GNN models cannot be explained. In this work, we propose a novel approach, known as XGNN, to interpret GNNs at the model-level. Our approach can provide high-level insights and generic understanding of how GNNs work. In particular, we propose to explain GNNs by training a graph generator so that the generated graph patterns maximize a certain prediction of the model. We formulate the graph generation as a reinforcement learning task, where for each step, the graph generator predicts how to add an edge into the current graph. The graph generator is trained via a policy gradient method based on information from the trained GNNs. In addition, we incorporate several graph rules to encourage the generated graphs to be valid. Experimental results on both synthetic and real-world datasets show that our proposed methods help understand and verify the trained GNNs. Furthermore, our experimental results indicate that the generated graphs can provide guidance on how to improve the trained GNNs.","[{""name"":""Hao Yuan"",""id"":""/profile/99659575033""},{""name"":""Jiliang Tang"",""id"":""/profile/81496640622""},{""name"":""Xia Hu"",""id"":""/profile/81453623389""},{""name"":""Shuiwang Ji"",""id"":""/profile/81333489125""},{""name"":""Hao Yuan"",""id"":""/profile/99659575033""},{""name"":""Jiliang Tang"",""id"":""/profile/81496640622""},{""name"":""Xia Hu"",""id"":""/profile/81453623389""},{""name"":""Shuiwang Ji"",""id"":""/profile/81333489125""}]","[""Uri Alon. 2006. An introduction to systems biology: design principles of biological circuits .Chapman and Hall/CRC.Google Scholar"",""Uri Alon. 2007. Network motifs: theory and experimental approaches. Nature Reviews Genetics, Vol. 8, 6 (2007), 450.Google ScholarCross Ref"",""Sebastian Bach, Alexander Binder, Grégoire Montavon, Frederick Klauschen, Klaus-Robert Müller, and Wojciech Samek. 2015. On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation. PloS one, Vol. 10, 7 (2015).Google Scholar"",""Federico Baldassarre and Hossein Azizpour. 2019. Explainability Techniques for Graph Convolutional Networks. In International Conference on Machine Learning (ICML) Workshops, 2019 Workshop on Learning and Reasoning with Graph-Structured Representations.Google Scholar"",""Piotr Dabkowski and Yarin Gal. 2017. Real time image saliency for black box classifiers. In Advances in Neural Information Processing Systems. 6967--6976.Google Scholar"",""Asim Kumar Debnath, Rosa L Lopez de Compadre, Gargi Debnath, Alan J Shusterman, and Corwin Hansch. 1991. Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds. correlation with molecular orbital energies and hydrophobicity. Journal of medicinal chemistry, Vol. 34, 2 (1991), 786--797.Google ScholarCross Ref"",""Finale Doshi-Velez and Been Kim. 2017. Towards a rigorous science of interpretable machine learning. arXiv preprint arXiv:1702.08608 (2017).Google Scholar"",""Dumitru Erhan, Yoshua Bengio, Aaron Courville, and Pascal Vincent. 2009. Visualizing higher-layer features of a deep network. Technical Report, University of Montreal, Vol. 1341, 3 (2009), 1.Google Scholar"",""Ruth C Fong and Andrea Vedaldi. 2017. Interpretable explanations of black boxes by meaningful perturbation. In Proceedings of the IEEE International Conference on Computer Vision. 3429--3437.Google ScholarCross Ref"",""Hongyang Gao and Shuiwang Ji. 2019 a. Graph representation learning via hard and channel-wise attention networks. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 741--749.Google ScholarDigital Library"",""Hongyang Gao and Shuiwang Ji. 2019 b. Graph U-Net. In International conference on machine learning. 2083--2092.Google Scholar"",""Muriel Gevrey, Ioannis Dimopoulos, and Sovan Lek. 2003. Review and comparison of methods to study the contribution of variables in artificial neural network models. Ecological modelling, Vol. 160, 3 (2003), 249--264.Google Scholar"",""Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. 2017. Neural message passing for quantum chemistry. In Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 1263--1272.Google ScholarDigital Library"",""Gabriel Lima Guimaraes, Benjamin Sanchez-Lengeling, Carlos Outeiral, Pedro Luis Cunha Farias, and Alán Aspuru-Guzik. 2017. Objective-reinforced generative adversarial networks (ORGAN) for sequence generation models. arXiv preprint arXiv:1705.10843 (2017).Google Scholar"",""Aric Hagberg, Pieter Swart, and Daniel S Chult. 2008. Exploring network structure, dynamics, and function using NetworkX. Technical Report. Los Alamos National Lab.(LANL), Los Alamos, NM (United States).Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In Advances in neural information processing systems. 1024--1034.Google Scholar"",""Wengong Jin, Regina Barzilay, and Tommi Jaakkola. 2018. Junction Tree Variational Autoencoder for Molecular Graph Generation. In Proceedings of the 35th International Conference on Machine Learning. 2323--2332.Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A Method for Stochastic Optimization. In Proceedings of the 3rd International Conference on Learning Representations.Google Scholar"",""Thomas N Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional networks. In Proceedings of the International Conference on Learning Representations.Google Scholar"",""Junhyun Lee, Inyeop Lee, and Jaewoo Kang. 2019. Self-Attention Graph Pooling. In International Conference on Machine Learning. 3734--3743.Google Scholar"",""Tao Lei, Regina Barzilay, and Tommi Jaakkola. 2016. Rationalizing Neural Predictions. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. 107--117.Google ScholarCross Ref"",""Yujia Li, Oriol Vinyals, Chris Dyer, Razvan Pascanu, and Peter Battaglia. 2018. Learning deep generative models of graphs. arXiv preprint arXiv:1803.03324 (2018).Google Scholar"",""Ron Milo, Shai Shen-Orr, Shalev Itzkovitz, Nadav Kashtan, Dmitri Chklovskii, and Uri Alon. 2002. Network motifs: simple building blocks of complex networks. Science, Vol. 298, 5594 (2002), 824--827.Google Scholar"",""Anh Nguyen, Jeff Clune, Yoshua Bengio, Alexey Dosovitskiy, and Jason Yosinski. 2017. Plug \u0026 play generative networks: Conditional iterative generation of images in latent space. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 4467--4477.Google ScholarCross Ref"",""Anh Nguyen, Jason Yosinski, and Jeff Clune. 2015. Deep neural networks are easily fooled: High confidence predictions for unrecognizable images. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 427--436.Google ScholarCross Ref"",""Chris Olah, Alexander Mordvintsev, and Ludwig Schubert. 2017. Feature visualization. Distill, Vol. 2, 11 (2017), e7.Google ScholarCross Ref"",""Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. 2017. Automatic differentiation in PyTorch. In Proceedings of the International Conference on Learning Representations.Google Scholar"",""Spencer L Seager and Michael R Slabaugh. 2013. Chemistry for today: General, organic, and biochemistry. Cengage learning.Google Scholar"",""Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. 2017. Grad-CAM: Visual explanations from deep networks via gradient-based localization. In Proceedings of the IEEE International Conference on Computer Vision. 618--626.Google ScholarCross Ref"",""Shai S Shen-Orr, Ron Milo, Shmoolik Mangan, and Uri Alon. 2002. Network motifs in the transcriptional regulation network of Escherichia coli. Nature genetics, Vol. 31, 1 (2002), 64.Google Scholar"",""Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. 2013. Deep inside convolutional networks: Visualising image classification models and saliency maps. arXiv preprint arXiv:1312.6034 (2013).Google Scholar"",""Daniel Smilkov, Nikhil Thorat, Been Kim, Fernanda Viégas, and Martin Wattenberg. 2017. Smoothgrad: removing noise by adding noise. arXiv preprint arXiv:1706.03825 (2017).Google Scholar"",""Jost Tobias Springenberg, Alexey Dosovitskiy, Thomas Brox, and Martin Riedmiller. 2014. Striving for simplicity: The all convolutional net. arXiv preprint arXiv:1412.6806 (2014).Google Scholar"",""James Andrew Storer. 2012. An introduction to data structures and algorithms .Springer Science \u0026 Business Media.Google Scholar"",""Richard S Sutton, David A McAllester, Satinder P Singh, and Yishay Mansour. 2000. Policy gradient methods for reinforcement learning with function approximation. In Advances in neural information processing systems. 1057--1063.Google Scholar"",""Kiran K Thekumparampil, Chong Wang, Sewoong Oh, and Li-Jia Li. 2018. Attention-based graph neural network for semi-supervised learning. arXiv preprint arXiv:1803.03735 (2018).Google Scholar"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2018. Graph Attention Networks. In International Conference on Learning Representations. https://openreview.net/forum?id=rJXMpikCZGoogle Scholar"",""Hongwei Wang, Jia Wang, Jialin Wang, Miao Zhao, Weinan Zhang, Fuzheng Zhang, Xing Xie, and Minyi Guo. 2018. GraphGAN: Graph representation learning with generative adversarial nets. In Thirty-Second AAAI Conference on Artificial Intelligence. 2508--2515.Google Scholar"",""Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2019. How Powerful are Graph Neural Networks?. In International Conference on Learning Representations. https://openreview.net/forum?id=ryGs6iA5KmGoogle Scholar"",""Zhitao Ying, Dylan Bourgeois, Jiaxuan You, Marinka Zitnik, and Jure Leskovec. 2019. GNNExplainer: Generating Explanations for Graph Neural Networks. In Advances in Neural Information Processing Systems 32. 9244--9255.Google Scholar"",""Jiaxuan You, Bowen Liu, Zhitao Ying, Vijay Pande, and Jure Leskovec. 2018. Graph convolutional policy network for goal-directed molecular graph generation. In Advances in Neural Information Processing Systems. 6410--6421.Google Scholar"",""L Yu, W Zhang, J Wang, and Y Yu. 2017. Seqgan: sequence generative adversarial nets with policy gradient. In AAAI-17: Thirty-First AAAI Conference on Artificial Intelligence, Vol. 31. Association for the Advancement of Artificial Intelligence (AAAI), 2852--2858.Google Scholar"",""Hao Yuan, Yongjun Chen, Xia Hu, and Shuiwang Ji. 2019. Interpreting Deep Models for Text Analysis via Optimization and Regularization Methods. In Thirty-Third AAAI Conference on Artificial Intelligence. 5717--5724.Google ScholarCross Ref"",""Hao Yuan and Shuiwang Ji. 2020. StructPool: Structured Graph Pooling via Conditional Random Fields. In International Conference on Learning Representations. https://openreview.net/forum?id=BJxg_hVtwHGoogle Scholar"",""Matthew D Zeiler and Rob Fergus. 2014. Visualizing and understanding convolutional networks. In European Conference on Computer Vision. Springer, 818--833.Google ScholarCross Ref"",""Muhan Zhang and Yixin Chen. 2018. Link prediction based on graph neural networks. In Advances in Neural Information Processing Systems. 5165--5175.Google Scholar"",""Muhan Zhang, Zhicheng Cui, Marion Neumann, and Yixin Chen. 2018. An end-to-end deep learning architecture for graph classification. In Thirty-Second AAAI Conference on Artificial Intelligence. 4438--4445.Google Scholar"",""Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba. 2016. Learning deep features for discriminative localization. In Proceedings of the IEEE International Conference on Computer Vision. 2921--2929.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403086,CAST: A Correlation-based Adaptive Spectral Clustering Algorithm on Multi-scale Data,"We study the problem of applying spectral clustering to cluster multi-scale data, which is data whose clusters are of various sizes and densities. Traditional spectral clustering techniques discover clusters by processing a similarity matrix that reflects the proximity of objects. For multi-scale data, distance-based similarity is not effective because objects of a sparse cluster could be far apart while those of a dense cluster have to be sufficiently close. Following [16], we solve the problem of spectral clustering on multi-scale data by integrating the concept of objects' ""reachability similarity"" with a given distance-based similarity to derive an objects' coefficient matrix. We propose the algorithm CAST that applies trace Lasso to regularize the coefficient matrix. We prove that the resulting coefficient matrix has the ""grouping effect"" and that it exhibits ""sparsity"". We show that these two characteristics imply very effective spectral clustering. We evaluate CAST and 10 other clustering methods on a wide range of datasets w.r.t. various measures. Experimental results show that CAST provides excellent performance and is highly robust across test cases of multi-scale data.","[{""name"":""Xiang Li"",""id"":""/profile/81477643519""},{""name"":""Ben Kao"",""id"":""/profile/81100519737""},{""name"":""Caihua Shan"",""id"":""/profile/99659133244""},{""name"":""Dawei Yin"",""id"":""/profile/81464666761""},{""name"":""Martin Ester"",""id"":""/profile/81100382875""},{""name"":""Xiang Li"",""id"":""/profile/81477643519""},{""name"":""Ben Kao"",""id"":""/profile/81100519737""},{""name"":""Caihua Shan"",""id"":""/profile/99659133244""},{""name"":""Dawei Yin"",""id"":""/profile/81464666761""},{""name"":""Martin Ester"",""id"":""/profile/81100382875""}]","[""Charles J Alpert and So-Zen Yao. 1995. Spectral partitioning: the more eigenvectors, the better. In Proceedings of the 32nd annual ACM/IEEE Design Automation Conference. ACM, 195--200.Google Scholar"",""Aleksandar Bojchevski, Yves Matkovic, and Stephan Günnemann. 2017. Robust Spectral Clustering for Noisy Data: Modeling Sparse Corruptions Improves Latent Embeddings. In KDD. 737--746.Google Scholar"",""Jian-Feng Cai, Emmanuel J Candès, and Zuowei Shen. 2010. A singular value thresholding algorithm for matrix completion. SIAM Journal on optimization, Vol. 20, 4 (2010), 1956--1982.Google Scholar"",""Xinlei Chen and Deng Cai. 2011. Large Scale Spectral Clustering with Landmark-Based Representation. In AAAI. 313--318.Google Scholar"",""Xiaojun Chen, Weijun Hong, Feiping Nie, Dan He, Min Yang, and Joshua Zhexue Huang. 2018. Spectral clustering of large-scale data by directly solving normalized cut. In KDD. ACM, 1206--1215.Google Scholar"",""Carlos D Correa and Peter Lindstrom. 2012. Locally-scaled spectral clustering using empty region graphs. In KDD. 1330--1338.Google Scholar"",""Jane K Cullum and Ralph A Willoughby. 2002. Lanczos algorithms for large symmetric eigenvalue computations: Vol. I: Theory. SIAM.Google Scholar"",""Inderjit S Dhillon. 2001. Co-clustering documents and words using bipartite spectral graph partitioning. In KDD. 269--274.Google Scholar"",""Edouard Grave, Guillaume R Obozinski, and Francis R Bach. 2011. Trace lasso: a trace norm regularization for correlated designs. In NeurIPS. 2187--2195.Google Scholar"",""Han Hu, Zhouchen Lin, Jianjiang Feng, and Jie Zhou. 2014. Smooth representation clustering. In CVPR. 3834--3841.Google Scholar"",""Hao Huang, Shinjae Yoo, Dantong Yu, and Hong Qin. 2014. Diverse power iteration embeddings and its applications. In ICDM. 200--209.Google Scholar"",""Ling Huang, Donghui Yan, Nina Taft, and Michael I Jordan. 2009. Spectral clustering with perturbed data. In NeurIPS. 705--712.Google Scholar"",""Ravi Kannan, Santosh Vempala, and Adrian Vetta. 2004. On clusterings: Good, bad and spectral. JACM, Vol. 51, 3 (2004), 497--515.Google Scholar"",""Agnan Kessy, Alex Lewin, and Korbinian Strimmer. 2017. Optimal whitening and decorrelation. The American Statistician (2017).Google Scholar"",""Stephane Lafon and Ann B Lee. 2006. Diffusion maps and coarse-graining: A unified framework for dimensionality reduction, graph partitioning, and data set parameterization. TPAMI, Vol. 28, 9 (2006), 1393--1403.Google Scholar"",""Xiang Li, Ben Kao, Siqiang Luo, and Martin Ester. 2018. ROSC: robust spectral clustering on multi-scale data. In WWW. 157--166.Google Scholar"",""Xiang Li, Ben Kao, Zhaochun Ren, and Dawei Yin. 2019. Spectral Clustering in Heterogeneous Information Networks. In AAAI. 4221--4228.Google Scholar"",""Zhenguo Li, Jianzhuang Liu, Shifeng Chen, and Xiaoou Tang. 2007. Noise robust spectral clustering. In ICCV. 1--8.Google Scholar"",""Frank Lin. 2012. Scalable methods for graph-based unsupervised and semi-supervised learning. Ph.D. Dissertation. Carnegie Mellon University.Google Scholar"",""Frank Lin and William W Cohen. 2010. Power iteration clustering. In ICML. 655--662.Google Scholar"",""Zhouchen Lin, Minming Chen, and Yi Ma. 2010. The augmented lagrange multiplier method for exact recovery of corrupted low-rank matrices. arXiv preprint arXiv:1009.5055 (2010).Google Scholar"",""Guangcan Liu, Zhouchen Lin, Shuicheng Yan, Ju Sun, Yong Yu, and Yi Ma. 2013. Robust recovery of subspace structures by low-rank representation. TPAMI, Vol. 35, 1 (2013), 171--184.Google Scholar"",""Canyi Lu, Jiashi Feng, Zhouchen Lin, and Shuicheng Yan. 2013. Correlation adaptive subspace segmentation by trace lasso. In ICCV. 1345--1352.Google Scholar"",""Can-Yi Lu, Hai Min, Zhong-Qiu Zhao, Lin Zhu, De-Shuang Huang, and Shuicheng Yan. 2012. Robust and efficient subspace segmentation via least squares regression. In ECCV. 347--360.Google Scholar"",""Marina Meila and Jianbo Shi. 2001. A random walks view of spectral segmentation. (2001).Google Scholar"",""Boaz Nadler and Meirav Galun. 2006. Fundamental limitations of spectral clustering. In NeurIPS. 1017--1024.Google Scholar"",""Boaz Nadler, Stephane Lafon, Ronald Coifman, and Ioannis Kevrekidis. 2005. Diffusion maps, spectral clustering and eigenfunctions of Fokker-Planck operators. In NeurIPS. 955--962.Google Scholar"",""Andrew Y Ng, Michael I Jordan, Yair Weiss, et al. 2001. On spectral clustering: Analysis and an algorithm. In NeurIPS. 849--856.Google Scholar"",""Jianbo Shi and Jitendra Malik. 2000. Normalized cuts and image segmentation. TPAMI, Vol. 22, 8 (2000), 888--905.Google Scholar"",""Anh Pham The, Nguyen Duc Thang, La The Vinh, Young-Koo Lee, and Sungyoung Lee. 2013. Deflation-based power iteration clustering. Applied Intelligence, Vol. 39, 2 (2013), 367--385.Google Scholar"",""Nguyen Xuan Vinh, Julien Epps, and James Bailey. 2010. Information theoretic measures for clusterings comparison: Variants, properties, normalization and correction for chance. JMLR, Vol. 11 (2010), 2837--2854.Google Scholar"",""Ulrike Von Luxburg. 2007. A tutorial on spectral clustering. Statistics and computing, Vol. 17, 4 (2007), 395--416.Google Scholar"",""Ulrike Von Luxburg, Mikhail Belkin, and Olivier Bousquet. 2008. Consistency of spectral clustering. The Annals of Statistics (2008), 555--586.Google Scholar"",""Tao Xiang and Shaogang Gong. 2008. Spectral clustering with eigenvector selection. Pattern Recognition, Vol. 41, 3 (2008), 1012--1029.Google Scholar"",""Donghui Yan, Ling Huang, and Michael I Jordan. 2009. Fast approximate spectral clustering. In KDD. 907--916.Google Scholar"",""Wei Ye, Sebastian Goebl, Claudia Plant, and Christian Böhm. 2016. FUSE: Full Spectral Clustering. In KDD. 1985--1994.Google Scholar"",""Stella X. Yu and Jianbo Shi. 2003. Multiclass spectral clustering. In ICCV. 313--319.Google Scholar"",""Lihi Zelnik-Manor and Pietro Perona. 2004. Self-tuning spectral clustering. In NeurIPS. 1601--1608.Google Scholar"",""Yin Zhang. 2010. Recent advances in alternating direction methods: Practice and theory. In IPAM workshop on continuous optimization .Google Scholar"",""Xiatian Zhu, Chen Change Loy, and Shaogang Gong. 2014. Constructing robust affinity graphs for spectral clustering. In CVPR. 1450--1457.Google Scholar""]"
https://doi.org/10.1145/3394486.3403087,INPREM: An Interpretable and Trustworthy Predictive Model for Healthcare,"Building a predictive model based on historical Electronic Health Records (EHRs) for personalized healthcare has become an active research area. Benefiting from the powerful ability of feature extraction, deep learning (DL) approaches have achieved promising performance in many clinical prediction tasks. However, due to the lack of interpretability and trustworthiness, it is difficult to apply DL in real clinical cases of decision making. To address this, in this paper, we propose an interpretable and trustworthy predictive model~(INPREM) for healthcare. Firstly, INPREM is designed as a linear model for interpretability while encoding non-linear relationships into the learning weights for modeling the dependencies between and within each visit. This enables us to obtain the contribution matrix of the input variables, which is served as the evidence of the prediction result(s), and help physicians understand why the model gives such a prediction, thereby making the model more interpretable. Secondly, for trustworthiness, we place a random gate (which follows a Bernoulli distribution to turn on or off) over each weight of the model, as well as an additional branch to estimate data noises. With the help of the Monto Carlo sampling and an objective function accounting for data noises, the model can capture the uncertainty of each prediction. The captured uncertainty, in turn, allows physicians to know how confident the model is, thus making the model more trustworthy. We empirically demonstrate that the proposed INPREM outperforms existing approaches with a significant margin. A case study is also presented to show how the contribution matrix and the captured uncertainty are used to assist physicians in making robust decisions.","[{""name"":""Xianli Zhang"",""id"":""/profile/99659479556""},{""name"":""Buyue Qian"",""id"":""/profile/81448593459""},{""name"":""Shilei Cao"",""id"":""/profile/99659573859""},{""name"":""Yang Li"",""id"":""/profile/99659575270""},{""name"":""Hang Chen"",""id"":""/profile/99659573184""},{""name"":""Yefeng Zheng"",""id"":""/profile/99659575101""},{""name"":""Ian Davidson"",""id"":""/profile/81488655446""},{""name"":""Xianli Zhang"",""id"":""/profile/99659479556""},{""name"":""Buyue Qian"",""id"":""/profile/81448593459""},{""name"":""Shilei Cao"",""id"":""/profile/99659573859""},{""name"":""Yang Li"",""id"":""/profile/99659575270""},{""name"":""Hang Chen"",""id"":""/profile/99659573184""},{""name"":""Yefeng Zheng"",""id"":""/profile/99659575101""},{""name"":""Ian Davidson"",""id"":""/profile/81488655446""}]","[""Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E. Hinton. 2016. Layer normalization. arXiv preprint arXiv:1607.06450 (2016).Google Scholar"",""Zhengping Che, Yu Cheng, Zhaonan Sun, and Yan Liu. 2017. Exploiting convolutional neural network for risk prediction with medical feature embedding. arXiv preprint arXiv:1701.07474 (2017).Google Scholar"",""Yu Cheng, Fei Wang, Ping Zhang, and Jianying Hu. 2016. Risk prediction with electronic health records: A deep learning approach. In Proc. SIAM Int'l Conf. Data Mining. SIAM, 432--440.Google ScholarCross Ref"",""Edward Choi, Mohammad Taha Bahadori, Andy Schuetz, Walter F. Stewart, and Jimeng Sun. 2016a. Doctor AI: Predicting clinical events via recurrent neural networks. In Machine Learning for Healthcare Conference. 301--318.Google Scholar"",""Edward Choi, Mohammad Taha Bahadori, Le Song, Walter F. Stewart, and Jimeng Sun. 2017. GRAM: Graph-based attention model for healthcare representation learning. In Proc. ACM SIGKDD Int'l Conf. on Knowledge Discovery and Data Mining. 787--795.Google ScholarDigital Library"",""Edward Choi, Mohammad Taha Bahadori, Jimeng Sun, Joshua Kulas, Andy Schuetz, and Walter Stewart. 2016b. RETAIN: An interpretable predictive model for healthcare using reverse time attention mechanism. In Advances in Neural Information Processing Systems. 3504--3512.Google Scholar"",""Ingyo Chung, Saehoon Kim, Juho Lee, Kwang Joon Kim, Sung Ju Hwang, and Eunho Yang. 2018. Deep mixed effect models using Gaussian process: A personalized and reliable prediction model for healthcare. arXiv preprint arXiv:1806.01551 (2018).Google Scholar"",""Michael W. Dusenberry, Dustin Tran, Edward Choi, Jonas Kemp, Jeremy Nixon, Ghassen Jerfel, Katherine Heller, and Andrew M. Dai. 2019. Analyzing the role of model uncertainty for electronic health records. arXiv preprint arXiv:1906.03842 (2019).Google Scholar"",""Yarin Gal. 2016. Uncertainty in deep learning. University of Cambridge (2016).Google Scholar"",""Yarin Gal and Zoubin Ghahramani. 2015. Bayesian convolutional neural networks with Bernoulli approximate variational inference. arXiv preprint arXiv:1506.02158 (2015).Google Scholar"",""Yarin Gal and Zoubin Ghahramani. 2016. Dropout as a Bayesian approximation: Representing model uncertainty in deep learning. In Proc. Int'l Conf. Machine Learning. 1050--1059.Google Scholar"",""Paulina Grnarova, Florian Schmidt, Stephanie L. Hyland, and Carsten Eickhoff. 2016. Neural document embeddings for intensive care patient mortality prediction. arXiv preprint arXiv:1612.00467 (2016).Google Scholar"",""Hrayr Harutyunyan, Hrant Khachatrian, David C. Kale, and Aram Galstyan. 2017. Multitask Learning and Benchmarking with Clinical Time Series Data. Scientific Data, Vol. 6, 1 (2017).Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In Proc. IEEE Conf. Computer Vision and Pattern Recognition. 770--778.Google ScholarCross Ref"",""Jay Heo, Hae Beom Lee, Saehoon Kim, Juho Lee, Kwang Joon Kim, Eunho Yang, and Sung Ju Hwang. 2018. Uncertainty-aware attention for reliable interpretation and prediction. In Advances in Neural Information Processing Systems 31, S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (Eds.). 909--918.Google Scholar"",""Geoffrey Hinton and Drew Van Camp. 1993. Keeping neural networks simple by minimizing the description length of the weights. In Proc. ACM Conf. Computational Learning Theory. 5--13.Google ScholarDigital Library"",""Alistair E.W. Johnson, Tom J. Pollard, Lu Shen, H. Lehman Li-wei, Mengling Feng, et al. 2016. MIMIC-III, a freely accessible critical care database. Scientific Data, Vol. 3 (2016), 160035.Google ScholarCross Ref"",""Alex Kendall and Yarin Gal. 2017. What uncertainties do we need in Bayesian deep learning for computer vision?killpunct. In Advances in Neural Information Processing Systems. 5574--5584.Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. 2017. Simple and scalable predictive uncertainty estimation using deep ensembles. In Advances in Neural Information Processing Systems. 6402--6413.Google Scholar"",""Yang Li, Buyue Qian, Xianli Zhang, and Hui Liu. [n.d.]. Knowledge guided diagnosis prediction via graph spatial-temporal network. 19--27.Google Scholar"",""Fenglong Ma, Radha Chitta, Jing Zhou, Quanzeng You, Tong Sun, and Jing Gao. 2017. Dipole: Diagnosis prediction in healthcare via attention-based bidirectional recurrent neural networks. In Proc. ACM SIGKDD Int'l Conf. on Knowledge Discovery and Data Mining. 1903--1911.Google ScholarDigital Library"",""Fenglong Ma, Jing Gao, Qiuling Suo, Quanzeng You, Jing Zhou, and Aidong Zhang. 2018a. Risk prediction on electronic health records with prior medical knowledge. In Proc. ACM SIGKDD Int'l Conf. on Knowledge Discovery and Data Mining. 1910--1919.Google ScholarDigital Library"",""Fenglong Ma, Quanzeng You, Houping Xiao, Radha Chitta, Jing Zhou, and Jing Gao. 2018b. KAME: Knowledge-based attention model for diagnosis prediction in healthcare. In Proc. ACM Int'l Conf. Information and Knowledge Management. 743--752.Google ScholarDigital Library"",""David J. C. MacKay. 1992. A Practical Bayesian Framework for Backpropagation Networks. Neural Computation, Vol. 4, 3 (1992), 448--472.Google ScholarDigital Library"",""Andre Martins and Ramon Astudillo. 2016. From Softmax to Sparsemax: A sparse model of attention and multi-label classification. In Proc. Int'l Conf. Machine Learning. 1614--1623.Google Scholar"",""Radford M. Neal. 2012. Bayesian learning for neural networks .Springer Science \u0026 Business Media.Google Scholar"",""John Paisley, David Blei, and Michael Jordan. 2012. Variational Bayesian inference with stochastic search. arXiv preprint arXiv:1206.6430 (2012).Google Scholar"",""Riyi Qiu, Yugang Jia, Mirsad Hadzikadic, Michael Dulin, Xi Niu, and Xin Wang. 2019. Modeling the uncertainty in electronic health records: A Bayesian deep learning approach. arXiv preprint arXiv:1907.06162 (2019).Google Scholar"",""Carl Edward Rasmussen. 2003. Gaussian processes in machine learning. In Summer School on Machine Learning. Springer, 63--71.Google Scholar"",""Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. 2014. Stochastic backpropagation and approximate inference in deep generative models. arXiv preprint arXiv:1401.4082 (2014).Google Scholar"",""Huan Song, Deepta Rajan, Jayaraman J. Thiagarajan, and Andreas Spanias. 2018. Attend and diagnose: Clinical time series analysis using attention models. In Proc. AAAI Conf. Artificial Intelligence. 4091--4098.Google Scholar"",""Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: A Simple Way to Prevent Neural Networks from Overfitting. Journal of Machine Learning Research, Vol. 15 (2014), 1929--1958.Google ScholarDigital Library"",""Qiuling Suo, Fenglong Ma, Ye Yuan, Mengdi Huai, Weida Zhong, Aidong Zhang, and Jing Gao. 2017. Personalized disease prediction using a CNN-based similarity learning method. In IEEE Int'l Conf. Bioinformatics and Biomedicine. IEEE, 811--816.Google Scholar"",""Michalis Titsias and Neil D. Lawrence. 2010. Bayesian Gaussian process latent variable model. In Proc. Int'l Conf. Artificial Intelligence and Statistics. 844--851.Google Scholar"",""Michalis Titsias and Miguel Lázaro-Gredilla. 2014. Doubly stochastic variational Bayes for non-conjugate inference. In Proc. Int'l Conf. Machine Learning. 1971--1979.Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems. 5998--6008.Google Scholar"",""Xianli Zhang, Buyue Qian, Xiaoyu Li, Jishang Wei, Yingqian Zheng, Lingyun Song, and Qinghua Zheng. [n.d.]. An Interpretable Fast Model for Predicting The Risk of Heart Failure. 576--584.Google Scholar"",""Xianli Zhang, Buyue Qian, Yang Li, Changchang Yin, Xudong Wang, and Qinghua Zheng. 2019. KnowRisk: An interpretable knowledge-guided model for disease risk prediction. In 2019 IEEE International Conference on Data Mining (ICDM). 1492--1497.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403088,Policy-GNN: Aggregation Optimization for Graph Neural Networks,"Graph data are pervasive in many real-world applications. Recently, increasing attention has been paid on graph neural networks (GNNs), which aim to model the local graph structures and capture the hierarchical patterns by aggregating the information from neighbors with stackable network modules. Motivated by the observation that different nodes often require different iterations of aggregation to fully capture the structural information, in this paper, we propose to explicitly sample diverse iterations of aggregation for different nodes to boost the performance of GNNs. It is a challenging task to develop an effective aggregation strategy for each node, given complex graphs and sparse features. Moreover, it is not straightforward to derive an efficient algorithm since we need to feed the sampled nodes into different number of network layers. To address the above challenges, we propose Policy-GNN, a meta-policy framework that models the sampling procedure and message passing of GNNs into a combined learning process. Specifically, Policy-GNN uses a meta-policy to adaptively determine the number of aggregations for each node. The meta-policy is trained with deep reinforcement learning~(RL) by exploiting the feedback from the model. We further introduce parameter sharing and a buffer mechanism to boost the training efficiency. Experimental results on three real-world benchmark datasets suggest that Policy-GNN significantly outperforms the state-of-the-art alternatives, showing the promise in aggregation optimization for GNNs.","[{""name"":""Kwei-Herng Lai"",""id"":""/profile/99659573364""},{""name"":""Daochen Zha"",""id"":""/profile/99659536427""},{""name"":""Kaixiong Zhou"",""id"":""/profile/99659573188""},{""name"":""Xia Hu"",""id"":""/profile/99659128094""},{""name"":""Kwei-Herng Lai"",""id"":""/profile/99659573364""},{""name"":""Daochen Zha"",""id"":""/profile/99659536427""},{""name"":""Kaixiong Zhou"",""id"":""/profile/99659573188""},{""name"":""Xia Hu"",""id"":""/profile/99659128094""}]","[""Peter W Battaglia, Jessica B Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, et al. 2018. Relational inductive biases, deep learning, and graph networks. arXiv preprint arXiv:1806.01261 (2018).Google Scholar"",""Xavier Bresson and Thomas Laurent. 2017. Residual gated graph convnets. arXiv preprint arXiv:1711.07553 (2017).Google Scholar"",""Jie Chen, Tengfei Ma, and Cao Xiao. 2018. FastGCN: Fast learning with graph convolutional networks via importance sampling. In ICLR.Google Scholar"",""Jie Chen, Tengfei Ma, and Cao Xiao. 2018. FastGCN: Fast learning with graph convolutional networks via importance sampling. In ICLRs.Google Scholar"",""Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolutional neural networks on graphs with fast localized spectral filtering. In NeurIPS.Google Scholar"",""Matthias Fey and Jan E. Lenssen. 2019. Fast graph representation learning with PyTorch Geometric. In ICLR Workshop on Representation Learning on Graphs and Manifolds.Google Scholar"",""Hongyang Gao and Shuiwang Ji. 2019. Graph u-nets. ICML (2019).Google Scholar"",""Hongyang Gao, Zhengyang Wang, and Shuiwang Ji. 2018. Large-scale learnable graph convolutional networks. In KDD.Google Scholar"",""Yang Gao, Hong Yang, Peng Zhang, Chuan Zhou, and Yue Hu. 2019. GraphNAS: Graph neural architecture search with reinforcement learning. arXiv preprint arXiv:1904.09981 (2019).Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In KDD.Google Scholar"",""Nezihe Merve Gürel, Hansheng Ren, Yujing Wang, Hui Xue, Yaming Yang, and Ce Zhang. 2019. An anatomy of graph neural networks going deep via the lens of mutual information: exponential decay vs. full preservation. arXiv preprint arXiv:1910.04499 (2019).Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In NeurIPS.Google Scholar"",""William L Hamilton, Rex Ying, and Jure Leskovec. 2017. Representation learning on graphs: Methods and applications. (2017).Google Scholar"",""William L. Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive Representation Learning on Large Graphs. In NeurIPS.Google Scholar"",""Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In WWW.Google Scholar"",""Xia Hu, Lei Tang, Jiliang Tang, and Huan Liu. 2013. Exploiting social relations for sentiment analysis in microblogging. In WSDM.Google Scholar"",""Wen-bing Huang, Tong Zhang, Yu Rong, and Junzhou Huang. 2018. Adaptive sampling towards fast graph representation learning. In NeurIPS.Google Scholar"",""Xiao Huang, Qingquan Song, Yuening Li, and Xia Hu. 2019. Graph recurrent networks with attributed random walks. In KDD.Google Scholar"",""Haifeng Jin, Qingquan Song, and Xia Hu. 2018. Auto-keras: Efficient neural architecture search with network morphism. arXiv preprint arXiv:1806.10282 (2018).Google Scholar"",""Thomas N. Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional networks. In ICLR.Google Scholar"",""Kwei-Herng Lai, Daochen Zha, Yuening Li, and Xia Hu. 2020. Dual policy distillation. arXiv preprint arXiv:2006.04061 (2020).Google Scholar"",""Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. 1998. Gradientbased learning applied to document recognition. IEEE (1998).Google Scholar"",""Guohao Li, Matthias Müller, Ali K. Thabet, and Bernard Ghanem. 2019. Can GCNs go as deep as CNNs? arXiv preprint (2019).Google Scholar"",""Yuening Li, Xiao Huang, Jundong Li, Mengnan Du, and Na Zou. 2019. SpecAE: Spectral autoencoder for anomaly Detection in Attributed Networks. In CIKM.Google Scholar"",""Yuening Li, Daochen Zha, Praveen Venugopal, Na Zou, and Xia Hu. 2020. PyODDS: An end-to-end outlier detection system with automated machine learning. In WWW.Google Scholar"",""Risto Miikkulainen, Jason Liang, Elliot Meyerson, Aditya Rawal, Daniel Fink, Olivier Francon, Bala Raju, Hormoz Shahrzad, Arshak Navruzyan, Nigel Duffy, et al. 2019. Evolving deep neural networks. In Artificial Intelligence in the Age of Neural Networks and Brain Computing. Elsevier, 293--312.Google Scholar"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In NeurIPS.Google Scholar"",""Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin A. Riedmiller. 2013. Playing Atari with deep reinforcement Learning. arXiv preprint (2013).Google Scholar"",""Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness, Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg Ostrovski, et al. 2015. Human-level control through deep reinforcement learning. Nature 518, 7540 (2015), 529.Google Scholar"",""Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A. Rusu, Joel Veness, Marc G. Bellemare, Alex Graves, Martin A. Riedmiller, Andreas Fidjeland, Georg Ostrovski, Stig Petersen, Charles Beattie, Amir Sadik, Ioannis Antonoglou, Helen King, Dharshan Kumaran, Daan Wierstra, Shane Legg, and Demis Hassabis. 2015. Human-level control through deep reinforcement learning. Nature (2015).Google Scholar"",""Kenta Oono and Taiji Suzuki. 2019. On asymptotic behaviors of graph cnns from dynamical systems perspective. arXiv preprint arXiv:1905.10947 (2019).Google Scholar"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. DeepWalk: online learning of social representations. In KDD.Google Scholar"",""Hieu Pham, Melody Y Guan, Barret Zoph, Quoc V Le, and Jeff Dean. 2018. Efficient neural architecture search via parameter sharing. arXiv preprint arXiv:1802.03268 (2018).Google Scholar"",""Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. 2009. The graph neural network model. IEEE Transactions on Neural Networks 20, 1 (2009), 61--80.Google ScholarDigital Library"",""Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, and Tina Eliassi-Rad. 2008. Collective classification in network data. AI magazine (2008).Google Scholar"",""Nino Shervashidze, Pascal Schweitzer, Erik Jan van Leeuwen, Kurt Mehlhorn, and Karsten M. Borgwardt. 2011. Weisfeiler-Lehman Graph Kernels. JMLR (2011).Google Scholar"",""Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. 2018. Graph attention networks. In ICLR.Google Scholar"",""Christopher John Cornish Hellaby Watkins. 1989. Learning from delayed rewards. Ph.D. Dissertation. King's College.Google Scholar"",""Zhongwen Xu, Hado van Hasselt, and David Silver. 2018. Meta-gradient reinforcement learning. In NeurIPS.Google Scholar"",""Jiaxuan You, Bowen Liu, Zhitao Ying, Vijay Pande, and Jure Leskovec. 2018. Graph convolutional policy network for goal-directed molecular graph generation. In NeurIPS.Google Scholar"",""Jiaxuan You, Rex Ying, Xiang Ren, William L Hamilton, and Jure Leskovec. 2018. Graphrnn: Generating realistic graphs with deep auto-regressive models. arXiv preprint arXiv:1802.08773 (2018).Google Scholar"",""Daochen Zha, Kwei-Herng Lai, Yuanpu Cao, Songyi Huang, Ruzhe Wei, Junyu Guo, and Xia Hu. 2019. RLCard: A toolkit for reinforcement learning in card games. arXiv preprint arXiv:1910.04376 (2019).Google Scholar"",""Daochen Zha, Kwei-Herng Lai, Kaixiong Zhou, and Xia Hu. 2019. Experience replay optimization. IJCAI.Google Scholar"",""Jie Zhou, Ganqu Cui, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li, and Maosong Sun. 2018. Graph neural networks: A review of methods and applications. arXiv preprint arXiv:1812.08434 (2018).Google Scholar"",""Kaixiong Zhou, Qingquan Song, Xiao Huang, and Xia Hu. 2019. Auto-GNN: Neural architecture search of graph neural networks. arXiv preprint arXiv:1909.03184 (2019).Google Scholar"",""Kaixiong Zhou, Qingquan Song, Xiao Huang, Daochen Zha, Na Zou, and Xia Hu. 2019. Multi-Channel graph convolutional networks. arXiv preprint arXiv:1912.08306 (2019).Google Scholar"",""Barret Zoph and Quoc V Le. 2016. Neural architecture search with reinforcement learning. arXiv preprint arXiv:1611.01578 (2016).Google Scholar""]"
https://doi.org/10.1145/3394486.3403089,Malicious Attacks against Deep Reinforcement Learning Interpretations,"The past years have witnessed the rapid development of deep reinforcement learning (DRL), which is a combination of deep learning and reinforcement learning (RL). However, the adoption of deep neural networks makes the decision-making process of DRL opaque and lacking transparency. Motivated by this, various interpretation methods for DRL have been proposed. However, those interpretation methods make an implicit assumption that they are performed in a reliable and secure environment. In practice, sequential agent-environment interactions expose the DRL algorithms and their corresponding downstream interpretations to extra adversarial risk. In spite of the prevalence of malicious attacks, there is no existing work studying the possibility and feasibility of malicious attacks against DRL interpretations. To bridge this gap, in this paper, we investigate the vulnerability of DRL interpretation methods. Specifically, we introduce the first study of the adversarial attacks against DRL interpretations, and propose an optimization framework based on which the optimal adversarial attack strategy can be derived. In addition, we study the vulnerability of DRL interpretation methods to the model poisoning attacks, and present an algorithmic framework to rigorously formulate the proposed model poisoning attack. Finally, we conduct both theoretical analysis and extensive experiments to validate the effectiveness of the proposed malicious attacks against DRL interpretations.","[{""name"":""Mengdi Huai"",""id"":""/profile/99659259703""},{""name"":""Jianhui Sun"",""id"":""/profile/99659574869""},{""name"":""Renqin Cai"",""id"":""/profile/99659191153""},{""name"":""Liuyi Yao"",""id"":""/profile/99659364150""},{""name"":""Aidong Zhang"",""id"":""/profile/99659573207""},{""name"":""Mengdi Huai"",""id"":""/profile/99659259703""},{""name"":""Jianhui Sun"",""id"":""/profile/99659574869""},{""name"":""Renqin Cai"",""id"":""/profile/99659191153""},{""name"":""Liuyi Yao"",""id"":""/profile/99659364150""},{""name"":""Aidong Zhang"",""id"":""/profile/99659573207""}]","[""Julius Adebayo, Justin Gilmer, Michael Muelly, Ian Goodfellow, Moritz Hardt, and Been Kim. 2018. Sanity checks for saliency maps. In NeurIPS. 9505--9515.Google Scholar"",""Akanksha Atrey, Kaleigh Clary, and David Jensen. 2019. Exploratory Not Explanatory: Counterfactual Analysis of Saliency Maps for Deep Reinforcement Learning. arXiv preprint arXiv:1912.05743 (2019).Google Scholar"",""Vahid Behzadan and Arslan Munir. 2017. Vulnerability of deep reinforcement learning to policy induction attacks. In International Conference on Machine Learning and Data Mining in Pattern Recognition. Springer, 262--275.Google Scholar"",""Amirata Ghorbani, Abubakar Abid, and James Zou. 2019. Interpretation of neural networks is fragile. In Proceedings of the AAAI Conference on Artificial Intelligence.Google Scholar"",""Sam Greydanus, Anurag Koul, Jonathan Dodge, and Alan Fern. 2017. Visualizing and understanding atari agents. arXiv preprint arXiv:1711.00138 (2017).Google Scholar"",""Mengdi Huai, Di Wang, Chenglin Miao, and Aidong Zhang. 2020. Towards Interpretation of Pairwise Learning. In Thirty-fourth AAAI Conference on Artificial Intelligence.Google Scholar"",""Sandy Huang, Nicolas Papernot, Ian Goodfellow, Yan Duan, and Pieter Abbeel. 2017. Adversarial attacks on neural network policies. arXiv preprint arXiv:1702.02284 (2017).Google Scholar"",""Léonard Hussenot, Matthieu Geist, and Olivier Pietquin. 2019. Targeted Attacks on Deep Reinforcement Learning Agents through Adversarial Observations. arXiv preprint arXiv:1905.12282 (2019).Google Scholar"",""Rahul Iyer, Yuezhang Li, Huao Li, Michael Lewis, Ramitha Sundar, and Katia Sycara. 2018. Transparency and explanation in deep reinforcement learning neural networks. In Proc. of the AAAI/ACM Conference on AI, Ethics, and Society.Google Scholar"",""Michael Kearns and Satinder Singh. 2002. Near-Optimal Reinforcement Learning in Polynomial Time. Mach. Learn. (2002).Google Scholar"",""Pieter-Jan Kindermans, Sara Hooker, Julius Adebayo, Maximilian Alber, Kristof T Schütt, Sven Dahne, Dumitru Erhan, and Been Kim. 2019. The (un) reliability of saliency methods. In Explainable AI: Interpreting, Explaining and Visualizing Deep Learning. Springer, 267--280.Google Scholar"",""Yen-Chen Lin, Zhang-Wei Hong, Yuan-Hong Liao, Meng-Li Shih, Ming-Yu Liu, and Min Sun. 2017. Tactics of adversarial attack on deep reinforcement learning agents. arXiv preprint arXiv:1703.06748 (2017).Google Scholar"",""Chenglin Miao, Qi Li, Lu Su, Mengdi Huai, Wenjun Jiang, and Jing Gao. 2018a. Attack under Disguise: An Intelligent Data Poisoning Attack Mechanism in Crowdsourcing. In Proc. of the 2018 World Wide Web Conference. 13--22.Google Scholar"",""Chenglin Miao, Qi Li, Houping Xiao, Wenjun Jiang, Mengdi Huai, and Lu Su. 2018b. Towards data poisoning attacks in crowd sensing systems. In Proc. of the Eighteenth ACM International Symposium on Mobile Ad Hoc Networking and Computing. 111--120.Google Scholar"",""Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness, Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg Ostrovski, et al. 2015. Human-level control through deep reinforcement learning. Nature, Vol. 518, 7540 (2015), 529.Google Scholar"",""Anay Pattanaik, Zhenyi Tang, Shuijing Liu, Gautham Bommannan, and Girish Chowdhary. 2018. Robust deep reinforcement learning with adversarial attacks. In Proc. of the 17th International Conference on Autonomous Agents and MultiAgent Systems. 2040--2042.Google Scholar"",""Xinghua Qu, Zhu Sun, Pengfei Wei, Yew-Soon Ong, and Abhishek Gupta. 2019. Minimalistic Attacks: How Little it Takes to Fool a Deep Reinforcement Learning Policy. arXiv preprint arXiv:1911.03849 (2019).Google Scholar"",""John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp Moritz. 2015. Trust region policy optimization. In ICML. 1889--1897.Google Scholar"",""Jianwen Sun, Tianwei Zhang, Xiaofei Xie, Lei Ma, Yan Zheng, Kangjie Chen, and Yang Liu. 2020. Stealthy and efficient adversarial attacks against deep reinforcement learning. arXiv preprint arXiv:2005.07099 (2020).Google Scholar"",""Richard S Sutton and Andrew G Barto. 2018. Reinforcement learning: An introduction. MIT press.Google Scholar"",""Ziyu Wang, Tom Schaul, Matteo Hessel, Hado Van Hasselt, Marc Lanctot, and Nando De Freitas. 2015. Dueling network architectures for deep reinforcement learning. arXiv preprint arXiv:1511.06581 (2015).Google Scholar"",""Laurens Weitkamp, Elise van der Pol, and Zeynep Akata. 2018. Visual rationalizations in deep reinforcement learning for atari games. In Benelux Conference on Artificial Intelligence. Springer, 151--165.Google Scholar"",""Kaidi Xu, Sijia Liu, Pu Zhao, Pin-Yu Chen, Huan Zhang, Quanfu Fan, Deniz Erdogmus, Yanzhi Wang, and Xue Lin. 2018. Structured adversarial attack: Towards general implementation and better interpretability. arXiv preprint arXiv:1808.01664 (2018).Google Scholar"",""Liu Yuezhang, Ruohan Zhang, and Dana H Ballard. 2018. An Initial Attempt of Combining Visual Selective Attention with Deep Reinforcement Learning. arXiv preprint arXiv:1811.04407 (2018).Google Scholar"",""Tom Zahavy, Nir Ben-Zrihem, and Shie Mannor. 2016. Graying the black box: Understanding dqns. In ICML. 1899--1908.Google Scholar"",""Xinyang Zhang, Ningfei Wang, Hua Shen, Shouling Ji, Xiapu Luo, and Ting Wang. 2020. Interpretable deep learning under fire. In 29th USENIX Security Symposium (USENIX Security 20).Google Scholar""]"
https://doi.org/10.1145/3394486.3403091,Disentangled Self-Supervision in Sequential Recommenders,"To learn a sequential recommender, the existing methods typically adopt the sequence-to-item (seq2item) training strategy, which supervises a sequence model with a user's next behavior as the label and the user's past behaviors as the input. The seq2item strategy, however, is myopic and usually produces non-diverse recommendation lists. In this paper, we study the problem of mining extra signals for supervision by looking at the longer-term future. There exist two challenges: i) reconstructing a future sequence containing many behaviors is exponentially harder than reconstructing a single next behavior, which can lead to difficulty in convergence, and ii) the sequence of all future behaviors can involve many intentions, not all of which may be predictable from the sequence of earlier behaviors. To address these challenges, we propose a sequence-to-sequence (seq2seq) training strategy based on latent self-supervision and disentanglement. Specifically, we perform self-supervision in the latent space, i.e., reconstructing the representation of the future sequence as a whole, instead of reconstructing the items in the future sequence individually. We also disentangle the intentions behind any given sequence of behaviors and construct seq2seq training samples using only pairs of sub-sequences that involve a shared intention. Results on real-world benchmarks and synthetic data demonstrate the improvement brought by seq2seq training.","[{""name"":""Jianxin Ma"",""id"":""/profile/99659286785""},{""name"":""Chang Zhou"",""id"":""/profile/99659371467""},{""name"":""Hongxia Yang"",""id"":""/profile/99659259298""},{""name"":""Peng Cui"",""id"":""/profile/81413596063""},{""name"":""Xin Wang"",""id"":""/profile/99659217638""},{""name"":""Wenwu Zhu"",""id"":""/profile/99659586535""},{""name"":""Jianxin Ma"",""id"":""/profile/99659286785""},{""name"":""Chang Zhou"",""id"":""/profile/99659371467""},{""name"":""Hongxia Yang"",""id"":""/profile/99659259298""},{""name"":""Peng Cui"",""id"":""/profile/81413596063""},{""name"":""Xin Wang"",""id"":""/profile/99659217638""},{""name"":""Wenwu Zhu"",""id"":""/profile/99659586535""}]","[""Yoshua Bengio, Aaron Courville, and Pascal Vincent. 2013. Representation learning: A review and new perspectives. IEEE transactions on pattern analysis and machine intelligence, Vol. 35, 8 (2013), 1798--1828.Google Scholar"",""Diane Bouchacourt, Ryota Tomioka, and Sebastian Nowozin. 2018. Multi-level variational autoencoder: Learning disentangled representations from grouped observations. In Thirty-Second AAAI Conference on Artificial Intelligence.Google Scholar"",""Christopher P Burgess, Irina Higgins, Arka Pal, Loic Matthey, Nick Watters, Guillaume Desjardins, and Alexander Lerchner. 2018. Understanding disentangling in $beta $-VAE. arXiv preprint arXiv:1804.03599 (2018).Google Scholar"",""Minmin Chen, Alex Beutel, Paul Covington, Sagar Jain, Francois Belletti, and Ed H Chi. 2019. Top-k off-policy correction for a REINFORCE recommender system. In Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining. 456--464.Google Scholar"",""Tian Qi Chen, Xuechen Li, Roger B Grosse, and David K Duvenaud. 2018a. Isolating sources of disentanglement in variational autoencoders. In Advances in Neural Information Processing Systems. 2610--2620.Google Scholar"",""Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. 2016. Infogan: Interpretable representation learning by information maximizing generative adversarial nets. In NIPS 2016.Google Scholar"",""Xu Chen, Hongteng Xu, Yongfeng Zhang, Jiaxi Tang, Yixin Cao, Zheng Qin, and Hongyuan Zha. 2018b. Sequential recommendation with user memory networks. In Proceedings of WSDM 2018.Google Scholar"",""Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep neural networks for youtube recommendations. In Proceedings of the 10th ACM Conference on Recommender Systems. ACM, 191--198.Google Scholar"",""Mukund Deshpande and George Karypis. 2004. Item-based top-n recommendation algorithms. ACM TOIS, Vol. 22, 1 (2004), 143--177.Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).Google Scholar"",""Nat Dilokthanakul, Pedro AM Mediano, Marta Garnelo, Matthew CH Lee, Hugh Salimbeni, Kai Arulkumaran, and Murray Shanahan. 2016. Deep unsupervised clustering with gaussian mixture variational autoencoders. arXiv preprint arXiv:1611.02648 (2016).Google Scholar"",""Emilien Dupont. 2018. Learning disentangled joint continuous and discrete representations. In Advances in Neural Information Processing Systems. 710--720.Google Scholar"",""Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. 2019. Momentum contrast for unsupervised visual representation learning. arXiv preprint arXiv:1911.05722 (2019).Google Scholar"",""Ruining He, Chen Fang, Zhaowen Wang, and Julian McAuley. 2016. Vista: a visually, socially, and temporally-aware model for artistic recommendation. In Proceedings of the 10th ACM Conference on Recommender Systems. 309--316.Google Scholar"",""Ruining He, Wang-Cheng Kang, and Julian McAuley. 2017a. Translation-based recommendation. In Proceedings of ACM RecSys 2017.Google Scholar"",""Ruining He and Julian McAuley. 2016. Fusing similarity models with markov chains for sparse sequential recommendation. In 2016 IEEE 16th International Conference on Data Mining (ICDM). IEEE, 191--200.Google Scholar"",""Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017b. Neural Collaborative Filtering. In Proceedings of WWW 2017.Google Scholar"",""Balázs Hidasi and Alexandros Karatzoglou. 2018. Recurrent neural networks with top-k gains for session-based recommendations. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management. 843--852.Google Scholar"",""Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2015. Session-based recommendations with recurrent neural networks. arXiv preprint arXiv:1511.06939 (2015).Google Scholar"",""Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. 2017. beta-vae: Learning basic visual concepts with a constrained variational framework. In International Conference on Learning Representations, Vol. 3.Google Scholar"",""R Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil Bachman, Adam Trischler, and Yoshua Bengio. 2018. Learning deep representations by mutual information estimation and maximization. arXiv preprint arXiv:1808.06670 (2018).Google Scholar"",""Yifan Hu, Yehuda Koren, and Chris Volinsky. 2008. Collaborative filtering for implicit feedback datasets. In 2008 Eighth IEEE International Conference on Data Mining. Ieee, 263--272.Google Scholar"",""Jin Huang, Wayne Xin Zhao, Hongjian Dou, Ji-Rong Wen, and Edward Y Chang. 2018. Improving sequential recommendation with knowledge-enhanced memory networks. In SIGIR 2018.Google Scholar"",""Zhuxi Jiang, Yin Zheng, Huachun Tan, Bangsheng Tang, and Hanning Zhou. 2017. Variational deep embedding: an unsupervised and generative approach to clustering. In Proceedings of IJCAI 2017.Google Scholar"",""Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recommendation. In ICDM 2018.Google Scholar"",""Hyunjik Kim and Andriy Mnih. 2018. Disentangling by Factorising. In International Conference on Machine Learning. 2654--2663.Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. In International Conference for Learning Representations.Google Scholar"",""Diederik P Kingma and Max Welling. 2013. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 (2013).Google Scholar"",""Yehuda Koren, Robert Bell, Chris Volinsky, et al. 2009. Matrix factorization techniques for recommender systems. Computer, Vol. 42, 8 (2009), 30--37.Google Scholar"",""Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, and Jun Ma. 2017. Neural attentive session-based recommendation. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management. 1419--1428.Google Scholar"",""Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, and Kai-Wei Chang. 2019. Visualbert: A simple and performant baseline for vision and language. arXiv preprint arXiv:1908.03557 (2019).Google Scholar"",""Xiaopeng Li and James She. 2017. Collaborative variational autoencoder for recommender systems. In Proceedings of SIGKDD 2017.Google Scholar"",""Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara. 2018. Variational Autoencoders for Collaborative Filtering. In Proceedings of WWW 2018.Google Scholar"",""Ninghao Liu, Qiaoyu Tan, Yuening Li, Hongxia Yang, Jingren Zhou, and Xia Hu. 2019. Is a Single Vector Enough? Exploring Node Polysemy for Network Embedding. In Proceedings of SIGKDD 2019.Google Scholar"",""Qiang Liu, Shu Wu, Diyi Wang, Zhaokang Li, and Liang Wang. 2016. Context-aware sequential recommendation. In 2016 IEEE 16th International Conference on Data Mining (ICDM). IEEE, 1053--1058.Google Scholar"",""Qiao Liu, Yifu Zeng, Refuoe Mokhosi, and Haibin Zhang. 2018. STAMP: short-term attention/memory priority model for session-based recommendation. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1831--1839.Google Scholar"",""Jianxin Ma, Peng Cui, Kun Kuang, Xin Wang, and Wenwu Zhu. 2019 a. Disentangled Graph Convolutional Networks. In Proceedings of the 36th International Conference on Machine Learning (ICML 2019).Google Scholar"",""Jianxin Ma, Chang Zhou, Peng Cui, Hongxia Yang, and Wenwu Zhu. 2019 b. Learning disentangled representations for recommendation. In Advances in Neural Information Processing Systems. 5712--5723.Google Scholar"",""Ishan Misra, C Lawrence Zitnick, and Martial Hebert. 2016. Shuffle and learn: unsupervised learning using temporal order verification. In European Conference on Computer Vision. Springer, 527--544.Google Scholar"",""Mehdi Noroozi and Paolo Favaro. 2016. Unsupervised learning of visual representations by solving jigsaw puzzles. In European Conference on Computer Vision. Springer, 69--84.Google Scholar"",""Aaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018. Representation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748 (2018).Google Scholar"",""Steffen Rendle. 2019. Evaluation Metrics for Item Recommendation under Sampling.Google Scholar"",""Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian personalized ranking from implicit feedback. In Proceedings of the twenty-fifth conference on uncertainty in artificial intelligence.Google Scholar"",""Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Factorizing personalized markov chains for next-basket recommendation. In Proceedings of the 19th international conference on World wide web. 811-820.Google Scholar"",""Paul Resnick, Neophytos Iacovou, Mitesh Suchak, Peter Bergstrom, and John Riedl. 1994. GroupLens: an open architecture for collaborative filtering of netnews. In Proceedings of the 1994 ACM conference on Computer supported cooperative work. ACM, 175?186.Google Scholar"",""Ruslan Salakhutdinov and Andriy Mnih. 2011. Probabilistic matrix factorization. In NIPS, Vol. 20. 1-8.Google Scholar"",""Badrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. 2001. Item-based collaborative filtering recommendation algorithms. In Proceedings of the 10th international conference on World Wide Web. ACM, 285?295.Google Scholar"",""Kihyuk Sohn. 2016. Improved deep metric learning with multi-class n-pair loss objective. In Advances in Neural Information Processing Systems. 1857?-1865.Google Scholar"",""Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer. In Proceedings of CIKM 2019.Google Scholar"",""Jiaxi Tang and Ke Wang. 2018. Personalized top-n sequential recommendation via convolutional sequence embedding. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. 565-573.Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998-6008.Google Scholar"",""Hao Wang, Naiyan Wang, and Dit-Yan Yeung. 2015. Collaborative deep learning for recommender systems. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 1235-1244.Google Scholar"",""Pengfei Wang, Jiafeng Guo, Yanyan Lan, Jun Xu, Shengxian Wan, and Xueqi Cheng. 2015. Learning hierarchical representation model for next basket recommendation. In Proceedings of SIGIR 2015.Google Scholar"",""Chao-Yuan Wu, Amr Ahmed, Alex Beutel, Alexander J Smola, and How Jing. 2017. Recurrent recommender networks. In Proceedings of the tenth ACM international conference on web search and data mining. 495-503.Google Scholar"",""Zhirong Wu, Yuanjun Xiong, Stella X Yu, and Dahua Lin. 2018. Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 3733-3742.Google Scholar"",""Feng Yu, Qiang Liu, Shu Wu, Liang Wang, and Tieniu Tan. 2016. A dynamic recurrent model for next basket recommendation. In Proceedings of SIGIR 2016.Google Scholar"",""Richard Zhang, Phillip Isola, and Alexei A Efros. 2016. Colorful image colorization. In European conference on computer vision. Springer, 649-666.Google Scholar"",""Chang Zhou, Jinze Bai, Junshuai Song, Xiaofei Liu, Zhengchao Zhao, Xiusi Chen, and Jun Gao. 2018. ATRank: An attention-based user behavior modeling frame-work for recommendation. In AAAI 2018.Google Scholar"",""Chang Zhou, Jianxin Ma, Jianwei Zhang, Jingren Zhou, and Hongxia Yang. 2020. Contrastive Learning for Debiased Candidate Generation in Large-Scale Recommender Systems. arXiv: arXiv: 2005.12964Google Scholar""]"
https://doi.org/10.1145/3394486.3403092,DETERRENT: Knowledge Guided Graph Attention Network for Detecting Healthcare Misinformation,"To provide accurate and explainable misinformation detection, it is often useful to take an auxiliary source (e.g., social context and knowledge base) into consideration. Existing methods use social contexts such as users' engagements as complementary information to improve detection performance and derive explanations. However, due to the lack of sufficient professional knowledge, users seldom respond to healthcare information, which makes these methods less applicable. In this work, to address these shortcomings, we propose a novel knowledge guided graph attention network for detecting health misinformation better. Our proposal, named as DETERRENT, leverages on the additional information from medical knowledge graph by propagating information along with the network, incorporates a Medical Knowledge Graph and an Article-Entity Bipartite Graph, and propagates the node embeddings through Knowledge Paths. In addition, an attention mechanism is applied to calculate the importance of entities to each article, and the knowledge guided article embeddings are used for misinformation detection. DETERRENT addresses the limitation on social contexts in the healthcare domain and is capable of providing useful explanations for the results of detection. Empirical validation using two real-world datasets demonstrated the effectiveness of DETERRENT. Comparing with the best results of eight competing methods, in terms of F1 Score, DETERRENT outperforms all methods by at least 4.78% on the diabetes dataset and 12.79% on cancer dataset. We release the source code of DETERRENT at: https://github.com/cuilimeng/DETERRENT.","[{""name"":""Limeng Cui"",""id"":""/profile/99659573248""},{""name"":""Haeseung Seo"",""id"":""/profile/99659443244""},{""name"":""Maryam Tabar"",""id"":""/profile/99659574918""},{""name"":""Fenglong Ma"",""id"":""/profile/99659575182""},{""name"":""Suhang Wang"",""id"":""/profile/99659577116""},{""name"":""Dongwon Lee"",""id"":""/profile/81452592724""},{""name"":""Limeng Cui"",""id"":""/profile/99659573248""},{""name"":""Haeseung Seo"",""id"":""/profile/99659443244""},{""name"":""Maryam Tabar"",""id"":""/profile/99659574918""},{""name"":""Fenglong Ma"",""id"":""/profile/99659575182""},{""name"":""Suhang Wang"",""id"":""/profile/99659577116""},{""name"":""Dongwon Lee"",""id"":""/profile/81452592724""}]","[""Hunt Allcott and Matthew Gentzkow. 2017. Social media and fake news in the 2016 election. Journal of economic perspectives, Vol. 31, 2 (2017), 211--36.Google ScholarCross Ref"",""Gabor Angeli, Melvin Jose Johnson Premkumar, and Christopher D Manning. 2015. Leveraging linguistic structure for open domain information extraction. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 344--354.Google ScholarCross Ref"",""Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473 (2014).Google Scholar"",""Gaurav Bhatt, Aman Sharma, Shivam Sharma, Ankush Nagpal, Balasubramanian Raman, and Ankush Mittal. 2018. Combining neural, statistical and external features for fake news stance identification. In Companion Proceedings of the The Web Conference 2018. 1353--1357.Google ScholarDigital Library"",""Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko. 2013. Translating embeddings for modeling multi-relational data. In Advances in neural information processing systems. 2787--2795.Google Scholar"",""Dan Busbridge, Dane Sherburn, Pietro Cavallo, and Nils Y Hammerla. 2019. Relational Graph Attention Networks. arXiv preprint arXiv:1904.05811 (2019).Google Scholar"",""Giovanni Luca Ciampaglia, Prashant Shiralkar, Luis M Rocha, Johan Bollen, Filippo Menczer, and Alessandro Flammini. 2015. Computational fact checking from knowledge networks. PloS one, Vol. 10, 6 (2015).Google Scholar"",""Limeng Cui, Kai Shu, Suhang Wang, Dongwon Lee, and Huan Liu. 2019 a. dEFEND: A System for Explainable Fake News Detection. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management. 2961--2964.Google ScholarDigital Library"",""Limeng Cui, Suhang Wang, and Dongwon Lee. 2019 b. SAME: sentiment-aware multi-modal embedding for detecting fake news. In Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining. 41--48.Google ScholarDigital Library"",""Tyler Derr, Yao Ma, and Jiliang Tang. 2018. Signed graph convolutional networks. In 2018 IEEE International Conference on Data Mining (ICDM). IEEE, 929--934.Google ScholarCross Ref"",""Patrick Ernst, Amy Siu, and Gerhard Weikum. 2015. KnowLife: a versatile approach for constructing a large knowledge graph for biomedical sciences. BMC bioinformatics, Vol. 16, 1 (2015), 157.Google Scholar"",""Gunther Eysenbach, John Powell, Oliver Kuss, and Eun-Ryoung Sa. 2002. Empirical studies assessing the quality of health information for consumers on the world wide web: a systematic review. Jama, Vol. 287, 20 (2002), 2691--2700.Google ScholarCross Ref"",""Han Guo, Juan Cao, Yazi Zhang, Junbo Guo, and Jintao Li. 2018. Rumor detection with hierarchical social attention network. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management. 943--951.Google ScholarDigital Library"",""Fritz Heider. 1946. Attitudes and cognitive organization. The Journal of psychology, Vol. 21, 1 (1946), 107--112.Google ScholarCross Ref"",""Viet-Phi Huynh and Paolo Papotti. 2019. A Benchmark for Fact Checking Algorithms Built on Knowledge Bases. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management. 689--698.Google ScholarDigital Library"",""Zhiwei Jin, Juan Cao, Yongdong Zhang, and Jiebo Luo. 2016. News verification by exploiting conflicting social viewpoints in microblogs. In Thirtieth AAAI conference on artificial intelligence .Google ScholarDigital Library"",""Georgios Karagiannis, Immanuel Trummer, Saehan Jo, Shubham Khandelwal, Xuezhi Wang, and Cong Yu. 2019. Mining an \""anti-knowledge base\"" from Wikipedia updates with applications to fact checking and beyond. Proceedings of the VLDB Endowment, Vol. 13, 4 (2019), 561--573.Google ScholarDigital Library"",""Yoon Kim. 2014. Convolutional Neural Networks for Sentence Classification. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). 1746--1751.Google ScholarCross Ref"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).Google Scholar"",""Quoc Le and Tomas Mikolov. 2014. Distributed representations of sentences and documents. In International conference on machine learning. 1188--1196.Google ScholarDigital Library"",""Jure Leskovec, Daniel Huttenlocher, and Jon Kleinberg. 2010a. Predicting positive and negative links in online social networks. In Proceedings of the 19th international conference on World wide web. 641--650.Google ScholarDigital Library"",""Jure Leskovec, Daniel Huttenlocher, and Jon Kleinberg. 2010b. Signed networks in social media. In Proceedings of the SIGCHI conference on human factors in computing systems. 1361--1370.Google ScholarDigital Library"",""Hu Linmei, Tianchi Yang, Chuan Shi, Houye Ji, and Xiaoli Li. 2019. Heterogeneous graph attention networks for semi-supervised short text classification. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 4823--4832.Google ScholarCross Ref"",""Amy Nguyen, Sasan Mosadeghi, and Christopher V Almario. 2017. Persistent digital divide in access to and use of the Internet as a resource for health information: Results from a California population-based study. International journal of medical informatics, Vol. 103 (2017), 49--54.Google Scholar"",""Shivam B Parikh and Pradeep K Atrey. 2018. Media-rich fake news detection: A survey. In 2018 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR). IEEE, 436--441.Google ScholarCross Ref"",""Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. 2011. Scikit-learn: Machine learning in Python. Journal of machine learning research, Vol. 12, Oct (2011), 2825--2830.Google ScholarDigital Library"",""Martin Potthast, Johannes Kiesel, Kevin Reinartz, Janek Bevendorff, and Benno Stein. 2017. A stylometric inquiry into hyperpartisan and fake news. arXiv preprint arXiv:1702.05638 (2017).Google Scholar"",""Hannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana Volkova, and Yejin Choi. 2017. Truth of varying shades: Analyzing language in fake news and political fact-checking. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. 2931--2937.Google ScholarCross Ref"",""Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian personalized ranking from implicit feedback. In Proceedings of the twenty-fifth conference on uncertainty in artificial intelligence. AUAI Press, 452--461.Google ScholarDigital Library"",""Natali Ruchansky, Sungyong Seo, and Yan Liu. 2017. Csi: A hybrid deep model for fake news detection. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management. ACM, 797--806.Google ScholarDigital Library"",""Daniel Scanfeld, Vanessa Scanfeld, and Elaine L Larson. 2010. Dissemination of health information through social networks: Twitter and antibiotics. American journal of infection control, Vol. 38, 3 (2010), 182--188.Google Scholar"",""Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. 2009. The Graph Neural Network Model. IEEE Transactions on Neural Networks, Vol. 20, 1 (2009), 61--80.Google ScholarDigital Library"",""Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den Berg, Ivan Titov, and Max Welling. 2018. Modeling relational data with graph convolutional networks. In European Semantic Web Conference. Springer, 593--607.Google ScholarCross Ref"",""Baoxu Shi and Tim Weninger. 2016. Discriminative predicate path mining for fact checking in knowledge graphs. Knowledge-based systems, Vol. 104 (2016), 123--133.Google Scholar"",""Kai Shu, Limeng Cui, Suhang Wang, Dongwon Lee, and Huan Liu. 2019. defend: Explainable fake news detection. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 395--405.Google ScholarDigital Library"",""Jizhi Tang, Yansong Feng, and Dongyan Zhao. 2019. Learning to Update Knowledge Graphs by Reading News. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2632--2641.Google ScholarCross Ref"",""Christopher C Tsai, SH Tsai, Q Zeng-Treitler, and BA Liang. 2007. Patient-centered consumer health social network websites: a pilot study of quality of user-generated health information. In AMIA Annu Symp Proc, Vol. 1137.Google Scholar"",""Sebastian Tschiatschek, Adish Singla, Manuel Gomez Rodriguez, Arpit Merchant, and Andreas Krause. 2018. Fake news detection in social networks via crowd signals. In Companion Proceedings of the The Web Conference 2018. 517--524.Google ScholarDigital Library"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. 2018. Graph Attention Networks. International Conference on Learning Representations (2018).Google Scholar"",""Soroush Vosoughi, Deb Roy, and Sinan Aral. 2018. The spread of true and false news online. Science, Vol. 359, 6380 (2018), 1146--1151.Google Scholar"",""Yaqing Wang, Fenglong Ma, Zhiwei Jin, Ye Yuan, Guangxu Xun, Kishlay Jha, Lu Su, and Jing Gao. 2018. Eann: Event adversarial neural networks for multi-modal fake news detection. In Proceedings of the 24th acm sigkdd international conference on knowledge discovery \u0026 data mining. 849--857.Google ScholarDigital Library"",""Jie Zhou, Ganqu Cui, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li, and Maosong Sun. 2018. Graph neural networks: A review of methods and applications. arXiv preprint arXiv:1812.08434 (2018).Google Scholar""]"
https://doi.org/10.1145/3394486.3403093,MultiImport: Inferring Node Importance in a Knowledge Graph from Multiple Input Signals,"Given multiple input signals, how can we infer node importance in a knowledge graph (KG)? Node importance estimation is a crucial and challenging task that can benefit a lot of applications including recommendation, search, and query disambiguation. A key challenge towards this goal is how to effectively use input from different sources. On the one hand, a KG is a rich source of information, with multiple types of nodes and edges. On the other hand, there are external input signals, such as the number of votes or pageviews, which can directly tell us about the importance of entities in a KG. While several methods have been developed to tackle this problem, their use of these external signals has been limited as they are not designed to consider multiple signals simultaneously. In this paper, we develop an end-to-end model MultiImport, which infers latent node importance from multiple, potentially overlapping, input signals. MultiImport is a latent variable model that captures the relation between node importance and input signals, and effectively learns from multiple signals with potential conflicts. Also, MultiImport provides an effective estimator based on attentive graph neural networks. We ran experiments on real-world KGs to show that MultiImport handles several challenges involved with inferring node importance from multiple input signals, and consistently outperforms existing methods, achieving up to 23.7% higher [email protected] than the state-of-the-art method.","[{""name"":""Namyong Park"",""id"":""/profile/99659452617""},{""name"":""Andrey Kan"",""id"":""/profile/81548396856""},{""name"":""Xin Luna Dong"",""id"":""/profile/99659531494""},{""name"":""Tong Zhao"",""id"":""/profile/99659452891""},{""name"":""Christos Faloutsos"",""id"":""/profile/81100373169""},{""name"":""Namyong Park"",""id"":""/profile/99659452617""},{""name"":""Andrey Kan"",""id"":""/profile/81548396856""},{""name"":""Xin Luna Dong"",""id"":""/profile/99659531494""},{""name"":""Tong Zhao"",""id"":""/profile/99659452891""},{""name"":""Christos Faloutsos"",""id"":""/profile/81100373169""}]","[""Kurt D. Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: a collaboratively created graph database for structuring human knowledge. In SIGMOD. 1247--1250.Google Scholar"",""Antoine Bordes, Nicolas Usunier, Alberto Garc'i a-Durá n, Jason Weston, and Oksana Yakhnenko. 2013. Translating Embeddings for Modeling Multi-relational Data. In NIPS. 2787--2795.Google Scholar"",""Zhe Cao, Tao Qin, Tie-Yan Liu, Ming-Feng Tsai, and Hang Li. 2007. Learning to rank: from pairwise approach to listwise approach. In ICML. 129--136.Google Scholar"",""Xin Dong, Laure Berti-É quille, Yifan Hu, and Divesh Srivastava. 2010. Global Detection of Complex Copying Relationships Between Sources. Proc. VLDB Endow., Vol. 3, 1 (2010), 1358--1369.Google ScholarDigital Library"",""Xin Luna Dong, Laure Berti-É quille, and Divesh Srivastava. 2009. Integrating Conflicting Data: The Role of Source Dependence. Proc. VLDB Endow., Vol. 2, 1 (2009).Google ScholarDigital Library"",""Martin Ester, Hans-Peter Kriegel, Jö rg Sander, and Xiaowei Xu. 1996. A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise. In KDD. 226--231.Google Scholar"",""Justin Gilmer, Samuel S. Schoenholz, Patrick F. Riley, Oriol Vinyals, and George E. Dahl. 2017. Neural Message Passing for Quantum Chemistry. In ICML. 1263--1272.Google Scholar"",""Taher H. Haveliwala. 2002. Topic-sensitive PageRank. In WWW. 517--526.Google Scholar"",""Jinhong Jung, Namyong Park, Lee Sael, and U. Kang. 2017. BePI: Fast and Memory-Efficient Method for Billion-Scale Random Walk with Restart. In SIGMOD.Google Scholar"",""Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In ICLR.Google Scholar"",""Jon M. Kleinberg. 1999. Authoritative Sources in a Hyperlinked Environment. J. ACM, Vol. 46, 5 (1999), 604--632.Google ScholarDigital Library"",""Tamara G. Kolda and Brett W. Bader. 2009. Tensor Decompositions and Applications. SIAM Rev., Vol. 51, 3 (2009), 455--500.Google ScholarDigital Library"",""John Boaz Lee, Ryan A. Rossi, and Xiangnan Kong. 2018. Graph Classification using Structural Attention. KDD. 1666--1674.Google Scholar"",""Jens Lehmann, Robert Isele, Max Jakob, Anja Jentzsch, Dimitris Kontokostas, Pablo N. Mendes, Sebastian Hellmann, Mohamed Morsey, Patrick van Kleef, Sören Auer, and Christian Bizer. 2015. DBpedia - A large-scale, multilingual knowledge base extracted from Wikipedia. Semantic Web, Vol. 6, 2 (2015), 167--195.Google ScholarCross Ref"",""Xutao Li, Michael K. Ng, and Yunming Ye. 2012. HAR: Hub, Authority and Relevance Scores in Multi-Relational Data for Query Search. In SDM. 141--152.Google Scholar"",""Sejoon Oh, Namyong Park, Jun-Gi Jang, Lee Sael, and U Kang. 2019. High-Performance Tucker Factorization on Heterogeneous Platforms. IEEE TPDS., Vol. 30, 10 (2019), 2237--2248.Google Scholar"",""Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. 1999. The PageRank citation ranking: Bringing order to the web. Technical Report. Stanford InfoLab.Google Scholar"",""Namyong Park, ByungSoo Jeon, Jungwoo Lee, and U Kang. 2016. BIGtensor: Mining Billion-Scale Tensor Made Easy. CIKM. 2457--2460.Google Scholar"",""Namyong Park, Andrey Kan, Xin Luna Dong, Tong Zhao, and Christos Faloutsos. 2019 a. Estimating Node Importance in Knowledge Graphs Using Graph Neural Networks. In KDD. 596--606.Google Scholar"",""Namyong Park, Sejoon Oh, and U Kang. 2017. Fast and Scalable Distributed Boolean Tensor Factorization. In ICDE. 1071--1082.Google Scholar"",""Namyong Park, Sejoon Oh, and U Kang. 2019 b. Fast and scalable method for distributed Boolean tensor factorization. VLDB J., Vol. 28, 4 (2019), 549--574.Google ScholarCross Ref"",""Aravind Subramanian, Pablo Tamayo, Vamsi K Mootha, Sayan Mukherjee, Benjamin L Ebert, Michael A Gillette, Amanda Paulovich, Scott L Pomeroy, Todd R Golub, Eric S Lander, et al. 2005. Gene set enrichment analysis: a knowledge-based approach for interpreting genome-wide expression profiles. Proceedings of the National Academy of Sciences, Vol. 102, 43 (2005), 15545--15550.Google ScholarCross Ref"",""Hanghang Tong, Christos Faloutsos, and Jia-Yu Pan. 2008. Random walk with restart: fast solutions and applications. Knowl. Inf. Syst., Vol. 14, 3 (2008), 327--346.Google ScholarDigital Library"",""Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. 2018. Graph Attention Networks. In ICLR.Google Scholar"",""Quan Wang, Zhendong Mao, Bin Wang, and Li Guo. 2017. Knowledge Graph Embedding: A Survey of Approaches and Applications. IEEE TKDE, Vol. 29, 12 (2017).Google ScholarCross Ref"",""Qitian Wu, Hengrui Zhang, Xiaofeng Gao, Peng He, Paul Weng, Han Gao, and Guihai Chen. 2019. Dual Graph Attention Networks for Deep Latent Representation of Multifaceted Social Effects in Recommender Systems. In WWW.Google Scholar"",""Keyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi, and Stefanie Jegelka. 2018. Representation Learning on Graphs with Jumping Knowledge Networks. In ICML. 5449--5458.Google Scholar"",""Xiaoxin Yin, Jiawei Han, and Philip S. Yu. 2008. Truth Discovery with Multiple Conflicting Information Providers on the Web. IEEE TKDE, Vol. 20, 6 (2008), 796--808.Google Scholar"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L. Hamilton, and Jure Leskovec. 2018. Graph Convolutional Neural Networks for Web-Scale Recommender Systems. In KDD. 974--983.Google Scholar"",""Wen Zhang, Bibek Paudel, Liang Wang, Jiaoyan Chen, Hai Zhu, Wei Zhang, Abraham Bernstein, and Huajun Chen. 2019. Iteratively Learning Embeddings and Rules for Knowledge Graph Reasoning. In WWW. 2366--2377.Google Scholar""]"
https://doi.org/10.1145/3394486.3403094,Geodesic Forests,"Together with the curse of dimensionality, nonlinear dependencies in large data sets persist as major challenges in data mining tasks. A reliable way to accurately preserve nonlinear structure is to compute geodesic distances between data points. Manifold learning methods, such as Isomap, aim to preserve geodesic distances in a Riemannian manifold. However, as manifold learning algorithms operate on the ambient dimensionality of the data, the essential step of geodesic distance computation is sensitive to high-dimensional noise. Therefore, a direct application of these algorithms to high-dimensional, noisy data often yields unsatisfactory results and does not accurately capture nonlinear structure.We propose an unsupervised random forest approach called geodesic forests (GF) to geodesic distance estimation in linear and nonlinear manifolds with noise. GF operates on low-dimensional sparse linear combinations of features, rather than the full observed dimensionality. To choose the optimal split in a computationally efficient fashion, we developed Fast-BIC, a fast Bayesian Information Criterion statistic for Gaussian mixture models.We additionally propose geodesic precision and geodesic recall as novel evaluation metrics that quantify how well the geodesic distances of a latent manifold are preserved. Empirical results on simulated and real data demonstrate that GF is robust to high-dimensional noise, whereas other methods, such as Isomap, UMAP, and FLANN, quickly deteriorate in such settings. Notably, GF is able to estimate geodesic distances better than other approaches on a real connectome dataset.","[{""name"":""Meghana Madhyastha"",""id"":""/profile/99659573790""},{""name"":""Gongkai Li"",""id"":""/profile/99659574003""},{""name"":""Veronika Strnadová-Neeley"",""id"":""/profile/99658746200""},{""name"":""James Browne"",""id"":""/profile/99659574517""},{""name"":""Joshua T. Vogelstein"",""id"":""/profile/81470654984""},{""name"":""Randal Burns"",""id"":""/profile/81100421114""},{""name"":""Carey E. Priebe"",""id"":""/profile/81100176044""},{""name"":""Meghana Madhyastha"",""id"":""/profile/99659573790""},{""name"":""Gongkai Li"",""id"":""/profile/99659574003""},{""name"":""Veronika Strnadová-Neeley"",""id"":""/profile/99658746200""},{""name"":""James Browne"",""id"":""/profile/99659574517""},{""name"":""Joshua T. Vogelstein"",""id"":""/profile/81470654984""},{""name"":""Randal Burns"",""id"":""/profile/81100421114""},{""name"":""Carey E. Priebe"",""id"":""/profile/81100176044""}]","[""David Arthur and Sergei Vassilvitskii. 2007. k-means+: The advantages of careful seeding. In Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms. dl.acm.org, 1027--1035. https://dl.acm.org/citation.cfm?id=128338Google Scholar"",""Martin Aumüller, Erik Bernhardsson, and Alexander Faithfull. 2017. ANN-Benchmarks: A Benchmarking Tool for Approximate Nearest Neighbor Algorithms. In Similarity Search and Applications. Springer International Publishing, 34--49. https://doi.org/10.1007/978--3--319--68474--1_3Google Scholar"",""Matej Balog, Balaji Lakshminarayanan, Zoubin Ghahramani, Daniel M Roy, and Yee Whye Teh. 2016. The Mondrian Kernel. (June 2016). arxiv: stat.ML/1606.05241 http://arxiv.org/abs/1606.05241Google Scholar"",""Mikhail Belkin and Partha Niyogi. 2002. Laplacian eigenmaps and spectral techniques for embedding and clustering. In Advances in neural information processing systems. 585--591.Google Scholar"",""G AvS rard Biau, Luc Devroye, and G AkA bor Lugosi. 2008. Consistency of random forests and other averaging classifiers. Journal of Machine Learning Research, Vol. 9, Sep (2008), 2015--2033.Google ScholarDigital Library"",""Leo Breiman. 2000. Some infinity theory for predictor ensembles. Technical Report. Technical Report 579, Statistics Dept. UCB. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.24.7078\u0026rep=rep1\u0026type=pdfGoogle Scholar"",""Leo Breiman. 2001. Random forests. Machine learning, Vol. 45, 1 (2001), 5--32.Google Scholar"",""Leo Breiman, Jerome Friedman, Charles J Stone, and R A Olshen. 1984. Classification and Regression Trees (Wadsworth Statistics/Probability) 1 edition ed.). Chapman and Hall/CRC. https://www.amazon.com/Classification-Regression-Wadsworth-Statistics-Probability/dp/0412048418Google Scholar"",""Rich Caruana, Nikos Karampatziakis, and Ainur Yessenalina. 2008. An empirical evaluation of supervised learning in high dimensions. In Proceedings of the 25th international conference on Machine learning. ACM, New York, New York, USA, 96--103. https://doi.org/10.1145/1390156.1390169Google ScholarDigital Library"",""Rich Caruana and Alexandru Niculescu-Mizil. 2006. An Empirical Comparison of Supervised Learning Algorithms. In Proceedings of the 23rd International Conference on Machine Learning (Pittsburgh, Pennsylvania, USA) (ICML '06). ACM, New York, NY, USA, 161--168. https://doi.org/10.1145/1143844.1143865Google ScholarDigital Library"",""Tianqi Chen and Carlos Guestrin. 2016. XGBoost: A Scalable Tree Boosting System. In Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (San Francisco, California, USA) (KDD '16). ACM, New York, NY, USA, 785--794. https://doi.org/10.1145/2939672.2939785Google ScholarDigital Library"",""Ronald R Coifman and S Lafon. 2006. Diffusion maps. Appl. Comput. Harmon. Anal., Vol. 21, 1 (July 2006), 5--30.Google ScholarCross Ref"",""A Criminisi and J Shotton. 2013. Manifold forests. In Decision Forests for Computer Vision and Medical Image Analysis. Springer, 79--93.Google Scholar"",""Sanjoy Dasgupta and Yoav Freund. 2008a. Random projection trees and low dimensional manifolds.. In STOC, Vol. 8. Citeseer, 537--546.Google ScholarDigital Library"",""Sanjoy Dasgupta and Yoav Freund. 2008b. Random projection trees and low dimensional manifolds.. In STOC, Vol. 8. Citeseer, 537--546.Google ScholarDigital Library"",""Sanjoy Dasgupta and Yoav Freund. 2008c. Random projection trees for vector quantization. IEEE Trans. Inf. Theory 7 (May 2008), 3229--3242. arxiv: stat.ML/0805.1390 http://arxiv.org/abs/0805.1390Google Scholar"",""Alex Davies and Zoubin Ghahramani. 2014. The Random Forest Kernel and other kernels for big data from random partitions. (Feb. 2014). arxiv: stat.ML/1402.4293 http://arxiv.org/abs/1402.4293Google Scholar"",""Luc Devroye, Laszlo Györfi, and Gabor Lugosi. 1997. A Probabilistic Theory of Pattern Recognition (Stochastic Modelling and Applied Probability) corrected edition ed.). Springer.Google Scholar"",""David L Donoho and Carrie Grimes. 2003. Hessian eigenmaps: locally linear embedding techniques for high-dimensional data. Proc. Natl. Acad. Sci. U. S. A., Vol. 100, 10 (May 2003), 5591--5596.Google ScholarCross Ref"",""Katharina Eichler, Feng Li, Ashok Litwin-Kumar, Youngser Park, Ingrid Andrade, Casey M Schneider-Mizell, Timo Saumweber, Annina Huser, Claire Eschbach, Bertram Gerber, et al. 2017. The complete connectome of a learning and memory centre in an insect brain. Nature, Vol. 548, 7666 (2017), 175.Google Scholar"",""Chris Fraley and Adrian E Raftery. 2002. Model-Based Clustering, Discriminant Analysis, and Density Estimation. J. Amer. Statist. Assoc., Vol. 97, 458 (June 2002), 611--631. https://doi.org/10.1198/016214502760047131Google ScholarCross Ref"",""Y Freund and R E Schapire. 1997. A decision-theoretic generalization of on-line learning and an application to boosting. J. Comput. System Sci. (1997). https://www.sciencedirect.com/science/article/pii/S002200009791504XGoogle Scholar"",""Jerome H Friedman. 2001. Greedy function approximation: a gradient boosting machine. Annals of statistics (2001), 1189--1232.Google Scholar"",""Wayne A Fuller. 1987. Measurement Error Models 99 edition ed.). Wiley. https://smile.amazon.com/Measurement-Error-Models-Wayne-Fuller/dp/0471861871/ref=sr_1_2?keywords=Measurement+Error+Models\u0026qid=1561237036\u0026s=gateway\u0026sr=8--2Google Scholar"",""David J Hand. 2016. Measurement: A Very Short Introduction (Very Short Introductions) 1 edition ed.). Oxford University Press. https://www.amazon.com/Measurement-Very-Short-Introduction-Introductions/dp/0198779569Google ScholarCross Ref"",""J A Hartigan and M A Wong. 1979. Algorithm AS 136: A K-Means Clustering Algorithm. Applied statistics, Vol. 28, 1 (1979), 100. https://doi.org/10.2307/2346830Google Scholar"",""John A Lee and Michel Verleysen. 2007. Nonlinear Dimensionality Reduction 2007 edition ed.). Springer Science \u0026 Business Media. https://market.android.com/details?id=book-e4qkkQEACAAJGoogle Scholar"",""Andy Liaw and Matthew Wiener. 2002. Classification and Regression by randomForest. R News, Vol. 2, 3 (2002), 18--22.Google Scholar"",""Laurens van der Maaten and Geoffrey Hinton. 2008a. Visualizing Data using t-SNE. J. Mach. Learn. Res., Vol. 9, Nov (2008), 2579--2605. http://www.jmlr.org/papers/v9/vandermaaten08a.htmlGoogle Scholar"",""Laurens van der Maaten and Geoffrey Hinton. 2008b. Visualizing data using t-SNE. Journal of machine learning research, Vol. 9, Nov (2008), 2579--2605.Google Scholar"",""Leland McInnes and John Healy. 2018. Umap: Uniform manifold approximation and projection for dimension reduction. arXiv preprint arXiv:1802.03426 (2018).Google Scholar"",""Geoffrey McLachlan and Thriyambakam Krishnan. 2008. The EM Algorithm and Extensions 2 edition ed.). Wiley-Interscience. https://www.amazon.com/EM-Algorithm-Extensions-Geoffrey-McLachlan/dp/0471201707Google Scholar"",""Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. 2018. Foundations of Machine Learning. MIT Press. https://market.android.com/details?id=book-dWB9DwAAQBAJGoogle Scholar"",""Marius Muja and David G Lowe. 2014. Scalable nearest neighbor algorithms for high dimensional data. IEEE Transactions on Pattern Analysis \u0026 Machine Intelligence 11 (2014), 2227--2240.Google ScholarCross Ref"",""Carey E Priebe, Youngser Park, Minh Tang, Avanti Athreya, Vince Lyzinski, Joshua T Vogelstein, Yichen Qin, Ben Cocanougher, Katharina Eichler, Marta Zlatic, et al. 2017. Semiparametric spectral modeling of the Drosophila connectome. arXiv preprint arXiv:1705.03297 (2017).Google Scholar"",""Bernhard Schölkopf, Alexander Smola, and Klaus-Robert Müller. 1997. Kernel principal component analysis. In International Conference on Artificial Neural Networks. Springer, 583--588.Google ScholarDigital Library"",""Bernhard Schölkopf and Alexander J Smola. 2002. Learning with kernels: support vector machines, regularization, optimization, and beyond. MIT press.Google Scholar"",""E Scornet. 2016. Random Forests and Kernel Methods. IEEE Trans. Inf. Theory, Vol. 62, 3 (March 2016), 1485--1500. http://dx.doi.org/10.1109/TIT.2016.2514489Google ScholarDigital Library"",""Cencheng Shen and Joshua T Vogelstein. 2018. Decision Forests Induce Characteristic Kernels. (Nov. 2018). arxiv: stat.ML/1812.00029 http://arxiv.org/abs/1812.00029Google Scholar"",""Tao Shi and Steve Horvath. 2006 a. Unsupervised Learning With Random Forest Predictors. J. Comput. Graph. Stat., Vol. 15, 1 (March 2006), 118--138.Google ScholarCross Ref"",""Tao Shi and Steve Horvath. 2006 b. Unsupervised learning with random forest predictors. Journal of Computational and Graphical Statistics, Vol. 15, 1 (2006), 118--138.Google ScholarCross Ref"",""Vin D Silva and Joshua B Tenenbaum. 2003. Global Versus Local Methods in Nonlinear Dimensionality Reduction. In Advances in Neural Information Processing Systems 15, S Becker, S Thrun, and K Obermayer (Eds.). MIT Press, 721--728. http://papers.nips.cc/paper/2141-global-versus-local-methods-in-nonlinear-dimensionality-reduction.pdfGoogle Scholar"",""Charles J Stone. 1977. Consistent Nonparametric Regression. Annals of statistics, Vol. 5, 4 (July 1977), 595--620. https://doi.org/10.1214/aos/1176343886Google ScholarCross Ref"",""Daniel L Sussman, Minh Tang, Donniell E Fishkind, and Carey E Priebe. 2012. A consistent adjacency spectral embedding for stochastic block model graphs. J. Amer. Statist. Assoc., Vol. 107, 499 (2012), 1119--1128.Google ScholarCross Ref"",""Joshua B Tenenbaum, Vin De Silva, and John C Langford. 2000. A global geometric framework for nonlinear dimensionality reduction. science, Vol. 290, 5500 (2000), 2319--2323.Google Scholar"",""William C Thibault and Bruce F Naylor. 1987. Set operations on polyhedra using binary space partitioning trees. In ACM SIGGRAPH computer graphics, Vol. 21. ACM, 153--162.Google Scholar"",""T Tomita, M Maggioni, and J Vogelstein. 2017. ROFLMAO: Robust Oblique Forests with Linear MAtrix Operations. In Proceedings of the 2017 SIAM International Conference on Data Mining. Society for Industrial and Applied Mathematics, 498--506. https://doi.org/10.1137/1.9781611974973.56Google ScholarCross Ref"",""Tyler M Tomita, Mauro Maggioni, and Joshua T Vogelstein. 2015. Randomer forests. arXiv preprint arXiv:1506.03410 (2015).Google Scholar"",""Joshua T Vogelstein, Eric W Bridgeford, Benjamin D Pedigo, Jaewon Chung, Keith Levin, Brett Mensh, and Carey E Priebe. 2019. Connectal coding: discovering the structures linking cognitive phenotypes to individual histories. Current opinion in neurobiology, Vol. 55 (2019), 199--212.Google Scholar"",""Joe H Ward. 1963. Hierarchical Grouping to Optimize an Objective Function. J. Amer. Statist. Assoc., Vol. 58, 301 (March 1963), 236--244. https://doi.org/10.1080/01621459.1963.10500845Google ScholarCross Ref"",""Xindong Wu, Vipin Kumar, J Ross Quinlan, Joydeep Ghosh, Qiang Yang, Hiroshi Motoda, Geoffrey J McLachlan, Angus Ng, Bing Liu, Philip S Yu, Zhi-Hua Zhou, Michael Steinbach, David J Hand, and Dan Steinberg. 2007. Top 10 Algorithms in Data Mining. Knowledge and information systems, Vol. 14, 1 (Dec. 2007), 1--37. https://doi.org/10.1007/s10115-007-0114--2Google Scholar"",""Jordan Yoder, Li Chen, Henry Pao, Eric Bridgeford, Keith Levin, Donniell Fishkind, Carey Priebe, and Vince Lyzinski. 2018. Vertex nomination: The canonical sampling and the extended spectral nomination schemes. arXiv preprint arXiv:1802.04960 (2018).Google Scholar""]"
https://doi.org/10.1145/3394486.3403095,Z-Miner: An Efficient Method for Mining Frequent Arrangements of Event Intervals,"Mining frequent patterns of event intervals from a large collection of interval sequences is a problem that appears in several application domains. In this paper, we propose Z-Miner, a novel algorithm for solving this problem that addresses the deficiencies of existing competitors by employing two novel data structures: Z-Table, a hierarchical hash-based data structure for time-efficient candidate generation and support count, and Z-Arrangement, a data structure for efficient memory consumption. The proposed algorithm is able to handle patterns with repetitions of the same event label, allowing for gap and error tolerance constraints, as well as keeping track of the exact occurrences of the extracted frequent patterns. Our experimental evaluation on eight real-world and six synthetic datasets demonstrates the superiority of Z-Miner against four state-of-the-art competitors in terms of runtime efficiency and memory footprint.","[{""name"":""Zed Lee"",""id"":""/profile/99659573756""},{""name"":""Tony Lindgren"",""id"":""/profile/81337491226""},{""name"":""Panagiotis Papapetrou"",""id"":""/profile/81309502280""},{""name"":""Zed Lee"",""id"":""/profile/99659573756""},{""name"":""Tony Lindgren"",""id"":""/profile/81337491226""},{""name"":""Panagiotis Papapetrou"",""id"":""/profile/81309502280""}]","[""Tamas Abraham and John F. Roddick. 1998. Incremental Meta-Mining from Large Temporal Data Sets. In ER. Springer, 41--54.Google Scholar"",""Juan M. Ale and Gustavo H. Rossi. 2000. An Approach to Discovering Temporal Association Rules. In SAC. ACM, 294--300.Google Scholar"",""James F. Allen. 1983. Maintaining Knowledge about Temporal Intervals. CACM 26, 11 (1983), 832--843.Google ScholarDigital Library"",""Iyad Batal, Hamed Valizadegan, Gregory F. Cooper, and Milos Hauskrecht. 2013. A Temporal Pattern Mining Approach for Classifying Electronic Health Record Data. TIST 4, 4 (2013), 1--22.Google ScholarDigital Library"",""Benjamin K. Bergen and Nancy Chang. 2005. Embodied Construction Grammar in Simulation-based Language Understanding. Construction Grammars: Cognitive Grounding and Theoretical Extensions 3 (2005), 147--190.Google ScholarCross Ref"",""Xiaodong Chen and Ilias Petrounias. 1999. Mining Temporal Features in Association Rules. In PKDD. Springer, 295--300.Google Scholar"",""Yi-Cheng Chen, Ji-Chiang Jiang, Wen-Chih Peng, and Suh-Yin Lee. 2010. An Efficient Algorithm for Mining Time Interval-Based Patterns in Large Database. In CIKM. ACM, 49--58.Google Scholar"",""Yi-Cheng Chen, Wen-Chih Peng, and Suh-Yin Lee. 2015. Mining Temporal Patterns in Time Interval-Based Data. TKDE 27, 12 (2015), 3318--3331.Google ScholarDigital Library"",""Yi-Cheng Chen, Julia Tzu-Ya Weng, and Lin Hui. 2016. A novel algorithm for mining closed temporal patterns from interval-based data. KAIS 46, 1 (2016), 151--183.Google ScholarDigital Library"",""Dmitriy Fradkin and Fabian Moerchen. 2010. Margin-closed Frequent Sequential Pattern Mining. In KDD-UP. ACM, 45--54.Google Scholar"",""Fosca Giannotti, Mirco Nanni, and Dino Pedreschi. 2006. Efficient mining of temporally annotated sequences. In SDM, Vol. 124. SIAM, 348--359.Google Scholar"",""Thomas Guyet and Quiniou René. 2011. Extracting Temporal Patterns from Interval-Based Sequences. In IJCAI. AAAI, 1306--1311.Google Scholar"",""Frank Höppner. 2001. Discovery of Temporal Patterns - Learning Rules about the Qualitative Behaviour of Time Series. In PKDD. Springer, 192--203.Google Scholar"",""Frank Höppner and Frank Klawonn. 2001. Finding Informative Rules in Interval Sequences. In IDA. Springer, 125--134.Google Scholar"",""San-Yih Hwang, Chih-Ping Wei, and Wan-Shiou Yang. 2004. Discovery of temporal patterns from process instances. Computers in Industry 53, 3 (2004), 345--364.Google ScholarDigital Library"",""Po-shan Kam and Ada Wai-chee Fu. 2000. Discovering Temporal Patterns for Interval-based Events. In DaWak. Springer, 317--326.Google Scholar"",""Hoang Thanh Lam, Fabian Mörchen, Dmitriy Fradkin, and Toon Calders. 2014. Mining Compressing Sequential Patterns. SADM 7, 1 (2014), 34--52.Google Scholar"",""Srivatsan Laxman, Pidaparthy S. Sastry, and K. P. Unnikrishnan. 2007. Discovering Frequent Generalized Episodes When Events Persist for Different Durations. TKDE 19, 9 (2007), 1188--1201.Google ScholarDigital Library"",""Jun-Lin Lin. 2003. Mining Maximal Frequent Intervals. In SAC. ACM, 426--431.Google Scholar"",""Li Liu, Shu Wang, Bin Hu, Qingyu Qiong, Junhao Wen, and David S Rosenblum. 2018. Learning structures of interval-based Bayesian networks in probabilistic generative model for human complex activity recognition. PR 81 (2018), 545--561.Google Scholar"",""Fabian Moerchen. 2010. Temporal Pattern Mining in Symbolic Time Point and Time Interval Data. In KDD. ACM, Article 2, 1 pages.Google Scholar"",""Carl H. Mooney and John F. Roddick. 2004. Mining Relationships Between Interacting Episodes. In SDM. SIAM, 1--10.Google Scholar"",""Fabian Mörchen. 2007. Unsupervised Pattern Mining from Symbolic Temporal Data. SIGKDD Explorations 9, 1 (2007), 41--55.Google ScholarDigital Library"",""Fabian Mörchen and Dmitriy Fradkin. 2010. Robust Mining of Time Intervals with Semi-interval Partial Order Patterns. In SDM. SIAM, 315--326.Google Scholar"",""Robert Moskovitch and Yuval Shahar. 2015. Classification of multivariate time series via temporal abstraction and time intervals mining. KAIS 45, 1 (2015), 35--74.Google ScholarDigital Library"",""Robert Moskovitch and Yuval Shahar. 2015. Fast time intervals mining using the transitivity of temporal relations. KAIS 42, 1 (2015), 21--48.Google ScholarDigital Library"",""Robert Moskovitch, Colin Walsh, Fei Wang, George Hripcsak, and Nicholas Tatonetti. 2015. Outcomes Prediction via Time Intervals Related Patterns. In ICDM. IEEE, 919--924.Google Scholar"",""Panagiotis Papapetrou, George Kollios, Stan Sclaroff, and Dimitrios Gunopulos. 2009. Mining Frequent Arrangements of Temporal Intervals. KAIS 21, 2 (2009), 133--171.Google Scholar"",""Dhaval Patel, Wynne Hsu, and Mong Li Lee. 2008. Mining Relationships among Interval-Based Events for Classification. ACM, 393--404.Google Scholar"",""Niki Pissinou, Ivan Radev, and Kia Makki. 2001. Spatio-Temporal Modeling in Video and Multimedia Geographic Information Systems. GeoInformatica 5, 4 (2001), 375--409.Google ScholarDigital Library"",""Amit K. Sharma and Dhaval Patel. 2018. STIPA: A Memory Efficient Technique for Interval Pattern Discovery. In Big Data. IEEE, 1767--1776.Google Scholar"",""Eitam Sheetrit, Nir Nissim, Denis Klimov, and Yuval Shahar. 2019. Temporal Probabilistic Profiles for Sepsis Prediction in the ICU. In KDD. 2961--2969.Google Scholar"",""Roy Villafane, Kien A. Hua, Duc Tran, and Basab Maulik. 2000. Knowledge Discovery from Series of Interval Events. IIS 15, 1 (2000), 71--89.Google Scholar"",""Jianyong Wang and Jiawei Han. 2004. BIDE: Efficient Mining of Frequent Closed Sequences. In ICDE. IEEE, 79.Google ScholarDigital Library"",""Edi Winarko and John F. Roddick. 2007. ARMADA - An algorithm for discovering richer relative temporal association rules from interval-based data. DKE 63, 1 (2007), 76--90.Google ScholarDigital Library"",""Shin-YiWu and Yen-Liang Chen. 2007. Mining Nonambiguous Temporal Patterns for Interval-Based Events. TKDE 19, 6 (2007), 742--758.Google Scholar""]"
https://doi.org/10.1145/3394486.3403096,Imputing Various Incomplete Attributes via Distance Likelihood Maximization,"Missing values may appear in various attributes. By ""various"", we mean (1) different types of values in a tuple, such as numerical or categorical, and (2) different attributes in a tuple, either the dependent or determinant attributes of regression models or dependency rules. Such varieties unfortunately prevent the imputation performing. In this paper, we propose to study the distance models that predict distances between tuples for missing data imputation. The immediate benefits are in two aspects, (1) uniformly processing and collaboratively utilizing the distances on all the attributes with various types of values, and (2) rather than enumerating the combinations of imputation candidates on various attributes, we can directly calculate the most likely distances of missing values to other complete ones and thus infer the corresponding imputations. Our major technical highlights include (1) introducing the imputation statistically explainable by the likelihood on distances, (2) proving NP-hardness of finding the maximum likelihood imputation, and (3) devising the approximation algorithm with performance guarantees. Experiments over datasets with real missing values demonstrate the superiority of the proposed method compared to 11 existing approaches in 5 categories. Our proposal improves not only the imputation accuracy but also the downstream applications such as classification, clustering and record matching.","[{""name"":""Shaoxu Song"",""id"":""/profile/81552921256""},{""name"":""Yu Sun"",""id"":""/profile/99659573468""},{""name"":""Shaoxu Song"",""id"":""/profile/81552921256""},{""name"":""Yu Sun"",""id"":""/profile/99659573468""}]","[""N. S. Altman. An introduction to kernel and nearest-neighbor nonparametric regression. The American Statistician, 46(3):175--185, 1992.Google Scholar"",""C. M. Bishop. Pattern recognition and machine learning. springer, 2006.Google Scholar"",""P. Bohannon, W. Fan, M. Flaster, and R. Rastogi. A cost-based model and effective heuristic for repairing constraints by value modification. In SIGMOD, pages 143--154. ACM, 2005.Google ScholarDigital Library"",""E. J. Candè s and B. Recht. Exact matrix completion via convex optimization. Foundations of Computational Mathematics, 9(6):717--772, 2009.Google ScholarCross Ref"",""W. S. Cleveland and C. Loader. Smoothing by Local Regression: Principles and Methods, pages 10--49. Physica-Verlag HD, Heidelberg, 1996.Google Scholar"",""C. Cuadras and C. Arenas. A distance based regression model for prediction with mixed data. Communications in Statistics-Theory and Methods, 19(6):2261--2279, 1990.Google ScholarCross Ref"",""A. H. de Souza Júnior, F. Corona, G. D. A. Barreto, Y. Miché, and A. Lendasse. Minimal learning machine: A novel supervised distance-based approach for regression and classification. Neurocomputing, 164:34--44, 2015.Google ScholarDigital Library"",""C. Domeniconi and B. Yan. Nearest neighbor ensemble. In ICPR, pages 228--231, 2004.Google ScholarCross Ref"",""A. K. Elmagarmid, P. G. Ipeirotis, and V. S. Verykios. Duplicate record detection: A survey. TKDE, 19(1):1--16, 2007.Google ScholarCross Ref"",""W. Fan, F. Geerts, L. V. S. Lakshmanan, and M. Xiong. Discovering conditional functional dependencies. In ICDE, pages 1231--1234, 2009.Google ScholarDigital Library"",""W. Fan, X. Jia, J. Li, and S. Ma. Reasoning about record matching rules. PVLDB, 2(1):407--418, 2009.Google ScholarDigital Library"",""W. Fan, J. Li, S. Ma, N. Tang, and W. Yu. Towards certain fixes with editing rules and master data. PVLDB, 3(1):173--184, 2010.Google ScholarDigital Library"",""J. Han, M. Kamber, and J. Pei. Data Mining: Concepts and Techniques, 3rd edition. Morgan Kaufmann, 2011.Google ScholarDigital Library"",""M. Interlandi and N. Tang. Proof positive and negative in data cleaning. In ICDE, pages 18--29, 2015.Google ScholarCross Ref"",""R. M. Karp. Reducibility among combinatorial problems. In Proceedings of a symposium on the Complexity of Computer Computations, pages 85--103, 1972.Google ScholarCross Ref"",""D. Li, J. Deogun, W. Spaulding, and B. Shuart. Towards missing data imputation: a study of fuzzy k-means clustering method. In Rough sets and current trends in computing, volume 3066, pages 573--579. Springer, 2004.Google Scholar"",""Y. Li and B. Liu. A normalized levenshtein distance metric. TPAMI, 29(6):1091--1095, 2007.Google ScholarDigital Library"",""R. J. Little and D. B. Rubin. Statistical analysis with missing data. John Wiley \u0026 Sons, 2014.Google ScholarDigital Library"",""C. Mayfield, J. Neville, and S. Prabhakar. ERACER: a database approach for statistical inference and data cleaning. In SIGMOD, pages 75--86, 2010.Google ScholarDigital Library"",""M. Mohri, A. Rostamizadeh, and A. Talwalkar. Foundations of machine learning. MIT press, 2018.Google Scholar"",""G. Navarro. A guided tour to approximate string matching. ACM Comput. Surv., 33(1):31--88, 2001.Google ScholarDigital Library"",""S. Nikfalazar, C. Yeh, S. E. Bedingfield, and H. A. Khorshidi. A new iterative fuzzy clustering algorithm for multiple imputation of missing data. In FUZZ-IEEE, pages 1--6, 2017.Google ScholarCross Ref"",""C. Patil and I. Baidari. Estimating the optimal number of clusters k in a dataset using data depth. Data Science and Engineering, 4(2):132--140, 2019.Google ScholarCross Ref"",""T. Rekatsinas, X. Chu, I. F. Ilyas, and C. Ré. Holoclean: Holistic data repairs with probabilistic inference. PVLDB, 10(11):1190--1201, 2017.Google ScholarDigital Library"",""J. T. Rgd Steel. Principales and pricedures of statistics. 1960.Google Scholar"",""W. Rudin et al. Principles of mathematical analysis, volume 3. McGraw-hill New York, 1964.Google Scholar"",""S. Song and L. Chen. Differential dependencies: Reasoning and discovery. ACM Trans. Database Syst., 36(3):16:1--16:41, 2011.Google ScholarDigital Library"",""S. Song, A. Zhang, L. Chen, and J. Wang. Enriching data imputation with extensive similarity neighbors. PVLDB, 8(11):1286--1297, 2015.Google ScholarDigital Library"",""J. Wang and N. Tang. Towards dependable data repairing with fixing rules. In ICDE, pages 457--468, 2014.Google ScholarDigital Library"",""I. H. Witten, E. Frank, M. A. Hall, and C. J. Pal. Data Mining: Practical machine learning tools and techniques. Morgan Kaufmann, 2016.Google ScholarDigital Library"",""S. Wu, X. Feng, Y. Han, and Q. Wang. Missing categorical data imputation approach based on similarity. In SMC, pages 2827--2832, 2012.Google ScholarCross Ref"",""M. Yakout, L. Berti-É quille, and A. K. Elmagarmid. Don't be scared: use scalable automatic repairing with maximal likelihood and bounded changes. In SIGMOD, pages 553--564, 2013.Google ScholarDigital Library"",""X. Yan, W. Xiong, L. Hu, F. Wang, and K. Zhao. Missing value imputation based on gaussian mixture model for the internet of things. Mathematical Problems in Engineering, 2015, 2015.Google Scholar"",""A. Zhang, S. Song, Y. Sun, and J. Wang. Learning individual models for imputation. In ICDE, pages 160--171, 2019.Google ScholarCross Ref"",""S. Zhang, J. Zhang, X. Zhu, Y. Qin, and C. Zhang. Missing value imputation based on data clustering. Trans. Computational Science, 1:128--138, 2008.Google Scholar""]"
https://doi.org/10.1145/3394486.3403097,WeightGrad: Geo-Distributed Data Analysis Using Quantization for Faster Convergence and Better Accuracy,"High network communication cost for synchronizing weights and gradients in geo-distributed data analysis consumes the benefits of advancement in computation and optimization techniques. Many quantization methods for weight, gradient or both have been proposed in recent years where weight-quantized model suffers from error related to weight dimension and gradient-quantized method suffers from slow convergence rate by a factor related to the gradient quantization resolution and gradient dimension. All these methods have been proved to be infeasible in terms of distributed training across multiple data centers all over the world. Moreover recent studies show that communicating over WANs can significantly degrade DNN model performance by upto 53.7x because of unstable and limited WAN bandwidth. Our goal in this work is to design a geo-distributed Deep-Learning system that (1) ensures efficient and faster communication over LAN and WAN and (2) maintain accuracy and convergence for complex DNNs with billions of parameters. In this paper, we introduce WeightGrad which acknowledges the limitations of quantization and provides loss-aware weight-quantized networks with quantized gradients for local convergence and for global convergence it dynamically eliminates insignificant communication between data centers while still guaranteeing the correctness of DNN models. Our experiments on our developed prototypes of WeightGrad running across 3 Amazon EC2 global regions and on a cluster that emulates EC2 WAN bandwidth show that WeightGrad provides 1.06% gain in top-1 accuracy, 5.36x speedup over baseline and 1.4x-2.26x over the four state-of-the-art distributed ML systems.","[{""name"":""Syeda Nahida Akter"",""id"":""/profile/99659574787""},{""name"":""Muhammad Abdullah Adnan"",""id"":""/profile/99659566838""},{""name"":""Syeda Nahida Akter"",""id"":""/profile/99659574787""},{""name"":""Muhammad Abdullah Adnan"",""id"":""/profile/99659566838""}]","[""[n.d.]. AWS. http://aws.amazon.com/about-aws/global-infrastructure/.Google Scholar"",""[n.d.]. AWS EC2 Instance. https://aws.amazon.com/ec2/instance-types/.Google Scholar"",""[n.d.]. Google Datacenter Locations. http://www.google.com/about/datacenters/inside/locations/.Google Scholar"",""[n.d.]. isperf3. https://software.es.net/iperf/.Google Scholar"",""[n.d.]. Microsoft Datacenters. http://www.microsoft.com/en-us/server-cloud/cloud-os/global-datacenters.aspx.Google Scholar"",""Martin Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. 2015. TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems. https://www.tensorflow.org/ Software available from tensorflow.org.Google Scholar"",""Mart'in Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, Manjunath Kudlur, Josh Levenberg, Rajat Monga, Sherry Moore, Derek G. Murray, Benoit Steiner, Paul Tucker, Vijay Vasudevan, Pete Warden, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. 2016. TensorFlow: A System for Large-Scale Machine Learning. In 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16). USENIX Association, Savannah, GA, 265--283. https://www.usenix.org/conference/osdi16/technical-sessions/presentation/abadiGoogle ScholarDigital Library"",""Amr Ahmed, Moahmed Aly, Joseph Gonzalez, Shravan Narayanamurthy, and Alexander J Smola. 2012. Scalable inference in latent variable models. In Proceedings of the fifth ACM international conference on Web search and data mining. 123--132.Google ScholarDigital Library"",""Alham Fikri Aji and Kenneth Heafield. 2017. Sparse Communication for Distributed Gradient Descent. arxiv: 1704.05021 [cs.CL]Google Scholar"",""Dan Alistarh, Demjan Grubic, Jerry Li, Ryota Tomioka, and Milan Vojnovic. 2016. QSGD: Communication-Efficient SGD via Gradient Quantization and Encoding. arxiv: 1610.02132 [cs.LG]Google Scholar"",""Joseph K. Bradley, Aapo Kyrola, Danny Bickson, and Carlos Guestrin. 2011. Parallel Coordinate Descent for L1-Regularized Loss Minimization. arxiv: 1105.5379 [cs.LG]Google Scholar"",""Jianmin Chen, Xinghao Pan, Rajat Monga, Samy Bengio, and Rafal Jozefowicz. 2016. Revisiting Distributed Synchronous SGD. arxiv: 1604.00981 [cs.LG]Google Scholar"",""Franccois Chollet et al. 2015. Keras. https://github.com/fchollet/keras.Google Scholar"",""Matthieu Courbariaux, Itay Hubara, Daniel Soudry, Ran El-Yaniv, and Yoshua Bengio. 2016. Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1. arxiv: 1602.02830 [cs.LG]Google Scholar"",""Henggang Cui, Alexey Tumanov, Jinliang Wei, Lianghong Xu, Wei Dai, Jesse Haber-kucharsky, Qirong Ho, Gregory R. Ganger, Phillip B. Gibbons, Garth A. Gibson, and Eric P. Xing. [n.d.]. Exploiting iterative-ness for parallel ML computations.Google Scholar"",""Henggang Cui, Hao Zhang, Gregory Ganger, Phillip Gibbons, and Eric Xing. 2016. GeePS: scalable deep learning on distributed GPUs with a GPU-specialized parameter server. 1--16. https://doi.org/10.1145/2901318.2901323Google Scholar"",""Nikoli Dryden, Sam Ade Jacobs, Tim Moon, and Brian Van Essen. 2016. Communication Quantization for Data-parallel Training of Deep Neural Networks. In Proceedings of the Workshop on Machine Learning in High Performance Computing Environments (Salt Lake City, Utah) (MLHPC '16). IEEE Press, Piscataway, NJ, USA, 1--8. https://doi.org/10.1109/MLHPC.2016.4Google ScholarDigital Library"",""John Duchi, Elad Hazan, and Yoram Singer. 2011. Adaptive subgradient methods for online learning and stochastic optimization. Journal of machine learning research, Vol. 12, Jul (2011), 2121--2159.Google ScholarDigital Library"",""Priya Goyal, Piotr Dollár, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He. 2017. Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour. arxiv: 1706.02677 [cs.CV]Google Scholar"",""Suyog Gupta, Ankur Agrawal, Kailash Gopalakrishnan, and Pritish Narayanan. 2015. Deep Learning with Limited Numerical Precision. arxiv: 1502.02551 [cs.LG]Google Scholar"",""Song Han, Huizi Mao, and William J. Dally. 2015. Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding. arxiv: 1510.00149 [cs.CV]Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. Deep Residual Learning for Image Recognition. arxiv: 1512.03385 [cs.CV]Google Scholar"",""Lu Hou, Ruiliang Zhang, and James T. Kwok. 2019. Analysis of Quantized Models. In International Conference on Learning Representations. https://openreview.net/forum?id=ryM_IoAqYXGoogle Scholar"",""Kevin Hsieh, Aaron Harlap, Nandita Vijaykumar, Dimitris Konomis, Gregory R. Ganger, Phillip B. Gibbons, and Onur Mutlu. 2017. Gaia: Geo-Distributed Machine Learning Approaching LAN Speeds. In 14th USENIX Symposium on Networked Systems Design and Implementation (NSDI 17). USENIX Association, Boston, MA, 629--647. https://www.usenix.org/conference/nsdi17/technical-sessions/presentation/hsiehGoogle ScholarDigital Library"",""Diederik P. Kingma and Jimmy Ba. 2014. Adam: A Method for Stochastic Optimization. arxiv: 1412.6980 [cs.LG]Google Scholar"",""Alex Krizhevsky, Geoffrey Hinton, et al. 2009. Learning multiple layers of features from tiny images. (2009).Google Scholar"",""Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. [n.d.]. CIFAR-10 (Canadian Institute for Advanced Research). ( [n.,d.]). http://www.cs.toronto.edu/ kriz/cifar.htmlGoogle Scholar"",""Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012. ImageNet Classification with Deep Convolutional Neural Networks. In Advances in Neural Information Processing Systems 25, F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger (Eds.). Curran Associates, Inc., 1097--1105. http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdfGoogle ScholarDigital Library"",""Xiangru Lian, Wei Zhang, Ce Zhang, and Ji Liu. 2017. Asynchronous decentralized parallel stochastic gradient descent. arXiv preprint arXiv:1710.06952 (2017).Google Scholar"",""Yujun Lin, Song Han, Huizi Mao, Yu Wang, and William J. Dally. 2017. Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training. arxiv: 1712.01887 [cs.CV]Google Scholar"",""Feng Niu, Benjamin Recht, Christopher Re, and Stephen J. Wright. 2011. HOGWILD!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent. arxiv: 1106.5730 [math.OC]Google Scholar"",""Jongsoo Park, Sheng Li, Wei Wen, Ping Tak Peter Tang, Hai Li, Yiran Chen, and Pradeep Dubey. 2016. Faster CNNs with Direct Sparse Convolutions and Guided Pruning. arxiv: 1608.01409 [cs.CV]Google Scholar"",""Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, and Ali Farhadi. 2016. XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks. In ECCV.Google Scholar"",""Frank Seide, Hao Fu, Jasha Droppo, Gang Li, and Dong Yu. 2014. 1-Bit Stochastic Gradient Descent and Application to Data-Parallel Distributed Training of Speech DNNs. In Interspeech 2014 interspeech 2014 ed.). https://www.microsoft.com/en-us/research/publication/1-bit-stochastic-gradient-descent-and-application-to-data-parallel-distributed-training-of-speech-dnns/Google Scholar"",""Karen Simonyan and Andrew Zisserman. 2014a. Very Deep Convolutional Networks for Large-Scale Image Recognition. arxiv: 1409.1556 [cs.CV]Google Scholar"",""Karen Simonyan and Andrew Zisserman. 2014b. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556 (2014).Google Scholar"",""Nikko Strom. 2015. Scalable distributed DNN training using commodity GPU cloud computing. In INTERSPEECH.Google Scholar"",""Wei Wen, Cong Xu, Feng Yan, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li. 2017. TernGrad: Ternary Gradients to Reduce Communication in Distributed Deep Learning. arxiv: 1705.07878 [cs.LG]Google Scholar"",""Shuang Wu, Guoqi Li, Feng Chen, and Luping Shi. 2018. Training and Inference with Integers in Deep Neural Networks. arxiv: 1802.04680 [cs.LG]Google Scholar"",""Shuxin Zheng, Qi Meng, Taifeng Wang, Wei Chen, Nenghai Yu, Zhi-Ming Ma, and Tie-Yan Liu. 2016. Asynchronous Stochastic Gradient Descent with Delay Compensation. arxiv: 1609.08326 [cs.LG]Google Scholar"",""Shuchang Zhou, Yuxin Wu, Zekun Ni, Xinyu Zhou, He Wen, and Yuheng Zou. 2016. DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients. CoRR, Vol. abs/1606.06160 (2016). http://arxiv.org/abs/1606.06160Google Scholar"",""Martin Zinkevich. 2003. Online convex programming and generalized infinitesimal gradient ascent. In Proceedings of the 20th international conference on machine learning (icml-03). 928--936.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403098,Feature-Induced Manifold Disambiguation for Multi-View Partial Multi-label Learning,"In conventional multi-label learning framework, each example is assumed to be represented by a single feature vector and associated with multiple valid labels simultaneously. Nonetheless, real-world objects usually exhibit complicated properties which can have multi-view feature representation as well as false positive labeling. Accordingly, the problem of multi-view partial multi-label learning (MVPML) is studied in this paper, where each example is assumed to be presented by multiple feature vectors while associated with multiple candidate labels which are only partially valid. To learn from MVPML examples, a novel approach named FIMAN is proposed which makes use of multi-view feature representation to tackle the noisy labeling information. Firstly, an aggregate manifold structure over training examples is generated by adaptively fusing affinity information conveyed by feature vectors of different views. Then, candidate labels of each training example are disambiguated by preserving the feature-induced manifold structure in label space. Finally, the resulting predictive models are learned by fitting modeling outputs with the disambiguated labels. Extensive experiments on a number of real-world data sets show that FIMAN achieves highly competitive performance against state-of-the-art approaches in solving the MVPML problem.","[{""name"":""Jing-Han Wu"",""id"":""/profile/99659455677""},{""name"":""Xuan Wu"",""id"":""/profile/99659337763""},{""name"":""Qing-Guo Chen"",""id"":""/profile/99659574060""},{""name"":""Yao Hu"",""id"":""/profile/99659573331""},{""name"":""Min-Ling Zhang"",""id"":""/profile/81423595920""},{""name"":""Jing-Han Wu"",""id"":""/profile/99659455677""},{""name"":""Xuan Wu"",""id"":""/profile/99659337763""},{""name"":""Qing-Guo Chen"",""id"":""/profile/99659574060""},{""name"":""Yao Hu"",""id"":""/profile/99659573331""},{""name"":""Min-Ling Zhang"",""id"":""/profile/81423595920""}]","[""A. Blum and T. Mitchell. 1998. Combining labeled and unlabeled data with co-training. In Proceedings of the 11th Annual Conference on Computational Learning Theory. Madison, WI, 92--100.Google Scholar"",""C.-H. Chen, V. M. Patel, and R. Chellappa. 2018. Learning from ambiguously labeled face images. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 40, 7 (2018), 1653--1667.Google ScholarCross Ref"",""Z.-S. Chen, X. Wu, Q.-G. Chen, Y. Hu, and M.-L. Zhang. 2020. Multi-view partial multi-label learning with graph-based disambiguation. In Proceedings of the 34th AAAI Conference on Artificial Intelligence. New York, NY.Google ScholarCross Ref"",""T. Cour, B. Sapp, and B. Taskar. 2011. Learning from partial labels. Journal of Machine Learning Research, Vol. 12, May (2011), 1501--1536.Google ScholarDigital Library"",""J. Demvs ar. 2006. Statistical comparisons of classifiers over multiple data sets. Journal of Machine Learning Research, Vol. 7, Jan (2006), 1--30.Google ScholarDigital Library"",""A. Elisseeff and J. Weston. 2002. A kernel method for multi-labelled classification. In Advances in Neural Information Processing Systems 14, T. G. Dietterich, S. Becker, and Z. Ghahramani (Eds.). MIT Press, Cambridge, MA, 681--687.Google Scholar"",""M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. 2010. The Pascal visual object classes (VOC) challenge. International Journal of Computer Vision, Vol. 88, 2 (2010), 303--338.Google ScholarDigital Library"",""J. F. Gemmeke, D. P. W. Ellis, D. Freedman, A. Jansen, W. Lawrence, R. C. Moore, M. Plakal, and M. Ritter. 2017. Audio set: An ontology and human-labeled dataset for audio events. In Proceedings of the 2017 IEEE International Conference on Acoustics, Speech and Signal Processing. New Orleans, LA, 776--780.Google Scholar"",""E. Gibaja and S. Ventura. 2015. A tutorial on multilabel learning. ACM Computing Surveys, Vol. 47, 3 (2015), Article 52.Google Scholar"",""S. He, K. Deng, L. Li, S. Shu, and L. Liu. 2019. Discriminatively relabel for partial multi-label learning. In Proceedings of the 19th IEEE International Conference on Data Mining. Beijing, China, 280--288.Google Scholar"",""S.-J. Huang, G.-X. Li, W.-Y. Huang, and S.-Y. Li. 2020. Incremental multi-label learning with active queries. Journal of Computer Science and Technology, Vol. 35, 2 (2020), 234--246.Google ScholarCross Ref"",""M. J. Huiskes and M. S. Lew. 2008. The MIR Flickr retrieval evaluation. In Proceedings of the 1st ACM International Conference on Multimedia Information Retrieval. Vancouver, Canada, 39--43.Google Scholar"",""L. Liu and T. Dietterich. 2012. A conditional multinomial mixture model for superset label learning. In Advances in Neural Information Processing Systems 25, P. Bartlett, F. C. N. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger (Eds.). MIT Press, Cambridge, MA, 557--565.Google Scholar"",""M. Liu, Y. Luo, D. Tao, C. Xu, and Y. Wen. 2015. Low-rank multi-view learning in matrix completion for multi-label image classification. In Proceedings of the 29th AAAI Conference on Artificial Intelligence. Austin, TX, 2778--2784.Google Scholar"",""Y. Luo, D. Tao, C. Xu, C. Xu, H. Liu, and Y. Wen. 2013. Multiview vector-valued manifold regularization for multilabel image classification. IEEE Transactions on Neural Networks and Learning Systems, Vol. 24, 5 (2013), 709--722.Google ScholarCross Ref"",""Y. Ma, C. Cui, X. Nie, G. Yang, K. Shaheed, and Y. Yin. 2019. Pre-course student performance prediction with multi-instance multi-label learning. Science China Information Sciences, Vol. 62, 2 (2019), Article 029101.Google Scholar"",""L. Sun, S. Feng, T. Wang, C. Lang, and Y. Jin. 2019. Partial multi-label learning by low-rank and sparse decomposition. In Proceedings of the 33rd AAAI Conference on Artificial Intelligence. Honolulu, HI, 5016--5023.Google Scholar"",""C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna. 2016. Rethinking the inception architecture for computer vision. In Proceedings of the 29th IEEE Conference on Computer Vision and Pattern Recognition. Las Vegas, NV, 2818--2826.Google Scholar"",""Q. Tan, G. Yu, J. Wang, C. Domeniconi, and X. Zhang. in press. Individually- and commonality-based multiview multilabel learning. IEEE Transactions on Cybernetics (in press).Google Scholar"",""K. Trohidis, G. Tsoumakas, G. Kalliris, and I. Vlahavas. 2008. Multilabel classification of music into emotions. In Proceedings of the 2008 International Conference on Music Information Retrieval. Philadelphia, PA, 325--330.Google Scholar"",""L. von Ahn and L. Dabbish. 2004. Labeling images with a computer game. In Proceedings of ACM CHI 2004 Conference on Human Factors in Computing Systems. Vienna, Austria, 319--326.Google Scholar"",""D.-B. Wang, L. Li, and M.-L. Zhang. 2019 a. Adaptive graph guided disambiguation for partial label learning. In Proceedings of the 25th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. Anchorage, AK, 83--91.Google ScholarDigital Library"",""H. Wang, W. Liu, Y. Zhao, C. Zhang, T. Hu, and G. Chen. 2019 b. Discriminative and correlative partial multi-label learning. In Proceedings of the 28th International Joint Conference on Artificial Intelligence. Macau, China, 3691--3697.Google Scholar"",""X. Wu, Q.-G. Chen, Y. Hu, D. Wang, X. Chang, X. Wang, and M.-L. Zhang. 2019. Multi-view multi-label learning with view-specific information extraction. In Proceedings of the 28th International Joint Conference on Artificial Intelligence. Macau, China, 3884--3890.Google ScholarCross Ref"",""T. Xia, D. Tao, T. Mei, and Y. Zhang. 2010. Multiview spectral embedding. IEEE Transactions on System, Man, and Cybernetics - Part B: Cybernetics, Vol. 40, 6 (2010), 1438--1446.Google ScholarDigital Library"",""M.-K. Xie and S.-J. Huang. 2018. Partial multi-label learning. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence. New Orleans, LA, 4302--4309.Google Scholar"",""Y. Xing, G. Yu, C. Domeniconi, J. Wang, and Z. Zhang. 2018. Multi-label co-training. In Proceedings of the 27th International Joint Conference on Artificial Intelligence. Stockholm, Sweden, 2882--2888.Google Scholar"",""F. Yu and M.-L. Zhang. 2017. Maximum margin partial label learning. Machine Learning, Vol. 106, 4 (2017), 573--593.Google ScholarDigital Library"",""G. Yu, X. Chen, C. Domeniconi, J. Wang, Z. Li, Z. Zhang, and X. Wu. 2018. Feature-induced partial multi-label learning. In Proceedings of the 18th IEEE International Conference on Data Mining. Singapore, 1398--1403.Google Scholar"",""W. Zhan and M.-L. Zhang. 2017. Inductive semi-supervised multi-label learning with co-training. In Proceedings of the 23rd ACM SIGKDD Conference on Knowledge Discovery and Data Mining. Halifax, Canada, 1305--1314.Google ScholarDigital Library"",""C. Zhang, Z. Yu, Q. Hu, P. Zhu, X. Liu, and X. Wang. 2018b. Latent semantic aware multi-view multi-label classification. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence. New Orleans, LA, 4414--4421.Google Scholar"",""L. Zhang, Q. Zhang, L. Zhang, D. Tao, X. Huang, and B. Du. 2015. Ensemble manifold regularized sparse low-rank approximation for multiview feature embedding. Pattern Recognition, Vol. 48, 10 (2015), 3102--3112.Google ScholarDigital Library"",""M.-L. Zhang and J.-P. Fang. in press. Partial multi-label learning via credible label elicitation. IEEE Transactions on Pattern Analysis and Machine Intelligence (in press).Google Scholar"",""M.-L. Zhang, Y.-K. Li, X.-Y. Liu, and X. Geng. 2018a. Binary relevance for multi-label learning: An overview. Frontiers of Computer Science, Vol. 12, 2 (2018), 191--202.Google ScholarDigital Library"",""M.-L. Zhang and Z.-H. Zhou. 2014. A review on multi-label learning algorithms. IEEE Transactions on Knowledge and Data Engineering, Vol. 26, 8 (2014), 1819--1837.Google ScholarCross Ref"",""T. Zhang, D. Tao, X. Li, and J. Yang. 2009. Patch alignment for dimensionality reduction. IEEE Transactions on Knowledge and Data Engineering, Vol. 21, 9 (2009), 1299--1313.Google ScholarDigital Library"",""Z.-H. Zhou and M. Li. 2010. Semi-supervised learning by disagreement. Knowledge and Information Systems, Vol. 24, 3 (2010), 415--439.Google ScholarDigital Library"",""Z.-H. Zhou and M.-L. Zhang. 2017. Multi-label learning. In Encyclopedia of Machine Learning and Data Mining, C. Sammut and G. I. Webb (Eds.). Springer, Berlin, 875--881.Google Scholar"",""P. Zhu, Q. Hu, Q. Hu, C. Zhang, and Z. Feng. 2018. Multi-view label embedding. Pattern Recognition, Vol. 84 (2018), 126--135.Google ScholarCross Ref"",""X. Zhu, X. Li, and S. Zhang. 2016. Block-row sparse multiview multilabel learning for image classification. IEEE Transactions on Cybernetics, Vol. 46, 2 (2016), 450--461.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403099,MinSearch: An Efficient Algorithm for Similarity Search under Edit Distance,"We study a fundamental problem in data analytics: similarity search under edit distance (or, edit similarity search for short). In this problem we try to build an index on a set of n strings S = s1, ..., sn, with the goal of answering the following two types of queries: (1) the threshold query: given a query string t and a threshold K, output all si ∈ S such that the edit distance between si and t is at most K; (2) the top-k query: given a query string t, output the k strings in S that are closest to t in terms of edit distance. Edit similarity search has numerous applications in bioinformatics, databases, data mining, information retrieval, etc., and has been studied extensively in the literature. In this paper we propose a novel algorithm for edit similarity search named MinSearch. The algorithm is randomized, and we can show mathematically that it outputs the correct answer with high probability for both types of queries. We have conducted an extensive set of experiments on MinSearch, and compared it with the best existing algorithms for edit similarity search. Our experiments show that MinSearch has a clear advantage (often in orders of magnitudes) against the best previous algorithms in query time, and MinSearch is always one of the best among all competitors in the indexing time and space usage. Finally, MinSearch achieves perfect accuracy for both types of queries on all datasets that we have tested.","[{""name"":""Haoyu Zhang"",""id"":""/profile/99659193574""},{""name"":""Qin Zhang"",""id"":""/profile/81351602816""},{""name"":""Haoyu Zhang"",""id"":""/profile/99659193574""},{""name"":""Qin Zhang"",""id"":""/profile/81351602816""}]","[""Arvind Arasu, Venkatesh Ganti, and Raghav Kaushik. Efficient exact set-similarity joins. In PVLDB, pages 918--929, 2006.Google Scholar"",""Roberto J. Bayardo, Yiming Ma, and Ramakrishnan Srikant. Scaling up all pairs similarity search. In WWW, pages 131--140, 2007.Google ScholarDigital Library"",""Surajit Chaudhuri, Kris Ganjam, Venkatesh Ganti, and Rajeev Motwani. Robust and efficient fuzzy match for online data cleaning. In SIGMOD, pages 313--324, 2003.Google ScholarDigital Library"",""Dong Deng, Guoliang Li, and Jianhua Feng. A pivotal prefix based filtering algorithm for string similarity search. In SIGMOD, pages 673--684, 2014.Google ScholarDigital Library"",""Dong Deng, Guoliang Li, Jianhua Feng, and Wen-Syan Li. Top-k string similarity search with edit-distance constraints. In ICDE, pages 925--936, 2013.Google ScholarDigital Library"",""Aristides Gionis, Piotr Indyk, and Rajeev Motwani. Similarity search in high dimensions via hashing. In PVLDB, pages 518--529, 1999.Google ScholarDigital Library"",""Luis Gravano, Panagiotis G. Ipeirotis, H. V. Jagadish, Nick Koudas, S. Muthukrishnan, and Divesh Srivastava. Approximate string joins in a database (almost) for free. In PVLDB, pages 491--500, 2001.Google ScholarDigital Library"",""Marios Hadjieleftheriou, Nick Koudas, and Divesh Srivastava. Incremental maintenance of length normalized indexes for approximate string matching. In SIGMOD, pages 429--440, 2009.Google ScholarDigital Library"",""Zhang Haoyu and Zhang Qin. Minjoin: Efficient edit similarity joins via local hash minima. KDD, pages 1093--1103, 2019.Google Scholar"",""Wang Jiannan, Li Guoliang, and Feng Jianhua. Can we beat the prefix filtering?: an adaptive framework for similarity join and search. SIGMOD, pages 85--96, 2012.Google Scholar"",""Tamer Kahveci and Ambuj K. Singh. Efficient index structures for string databases. In PVLDB, pages 351--360, 2001.Google Scholar"",""Richard M. Karp and Michael O. Rabin. Efficient randomized pattern-matching algorithms. IBM Journal of Research and Development, 31(2):249--260, 1987.Google ScholarDigital Library"",""Chen Li, Jiaheng Lu, and Yiming Lu. Efficient merging and filtering algorithms for approximate string searches. In ICDE, pages 257--266, 2008.Google ScholarDigital Library"",""Chen Li, Bin Wang, and Xiaochun Yang. VGRAM: improving performance of approximate queries on string collections using variable-length grams. In PVLDB, pages 303--314, 2007.Google Scholar"",""Jianbin Qin, Wei Wang, Yifei Lu, Chuan Xiao, and Xuemin Lin. Efficient exact edit similarity query processing with the asymmetric signature scheme. In SIGMOD, pages 1033--1044, 2011.Google ScholarDigital Library"",""Venu Satuluri and Srinivasan Parthasarathy. Bayesian locality sensitive hashing for fast similarity search. PVLDB, 5(5):430--441, 2012.Google ScholarDigital Library"",""Esko Ukkonen. Algorithms for approximate string matching. Information and Control, 64(1--3):100--118, 1985.Google Scholar"",""Sebastian Wandelt, Dong Deng, Stefan Gerdjikov, Shashwat Mishra, Petar Mitankin, Manish Patil, Enrico Siragusa, Alexander Tiskin, Wei Wang, Jiaying Wang, and Ulf Leser. State-of-the-art in string similarity search and join. SIGMOD Record, 43(1):64--76, 2014.Google ScholarDigital Library"",""Jiannan Wang, Guoliang Li, and Jianhua Feng. Trie-join: Efficient trie-based string similarity joins with edit-distance constraints. PVLDB, 3(1):1219--1230, 2010.Google Scholar"",""Xiaoli Wang, Xiaofeng Ding, Anthony K. H. Tung, and Zhenjie Zhang. Efficient and effective KNN sequence search with approximate n-grams. PVLDB, 7(1):1--12, 2013.Google ScholarDigital Library"",""Chuan Xiao, Wei Wang, and Xuemin Lin. Ed-join: an efficient algorithm for similarity joins with edit distance constraints. PVLDB, 1(1):933--944, 2008.Google ScholarDigital Library"",""Chuan Xiao, Wei Wang, Xuemin Lin, and Jeffrey Xu Yu. Efficient similarity joins for near duplicate detection. In WWW, pages 131--140, 2008.Google ScholarDigital Library"",""Zhenglu Yang, Jianjun Yu, and Masaru Kitsuregawa. Fast algorithms for top-k approximate string matching. In AAAI, 2010.Google Scholar"",""Minghe Yu, Jin Wang, Guoliang Li, Yong Zhang, Dong Deng, and Jianhua Feng. A unified framework for string similarity search with edit-distance constraint. The VLDB Journal, 26(2):249--274, 2017.Google ScholarDigital Library"",""Jiaqi Zhai, Yin Lou, and Johannes Gehrke. ATLAS: a probabilistic algorithm for high dimensional similarity search. In SIGMOD, pages 997--1008, 2011.Google Scholar"",""Haoyu Zhang and Qin Zhang. Embedjoin: Efficient edit similarity joins via embeddings. KDD, pages 585--594, 2017.Google ScholarDigital Library"",""Zhenjie Zhang, Marios Hadjieleftheriou, Beng Chin Ooi, and Divesh Srivastava. Bed-tree: an all-purpose index structure for string similarity search based on edit distance. In SIGMOD, pages 915--926, 2010.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403100,Mining Large Quasi-cliques with Quality Guarantees from Vertex Neighborhoods,"Mining dense subgraphs is an important primitive across a spectrum of graph-mining tasks. In this work, we formally establish that two recurring characteristics of real-world graphs, namely heavy-tailed degree distributions and large clustering coefficients, imply the existence of substantially large vertex neighborhoods with high edge-density. This observation suggests a very simple approach for extracting large quasi-cliques: simply scan the vertex neighborhoods, compute the clustering coefficient of each vertex, and output the best such subgraph. The implementation of such a method requires counting the triangles in a graph, which is a well-studied problem in graph mining. When empirically tested across a number of real-world graphs, this approach reveals a surprise: vertex neighborhoods include maximal cliques of non-trivial sizes, and the density of the best neighborhood often compares favorably to subgraphs produced by dedicated algorithms for maximizing subgraph density. For graphs with small clustering coefficients, we demonstrate that small vertex neighborhoods can be refined using a local-search method to grow larger cliques and near-cliques. Our results indicate that contrary to worst-case theoretical results, mining cliques and quasi-cliques of non-trivial sizes from real-world graphs is often not a difficult problem, and provides motivation for further work geared towards a better explanation of these empirical successes.","[{""name"":""Aritra Konar"",""id"":""/profile/99659176048""},{""name"":""Nicholas D. Sidiropoulos"",""id"":""/profile/81100633355""},{""name"":""Aritra Konar"",""id"":""/profile/99659176048""},{""name"":""Nicholas D. Sidiropoulos"",""id"":""/profile/81100633355""}]","[""2015. Large Near-Clique Detection. http://github.com/tsourolampis/Scalable-Large-Near-Clique-Detection.Google Scholar"",""Noga Alon and Joel H Spencer. 2016. The probabilistic method. John Wiley \u0026 Sons.Google Scholar"",""Albert Angel, Nikos Sarkas, Nick Koudas, and Divesh Srivastava. 2012. Dense subgraph maintenance under streaming edge weight updates for real-time story identification. In Proceedings of the 38th International Conference on Very Large Data Bases. VLDB Endowment, 574--585.Google ScholarDigital Library"",""Gary D Bader and Christopher WV Hogue. 2003. An automated method for finding molecular complexes in large protein interaction networks. BMC Bioinformatics 4, 1 (2003), 2.Google ScholarCross Ref"",""Albert-László Barabási and Réka Albert. 1999. Emergence of scaling in random networks. Science 286, 5439 (1999), 509--512.Google Scholar"",""Vladimir Batagelj and Matjaz Zaversnik. 2003. An O(m) algorithm for cores decomposition of networks. arXiv preprint cs/0310049 (2003).Google Scholar"",""Coen Bron and Joep Kerbosch. 1973. Algorithm 457: Finding all cliques of an undirected graph. Commun. ACM 16, 9 (1973), 575--577.Google ScholarDigital Library"",""Gregory Buehrer and Kumar Chellapilla. 2008. A scalable pattern mining approach to web graph compression with communities. In Proceedings of the 2008 International Conference on Web Search and Data Mining. ACM, 95--106.Google ScholarDigital Library"",""Jose Cadena, Anil Kumar Vullikanti, and Charu C Aggarwal. 2016. On dense subgraphs in signed network streams. In Proceedings of the 16th IEEE International Conference on Data Mining (ICDM). IEEE, 51--60.Google ScholarCross Ref"",""Moses Charikar. 2000. Greedy approximation algorithms for finding dense components in a graph. In International Workshop on Approximation Algorithms for Combinatorial Optimization. Springer, 84--95.Google ScholarCross Ref"",""Thomas H Cormen, Charles E Leiserson, Ronald L Rivest, and Clifford Stein. 2009. Introduction to algorithms. MIT press.Google Scholar"",""Timothy A Davis and Yifan Hu. 2011. The University of Florida sparse matrix collection. ACM Transactions on Mathematical Software (TOMS) 38, 1 (2011), 1.Google ScholarDigital Library"",""David Eppstein, Maarten Löffler, and Darren Strash. 2010. Listing all maximal cliques in sparse graphs in near-optimal time. In International Symposium on Algorithms and Computation. Springer, 403--414.Google ScholarCross Ref"",""Pooya Esfandiar, Francesco Bonchi, David F Gleich, Chen Greif, Laks VS Lakshmanan, and Byung-Won On. 2010. Fast Katz and commuters: Efficient estimation of social relatedness in large networks. In International Workshop on Algorithms and Models for the Web-Graph. Springer, 132--145.Google ScholarCross Ref"",""Michalis Faloutsos, Petros Faloutsos, and Christos Faloutsos. 1999. On power-law relationships of the internet topology. In ACM SIGCOMM Computer Communication Review, Vol. 29. ACM, 251--262.Google ScholarDigital Library"",""Alessandro Ferrante, Gopal Pandurangan, and Kihong Park. 2008. On the hardness of optimization in power-law graphs. Theoretical Computer Science 393, 1--3 (2008), 220--230.Google ScholarDigital Library"",""Michael R Garey and David S Johnson. 2002. Computers and intractability.Google Scholar"",""David Gibson, Ravi Kumar, and Andrew Tomkins. 2005. Discovering large dense subgraphs in massive graphs. In Proceedings of the 31st International Conference on Very Large Data Bases. VLDB Endowment, 721--732.Google ScholarDigital Library"",""David F Gleich and C Seshadhri. 2012. Vertex neighborhoods, low conductance cuts, and good seeds for local community methods. In Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 597--605.Google ScholarDigital Library"",""Andrew V Goldberg. 1984. Finding a maximum density subgraph. Technical report, University of California Berkeley, CA.Google Scholar"",""Rishi Gupta, Tim Roughgarden, and Comandur Seshadhri. 2014. Decompositions of triangle-dense graphs. In Proceedings of the 5th conference on Innovations in Theoretical Computer Science. ACM, 471--482.Google ScholarDigital Library"",""Bryan Hooi, Hyun Ah Song, Alex Beutel, Neil Shah, Kijung Shin, and Christos Faloutsos. 2016. Fraudar: Bounding graph fraud in the face of camouflage. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 895--904.Google ScholarDigital Library"",""Matthieu Latapy. 2008. Main-memory triangle computations for very large (sparse (power-law)) graphs. Theoretical Computer Science 407, 1--3 (2008), 458--473.Google ScholarDigital Library"",""Jure Leskovec and Andrej Krevl. 2014. SNAP Datasets: Stanford Large Network Dataset Collection. http://snap.stanford.edu/data.Google Scholar"",""Zhi-Quan Luo, Wing-Kin Ma, Anthony Man-Cho So, Yinyu Ye, and Shuzhong Zhang. 2010. Semidefinite relaxation of quadratic optimization problems. IEEE Signal Processing Magazine 3, 27 (2010), 20--34.Google ScholarCross Ref"",""Michael Mitzenmacher, Jakub Pachocki, Richard Peng, Charalampos Tsourakakis, and Shen Chen Xu. 2015. Scalable large near-clique detection in large-scale networks via sampling. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 815--824.Google ScholarDigital Library"",""Mark Newman. 2018. Networks. Oxford university press.Google Scholar"",""N Prulj, Dennis A Wigle, and Igor Jurisica. 2004. Functional topology in a network of protein interactions. Bioinformatics 20, 3 (2004), 340--348.Google ScholarDigital Library"",""Stephen B Seidman. 1983. Network structure and minimum degree. Social networks 5, 3 (1983), 269--287.Google Scholar"",""Lei Tang and Huan Liu. 2009. Relational learning via latent social dimensions. In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 817--826.Google ScholarDigital Library"",""Charalampos Tsourakakis. 2015. The k-clique densest subgraph problem. In Proceedings of the 24th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 1122--1132.Google ScholarDigital Library"",""Charalampos Tsourakakis, Francesco Bonchi, Aristides Gionis, Francesco Gullo, and Maria Tsiarli. 2013. Denser than the densest subgraph: extracting optimal quasi-cliques with quality guarantees. In Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 104--112.Google ScholarDigital Library"",""Takeaki Uno. 2005. Maximal Clique Enumerator (MACE). http://research.nii.ac.jp/~uno/codes.htm.Google Scholar"",""Bimal Viswanath, Alan Mislove, Meeyoung Cha, and Krishna P Gummadi. 2009. On the evolution of user interaction in Facebook. In Proceedings of the 2nd ACM Workshop on Online social networks. ACM, 37--42.Google ScholarDigital Library"",""Duncan JWatts and Steven H Strogatz. 1998. Collective dynamics of 'small-world' networks. Nature 393, 6684 (1998), 440.Google Scholar""]"
https://doi.org/10.1145/3394486.3403101,Residual Correlation in Graph Neural Network Regression,"A graph neural network transforms features in each vertex's neighborhood into a vector representation of the vertex. Afterward, each vertex's representation is used independently for predicting its label. This standard pipeline implicitly assumes that vertex labels are conditionally independent given their neighborhood features. However, this is a strong assumption, and we show that it is far from true on many real-world graph datasets. Focusing on regression tasks, we find that this conditional independence assumption severely limits predictive power. This should not be that surprising, given that traditional graph-based semi-supervised learning methods such as label propagation work in the opposite fashion by explicitly modeling the correlation in predicted outcomes.Here, we address this problem with an interpretable and efficient framework that can improve any graph neural network architecture simply by exploiting correlation structure in the regression residuals. In particular, we model the joint distribution of residuals on vertices with a parameterized multivariate Gaussian, and estimate the parameters by maximizing the marginal likelihood of the observed labels. Our framework achieves substantially higher accuracy than competing baselines, and the learned parameters can be interpreted as the strength of correlation among connected vertices. Furthermore, we develop linear time algorithms for low-variance, unbiased model parameter estimates, allowing us to scale to large networks. We also provide a basic version of our method that makes stronger assumptions on correlation structure but is painless to implement, often leading to great practical performance with minimal overhead.","[{""name"":""Junteng Jia"",""id"":""/profile/99659346355""},{""name"":""Austion R. Benson"",""id"":""/profile/99659574988""},{""name"":""Junteng Jia"",""id"":""/profile/99659346355""},{""name"":""Austion R. Benson"",""id"":""/profile/99659574988""}]","[""Rie Kubota Ando and Tong Zhang. 2006. Learning on Graph with Laplacian Regularization. In NeurIPS.Google Scholar"",""Haim Avron and Sivan Toledo. 2011. Randomized Algorithms for Estimating the Trace of an Implicit Symmetric Positive Semi-Definite Matrix. J. ACM (2011).Google Scholar"",""Mikhail Belkin, Partha Niyogi, and Vikas Sindhwani. 2006. Manifold Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples. J. Mach. Learn. Res. (2006).Google Scholar"",""Fan RK Chung and Fan Chung Graham. 1997. Spectral graph theory. Number 92. American Mathematical Soc.Google Scholar"",""Barry A. Cipra. 1987. An Introduction to the Ising Model. Am. Math. Monthly (1987).Google Scholar"",""Kun Dong, Austin R Benson, and David Bindel. 2019. Network density of states. In KDD.Google Scholar"",""David Easley and Jon Kleinberg. 2010. Networks, Crowds, and Markets: Reasoning About a Highly Connected World .Cambridge University Press.Google Scholar"",""Juan Fernández-Gracia et al. 2014. Is the Voter Model a Model for Voters? Physical Review Letters (2014).Google Scholar"",""JK Fitzsimons, MA Osborne, SJ Roberts, and JF Fitzsimons. 2018. Improved stochastic trace estimation using mutually unbiased bases. AUAI Press.Google Scholar"",""Jerome Friedman, Trevor Hastie, and Robert Tibshirani. 2001. The Elements of Statistical Learning .Springer.Google Scholar"",""Hongchang Gao, Jian Pei, and Heng Huang. 2019. Conditional Random Field Enhanced Graph Convolutional Neural Networks. In KDD.Google Scholar"",""Jacob Gardner et al. 2018. GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration. In NeurIPS.Google Scholar"",""William L. Hamilton, Rex Ying, and Jure Leskovec. 2017a. Inductive Representation Learning on Large Graphs. In NeurIPS.Google Scholar"",""William L Hamilton, Rex Ying, and Jure Leskovec. 2017b. Representation learning on graphs: Methods and applications. IEEE Data Engineering Bulletin (2017).Google Scholar"",""Ken Hayami. 2018. Convergence of the Conjugate Gradient Method on Singular Systems. NII Technical Reports (2018).Google Scholar"",""M.F. Hutchinson. 1989. A Stochastic Estimator of the Trace of the Influence Matrix for Laplacian Smoothing Splines. Communications in Statistics - Simulation and Computation (1989).Google Scholar"",""Rania Ibrahim and David Gleich. 2019. Nonlinear Diffusion for Community Detection and Semi-Supervised Learning. In WWW.Google Scholar"",""Mike Innes. 2018. Flux: Elegant Machine Learning with Julia. Journal of Open Source Software (2018).Google Scholar"",""Junteng Jia, Michael T. Schaub, Santiago Segarra, and Austin R. Benson. 2019. Graph-Based Semi-Supervised \u0026 Active Learning for Edge Flows. In KDD.Google Scholar"",""Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In ICLR.Google Scholar"",""Martina Morris and Richard Rothenberg. 2011. HIV Transmission Network Metastudy Project: An Archive of Data From Eight Network Studies, 1988--2001 .Inter-university Consortium for Political and Social Research.Google Scholar"",""Mark Newman. 2010. Networks: An Introduction .Oxford University Press.Google Scholar"",""Meng Qu, Yoshua Bengio, and Jian Tang. 2019. GMNN: Graph Markov Neural Networks. ICML.Google Scholar"",""Carl Edward Rasmussen. 2003. Gaussian processes in machine learning. In Summer School on Machine Learning. Springer, 63--71.Google Scholar"",""Benedek Rozemberczki, Carl Allen, and Rik Sarkar. 2019. Multi-scale Attributed Node Embedding. arXiv preprint arXiv:1909.13021 (2019).Google Scholar"",""Cosma Shalizi. 2015. Weighted and Generalized Least Squares. https://www.stat.cmu.edu/ cshalizi/mreg/15/lectures/24/lecture-24--25.pdf.Google Scholar"",""Jelena Stojanovic et al. 2015. Semi-supervised learning for structured regression on partially observed attributed graphs. In ICDM.Google Scholar"",""Shashanka Ubaru, Jie Chen, and Yousef Saad. 2017. Fast Estimation of tr(f(A)) via Stochastic Lanczos Quadrature. SIAMX (2017).Google Scholar"",""Petar Velivcković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. 2018. Graph Attention Networks. ICLR (2018).Google Scholar"",""David S. Watkins. 2007. The Matrix Eigenvalue Problem .Society for Industrial and Applied Mathematics.Google Scholar"",""Duncan J Watts and Steven H Strogatz. 1998. Collective dynamics of small-world'networks. Nature (1998).Google Scholar"",""Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2019. How Powerful are Graph Neural Networks?. In ICLR.Google Scholar"",""Ya Xu, Justin S Dyer, and Art B Owen. 2010. Empirical Stationary Correlations for Semi-supervised Learning on Graphs: Network Modeling. AOAS (2010).Google Scholar"",""Jiaxuan You, Rex Ying, and Jure Leskovec. 2019. Position-aware graph neural networks. ICML (2019).Google Scholar"",""Dengyong Zhou et al. 2004. Learning with Local and Global Consistency. In NeurIPS.Google Scholar"",""Jie Zhou et al. 2018. Graph neural networks: A review of methods and applications. arXiv preprint arXiv:1812.08434 (2018).Google Scholar"",""Xiaojin Zhu, Zoubin Ghahramani, and John Lafferty. 2003. Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions. In ICML.Google Scholar""]"
https://doi.org/10.1145/3394486.3403102,Towards Fair Truth Discovery from Biased Crowdsourced Answers,"Crowdsourcing systems have gained considerable interest and adoption in recent years. One important research problem for crowdsourcing systems is truth discovery, which aims to aggregate noisy answers contributed by the workers to obtain the correct answer (truth) of each task. However, since the collected answers are highly prone to the workers' biases, aggregating these biased answers without proper treatment will unavoidably lead to discriminatory truth discovery results for particular race, gender and political groups. To address this challenge, in this paper, first, we define a new fairness notion named θ-disparity for truth discovery. Intuitively, θ-disparity bounds the difference in the probabilities that the truth of both protected and unprotected groups being predicted to be positive. Second, we design three fairness enhancing methods, namely Pre-TD, FairTD, and Post-TD, for truth discovery. Pre-TD is a pre-processing method that removes the bias in workers' answers before truth discovery. FairTD is an in-processing method that incorporates fairness into the truth discovery process. And Post-TD is a post-processing method that applies additional treatment on the discovered truth to make it satisfy θ-disparity. We perform an extensive set of experiments on both synthetic and real-world crowdsourcing datasets. Our results demonstrate that among the three fairness enhancing methods, FairTD produces the best accuracy with θ-disparity. In some settings, the accuracy of FairTD is even better than truth discovery without fairness, as it removes some low-quality answers as side effects.","[{""name"":""Yanying Li"",""id"":""/profile/99659350683""},{""name"":""Haipei Sun"",""id"":""/profile/99659352218""},{""name"":""Wendy Hui Wang"",""id"":""/profile/81414595229""},{""name"":""Yanying Li"",""id"":""/profile/99659350683""},{""name"":""Haipei Sun"",""id"":""/profile/99659352218""},{""name"":""Wendy Hui Wang"",""id"":""/profile/81414595229""}]","[""Propublica. https://www.propublica.org/datastore/ dataset/compasrecidivism-risk-score-data-and-analysis.Google Scholar"",""B. I. Aydin, Y. S. Yilmaz, Y. Li, Q. Li, J. Gao, and M. Demirbas. Crowdsourcing for multiple-choice question answering. In Twenty-Sixth IAAI Conference, 2014.Google Scholar"",""A. Brew, D. Greene, and P. Cunningham. Using crowdsourcing and active learning to track sentiment in online media. In ECAI, pages 145--150, 2010.Google ScholarDigital Library"",""T. Calders, F. Kamiran, and M. Pechenizkiy. Building classifiers with independency constraints. In 2009 IEEE International Conference on Data Mining Workshops, pages 13--18. IEEE, 2009.Google ScholarDigital Library"",""T. Calders and S. Verwer. Three naive bayes approaches for discrimination-free classification. Data Mining and Knowledge Discovery, 21(2):277--292, 2010.Google ScholarDigital Library"",""A. Chouldechova. Fair prediction with disparate impact: A study of bias in recidivism prediction instruments. Big data, 5(2):153--163, 2017.Google ScholarCross Ref"",""A. P. Dawid and A. M. Skene. Maximum likelihood estimation of observer error-rates using the em algorithm. Journal of the Royal Statistical Society: Series C (Applied Statistics), 28(1):20--28, 1979.Google Scholar"",""G. Demartini, D. E. Difallah, and P. Cudré-Mauroux. Zencrowd: leveraging probabilistic reasoning and crowdsourcing techniques for large-scale entity linking. In Proceedings of the 21st international conference on World Wide Web, pages 469--478. ACM, 2012.Google ScholarDigital Library"",""J. Dressel and H. Farid. The accuracy, fairness, and limits of predicting recidivism. Science advances, 4(1):eaao5580, 2018.Google Scholar"",""C. Dwork, M. Hardt, T. Pitassi, O. Reingold, and R. Zemel. Fairness through awareness. In Proceedings of the 3rd innovations in theoretical computer science conference, pages 214--226. ACM, 2012.Google ScholarDigital Library"",""M. Feldman, S. A. Friedler, J. Moeller, C. Scheidegger, and S. Venkatasubramanian. Certifying and removing disparate impact. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 259--268. ACM, 2015.Google ScholarDigital Library"",""G. Goh, A. Cotter, M. Gupta, and M. P. Friedlander. Satisfying real-world goals with dataset constraints. In Advances in Neural Information Processing Systems, pages 2415--2423, 2016.Google ScholarDigital Library"",""E. Granell and C.-D. Martinez-Hinarejos. Multimodal crowdsourcing for transcribing handwritten documents. IEEE/ACM transactions on audio, speech, and language processing, 25(2):409--419, 2016.Google Scholar"",""M. Hardt, E. Price, and N. Srebro. Equality of opportunity in supervised learning. In Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016, December 5--10, 2016, Barcelona, Spain, pages 3315--3323, 2016.Google Scholar"",""M. Hardt, E. Price, N. Srebro, et al. Equality of opportunity in supervised learning. In Advances in neural information processing systems, pages 3315--3323, 2016.Google ScholarDigital Library"",""A. Inc. Amazon mechanical turk. https://www.mturk.com/mturk.Google Scholar"",""C. Inc. Data for everyone. https://www.crowdflower.com/data-for-everyone/.Google Scholar"",""E. Kamar, S. Hacker, and E. Horvitz. Combining human and machine intelligence in large-scale crowdsourcing. In Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems-Volume 1, pages 467--474. International Foundation for Autonomous Agents and Multiagent Systems, 2012.Google ScholarDigital Library"",""F. Kamiran and T. Calders. Classifying without discriminating. In 2009 2nd International Conference on Computer, Control and Communication, pages 1--6. IEEE, 2009.Google ScholarCross Ref"",""F. Kamiran and T. Calders. Data preprocessing techniques for classification without discrimination. Knowledge and Information Systems, 33(1):1--33, 2012.Google ScholarDigital Library"",""T. Kamishima, S. Akaho, and J. Sakuma. Fairness-aware learning through regularization approach. In 2011 IEEE 11th International Conference on Data Mining Workshops, pages 643--650. IEEE, 2011.Google ScholarDigital Library"",""D. R. Karger, S. Oh, and D. Shah. Iterative learning for reliable crowdsourcing systems. In Advances in neural information processing systems, pages 1953--1961, 2011.Google ScholarDigital Library"",""J. M. Kleinberg, S. Mullainathan, and M. Raghavan. Inherent trade-offs in the fair determination of risk scores. In 8th Innovations in Theoretical Computer Science Conference, ITCS, pages 43:1--43:23, 2017.Google Scholar"",""Q. Li, Y. Li, J. Gao, L. Su, B. Zhao, M. Demirbas, W. Fan, and J. Han. A confidence-aware approach for truth discovery on long-tail data. Proceedings of the VLDB Endowment, 8(4):425--436, 2014.Google ScholarDigital Library"",""Y. Li, J. Gao, C. Meng, Q. Li, L. Su, B. Zhao, W. Fan, and J. Han. A survey on truth discovery. ACM Sigkdd Explorations Newsletter, 17(2):1--16, 2016.Google ScholarDigital Library"",""D. Morocho, M. Proa no, D. Alulema, A. Morales, and J. Fierrez. Signature recognition: Human performance analysis vs. automatic system and feature extraction via crowdsourcing. In Mexican Conference on Pattern Recognition, pages 324--334. Springer, 2016.Google ScholarCross Ref"",""V. C. Raykar, S. Yu, L. H. Zhao, G. H. Valadez, C. Florin, L. Bogoni, and L. Moy. Learning from crowds. Journal of Machine Learning Research, 11(Apr):1297--1322, 2010.Google Scholar"",""P. Welinder, S. Branson, P. Perona, and S. J. Belongie. The multidimensional wisdom of crowds. In Advances in neural information processing systems, pages 2424--2432, 2010.Google ScholarDigital Library"",""J. Whitehill, T.-f. Wu, J. Bergsma, J. R. Movellan, and P. L. Ruvolo. Whose vote should count more: Optimal integration of labels from labelers of unknown expertise. In Advances in neural information processing systems, pages 2035--2043, 2009.Google ScholarDigital Library"",""M. B. Zafar, I. Valera, M. Gomez Rodriguez, and K. P. Gummadi. Fairness beyond disparate treatment \u0026 disparate impact: Learning classification without disparate mistreatment. In Proceedings of the 26th International Conference on World Wide Web, pages 1171--1180. International World Wide Web Conferences Steering Committee, 2017.Google ScholarDigital Library"",""Y. Zheng, G. Li, Y. Li, C. Shan, and R. Cheng. Truth inference in crowdsourcing: is the problem solved? Proceedings of the VLDB Endowment, 10(5):541--552, 2017.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403103,AutoShuffleNet: Learning Permutation Matrices via an Exact Lipschitz Continuous Penalty in Deep Convolutional Neural Networks,"ShuffleNet is a state-of-the-art light weight convolutional neural network architecture. Its basic operations include group, channel-wise convolution and channel shuffling. However, channel shuffling is manually designed on empirical grounds. Mathematically, shuffling is a multiplication by a permutation matrix. In this paper, we propose to automate channel shuffling by learning permutation matrices in network training. We introduce an exact Lipschitz continuous non-convex penalty so that it can be incorporated in the stochastic gradient descent to approximate permutation at high precision. Exact permutations are obtained by simple rounding at the end of training and are used in inference. The resulting network, referred to as AutoShuffleNet, achieved improved classification accuracies on data from CIFAR-10, CIFAR-100 and ImageNet while preserving the inference costs of ShuffleNet. In addition, we found experimentally that the standard convex relaxation of permutation matrices into stochastic matrices leads to poor performance. We prove theoretically the exactness (error bounds) in recovering permutation matrices when our penalty function is zero (very small). We present examples of permutation optimization through graph matching and two-layer neural network models where the loss functions are calculated in closed analytical form. In the examples, convex relaxation failed to capture permutations whereas our penalty succeeded.","[{""name"":""Jiancheng Lyu"",""id"":""/profile/99659574566""},{""name"":""Shuai Zhang"",""id"":""/profile/99659574630""},{""name"":""Yingyong Qi"",""id"":""/profile/99659574028""},{""name"":""Jack Xin"",""id"":""/profile/99659573546""},{""name"":""Jiancheng Lyu"",""id"":""/profile/99659574566""},{""name"":""Shuai Zhang"",""id"":""/profile/99659574630""},{""name"":""Yingyong Qi"",""id"":""/profile/99659574028""},{""name"":""Jack Xin"",""id"":""/profile/99659573546""}]","[""Y. Aalo, A. Bronstein, and R. Kimmel. 2015. On convex relaxation of graph isomorphism. Proc. National Academy Sci, Vol. 112(10) (2015), 2942--2947.Google ScholarCross Ref"",""R Badhwar and G Bagler. 2015. Control of Neuronal Network in Caenorhabditis elegans. PLOS One, Vol. 10(9) (2015).Google ScholarCross Ref"",""R. Burkard. 2013. The quadratic assignment problem. in: Handbook of Combinatorial Optimization (2013), 2741--2814.Google ScholarCross Ref"",""Rodrigo Santa Cruz, Basura Fernando, Anoop Cherian, and Stephen Gould. 2018. Visual Permutation Learning. IEEE Pattern Analysis and Machine Intelligence (2018).Google Scholar"",""Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Fei-Fei Li. 2009. ImageNet: A Large-Scale Hierarchical Image Database. CVPR (2009), 248--255.Google Scholar"",""Ernie Esser, Yifei Lou, and Jack Xin. 2013. A Method for Finding Structured Sparse Solutions to Non-negative Least Squares Problems with Applications. SIAM J. Imaging Sciences, Vol. 6 (2013), 2010--2046.Google ScholarCross Ref"",""Aude Genevay, Gabriel Peyré, and Marco Cuturi. 2018. Learning Generative Models with Sinkhorn Divergences. AISTATS (2018).Google Scholar"",""T. Koopmans and M. Beckman. 1957. Assignment problems and the location of economic activities. The Econometric Society, Vol. 25 (1957), 53--76.Google ScholarCross Ref"",""Alex Krizhevsky. 2009. Learning Multiple Layers of Features from Tiny Images. Tech Report (2009).Google Scholar"",""Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. 2012. Imagenet classification with deep convolutional neural networks. NeurIPS (2012), 1097--1105.Google Scholar"",""Y. Li and Y. Yuan. 2017. Convergence analysis of two-layer neural networks with ReLU activation. NeurIPS (2017).Google Scholar"",""C. Lim and S. Wright. 2016. A Box-Constrained Approach for Hard Permutation Problems. ICML (2016), 10 pages.Google Scholar"",""V. Lyzinski, D. Fishkind, M. Fiori, J. Vogelstein, C. Priebe, and G. Sapiro. 2014. Graph matching: Relax at your own risk. arXiv preprint 1405.3133 (2014).Google Scholar"",""Ningning Ma, Xiangyu Zhang, Hai-Tao Zheng, and Jian Sun. 2018. ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design. ECCV (2018).Google Scholar"",""G. Mena, D. Belanger, Linderman S, and J. Snoek. 2018. Learning Latent Permutations with Gumbel-Sinkhorn Networks. ICLR (2018).Google Scholar"",""Richard Sinkhorn. 1964. A relationship between arbitrary positive matrices and doubly stochastic matrices. The annals of mathematical statistics, Vol. 35(2) (1964), 876--879.Google Scholar"",""K. Sun, M. Li, D. Liu, and J. Wang. 2018. IGCV3: Interleaved Low-Rank Group Convolutions for Efficient Deep Neural Networks. BMVC (2018).Google Scholar"",""J. Vogelstein, J. Conroy, V. Lyzinski, L. Podrazik, S. Kratzer, E. Harley, D. Fishkind, R. Vogelstein, and C. Priebe. 2015. Fast approximate quadratic programming for graph matching. PloS one, Vol. 10(4) (2015).Google Scholar"",""Y. Yang, S. Hallman, D. Ramanan, and C. Fowlkes. 2011. Layered Object Models for Image Segmentation. IEEE Pattern Analysis and Machine Intelligence (2011).Google Scholar"",""Penghang Yin, Yifei Lou, Qi He, and Jack Xin. 2015. Minimization of $ell_1--2$ for compressed sensing. SIAM J. Sci. Computing, Vol. 37(1) (2015), A536--A563.Google Scholar"",""M. Zaslavskiy, F. Bach, and J. Vert. 2009. A path following algorithm for the graph matching problem. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 31 (2009), 2227--2242.Google ScholarDigital Library"",""T. Zhang, G-J Qi, B. Xiao, and J. Wang. 2017a. Interleaved group convolutions. CVPR (2017), 4373--4382.Google Scholar"",""Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, and Jian Sun. 2017b. Shufflenet: An extremely efficient convolutional neural network for mobile devices. CVPR (2017).Google Scholar"",""Ritchie Zhao, Yuwei Hu, Jordan Dotzel, Christopher De Sa, and Zhiru Zhang. 2019. Building Efficient Deep Neural Networks with Unitary Group Convolutions. CVPR (2019).Google Scholar""]"
https://doi.org/10.1145/3394486.3403104,MoFlow: An Invertible Flow Model for Generating Molecular Graphs,"Generating molecular graphs with desired chemical properties driven by deep graph generative models provides a very promising way to accelerate drug discovery process. Such graph generative models usually consist of two steps: learning latent representations and generation of molecular graphs. However, to generate novel and chemically-valid molecular graphs from latent representations is very challenging because of the chemical constraints and combinatorial complexity of molecular graphs. In this paper, we propose MoFlow, a flow-based graph generative model to learn invertible mappings between molecular graphs and their latent representations. To generate molecular graphs, our MoFlow first generates bonds (edges) through a Glow based model, then generates atoms (nodes) given bonds by a novel graph conditional flow, and finally assembles them into a chemically valid molecular graph with a posthoc validity correction. Our MoFlow has merits including exact and tractable likelihood training, efficient one-pass embedding and generation, chemical validity guarantees, 100% reconstruction of training data, and good generalization ability. We validate our model by four tasks: molecular graph generation and reconstruction, visualization of the continuous latent space, property optimization, and constrained property optimization. Our MoFlow achieves state-of-the-art performance, which implies its potential efficiency and effectiveness to explore large chemical space for drug discovery.","[{""name"":""Chengxi Zang"",""id"":""/profile/99659060484""},{""name"":""Fei Wang"",""id"":""/profile/99658710924""},{""name"":""Chengxi Zang"",""id"":""/profile/99659060484""},{""name"":""Fei Wang"",""id"":""/profile/99658710924""}]","[""Jerry Avorn. 2015. The $2.6 billion pill-ethodologic and policy considerations. New England Journal of Medicine, Vol. 372, 20 (2015), 1877--1879.Google ScholarCross Ref"",""Dávid Bajusz, Anita Rácz, and Károly Héberger. 2015. Why is Tanimoto index an appropriate choice for fingerprint-based similarity calculations? Journal of cheminformatics, Vol. 7, 1 (2015), 20.Google ScholarCross Ref"",""G Richard Bickerton, Gaia V Paolini, Jérémy Besnard, Sorel Muresan, and Andrew L Hopkins. 2012. Quantifying the chemical beauty of drugs. Nature chemistry, Vol. 4, 2 (2012), 90.Google Scholar"",""Xavier Bresson and Thomas Laurent. 2019. A Two-Step Graph Convolutional Decoder for Molecule Generation. arXiv preprint arXiv:1906.03412 (2019).Google Scholar"",""Hanjun Dai, Yingtao Tian, Bo Dai, Steven Skiena, and Le Song. 2018. Syntax-directed variational autoencoder for structured data. arXiv preprint arXiv:1802.08786 (2018).Google Scholar"",""Nicola De Cao and Thomas Kipf. 2018. MolGAN: An implicit generative model for small molecular graphs. arXiv preprint arXiv:1805.11973 (2018).Google Scholar"",""Laurent Dinh, David Krueger, and Yoshua Bengio. 2014. Nice: Non-linear independent components estimation. arXiv preprint arXiv:1410.8516 (2014).Google Scholar"",""Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. 2016. Density estimation using real nvp. arXiv preprint arXiv:1605.08803 (2016).Google Scholar"",""Rafael Gómez-Bombarelli, Jennifer N Wei, David Duvenaud, José Miguel Hernández-Lobato, Benjam'in Sánchez-Lengeling, Dennis Sheberla, Jorge Aguilera-Iparraguirre, Timothy D Hirzel, Ryan P Adams, and Alán Aspuru-Guzik. 2018. Automatic chemical design using a data-driven continuous representation of molecules. ACS central science, Vol. 4, 2 (2018), 268--276.Google Scholar"",""Shion Honda, Hirotaka Akita, Katsuhiko Ishiguro, Toshiki Nakanishi, and Kenta Oono. 2019. Graph residual flow for molecular graph generation. arXiv preprint arXiv:1909.13521 (2019).Google Scholar"",""John J Irwin, Teague Sterling, Michael M Mysinger, Erin S Bolstad, and Ryan G Coleman. 2012. ZINC: a free tool to discover chemistry for biology. Journal of chemical information and modeling, Vol. 52, 7 (2012), 1757--1768.Google ScholarCross Ref"",""Wengong Jin, Regina Barzilay, and Tommi Jaakkola. 2018. Junction tree variational autoencoder for molecular graph generation. arXiv preprint arXiv:1802.04364 (2018).Google Scholar"",""Durk P Kingma and Prafulla Dhariwal. 2018. Glow: Generative flow with invertible 1x1 convolutions. In Advances in Neural Information Processing Systems. 10215--10224.Google Scholar"",""Ivan Kobyzev, Simon Prince, and Marcus A Brubaker. 2019. Normalizing flows: Introduction and ideas. arXiv preprint arXiv:1908.09257 (2019).Google Scholar"",""Matt J Kusner, Brooks Paige, and José Miguel Hernández-Lobato. 2017. Grammar variational autoencoder. In Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 1945--1954.Google ScholarDigital Library"",""Greg Landrum et al. 2006. RDKit: Open-source cheminformatics.Google Scholar"",""Jenny Liu, Aviral Kumar, Jimmy Ba, Jamie Kiros, and Kevin Swersky. 2019. Graph normalizing flows. In Advances in Neural Information Processing Systems. 13556--13566.Google Scholar"",""Qi Liu, Miltiadis Allamanis, Marc Brockschmidt, and Alexander Gaunt. 2018. Constrained graph variational autoencoders for molecule design. In Advances in Neural Information Processing Systems. 7795--7804.Google Scholar"",""Tengfei Ma, Jie Chen, and Cao Xiao. 2018. Constrained generation of semantically valid graphs via regularizing variational autoencoders. In Advances in Neural Information Processing Systems. 7113--7124.Google Scholar"",""Kaushalya Madhawa, Katushiko Ishiguro, Kosuke Nakago, and Motoki Abe. 2019. GraphNVP: An Invertible Flow Model for Generating Molecular Graphs. arXiv preprint arXiv:1905.11600 (2019).Google Scholar"",""Asher Mullard. 2017. The drug-maker's guide to the galaxy. Nature News, Vol. 549, 7673 (2017), 445.Google ScholarCross Ref"",""George Papamakarios, Eric Nalisnick, Danilo Jimenez Rezende, Shakir Mohamed, and Balaji Lakshminarayanan. 2019. Normalizing Flows for Probabilistic Modeling and Inference. arXiv preprint arXiv:1912.02762 (2019).Google Scholar"",""Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Łukasz Kaiser, Noam Shazeer, Alexander Ku, and Dustin Tran. 2018. Image transformer. arXiv preprint arXiv:1802.05751 (2018).Google Scholar"",""Steven M Paul, Daniel S Mytelka, Christopher T Dunwiddie, Charles C Persinger, Bernard H Munos, Stacy R Lindborg, and Aaron L Schacht. 2010. How to improve R\u0026D productivity: the pharmaceutical industry's grand challenge. Nature reviews Drug discovery, Vol. 9, 3 (2010), 203.Google Scholar"",""Mariya Popova, Mykhailo Shvets, Junier Oliva, and Olexandr Isayev. 2019. MolecularRNN: Generating realistic molecular graphs with optimized properties. arXiv preprint arXiv:1905.13372 (2019).Google Scholar"",""Raghunathan Ramakrishnan, Pavlo O Dral, Matthias Rupp, and O Anatole Von Lilienfeld. 2014. Quantum chemistry structures and properties of 134 kilo molecules. Scientific data, Vol. 1 (2014), 140022.Google Scholar"",""David Rogers and Mathew Hahn. 2010. Extended-connectivity fingerprints. Journal of chemical information and modeling, Vol. 50, 5 (2010), 742--754.Google ScholarCross Ref"",""Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den Berg, Ivan Titov, and Max Welling. 2018. Modeling relational data with graph convolutional networks. In European Semantic Web Conference. Springer, 593--607.Google ScholarCross Ref"",""Chence Shi, Minkai Xu, Zhaocheng Zhu, Weinan Zhang, Ming Zhang, and Jian. Tang. 2020. GraphAF: a Flow-based Autoregressive Model for Molecular Graph Generation. ICLR 2020, Addis Ababa, Ethiopia, Apr.26-Apr. 30, 2020 (2020).Google Scholar"",""Martin Simonovsky and Nikos Komodakis. 2018. Graphvae: Towards generation of small graphs using variational autoencoders. In International Conference on Artificial Neural Networks. Springer, 412--422.Google ScholarCross Ref"",""Mengying Sun, Sendong Zhao, Coryandar Gilvary, Olivier Elemento, Jiayu Zhou, and Fei Wang. 2019. Graph convolutional networks for computational drug development and discovery. Briefings in bioinformatics (2019).Google Scholar"",""David Weininger, Arthur Weininger, and Joseph L Weininger. 1989. SMILES. 2. Algorithm for generation of unique SMILES notation. Journal of chemical information and computer sciences, Vol. 29, 2 (1989), 97--101.Google ScholarCross Ref"",""Jiaxuan You, Bowen Liu, Zhitao Ying, Vijay Pande, and Jure Leskovec. 2018. Graph convolutional policy network for goal-directed molecular graph generation. In Advances in Neural Information Processing Systems. 6410--6421.Google Scholar"",""Alex Zhavoronkov, Yan A Ivanenkov, Alex Aliper, Mark S Veselov, Vladimir A Aladinskiy, Anastasiya V Aladinskaya, Victor A Terentiev, Daniil A Polykovskiy, Maksim D Kuznetsov, et al. 2019. Deep learning enables rapid identification of potent DDR1 kinase inhibitors. Nature biotechnology, Vol. 37, 9 (2019), 1038--1040.Google Scholar""]"
https://doi.org/10.1145/3394486.3403105,Parallel DNN Inference Framework Leveraging a Compact RISC-V ISA-based Multi-core System,"RISC-V is an open-source instruction set and now has been examined as a universal standard to unify the heterogeneous platforms. However, current research focuses primarily on the design and fabrication of general-purpose processors based on RISC-V, despite the fact that in the era of IoT (Internet of Things), the fusion of heterogeneous platforms should also take application-specific processors into account. Accordingly, this paper proposes a collaborative RISC-V multi-core system for Deep Neural Network (DNN) accelerators. To the best of our knowledge, this is the first time that a multi-core scheduling architecture for DNN acceleration is formulated and RISC-V is explored as the ISA of a multi-core system to bridge the gap between the memory and the DNN Processor in order to increase the entire system throughput. The experiment realizes a four-stage design of the RISC-V core, and further reveals that a multi-core design along with an appropriate scheduling algorithm can efficiently decrease the runtime and elevate the throughput. Moreover, the experiment also provides us with a constructive suggestion regarding the ideal proportion of the cores to Process Engines (PE), which provides us with significant assistance in building highly efficient AI System-on-Chips (SoCs) in resource-aware situations.","[{""name"":""Yipeng Zhang"",""id"":""/profile/99659336831""},{""name"":""Bo Du"",""id"":""/profile/81456618823""},{""name"":""Lefei Zhang"",""id"":""/profile/99658724017""},{""name"":""Jia Wu"",""id"":""/profile/99658656198""},{""name"":""Yipeng Zhang"",""id"":""/profile/99659336831""},{""name"":""Bo Du"",""id"":""/profile/81456618823""},{""name"":""Lefei Zhang"",""id"":""/profile/99658724017""},{""name"":""Jia Wu"",""id"":""/profile/99658656198""}]","[""Xiaobing Chen, Shaohui Peng, Luyang Jin, Yimin Zhuang, Jin Song, Weijian Du, Shaoli Liu, and Tian Zhi. 2019. Partition and Scheduling Algorithms for Neural Network Accelerators. In Advanced Parallel Processing Technologies - 13th International Symposium, APPT 2019, Tianjin, China, August 15--16, 2019, Proceedings (Lecture Notes in Computer Science, Vol. 11719), Pen-Chung Yew, Per Stenströ m, Junjie Wu, Xiaoli Gong, and Tao Li (Eds.). Springer, 55--67.Google Scholar"",""Tomasz S. Czajkowski, Utku Aydonat, Dmitry Denisenko, John Freeman, Michael Kinsner, David Neto, Jason Wong, Peter Yiannacouras, and Deshanand P. Singh. 2012. From opencl to high-performance hardware on FPGAS. In International Conference on Field Programmable Logic \u0026 Applications.Google Scholar"",""Absalom E. Ezugwu, Marc Fr^i ncu, Aderemi Oluyinka Adewumi, Seyed M. Buhari, and Sahalu B. Junaidu. 2017. Neural network-based multi-agent approach for scheduling in distributed systems. Concurrency and Computation: Practice and Experience, Vol. 29, 1 (2017).Google Scholar"",""Angelo Garofalo, Manuele Rusci, Francesco Conti, Davide Rossi, and Luca Benini. 2019. PULP-NN: A Computing Library for Quantized Neural Network inference at the edge on RISC-V Based Parallel Ultra Low Power Clusters. In 26th IEEE International Conference on Electronics, Circuits and Systems, ICECS 2019, Genoa, Italy, November 27--29, 2019. IEEE, 33--36.Google ScholarCross Ref"",""Jan Gray. 2016. GRVI Phalanx: A Massively Parallel RISC-V FPGA Accelerator Accelerator. In IEEE International Symposium on Field-programmable Custom Computing Machines.Google Scholar"",""C. B. Hsu, Y. S. Hong, and J. B. Kuo. 2015. MTCMOS low-power optimization technique (LPOT) for 1V pipelined RISC CPU circuit. In IEEE International Conference on Electronics.Google Scholar"",""Rachel Huang, Jonathan Pedoeem, and Cuixian Chen. 2018. YOLO-LITE: A Real-Time Object Detection Algorithm Optimized for Non-GPU Computers. In IEEE International Conference on Big Data, Big Data 2018, Seattle, WA, USA, December 10--13, 2018. 2503--2510.Google Scholar"",""Goshgar Ismayilov and Haluk Rahmi Topcuoglu. 2020. Neural network based multi-objective evolutionary algorithm for dynamic workflow scheduling in cloud computing. Future Generation Comp. Syst., Vol. 102 (2020), 307--322.Google ScholarCross Ref"",""Michael A Iverson, Füsun Özgüner, and Gregory J Follen. 1995. Parallelizing existing applications in a distributed heterogeneous environment. In 4th Heterogeneous Computing Workshop (HCW'95). Citeseer.Google Scholar"",""Hayato Kato and Hiroshi Saito. 2019. Design of Asynchronous CNN Circuits on Commercial FPGA from Synchronous CNN Circuits. In 13th IEEE International Symposium on Embedded Multicore/Many-core Systems-on-Chip, MCSoC 2019, Singapore, Singapore, October 1--4, 2019. IEEE, 61--67.Google ScholarCross Ref"",""Jungwon Kim, Sangmin Seo, Jun Lee, Jeongho Nah, Gangwon Jo, and Jaejin Lee. 2012. SnuCL: an OpenCL framework for heterogeneous CPU/GPU clusters. Poetry, Vol. 3, 6 (2012), 304--307.Google Scholar"",""Thaddeus Koehn and Peter Athanas. 2019. Scheduling Data in Neural Network Applications. In Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, FPGA 2019, Seaside, CA, USA, February 24--26, 2019, Kia Bazargan and Stephen Neuendorffer (Eds.). ACM, 116.Google ScholarDigital Library"",""Ryosuke Kuramochi, Youki Sada, Masayuki Shimoda, Shimpei Sato, and Hiroki Nakahara. 2019. Many Universal Convolution Cores for Ensemble Sparse Convolutional Neural Networks. In 13th IEEE International Symposium on Embedded Multicore/Many-core Systems-on-Chip, MCSoC 2019, Singapore, Singapore, October 1--4, 2019. IEEE, 93--100.Google Scholar"",""C. Lamb. 2009. OpenCL for NVIDIA GPUs. In 2009 IEEE Hot Chips 21 Symposium (HCS). 1--24.Google Scholar"",""Yann LeCun, Bernhard E. Boser, John S. Denker, Donnie Henderson, Richard E. Howard, Wayne E. Hubbard, and Lawrence D. Jackel. 1989. Handwritten Digit Recognition with a Back-Propagation Network. In Advances in Neural Information Processing Systems 2, [NIPS Conference, Denver, Colorado, USA, November 27--30, 1989], David S. Touretzky (Ed.). Morgan Kaufmann, 396--404.Google Scholar"",""Jaejin Lee, Jungwon Kim, Sangmin Seo, Seungkyun Kim, Jung Ho Park, Honggyu Kim, Thanh Tuan Dao, Yongjin Cho, Sung Jong Seo, and Seung Hak Lee. 2010. An OpenCL Framework for Heterogeneous Multicores with Local Memory. In International Conference on Parallel Architectures \u0026 Compilation Techniques.Google Scholar"",""Yunsup Lee, Andrew Waterman, Rimas Avizienis, Henry Cook, Chen Sun, Vladimir Stojanovic, and Krste Asanovic. 2014. A 45nm 1.3GHz 16.7 double-precision GFLOPS/W RISC-V processor with vector accelerators. In European Solid State Circuits Conference.Google ScholarCross Ref"",""Yunsup Lee, Andrew Waterman, Henry Cook, Brian Zimmer, and Krste Asanovic. 2016. An Agile Approach to Building RISC-V Microprocessors. IEEE Micro, Vol. 36, 2 (2016), 8--20.Google ScholarDigital Library"",""Shijie Li, Xiaolong Shen, Yong Dou, Shi-Ce Ni, Jinwei Xu, Ke Yang, Qiang Wang, and Xin Niu. 2019. A Novel Memory-Scheduling Strategy for Large Convolutional Neural Network on Memory-Limited Devices. Comp. Int. and Neurosc., Vol. 2019 (2019), 4328653:1--4328653:12.Google ScholarDigital Library"",""Longlong Liao, Kenli Li, Keqin Li, Canqun Yang, and Qi Tian. 2018. UHCL-Darknet: An OpenCL-based Deep Neural Network Framework for Heterogeneous Multi-/Many-core Clusters. In Proceedings of the 47th International Conference on Parallel Processing, ICPP 2018, Eugene, OR, USA, August 13--16, 2018. ACM, 44:1--44:10.Google ScholarDigital Library"",""Katie Lim, Jonathan Balkind, and David Wentzlaff. 2019. JuxtaPiton: Enabling Heterogeneous-ISA Research with RISC-V and SPARC FPGA Soft-cores. In Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, FPGA 2019, Seaside, CA, USA, February 24--26, 2019. 184.Google ScholarDigital Library"",""Wenqi Lou, Chao Wang, Lei Gong, and Xuehai Zhou. 2019. RV-CNN: Flexible and Efficient Instruction Set for CNNs Based on RISC-V Processors. In Advanced Parallel Processing Technologies - 13th International Symposium, APPT 2019, Tianjin, China, August 15--16, 2019, Proceedings. 3--14.Google Scholar"",""Hyeongyun Moon, Jeonghun Cho, and Daejin Park. 2019. Reconfigurable Fault-Safe Processor Platform Based on RISC-V for Large-Scaled IoT-Driven Applications. In 2019 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress, DASC/PiCom/CBDCom/CyberSciTech 2019, Fukuoka, Japan, August 5--8, 2019. 627--632.Google Scholar"",""Lucas Morais, Vitor Silva, Alfredo Goldman, Carlos Á lvarez, Jaume Bosch, Michael Frank, and Guido Araujo. 2019. Adding Tightly-Integrated Task Scheduling Acceleration to a RISC-V Multi-core Processor. In Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture, MICRO 2019, Columbus, OH, USA, October 12--16, 2019. ACM, 861--872.Google ScholarDigital Library"",""Vinayak Patil, Aneesh Raveendran, P. M. Sobha, A. David Selvakumar, and D. Vivian. 2015. Out of order floating point coprocessor for RISC V ISA. In 19th International Symposium on VLSI Design and Test, VDAT 2015, Ahmedabad, India, June 26--29, 2015. 1--7.Google ScholarCross Ref"",""Karyofyllis Patsidis, Dimitris Konstantinou, Chrysostomos Nicopoulos, and Giorgos Dimitrakopoulos. 2018. A low-cost synthesizable RISC-V dual-issue processor core leveraging the compressed Instruction Set Extension. Microprocessors \u0026 Microsystems, Vol. 61 (2018), 1--10.Google ScholarCross Ref"",""Jagadish Kumar Ranbirsingh, Hanke Kimm, and Haklin Kimm. 2019. Distributed Neural Networks using TensorFlow over Multicore and Many-Core Systems. In 13th IEEE International Symposium on Embedded Multicore/Many-core Systems-on-Chip, MCSoC 2019, Singapore, Singapore, October 1--4, 2019. IEEE, 101--107.Google ScholarCross Ref"",""Joseph Redmon, Santosh Kumar Divvala, Ross B. Girshick, and Ali Farhadi. 2016. You Only Look Once: Unified, Real-Time Object Detection. In 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016, Las Vegas, NV, USA, June 27--30, 2016. 779--788.Google Scholar"",""Colin Shea and Tinoosh Mohsenin. 2019. Heterogeneous Scheduling of Deep Neural Networks for Low-power Real-time Designs. JETC, Vol. 15, 4 (2019), 36:1--36:31.Google ScholarDigital Library"",""Dongjoo Shin, Jinmook Lee, Jinsu Lee, Juhyoung Lee, and Hoi-Jun Yoo. 2017. An energy-efficient deep learning processor with heterogeneous multi-core architecture for convolutional neural networks and recurrent neural networks. In 2017 IEEE Symposium in Low-Power and High-Speed Chips, COOL Chips 2017, Yokohama, Japan, April 19--21, 2017. IEEE Computer Society, 1--2.Google ScholarCross Ref"",""Haluk Topcuoglu, Salim Hariri, and Min-You Wu. 2002. Performance-Effective and Low-Complexity Task Scheduling for Heterogeneous Computing. IEEE Trans. Parallel Distrib. Syst., Vol. 13, 3 (2002), 260--274.Google ScholarDigital Library"",""Bay Vo, Loan T. T. Nguyen, Trinh D. D. Nguyen, Philippe Fournier-Viger, and Unil Yun. 2020. A Multi-Core Approach to Efficiently Mining High-Utility Itemsets in Dynamic Profit Databases. IEEE Access, Vol. 8 (2020), 85890--85899.Google ScholarCross Ref"",""Zeyang Ye, Lihao Zhang, Keli Xiao, Wenjun Zhou, Yong Ge, and Yuefan Deng. 2018. Multi-User Mobile Sequential Recommendation: An Efficient Parallel Computing Paradigm. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining, KDD 2018, London, UK, August 19--23, 2018, Yike Guo and Faisal Farooq (Eds.). ACM, 2624--2633.Google ScholarDigital Library"",""Yipeng Zhang, Bo Du, Lefei Zhang, Rongchun Li, and Yong Dou. 2019. Accelerated Inference Framework of Sparse Neural Network Based on Nested Bitmask Structure. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019, Macao, China, August 10--16, 2019. 4355--4361.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403106,Missing Value Imputation for Mixed Data via Gaussian Copula,"Missing data imputation forms the first critical step of many data analysis pipelines. The challenge is greatest for mixed data sets, including real, Boolean, and ordinal data, where standard techniques for imputation fail basic sanity checks: for example, the imputed values may not follow the same distributions as the data. This paper proposes a new semiparametric algorithm to impute missing values, with no tuning parameters. The algorithm models mixed data as a Gaussian copula. This model can fit arbitrary marginals for continuous variables and can handle ordinal variables with many levels, including Boolean variables as a special case. We develop an efficient approximate EM algorithm to estimate copula parameters from incomplete mixed data. The resulting model reveals the statistical associations among variables. Experimental results on several synthetic and real datasets show the superiority of our proposed algorithm to state-of-the-art imputation algorithms for mixed data.","[{""name"":""Yuxuan Zhao"",""id"":""/profile/99659573487""},{""name"":""Madeleine Udell"",""id"":""/profile/99658655855""},{""name"":""Yuxuan Zhao"",""id"":""/profile/99659573487""},{""name"":""Madeleine Udell"",""id"":""/profile/99658655855""}]","[""Clifford Anderson-Bergman, Tamara G Kolda, and Kina Kincher-Winoto. 2018. XPCA: Extending PCA for a Combination of Discrete and Continuous Variables. arXiv preprint arXiv:1808.07510 (2018).Google Scholar"",""Vincent Audigier, Francc ois Husson, and Julie Josse. 2016. A principal component method to impute missing values for mixed data. Advances in Data Analysis and Classification, Vol. 10, 1 (2016), 5--26.Google ScholarDigital Library"",""Haim Avron, Satyen Kale, Shiva Kasiviswanathan, and Vikas Sindhwani. 2012. Efficient and practical stochastic subgradient descent for nuclear norm regularization. arXiv preprint arXiv:1206.6384 (2012).Google Scholar"",""Manjunath BG and Stefan Wilhelm. 2009. Moments calculation for the double truncated multivariate normal density. Available at SSRN 1472153 (2009).Google Scholar"",""Emmanuel J Candès and Benjamin Recht. 2009. Exact matrix completion via convex optimization. Foundations of Computational mathematics, Vol. 9, 6 (2009), 717.Google Scholar"",""Ruifei Cui, Ioan Gabriel Bucur, Perry Groot, and Tom Heskes. 2019. A novel Bayesian approach for latent variable modeling from mixed data with missing values. Statistics and Computing, Vol. 29, 5 (2019), 977--993.Google ScholarCross Ref"",""Aryeh Dvoretzky, Jack Kiefer, Jacob Wolfowitz, et al. 1956. Asymptotic minimax character of the sample distribution function and of the classical multinomial estimator. The Annals of Mathematical Statistics, Vol. 27, 3 (1956), 642--669.Google ScholarCross Ref"",""Jianqing Fan, Han Liu, Yang Ning, and Hui Zou. 2017. High dimensional semiparametric latent graphical model for mixed data. Journal of the Royal Statistical Society: Series B (Statistical Methodology), Vol. 79, 2 (2017), 405--421.Google ScholarCross Ref"",""Huijie Feng and Yang Ning. 2019. High-dimensional Mixed Graphical Model with Ordinal Data: Parameter Estimation and Statistical Inference. In The 22nd International Conference on Artificial Intelligence and Statistics. 654--663.Google Scholar"",""Ravi Sastry Ganti, Laura Balzano, and Rebecca Willett. 2015. Matrix completion under monotonic single index models. In Advances in Neural Information Processing Systems. 1873--1881.Google Scholar"",""Jian Guo, Elizaveta Levina, George Michailidis, and Ji Zhu. 2015. Graphical models for ordinal data. Journal of Computational and Graphical Statistics, Vol. 24, 1 (2015), 183--204.Google ScholarCross Ref"",""F Maxwell Harper and Joseph A Konstan. 2016. The movielens datasets: History and context. Acm transactions on interactive intelligent systems (tiis), Vol. 5, 4 (2016), 19.Google Scholar"",""Peter Hoff and Maintainer Peter Hoff. 2018. Package 'sbgcop'. (2018).Google Scholar"",""Peter D Hoff et al. 2007. Extending the rank likelihood for semiparametric copula estimation. The Annals of Applied Statistics, Vol. 1, 1 (2007), 265--283.Google ScholarCross Ref"",""Florian M Hollenbach, Iavor Bojinov, Shahryar Minhas, Nils W Metternich, Michael D Ward, and Alexander Volfovsky. 2018. Multiple Imputation Using Gaussian Copulas. Sociological Methods \u0026 Research (2018), 0049124118799381.Google Scholar"",""Raghunandan H Keshavan, Andrea Montanari, and Sewoong Oh. 2010. Matrix completion from noisy entries. Journal of Machine Learning Research, Vol. 11, Jul (2010), 2057--2078.Google ScholarDigital Library"",""Michael R Kosorok. 2008. Introduction to empirical processes and semiparametric inference. Springer.Google Scholar"",""Roderick JA Little and Donald B Rubin. 2019. Statistical analysis with missing data. Vol. 793. Wiley.Google Scholar"",""Han Liu, John Lafferty, and Larry Wasserman. 2009. The nonparanormal: Semiparametric estimation of high dimensional undirected graphs. Journal of Machine Learning Research, Vol. 10, Oct (2009), 2295--2328.Google ScholarDigital Library"",""Rahul Mazumder, Trevor Hastie, and Robert Tibshirani. 2010. Spectral regularization algorithms for learning large incomplete matrices. Journal of machine learning research, Vol. 11, Aug (2010), 2287--2322.Google ScholarDigital Library"",""Geoffrey McLachlan and Thriyambakam Krishnan. 2007. The EM algorithm and extensions. Vol. 382. John Wiley \u0026 Sons.Google Scholar"",""Jared S Murray, David B Dunson, Lawrence Carin, and Joseph E Lucas. 2013. Bayesian Gaussian copula factor models for mixed data. J. Amer. Statist. Assoc., Vol. 108, 502 (2013), 656--665.Google ScholarCross Ref"",""Ari Pakman and Liam Paninski. 2014. Exact hamiltonian monte carlo for truncated multivariate gaussians. Journal of Computational and Graphical Statistics, Vol. 23, 2 (2014), 518--542.Google ScholarCross Ref"",""Weiliang Qiu and Harry Joe. 2009. clusterGeneration: random cluster generation (with specified degree of separation). R package version, Vol. 1, 7 (2009), 75275--0122.Google Scholar"",""Benjamin Recht, Maryam Fazel, and Pablo A Parrilo. 2010. Guaranteed minimum-rank solutions of linear matrix equations via nuclear norm minimization. SIAM review, Vol. 52, 3 (2010), 471--501.Google Scholar"",""Jasson DM Rennie and Nathan Srebro. 2005 a. Fast maximum margin matrix factorization for collaborative prediction. In Proceedings of the 22nd international conference on Machine learning. ACM, 713--719.Google ScholarDigital Library"",""Jason DM Rennie and Nathan Srebro. 2005 b. Loss functions for preference levels: Regression with discrete ordered labels. In Proceedings of the IJCAI multidisciplinary workshop on advances in preference handling. Kluwer Norwell, MA, 180--186.Google Scholar"",""Daniel J Stekhoven. 2011. Using the missForest package. R package (2011), 1--11.Google Scholar"",""Daniel J Stekhoven and Peter Bühlmann. 2011. MissForest-non-parametric missing value imputation for mixed-type data. Bioinformatics, Vol. 28, 1 (2011), 112--118.Google ScholarDigital Library"",""Hideatsu Tsukahara. 2005. Semiparametric estimation in copula models. Canadian Journal of Statistics, Vol. 33, 3 (2005), 357--375.Google ScholarCross Ref"",""Douglas Turnbull, Luke Barrington, David Torres, and Gert Lanckriet. 2007. Towards musical query-by-semantic-description using the cal500 data set. In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval. 439--446.Google ScholarDigital Library"",""Madeleine Udell, Corinne Horn, Reza Zadeh, Stephen Boyd, et al. 2016. Generalized low rank models. Foundations and Trends® in Machine Learning, Vol. 9, 1 (2016), 1--118.Google ScholarCross Ref"",""Madeleine Udell and Alex Townsend. 2019. Why are Big Data Matrices Approximately Low Rank? SIAM Journal on Mathematics of Data Science (SIMODS), Vol. 1, 1 (2019), 144--160. https://epubs.siam.org/doi/pdf/10.1137/18M1183480Google ScholarCross Ref"",""Aad W Vaart and Jon A Wellner. 1996. Weak convergence and empirical processes: with applications to statistics. Springer.Google Scholar"",""Stef Van Buuren and Karin Oudshoorn. 1999. Flexible multivariate imputation by MICE .Leiden: TNO.Google Scholar"",""Shuo-Yang Wang, Ju-Chiang Wang, Yi-Hsuan Yang, and Hsin-Min Wang. 2014. Towards time-varying music auto-tagging based on CAL500 expansion. In 2014 IEEE International Conference on Multimedia and Expo (ICME). IEEE, 1--6.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403107,HiTANet: Hierarchical Time-Aware Attention Networks for Risk Prediction on Electronic Health Records,"Deep learning methods especially recurrent neural network based models have demonstrated early success in disease risk prediction on longitudinal patient data. Existing works follow a strong assumption to implicitly assume the stationary disease progression during each time period, and thus, take a homogeneous way to decay the information from previous time steps for all patients. However,in reality, disease progression is non-stationary. Besides, the key time steps for a target disease vary among patients. To leverage time information for risk prediction in a more reasonable way, we propose a new hierarchical time-aware attention network, named HiTANet, which imitates the decision making process of doctors inrisk prediction. Particularly, HiTANet models time information in local and global stages. The local evaluation stage has a time aware Transformer that embeds time information into visit-level embed-ding and generates local attention weight for each visit. The global synthesis stage further adopts a time-aware key-query attention mechanism to assign global weights to different time steps. Finally, the two types of attention weights are dynamically combined to generate the patient representations for further risk prediction. We evaluate HiTANet on three real-world datasets. Compared with the best results among twelve competing baselines, HiTANet achieves over 7% in terms of F1 score on all datasets, which demonstrates the effectiveness of the proposed model and the necessity of modeling time information in risk prediction task.","[{""name"":""Junyu Luo"",""id"":""/profile/99659573252""},{""name"":""Muchao Ye"",""id"":""/profile/99659573390""},{""name"":""Cao Xiao"",""id"":""/profile/99659193846""},{""name"":""Fenglong Ma"",""id"":""/profile/99659575182""},{""name"":""Junyu Luo"",""id"":""/profile/99659573252""},{""name"":""Muchao Ye"",""id"":""/profile/99659573390""},{""name"":""Cao Xiao"",""id"":""/profile/99659193846""},{""name"":""Fenglong Ma"",""id"":""/profile/99659575182""}]","[""J Malcolm O Arnold, Salim Yusuf, James Young, James Mathew, David Johnstone, Alvaro Avezum, Eva Lonn, Janice Pogue, and Jackie Bosch. 2003. Prevention of heart failure in patients in the Heart Outcomes Prevention Evaluation (HOPE) study. Circulation, Vol. 107, 9 (2003), 1284--1290.Google ScholarCross Ref"",""Tian Bai, Shanshan Zhang, Brian L Egleston, and Slobodan Vucetic. 2018. Interpretable representation learning for healthcare via capturing disease progression through time. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 43--51.Google ScholarDigital Library"",""Inci M Baytas, Cao Xiao, Xi Zhang, Fei Wang, Anil K Jain, and Jiayu Zhou. 2017. Patient subtyping via time-aware LSTM networks. In Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. ACM, 65--74.Google ScholarDigital Library"",""Luca Bertinetto, Joao F Henriques, Philip HS Torr, and Andrea Vedaldi. 2019. Meta-learning with differentiable closed-form solvers. In The International Conference on Learning Representations (ICLR).Google Scholar"",""T Douglas Bradley and John S Floras. 2003 a. Sleep apnea and heart failure: Part I: obstructive sleep apnea. Circulation, Vol. 107, 12 (2003), 1671--1678.Google ScholarCross Ref"",""T Douglas Bradley and John S Floras. 2003 b. Sleep apnea and heart failure: Part II: central sleep apnea. Circulation, Vol. 107, 13 (2003), 1822--1826.Google ScholarCross Ref"",""Prithwish Chakraborty and Faisal Farooq. 2019. A Robust Framework for Accelerated Outcome-driven Risk Factor Identification from EHR. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1800--1808.Google ScholarDigital Library"",""Zhengping Che, David Kale, Wenzhe Li, Mohammad Taha Bahadori, and Yan Liu. 2015. Deep computational phenotyping. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 507--516.Google ScholarDigital Library"",""Zhengping Che, Sanjay Purushotham, Kyunghyun Cho, David Sontag, and Yan Liu. 2018. Recurrent neural networks for multivariate time series with missing values. Scientific reports, Vol. 8, 1 (2018), 1--12.Google Scholar"",""Yu Cheng, Fei Wang, Ping Zhang, and Jianying Hu. 2016. Risk prediction with electronic health records: A deep learning approach. In Proceedings of the 2016 SIAM International Conference on Data Mining. SIAM, 432--440.Google ScholarCross Ref"",""Kyunghyun Cho, Bart Van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078 (2014).Google Scholar"",""Edward Choi, Mohammad Taha Bahadori, Elizabeth Searles, Catherine Coffey, Michael Thompson, James Bost, Javier Tejedor-Sojo, and Jimeng Sun. 2016a. Multi-layer representation learning for medical concepts. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 1495--1504.Google ScholarDigital Library"",""Edward Choi, Mohammad Taha Bahadori, Le Song, Walter F Stewart, and Jimeng Sun. 2017. GRAM: graph-based attention model for healthcare representation learning. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 787--795.Google ScholarDigital Library"",""Edward Choi, Mohammad Taha Bahadori, Jimeng Sun, Joshua Kulas, Andy Schuetz, and Walter Stewart. 2016b. Retain: An interpretable predictive model for healthcare using reverse time attention mechanism. In Advances in Neural Information Processing Systems. 3504--3512.Google Scholar"",""Edward Choi, Cao Xiao, Walter Stewart, and Jimeng Sun. 2018. Mime: Multilevel medical embedding of electronic health records for predictive healthcare. In Advances in Neural Information Processing Systems. 4547--4557.Google Scholar"",""Shannon M Dunlay, Susan A Weston, Steven J Jacobsen, and Véronique L Roger. 2009. Risk factors for heart failure: a population-based case-control study. The American journal of medicine, Vol. 122, 11 (2009), 1023--1028.Google Scholar"",""Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural computation, Vol. 9, 8 (1997), 1735--1780.Google Scholar"",""Diederik Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Bum Chul Kwon, Min-Je Choi, Joanne Taery Kim, Edward Choi, Young Bin Kim, Soonwook Kwon, Jimeng Sun, and Jaegul Choo. 2018. Retainvis: Visual analytics with interpretable and interactive recurrent neural networks on electronic medical records. IEEE transactions on visualization and computer graphics, Vol. 25, 1 (2018), 299--309.Google Scholar"",""Yikuan Li, Shishir Rao, Jose Roberto Ayala Solares, Abdelaali Hassaine, Dexter Canoy, Yajie Zhu, Kazem Rahimi, and Gholamreza Salimi-Khorshidi. 2019. BEHRT: Transformer for Electronic Health Records. arXiv preprint arXiv:1907.09538 (2019).Google Scholar"",""Andy Liaw, Matthew Wiener, et al. 2002. Classification and regression by randomForest. R news, Vol. 2, 3 (2002), 18--22.Google Scholar"",""Minh-Thang Luong, Hieu Pham, and Christopher D Manning. 2015. Effective approaches to attention-based neural machine translation. arXiv preprint arXiv:1508.04025 (2015).Google Scholar"",""Fenglong Ma, Radha Chitta, Jing Zhou, Quanzeng You, Tong Sun, and Jing Gao. 2017. Dipole: Diagnosis prediction in healthcare via attention-based bidirectional recurrent neural networks. In Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. ACM, 1903--1911.Google ScholarDigital Library"",""Fenglong Ma, Jing Gao, Qiuling Suo, Quanzeng You, Jing Zhou, and Aidong Zhang. 2018a. Risk prediction on electronic health records with prior medical knowledge. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 1910--1919.Google ScholarDigital Library"",""Fenglong Ma, Yaqing Wang, Houping Xiao, Ye Yuan, Radha Chitta, Jing Zhou, and Jing Gao. 2018b. A General Framework for Diagnosis Prediction via Incorporating Medical Code Descriptions. In 2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). IEEE, 1070--1075.Google ScholarCross Ref"",""Fenglong Ma, Quanzeng You, Houping Xiao, Radha Chitta, Jing Zhou, and Jing Gao. 2018 d. Kame: Knowledge-based attention model for diagnosis prediction in healthcare. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management. ACM, 743--752.Google ScholarDigital Library"",""Liantao Ma, Chaohe Zhang, Yasha Wang, Wenjie Ruan, Jiantao Wang, Wen Tang, Xinyu Ma, Xin Gao, and Junyi Gao. 2019. Concare: Personalized clinical feature embedding via capturing the healthcare context. arXiv preprint arXiv:1911.12216 (2019).Google Scholar"",""Liantao Ma, Chaohe Zhang, Yasha Wang, Wenjie Ruan, Jiantao Wang, Wen Tang, Xinyu Ma, Xin Gao, and Junyi Gao. 2020. Concare: Personalized clinical feature embedding via capturing the healthcare context. In Proceedings of the Thirty-Fourth AAAI Conference on Artificial Intelligence.Google ScholarCross Ref"",""Tengfei Ma, Cao Xiao, and Fei Wang. 2018c. Health-atm: A deep architecture for multifaceted patient health record representation and risk prediction. In Proceedings of the 2018 SIAM International Conference on Data Mining. SIAM, 261--269.Google ScholarCross Ref"",""Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. 2019. PyTorch: An imperative style, high-performance deep learning library. In Advances in Neural Information Processing Systems. 8024--8035.Google Scholar"",""Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. 2011. Scikit-learn: Machine learning in Python. Journal of machine learning research, Vol. 12, Oct (2011), 2825--2830.Google ScholarDigital Library"",""Trang Pham, Truyen Tran, Dinh Phung, and Svetha Venkatesh. 2016. Deepcare: A deep dynamic memory model for predictive medicine. In Pacific-Asia Conference on Knowledge Discovery and Data Mining. Springer, 30--41.Google ScholarDigital Library"",""George AF Seber and Alan J Lee. 2012. Linear regression analysis. Vol. 329. John Wiley \u0026 Sons.Google Scholar"",""Junyuan Shang, Tengfei Ma, Cao Xiao, and Jimeng Sun. 2019. Pre-training of graph augmented transformers for medication recommendation. arXiv preprint arXiv:1906.00346 (2019).Google Scholar"",""Huan Song, Deepta Rajan, Jayaraman J Thiagarajan, and Andreas Spanias. 2018. Attend and diagnose: Clinical time series analysis using attention models. In Thirty-second AAAI conference on artificial intelligence.Google Scholar"",""Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research, Vol. 15, 1 (2014), 1929--1958.Google Scholar"",""Qiuling Suo, Fenglong Ma, Giovanni Canino, Jing Gao, Aidong Zhang, Pierangelo Veltri, and Gnasso Agostino. 2017a. A multi-task framework for monitoring health conditions via attention-based recurrent neural networks. In AMIA annual symposium proceedings, Vol. 2017. American Medical Informatics Association, 1665.Google Scholar"",""Qiuling Suo, Fenglong Ma, Ye Yuan, Mengdi Huai, Weida Zhong, Jing Gao, and Aidong Zhang. 2018. Deep patient similarity learning for personalized healthcare. IEEE transactions on nanobioscience, Vol. 17, 3 (2018), 219--227.Google Scholar"",""Qiuling Suo, Fenglong Ma, Ye Yuan, Mengdi Huai, Weida Zhong, Aidong Zhang, and Jing Gao. 2017b. Personalized disease prediction using a cnn-based similarity learning method. In 2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). IEEE, 811--816.Google ScholarCross Ref"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998--6008.Google Scholar"",""Lipo Wang. 2005. Support vector machines: theory and applications. Vol. 177. Springer Science \u0026 Business Media.Google Scholar"",""Xiancheng Xie, Yun Xiong, Philip S Yu, and Yangyong Zhu. 2019. EHR Coding with Multi-scale Feature Attention and Structured Knowledge Graph Propagation. In CIKM. 649--658.Google Scholar"",""Changchang Yin, Rongjian Zhao, Buyue Qian, Xin Lv, and Ping Zhang. 2019. Domain Knowledge Guided Deep Learning with Electronic Health Records. In 2019 IEEE International Conference on Data Mining (ICDM).Google Scholar"",""Xianli Zhang, Buyue Qian, Yang Li, Changchang Yin, Xudong Wang, and Qinghua Zheng. 2019 a. KnowRisk: An Interpretable Knowledge-Guided Model for Disease Risk Prediction. In ICDM. IEEE, 1492--1497.Google Scholar"",""Xi Sheryl Zhang, Fengyi Tang, Hiroko H. Dodge, Jiayu Zhou, and Fei Wang. 2019 b. MetaPred: Meta-Learning for Clinical Risk Prediction with Limited Patient Electronic Health Records (KDD '19). ACM, New York, NY, USA, 2487--2495. http://doi.acm.org/10.1145/3292500.3330779Google Scholar""]"
https://doi.org/10.1145/3394486.3403108,"Personalized PageRank to a Target Node, Revisited","Personalized PageRank (PPR) is a widely used node proximity measure in graph mining and network analysis. Given a source node s and a target node t, the PPR value π(s,t) represents the probability that a random walk from s terminates at t, and thus indicates the bidirectional importance between s and t. The majority of the existing work focuses on the single-source queries, which asks for the PPR value of a given source node s and every node t ∈ V. However, the single-source query only reflects the importance of each node t with respect to s. In this paper, we consider the single-target PPR query, which measures the opposite direction of importance for PPR. Given a target node t, the single-target PPR query asks for the PPR value of every node $s\in V$ to a given target node t. We propose RBS, a novel algorithm that answers approximate single-target queries with optimal computational complexity. We show that RBS improves three concrete applications: heavy hitters PPR query, single-source SimRank computation, and scalable graph neural networks. We conduct experiments to demonstrate that RBS outperforms the state-of-the-art algorithms in terms of both efficiency and precision on real-world benchmark datasets.","[{""name"":""Hanzhi Wang"",""id"":""/profile/99659534428""},{""name"":""Zhewei Wei"",""id"":""/profile/81440609796""},{""name"":""Junhao Gan"",""id"":""/profile/99659573946""},{""name"":""Sibo Wang"",""id"":""/profile/99658717560""},{""name"":""Zengfeng Huang"",""id"":""/profile/99659436273""},{""name"":""Hanzhi Wang"",""id"":""/profile/99659534428""},{""name"":""Zhewei Wei"",""id"":""/profile/81440609796""},{""name"":""Junhao Gan"",""id"":""/profile/99659573946""},{""name"":""Sibo Wang"",""id"":""/profile/99658717560""},{""name"":""Zengfeng Huang"",""id"":""/profile/99659436273""}]","[""http://arxiv.org/abs/2006.11876.Google Scholar"",""http://snap.stanford.edu/data.Google Scholar"",""http://law.di.unimi.it/datasets.php.Google Scholar"",""Reid Andersen, Christian Borgs, Jennifer Chayes, John Hopcroft, Kamal Jain, Vahab Mirrokni, and Shanghua Teng. Robust pagerank and locally computable spam detection features. In Proceedings of the 4th international workshop on Adversarial information retrieval on the web, pages 69--76, 2008.Google ScholarDigital Library"",""Reid Andersen, Christian Borgs, Jennifer T. Chayes, John E. Hopcroft, Vahab S. Mirrokni, and Shang-Hua Teng. Local computation of pagerank contributions. In WAW, pages 150--165, 2007.Google ScholarDigital Library"",""Reid Andersen, Fan R. K. Chung, and Kevin J. Lang. Local graph partitioning using pagerank vectors. In FOCS, pages 475--486, 2006.Google ScholarDigital Library"",""Lars Backstrom and Jure Leskovec. Supervised random walks: predicting and recommending links in social networks. In WSDM, pages 635--644, 2011.Google ScholarDigital Library"",""Bahman Bahmani, Kaushik Chakrabarti, and Dong Xin. Fast personalized pagerank on mapreduce. In SIGMOD, pages 973--984, 2011.Google ScholarDigital Library"",""Bahman Bahmani, Abdur Chowdhury, and Ashish Goel. Fast incremental and personalized pagerank. VLDB, 4(3):173--184, 2010.Google ScholarDigital Library"",""Marco Bressan, Enoch Peserico, and Luca Pretto. Sublinear algorithms for local graph centrality estimation. In 2018 IEEE 59th Annual Symposium on Foundations of Computer Science (FOCS), pages 709--718. IEEE, 2018.Google ScholarCross Ref"",""Soumen Chakrabarti. Dynamic personalized pagerank in entity-relation graphs. In WWW, pages 571--580, 2007.Google ScholarDigital Library"",""Moses Charikar, Kevin Chen, and Martin Farach-Colton. Finding frequent items in data streams. In ICALP, pages 693--703. Springer, 2002.Google ScholarDigital Library"",""Mustafa Coskun, Ananth Grama, and Mehmet Koyuturk. Efficient processing of network proximity queries via chebyshev acceleration. In KDD, pages 1515--1524, 2016.Google ScholarDigital Library"",""Dániel Fogaras, Balázs Rácz, Károly Csalogány, and Tamás Sarlós. Towards scaling fully personalized pagerank: Algorithms, lower bounds, and experiments. Internet Mathematics, 2(3):333--358, 2005.Google ScholarCross Ref"",""Yasuhiro Fujiwara, Makoto Nakatsuji, Makoto Onizuka, and Masaru Kitsuregawa. Fast and exact top-k search for random walk with restart. PVLDB, 5(5):442--453, 2012.Google ScholarDigital Library"",""Yasuhiro Fujiwara, Makoto Nakatsuji, Hiroaki Shiokawa, Takeshi Mishima, and Makoto Onizuka. Efficient ad-hoc search for personalized pagerank. In SIGMOD, pages 445--456, 2013.Google ScholarDigital Library"",""Yasuhiro Fujiwara, Makoto Nakatsuji, Hiroaki Shiokawa, Takeshi Mishima, and Makoto Onizuka. Fast and exact top-k algorithm for pagerank. In AAAI, 2013.Google ScholarDigital Library"",""Yasuhiro Fujiwara, Makoto Nakatsuji, Takeshi Yamamuro, Hiroaki Shiokawa, and Makoto Onizuka. Efficient personalized pagerank with accuracy assurance. In KDD, pages 15--23, 2012.Google ScholarDigital Library"",""Tao Guo, Xin Cao, Gao Cong, Jiaheng Lu, and Xuemin Lin. Distributed algorithms on exact personalized pagerank. In SIGMOD, pages 479--494, 2017.Google ScholarDigital Library"",""Manish S. Gupta, Amit Pathak, and Soumen Chakrabarti. Fast algorithms for top-k personalized pagerank queries. In WWW, pages 1225--1226, 2008.Google ScholarDigital Library"",""Pankaj Gupta, Ashish Goel, Jimmy Lin, Aneesh Sharma, Dong Wang, and Reza Zadeh. Wtf: The who to follow service at twitter. In WWW, pages 505--514, 2013.Google Scholar"",""Glen Jeh and Jennifer Widom. Simrank: a measure of structural-context similarity. In SIGKDD, pages 538--543, 2002.Google ScholarDigital Library"",""Glen Jeh and Jennifer Widom. Scaling personalized web search. In WWW, pages 271--279, 2003.Google ScholarDigital Library"",""Minhao Jiang, Ada Wai-Chee Fu, and Raymond Chi-Wing Wong. Reads: a random walk approach for efficient and accurate dynamic simrank. PPVLDB, 10(9):937--948, 2017.Google ScholarDigital Library"",""Ruoming Jin, Victor E Lee, and Hui Hong. Axiomatic ranking of network role similarity. In KDD, pages 922--930, 2011.Google ScholarDigital Library"",""Jinhong Jung, Namyong Park, Sael Lee, and U Kang. Bepi: Fast and memory-efficient method for billion-scale random walk with restart. In SIGMOD, pages 789--804, 2017.Google ScholarDigital Library"",""Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. ICLR, 2017.Google Scholar"",""Johannes Klicpera, Aleksandar Bojchevski, and Stephan Günnemann. Personalized embedding propagation: Combining neural networks on graphs with personalized pagerank. CoRR, abs/1810.05997, 2018.Google Scholar"",""Johannes Klicpera, Stefan Weißenberger, and Stephan Günnemann. Diffusion improves graph learning, 2019.Google Scholar"",""Mitsuru Kusumoto, Takanori Maehara, and Ken-ichi Kawarabayashi. Scalable similarity search for simrank. In SIGMOD, pages 325--336, 2014.Google ScholarDigital Library"",""Pei Lee, Laks V. S. Lakshmanan, and Jeffrey Xu Yu. On top-k structural similarity search. In ICDE, pages 774--785, 2012.Google ScholarDigital Library"",""Lina Li, Cuiping Li, Chen Hong, and Xiaoyong Du. Mapreduce-based simrank computation and its application in social recommender system. In Big Data (BigData Congress), 2013 IEEE International Congress on, 2013.Google ScholarDigital Library"",""Zhenguo Li, Yixiang Fang, Qin Liu, Jiefeng Cheng, Reynold Cheng, and John Lui. Walking in the cloud: Parallel simrank at scale. PVLDB, 9(1):24--35, 2015.Google ScholarDigital Library"",""David Liben-Nowell and Jon M. Kleinberg. The link prediction problem for social networks. In CIKM, pages 556--559, 2003.Google ScholarDigital Library"",""Yu Liu, Bolong Zheng, Xiaodong He, Zhewei Wei, Xiaokui Xiao, Kai Zheng, and Jiaheng Lu. Probesim: scalable single-source and top-k simrank computations on dynamic graphs. PVLDB, 11(1):14--26, 2017.Google ScholarDigital Library"",""Peter Lofgren, Siddhartha Banerjee, and Ashish Goel. Bidirectional pagerank estimation: From average-case to worst-case. In WAW, pages 164--176, 2015.Google ScholarDigital Library"",""Peter Lofgren, Siddhartha Banerjee, and Ashish Goel. Personalized pagerank estimation and search: A bidirectional approach. In WSDM, pages 163--172, 2016.Google ScholarDigital Library"",""Peter Lofgren and Ashish Goel. Personalized pagerank to a target node. arXiv preprint arXiv:1304.4658, 2013.Google Scholar"",""Peter A. Lofgren, Siddhartha Banerjee, Ashish Goel, and C. Seshadhri. Fast-ppr: Scaling personalized pagerank estimation for large graphs. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '14, pages 1436--1445, New York, NY, USA, 2014. ACM.Google ScholarDigital Library"",""Peter A Lofgren, Siddhartha Banerjee, Ashish Goel, and C Seshadhri. Fast-ppr: Scaling personalized pagerank estimation for large graphs. In KDD, pages 1436--1445, 2014.Google ScholarDigital Library"",""Linyuan Lü and Tao Zhou. Link prediction in complex networks: A survey. Physica A: statistical mechanics and its applications, 390(6):1150--1170, 2011.Google Scholar"",""Takanori Maehara, Takuya Akiba, Yoichi Iwata, and Ken-ichi Kawarabayashi. Computing personalized pagerank quickly by exploiting graph structures. PVLDB, 7(12):1023--1034, 2014.Google ScholarDigital Library"",""Takanori Maehara, Mitsuru Kusumoto, and Ken-ichi Kawarabayashi. Efficient simrank computation via linearization. CoRR, abs/1411.7228, 2014.Google Scholar"",""Naoto Ohsaka, Takanori Maehara, and Ken-ichi Kawarabayashi. Efficient pagerank tracking in evolving networks. In KDD, pages 875--884, 2015.Google ScholarDigital Library"",""Mingdong Ou, Peng Cui, Jian Pei, Ziwei Zhang, and Wenwu Zhu. Asymmetric transitivity preserving graph embedding. In SIGKDD, pages 1105--1114. ACM, 2016.Google ScholarDigital Library"",""Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. The pagerank citation ranking: bringing order to the web. 1999.Google Scholar"",""Hannu Reittu, Ilkka Norros, Tomi R\""aty, Marianna Bolla, and Fülöp Bazsó. Regular decomposition of large graphs: Foundation of a sampling approach to stochastic block model fitting. Data Science and Engineering, 4(1):44--60, 2019.Google ScholarCross Ref"",""CH Ren, Luyi Mo, CM Kao, CK Cheng, and DWL Cheung. Clude: An efficient algorithm for lu decomposition over a sequence of evolving graphs. In EDBT, 2014.Google Scholar"",""Atish Das Sarma, Anisur Rahaman Molla, Gopal Pandurangan, and Eli Upfal. Fast distributed pagerank computation. Theoretical Computer Science, 561:113--121, 2015.Google ScholarDigital Library"",""Yingxia Shao, Bin Cui, Lei Chen, Mingming Liu, and Xing Xie. An efficient similarity search framework for simrank over large dynamic graphs. PVLDB, 8(8):838--849, 2015.Google ScholarDigital Library"",""Kijung Shin, Jinhong Jung, Lee Sael, and U. Kang. BEAR: block elimination approach for random walk with restart on large graphs. In SIGMOD, pages 1571--1585, 2015.Google ScholarDigital Library"",""Nikita Spirin and Jiawei Han. Survey on web spam detection: principles and algorithms. SIGKDD Explorations, 13(2):50--64, 2011.Google ScholarDigital Library"",""Boyu Tian and Xiaokui Xiao. SLING: A near-optimal index structure for simrank. In SIGMOD, pages 1859--1874, 2016.Google ScholarDigital Library"",""Anton Tsitsulin, Davide Mottin, Panagiotis Karras, and Emmanuel Müller. Verse: Versatile graph embeddings from similarity measures. In WWW, pages 539--548. International World Wide Web Conferences Steering Committee, 2018.Google Scholar"",""Petar Veli?kovi?c, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. Graph attention networks, 2017.Google Scholar"",""Sibo Wang, Youze Tang, Xiaokui Xiao, Yin Yang, and Zengxiang Li. Hubppr: Effective indexing for approximate personalized pagerank. PVLDB, 10(3):205--216, 2016.Google ScholarDigital Library"",""Sibo Wang, Youze Tang, Xiaokui Xiao, Yang Yin, and Zengxiang Li. Hubppr: Effective indexing for approximate personalized pagerank. In PVLDB, 2016.Google Scholar"",""Sibo Wang and Yufei Tao. Efficient algorithms for finding approximate heavy hitters in personalized pageranks. In Proceedings of the 2018 International Conference on Management of Data, pages 1113--1127, 2018.Google ScholarDigital Library"",""Sibo Wang, Renchi Yang, Xiaokui Xiao, Zhewei Wei, and Yin Yang. FORA: simple and effective approximate single-source personalized pagerank. In KDD, pages 505--514, 2017.Google ScholarDigital Library"",""Zhewei Wei, Xiaodong He, Xiaokui Xiao, Sibo Wang, Yu Liu, Xiaoyong Du, and Ji-Rong Wen. Prsim: Sublinear time simrank computation on large power-law graphs. In Proceedings of the 2019 International Conference on Management of Data, pages 1042--1059, 2019.Google Scholar"",""Zhewei Wei, Xiaodong He, Xiaokui Xiao, Sibo Wang, Shuo Shang, and Ji-Rong Wen. Topppr: top-k personalized pagerank queries with precision guarantees on large graphs. In SIGMOD, pages 441--456. ACM, 2018.Google ScholarDigital Library"",""Yubao Wu, Ruoming Jin, and Xiang Zhang. Fast and unified local search for random walk based k-nearest-neighbor query in large graphs. In SIGMOD 2014, pages 1139--1150, 2014.Google ScholarDigital Library"",""Keyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi, and Stefanie Jegelka. Representation learning on graphs with jumping knowledge networks. CoRR, abs/1806.03536, 2018.Google Scholar"",""Yuan Yin and Zhewei Wei. Scalable graph embeddings via sparse transpose proximities. CoRR, abs/1905.07245, 2019.Google Scholar"",""Weiren Yu and Xuemin Lin. IRWR: incremental random walk with restart. In SIGIR, pages 1017--1020, 2013.Google ScholarDigital Library"",""Weiren Yu and Julie A. McCann. Efficient partial-pairs simrank search on large networks. Proceedings of the Vldb Endowment, 8(5):569--580.Google ScholarDigital Library"",""Weiren Yu and Julie A. McCann. Random walk with restart over dynamic graphs. In ICDM, pages 589--598, 2016.Google ScholarCross Ref"",""Hongyang Zhang, Peter Lofgren, and Ashish Goel. Approximate personalized pagerank on dynamic graphs. In KDD, pages 1315--1324, 2016.Google ScholarDigital Library"",""Fanwei Zhu, Yuan Fang, Kevin Chen-Chuan Chang, and Jing Ying. Incremental and accuracy-aware personalized pagerank through scheduled approximation. PVLDB, 6(6):481--492, 2013.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403109,Edge-consensus Learning: Deep Learning on P2P Networks with Nonhomogeneous Data,"An effective Deep Neural Network (DNN) optimization algorithm that can use decentralized data sets over a peer-to-peer (P2P) network is proposed. In applications such as medical data analysis, the aggregation of data in one location may not be possible due to privacy issues. Hence, we formulate an algorithm to reach a global DNN model that does not require transmission of data among nodes. An existing solution for this issue is gossip stochastic gradient descend (SGD), which updates by averaging node models over a P2P network. However, in practical situations where the data are statistically heterogeneous across the nodes and/or where communication is asynchronous, gossip SGD often gets trapped in local minimum since the model gradients are noticeably different. To overcome this issue, we solve a linearly constrained DNN cost minimization problem, which results in variable update rules that restrict differences among all node models. Our approach can be based on the Primal-Dual Method of Multipliers (PDMM) or the Alternating Direction Method of Multiplier (ADMM), but the cost function is linearized to be suitable for deep learning. It facilitates asynchronous communication. The results of our numerical experiments using CIFAR-10 indicate that the proposed algorithms converge to a global recognition model even though statistically heterogeneous data sets are placed on the nodes.","[{""name"":""Kenta Niwa"",""id"":""/profile/81503692558""},{""name"":""Noboru Harada"",""id"":""/profile/99659572953""},{""name"":""Guoqiang Zhang"",""id"":""/profile/99659574552""},{""name"":""W. Bastiaan Kleijn"",""id"":""/profile/81100235410""},{""name"":""Kenta Niwa"",""id"":""/profile/81503692558""},{""name"":""Noboru Harada"",""id"":""/profile/99659572953""},{""name"":""Guoqiang Zhang"",""id"":""/profile/99659574552""},{""name"":""W. Bastiaan Kleijn"",""id"":""/profile/81100235410""}]","[""T. Akiba, S. Suzuki, and K. Fukuda. 2017. Extremely large minibatch SGD: training resnet-50 on ImageNet in 15 minutes. arXiv preprint arXiv:1711.04325 (2017).Google Scholar"",""J. L. Ba, J. R. Kiros, and G. E. Hinton. 2016. Layer normalization. arXiv preprint arXiv:1607.06450 (2016).Google Scholar"",""H. H. Bauschke and P. L. Combettes. 2011. Convex analysis and monotone operator theory in Hilbert spaces. Vol. 408. Springer.Google Scholar"",""M. Blot, D. Picard, M. Cord, and N. Thome. 2016. Gossip training for deep learning. arXiv preprint arXiv:1611.09726 (2016).Google Scholar"",""S. Boyd, A. Ghosh, B. Prabhakar, and D. Shah. 2006. Randomized gossip algorithms. IEEE/ACM Transactions on Networking (TON), Vol. 14, SI (2006), 2508--2530.Google ScholarDigital Library"",""B. Custers, A. Sears, F. Dechesne, I. Georgieva, T. Tani, and S. van der Hof. 2019. EU personal data protection in policy and practice .Springer.Google Scholar"",""J. Douglas and H. H. Rachford. 1956. On the numerical solution of heat conduction problems in two and three space variables. Trans. of American Mathematical Soc., Vol. 82 (1956), 421--439.Google ScholarCross Ref"",""W. Fenchel. 1949. On conjugate convex functions. Canadian Journal of Mathematics, Vol. 1, 1 (1949), 73--77.Google ScholarCross Ref"",""D. Gabay and B. Mercier. 1976. A dual algorithm for the solution of nonlinear variational problems via finite element approximation. Computers \u0026 mathematics with applications, Vol. 2, 1 (1976), 17--40.Google Scholar"",""I. Goodfellow, Y. Bengio, and A. Courville. 2016. Deep learning .MIT press.Google Scholar"",""P. Goyal, P. Dollár, R. Girshick, P. Noordhuis, L. Wesolowski, A. Kyrola, A. Tulloch, Y. Jia, and K. He. 2017. Accurate, large minibatch SGD: Training ImageNet in 1 hour. arXiv preprint arXiv:1706.02677 (2017).Google Scholar"",""K. He, X. Zhang, S. Ren, and J. Sun. 2015. Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification. In Proc. of the IEEE international conference on computer vision (ICCV'15). 1026--1034.Google Scholar"",""S. Ioffe and C. Szegedy. 2015. Batch normalization: Accelerating deep network training by reducing internal covariate shift. Proc. of international conference on machine learning (ICML'15), Vol. 37 (2015), 448--456.Google Scholar"",""Z. Jiang, A. Balu, C. Hegde, and S. Sarkar. 2017. Collaborative deep learning in fixed topology networks. In Proc. of neural information processing systems (NeurIPS'17). 5904--5914.Google Scholar"",""P. H. Jin, Q. Yuan, F. Iandola, and K. Keutzer. 2016. How to scale distributed deep learning? arXiv preprint arXiv:1611.04581 (2016).Google Scholar"",""A. Krizhevsky, V. Nair, and G. Hinton. [n.d.]. CIFAR-10 (Canadian Institute for Advanced Research). ( [n.,d.]). http://www.cs.toronto.edu/ kriz/cifar.htmlGoogle Scholar"",""X. Lian, C. Zhang, H. Zhang, C. J. Hsieh, W. Zhang, and J. Liu. 2017. Can decentralized algorithms outperform centralized algorithms? a case study for decentralized parallel stochastic gradient descent. In Proc. of neural information processing systems (NeurIPS'17). 5330--5340.Google Scholar"",""W. Y. B. Lim, N. C. Luong, D. T. Hoang, Y. Jiao, Y. C. Liang, Q. Yang, D. Niyato, and C. Miao. 2019. Federated learning in mobile edge networks: A comprehensive survey. arXiv preprint arXiv:1909.11875 (2019).Google Scholar"",""H. B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas. 2017. Communication-efficient learning of deep networks from decentralized data. Proc. of artificial intelligence and statistics (AISTATS'17) (2017).Google Scholar"",""R. Ormándi, H. I. Heged, and M. Jelasity. 2013. Gossip learning with linear models on fully distributed data. Concurrency and Computation: Practice and Experience, Vol. 25, 4 (2013), 556--571.Google ScholarCross Ref"",""D. W. Peaceman and H. H. Rachford. 1955. The numerical solution of parabolic and elliptic differential equations. Journal of the society for industrial and applied mathematics, Vol. 3, 1 (1955), 28--41.Google ScholarCross Ref"",""R. T. Rockafellar. 1970. Convex analysis. Number 28. Princeton university press.Google Scholar"",""E. K. Ryu and S. Boyd. 2016. Primer on monotone operator methods. Applied and Computational Mathematics, Vol. 15, 1 (2016), 3--43.Google Scholar"",""F. Sattler, S. Wiedemann, K. R. Müller, and W. Samek. 2019. Robust and communication-efficient federated learning from non-IID data. IEEE transactions on neural networks and learning systems (2019).Google Scholar"",""T. W. Sherson, R. Heusdens, and W. B. Kleijn. 2018. Derivation and analysis of the primal-dual method of multipliers based on monotone operator theory. IEEE transactions on signal and information processing over networks, Vol. 5, 2 (2018), 334--347.Google Scholar"",""H. Tang, X. Lian, M. Yan, C. Zhang, and J. Liu. 2018. D2: decentralized training over decentralized data. Proc. of international conference on machine learning (ICML'18) (2018), 4848--4856.Google Scholar"",""D. Ulyanov, A. Vedaldi, and V. Lempitsky. 2016. Instance normalization: The missing ingredient for fast stylization. arXiv preprint arXiv:1607.08022 (2016).Google Scholar"",""Y. Wu and K. He. 2018. Group normalization. In Proc. of European conference on computer vision (ECCV'18). 3--19.Google Scholar"",""C. Xie, S. Koyejo, and I. Gupta. 2019. Asynchronous federated optimization. arXiv preprint arXiv:1903.03934 (2019).Google Scholar"",""Y. You, Z. Zhang, C. J. Hsieh, J. Demmel, and K. Keutzer. 2018. ImageNet training in minutes. In Proc. of international conference on parallel processing. ACM, 1.Google Scholar"",""G. Zhang and R. Heusdens. 2017. Distributed optimization using the primal-dual method of multipliers. IEEE transactions on signal and information processing over networks, Vol. 4, 1 (2017), 173--187.Google Scholar"",""R. Zhang and J. Kwok. 2014. Asynchronous distributed ADMM for consensus optimization. In Proc. of international conference on machine learning (ICML'14). 1701--1709.Google Scholar"",""S. Zhang, A. E. Choromanska, and Y. LeCun. 2015. Deep learning with elastic averaging SGD. In Proc. of neural information processing systems (NeurIPS'15). 685--693.Google Scholar""]"
https://doi.org/10.1145/3394486.3403110,Deep Learning of High-Order Interactions for Protein Interface Prediction,"Protein interactions are important in a broad range of biological processes. Traditionally, computational methods have been developed to automatically predict protein interface from hand-crafted features. Recent approaches employ deep neural networks and predict the interaction of each amino acid pair independently. However, these methods do not incorporate the important sequential information from amino acid chains and the high-order pairwise interactions. Intuitively, the prediction of an amino acid pair should depend on both their features and the information of other amino acid pairs. In this work, we propose to formulate the protein interface prediction as a 2D dense prediction problem. In addition, we propose a novel deep model to incorporate the sequential information and high-order pairwise interactions to perform interface predictions. We represent proteins as graphs and employ graph neural networks to learn node features. Then we propose the sequential modeling method to incorporate the sequential information and reorder the feature matrix. Next, we incorporate high-order pairwise interactions to generate a 3D tensor containing different pairwise interactions. Finally, we employ convolutional neural networks to perform 2D dense predictions. Experimental results on multiple benchmarks demonstrate that our proposed method can consistently improve the protein interface prediction performance.","[{""name"":""Yi Liu"",""id"":""/profile/99659575250""},{""name"":""Hao Yuan"",""id"":""/profile/99659575033""},{""name"":""Lei Cai"",""id"":""/profile/99659287486""},{""name"":""Shuiwang Ji"",""id"":""/profile/81333489125""},{""name"":""Yi Liu"",""id"":""/profile/99659575250""},{""name"":""Hao Yuan"",""id"":""/profile/99659575033""},{""name"":""Lei Cai"",""id"":""/profile/99659287486""},{""name"":""Shuiwang Ji"",""id"":""/profile/81333489125""}]","[""Fayyaz ul Amir Afsar Minhas, Brian J Geiss, and Asa Ben-Hur. 2014. PAIRpred: Partner-specific prediction of interacting residues from sequence and structure. Proteins: Structure, Function, and Bioinformatics, Vol. 82, 7 (2014), 1142--1155.Google ScholarCross Ref"",""Shandar Ahmad and Kenji Mizuguchi. 2011. Partner-aware prediction of interacting residues in protein-protein complexes from sequence data. PloS one, Vol. 6, 12 (2011).Google Scholar"",""James Atwood and Don Towsley. 2016. Diffusion-convolutional neural networks. In Advances in neural information processing systems. 1993--2001.Google Scholar"",""Helen M. Berman, John Westbrook, Zukang Feng, Gary Gilliland, T. N. Bhat, Helge Weissig, Ilya N. Shindyalov, and Philip E. Bourne. 2000. The Protein Data Bank. Nucleic Acids Research, Vol. 28, 1 (2000), 235--242.Google ScholarCross Ref"",""James R Bradford and David R Westhead. 2005. Improved prediction of protein--protein binding sites using a support vector machines approach. Bioinformatics, Vol. 21, 8 (2005), 1487--1494.Google ScholarDigital Library"",""Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L Yuille. 2017. Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. IEEE transactions on pattern analysis and machine intelligence, Vol. 40, 4 (2017), 834--848.Google Scholar"",""Tianqi Chen and Carlos Guestrin. 2016. Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining. 785--794.Google ScholarDigital Library"",""Lei Deng, Jihong Guan, Qiwen Dong, and Shuigeng Zhou. 2009. Prediction of protein-protein interaction sites using an ensemble method. BMC bioinformatics, Vol. 10, 1 (2009), 426.Google Scholar"",""Horace R Drew, Richard M Wing, Tsunehiro Takano, Christopher Broka, Shoji Tanaka, Keiichi Itakura, and Richard E Dickerson. 1981. Structure of a B-DNA dodecamer: conformation and dynamics. Proceedings of the National Academy of Sciences, Vol. 78, 4 (1981), 2179--2183.Google ScholarCross Ref"",""David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Alán Aspuru-Guzik, and Ryan P Adams. 2015. Convolutional networks on graphs for learning molecular fingerprints. In Advances in neural information processing systems. 2224--2232.Google Scholar"",""Iakes Ezkurdia, Lisa Bartoli, Piero Fariselli, Rita Casadio, Alfonso Valencia, and Michael L Tress. 2009. Progress and challenges in predicting protein--protein interaction sites. Briefings in bioinformatics, Vol. 10, 3 (2009), 233--246.Google Scholar"",""Alex Fout, Jonathon Byrd, Basir Shariat, and Asa Ben-Hur. 2017. Protein interface prediction using graph convolutional networks. In Advances in neural information processing systems. 6530--6539.Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In Advances in neural information processing systems. 1024--1034.Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition. 770--778.Google ScholarCross Ref"",""Howook Hwang, Brian Pierce, Julian Mintseris, Joël Janin, and Zhiping Weng. 2008. Protein--protein docking benchmark version 3.0. Proteins: Structure, Function, and Bioinformatics, Vol. 73, 3 (2008), 705--709.Google ScholarCross Ref"",""Howook Hwang, Thom Vreven, Joël Janin, and Zhiping Weng. 2010. Protein--protein docking benchmark version 4.0. Proteins: Structure, Function, and Bioinformatics, Vol. 78, 15 (2010), 3111--3114.Google ScholarCross Ref"",""Rafael A Jordan, EL-Manzalawy Yasser, Drena Dobbs, and Vasant Honavar. 2012. Predicting protein-protein interface residues using local surface structural similarity. BMC bioinformatics, Vol. 13, 1 (2012), 41.Google Scholar"",""D Kinga and J Ba Adam. 2015. A method for stochastic optimization. In ICLR .Google Scholar"",""Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).Google Scholar"",""Simon Leis, Sebastian Schneider, and Martin Zacharias. 2010. In silico prediction of binding sites on proteins. Current medicinal chemistry, Vol. 17, 15 (2010), 1550--1562.Google Scholar"",""Bin Liu, Xiaolong Wang, Lei Lin, Buzhou Tang, Qiwen Dong, and Xuan Wang. 2009. Prediction of protein binding sites in protein structures using hidden Markov support vector machine. BMC bioinformatics, Vol. 10, 1 (2009), 381.Google Scholar"",""Yi Liu, Hao Yuan, and Shuiwang Ji. 2019. Learning Local and Global Multi-context Representations for Document Classification. In 2019 IEEE International Conference on Data Mining (ICDM). IEEE, 1234--1239.Google Scholar"",""Yi Liu, Hao Yuan, Zhengyang Wang, and Shuiwang Ji. 2020. Global Pixel Transformers for Virtual Staining of Microscopy Images. IEEE Transactions on Medical Imaging, Vol. 39, 6 (2020), 2256--2266.Google ScholarCross Ref"",""Julian Mintseris, Kevin Wiehe, Brian Pierce, Robert Anderson, Rong Chen, Joël Janin, and Zhiping Weng. 2005. Protein--protein docking benchmark 2.0: an update. Proteins: Structure, Function, and Bioinformatics, Vol. 60, 2 (2005), 214--216.Google ScholarCross Ref"",""Thomas C Northey, Anja Barevs ić, and Andrew CR Martin. 2018. IntPred: a structure-based predictor of protein--protein interaction sites. Bioinformatics, Vol. 34, 2 (2018), 223--229.Google ScholarCross Ref"",""Linus Pauling, Robert B Corey, and Herman R Branson. 1951. The structure of proteins: two hydrogen-bonded helical configurations of the polypeptide chain. Proceedings of the National Academy of Sciences, Vol. 37, 4 (1951), 205--211.Google ScholarCross Ref"",""Brian G Pierce, Yuichiro Hourai, and Zhiping Weng. 2011. Accelerating protein docking in ZDOCK using an advanced 3D convolution library. PloS one, Vol. 6, 9 (2011).Google Scholar"",""Annick Pollet, Stefaan Sansen, Gert Raedschelders, Kurt Gebruers, Anja Rabijns, Jan A Delcour, and Christophe M Courtin. 2009. Identification of structural determinants for inhibition strength and specificity of wheat xylanase inhibitors TAXI-IA and TAXI-IIA. The FEBS journal, Vol. 276, 14 (2009), 3916--3927.Google ScholarCross Ref"",""Olaf Ronneberger, Philipp Fischer, and Thomas Brox. 2015. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computer-assisted intervention. Springer, 234--241.Google ScholarCross Ref"",""Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. 2015. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV), Vol. 115, 3 (2015), 211--252. https://doi.org/10.1007/s11263-015-0816-yGoogle ScholarDigital Library"",""Ruben Sanchez-Garcia, Carlos Oscar Sánchez Sorzano, José Mar'ia Carazo, and Joan Segura. 2019. BIPSPI: a method for the prediction of partner-specific protein--protein interfaces. Bioinformatics, Vol. 35, 3 (2019), 470--477.Google ScholarCross Ref"",""Ora Schueler-Furman, Chu Wang, and David Baker. 2005. Progress in protein--protein docking: Atomic resolution predictions in the CAPRI experiment using RosettaDock with an improved treatment of side-chain flexibility. Proteins: Structure, Function, and Bioinformatics, Vol. 60, 2 (2005), 187--194.Google ScholarCross Ref"",""Kristof T Schütt, Farhad Arbabzadah, Stefan Chmiela, Klaus R Müller, and Alexandre Tkatchenko. 2017. Quantum-chemical insights from deep tensor neural networks. Nature communications, Vol. 8, 1 (2017), 1--8.Google Scholar"",""Joan Segura, Pamela F Jones, and Narcis Fernandez-Fuentes. 2012. A holistic in silico approach to predict functional sites in protein structures. Bioinformatics, Vol. 28, 14 (2012), 1845--1850.Google ScholarDigital Library"",""Mile vS ikić, Sanja Tomić, and Kristian Vlahovivc ek. 2009. Prediction of protein--protein interaction sites in sequences and 3D structures by random forests. PLoS computational biology, Vol. 5, 1 (2009).Google Scholar"",""Karen Simonyan and Andrew Zisserman. 2014. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556 (2014).Google Scholar"",""Raphael Townshend, Rishi Bedi, Patricia Suriana, and Ron Dror. 2019. End-to-End Learning on 3D Protein Structure for Interface Prediction. In Advances in Neural Information Processing Systems. 15616--15625.Google Scholar"",""Nurcan Tuncbag, Attila Gursoy, and Ozlem Keskin. 2011. Prediction of protein--protein interactions: unifying evolution and structure at protein interfaces. Physical biology, Vol. 8, 3 (2011), 035006.Google Scholar"",""Thom Vreven, Iain H Moal, Anna Vangone, Brian G Pierce, Panagiotis L Kastritis, Mieczyslaw Torchala, Raphael Chaleil, Brian Jiménez-Garc'ia, Paul A Bates, Juan Fernandez-Recio, et al. 2015. Updates to the integrated protein--protein interaction benchmarks: docking benchmark version 5 and affinity benchmark version 2. Journal of molecular biology, Vol. 427, 19 (2015), 3031--3041.Google ScholarCross Ref"",""Feihong Wu, Byron Olson, Drena Dobbs, and Vasant Honavar. 2006. Comparing kernels for predicting protein binding sites from amino acid sequence. In The 2006 IEEE International Joint Conference on Neural Network Proceedings. IEEE, 1612--1616.Google Scholar"",""Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, and Jure Leskovec. 2018. Hierarchical graph representation learning with differentiable pooling. In Advances in neural information processing systems. 4800--4810.Google Scholar"",""Hao Yuan and Shuiwang Ji. 2020. StructPool: Structured Graph Pooling via Conditional Random Fields. In Proceedings of the 8th International Conference on Learning Representations .Google Scholar"",""Huan-Xiang Zhou and Sanbo Qin. 2007. Interaction-site prediction for protein complexes: a critical assessment. Bioinformatics, Vol. 23, 17 (2007), 2203--2209.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403113,MAMO: Memory-Augmented Meta-Optimization for Cold-start Recommendation,"A common challenge for most current recommender systems is the cold-start problem. Due to the lack of user-item interactions, the fine-tuned recommender systems are unable to handle situations with new users or new items. Recently, some works introduce the meta-optimization idea into the recommendation scenarios, i.e. predicting the user preference by only a few of past interacted items. The core idea is learning a global sharing initialization parameter for all users and then learning the local parameters for each user separately. However, most meta-learning based recommendation approaches adopt model-agnostic meta-learning for parameter initialization, where the global sharing parameter may lead the model into local optima for some users. In this paper, we design two memory matrices that can store task-specific memories and feature-specific memories. Specifically, the feature-specific memories are used to guide the model with personalized parameter initialization, while the task-specific memories are used to guide the model fast predicting the user preference. And we adopt a meta-optimization approach for optimizing the proposed method. We test the model on two widely used recommendation datasets and consider four cold-start situations. The experimental results show the effectiveness of the proposed methods.","[{""name"":""Manqing Dong"",""id"":""/profile/99659338210""},{""name"":""Feng Yuan"",""id"":""/profile/99659575132""},{""name"":""Lina Yao"",""id"":""/profile/81500655260""},{""name"":""Xiwei Xu"",""id"":""/profile/81351600780""},{""name"":""Liming Zhu"",""id"":""/profile/81100413984""},{""name"":""Manqing Dong"",""id"":""/profile/99659338210""},{""name"":""Feng Yuan"",""id"":""/profile/99659575132""},{""name"":""Lina Yao"",""id"":""/profile/81500655260""},{""name"":""Xiwei Xu"",""id"":""/profile/81351600780""},{""name"":""Liming Zhu"",""id"":""/profile/81100413984""}]","[""Oren Anava, Shahar Golan, Nadav Golbandi, Zohar Karnin, Ronny Lempel, Oleg Rokhlenko, and Oren Somekh. 2015. Budget-constrained item cold-start handling in collaborative filtering recommenders via optimal design. In Proceedings of the 24th International Conference on World Wide Web. 45--54.Google ScholarDigital Library"",""Tadas Baltruvs aitis, Chaitanya Ahuja, and Louis-Philippe Morency. 2018. Multimodal machine learning: A survey and taxonomy. IEEE transactions on pattern analysis and machine intelligence , Vol. 41, 2 (2018), 423--443.Google Scholar"",""Homanga Bharadhwaj. 2019. Meta-Learning for User Cold-Start Recommendation. In 2019 International Joint Conference on Neural Networks (IJCNN). IEEE, 1--8.Google Scholar"",""Dheeraj Bokde, Sheetal Girase, and Debajyoti Mukhopadhyay. 2015. Matrix factorization model in collaborative filtering algorithms: A survey. Procedia Computer Science , Vol. 49 (2015), 136--146.Google ScholarCross Ref"",""Fei Chen, Zhenhua Dong, Zhenguo Li, and Xiuqiang He. 2018a. Federated meta-learning for recommendation. arXiv preprint arXiv:1802.07876 (2018).Google Scholar"",""Xu Chen, Hongteng Xu, Yongfeng Zhang, Jiaxi Tang, Yixin Cao, Zheng Qin, and Hongyuan Zha. 2018b. Sequential recommendation with user memory networks. In Proceedings of the eleventh ACM international conference on web search and data mining. ACM, 108--116.Google ScholarDigital Library"",""Szu-Yu Chou, Yi-Hsuan Yang, Jyh-Shing Roger Jang, and Yu-Ching Lin. 2016. Addressing cold start for next-song recommendation. In Proceedings of the 10th ACM Conference on Recommender Systems. 115--118.Google ScholarDigital Library"",""Zhengxiao Du, Xiaowei Wang, Hongxia Yang, Jingren Zhou, and Jie Tang. 2019. Sequential Scenario-Specific Meta Learner for Online Recommendation. arXiv preprint arXiv:1906.00391 (2019).Google Scholar"",""Travis Ebesu and Yi Fang. 2017. Neural Semantic Personalized Ranking for item cold-start recommendation. Information Retrieval Journal , Vol. 20, 2 (2017), 109--131.Google ScholarDigital Library"",""Mehdi Elahi, Francesco Ricci, and Neil Rubens. 2016. A survey of active learning in collaborative filtering recommender systems. Computer Science Review , Vol. 20 (2016), 29--50.Google ScholarDigital Library"",""Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017. Model-agnostic meta-learning for fast adaptation of deep networks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 1126--1135.Google ScholarDigital Library"",""Marjan Ghazvininejad, Chris Brockett, Ming-Wei Chang, Bill Dolan, Jianfeng Gao, Wen-tau Yih, and Michel Galley. 2018. A knowledge-grounded neural conversation model. In Thirty-Second AAAI Conference on Artificial Intelligence .Google Scholar"",""Alex Graves, Greg Wayne, and Ivo Danihelka. 2014. Neural turing machines. arXiv preprint arXiv:1410.5401 (2014).Google Scholar"",""Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In Proceedings of the 26th international conference on world wide web. 173--182.Google ScholarDigital Library"",""Hoyeop Lee, Jinbae Im, Seongwon Jang, Hyunsouk Cho, and Sehee Chung. 2019. MeLU: Meta-Learned User Preference Estimator for Cold-Start Recommendation. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 1073--1082.Google ScholarDigital Library"",""Cheng-Te Li, Chia-Tai Hsu, and Man-Kwan Shan. 2018. A Cross-Domain Recommendation Mechanism for Cold-Start Users Based on Partial Least Squares Regression. ACM Transactions on Intelligent Systems and Technology (TIST) , Vol. 9, 6 (2018), 1--26.Google ScholarDigital Library"",""Yunxiao Li, Jiaxing Song, Xiao Li, and Weidong Liu. 2019. Gated Sequential Recommendation with Dynamic Memory Network. In 2019 International Joint Conference on Neural Networks (IJCNN). IEEE, 1--8.Google Scholar"",""Yutao Ma, Xiao Geng, and Jian Wang. 2020. A Deep Neural Network With Multiplex Interactions for Cold-Start Service Recommendation. IEEE Transactions on Engineering Management (2020).Google Scholar"",""Nima Mirbakhsh and Charles X Ling. 2015. Improving top-n recommendation for cold-start users via cross-domain information. ACM Transactions on Knowledge Discovery from Data (TKDD) , Vol. 9, 4 (2015), 1--19.Google Scholar"",""Nitin Mishra, Vimal Mishra, and Saumya Chaturvedi. 2017. Tools and techniques for solving cold start recommendation. In Proceedings of the 1st International Conference on Internet of Things and Machine Learning . 1--6.Google ScholarDigital Library"",""Sujoy Roy and Sharath Chandra Guntuku. 2016. Latent factor representations for cold-start video recommendation. In Proceedings of the 10th ACM conference on recommender systems. 99--106.Google ScholarDigital Library"",""Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy Lillicrap. 2016. Meta-learning with memory-augmented neural networks. In International conference on machine learning. 1842--1850.Google Scholar"",""Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, et almbox. 2015. End-to-end memory networks. In Advances in neural information processing systems. 2440--2448.Google Scholar"",""Joaquin Vanschoren. 2018. Meta-learning: A survey. arXiv preprint arXiv:1810.03548 (2018).Google Scholar"",""Xinghua Wang, Zhaohui Peng, Senzhang Wang, S Yu Philip, Wenjing Fu, Xiaokang Xu, and Xiaoguang Hong. 2019. CDLFM: cross-domain recommendation for cold-start users via latent feature mapping. Knowledge and Information Systems (2019), 1--28.Google Scholar"",""Yaqing Wang and Quanming Yao. 2019. Few-shot learning: A survey. arXiv preprint arXiv:1904.05046 (2019).Google Scholar"",""Jian Wei, Jianhua He, Kai Chen, Yi Zhou, and Zuoyin Tang. 2016. Collaborative filtering and deep learning based hybrid recommendation for cold start problem. In 2016 IEEE 14th Intl Conf on Dependable, Autonomic and Secure Computing, 14th Intl Conf on Pervasive Intelligence and Computing, 2nd Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress (DASC/PiCom/DataCom/CyberSciTech). IEEE, 874--877.Google Scholar"",""Jian Wei, Jianhua He, Kai Chen, Yi Zhou, and Zuoyin Tang. 2017. Collaborative filtering and deep learning based recommendation system for cold start items. Expert Systems with Applications , Vol. 69 (2017), 29--39.Google ScholarCross Ref"",""Mike Wu and Noah Goodman. 2018. Multimodal generative models for scalable weakly-supervised learning. In Advances in Neural Information Processing Systems. 5575--5585.Google Scholar"",""Caiming Xiong, Stephen Merity, and Richard Socher. 2016. Dynamic memory networks for visual and textual question answering. In International conference on machine learning. 2397--2406.Google ScholarDigital Library"",""Lina Yao, Quan Z Sheng, Xianzhi Wang, Wei Emma Zhang, and Yongrui Qin. 2018. Collaborative location recommendation by integrating multi-dimensional contextual information. ACM Transactions on Internet Technology (TOIT) , Vol. 18, 3 (2018), 1--24.Google ScholarDigital Library"",""Jianbo Yuan, Walid Shalaby, Mohammed Korayem, David Lin, Khalifeh AlJadda, and Jiebo Luo. 2016. Solving cold-start problem in large-scale recommendation engines: A deep learning approach. In 2016 IEEE International Conference on Big Data (Big Data). IEEE, 1901--1910.Google ScholarCross Ref"",""Shuai Zhang, Lina Yao, Aixin Sun, and Yi Tay. 2019. Deep learning based recommender system: A survey and new perspectives. ACM Computing Surveys (CSUR) , Vol. 52, 1 (2019), 5.Google ScholarDigital Library"",""Liang Zhao, Yang Wang, Daxiang Dong, and Hao Tian. 2019. Learning to Recommend via Meta Parameter Partition. arXiv preprint arXiv:1912.04108 (2019).Google Scholar"",""Yu Zhu, Jinghao Lin, Shibi He, Beidou Wang, Ziyu Guan, Haifeng Liu, and Deng Cai. 2019. Addressing the item cold-start problem by attribute-driven active learning. IEEE Transactions on Knowledge and Data Engineering (2019).Google Scholar""]"
https://doi.org/10.1145/3394486.3403114,Finding Effective Geo-social Group for Impromptu Activities with Diverse Demands,"Geo-social group search aims to find a group of people proximate to a location while socially related. One of the driven applications for geo-social group search is organizing an impromptu activity. This is because the social cohesiveness of a found geo-social group ensures a good communication atmosphere for the activity and the spatial closeness of the geo-social group reduces the preparation time for the activity. Most existing works treat geo-social group search as a problem that finds a group satisfying a single social constraint while optimizing the spatial proximity. However, since different impromptu activities have diverse demands on attendees, e.g. an activity could require (or prefer) the attendees to have skills (or favorites) related to the activity, the existing works cannot find this kind of geo-social groups effectively. In this paper, we propose a novel geo-social group model, equipped with elegant keyword constraints, to fill this gap. We propose a novel search framework which first significantly narrows down the search space with theoretical guarantees and then efficiently finds the optimum result. To evaluate the effectiveness, we conduct experiments on real datasets, demonstrating the superiority of our proposed model. We conduct extensive experiments on large semi-synthetic datasets for justifying the efficiency of the proposed search algorithms.","[{""name"":""Lu Chen"",""id"":""/profile/86158904157""},{""name"":""Chengfei Liu"",""id"":""/profile/81452598185""},{""name"":""Rui Zhou"",""id"":""/profile/81324495541""},{""name"":""Jiajie Xu"",""id"":""/profile/99658654639""},{""name"":""Jeffrey Xu Yu"",""id"":""/profile/81447600785""},{""name"":""Jianxin Li"",""id"":""/profile/99659574969""},{""name"":""Lu Chen"",""id"":""/profile/86158904157""},{""name"":""Chengfei Liu"",""id"":""/profile/81452598185""},{""name"":""Rui Zhou"",""id"":""/profile/81324495541""},{""name"":""Jiajie Xu"",""id"":""/profile/99658654639""},{""name"":""Jeffrey Xu Yu"",""id"":""/profile/81447600785""},{""name"":""Jianxin Li"",""id"":""/profile/99659574969""}]","[""Ritesh Ahuja, Nikos Armenatzoglou, Dimitris Papadias, and George J Fakas. 2015. Geo-social keyword search. In SSTD. Springer, 431--450.Google Scholar"",""Nikos Armenatzoglou, Stavros Papadopoulos, and Dimitris Papadias. 2013. A general framework for geo-social query processing. PVLDB, Vol. 6, 10 (2013), 913--924.Google ScholarDigital Library"",""Fei Bi, Lijun Chang, Xuemin Lin, and Wenjie Zhang. 2018. An optimal and progressive approach to online search of top-k influential communities. PVLDB, Vol. 11, 9 (2018), 1056--1068.Google ScholarDigital Library"",""Lu Chen, Chengfei Liu, Kewen Liao, Jianxin Li, and Rui Zhou. 2019. Contextual community search over large social networks. In ICDE. IEEE, 88--99.Google Scholar"",""Lu Chen, Chengfei Liu, Rui Zhou, Jianxin Li, Xiaochun Yang, and Bin Wang. 2018. Maximum co-located community search in large scale social networks. PVLDB, Vol. 11, 10 (2018), 1233--1246.Google ScholarDigital Library"",""Jonathan Cohen. 2008. Trusses: Cohesive subgraphs for social network analysis. National Security Agency Technical Report, Vol. 16 (2008).Google Scholar"",""Yerach Doytsher, Ben Galon, and Yaron Kanza. 2010. Querying geo-social data by bridging spatial networks and social networks. In SIGSPATIAL International Workshop on Location Based Social Networks. ACM, 39--46.Google ScholarDigital Library"",""Yixiang Fang, Reynold Cheng, Xiaodong Li, Siqiang Luo, and Jiafeng Hu. 2017. Effective Community Search over Large Spatial Graphs. PVLDB, Vol. 10, 6 (2017), 709--720.Google ScholarDigital Library"",""Giorgio Gallo, Michael D. Grigoriadis, and Robert E. Tarjan. 1989. A Fast Parametric Maximum Flow Algorithm and Applications. SIAM J. Comput., Vol. 18, 1 (Feb. 1989), 30--55.Google ScholarDigital Library"",""Bishwamittra Ghosh, Mohammed Eunus Ali, Farhana M. Choudhury, Sajid Hasan Apon, Timos Sellis, and Jianxin Li. 2018. The Flexible Socio Spatial Group Queries. PVLDB, Vol. 12, 2 (2018), 99--111.Google ScholarDigital Library"",""Jacob Holm, Kristian De Lichtenberg, Mikkel Thorup, and Mikkel Thorup. 2001. Poly-logarithmic deterministic fully-dynamic algorithms for connectivity, minimum spanning tree, 2-edge, and biconnectivity. J. ACM, Vol. 48, 4 (2001), 723--760.Google ScholarDigital Library"",""Xin Huang and Laks V. S. Lakshmanan. 2017. Attribute-driven Community Search. PVLDB, Vol. 10, 9 (2017), 949--960.Google ScholarDigital Library"",""Mehdi Kargar, Morteza Zihayat, and Aijun An. 2013. Finding affordable and collaborative teams from a network of experts. In SDM. SIAM, 587--595.Google Scholar"",""Theodoros Lappas, Kun Liu, and Evimaria Terzi. 2009. Finding a team of experts in social networks. In SIGKDD. ACM, 467--476.Google Scholar"",""Yafei Li, Dingming Wu, Jianliang Xu, Byron Choi, and Weifeng Su. 2014. Spatial-aware interest group queries in location-based social networks. Data \u0026 Knowledge Engineering, Vol. 92 (2014), 20--38.Google ScholarDigital Library"",""Qing Liu, Yifan Zhu, Minjun Zhao, Xin Huang, Jianliang Xu, and Yunjun Gao. 2020. VAC: Vertex-Centric Attributed Community Search. In ICDE. IEEE, 937--948.Google Scholar"",""Weimo Liu, Weiwei Sun, Chunan Chen, Yan Huang, Yinan Jing, and Kunjie Chen. 2012. Circle of friend query in geo-social networks. In DASFAA. Springer, 126--137.Google Scholar"",""C. Shen, D. Yang, L. Huang, W. Lee, and M. Chen. 2016. Socio-Spatial Group Queries for Impromptu Activity Planning. TKDE, Vol. 28, 1 (Jan 2016), 196--210.Google Scholar"",""Chih-Ya Shen, De-Nian Yang, Wang-Chien Lee, and Ming-Syan Chen. 2016. Spatial-Proximity Optimization for Rapid Task Group Deployment. TKDD, Vol. 10, 4 (2016), 47.Google ScholarDigital Library"",""Robert Endre Tarjan. 1975. Efficiency of a Good But Not Linear Set Union Algorithm. J. ACM, Vol. 22, 2 (April 1975), 215--225.Google ScholarDigital Library"",""Dingming Wu, Yafei Li, Byron Choi, and Jianliang Xu. 2014. Social-aware top-k spatial keyword search. In MDM, Vol. 1. IEEE, 235--244.Google Scholar"",""De-Nian Yang, Chih-Ya Shen, Wang-Chien Lee, and Ming-Syan Chen. 2012. On socio-spatial group query for location-based social networks. In SIGKDD. ACM, 949--957.Google Scholar"",""Fan Zhang, Ying Zhang, Lu Qin, Wenjie Zhang, and Xuemin Lin. 2017. When engagement meets similarity: efficient (k, r)-core computation on social networks. PVLDB, Vol. 10, 10 (2017), 998--1009.Google ScholarDigital Library"",""Yikai Zhang and Jeffrey Xu Yu. 2019. Unboundedness and Efficiency of Truss Maintenance in Evolving Graphs. In SIGMOD. 1024--1041.Google Scholar"",""Qijun Zhu, Haibo Hu, Cheng Xu, Jianliang Xu, and Wang-Chien Lee. 2017. Geo-social group queries with minimum acquaintance constraints. The VLDB Journal, Vol. 26, 5 (2017), 709--727.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403115,Representing Temporal Attributes for Schema Matching,"Temporal data are prevalent, where one or several time attributes present. It is challenging to identify the temporal attributes from heterogeneous sources. The reason is that the same attribute could contain distinct values in different time spans, whereas different attributes may have highly similar timestamps and alike values. Existing studies on schema matching seldom explore the temporal information for matching attributes. In this paper, we argue to order the values in an attribute A by some time attribute T as a time series. To learn deep temporal features in the attribute pair (T, A), we devise an auto-encoder to embed the transitions of values in the time series into a vector. The temporal attribute matching (TAM) is thus to evaluate matching distance of two temporal attribute pairs by comparing their transition vectors. We show that computing the optimal matching distance is NP-hard, and present an approximation algorithm. Experiments on real datasets demonstrate the superiority of our proposal in matching temporal attributes compared to the generic schema matching approaches.","[{""name"":""Yinan Mei"",""id"":""/profile/99659575181""},{""name"":""Shaoxu Song"",""id"":""/profile/81552921256""},{""name"":""Yunsu Lee"",""id"":""/profile/99659510452""},{""name"":""Jungho Park"",""id"":""/profile/99659510667""},{""name"":""Soo-Hyung Kim"",""id"":""/profile/99659510772""},{""name"":""Sungmin Yi"",""id"":""/profile/87059059857""},{""name"":""Yinan Mei"",""id"":""/profile/99659575181""},{""name"":""Shaoxu Song"",""id"":""/profile/81552921256""},{""name"":""Yunsu Lee"",""id"":""/profile/99659510452""},{""name"":""Jungho Park"",""id"":""/profile/99659510667""},{""name"":""Soo-Hyung Kim"",""id"":""/profile/99659510772""},{""name"":""Sungmin Yi"",""id"":""/profile/87059059857""}]","[""I. M. Baytas, C. Xiao, X. Zhang, F. Wang, A. K. Jain, and J. Zhou. Patient subtyping via time-aware LS™ networks. In SIGKDD, pages 65--74. ACM, 2017.Google ScholarDigital Library"",""Z. Bellahsene, A. Bonifati, and E. Rahm, editors. Schema Matching and Mapping. Data-Centric Systems and Applications. Springer, 2011.Google ScholarDigital Library"",""P. A. Bernstein, J. Madhavan, and E. Rahm. Generic schema matching, ten years later. PVLDB, 4(11):695--701, 2011.Google ScholarDigital Library"",""S. Bonner, I. Kureshi, J. Brennan, G. Theodoropoulos, A. S. McGough, and B. Obara. Exploring the semantic content of unsupervised graph embeddings: An empirical study. Data Science and Engineering, 4(3):269--289, 2019.Google ScholarCross Ref"",""K. Cheng and A. S. Krishnakumar. Automatic generation of functional vectors using the extended finite state machine model. ACM TODAES, 1(1):57--79, 1996.Google ScholarDigital Library"",""J. Chung, cC. Gü lcc ehre, K. Cho, and Y. Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.Google Scholar"",""H. Elmeleegy, M. Ouzzani, and A. K. Elmagarmid. Usage-based schema matching. In ICDE, pages 20--29, 2008.Google ScholarDigital Library"",""Y. Fan, X. Lu, D. Li, and Y. Liu. Video-based emotion recognition using CNN-RNN and C3D hybrid networks. In ICMI, pages 445--450, 2016.Google ScholarDigital Library"",""X. Gao, B. Xiao, D. Tao, and X. Li. A survey of graph edit distance. PAA, 13(1):113--129, 2010.Google Scholar"",""Y. Gao, S. Song, X. Zhu, J. Wang, X. Lian, and L. Zou. Matching heterogeneous event data. IEEE Trans. Knowl. Data Eng., 30(11):2157--2170, 2018.Google ScholarDigital Library"",""X. Glorot and Y. Bengio. Understanding the difficulty of training deep feedforward neural networks. In AISTATS, pages 249--256, 2010.Google Scholar"",""A. Grover and J. Leskovec. node2vec: Scalable feature learning for networks. In SIGKDD, pages 855--864. ACM, 2016.Google ScholarDigital Library"",""N. Gugulothu, V. TV, P. Malhotra, L. Vig, P. Agarwal, and G. Shroff. Predicting remaining useful life using time series embeddings based on recurrent neural networks. CoRR, abs/1709.01073, 2017.Google Scholar"",""S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural Computation, 9(8):1735--1780, 1997.Google ScholarDigital Library"",""A. Itai, M. Rodeh, and S. L. Tanimoto. Some matching problems for bipartite graphs. J. ACM, 25(4):517--525, 1978.Google ScholarDigital Library"",""A. R. Jaiswal, D. J. Miller, and P. Mitra. Uninterpreted schema matching with embedded value mapping under opaque column names and data values. IEEE TKDE, 22(2):291--304, 2010.Google Scholar"",""A. R. Jaiswal, D. J. Miller, and P. Mitra. Schema matching and embedded value mapping for databases with opaque column names and mixed continuous and discrete-valued data fields. ACM TODS, 38(1):2:1--2:34, 2013.Google ScholarDigital Library"",""J. Kang and J. F. Naughton. On schema matching with opaque column names and data values. In SIGMOD, pages 205--216. ACM, 2003.Google ScholarDigital Library"",""R. M. Karp. Reducibility among combinatorial problems. In 50 Years of Integer Programming 1958--2008 - From the Early Years to the State-of-the-Art, pages 219--241. Springer, 2010.Google Scholar"",""T. N. Kipf and M. Welling. Semi-supervised classification with graph convolutional networks. In ICLR. OpenReview.net, 2017.Google Scholar"",""H. W. Kuhn. The hungarian method for the assignment problem. In 50 Years of Integer Programming 1958--2008 - From the Early Years to the State-of-the-Art, pages 29--47. Springer, 2010.Google Scholar"",""S. Melnik, H. Garcia-Molina, and E. Rahm. Similarity flooding: A versatile graph matching algorithm and its application to schema matching. In ICDE, pages 117--128. IEEE Computer Society, 2002.Google ScholarDigital Library"",""R. O. Messina and J. Louradour. Segmentation-free handwritten chinese text recognition with LSTM-RNN. In ICDAR, pages 171--175. IEEE Computer Society, 2015.Google ScholarDigital Library"",""J. Peng, H. Wang, J. Li, and H. Gao. Set-based similarity search for time series. In SIGMOD, pages 2039--2052. ACM, 2016.Google ScholarDigital Library"",""Y. Qin, D. Song, H. Chen, W. Cheng, G. Jiang, and G. W. Cottrell. A dual-stage attention-based recurrent neural network for time series prediction. In IJCAI, pages 2627--2633. ijcai.org, 2017.Google ScholarCross Ref"",""E. Rahm and P. A. Bernstein. A survey of approaches to automatic schema matching. VLDB J., 10(4):334--350, 2001.Google ScholarDigital Library"",""A. Sanfeliu and K. Fu. A distance measure between attributed relational graphs for pattern recognition. IEEE SMC, 13(3):353--362, 1983.Google ScholarCross Ref"",""S. Song, Y. Gao, C. Wang, X. Zhu, J. Wang, and P. S. Yu. Matching heterogeneous events with patterns. IEEE TKDE, 29(8):1695--1708, 2017.Google Scholar"",""N. Srivastava, E. Mansimov, and R. Salakhutdinov. Unsupervised learning of video representations using lstms. In ICML, pages 843--852, 2015.Google ScholarDigital Library"",""D. Wang, P. Cui, and W. Zhu. Structural deep network embedding. In SIGKDD, pages 1225--1234. ACM, 2016.Google ScholarDigital Library"",""J. Wang, S. Song, X. Zhu, X. Lin, and J. Sun. Efficient recovery of missing events. IEEE TKDE, 28(11):2943--2957, 2016.Google Scholar"",""X. Zhu, S. Song, X. Lian, J. Wang, and L. Zou. Matching heterogeneous event data. In SIGMOD, pages 1211--1222. ACM, 2014.Google ScholarDigital Library"",""X. Zhu, S. Song, J. Wang, P. S. Yu, and J. Sun. Matching heterogeneous events with patterns. In IEEE 30th International Conference on Data Engineering, Chicago, ICDE 2014, IL, USA, March 31 - April 4, 2014, pages 376--387, 2014.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403116,Estimating Properties of Social Networks via Random Walk considering Private Nodes,"Accurately analyzing graph properties of social networks is a challenging task because of access limitations to the graph data. To address this challenge, several algorithms to obtain unbiased estimates of properties from few samples via a random walk have been studied. However, existing algorithms do not consider private nodes who hide their neighbors in real social networks, leading to some practical problems. Here we design random walk-based algorithms to accurately estimate properties without any problems caused by private nodes. First, we design a random walk-based sampling algorithm that comprises the neighbor selection to obtain samples having the Markov property and the calculation of weights for each sample to correct the sampling bias. Further, for two graph property estimators, we propose the weighting methods to reduce not only the sampling bias but also estimation errors due to private nodes. The proposed algorithms improve the estimation accuracy of the existing algorithms by up to 92.6% on real-world datasets.","[{""name"":""Kazuki Nakajima"",""id"":""/profile/99659573348""},{""name"":""Kazuyuki Shudo"",""id"":""/profile/81100391338""},{""name"":""Kazuki Nakajima"",""id"":""/profile/99659573348""},{""name"":""Kazuyuki Shudo"",""id"":""/profile/81100391338""}]","[""Yong-Yeol Ahn, Seungyeop Han, Haewoon Kwak, Sue Moon, and Hawoong Jeong. 2007. Analysis of Topological Characteristics of Huge Online Social Networking Services. In WWW. 835--844.Google Scholar"",""Réka Albert, Hawoong Jeong, and Albert-László Barabási. 2000. Error and attack tolerance of complex networks. Nature, Vol. 406 (2000), 378--382.Google ScholarCross Ref"",""Lars Backstrom, Paolo Boldi, Marco Rosa, Johan Ugander, and Sebastiano Vigna. 2012. Four Degrees of Separation. In WebSci. 33--42.Google Scholar"",""Salvatore A Catanese, Pasquale De Meo, Emilio Ferrara, Giacomo Fiumara, and Alessandro Provetti. 2011. Crawling Facebook for Social Network Analysis Purposes. In WIMS. 1--8.Google Scholar"",""Xiaowei Chen, Yongkun Li, Pinghui Wang, and John Lui. 2016. A General Framework for Estimating Graphlet Statistics via Random Walk. PVLDB, Vol. 10, 3 (2016), 253--264.Google ScholarDigital Library"",""Anirban Dasgupta, Ravi Kumar, and Tamas Sarlos. 2014. On Estimating the Average Degree. In WWW. 795--806.Google Scholar"",""Ratan Dey, Zubin Jelveh, and Keith Ross. 2012. Facebook Users Have Become Much More Private: A Large-Scale Study. In 2012 IEEE International Conference on Pervasive Computing and Communications Workshops. 346--352.Google Scholar"",""Facebook. 2010. Facebook 500 Million Stories. https://www.facebook.com/notes/facebook/500-million-stories/409753352130/.Google Scholar"",""Minas Gjoka, Maciej Kurant, Carter T Butts, and Athina Markopoulou. 2010. Walking in Facebook: A Case Study of Unbiased Sampling of OSNs. In INFOCOM. 1--9.Google Scholar"",""Minas Gjoka, Maciej Kurant, Carter T Butts, and Athina Markopoulou. 2011. Practical Recommendations on Crawling Online Social Networks. IEEE Journal on Selected Areas in Communications, Vol. 29, 9 (2011), 1872--1892.Google ScholarCross Ref"",""Stephen J Hardiman and Liran Katzir. 2013. Estimating clustering coefficients and size of social networks via random walk. In WWW. 539--550.Google Scholar"",""Liran Katzir, Edo Liberty, and Oren Somekh. 2011. Estimating sizes of social networks via biased sampling. In WWW. 597--606.Google Scholar"",""Gueorgi Kossinets. 2006. Effects of missing data in social networks. Social networks, Vol. 28, 3 (2006), 247--268.Google Scholar"",""Jérôme Kunegis. 2013. KONECT -- The Koblenz Network Collection. In WWW. 1343--1350.Google Scholar"",""Maciej Kurant, Minas Gjoka, Carter T Butts, and Athina Markopoulou. 2011. Walking on a Graph with a Magnifying Glass: Stratified Sampling via Weighted Random Walks. In SIGMETRICS. 281--292.Google Scholar"",""Haewoon Kwak, Changhyun Lee, Hosung Park, and Sue Moon. 2010. What is Twitter, a Social Network or a News Media?. In WWW. 591--600.Google Scholar"",""Chul-Ho Lee, Xin Xu, and Do Young Eun. 2012. Beyond random walk and metropolis-hastings samplers: why you should not backtrack for unbiased graph sampling. In SIGMETRICS. 319--330.Google Scholar"",""Jure Leskovec and Andrej Krevl. 2014. SNAP Datasets: Stanford Large Network Dataset Collection. http://snap.stanford.edu/data.Google Scholar"",""David A Levin and Yuval Peres. 2017. Markov Chains and Mixing Times. Vol. 107. American Mathematical Soc.Google Scholar"",""Alan Mislove, Massimiliano Marcon, Krishna P Gummadi, Peter Druschel, and Bobby Bhattacharjee. 2007. Measurement and Analysis of Online Social Networks. In IMC. 29--42.Google Scholar"",""Seth A Myers, Aneesh Sharma, Pankaj Gupta, and Jimmy Lin. 2014. Information Network or Social Network? The Structure of the Twitter Follow Graph. In WWW. 493--498.Google Scholar"",""Kazuki Nakajima and Kazuyuki Shudo. 2020. Estimating High Betweenness Centrality Nodes via Random walk in Social Networks. Journal of Information Processing (JIP), Vol. 28 (2020). (to appear).Google Scholar"",""Bruno Ribeiro and Don Towsley. 2010. Estimating and Sampling Graphs with Multidimensional Random Walks. In IMC. 390--403.Google Scholar"",""Ryan A. Rossi and Nesreen K. Ahmed. 2015. The Network Data Repository with Interactive Graph Analytics and Visualization. In AAAI. 4292--4293.Google Scholar"",""Lubos Takac and Michal Zabovsky. 2012. Data analysis in public social networks. In International Scientific Conference and International Workshop Present Day Trends of Innovations.Google Scholar"",""Twitter. 2020 a. Twitter API GET followers/ids. https://developer.twitter.com/en/docs/accounts-and-users/follow-search-get-users/api-reference/get-followers-ids.html.Google Scholar"",""Twitter. 2020 b. Twitter API GET friends/ids. https://developer.twitter.com/en/docs/accounts-and-users/follow-search-get-users/api-reference/get-friends-ids.html.Google Scholar"",""Pinghui Wang, John Lui, Bruno Ribeiro, Don Towsley, Junzhou Zhao, and Xiaohong Guan. 2014. Efficiently Estimating Motif Statistics of Large Networks. TKDD, Vol. 9, 2 (2014).Google ScholarDigital Library"",""Christo Wilson, Bryce Boe, Alessandra Sala, Krishna PN Puttaswamy, and Ben Y Zhao. 2009. User interactions in social networks and their implications. In EuroSys. 205--218.Google Scholar"",""Shaozhi Ye, Juan Lang, and Felix Wu. 2010. Crawling Online Social Graphs. In APWEB. 236--242.Google Scholar""]"
https://doi.org/10.1145/3394486.3403117,ASGN: An Active Semi-supervised Graph Neural Network for Molecular Property Prediction,"Molecular property prediction (e.g., energy) is an essential problem in chemistry and biology. Unfortunately, many supervised learning methods usually suffer from the problem of scarce labeled molecules in the chemical space, where such property labels are generally obtained by Density Functional Theory (DFT) calculation which is extremely computational costly. An effective solution is to incorporate the unlabeled molecules in a semi-supervised fashion. However, learning semi-supervised representation for large amounts of molecules is challenging, including the joint representation issue of both molecular essence and structure, the conflict between representation and property leaning. Here we propose a novel framework called Active Semi-supervised Graph Neural Network (ASGN) by incorporating both labeled and unlabeled molecules. Specifically, ASGN adopts a teacher-student framework. In the teacher model, we propose a novel semi-supervised learning method to learn general representation that jointly exploits information from molecular structure and molecular distribution. Then in the student model, we target at property prediction task to deal with the learning loss conflict. At last, we proposed a novel active learning strategy in terms of molecular diversities to select informative data during the whole framework learning. We conduct extensive experiments on several public datasets. Experimental results show the remarkable performance of our ASGN framework.","[{""name"":""Zhongkai Hao"",""id"":""/profile/99659573963""},{""name"":""Chengqiang Lu"",""id"":""/profile/99659573879""},{""name"":""Zhenya Huang"",""id"":""/profile/99659086161""},{""name"":""Hao Wang"",""id"":""/profile/99659455731""},{""name"":""Zheyuan Hu"",""id"":""/profile/99659575005""},{""name"":""Qi Liu"",""id"":""/profile/83358683257""},{""name"":""Enhong Chen"",""id"":""/profile/81323488612""},{""name"":""Cheekong Lee"",""id"":""/profile/99659573527""},{""name"":""Zhongkai Hao"",""id"":""/profile/99659573963""},{""name"":""Chengqiang Lu"",""id"":""/profile/99659573879""},{""name"":""Zhenya Huang"",""id"":""/profile/99659086161""},{""name"":""Hao Wang"",""id"":""/profile/99659455731""},{""name"":""Zheyuan Hu"",""id"":""/profile/99659575005""},{""name"":""Qi Liu"",""id"":""/profile/83358683257""},{""name"":""Enhong Chen"",""id"":""/profile/81323488612""},{""name"":""Cheekong Lee"",""id"":""/profile/99659573527""}]","[""Yuki Markus Asano, Christian Rupprecht, and Andrea Vedaldi. 2019. Self-labelling via simultaneous clustering and representation learning. arXiv preprint arXiv:1911.05371 (2019).Google Scholar"",""Jordan T Ash, Chicheng Zhang, Akshay Krishnamurthy, John Langford, and Alekh Agarwal. 2019. Deep batch active learning by diverse, uncertain gradient lower bounds. arXiv preprint arXiv:1906.03671 (2019).Google Scholar"",""Axel Becke. 2007. The quantum theory of atoms in molecules: from solid state to DNA and drug design .John Wiley \u0026 Sons.Google Scholar"",""Axel D Becke. 2014. Perspective: Fifty years of density-functional theory in chemical physics. The Journal of chemical physics, Vol. 140, 18 (2014), 18A301.Google ScholarCross Ref"",""Piotr Bojanowski and Armand Joulin. 2017. Unsupervised learning by predicting noise. In Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 517--526.Google ScholarDigital Library"",""Mathilde Caron, Piotr Bojanowski, Armand Joulin, and Matthijs Douze. 2018. Deep clustering for unsupervised learning of visual features. In Proceedings of the European Conference on Computer Vision (ECCV). 132--149.Google ScholarCross Ref"",""Marco Cuturi. 2013. Sinkhorn distances: Lightspeed computation of optimal transport. In Advances in neural information processing systems. 2292--2300.Google Scholar"",""Marco Cuturi and Arnaud Doucet. 2014. Fast computation of Wasserstein barycenters. (2014).Google Scholar"",""Kien Do, Truyen Tran, and Svetha Venkatesh. 2019. Graph transformation policy network for chemical reaction prediction. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 750--760.Google ScholarDigital Library"",""Sean Ekins, Ana C Puhl, Kimberley M Zorn, Thomas R Lane, Daniel P Russo, Jennifer J Klein, Anthony J Hickey, and Alex M Clark. 2019. Exploiting machine learning for end-to-end drug discovery and development. Nature materials, Vol. 18, 5 (2019), 435.Google Scholar"",""Yarin Gal, Riashat Islam, and Zoubin Ghahramani. 2017. Deep bayesian active learning with image data. In Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 1183--1192.Google ScholarDigital Library"",""Spyros Gidaris, Praveer Singh, and Nikos Komodakis. 2018. Unsupervised representation learning by predicting image rotations. arXiv preprint arXiv:1803.07728 (2018).Google Scholar"",""Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. 2017. Neural message passing for quantum chemistry. In Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 1263--1272.Google ScholarDigital Library"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In Advances in neural information processing systems. 1024--1034.Google Scholar"",""Katja Hansen, Franziska Biegler, Raghunathan Ramakrishnan, Wiktor Pronobis, O Anatole Von Lilienfeld, Klaus-Robert Muller, and Alexandre Tkatchenko. 2015. Machine learning predictions of molecular properties: Accurate many-body potentials and nonlocality in chemical space. The journal of physical chemistry letters, Vol. 6, 12 (2015), 2326--2331.Google Scholar"",""Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. [n.d.]. Momentum Contrast for Unsupervised Visual Representation Learning. Technical Report. arxiv: 1911.05722v2Google Scholar"",""Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531 (2015).Google Scholar"",""Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay S Pande, and Jure Leskovec. [n.d.]. Pre-training Graph Neural Networks. Technical Report. arxiv: 1905.12265v1Google Scholar"",""Zhenya Huang, Qi Liu, Yuying Chen, Le Wu, Keli Xiao, Enhong Chen, Haiping Ma, and Guoping Hu. 2020. Learning or Forgetting? A Dynamic Approach for Tracking the Knowledge Proficiency of Students. ACM Trans. Inf. Syst., Vol. 38, 2 (2020), 19:1--19:33. https://doi.org/10.1145/3379507Google ScholarDigital Library"",""Diederik P Kingma and Max Welling. 2013. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 (2013).Google Scholar"",""Walter Kohn and Lu Jeu Sham. 1965. Self-consistent equations including exchange and correlation effects. Physical review, Vol. 140, 4A (1965), A1133.Google Scholar"",""Alex Kulesza and Ben Taskar. 2011. k-DPPs: Fixed-size determinantal point processes. (2011).Google Scholar"",""Chengqiang Lu, Qi Liu, Chao Wang, Zhenya Huang, Peize Lin, and Lixin He. 2019. Molecular property prediction: A multilevel quantum interactions modeling perspective. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 1052--1060.Google ScholarCross Ref"",""Yao Ma, Suhang Wang, Charu C Aggarwal, and Jiliang Tang. 2019. Graph convolutional networks with eigenpooling. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 723--731.Google ScholarDigital Library"",""Dino Oglic, Roman Garnett, and Thomas G\""artner. 2017. Active search in intensionally specified structured spaces. In Thirty-First AAAI Conference on Artificial Intelligence .Google ScholarDigital Library"",""Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, and Alexei A Efros. 2016. Context encoders: Feature learning by inpainting. In Proceedings of the IEEE conference on computer vision and pattern recognition. 2536--2544.Google ScholarCross Ref"",""Hongbin Pei, Bingzhe Wei, Kevin Chen-Chuan Chang, Yu Lei, and Bo Yang. 2020. Geom-GCN: Geometric Graph Convolutional Networks. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26--30, 2020. OpenReview.net. https://openreview.net/forum?id=S1e2agrFvSGoogle Scholar"",""Raghunathan Ramakrishnan, Pavlo O Dral, Matthias Rupp, and O Anatole Von Lilienfeld. 2014. Quantum chemistry structures and properties of 134 kilo molecules. Scientific data, Vol. 1 (2014), 140022.Google Scholar"",""Antti Rasmus, Mathias Berglund, Mikko Honkala, Harri Valpola, and Tapani Raiko. 2015. Semi-supervised learning with ladder networks. In Advances in neural information processing systems. 3546--3554.Google Scholar"",""Kristof Schütt, Pieter-Jan Kindermans, Huziel Enoc Sauceda Felix, Stefan Chmiela, Alexandre Tkatchenko, and Klaus-Robert Müller. 2017. Schnet: A continuous-filter convolutional neural network for modeling quantum interactions. In Advances in neural information processing systems. 991--1001.Google Scholar"",""Ozan Sener and Silvio Savarese. 2017. Active Learning for Convolutional Neural Networks: A Core-Set Approach. (2017), 1--13. arxiv: 1708.00489 http://arxiv.org/abs/1708.00489Google Scholar"",""H Sebastian Seung, Manfred Opper, and Haim Sompolinsky. 1992. Query by committee. In Proceedings of the fifth annual workshop on Computational learning theory. 287--294.Google ScholarDigital Library"",""Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research, Vol. 15, 1 (2014), 1929--1958.Google Scholar"",""Peter C St. John, Caleb Phillips, Travis W Kemper, A Nolan Wilson, Yanfei Guan, Michael F Crowley, Mark R Nimlos, and Ross E Larsen. 2019. Message-passing neural networks for high-throughput polymer screening. The Journal of chemical physics, Vol. 150, 23 (2019), 234111.Google ScholarCross Ref"",""Fan-Yun Sun, Jordan Hoffmann, and Jian Tang. 2019. InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization. arXiv preprint arXiv:1908.01000 (2019).Google Scholar"",""Antti Tarvainen and Harri Valpola. 2017. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In Advances in neural information processing systems. 1195--1204.Google Scholar"",""David J Thouless. 2014. The quantum mechanics of many-body systems .Courier Corporation.Google Scholar"",""Daniel Ting and Eric Brochu. 2018. Optimal subsampling with influence functions. In Advances in Neural Information Processing Systems. 3650--3659.Google Scholar"",""Hao Wang, Enhong Chen, Qi Liu, Tong Xu, Dongfang Du, Wen Su, and Xiaopeng Zhang. 2018. A United Approach to Learning Sparse Attributed Network Embedding. In 2018 IEEE International Conference on Data Mining (ICDM). IEEE, 557--566.Google ScholarCross Ref"",""Hao Wang, Tong Xu, Qi Liu, Defu Lian, Enhong Chen, Dongfang Du, Han Wu, and Wen Su. 2019. MCNE: An End-to-End Framework for Learning Multiple Conditional Network Representations of Social Network. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1064--1072.Google ScholarDigital Library"",""Likang Wu, Zhi Li, Hongke Zhao, Zhen Pan, Qi Liu, and Enhong Chen. 2020. Estimating Early Fundraising Performance of Innovations via Graph-Based Market Environment Model. In The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020. AAAI Press, 6396--6403.Google ScholarCross Ref"",""Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2018. How Powerful are Graph Neural Networks? (2018), 1--17. arxiv: 1810.00826 http://arxiv.org/abs/1810.00826Google Scholar"",""Zhilin Yang, Jie Tang, and Yutao Zhang. 2014. Active learning for streaming networked data. In Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management. 1129--1138.Google ScholarDigital Library"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale recommender systems. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 974--983.Google ScholarDigital Library"",""Xiaojin Jerry Zhu. 2005. Semi-supervised learning literature survey. Technical Report. University of Wisconsin-Madison Department of Computer Sciences.Google Scholar""]"
https://doi.org/10.1145/3394486.3403118,Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks,"Modeling multivariate time series has long been a subject that has attracted researchers from a diverse range of fields including economics, finance, and traffic. A basic assumption behind multivariate time series forecasting is that its variables depend on one another but, upon looking closely, it is fair to say that existing methods fail to fully exploit latent spatial dependencies between pairs of variables. In recent years, meanwhile, graph neural networks (GNNs) have shown high capability in handling relational dependencies. GNNs require well-defined graph structures for information propagation which means they cannot be applied directly for multivariate time series where the dependencies are not known in advance. In this paper, we propose a general graph neural network framework designed specifically for multivariate time series data. Our approach automatically extracts the uni-directed relations among variables through a graph learning module, into which external knowledge like variable attributes can be easily integrated. A novel mix-hop propagation layer and a dilated inception layer are further proposed to capture the spatial and temporal dependencies within the time series. The graph learning, graph convolution, and temporal convolution modules are jointly learned in an end-to-end framework. Experimental results show that our proposed model outperforms the state-of-the-art baseline methods on 3 of 4 benchmark datasets and achieves on-par performance with other approaches on two traffic datasets which provide extra structural information.","[{""name"":""Zonghan Wu"",""id"":""/profile/99659573029""},{""name"":""Shirui Pan"",""id"":""/profile/81549268756""},{""name"":""Guodong Long"",""id"":""/profile/81549189756""},{""name"":""Jing Jiang"",""id"":""/profile/99659218371""},{""name"":""Xiaojun Chang"",""id"":""/profile/99658727663""},{""name"":""Chengqi Zhang"",""id"":""/profile/81350601426""},{""name"":""Zonghan Wu"",""id"":""/profile/99659573029""},{""name"":""Shirui Pan"",""id"":""/profile/81549268756""},{""name"":""Guodong Long"",""id"":""/profile/81549189756""},{""name"":""Jing Jiang"",""id"":""/profile/99659218371""},{""name"":""Xiaojun Chang"",""id"":""/profile/99658727663""},{""name"":""Chengqi Zhang"",""id"":""/profile/81350601426""}]","[""George EP Box, Gwilym M Jenkins, Gregory C Reinsel, and Greta M Ljung. 2015. Time series analysis: forecasting and control .John Wiley \u0026 Sons.Google Scholar"",""Fengwen Chen, Shirui Pan, Jing Jiang, Huan Huo, and Guodong Long. 2019 b. DAGCN: Dual Attention Graph Convolutional Networks. In Proc. of IJCNN.Google ScholarCross Ref"",""Weiqi Chen, Ling Chen, Yu Xie, Wei Cao, Yusong Gao, and Xiaojie Feng. 2019 a. Multi-Range Attentive Bicomponent Graph Convolutional Network for Traffic Forecasting. In Proc. of AAAI.Google Scholar"",""Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, and Cho-Jui Hsieh. 2019. Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks. In Proc. of KDD.Google ScholarDigital Library"",""Roger Frigola. 2015. Bayesian time series learning with Gaussian processes. Ph.D. Dissertation. University of Cambridge.Google Scholar"",""Roger Frigola-Alcalde. 2016. Bayesian time series learning with Gaussian processes. Ph.D. Dissertation. University of Cambridge.Google Scholar"",""Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. 2017. Neural message passing for quantum chemistry. In Proc. of ICML. 1263--1272.Google Scholar"",""Shengnan Guo, Youfang Lin, Ning Feng, Chao Song, and Huaiyu Wan. 2019. Attention based spatial-temporal graph convolutional networks for traffic flow forecasting. In Proc. of AAAI, Vol. 33. 922--929.Google ScholarCross Ref"",""Amol Kapoor, Aram Galstyan, Bryan Perozzi, Greg Ver Steeg, Hrayr Harutyunyan, Kristina Lerman, Nazanin Alipourfard, and Sami Abu-El-Haija. 2019. MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing. In Proc. of ICML.Google Scholar"",""Thomas N Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional networks. In Proc. of ICLR.Google Scholar"",""Johannes Klicpera, Aleksandar Bojchevski, and Stephan Günnemann. 2019. Predict then propagate: Graph neural networks meet personalized pagerank. In Proc. of ICLR.Google Scholar"",""Guokun Lai, Wei-Cheng Chang, Yiming Yang, and Hanxiao Liu. 2018. Modeling long-and short-term temporal patterns with deep neural networks. In Proc. of SIGIR. ACM, 95--104.Google ScholarDigital Library"",""Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. 2018. Diffusion convolutional recurrent neural network: Data-driven traffic forecasting. In Proc. of ICLR.Google Scholar"",""Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. 2016. Wavenet: A generative model for raw audio. arXiv:1609.03499 (2016).Google Scholar"",""Zheyi Pan, Yuxuan Liang, Weifeng Wang, Yong Yu, Yu Zheng, and Junbo Zhang. 2019. Urban Traffic Prediction from Spatio-Temporal Data Using Deep Meta Learning. In KDD. ACM, 1720--1730.Google Scholar"",""Stephen Roberts, Michael Osborne, Mark Ebden, Steven Reece, Neale Gibson, and Suzanne Aigrain. 2013. Gaussian processes for time-series modelling. Philos. Trans. R. Soc. A, Vol. 371, 1984 (2013), 20110550.Google ScholarCross Ref"",""Youngjoo Seo, Michaël Defferrard, Pierre Vandergheynst, and Xavier Bresson. 2018. Structured sequence modeling with graph convolutional recurrent networks. In Proc. of NIPS. Springer, 362--373.Google Scholar"",""Lei Shi, Yifan Zhang, Jian Cheng, and Hanqing Lu. 2019. Two-Stream Adaptive Graph Convolutional Networks for Skeleton-Based Action Recognition. In Proc. of CVPR. 12026--12035.Google ScholarCross Ref"",""Shun-Yao Shih, Fan-Keng Sun, and Hung-yi Lee. 2019. Temporal pattern attention for multivariate time series forecasting. Machine Learning, Vol. 108, 8--9 (2019), 1421--1441.Google ScholarCross Ref"",""Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. 2015. Going deeper with convolutions. In Proc. of CVPR. 1--9.Google ScholarCross Ref"",""Zonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, and Chengqi Zhang. 2019. Graph WaveNet for Deep Spatial-Temporal Graph Modeling. In Proc. of IJCAI.Google ScholarCross Ref"",""Sijie Yan, Yuanjun Xiong, and Dahua Lin. 2018. Spatial temporal graph convolutional networks for skeleton-based action recognition. In Proc. of AAAI. 3482--3489.Google Scholar"",""Bing Yu, Haoteng Yin, and Zhanxing Zhu. 2018. Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting. In Proc. of IJCAI. 3634--3640.Google ScholarCross Ref"",""Fisher Yu and Vladlen Koltun. 2016. Multi-scale context aggregation by dilated convolutions. In ICLR.Google Scholar"",""G Peter Zhang. 2003. Time series forecasting using a hybrid ARIMA and neural network model. Neurocomputing, Vol. 50 (2003), 159--175.Google ScholarCross Ref"",""Chuanpan Zheng, Xiaoliang Fan, Cheng Wang, and Jianzhong Qi. 2020. GMAN: A Graph Multi-Attention Network for Traffic Prediction. In Proc. of AAAI.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403119,Learning Opinion Dynamics From Social Traces,"Opinion dynamics the research field dealing with how people's opinions form and evolve in a social context? traditionally uses agent-based models to validate the implications of sociological theories. These models encode the causal mechanism that drives the opinion formation process, and have the advantage of being easy to interpret. However, as they do not exploit the availability of data, their predictive power is limited. Moreover, parameter calibration and model selection are manual and difficult tasks.In this work we propose an inference mechanism for fitting a generative, agent-like model of opinion dynamics to real-world social traces. Given a set of observables (e.g., actions and interactions between agents), our model can recover the most-likely latent opinion trajectories that are compatible with the assumptions about the process dynamics. This type of model retains the benefits of agent-based ones (i.e., causal interpretation), while adding the ability to perform model selection and hypothesis testing on real data.We showcase our proposal by translating a classical agent-based model of opinion dynamics into its generative counterpart. We then design an inference algorithm based on online expectation maximization to learn the latent parameters of the model. Such algorithm can recover the latent opinion trajectories from traces generated by the classical agent-based model. In addition, it can identify the most likely set of macro parameters used to generate a data trace, thus allowing testing of sociological hypotheses. Finally, we apply our model to real-world data from Reddit to explore the long-standing question about the impact of the backfire effect. Our results suggest a low prominence of the effect in Reddit's political conversation.","[{""name"":""Corrado Monti"",""id"":""/profile/82458729357""},{""name"":""Gianmarco De Francisci Morales"",""id"":""/profile/81479663507""},{""name"":""Francesco Bonchi"",""id"":""/profile/81100305585""},{""name"":""Corrado Monti"",""id"":""/profile/82458729357""},{""name"":""Gianmarco De Francisci Morales"",""id"":""/profile/81479663507""},{""name"":""Francesco Bonchi"",""id"":""/profile/81100305585""}]","[""A. E. Allahverdyan and A. Galstyan. 2014. Opinion Dynamics with Confirmation Bias. PLOS ONE, Vol. 9, 7 (2014), e99557.Google ScholarCross Ref"",""R. Axelrod. 1997. The Dissemination of Culture: A Model with Local Convergence and Global Polarization. Journal of Conflict Resolution, Vol. 41, 2 (1997), 203--226.Google ScholarCross Ref"",""E. A. Bender and E. R. Canfield. 1978. The asymptotic number of labeled graphs with given degree sequences. Journal of Combinatorial Theory, Series A, Vol. 24, 3 (1978), 296--307.Google ScholarCross Ref"",""C. Castellano, S. Fortunato, and V. Loreto. 2007. Statistical Physics of Social Dynamics. Reviews of Modern Physics, Vol. 81, 2 (2007), 591.Google ScholarCross Ref"",""X. Chen, P. Tsaparas, J. Lijffijt, and T. De Bie. 2019. Opinion Dynamics with Backfire Effect and Biased Assimilation. arXiv:1903.11535 (2019).Google Scholar"",""A. Coates, L. Han, and A. Kleerekoper. 2018. A Unified Framework for Opinion Dynamics. In 17th International Conference on Autonomous Agents and MultiAgent Systems (AAMAS'18). 1079--1086.Google Scholar"",""A. De, I. Valera, N. Ganguly, S. Bhattacharya, and M. G. Rodriguez. 2016. Learning and Forecasting Opinion Dynamics in Social Networks. In Advances in Neural Information Processing Systems (NIPS'16). 397--405.Google Scholar"",""G. Deffuant, S. Huet, and S. Skerratt. 2008. An agent based model of agri-environmental measure diffusion: What for? Agent Based Modelling in Natural Resource Management (2008), 55--73.Google Scholar"",""G. Deffuant, D. Neau, F. Amblard, and G. Weisbuch. 2000. Mixing Beliefs among Interacting Agents. Advances in Complex Systems, Vol. 3 (2000), 87--98.Google ScholarCross Ref"",""M. H. DeGroot. 1974. Reaching a Consensus. JASA, Vol. 69, 345 (1974), 118--121.Google ScholarCross Ref"",""M. Del Vicario, A. Scala, G. Caldarelli, H. E. Stanley, and W. Quattrociocchi. 2017. Modeling Confirmation Bias and Polarization. Scientific Reports, Vol. 7, 40391 (2017).Google Scholar"",""L. Festinger. 1957. A Theory Of Cognitive Dissonance. Stanford University Press.Google Scholar"",""A. Flache, M. M\""as, T. Feliciani, E. Chattoe-Brown, G. Deffuant, S. Huet, and J. Lorenz. 2017. Models of Social Influence: Towards the Next Frontiers. Journal of Artificial Societies and Social Simulation, Vol. 20, 4 (2017).Google ScholarCross Ref"",""R. Fletcher and J. Jenkins. 2019. Polarisation and the News Media in Europe: A Literature Review of the Effect of News Use on Polarisation across Europe. Technical Report. European Parliamentary Research Service.Google Scholar"",""J. R. P. French. 1956. A Formal Theory of Social Power. Psychological Review, Vol. 63, 3 (1956), 181--194. https://doi.org/10.1037/h0046123Google ScholarCross Ref"",""Noah E. Friedkin and E. C. Johnsen. 1990. Social influence and opinions. The Journal of Mathematical Sociology, Vol. 15, 3--4 (1990), 193--206.Google ScholarCross Ref"",""J. Gómez-Serrano, C. Graham, and J. Boudec. 2010. The Bounded Confidence Model Of Opinion Dynamics. Mathematical Models and Methods in Applied Sciences, Vol. 22, 2 (2010), 1150007.Google ScholarCross Ref"",""J. Grazzini, M. G. Richiardi, and M. Tsionas. 2017. Bayesian Estimation of Agent-Based Models. Journal of Economic Dynamics and Control, Vol. 77 (2017), 26--47.Google ScholarCross Ref"",""F. Harary. 1959. A criterion for unanimity in French's theory of social power. In Studies in social power. 168--182.Google Scholar"",""W. Jager and F. Amblard. 2005. Uniformity, Bipolarization and Pluriformity Captured as Generic Stylized Behavior with an Agent-Based Simulation Model of Attitude Change. Computational \u0026 Mathematical Organization Theory, Vol. 10 (2005), 295--303.Google ScholarDigital Library"",""J. Mathias, S. Huet, and G. Deffuant. 2016. Bounded Confidence Model with Fixed Uncertainties and Extremists: The Opinions Can Keep Fluctuating Indefinitely. Journal of Artificial Societies and Social Simulation, Vol. 19, 1 (2016), 6.Google ScholarCross Ref"",""J. Pearl. 2009. Causal Inference in Statistics: An Overview. Statistics Surveys, Vol. 3 (2009), 96--146.Google ScholarCross Ref"",""W. Quattrociocchi, R. Conte, and E. Lodi. 2011. Opinions within Media, Power and Gossip. arXiv:1102.2336 (2011).Google Scholar"",""M. Sherif and C. Hovland. 1961. Social Judgment: Assimilation and Contrast Effects in Communication and Attitude Change. Yale University Press.Google Scholar"",""O. A. Sichani and M. Jalili. 2017. Inference of Hidden Social Power Through Opinion Formation in Complex Networks. IEEE Transactions on Network Science and Engineering, Vol. 4, 3 (2017), 154--164.Google ScholarCross Ref"",""A. Sippitt. 2019. The Backfire Effect: Does It Exist? And Does It Matter for Factcheckers? Technical Report. Full Fact.Google Scholar"",""P. Sobkowicz. 2016. Quantitative Agent Based Model of Opinion Dynamics: Polish Elections of 2015. PLOS ONE, Vol. 11, 5 (2016), e0155098.Google ScholarCross Ref"",""F. Squazzoni. 2012. Agent-Based Computational Sociology.Google Scholar"",""A. Stefanelli and R. Seidl. 2014. Moderate and polarized opinions. Using empirical data for an agent-based simulation. In Social Simulation Conference.Google Scholar"",""T. Tang and C. G. Chorus. 2019. Learning Opinions by Observing Actions: Simulation of Opinion Dynamics Using an Action-Opinion Inference Model. Journal of Artificial Societies and Social Simulation, Vol. 22, 3 (2019), 1--2.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403120,Enterprise Cooperation and Competition Analysis with a Sign-Oriented Preference Network,"The development of effective cooperative and competitive strategies has been recognized as the key to the success of many companies in a globalized world. Therefore, many efforts have been made on the analysis of cooperation and competition among companies. However, existing studies either rely on labor intensive empirical analysis with specific cases or do not consider the heterogeneous company information when quantitatively measuring company relationships in a company network. More importantly, it is not clear how to generate a unified representation for cooperative and competitive strategies in a data driven way. To this end, in this paper, we provide a large-scale data driven analysis on the cooperative and competitive relationships among companies in a Sign-oriented Preference Network (SOPN). Specifically, we first exploit a Relational Graph Convolutional Network (RGCN) for generating a deep representation of the heterogeneous company features and a company relation network. Then, based on the representation, we generate two sets of preference vectors for each company by utilizing the attention mechanism to model the importance of different relations, representing their cooperative and competitive strategies respectively. Also, we design a sign constraint to model the dependency between cooperation and competition relations. Finally, we conduct extensive experiments on a real-world dataset, and verify the effectiveness of our approach. Moreover, we provide a case study to show some interesting patterns and their potential business value.","[{""name"":""Le Dai"",""id"":""/profile/99659575091""},{""name"":""Yu Yin"",""id"":""/profile/99659286714""},{""name"":""Chuan Qin"",""id"":""/profile/99659281492""},{""name"":""Tong Xu"",""id"":""/profile/81550320556""},{""name"":""Xiangnan He"",""id"":""/profile/87658767957""},{""name"":""Enhong Chen"",""id"":""/profile/81323488612""},{""name"":""Hui Xiong"",""id"":""/profile/81451596433""},{""name"":""Le Dai"",""id"":""/profile/99659575091""},{""name"":""Yu Yin"",""id"":""/profile/99659286714""},{""name"":""Chuan Qin"",""id"":""/profile/99659281492""},{""name"":""Tong Xu"",""id"":""/profile/81550320556""},{""name"":""Xiangnan He"",""id"":""/profile/87658767957""},{""name"":""Enhong Chen"",""id"":""/profile/81323488612""},{""name"":""Hui Xiong"",""id"":""/profile/81451596433""}]","[""Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural machine translation by jointly learning to align and translate. In 3rd International Conference on Learning Representations, ICLR 2015.Google Scholar"",""Ignacio Bretos and Carmen Marcuello. 2017. Revisiting globalization challenges and opportunities in the development of cooperatives. Annals of Public and Cooperative Economics, Vol. 88, 1 (2017), 47--73.Google ScholarCross Ref"",""Yingmei Chen, Zhongyu Wei, and Xuanjing Huang. 2018. Incorporating corporation relationship via graph convolutional neural networks for stock price prediction. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management. 1655--1658.Google ScholarDigital Library"",""Junyoung Chung, Caglar Gulcehre, Kyunghyun Cho, and Yoshua Bengio. 2014. Empirical evaluation of gated recurrent neural networks on sequence modeling. In NIPS 2014 Workshop on Deep Learning.Google Scholar"",""Hepu Deng, Chung-Hsing Yeh, and Robert J Willis. 2000. Inter-company comparison using modified TOPSIS with objective weights. Computers \u0026 Operations Research, Vol. 27, 10 (2000), 963--973.Google ScholarDigital Library"",""Tyler Derr, Yao Ma, and Jiliang Tang. 2018. Signed graph convolutional networks. In 2018 IEEE International Conference on Data Mining (ICDM). IEEE, 929--934.Google ScholarCross Ref"",""Dongfang Du, Hao Wang, Tong Xu, Yanan Lu, Qi Liu, and Enhong Chen. 2017. Solving link-oriented tasks in signed network via an embedding approach. In 2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC). 75--80.Google ScholarCross Ref"",""Xavier Glorot and Yoshua Bengio. 2010. Understanding the difficulty of training deep feedforward neural networks. In Proceedings of the thirteenth international conference on artificial intelligence and statistics. 249--256.Google Scholar"",""Devi R Gnyawali and Byung-Jin Robert Park. 2011. Co-opetition between giants: Collaboration with competitors for technological innovation. Research policy, Vol. 40, 5 (2011), 650--663.Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. 855--864.Google ScholarDigital Library"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. Advances in neural information processing systems. 1024--1034.Google Scholar"",""Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Optimization. In 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7--9, 2015, Conference Track Proceedings.Google Scholar"",""Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In Proceedings of the 5th International Conference on Learning Representations (ICLR '17).Google Scholar"",""Chaang-Yung Kung and Kun-Li Wen. 2007. Applying grey relational analysis and grey decision-making to evaluate the relationship between company attributes and its financial performance-a case study of venture capital enterprises in Taiwan. Decision support systems, Vol. 43, 3 (2007), 842--852.Google Scholar"",""Laurens van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE. Journal of machine learning research, Vol. 9, Nov (2008), 2579--2605.Google Scholar"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Distributed Representations of Words and Phrases and Their Compositionality. In Proceedings of the 26th International Conference on Neural Information Processing Systems (NIPS'13). Red Hook, NY, USA, 3111--3119.Google ScholarDigital Library"",""Semih Önüt, Selin Soner Kara, and Elif Ics ik. 2009. Long term supplier selection using a combined fuzzy MCDM approach: A case study for a telecommunication company. Expert systems with applications, Vol. 36, 2 (2009), 3887--3895.Google Scholar"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. 701--710.Google ScholarDigital Library"",""Cristina Quintana-Garcia and Carlos A Benavides-Velasco. 2004. Cooperation, competition, and innovative capability: a panel data of European dedicated biotechnology firms. Technovation, Vol. 24, 12 (2004), 927--938.Google ScholarCross Ref"",""Steffen Rendle. 2012. Factorization machines with libfm. ACM Transactions on Intelligent Systems and Technology (TIST), Vol. 3, 3 (2012), 1--22.Google ScholarDigital Library"",""Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian Personalized Ranking from Implicit Feedback. In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence. 452--461.Google ScholarDigital Library"",""Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den Berg, Ivan Titov, and Max Welling. 2018. Modeling relational data with graph convolutional networks. In European Semantic Web Conference. Springer, 593--607.Google ScholarCross Ref"",""Hubert Schmitz. 1999. Global competition and local cooperation: success and failure in the Sinos Valley, Brazil. World development, Vol. 27, 9 (1999), 1627--1650.Google Scholar"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. Proceedings of the 24th international conference on world wide web. 1067--1077.Google ScholarDigital Library"",""David J Teece. 2010. Business models, business strategy and innovation. Long range planning, Vol. 43, 2--3 (2010), 172--194.Google Scholar"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. 2018. Graph Attention Networks. International Conference on Learning Representations (2018).Google Scholar"",""Daixin Wang, Peng Cui, and Wenwu Zhu. 2016. Structural deep network embedding. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. 1225--1234.Google ScholarDigital Library"",""Hao Wang, Tong Xu, Qi Liu, Defu Lian, Enhong Chen, Dongfang Du, Han Wu, and Wen Su. 2019. MCNE: An End-to-End Framework for Learning Multiple Conditional Network Representations of Social Network. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1064--1072.Google ScholarDigital Library"",""Shuhan Yuan, Xintao Wu, and Yang Xiang. 2017. SNE: signed network embedding. In PAKDD. Springer, 183--195.Google Scholar"",""Thomas Zaslavsky. 1982. Signed graphs. Discrete Applied Mathematics (1982), 47--74.Google Scholar"",""Chuxu Zhang, Dongjin Song, Chao Huang, Ananthram Swami, and Nitesh V Chawla. 2019. Heterogeneous graph neural network. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 793--803.Google ScholarDigital Library"",""Le Zhang, Tong Xu, Hengshu Zhu, Chuan Qin, Qingxin Meng, Hui Xiong, and Enhong Chen. 2020. Large-Scale Talent Flow Embedding for Company Competitive Analysis. In Proceedings of The Web Conference 2020. 2354--2364.Google ScholarDigital Library"",""Le Zhang, Hengshu Zhu, Tong Xu, Chen Zhu, Chuan Qin, Hui Xiong, and Enhong Chen. 2019. Large-Scale Talent Flow Forecast with Dynamic Latent Factor Model. In The World Wide Web Conference. 2312--2322.Google Scholar""]"
https://doi.org/10.1145/3394486.3403121,BLOB: A Probabilistic Model for Recommendation that Combines Organic and Bandit Signals,"A common task for recommender systems is to build a profile of the interests of a user from items in their browsing history and later to recommend items to the user from the same catalog. The users' behavior consists of two parts: the sequence of items that they viewed without intervention (the organic part) and the sequences of items recommended to them and their outcome (the bandit part).In this paper, we propose Bayesian Latent Organic Bandit model (BLOB), a probabilistic approach to combine the 'organic' and 'bandit' signals in order to improve the estimation of recommendation quality. The bandit signal is valuable as it gives direct feedback of recommendation performance, but the signal quality is very uneven, as it is highly concentrated on the recommendations deemed optimal by the past version of the recommender system. In contrast, the organic signal is typically strong and covers most items, but is not always relevant to the recommendation task. In order to leverage the organic signal to efficiently learn the bandit signal in a Bayesian model we identify three fundamental types of distances, namely action-history, action-action and history-history distances. We implement a scalable approximation of the full model using variational auto-encoders and the local re-paramerization trick. We show using extensive simulation studies that our method out-performs or matches the value of both state-of-the-art organic-based recommendation algorithms, and of bandit-based methods (both value and policy-based) both in organic and bandit-rich environments.","[{""name"":""Otmane Sakhi"",""id"":""/profile/99659574818""},{""name"":""Stephen Bonner"",""id"":""/profile/99658691027""},{""name"":""David Rohde"",""id"":""/profile/99659549416""},{""name"":""Flavian Vasile"",""id"":""/profile/81392602246""},{""name"":""Otmane Sakhi"",""id"":""/profile/99659574818""},{""name"":""Stephen Bonner"",""id"":""/profile/99658691027""},{""name"":""David Rohde"",""id"":""/profile/99659549416""},{""name"":""Flavian Vasile"",""id"":""/profile/81392602246""}]","[""Gediminas Adomavicius and Alexander Tuzhilin. 2005. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. IEEE transactions on knowledge and data engineering 17, 6 (2005),734--749.Google Scholar"",""James O Berger, Robert L Wolpert, MJ Bayarri, MH DeGroot, Bruce M Hill, David A Lane, and Lucien LeCam. 1988. The likelihood principle. Lecture notes-Monograph series 6 (1988), iii--199.Google Scholar"",""Alina Beygelzimer and John Langford. 2009. The offset tree for learning with partial labels. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 129--138.Google ScholarDigital Library"",""David M. Blei and John D. Lafferty. 2005. Correlated Topic Models. InAdvances inNeural Information Processing Systems 18 [Neural Information Processing Systems,NIPS 2005, December 5--8, 2005, Vancouver, British Columbia, Canada]. 147--154. http://papers.nips.cc/paper/2906-correlated-topic-modelsGoogle Scholar"",""David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent dirichlet allocation.Journal of machine Learning research 3, Jan (2003), 993--1022.Google Scholar"",""L. Bottou, J. Peters, J. Quiñonero-Candela, D. Charles, D. Chickering, E. Portugaly, D. Ray, P. Simard, and E. Snelson. 2013. Counterfactual reasoning and learning systems: The example of computational advertising. The Journal of Machine Learning Research14, 1 (2013), 3207--3260.Google Scholar"",""Guillaume Bouchard. 2007. Efficient bounds for the softmax function, applications to inference in hybrid models. (2007).Google Scholar"",""Olivier Cappé and Eric Moulines. 2009. On-line expectation--maximization algorithm for latent data models. Journal of the Royal Statistical Society: Series B(Statistical Methodology)71, 3 (2009), 593--613.Google ScholarCross Ref"",""Kyunghyun Cho, Bart van Merrienboer, Çaglar Gülçehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, October 25--29, 2014, Doha, Qatar, A meeting of SIGDAT, a Special Interest Group of the ACL. ACL, 1724--1734. http://aclweb.org/anthology/D/D14/D14--1179.pdfGoogle Scholar"",""James Davidson, Benjamin Liebald, Junning Liu, Palash Nandy, Taylor Van Vleet, Ullas Gargi, Sujoy Gupta, Yu He, Mike Lambert, Blake Livingston, et al.2010.The YouTube video recommendation system. In Proceedings of the fourth ACM conference on Recommender systems. 293--296.Google Scholar"",""Aristides Gionis, Piotr Indyk, Rajeev Motwani, et al.1999. Similarity search in high dimensions via hashing. In Vldb, Vol. 99. 518--529.Google ScholarDigital Library"",""Miguel A Hernan and James M Robins. 2010. Causal inference. (2010).Google Scholar"",""Balázs Hidasi and Alexandros Karatzoglou. 2018. Recurrent Neural Networks with Top-k Gains for Session-based Recommendations. In Proceedings of the 27thACM International Conference on Information and Knowledge Management, CIKM2018, Torino, Italy, October 22--26, 2018, Alfredo Cuzzocrea, James Allan, Norman W.Paton, Divesh Srivastava, Rakesh Agrawal, Andrei Z. Broder, Mohammed J. Zaki,K. Selçuk Candan, Alexandros Labrinidis, Assaf Schuster, and Haixun Wang(Eds.). ACM, 843--852. https://doi.org/10.1145/3269206.3271761Google Scholar"",""Tommi Jaakkola and Michael Jordan. 1997. A variational approach to Bayesian logistic regression models and their extensions. In Sixth International Workshop on Artificial Intelligence and Statistics, Vol. 82. 4.Google Scholar"",""O. Jeunen, D. Rohde, F. Vasile, and M. Bompaire. 2020. Joint Policy-Value Learning for Recommendation. In Proc. of the 26th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining (KDD '20).Google Scholar"",""Fredrik Johansson, Uri Shalit, and David Sontag. 2016. Learning representations for counterfactual inference. In International Conference on Machine Learning. 3020--3029.Google ScholarDigital Library"",""Diederik P Kingma, Tim Salimans, and Max Welling. 2015. Variational dropout and the local reparameterization trick. In Advances in Neural Information Processing Systems. 2575--2583.Google Scholar"",""Diederik P. Kingma and Max Welling. 2014. Auto-Encoding Variational Bayes. In2nd International Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14--16, 2014, Conference Track Proceedings, Yoshua Bengio and Yann Le Cun (Eds.). https://openreview.net/group?id=ICLR.cc/2014Google Scholar"",""David A. Knowles and Tom Minka. 2011. Non-conjugate Variational Message Passing for Multinomial and Binary Regression. In Advances in Neural Information Processing Systems 24, J. Shawe-Taylor, R. S. Zemel, P. L. Bartlett, F. Pereira, and K. Q. Weinberger (Eds.). Curran Associates, Inc., 1701--1709.Google Scholar"",""Yehuda Koren and Robert Bell. 2015. Advances in collaborative filtering. In Recommender systems handbook. Springer, 77--118.Google ScholarDigital Library"",""John D. Lafferty and David M. Blei. 2006. Correlated Topic Models. In Advances in Neural Information Processing Systems 18, Y. Weiss, B. Schölkopf, and J. C. Platt(Eds.). MIT Press, 147--154. http://papers.nips.cc/paper/2906-correlated-topic-models.pdfGoogle Scholar"",""Tor Lattimore and Csaba Szepesvári. 2018. Bandit algorithms. preprint(2018),28.Google Scholar"",""Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara. 2018. Variational Autoencoders for Collaborative Filtering. In Proceedings of the 2018 World Wide Web Conference on World Wide Web, WWW 2018, Lyon, France, April23--27, 2018, Pierre-Antoine Champin, Fabien L. Gandon, Mounia Lalmas, and Panagiotis G. Ipeirotis (Eds.). ACM, 689--698. https://doi.org/10.1145/3178876.3186150Google ScholarDigital Library"",""D. Liang, R. G. Krishnan, M. D Hoffman, and T. Jebara. 2018. Variational autoencoders for collaborative filtering. In Proc. of the 2018 World Wide Web Conference(WWW '18). International World Wide Web Conferences Steering Committee, ACM, 689--698.Google Scholar"",""Alberto Lumbreras, Louis Filstroff, and Cédric Févotte. 2018. Bayesian mean-parameterized nonnegative binary matrix factorization. arXiv preprint arXiv: 1812.06866(2018).Google Scholar"",""Yury A Malkov and Dmitry A Yashunin. 2018. Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs. IEEE transactions on pattern analysis and machine intelligence(2018).Google Scholar"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed Representations of Words and Phrases and their Compositionality. InAdvances in Neural Information Processing Systems 26, C. J. C. Burges, L. Bottou,M. Welling, Z. Ghahramani, and K. Q. Weinberger (Eds.). Curran Associates, Inc.,3111--3119.Google Scholar"",""Radford M Neal. 2012. Bayesian learning for neural networks. Vol. 118. Springer Science \u0026 Business Media.Google Scholar"",""Tui H Nolan and Matt P Wand. 2017. Accurate logistic variational message passing: algebraic and numerical details. Stat 6, 1 (2017), 102--112.Google ScholarCross Ref"",""Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang,Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.2017. Automatic differentiation in PyTorch. In NIPS-W.Google Scholar"",""Ya'acov Ritov, Peter J Bickel, Anthony C Gamst, Bastiaan Jan Korneel Kleijn, et al. 2014. The Bayesian Analysis of Complex, High-Dimensional Models: Can It BeCODA? Statist. Sci. 29, 4 (2014), 619--639.Google ScholarCross Ref"",""Herbert Robbins and Sutton Monro. 1951. A stochastic approximation method. The annals of mathematical statistics 22, 3 (1951), 400--407.Google Scholar"",""David Rohde, Stephen Bonner, Travis Dunlop, Flavian Vasile, and Alexandros Karatzoglou. 2018. RecoGym: A Reinforcement Learning Environment for the problem of Product Recommendation in Online Advertising. In REVEAL workshop, ACM Conference on Recommender Systems 2018.Google Scholar"",""David Rohde and Matt P Wand. 2016. Semiparametric mean field variational Bayes: General principles and numerical issues. The Journal of Machine LearningResearch17, 1 (2016), 5975--6021.Google Scholar"",""Francisco JR Ruiz, Michalis K Titsias, Adji B Dieng, and David M Blei. 2018. Augment and reduce: Stochastic inference for large categorical distributions. arXiv preprint arXiv:1802.04220(2018).Google Scholar"",""Tobias Schnabel, Adith Swaminathan, Ashudeep Singh, Navin Chandak, and Thorsten Joachims. 2016. Recommendations As Treatments: Debiasing Learning and Evaluation. In Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48 (ICML'16). 1670--1679.Google ScholarDigital Library"",""A. Storkey. 2009. When training and test sets are different: characterizing learning transfer. Dataset shift in machine learning(2009), 3--28.Google Scholar"",""Adith Swaminathan and Thorsten Joachims. 2015. Batch learning from logged bandit feedback through counterfactual risk minimization. Journal of Machine Learning Research 16 (2015), 1731--1755.Google ScholarDigital Library"",""A. Swaminathan and T. Joachims. 2015. Batch learning from logged bandit feedback through counterfactual risk minimization. Journal of Machine Learning Research 16, 1 (2015), 1731--1755.Google ScholarDigital Library"",""Michalis Titsias. 2016. One-vs-each approximation to softmax for scalable estimation of probabilities. In Advances in Neural Information Processing Systems. 4161--4169.Google Scholar"",""Vladimir Vapnik. 2013. The nature of statistical learning theory. Springer science\u0026 business media.Google Scholar""]"
https://doi.org/10.1145/3394486.3403122,AutoST: Efficient Neural Architecture Search for Spatio-Temporal Prediction,"Spatio-temporal (ST) prediction (e.g. crowd flow prediction) is of great importance in a wide range of smart city applications from urban planning, intelligent transportation and public safety. Recently, many deep neural network models have been proposed to make accurate prediction. However, manually designing neural networks requires amount of expert efforts and ST domain knowledge. How to automatically construct a general neural network for diverse spatio-temporal predication tasks in cities? In this paper, we study Neural Architecture Search (NAS) for spatio-temporal prediction and propose an efficient spatio-temporal neural architecture search method, entitled AutoST. To our best knowledge, the search space is an important human prior to the success of NAS in different applications while current NAS models concentrated on optimizing search strategy in the fixed search space. Thus, we design a novel search space tailored for ST-domain which consists of two categories of components: (i) optional convolution operations at each layer to automatically extract multi-range spatio-temporal dependencies; (ii) learnable skip connections among layers to dynamically fuse low- and high-level ST-features. We conduct extensive experiments on four real-word spatio-temporal prediction tasks, including taxi flow and crowd flow, showing that the learned network architectures can significantly improve the performance of representative ST neural network models. Furthermore, our proposed efficient NAS approach searches 8-10x faster than state-of-the-art NAS approaches, demonstrating the efficiency and effectiveness of AutoST.","[{""name"":""Ting Li"",""id"":""/profile/99659479424""},{""name"":""Junbo Zhang"",""id"":""/profile/99659487173""},{""name"":""Kainan Bao"",""id"":""/profile/99659574732""},{""name"":""Yuxuan Liang"",""id"":""/profile/99659140812""},{""name"":""Yexin Li"",""id"":""/profile/99659575258""},{""name"":""Yu Zheng"",""id"":""/profile/81350600388""},{""name"":""Ting Li"",""id"":""/profile/99659479424""},{""name"":""Junbo Zhang"",""id"":""/profile/99659487173""},{""name"":""Kainan Bao"",""id"":""/profile/99659574732""},{""name"":""Yuxuan Liang"",""id"":""/profile/99659140812""},{""name"":""Yexin Li"",""id"":""/profile/99659575258""},{""name"":""Yu Zheng"",""id"":""/profile/81350600388""}]","[""J. An, H. Xiong, J. Huan, and J. Luo. Ultrafast photorealistic style transfer via neural architecture search. In Proceedings of the Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-20), 2020.Google ScholarCross Ref"",""Z. Barret and V. L. Quoc. Neural architecture search with reinforcement learning. In In International Conference on Learning Representations (ICLR-17), 2017.Google Scholar"",""G. Bender, P.-J. Kindermans, B. Zoph, V. Vasudevan, and Q. Le. Understanding and simplifying one-shot architecture search. In Thirty-fifth International Conference on Machine Learning (ICML-2018), 2018.Google Scholar"",""A. Brock, T. Lim,. J. Ritchie, and N. Weston. Smash: One-shot model architecture search through hypernetworks. In arXiv:1711.00536, 2017.Google Scholar"",""H. Cai, L. Zhu, and S. Han. ProxylessNAS: Direct neural architecture search on target task and hardware. In Proceedings of the Seventh International Conference on Learning Representations (ICLR-2019), 2019.Google Scholar"",""C. Chen, K. Li, S. G. Teo, X. Zou, k. Wang, j. Wang, and Z. Zeng. Gated residual recurrent graph neural networks for traffic prediction. In Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19), 2019.Google ScholarCross Ref"",""H. Chen, L. Zhuo, B. Zhang, X. Zheng, J. Liu, D. Doermann, and R. Ji. Binarized neural architecture search. In Proceedings of the Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-20), 2020.Google Scholar"",""W. Chen, L. Chen, Y. Xie, W. Cao, Y. Gao, and X. Feng. Multi-range attentive bicomponent graph convolutional network for traffic forecasting. In Proceedings of the Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-20), 2020.Google ScholarCross Ref"",""K. Cho, B. Van Merriënboer, C. Gulcehre, D. Bahdanau, F. Bougares, H. Schwenk, and Y. Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078, 2014.Google Scholar"",""X. Chu, B. Zhang, H. Ma, R. Xu, J. Li, and Q. Li. Fast, accurate and lightweight super-resolution with neural architecture search. In arXiv:1901.07261, 2019.Google Scholar"",""X. Chu, T. Zhou, B. Zhang, and J. Li. Fair darts: Eliminating unfair advantages in differentiable architecture search. In arXiv preprint arXiv:1911.12126, 2019.Google Scholar"",""x. Geng, Y. Li, L. Wang, L. Zhang, q. Yang, j. Ye, and Y. Liu. Spatiotemporal multi-graph convolution network for ride-hailing demand forecasting. In Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19), 2019.Google Scholar"",""S. Guo, Y. Lin, S. Li, Z. Chen, and H. Wan. Deep spatial--temporal 3d convolutional neural networks for traffic data forecasting. IEEE Transaction on intelligent transportation system (TITS-2019), 2019.Google Scholar"",""Z. Guo, X. Zhang, H. Mu, W. Heng, Z. Liu, Y. Wei, and J. Sun. Single path one-shot neural architecture search with uniform sampling. arXiv preprint arXiv:1904.00420, 2019.Google Scholar"",""P. Hieu, Y. Melody, Z. Barret, V. L. Quoc, and D. Jeff. Efficient neural architecture search via parameter sharing. In In International Conference on Learning Representations (ICLR-18), 2018.Google Scholar"",""S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural computation, 9(8):1735--1780, 1997.Google ScholarDigital Library"",""Y. Liang, S. Ke, J. Zhang, X. Yi, and Y. Zheng. Geoman: Multi-level attention networks for geo-sensory time series prediction. In Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI-18, pages 3428--3434. IJCAI, 7 2018.Google ScholarCross Ref"",""Y. Liang, K. Ouyang, L. Jing, S. Ruan, Y. Liu, J. Zhang, D. S. Rosenblum, and Y. Zheng. Urbanfm: Inferring fine-grained urban flows. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD-19), 2019.Google ScholarDigital Library"",""Y. Liang, K. Ouyang, J. Zhang, Y. Zheng, and D. S. Rosenblum. Revisiting convolutional neural networks for urban flow analytics. arXiv:2003.00895, 2020.Google Scholar"",""Z. Lin, J. Feng, Z. Lu, Y. Li, and D. Jin. Deepstn+: Context-aware spatial temporal neural network for crowd flow prediction in metropolis. In Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19), 2019.Google ScholarCross Ref"",""C. Liu, L.-C. Chen, F. Schroff, H. Adam, W. Hua, A. Yuille, and F. Li. Hierarchical neural architecture search for semantic image segmentation. In arXiv:1901.02985, 2019.Google Scholar"",""H. Liu, K. Simonyan, O. Vinyals, C. Fernando, and K. Kavukcuoglu. Hierarchical representations for efficient architecture search. In Proceedings of the Sixth International Conference on Learning Representations (ICLR-2018), 2018.Google Scholar"",""H. Liu, K. Simonyan, and Y. Yang. Darts: Differentiable architecture search. arXiv preprint arXiv:1806.09055, 2018.Google Scholar"",""H. Lu, J. Langford, R. Caruana, S. Mukherjee, E. Horvitz, and D. Dey. Efficient forward architecture search. In arXiv:1905.13360, 2019.Google Scholar"",""z. Pan, Y. Liang, W. Wang, Y. Yu, Y. Zheng, and J. Zhang. Urban traffic prediction from spatio-temporal data using deep meta learning. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD-19), 2019.Google Scholar"",""X. Shi and D.-Y. Yeung. Machine learning for spatiotemporal sequence forecasting: A survey. arXiv preprint arXiv:1808.06865, 2018.Google Scholar"",""Y. Wang, M. Long, J. Wang, Z. Gao, and S. Y. Philip. Predrnn: Recurrent neural networks for predictive learning using spatiotemporal lstms. In Advances in Neural Information Processing Systems, pages 879--888, 2017.Google Scholar"",""H. Yao, Y. Liu, Y. Wei, X. Tang, and Z. Li. Learning from multiple cities: A meta-learning approach for spatial-temporal prediction. In Proceedings of the Web Conference (WWW-2019), 2019.Google ScholarDigital Library"",""H. Yao, F. Wu, J. Ke, X. Tang, Y. Jia, S. Lu, P. Gong, J. Ye, and L. Zhenhui. Deep multi-view spatial-temporal network for taxi demand prediction. In Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence (AAAI-18), 2018.Google Scholar"",""B. Yu, H. Yin, and Z. Zhu. Spatio-temporal graph convolutional networks: A deep learning framework for traffic forecasting. In Proceedings of the Twenty-sixth International Joint Conference on Artificial Intelligence, IJCAI-17, 2017.Google Scholar"",""J. Zhang, Y. Zheng, Q. Dekang, R. Li, and X. Yi. Dnn-based prediction model for spatial-temporal data. In SIGSPATIAL, 2016.Google ScholarDigital Library"",""J. Zhang, Y. Zheng, and D. Qi. Deep spatio-temporal residual networks for citywide crowd flows prediction. In Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence (AAAI-17), pages 1655--1661, 2017.Google ScholarDigital Library"",""J. Zhang, Y. Zheng, J. Sun, and D. Qi. Flow prediction in spatio-temporal networks based on multitask deep learning. IEEE Transactions on Knowledge and Data Engineering (TKDE-2019), 09 2019.Google Scholar"",""Y. Zheng, L. Capra, O. Wolfson, and H. Yang. Urban computing: Concepts, methodologies, and applications. ACM Transaction on Intelligent Systems and Technology, October 2014.Google ScholarDigital Library"",""Z. Zhu, C. Liu, D. Yang, A. Yuille, and D. Xu. V-nas: Neural architecture search for volumetric medical image segmentation. In 3DV, 2019.Google Scholar"",""B. Zoph, V. Vasudevan, J. Shlens, and Q. V. Le. Learning transferable architectures for scalable image recognition. In arXiv:1707.07012, 2017.Google Scholar""]"
https://doi.org/10.1145/3394486.3403123,COMPOSE: Cross-Modal Pseudo-Siamese Network for Patient Trial Matching,"Clinical trials play important roles in drug development but often suffer from expensive, inaccurate and insufficient patient recruitment. The availability of massive electronic health records (EHR) data and trial eligibility criteria (EC) bring a new opportunity to data driven patient recruitment. One key task named patient-trial matching is to find qualified patients for clinical trials given structured EHR and unstructured EC text (both inclusion and exclusion criteria). How to match complex EC text with longitudinal patient EHRs? How to embed many-to-many relationships between patients and trials? How to explicitly handle the difference between inclusion and exclusion criteria? In this paper, we proposed CrOss-Modal PseudO-SiamEse network (COMPOSE) to address these challenges for patient-trial matching. One path of the network encodes EC using convolutional highway network. The other path processes EHR with multi-granularity memory network that encodes structured patient records into multiple levels based on medical ontology. Using the EC embedding as query, COMPOSE performs attentional record alignment and thus enables dynamic patient-trial matching. COMPOSE also introduces a composite loss term to maximize the similarity between patient records and inclusion criteria while minimize the similarity to the exclusion criteria. Experiment results show COMPOSE can reach 98.0% AUC on patient-criteria matching and 83.7% accuracy on patient-trial matching, which leads 24.3% improvement over the best baseline on real-world patient-trial matching tasks.","[{""name"":""Junyi Gao"",""id"":""/profile/99659535975""},{""name"":""Cao Xiao"",""id"":""/profile/99659193846""},{""name"":""Lucas M. Glass"",""id"":""/profile/99659537804""},{""name"":""Jimeng Sun"",""id"":""/profile/81490657940""},{""name"":""Junyi Gao"",""id"":""/profile/99659535975""},{""name"":""Cao Xiao"",""id"":""/profile/99659193846""},{""name"":""Lucas M. Glass"",""id"":""/profile/99659537804""},{""name"":""Jimeng Sun"",""id"":""/profile/81490657940""}]","[""Anita Alicante, Anna Corazza, Francesco Isgrò, and Stefano Silvestri. 2016. Unsupervised entity and relation extraction from clinical records in Italian. Computers in biology and medicine, Vol. 72 (2016), 263--275.Google Scholar"",""Emily Alsentzer, John R Murphy, Willie Boag, Wei-Hung Weng, Di Jin, Tristan Naumann, and Matthew McDermott. 2019. Publicly available clinical BERT embeddings. arXiv preprint arXiv:1904.03323 (2019).Google Scholar"",""Aurelia Bustos and Antonio Pertusa. 2018. Learning eligibility in cancer clinical trials using deep neural networks. Applied Sciences, Vol. 8, 7 (2018), 1206.Google ScholarCross Ref"",""MK. Campbell, C. Snowdon, D. Francis, D. Elbourne, AM. McDonald, R. Knight, and A. Grant. 2007. Recruitment to randomised trials: strategies for trial enrollment and participation study: the STEPS study. Health Technol. Assess. (2007).Google Scholar"",""Edward Choi, Mohammad Taha Bahadori, Le Song, Walter F Stewart, and Jimeng Sun. 2017. GRAM: graph-based attention model for healthcare representation learning. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 787--795.Google ScholarDigital Library"",""Edward Choi, Cao Xiao, Walter Stewart, and Jimeng Sun. 2018. Mime: Multilevel medical embedding of electronic health records for predictive healthcare. In Advances in Neural Information Processing Systems. 4547--4557.Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).Google Scholar"",""Jingyue Gao, Xiting Wang, Yasha Wang, Zhao Yang, Junyi Gao, Jiangtao Wang, Wen Tang, and Xing Xie. 2019. Camp: Co-attention memory networks for diagnosis prediction in healthcare. ICDM.Google Scholar"",""Junyi Gao, Cao Xiao, Yasha Wang, Wen Tang, Lucas M Glass, and Jimeng Sun. 2020. StageNet: Stage-Aware Neural Networks for Health Risk Prediction. arXiv preprint arXiv:2001.10054 (2020).Google Scholar"",""Qing Guo, Wei Feng, Ce Zhou, Rui Huang, Liang Wan, and Song Wang. 2017. Learning dynamic siamese network for visual object tracking. In Proceedings of the IEEE International Conference on Computer Vision. 1763--1771.Google ScholarCross Ref"",""NS. Hill, IR. Preston, and KE. Roberts. 2008. Patients with pulmonary arterial hypertension in clinical trials. Who are they? Proc. Am. Thorac. Soc., Vol. 5 (2008), 503--609.Google ScholarCross Ref"",""Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural computation, Vol. 9, 8 (1997), 1735--1780.Google Scholar"",""Baotian Hu, Zhengdong Lu, Hang Li, and Qingcai Chen. 2014. Convolutional neural network architectures for matching natural language sentences. In Advances in neural information processing systems. 2042--2050.Google Scholar"",""Lloyd H Hughes, Michael Schmitt, Lichao Mou, Yuanyuan Wang, and Xiao Xiang Zhu. 2018. Identifying corresponding patches in SAR and optical images with a pseudo-siamese CNN. IEEE Geoscience and Remote Sensing Letters, Vol. 15, 5 (2018), 784--788.Google ScholarCross Ref"",""Alistair EW Johnson, Tom J Pollard, Lu Shen, H Lehman Li-wei, Mengling Feng, Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G Mark. 2016. MIMIC-III, a freely accessible critical care database. Scientific data, Vol. 3 (2016), 160035.Google Scholar"",""Tian Kang, Shaodian Zhang, Youlan Tang, Gregory W Hruby, Alexander Rusanov, Noémie Elhadad, and Chunhua Weng. 2017. EliIE: An open-source information extraction system for clinical trial eligibility criteria. Journal of the American Medical Informatics Association, Vol. 24, 6 (2017), 1062--1071.Google ScholarCross Ref"",""Yoon Kim, Yacine Jernite, David Sontag, and Alexander M Rush. 2016. Character-aware neural language models. In Thirtieth AAAI Conference on Artificial Intelligence .Google ScholarDigital Library"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Liantao Ma, Junyi Gao, Yasha Wang, Chaohe Zhang, Jiangtao Wang, Wenjie Ruan, Wen Tang, Xin Gao, and Xinyu Ma. 2019. AdaCare: Explainable Clinical Health Status Representation Learning via Scale-Adaptive Feature Extraction and Recalibration. arXiv preprint arXiv:1911.12205 (2019).Google Scholar"",""Denise Myshko. 2005. Accurately Costing a Clinical Trial - PharmaVOICE. https://www.pharmavoice.com/article/434/. (2005). Accessed: 2020--2--13.Google Scholar"",""Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. 2017. Automatic differentiation in PyTorch. (2017).Google Scholar"",""Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. Glove: Global vectors for word representation. In In EMNLP .Google Scholar"",""Pharmafile. 2016. Clinical trials and their patients: The rising costs and how to stem the loss. http://www.pharmafile.com/news/511225/clinical-trials-and-their-patients-rising-costs-and-how-stem-loss. (2016). Accessed Jan 1, 2020.Google Scholar"",""Yonggang Qi, Yi-Zhe Song, Honggang Zhang, and Jun Liu. 2016. Sketch-based image retrieval via siamese convolutional neural network. In 2016 IEEE International Conference on Image Processing (ICIP). IEEE, 2460--2464.Google ScholarCross Ref"",""Zhou Ren, Hailin Jin, Zhe Lin, Chen Fang, and Alan Yuille. 2015. Multi-instance visual-semantic embedding. arXiv preprint arXiv:1512.06963 (2015).Google Scholar"",""Feller S. 2015. One in Four Cancer Trials Fails to Enroll Enough Participants. (2015). https://www.upi.com/Health_News/2015/12/30/One-in-four-cancer-trials-fails-to-enroll-enough-participants/2611451485504Google Scholar"",""Rupesh Kumar Srivastava, Klaus Greff, and Jürgen Schmidhuber. 2015. Highway networks. arXiv preprint arXiv:1505.00387 (2015).Google Scholar"",""Wayne Treible, Philip Saponaro, and Chandra Kambhamettu. 2019. Wildcat: In-the-wild color-and-thermal patch comparison with deep residual pseudo-siamese networks. In 2019 IEEE International Conference on Image Processing (ICIP). IEEE, 1307--1311.Google ScholarCross Ref"",""Chunhua Weng, Xiaoying Wu, Zhihui Luo, Mary Regina Boland, Dimitri Theodoratos, and Stephen B Johnson. 2011. EliXR: an approach to eligibility criteria extraction and representation. Journal of the American Medical Informatics Association, Vol. 18, Supplement_1 (2011), i116--i124.Google ScholarCross Ref"",""Jason Weston, Sumit Chopra, and Antoine Bordes. 2014. Memory networks. arXiv preprint arXiv:1410.3916 (2014).Google Scholar"",""Quanzeng You, Zhengyou Zhang, and Jiebo Luo. 2018. End-to-end convolutional semantic embeddings. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 5735--5744.Google ScholarCross Ref"",""Chi Yuan, Patrick B Ryan, Casey Ta, Yixuan Guo, Ziran Li, Jill Hardin, Rupa Makadia, Peng Jin, Ning Shang, Tian Kang, et al. 2019. Criteria2Query: a natural language interface to clinical databases for cohort definition. Journal of the American Medical Informatics Association, Vol. 26, 4 (2019), 294--305.Google ScholarCross Ref"",""Jiani Zhang, Xingjian Shi, Irwin King, and Dit-Yan Yeung. 2017. Dynamic key-value memory networks for knowledge tracing. In Proceedings of the 26th international conference on World Wide Web. International World Wide Web Conferences Steering Committee, 765--774.Google ScholarDigital Library"",""Xingyao Zhang, Cao Xiao, Lucas Glass, and Jimeng Sun. 2020. Patient-Trial Matching with Deep Embedding and Entailment Prediction. In Proceedings of The Web Conference 2020 (WWW '20). Association for Computing Machinery, New York, NY, USA, 1029--1037. https://doi.org/10.1145/3366423.3380181Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403124,Discovering Succinct Pattern Sets Expressing Co-Occurrence and Mutual Exclusivity,"Pattern mining is one of the core topics of data mining. We consider the problem of mining a succinct set of patterns that together explain the data in terms of mutual exclusivity and co-occurence. That is, we extend the traditional pattern languages beyond conjunctions, enabling us to capture more complex relationships, such as replacable sub-components or antagonists in biological pathways.We formally define this problem in terms of the Minimum Description Length principle, by which we identify the best set of patterns as the one that most succinctly describes the data. To avoid spurious results---in sparse data mutual exclusivity is likely just due to chance---we propose an efficient statistical test for K-ary mutual exclusivity. As the search space for the optimal model is enormous and unstructured, we propose Mexican, a heuristic algorithm to efficiently discover high quality sets of patterns of co-occurences and mutual exclusivity. Through extensive experiments we show that Mexican recovers the ground truth on synthetic data, and meaningful results on real-world data. Both in stark contrast to the state of the art, that result in millions of spurious patterns.","[{""name"":""Jonas Fischer"",""id"":""/profile/99659574472""},{""name"":""Jilles Vreeken"",""id"":""/profile/81335499054""},{""name"":""Jonas Fischer"",""id"":""/profile/99659574472""},{""name"":""Jilles Vreeken"",""id"":""/profile/81335499054""}]","[""R. Agrawal, T. Imielinksi, and A. Swami. 1993. Mining association rules between sets of items in large databases. In SIGMOD. ACM, 207--216.Google Scholar"",""M.-L. Antonie and O. R. Zaïane. 2004. Mining Positive and Negative Association Rules: An Approach for Confined Rules. In PKDD. Springer, 27--38.Google Scholar"",""F. B. Ardakani, K. Kattler, K. Nordström, N. Gasparoni, G. Gasparoni, S. Fuchs, A.Sinha, M. Barann, P. Ebert, J. Fischer, B. Hutter, G. Zipprich, C. D. Imbusch, B.Felder, J. Eils, B. Brors, T. Lengauer, T. Manke, P. Rosenstiel, J. Walter, and M. H.Schulz. 2018. Integrative analysis of single-cell expression data reveals distinct regulatory states in bidirectional promoters. Epigen. \u0026 chrom. 11, 1 (2018), 66.Google Scholar"",""T. Calders and B. Goethals. 2002. Mining all Non-Derivable Frequent Itemsets. In PKDD. 74--85.Google Scholar"",""S. F. Carr, E. Papp, J. C. Wu, and Y. Natsumeda. 1993. Characterization of human type I and type II IMP dehydrogenases. J. Biol. Chem.268, 36 (1993), 27286--27290.Google Scholar"",""S. Dalleiger and J. Vreeken. 2020. Explainable Data Decompositions. AAAI.Google Scholar"",""T. De Bie. 2011. Maximum entropy models and subjective interestingness: an application to tiles in binary databases. Data Min. Knowl. Disc.23, 3 (2011),407--446.Google ScholarDigital Library"",""J. Fischer and J. Vreeken. 2019. Sets of Robust Rules, and How to Find Them. Springer.Google Scholar"",""J. Fowkes and C. Sutton. 2016. A Subsequence Interleaving Model for Sequential Pattern Mining. InKDD.Google Scholar"",""P. Grünwald. 2007. The Minimum Description Length Principle. MIT Press.Google Scholar"",""W. Hämäläinen. 2012. Kingfisher: an efficient algorithm for searching for both positive and negative dependency rules with statistical significance measures. Knowl. Inf. Sys.32, 2 (2012), 383--414.Google ScholarCross Ref"",""J. Han, J. Pei, and Y. Yin. 2000. Mining frequent patterns without candidate generation. In SIGMOD. ACM, 1--12.Google Scholar"",""H. Heikinheimo, J. K. Seppänen, E. Hinkkanen, H. Mannila, and T. Mielikäinen. 2007. Finding low-entropy sets and trees from binary data. In KDD. 350--359.Google Scholar"",""Y. J. Hsieh, T. K. Kundu, Z. Wang, R. Kovelman, and R. G. Roeder. 1999. The TFIIIC90 subunit of TFIIIC interacts with multiple components of the RNA poly-merase III machinery and contains a histone-specific acetyltransferase activity.Mol. Cell. Biol.19, 11 (1999), 7697--7704.Google ScholarCross Ref"",""E. Inoue and J. Yamauchi. 2006. AMP-activated protein kinase regulates PEPCK gene expression by direct phosphorylation of a novel zinc finger transcription factor. Biochem. Biophys. Res. Commun. 351, 4 (2006), 793--799.Google ScholarCross Ref"",""P. Kontkanen and P. Myllymäki. 2007. A linear-time algorithm for computing the multinomial stochastic complexity. Inf. Process. Lett. 103, 6 (2007), 227--233.Google ScholarDigital Library"",""J. Krungkrai, N. Wutipraditkul, P. Prapunwattana, S. R. Krungkrai, and S. Rochanakij. 2001. A nonradioactive high-performance liquid chromatographicmicroassay for uridine 5'-monophosphate synthase, orotate phosphoribosyltrans-ferase, and orotidine 5'-monophosphate decarboxylase. Anal. Biochem. 299, 2(2001), 162--168.Google ScholarCross Ref"",""M. Li and P. Vitányi. 1993.An Introduction to Kolmogorov Complexity and its Applications. Springer.Google Scholar"",""M. Mampaey, J. Vreeken, and N. Tatti. 2012. Summarizing Data Succinctly with the Most Informative Itemsets. ACM TKDD 6 (2012), 1--44. Issue 4.Google ScholarDigital Library"",""T. Mitchell-Jones. 1999. Societas Europaea Mammalogica. http://www.european-mammals.org. (1999). http://www.european-mammals.orgGoogle Scholar"",""F. Moerchen, M. Thies, and A. Ultsch. 2011. Efficient mining of all margin-closed itemsets with applications in temporal knowledge discovery and classification by compression. Knowl. Inf. Sys.29, 1 (2011), 55--80.Google ScholarDigital Library"",""S. Myllykangas, J. Himberg, T. Böhling, B. Nagy, J. Hollmén, and S. Knuutila. 2006. DNA copy number amplification profiling of human neoplasms. Oncogene 25, 55(2006), 7324--7332.Google ScholarCross Ref"",""R. Naffouje, P. Grover, H. Yu, A. Sendilnathan, K. Wolfe, N. Majd, E. P. Smith, K. Takeuchi, T. Senda, S. Kofuji, and A. T. Sasaki. 2019. Anti-Tumor Potential of IMP Dehydrogenase Inhibitors: A Century-Long Story.Cancers (Basel)11, 9(2019).Google Scholar"",""A. A. Nanavati, K. P. Chitrapura, S. Joshi, and R. Krishnapuram. 2001. Mining Generalised Disjunctive Association Rules. In CIKM. ACM, 482--489.Google Scholar"",""L. Papaxanthos, F. Llinares-López, D. A. Bodenham, and K. M. Borgwardt. 2016. Finding significant combinations of features in the presence of categorical co-variates. In NIPS. 2271--2279.Google Scholar"",""N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal. 1999. Discovering Frequent Closed Item sets for Association Rules. In ICDT. ACM, 398--416.Google Scholar"",""L. Pellegrina, M. Riondato, and F. Vandin. 2019. SPuManTE: Significant Pattern Mining with Unconditional Testing. In KDD. ACM, 1528--1538.Google Scholar"",""L. Pellegrina and F. Vandin. 2018. Efficient Mining of the Most Significant Patterns with Permutation Testing. In KDD. 2070--2079.Google Scholar"",""J. Rissanen. 1978. Modeling by shortest data description. Automatica 14, 1 (1978), 465--471.Google ScholarDigital Library"",""J. Rissanen. 1983. A Universal Prior for Integers and Estimation by Minimum Description Length. Annals Stat.11, 2 (1983), 416--431.Google ScholarCross Ref"",""D. C. Schultz, K. Ayyanathan, D. Negorev, G. G. Maul, and F. J. Rauscher. 2002.SETDB1: a novel KAP-1-associated histone H3, lysine 9-specific methyl transferase that contributes to HP1-mediated silencing of euchromatic genes by KRAB zinc-finger proteins.Genes Dev.16, 8 (2002), 919--932.Google Scholar"",""I. Sharma, R. K. Dutta, N. K. Singh, and Y. S. Kanwar. 2017. High Glucose-Induced Hypomethylation Promotes Binding of Sp-1 to Myo-Inositol Oxygenase:Implication in the Pathobiology of Diabetic Tubulopathy. Am. J. Pathol. 187, 4(2017), 724--739.Google ScholarCross Ref"",""Y. Shima, S. Mitsuishi, K. Hirata, and M. Harao. 2004. Extracting Minimal and Closed Monotone DNF Formulas. In DS. Springer, 298--305.Google Scholar"",""J. Vreeken, M. van Leeuwen, and A. Siebes. 2011. Krimp: Mining Item sets that Compress. Data Min. Knowl. Disc.23, 1 (2011), 169--214.Google ScholarDigital Library"",""G. I. Webb. 2010. Self-sufficient item sets: An approach to screening potentially interesting associations between items. ACM TKDD 4, 1 (2010), 1--20.Google ScholarDigital Library"",""M. Zaki, N. Ramakrishnan, and L. Zhao. 2010. Mining Frequent Boolean Expressions: Application to Gene Expression and Regulatory Modeling. IJKDB 1 (092010), 68--96.Google Scholar"",""M. J. Zaki, S. Parthasarathy, M. Ogihara, and W. Li. 1997. New algorithms for fast discovery of association rules. In KDD.Google Scholar""]"
https://doi.org/10.1145/3394486.3403125,TIPRDC: Task-Independent Privacy-Respecting Data Crowdsourcing Framework for Deep Learning with Anonymized Intermediate Representations,"The success of deep learning partially benefits from the availability of various large-scale datasets. These datasets are often crowdsourced from individual users and contain private information like gender, age, etc. The emerging privacy concerns from users on data sharing hinder the generation or use of crowdsourcing datasets and lead to hunger of training data for new deep learning applications. One naive solution is to pre-process the raw data to extract features at the user-side, and then only the extracted features will be sent to the data collector. Unfortunately, attackers can still exploit these extracted features to train an adversary classifier to infer private attributes. Some prior arts leveraged game theory to protect private attributes. However, these defenses are designed for known primary learning tasks, the extracted features work poorly for unknown learning tasks. To tackle the case where the learning task may be unknown or changing, we present TIPRDC, a task-independent privacy-respecting data crowdsourcing framework with anonymized intermediate representation. The goal of this framework is to learn a feature extractor that can hide the privacy information from the intermediate representations; while maximally retaining the original information embedded in the raw data for the data collector to accomplish unknown learning tasks. We design a hybrid training method to learn the anonymized intermediate representation: (1) an adversarial training process for hiding private information from features; (2) maximally retain original information using a neural-network-based mutual information estimator. We extensively evaluate TIPRDC and compare it with existing methods using two image datasets and one text dataset. Our results show that TIPRDC substantially outperforms other existing methods. Our work is the first task-independent privacy-respecting data crowdsourcing framework.","[{""name"":""Ang Li"",""id"":""/profile/99659523808""},{""name"":""Yixiao Duan"",""id"":""/profile/99659574248""},{""name"":""Huanrui Yang"",""id"":""/profile/99659321276""},{""name"":""Yiran Chen"",""id"":""/profile/81502777312""},{""name"":""Jianlei Yang"",""id"":""/profile/99658715116""},{""name"":""Ang Li"",""id"":""/profile/99659523808""},{""name"":""Yixiao Duan"",""id"":""/profile/99659574248""},{""name"":""Huanrui Yang"",""id"":""/profile/99659321276""},{""name"":""Yiran Chen"",""id"":""/profile/81502777312""},{""name"":""Jianlei Yang"",""id"":""/profile/99658715116""}]","[""Brendan Avent, Aleksandra Korolova, David Zeber, Torgeir Hovden, and Benjamin Livshits. 2017. BLENDER: Enabling local search with a hybrid differential privacy model. In 26th $$USENIX$$ Security Symposium (USENIX Security 17). 747--764.Google Scholar"",""Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473 (2014).Google Scholar"",""Raef Bassily and Adam Smith. 2015. Local, private, efficient protocols for succinct histograms. In Proceedings of the forty-seventh annual ACM symposium on Theory of computing. 127--135.Google Scholar"",""Su Lin Blodgett, Lisa Green, and Brendan O'Connor. 2016. Demographic dialectal variation in social media: A case study of African-American English. arXiv preprint arXiv:1608.08868 (2016).Google Scholar"",""Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition. Ieee, 248--255.Google Scholar"",""Alexey Dosovitskiy and Thomas Brox. 2016a. Generating images with perceptual similarity metrics based on deep networks. In Advances in neural information processing systems. 658--666.Google Scholar"",""Alexey Dosovitskiy and Thomas Brox. 2016b. Inverting visual representations with convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern recognition. 4829--4837.Google Scholar"",""John C Duchi, Michael I Jordan, and Martin J Wainwright. 2013. Local privacy and statistical minimax rates. In 2013 IEEE 54th Annual Symposium on Foundations of Computer Science. IEEE, 429--438.Google Scholar"",""Úlfar Erlingsson, Vasyl Pihur, and Aleksandra Korolova. 2014. Rappor: Randomized aggregatable privacy-preserving ordinal response. In Proceedings of the 2014 ACM SIGSAC conference on computer and communications security. 1054--1067.Google Scholar"",""Ran Gilad-Bachrach, Nathan Dowlin, Kim Laine, Kristin Lauter, Michael Naehrig, and John Wernsing. 2016. Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy. In International Conference on Machine Learning. 201--210.Google Scholar"",""Google. 2018a. Data Preparation. https://cloud.google.com/ml-engine/docs/tensorflow/data-prep.Google Scholar"",""Google. 2018b. Google Now Launcher. https://en.wikipedia.org/wiki/Google_Now.Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition. 770--778.Google Scholar"",""R Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil Bachman, Adam Trischler, and Yoshua Bengio. 2018. Learning deep representations by mutual information estimation and maximization. arXiv preprint arXiv:1808.06670 (2018).Google Scholar"",""Tae-hoon Kim, Dongmin Kang, Kari Pulli, and Jonghyun Choi. 2019. Training with the invisibles: Obfuscating images to share safely for learning visual recognition models. arXiv preprint arXiv:1901.00098 (2019).Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A Method for Stochastic Optimization. arXiv.org (Dec. 2014), arXiv:1412.6980. arxiv: cs.LG/1412.6980Google Scholar"",""Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems. 1097--1105.Google Scholar"",""Neeraj Kumar, Alexander C Berg, Peter N Belhumeur, and Shree K Nayar. 2009. Attribute and simile classifiers for face verification. In 2009 IEEE 12th International Conference on Computer Vision. IEEE, 365--372.Google Scholar"",""Ang Li, Jiayi Guo, Huanrui Yang, and Yiran Chen. 2019. Deepobfuscator: Adversarial training framework for privacy-preserving image classification. arXiv preprint arXiv:1909.04126 (2019).Google Scholar"",""Ninghui Li, Tiancheng Li, and Suresh Venkatasubramanian. 2007. t-closeness: Privacy beyond k-anonymity and l-diversity. In 2007 IEEE 23rd International Conference on Data Engineering. IEEE, 106--115.Google Scholar"",""Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C Lawrence Zitnick. 2014. Microsoft coco: Common objects in context. In European conference on computer vision. Springer, 740--755.Google Scholar"",""Sicong Liu, Junzhao Du, Anshumali Shrivastava, and Lin Zhong. 2019. Privacy Adversarial Network: Representation Learning for Mobile Data Privacy. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 3, 4 (2019), 1--18.Google Scholar"",""Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. 2015. Deep Learning Face Attributes in the Wild. In Proceedings of International Conference on Computer Vision (ICCV).Google Scholar"",""Aravindh Mahendran and Andrea Vedaldi. 2015. Understanding deep image representations by inverting them. In Proceedings of the IEEE conference on computer vision and pattern recognition. 5188--5196.Google Scholar"",""Sebastian Nowozin, Botond Cseke, and Ryota Tomioka. 2016. f-gan: Training generative neural samplers using variational divergence minimization. In Advances in neural information processing systems. 271--279.Google Scholar"",""Seong Joon Oh, Rodrigo Benenson, Mario Fritz, and Bernt Schiele. 2016. Faceless person recognition: Privacy implications in social media. In European Conference on Computer Vision. Springer, 19--35.Google Scholar"",""Seong Joon Oh, Mario Fritz, and Bernt Schiele. 2017. Adversarial image perturbation for privacy protection a game theory perspective. In 2017 IEEE International Conference on Computer Vision (ICCV). IEEE, 1491--1500.Google Scholar"",""Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. 2016. Wavenet: A generative model for raw audio. arXiv preprint arXiv:1609.03499 (2016).Google Scholar"",""Seyed Ali Osia, Ali Shahin Shamsabadi, Sina Sajadmanesh, Ali Taheri, Kleomenis Katevas, Hamid R Rabiee, Nicholas D Lane, and Hamed Haddadi. 2020. A hybrid deep learning architecture for privacy-preserving mobile analytics. IEEE Internet of Things Journal (2020).Google Scholar"",""Nicolas Papernot, Shuang Song, Ilya Mironov, Ananth Raghunathan, Kunal Talwar, and Úlfar Erlingsson. 2018. Scalable private learning with pate. arXiv preprint arXiv:1802.08908 (2018).Google Scholar"",""Xue Bin Peng, Angjoo Kanazawa, Sam Toyer, Pieter Abbeel, and Sergey Levine. 2018. Variational discriminator bottleneck: Improving imitation learning, inverse rl, and gans by constraining information flow. arXiv preprint arXiv:1810.00821 (2018).Google Scholar"",""Francesco Pittaluga, Sanjeev Koppal, and Ayan Chakrabarti. 2019. Learning privacy preserving encodings through adversarial training. In 2019 IEEE Winter Conference on Applications of Computer Vision (WACV). IEEE, 791--799.Google Scholar"",""Zhan Qin, Yin Yang, Ting Yu, Issa Khalil, Xiaokui Xiao, and Kui Ren. 2016. Heavy hitter estimation over set-valued data with local differential privacy. In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security. 192--203.Google Scholar"",""Adam Smith, Abhradeep Thakurta, and Jalaj Upadhyay. 2017. Is interaction necessary for distributed private learning?. In 2017 IEEE Symposium on Security and Privacy (SP). IEEE, 58--77.Google Scholar"",""Jiaming Song, Pratyusha Kalluri, Aditya Grover, Shengjia Zhao, and Stefano Ermon. 2018. Learning controllable fair representations. arXiv preprint arXiv:1812.04218 (2018).Google Scholar"",""Latanya Sweeney. 2002. k-anonymity: A model for protecting privacy. International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, Vol. 10, 05 (2002), 557--570.Google Scholar"",""Stacey Truex, Nathalie Baracaldo, Ali Anwar, Thomas Steinke, Heiko Ludwig, Rui Zhang, and Yi Zhou. 2019. A hybrid approach to privacy-preserving federated learning. In Proceedings of the 12th ACM Workshop on Artificial Intelligence and Security. 1--11.Google Scholar"",""Tianhao Wang, Jeremiah Blocki, Ninghui Li, and Somesh Jha. 2017. Locally differentially private protocols for frequency estimation. In 26th $$USENIX$$ Security Symposium ($$USENIX$$ Security 17). 729--745.Google Scholar"",""Thomas Winkler, Adám Erdélyi, and Bernhard Rinner. 2014. TrustEYE. M4: protecting the sensor-not the camera. In 2014 11th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS). IEEE, 159--164.Google Scholar"",""Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. 2016. Google's neural machine translation system: Bridging the gap between human and machine translation. arXiv preprint arXiv:1609.08144 (2016).Google Scholar"",""Zhenyu Wu, Zhangyang Wang, Zhaowen Wang, and Hailin Jin. 2018. Towards privacy-preserving visual recognition via adversarial training: A pilot study. In Proceedings of the European Conference on Computer Vision (ECCV). 606--624.Google Scholar"",""Ryo Yonetani, Vishnu Naresh Boddeti, Kris M Kitani, and Yoichi Sato. 2017. Privacy-preserving visual learning using doubly permuted homomorphic encryption. In Proceedings of the IEEE International Conference on Computer Vision. 2040--2050.Google Scholar""]"
https://doi.org/10.1145/3394486.3403126,AutoGrow: Automatic Layer Growing in Deep Convolutional Networks,"Depth is a key component of Deep Neural Networks (DNNs), however, designing depth is heuristic and requires many human efforts. We proposeAutoGrow to automate depth discovery in DNNs: starting from a shallow seed architecture,AutoGrow grows new layers if the growth improves the accuracy; otherwise, stops growing and thus discovers the depth. We propose robust growing and stopping policies to generalize to different network architectures and datasets. Our experiments show that by applying the same policy to different network architectures,AutoGrow can always discover near-optimal depth on various datasets of MNIST, FashionMNIST, SVHN, CIFAR10, CIFAR100 and ImageNet. For example, in terms of accuracy-computation trade-off,AutoGrow discovers a better depth combination in \resnets than human experts. OurAutoGrow is efficient. It discovers depth within similar time of training a single DNN. Our code is available at \urlhttps://github.com/wenwei202/autogrow.","[{""name"":""Wei Wen"",""id"":""/profile/99658716589""},{""name"":""Feng Yan"",""id"":""/profile/81490667438""},{""name"":""Yiran Chen"",""id"":""/profile/81502777312""},{""name"":""Hai Li"",""id"":""/profile/81558286956""},{""name"":""Wei Wen"",""id"":""/profile/99658716589""},{""name"":""Feng Yan"",""id"":""/profile/81490667438""},{""name"":""Yiran Chen"",""id"":""/profile/81502777312""},{""name"":""Hai Li"",""id"":""/profile/81558286956""}]","[""Peter J Angeline, Gregory M Saunders, and Jordan B Pollack. 1994. An evolutionary algorithm that constructs recurrent neural networks. IEEE transactions on Neural Networks , Vol. 5, 1 (1994), 54--65.Google Scholar"",""Gabriel Bender, Pieter-Jan Kindermans, Barret Zoph, Vijay Vasudevan, and Quoc Le. 2018. Understanding and simplifying one-shot architecture search. In International Conference on Machine Learning. 549--558.Google Scholar"",""Han Cai, Tianyao Chen, Weinan Zhang, Yong Yu, and Jun Wang. 2018a. Efficient architecture search by network transformation. In Thirty-Second AAAI Conference on Artificial Intelligence .Google Scholar"",""Han Cai, Jiacheng Yang, Weinan Zhang, Song Han, and Yong Yu. 2018b. Path-level network transformation for efficient architecture search. arXiv preprint arXiv:1806.02639 (2018).Google Scholar"",""Tianqi Chen, Ian Goodfellow, and Jonathon Shlens. 2015. Net2net: Accelerating learning via knowledge transfer. arXiv preprint arXiv:1511.05641 (2015).Google Scholar"",""Corinna Cortes, Xavier Gonzalvo, Vitaly Kuznetsov, Mehryar Mohri, and Scott Yang. 2017. Adanet: Adaptive structural learning of artificial neural networks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 874--883.Google Scholar"",""Xiaoliang Dai, Hongxu Yin, and Niraj K Jha. 2017. NeST: A neural network synthesis tool based on a grow-and-prune paradigm. arXiv:1711.02017 (2017).Google Scholar"",""Xiaocong Du, Zheng Li, and Yu Cao. 2019. CGaP: Continuous Growth and Pruning for Efficient Deep Learning. arXiv preprint arXiv:1905.11533 (2019).Google Scholar"",""Thomas Elsken, Jan-Hendrik Metzen, and Frank Hutter. 2017. Simple and Efficient Architecture Search for CNNs. In Workshop on Meta-Learning (MetaLearn 2017) at NIPS .Google Scholar"",""Jiashi Feng and Trevor Darrell. 2015. Learning the structure of deep convolutional networks. In Proceedings of the IEEE international conference on computer vision. 2749--2757.Google ScholarDigital Library"",""Ariel Gordon, Elad Eban, Ofir Nachum, Bo Chen, Hao Wu, Tien-Ju Yang, and Edward Choi. 2018. Morphnet: Fast \u0026 simple resource-constrained structure learning of deep networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 1586--1595.Google ScholarCross Ref"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition. 770--778.Google ScholarCross Ref"",""Yihui He, Xiangyu Zhang, and Jian Sun. 2017. Channel pruning for accelerating very deep neural networks. In Proceedings of the IEEE International Conference on Computer Vision. 1389--1397.Google ScholarCross Ref"",""Gao Huang, Shichen Liu, Laurens Van der Maaten, and Kilian Q Weinberger. 2018. Condensenet: An efficient densenet using learned group convolutions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . 2752--2761.Google ScholarCross Ref"",""Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. 2017. Densely connected convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern recognition. 4700--4708.Google ScholarCross Ref"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems. 1097--1105.Google Scholar"",""Vadim Lebedev and Victor Lempitsky. 2016. Fast convnets using group-wise brain damage. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2554--2564.Google ScholarCross Ref"",""Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans Peter Graf. 2016. Pruning filters for efficient convnets. arXiv preprint arXiv:1608.08710 (2016).Google Scholar"",""Hao Li, Zheng Xu, Gavin Taylor, Christoph Studer, and Tom Goldstein. 2018. Visualizing the loss landscape of neural nets. In Advances in Neural Information Processing Systems. 6391--6401.Google Scholar"",""Chenxi Liu, Barret Zoph, Maxim Neumann, Jonathon Shlens, Wei Hua, Li-Jia Li, Li Fei-Fei, Alan Yuille, Jonathan Huang, and Kevin Murphy. 2018b. Progressive neural architecture search. In Proceedings of the European Conference on Computer Vision (ECCV). 19--34.Google ScholarCross Ref"",""Hanxiao Liu, Karen Simonyan, Oriol Vinyals, Chrisantha Fernando, and Koray Kavukcuoglu. 2017b. Hierarchical representations for efficient architecture search. arXiv preprint arXiv:1711.00436 (2017).Google Scholar"",""Hanxiao Liu, Karen Simonyan, and Yiming Yang. 2018a. Darts: Differentiable architecture search. arXiv preprint arXiv:1806.09055 (2018).Google Scholar"",""Zhuang Liu, Jianguo Li, Zhiqiang Shen, Gao Huang, Shoumeng Yan, and Changshui Zhang. 2017a. Learning efficient convolutional networks through network slimming. In Proceedings of the IEEE International Conference on Computer Vision. 2736--2744.Google ScholarCross Ref"",""Jian-Hao Luo, Jianxin Wu, and Weiyao Lin. 2017. Thinet: A filter level pruning method for deep neural network compression. In Proceedings of the IEEE international conference on computer vision . 5058--5066.Google ScholarCross Ref"",""Risto Miikkulainen, Jason Liang, Elliot Meyerson, Aditya Rawal, Daniel Fink, Olivier Francon, Bala Raju, Hormoz Shahrzad, Arshak Navruzyan, Nigel Duffy, et almbox. 2019. Evolving deep neural networks. In Artificial Intelligence in the Age of Neural Networks and Brain Computing. Elsevier, 293--312.Google Scholar"",""Jongsoo Park, Sheng Li, Wei Wen, Ping Tak Peter Tang, Hai Li, Yiran Chen, and Pradeep Dubey. 2017. Faster cnns with direct sparse convolutions and guided pruning. In International Conference on Learning Representations (ICLR) .Google Scholar"",""Hieu Pham, Melody Y Guan, Barret Zoph, Quoc V Le, and Jeff Dean. 2018. Efficient neural architecture search via parameter sharing. arXiv preprint arXiv:1802.03268 (2018).Google Scholar"",""George Philipp and Jaime G Carbonell. 2017. Nonparametric neural networks. arXiv preprint arXiv:1712.05440 (2017).Google Scholar"",""Esteban Real, Sherry Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon Suematsu, Jie Tan, Quoc V Le, and Alexey Kurakin. 2017. Large-scale evolution of image classifiers. In Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 2902--2911.Google ScholarDigital Library"",""Shreyas Saxena and Jakob Verbeek. 2016. Convolutional neural fabrics. In Advances in Neural Information Processing Systems. 4053--4061.Google Scholar"",""Karen Simonyan and Andrew Zisserman. 2014. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556 (2014).Google Scholar"",""Leslie N Smith, Emily M Hand, and Timothy Doster. 2016. Gradual dropin of layers to train very deep neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 4763--4771.Google ScholarCross Ref"",""Kenneth O Stanley and Risto Miikkulainen. 2002. Evolving neural networks through augmenting topologies. Evolutionary computation , Vol. 10, 2 (2002), 99--127.Google Scholar"",""Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. 2015. Going deeper with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition. 1--9.Google ScholarCross Ref"",""Tao Wei, Changhu Wang, and Chang Wen Chen. 2017. Modularized morphing of neural networks. arXiv preprint arXiv:1701.03281 (2017).Google Scholar"",""Tao Wei, Changhu Wang, Yong Rui, and Chang Wen Chen. 2016. Network morphism. In International Conference on Machine Learning . 564--572.Google Scholar"",""Wei Wen, Yuxiong He, Samyam Rajbhandari, Minjia Zhang, Wenhan Wang, Fang Liu, Bin Hu, Yiran Chen, and Hai Li. 2018. Learning intrinsic sparse structures within long short-term memory. In International Conference on Learning Representations (ICLR) .Google Scholar"",""Wei Wen, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li. 2016. Learning structured sparsity in deep neural networks. In Advances in neural information processing systems. 2074--2082.Google Scholar"",""Huanrui Yang, Wei Wen, and Hai Li. 2020. DeepHoyer: Learning Sparser Neural Network with Differentiable Scale-Invariant Sparsity Measures. In International Conference on Learning Representations (ICLR) .Google Scholar"",""Jaehong Yoon, Eunho Yang, Jeongtae Lee, and Sung Ju Hwang. 2017. Lifelong learning with dynamically expandable networks. arXiv preprint arXiv:1708.01547 (2017).Google Scholar"",""Barret Zoph and Quoc V Le. 2016. Neural architecture search with reinforcement learning. arXiv preprint arXiv:1611.01578 (2016).Google Scholar"",""Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V Le. 2018. Learning transferable architectures for scalable image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition . 8697--8710.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403127,Curb-GAN: Conditional Urban Traffic Estimation through Spatio-Temporal Generative Adversarial Networks,"Given an urban development plan and the historical traffic observations over the road network, the Conditional Urban Traffic Estimation problem aims to estimate the resulting traffic status prior to the deployment of the plan. This problem is of great importance to urban development and transportation management, yet is very challenging because the plan would change the local travel demands drastically and the new travel demand pattern might be unprecedented in the historical data. To tackle these challenges, we propose a novel Conditional Urban Traffic Generative Adversarial Network (Curb-GAN), which provides traffic estimations in consecutive time slots based on different (unprecedented) travel demands, thus enables urban planners to accurately evaluate urban plans before deploying them. The proposed Curb-GAN adopts and advances the conditional GAN structure through a few novel ideas: (1) dealing with various travel demands as the ""conditions"" and generating corresponding traffic estimations, (2) integrating dynamic convolutional layers to capture the local spatial auto-correlations along the underlying road networks, (3) employing self-attention mechanism to capture the temporal dependencies of the traffic across different time slots. Extensive experiments on two real-world spatio-temporal datasets demonstrate that our Curb-GAN outperforms major baseline methods in estimation accuracy under various conditions and can produce more meaningful estimations.","[{""name"":""Yingxue Zhang"",""id"":""/profile/99659575115""},{""name"":""Yanhua Li"",""id"":""/profile/81548016057""},{""name"":""Xun Zhou"",""id"":""/profile/81488657016""},{""name"":""Xiangnan Kong"",""id"":""/profile/81466643630""},{""name"":""Jun Luo"",""id"":""/profile/99659232654""},{""name"":""Yingxue Zhang"",""id"":""/profile/99659575115""},{""name"":""Yanhua Li"",""id"":""/profile/81548016057""},{""name"":""Xun Zhou"",""id"":""/profile/81488657016""},{""name"":""Xiangnan Kong"",""id"":""/profile/81466643630""},{""name"":""Jun Luo"",""id"":""/profile/99659232654""}]","[""2020. Curb-GAN. https://github.com/Curb-GAN/Curb-GAN. [Online].Google Scholar"",""Dina Al-Shibeeb. 2019. Vaughan council rejects Sports Village expansion after 4-year debate. YorkRegion.Google Scholar"",""Pablo Samuel Castro, Daqing Zhang, and Shijian Li. 2012. Urban Traffic Modelling and Prediction Using Large Scale Taxi GPS Traces. In Pervasive .Google Scholar"",""Junyoung Chung, cC aglar Gü lcc ehre, KyungHyun Cho, and Yoshua Bengio. 2014. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling. CoRR (2014).Google Scholar"",""Zhiyong Cui, Ruimin Ke, and YinhaiWang. 2017. Deep Stacked Bidirectional and Unidirectional LSTM Recurrent Neural Network for Network-wide Traffic Speed Prediction. In 6th International Workshop on Urban Computing .Google Scholar"",""Jeff Donahue, Lisa Anne Hendricks, Sergio Guadarrama, Marcus Rohrbach, Subhashini Venugopalan, Kate Saenko, and Trevor Darrell. 2014. Long-term Recurrent Convolutional Networks for Visual Recognition and Description. CoRR (2014).Google Scholar"",""Zipei Fan, Xuan Song, Ryosuke Shibasaki, and Ryutaro Adachi. 2015. CityMomentum: An Online Approach for Crowd Behavior Prediction at a Citywide Level. In ACM UbiComp .Google Scholar"",""Arthur Getis. 2008. A History of the Concept of Spatial Autocorrelation: A Geographer's Perspective. Geographical Analysis, Vol. 40 (2008).Google ScholarCross Ref"",""Eric J. Gonzales, Ci (Jesse) Yang, Ender Faruk Morgul, and Kaan Ozbay. 2014. Modeling Taxi Demand with GPS Data from Taxis and Transit. Technical Report. Mineta National Transit Research Consortium.Google Scholar"",""Jan Hauke and Tomasz Kossowski. 2011. Comparison of Values of Pearson's and Spearman's Correlation Coefficients on the Same Sets of Data. Quaestiones Geographicae (2011).Google Scholar"",""Ryan Herring, Aude Hofleitner, Pieter Abbeel, and Alexandre M. Bayen. 2010. Estimating arterial traffic conditions using sparse probe data. In ITSC .Google Scholar"",""Chao Huang, Junbo Zhang, Yu Zheng, and Nitesh V Chawla. 2018. DeepCrime: Attentive Hierarchical Recurrent Networks for Crime Prediction. In CIKM .Google Scholar"",""Benhamza Karima, Salah Ellagoune, Hamid Seridi, and Herman Akdag. 2019. Agent-based modeling for traffic simulation. (June 2019).Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2015. Adam: A method for stochastic optimization. In ICLR .Google Scholar"",""Yexin Li, Yu Zheng, and Qiang Yang. 2018. Dynamic Bike Reposition: A Spatio-Temporal Reinforcement Learning Approach. In KDD .Google Scholar"",""Xinyue Liu, Xiangnan Kong, and Yanhua Li. 2016. Collective traffic prediction with partially observed traffic history using location-base social media. In CIKM .Google Scholar"",""Yisheng Lv, Yanjie Duan, Wenwen Kang, Zhengxi Li, Fei-Yue Wang, et al. 2015. Traffic flow prediction with big data: A deep learning approach. IEEE Transactions on Intelligent Transportation Systems (2015).Google Scholar"",""Mehdi Mirza and Simon Osindero. 2014. Conditional generative adversarial nets. In CoRR abs/1411.1784 .Google Scholar"",""Olof Mogren. 2016. C-RNN-GAN: Continuous recurrent neural networks with adversarial training. CoRR (2016).Google Scholar"",""Naoto Mukai and Naoto Yoden. 2012. Taxi Demand Forecasting Based on Taxi Probe Data by Neural Network. In IIMSS .Google Scholar"",""Xingjian Shi, Zhourong Chen, Hao Wang, Dit-Yan Yeung, Wai-Kin Wong, and Wang chun Woo. 2015. Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting. Advances in neural information processing systems (2015).Google Scholar"",""Xuan Song, Quanshi Zhang, Yoshihide Sekimoto, and Ryosuke Shibasaki. 2014. Prediction of Human Emergency Behavior and Their Mobility Following Large-Scale Disaster. In SIGKDD .Google Scholar"",""John Taplin. 2008. Simulation models of traffic flow. (2008).Google Scholar"",""Waldo R Tobler. 1970. A computer movie simulating urban growth in the Detroit region. Economic geography (1970).Google Scholar"",""Ermal Toto, Elke A. Rundensteiner, Yanhua Li, Richard Jordan, Mariya Ishutkina, Kajal Claypool, Jun Luo, and Fan Zhang. 2016. PULSE: A Real Time System for Crowd Flow Prediction at Metropolitan Subway Stations. In ECMLPKDD .Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention Is All You Need. CoRR (2017).Google Scholar"",""Dong Wang, Junbo Zhang, Wei Cao, Jian Li, and Yu Zheng. 2018. When Will You Arrive? Estimating Travel Time Based on Deep Neural Networks. In AAAI .Google Scholar"",""Yunbo Wang, Mingsheng Long, Jianmin Wang, Zhifeng Gao, and Philip S. Yu. 2017. PredRNN: Recurrent Neural Networks for Predictive Learning using Spatiotemporal LSTMs. In NIPS .Google Scholar"",""Huaxiu Yao, Fei Wu, Jintao ke, Xianfeng Tang, Yitian Jia, Siyu Lu, Pinghua Gong, and Jieping Ye. 2018. Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction. (2018).Google Scholar"",""Adams Wei Yu, David Dohan, Minh-Thang Luong, Rui Zhao, Kai Chen, Mohammad Norouzi, and Quoc V. Le. 2018. QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. CoRR (2018).Google Scholar"",""Haiyang Yu, Zhihai Wu, Shuqin Wang, Yunpeng Wang, and Xiaolei Ma. 2017. Spatiotemporal recurrent convolutional networks for traffic prediction in transportation networks. Sensors (2017).Google Scholar"",""Jing Yuan, Yu Zheng, Xing Xie, and Guangzhong Sun. 2011. Driving with knowledge from the physical world. In KDD .Google Scholar"",""Jing Yuan, Yu Zheng, Chengyang Zhang, Wenlei Xie, Xing Xie, Guangzhong Sun, and Yan Huang. 2010. T-drive: driving directions based on taxi trajectories. In GIS .Google Scholar"",""Zhuoning Yuan, Xun Zhou, and Tianbao Yang. 2018. Hetero-ConvLSTM: A Deep Learning Approach to Traffic Accident Prediction on Heterogeneous Spatio-Temporal Data.Google Scholar"",""Xianyuan Zhan, Yu Zheng, Xiuwen Yi, and Satish Ukkusuri. 2017. Citywide Traffic Volume Estimation Using Trajectory Data. TKDE (2017).Google Scholar"",""Junbo Zhang, Yu Zheng, and Dekang Qi. 2016. Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction. CoRR (2016).Google Scholar"",""Yingxue Zhang, Yanhua Li, Xun Zhou, Xiangnan Kong, and Jun Luo. 2019. TrafficGAN: Off-Deployment Traffic Estimation with Traffic Generative Adversarial Networks. In ICDM .Google Scholar"",""Jiachen Zhao, Fang Deng, Yeyun Cai, and Jie Chen. 2019. Long short-term memory - Fully connected (LSTM-FC) neural network for PM2.5 concentration prediction. Chemosphere (2019).Google Scholar"",""Yu Zheng, Licia Capra, Ouri Wolfson, and Hai Yang. 2014. Urban computing: concepts, methodologies, and applications. TIST (2014).Google Scholar"",""Ali Zonoozi, Jung jae Kim, Xiao-Li Li, and Gao Cong. 2018. Convolutional Recurrent Model for Crowd Density Prediction with Recurring Periodic Patterns. In IJCAI .Google Scholar""]"
https://doi.org/10.1145/3394486.3403128,Incremental Mobile User Profiling: Reinforcement Learning with Spatial Knowledge Graph for Modeling Event Streams,"We study the integration of reinforcement learning and spatial knowledge graph for incremental mobile user profiling, which aims to map mobile users to dynamically-updated profile vectors by incremental learning from a mixed-user event stream. After exploring many profiling methods, we identify a new imitation based criteria to better evaluate and optimize profiling accuracy. Considering the objective of teaching an autonomous agent to imitate a mobile user to plan next-visit based on the user's profile, the user profile is the most accurate when the agent can perfectly mimic the activity patterns of the user. We propose to formulate the problem into a reinforcement learning task, where an agent is a next-visit planner, an action is a POI that a user will visit next, and the state of environment is a fused representation of a user and spatial entities (e.g., POIs, activity types, functional zones). An event that a user takes an action to visit a POI, will change the environment, resulting into a new state of user profiles and spatial entities, which helps the agent to predict next visit more accurately. After analyzing such interactions among events, users, and spatial entities, we identify (1)semantic connectivity among spatial entities, and, thus, introduce a spatial Knowledge Graph (KG) to characterize the semantics of user visits over connected locations, activities, and zones. Besides, we identify (2) mutual influence between users and the spatial KG, and, thus, develop a mutual-updating strategy between users and the spatial KG, mixed with temporal context, to quantify the state representation that evolves over time. Along these lines, we develop a reinforcement learning framework integrated with spatial KG. The proposed framework can achieve incremental learning in multi-user profiling given a mixed-user event stream. Finally, we apply our approach to human mobility activity prediction and present extensive experiments to demonstrate improved performances.","[{""name"":""Pengyang Wang"",""id"":""/profile/99659288023""},{""name"":""Kunpeng Liu"",""id"":""/profile/99659454174""},{""name"":""Lu Jiang"",""id"":""/profile/99659575063""},{""name"":""Xiaolin Li"",""id"":""/profile/81323492622""},{""name"":""Yanjie Fu"",""id"":""/profile/82658841557""},{""name"":""Pengyang Wang"",""id"":""/profile/99659288023""},{""name"":""Kunpeng Liu"",""id"":""/profile/99659454174""},{""name"":""Lu Jiang"",""id"":""/profile/99659575063""},{""name"":""Xiaolin Li"",""id"":""/profile/81323492622""},{""name"":""Yanjie Fu"",""id"":""/profile/82658841557""}]","[""Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko. 2013. Translating embeddings for modeling multi-relational data. In Advances in neural information processing systems. 2787--2795.Google Scholar"",""Sungwoon Choi, Heonseok Ha, Uiwon Hwang, Chanju Kim, Jung-Woo Ha, and Sungroh Yoon. 2018. Reinforcement learning based recommender system using biclustering technique. arXiv preprint arXiv:1801.05532 (2018).Google Scholar"",""Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep neural networks for youtube recommendations. In Proceedings of the 10th ACM conference on recommender systems. 191--198.Google ScholarDigital Library"",""Daniela Godoy and Analia Amandi. 2005. User profiling in personal information agents: a survey. The Knowledge Engineering Review, Vol. 20, 4 (2005), 329--361.Google ScholarDigital Library"",""Jean-Benoit Griesner, Talel Abdessalem, and Hubert Naacke. 2015. POI recommendation: Towards fused matrix factorization with geographical and temporal influences. In Proceedings of the 9th ACM Conference on Recommender Systems. 301--304.Google Scholar"",""Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2015. Session-based recommendations with recurrent neural networks. arXiv preprint arXiv:1511.06939 (2015).Google Scholar"",""Guoliang Ji, Shizhu He, Liheng Xu, Kang Liu, and Jun Zhao. 2015. Knowledge graph embedding via dynamic mapping matrix. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 687--696.Google ScholarCross Ref"",""Maciej Kula. 2017. Spotlight. https://github.com/maciejkula/spotlight.Google Scholar"",""Defu Lian, Cong Zhao, Xing Xie, Guangzhong Sun, Enhong Chen, and Yong Rui. 2014. GeoMF: joint geographical modeling and matrix factorization for point-of-interest recommendation. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. 831--840.Google ScholarDigital Library"",""Long-Ji Lin. 1993. Reinforcement learning for robots using neural networks. Technical Report. Carnegie-Mellon Univ Pittsburgh PA School of Computer Science.Google ScholarDigital Library"",""Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu. 2015. Learning entity and relation embeddings for knowledge graph completion. In Twenty-ninth AAAI conference on artificial intelligence.Google ScholarDigital Library"",""Kunpeng Liu, Pengyang Wang, Jiawei Zhang, Yanjie Fu, and Sajal K Das. 2018. Modeling the Interaction Coupling of Multi-View Spatiotemporal Contexts for Destination Prediction. In Proceedings of the 2018 SIAM International Conference on Data Mining. SIAM, 171--179.Google ScholarCross Ref"",""Andriy Mnih and Russ R Salakhutdinov. 2008. Probabilistic matrix factorization. In Advances in neural information processing systems. 1257--1264.Google Scholar"",""Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin Riedmiller. 2013. Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602 (2013).Google Scholar"",""Isshu Munemasa, Yuta Tomomatsu, Kunioki Hayashi, and Tomohiro Takagi. 2018. Deep reinforcement learning for recommender systems. In 2018 international conference on information and communications technology (icoiact). IEEE, 226--233.Google ScholarCross Ref"",""Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. 2016. Wavenet: A generative model for raw audio. arXiv preprint arXiv:1609.03499 (2016).Google Scholar"",""Pengyang Wang, Yanjie Fu, Hui Xiong, and Xiaolin Li. 2019. Adversarial Substructured Representation Learning for Mobile User Profiling. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 130--138.Google ScholarDigital Library"",""Pengyang Wang, Yanjie Fu, Yuanchun Zhou, Kunpeng Liu, Xiaolin Li, and Kien Hua. 2020. Exploiting Mutual Information for Substructure-aware Graph Representation Learning. In Proceedings of the 29th International Joint Conference on Artificial Intelligence. AAAI Press.Google ScholarCross Ref"",""Pengyang Wang, Jiawei Zhang, Guannan Liu, Yanjie Fu, and Charu Aggarwal. 2018. Ensemble-Spotting: Ranking Urban Vibrancy via POI Embedding with Multi-view Spatial Graphs. In Proceedings of the 2018 SIAM International Conference on Data Mining. SIAM, 351--359.Google ScholarCross Ref"",""Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. 2014. Knowledge graph embedding by translating on hyperplanes. In Twenty-Eighth AAAI conference on artificial intelligence.Google ScholarDigital Library"",""Carl Yang, Lanxiao Bai, Chao Zhang, Quan Yuan, and Jiawei Han. 2017. Bridging collaborative filtering and semi-supervised learning: a neural approach for poi recommendation. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 1245--1254.Google ScholarDigital Library"",""Dingqi Yang, Daqing Zhang, Vincent W Zheng, and Zhiyong Yu. 2014. Modeling user activity preference by leveraging user spatial temporal characteristics in LBSNs. IEEE Transactions on Systems, Man, and Cybernetics: Systems, Vol. 45, 1 (2014), 129--142.Google ScholarCross Ref"",""Hongzhi Yin, Weiqing Wang, Hao Wang, Ling Chen, and Xiaofang Zhou. 2017. Spatial-aware hierarchical collaborative deep learning for POI recommendation. IEEE Transactions on Knowledge and Data Engineering, Vol. 29, 11 (2017), 2537--2551.Google ScholarCross Ref"",""Shuai Zhang, Lina Yao, Aixin Sun, and Yi Tay. 2019. Deep learning based recommender system: A survey and new perspectives. ACM Computing Surveys (CSUR), Vol. 52, 1 (2019), 1--38.Google ScholarDigital Library"",""Xiangyu Zhao, Liang Zhang, Zhuoye Ding, Long Xia, Jiliang Tang, and Dawei Yin. 2018. Recommendations with negative feedback via pairwise deep reinforcement learning. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1040--1048.Google ScholarDigital Library"",""Guanjie Zheng, Fuzheng Zhang, Zihan Zheng, Yang Xiang, Nicholas Jing Yuan, Xing Xie, and Zhenhui Li. 2018. DRN: A deep reinforcement learning framework for news recommendation. In Proceedings of the 2018 World Wide Web Conference. 167--176.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403129,Identifying Sepsis Subphenotypes via Time-Aware Multi-Modal Auto-Encoder,"Sepsis is a heterogeneous clinical syndrome that is the leading cause of mortality in hospital intensive care units (ICUs). Identification of sepsis subphenotypes may allow for more precise treatments and lead to more targeted clinical interventions. Recently, sepsis subtyping on electronic health records (EHRs) has attracted interest from healthcare researchers. However, most sepsis subtyping studies ignore the temporality of EHR data and suffer from missing values. In this paper, we propose a new sepsis subtyping framework to address the two issues. Our subtyping framework consists of a novel Time-Aware Multi-modal auto-Encoder (TAME) model which introduces time-aware attention mechanism and incorporates multi-modal inputs (e.g., demographics, diagnoses, medications, lab tests and vital signs) to impute missing values, a dynamic time wrapping (DTW) method to measure patients' temporal similarity based on the imputed EHR data, and a weighted k-means algorithm to cluster patients. Comprehensive experiments on real-world datasets show TAME outperforms the baselines on imputation accuracy. After analyzing TAME-imputed EHR data, we identify four novel subphenotypes of sepsis patients, paving the way for improved personalization of sepsis management.","[{""name"":""Changchang Yin"",""id"":""/profile/99659573244""},{""name"":""Ruoqi Liu"",""id"":""/profile/99659573967""},{""name"":""Dongdong Zhang"",""id"":""/profile/99659574322""},{""name"":""Ping Zhang"",""id"":""/profile/99659573698""},{""name"":""Changchang Yin"",""id"":""/profile/99659573244""},{""name"":""Ruoqi Liu"",""id"":""/profile/99659573967""},{""name"":""Dongdong Zhang"",""id"":""/profile/99659574322""},{""name"":""Ping Zhang"",""id"":""/profile/99659573698""}]","[""Edgar Acuna and Caroline Rodriguez. 2004. The treatment of missing values and its effect on classifier accuracy. In Classification, clustering, and data mining applications. Springer, 639--647.Google Scholar"",""Inci M. Baytas, Cao Xiao, et al. 2017. Patient Subtyping via Time-Aware LSTM Networks. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Halifax, Canada, 2017. 65--74.Google ScholarDigital Library"",""S van Buuren and Karin Groothuis-Oudshoorn. 2010. mice: Multivariate imputation by chained equations in R. Journal of statistical software (2010), 1--68.Google Scholar"",""Tadeusz Cali'ski and Jerzy Harabasz. 1974. A dendrite method for cluster analysis. Communications in Statistics-theory and Methods 3, 1 (1974), 1--27.Google ScholarCross Ref"",""Wei Cao, Dong Wang, Jian Li, et al. 2018. BRITS: Bidirectional Recurrent Imputation for Time Series. CoRR abs/1805.10572 (2018). arXiv:1805.10572Google Scholar"",""David L Davies and DonaldWBouldin. 1979. A cluster separation measure. IEEE transactions on pattern analysis and machine intelligence 2 (1979), 224--227.Google Scholar"",""Tomoaki Hori, David Montcho, Clement Agbangla, et al. 2016. Multi-task Gaussian process for imputing missing data in multi-trait and multi-environment trials. Theoretical and Applied Genetics 129, 11 (2016), 2101--2115.Google ScholarCross Ref"",""Zina Ibrahim, Honghan Wu, Ahmed Hamoud, et al. 2019. On Classifying Sepsis Heterogeneity in the ICU: Insight Using Machine Learning. arXiv preprint arXiv:1912.00672 (2019).Google Scholar"",""Alistair E.W. Johnson, Tom J. Pollard, Lu Shen, et al. 2016. MIMIC-III, a freely accessible critical care database. (2016).Google Scholar"",""Guolin Ke, Qi Meng, Thomas Finley, et al. 2017. Lightgbm: A highly efficient gradient boosting decision tree. In Advances in neural information processing systems. 3146--3154.Google ScholarDigital Library"",""Vincent Liu, Gabriel J. Escobar, John D. Greene, et al. 2014. Hospital Deaths in Patients With Sepsis From 2 Independent Cohorts. JAMA 312, 1 (07 2014), 90--92.Google Scholar"",""Yuan Luo, Peter Szolovits, Anand Dighe, and Jason Baron. 2018. 3D-MICE: integration of cross-sectional and longitudinal imputation for multi-analyte longitudinal clinical data. JAMIA 25, 6 (2018), 645--653.Google Scholar"",""Meinard Müller. 2007. Dynamic time warping. Information retrieval for music and motion (2007), 69--84.Google Scholar"",""ChristopherWSeymour, Jason N Kennedy, ShuWang, Chang, et al. 2019. Derivation, validation, and potential treatment implications of novel clinical phenotypes for sepsis. Jama 321, 20 (2019), 2003--2017.Google ScholarCross Ref"",""Mervyn Singer, Clifford S Deutschman, Christopher Warren Seymour, et al. 2016. The third international consensus definitions for sepsis and septic shock (Sepsis- . Jama 315, 8 (2016), 801--810.Google Scholar"",""William E. Strawderman. 1989. Statistical Analysis with Missing Data (Roderick J. A. Little and Donald B. Rubin). SIAM Rev. 31, 2 (1989), 348--349.Google ScholarCross Ref"",""Qiuling Suo, Liuyi Yao, Guangxu Xun, et al. 2019. Recurrent Imputation for Multivariate Time Series with Missing Values. In 2019 IEEE International Conference on Healthcare Informatics, ICHI 2019, Xi'an, China, June 10--13, 2019. 1--3.Google Scholar"",""J-L Vincent, Rui Moreno, Jukka Takala, et al. 1996. The SOFA (Sepsis-related Organ Failure Assessment) score to describe organ dysfunction/failure.Google Scholar"",""Xiao Xu, Junmei Wang, Xian Xu, et al. 2019. Estimating Missing Values in Multivariate-Time-Series Clinical Data using Gradient Boosting Tree on Temporal and Cross-variable Features. In 2019 IEEE International Conference on Healthcare Informatics, ICHI 2019, Xi'an, China, June 10--13, 2019. 1--3.Google ScholarCross Ref"",""Zhenxing Xu, Jingyuan Chou, et al. 2019. Identifying Sub-Phenotypes of Acute Kidney Injury using Structured and Unstructured Electronic Health Record Data with Memory Networks. arXiv preprint arXiv:1904.04990 (2019).Google Scholar"",""Chao Yan, Cheng Gao, Xinmeng Zhang, et al. 2019. Deep Imputation of Temporal Data. In 2019 IEEE International Conference on Healthcare Informatics, ICHI 2019, Xi'an, China, June 10--13, 2019. 1--3.Google Scholar"",""Kejing Yin and William K. Cheung. 2019. Context-Aware Imputation for Clinical Time Series. In 2019 IEEE International Conference on Healthcare Informatics, ICHI 2019, Xi'an, China, June 10--13, 2019. 1--3.Google Scholar"",""Xi Zhang, Jingyuan Chou, Jian Liang, et al. 2019. Data-driven subtyping of Parkinson's disease using longitudinal clinical records: a cohort study. Scientific reports 9, 1 (2019), 1--12.Google Scholar""]"
https://doi.org/10.1145/3394486.3403130,A Causal Look at Statistical Definitions of Discrimination,"Predictive parity and error rate balance are both widely accepted and adopted criteria for assessing fairness of classifiers. The realization that these equally reasonable criteria can lead to contradictory results has, nonetheless, generated a lot of debate/controversy, and has motivated the development of mathematical results establishing the impossibility of concomitantly satisfying predictive parity and error rate balance. Here, we investigate these fairness criteria from a causality perspective. By taking into consideration the data generation process giving rise to the observed data, as well as, the data generation process giving rise to the predictions, and assuming faithfulness, we prove that when the base rates differ across the protected groups and there is no perfect separation, then a standard classifier cannot achieve exact predictive parity. (Where, by standard classifier we mean a classifier trained in the usual way, without adopting pre-processing, in-processing, or post-processing fairness techniques.) This result holds in general, irrespective of the data generation process giving rise to the observed data. Furthermore, we show that the amount of disparate mistreatment for the positive predictive value metric is proportional to the difference between the base rates. For the error rate balance, as well as, the closely related equalized odds and equality of opportunity criteria, we show that there are, nonetheless, data generation processes that can still satisfy these criteria when the base rates differ by protected group, and we characterize the conditions under which these criteria hold. We illustrate our results using synthetic data, and with the re-analysis of the COMPAS data.","[{""name"":""Elias Chaibub Neto"",""id"":""/profile/99659455516""},{""name"":""Elias Chaibub Neto"",""id"":""/profile/99659455516""}]","[""Julia Angwin, Jeff Larson, Suria Mattu, and Lauren Kirchner. 2016. Machine bias: There's software used across the country to predict future criminals. And it's biased against blacks. ProPublica, May 23, 2016.Google Scholar"",""Yahav Bechavod and Katrina Ligget. 2017. Penalizing unfairness in binary classification. arXiv:1707.00044.Google Scholar"",""Richard Berk, Hoda Heidari, Shahin Jabbari, Michael Kearns, Aaron Roth. 2017. Fairness in criminal justice risk assessment: the state of the art. arXiv:1703.09207.Google Scholar"",""Alexandra Chouldechova. 2017. Fair prediction with disparate impact: A study of bias in recidivism prediction instruments. Big Data, 5(2):153--163.Google ScholarCross Ref"",""Sam Corbett-Davies, Emma Pierson, Avi Feller and Sharad Goel. 2016. A computer program used for bail and sentencing decisions was labeled biased against blacks. Its actually not that clear. Washington Post, October 7, 2016.Google Scholar"",""Joseph L. Fleiss, Alex Tytun and Hans K. Ury. 1980. A simple approximation for calculating sample sizes for comparing independent proportions. Biometrics, 36:343--6.Google ScholarCross Ref"",""Anthony W. Flores, Kristin Bechtel, and Christopher T. Lowenkamp. 2016. False positives, false negatives, and false analyses: A rejoinder to “machine bias: There's software used across the country to predict future criminals. And it's biased against blacks.\"". Technical report, Crime \u0026 Justice Institute, September 2016.Google Scholar"",""Sara Hajian and Josep Domingo-Ferrer. 2013. A methodology for direct and indirect discrimination prevention in data mining. IEEE Transactions on Knowledge and Data Engineering, 25(7):1445--1459.Google ScholarDigital Library"",""Moritz Hardt, Eric Price, and Nathan Srebro. 2016. Equality of opportunity in supervised learning. Advances in Neural Information Processing Systems, 2016. (NIPS 2016), pp. 3315--3323.Google Scholar"",""Nikki Kilbertus et al. 2017. Avoiding discrimination through causal reasoning. Advances in Neural Information Processing Systems, 2017. (NIPS 2017), pp. 656--666.Google Scholar"",""Jon Kleinberg, Sendhil Mullainathan, Manish Raghavan. 2016. Inherent trade-offs in the fair determination of risk scores. arXiv:1609.05807.Google Scholar"",""Matt Kusner, Joshua Loftus, Chris Russell, and Ricardo Silva. 2017. Counterfactual fairness. Advances in Neural Information Processing Systems, 2017. (NIPS 2017).Google Scholar"",""Jeff Larson, Surya Mattu, Lauren Kirchner and Julia Angwin. 2016. How We Analyzed the COMPAS Recidivism Algorithm. ProPublica, May 23, 2016.Google Scholar"",""Razieh Nabi, and Ilya Shpitser. 2018. Fair inference on outcomes. The Thirty-Second AAAI Conference on Artificial Intelligence, 2018 (AAAI-18), pp. 1931--1940.Google Scholar"",""Judea Pearl. 2009. Causality: models, reasoning, and inference. Cambridge University Press New York, NY, 2nd edition.Google Scholar"",""Judea Pearl. 2019. The seven tools of causal inference with reflections on machine learning. Communications of ACM, textbf62, 54--60.Google Scholar"",""Judea Pearl and Dana Mackenzie. 2018. The book of why: the new science of cause and effect. Basic Books, New York, NY.Google Scholar"",""Thomas J. Santner Brian J. Williams, and William I. Notz. 2003. The design and analysis of computer experiments. Springer, New York.Google Scholar"",""Jennifer L. Skeem, Christopher Lowenkamp. 2016. Risk, race, and recidivism: predictive bias and disparate impact. Available at SSRN: https://ssrn.com/abstract=2687339Google Scholar"",""Peter Spirtes, Clark Glymour and Richard Scheines. 2000. Causation, Prediction and Search. MIT Press, Cambridge, MA, 2nd edition.Google Scholar"",""Caroline Uhler, Garvesh Raskutti, Peter Buhlmann, Bin Yu. 2013. Geometry of the faithfulness assumption in causal inference. Annals of Statistics, 41(2):436--463.Google ScholarCross Ref"",""Muhammad B. Zafar, Isabel Valera, Manuel G. Rodriguez, Krishna P. Gummadi Zafar. 2017. Fairness beyond disparate treatment and disparate impact: learning classification without disparate mistreatment. Proceedings of the 26th International World Wide Web Conference (WWW), 2017. pp. 1171--1180.Google ScholarDigital Library"",""Lu Zhang, Yongkai Wu, and Xintao Wu. 2017. A causal framework for discovering and removing direct and indirect discrimination. Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence (IJCAI-17), pp. 3929--3935.Google ScholarCross Ref"",""Junzhe Zhang and Elias Bareinboim. 2018. Fairness in decision-making - the causal explanation formula. Proceedings of the AAAI Conference on Artificial Intelligence (AAAI-18), pp. 2037--2045.Google Scholar"",""Junzhe Zhang and Elias Bareinboim. 2018. Equality of opportunity in classification: a causal approach. Advances in Neural Information Processing Systems, 2018. (NIPS 2018).Google Scholar""]"
https://doi.org/10.1145/3394486.3403131,Targeted Data-driven Regularization for Out-of-Distribution Generalization,"Due to biases introduced by large real-world datasets, deviations of deep learning models from their expected behavior on out-of-distribution test data are worrisome. Especially when data come from imbalanced or heavy-tailed label distributions, or minority groups of a sensitive feature. Classical approaches to address these biases are mostly data- or application-dependent, hence are burdensome to tune. Some meta-learning approaches, on the other hand, aim to learn hyperparameters in the learning process using different objective functions on training and validation data. However, these methods suffer from high computational complexity and are not scalable to large datasets. In this paper, we propose a unified data-driven regularization approach to learn a generalizable model from biased data. The proposed framework, named as targeted data-driven regularization (TDR), is model- and dataset-agnostic, and employs a target dataset that resembles the desired nature of test data in order to guide the learning process in a coupled manner. We cast the problem as a bilevel optimization and propose an efficient stochastic gradient descent based method to solve it. The framework can be utilized to alleviate various types of biases in real-world applications. We empirically show, on both synthetic and real-world datasets, the superior performance of TDR for resolving issues stem from these biases.","[{""name"":""Mohammad Mahdi Kamani"",""id"":""/profile/99659213316""},{""name"":""Sadegh Farhang"",""id"":""/profile/99658725020""},{""name"":""Mehrdad Mahdavi"",""id"":""/profile/81418595722""},{""name"":""James Z. Wang"",""id"":""/profile/81408593631""},{""name"":""Mohammad Mahdi Kamani"",""id"":""/profile/99659213316""},{""name"":""Sadegh Farhang"",""id"":""/profile/99658725020""},{""name"":""Mehrdad Mahdavi"",""id"":""/profile/81418595722""},{""name"":""James Z. Wang"",""id"":""/profile/81408593631""}]","[""Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al. 2016. Tensorflow: A system for large-scale machine learning. In Proc. of the 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16). 265--283.Google Scholar"",""Alekh Agarwal, Alina Beygelzimer, Miroslav Dudík, John Langford, and Hanna Wallach. 2018. A reductions approach to fair classification. arXiv preprint arXiv:1803.02453 (2018).Google Scholar"",""Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W Hoffman, David Pfau, Tom Schaul, Brendan Shillingford, and Nando De Freitas. 2016. Learning to learn by gradient descent by gradient descent. In Advances in Neural Information Processing Systems. 3981--3989.Google Scholar"",""Antreas Antoniou, Amos Storkey, and Harrison Edwards. 2017. Data augmentation generative adversarial networks. arXiv preprint arXiv:1711.04340 (2017).Google Scholar"",""Martin Arjovsky, Léon Bottou, Ishaan Gulrajani, and David Lopez-Paz. 2019. Invariant risk minimization. arXiv preprint arXiv:1907.02893 (2019).Google Scholar"",""Tamer Basar and Geert Jan Olsder. 1999. Dynamic Noncooperative Game Theory. Vol. 23. SIAM.Google Scholar"",""Samy Bengio. 2015. Sharing representations for long tail computer vision problems. In Proc. of the ACM International Conference on Multimodal Interaction. ACM, 1--1.Google ScholarDigital Library"",""Yoshua Bengio, Jérôme Louradour, Ronan Collobert, and Jason Weston. 2009. Curriculum learning. In Proc. of the International Conference on Machine Learning. ACM, 41--48.Google ScholarDigital Library"",""Mateusz Buda, Atsuto Maki, and Maciej A Mazurowski. 2018. A systematic study of the class imbalance problem in convolutional neural networks. Neural Networks 106 (2018), 249--259.Google ScholarCross Ref"",""Flavio Calmon, Dennis Wei, Bhanukiran Vinzamuri, Karthikeyan Natesan Ramamurthy, and Kush R Varshney. 2017. Optimized pre-processing for discrimination prevention. In Advances in Neural Information Processing Systems. 3992--4001.Google Scholar"",""Nitesh V Chawla, Kevin W Bowyer, Lawrence O Hall, and W Philip Kegelmeyer. 2002. SMOTE: synthetic minority over-sampling technique. Journal of Artificial Intelligence Research 16 (2002), 321--357.Google ScholarDigital Library"",""Benoît Colson, Patrice Marcotte, and Gilles Savard. 2007. An overview of bilevel optimization. Annals of Operations Research 153, 1 (2007), 235--256.Google ScholarCross Ref"",""Andrew Cotter, Heinrich Jiang, and Karthik Sridharan. 2019. Two-Player Games for Efficient Non-Convex Constrained Optimization. In Algorithmic Learning Theory. 300--332.Google Scholar"",""Yin Cui, Menglin Jia, Tsung-Yi Lin, Yang Song, and Serge Belongie. 2019. Class- Balanced Loss Based on Effective Number of Samples. In Proc. of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 9260--9269.Google ScholarCross Ref"",""Michele Donini, Luca Oneto, Shai Ben-David, John S Shawe-Taylor, and Massimiliano Pontil. 2018. Empirical risk minimization under fairness constraints. In Advances in Neural Information Processing Systems. 2796--2806.Google Scholar"",""Charles Elkan. 2001. The foundations of cost-sensitive learning. In Proc. of the International Joint Conference on Artificial Intelligence, Vol. 17. Lawrence Erlbaum Associates Ltd, 973--978.Google Scholar"",""Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017. Model-agnostic metalearning for fast adaptation of deep networks. In Proc. of the International Conference on Machine Learning-Volume 70. JMLR. org, 1126--1135.Google ScholarDigital Library"",""Luca Franceschi, Paolo Frasconi, Saverio Salzo, Riccardo Grazzi, and Massimilano Pontil. 2018. Bilevel programming for hyperparameter optimization and metalearning. arXiv preprint arXiv:1806.04910 (2018).Google Scholar"",""Saeed Ghadimi and Mengdi Wang. 2018. Approximation Methods for Bilevel Programming. arXiv preprint arXiv:1802.02246 (2018).Google Scholar"",""Gabriel Goh, Andrew Cotter, Maya Gupta, and Michael P Friedlander. 2016. Satisfying real-world goals with dataset constraints. In Advances in Neural Information Processing Systems. 2415--2423.Google Scholar"",""Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi Sugiyama. 2018. Co-teaching: Robust training of deep neural networks with extremely noisy labels. In Advances in Neural Information Processing Systems. 8535--8545.Google Scholar"",""Moritz Hardt, Eric Price, Nati Srebro, et al. 2016. Equality of opportunity in supervised learning. In Advances in Neural Information Processing Systems. 3315--3323.Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In Proc. of the IEEE Conference on Computer Vision and Pattern Recognition. 770--778.Google ScholarCross Ref"",""Chen Huang, Yining Li, Chen Change Loy, and Xiaoou Tang. 2016. Learning deep representation for imbalanced classification. In Proc. of the IEEE Conference on Computer Vision and Pattern Recognition. 5375--5384.Google ScholarCross Ref"",""Simon Jenni and Paolo Favaro. 2018. Deep bilevel learning. In Proc. of the European Conference on Computer Vision. 618--633.Google ScholarCross Ref"",""Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and Li Fei-Fei. 2018. Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels. In Proc. of the International Conference on Machine Learning. 2309--2318.Google Scholar"",""Herman Kahn and Andy W Marshall. 1953. Methods of reducing sample size in Monte Carlo computations. Journal of the Operations Research Society of America 1, 5 (1953), 263--278.Google ScholarCross Ref"",""Mohammad Mahdi Kamani, Sadegh Farhang, Mehrdad Mahdavi, and James Z Wang. 2019. Targeted meta-learning for critical incident detection in weather data. In Proc. of the International Conference on Machine Learning, Workshop on Climate Change: How Can AI Help.Google Scholar"",""Mohammad Mahdi Kamani, Farshid Farhat, Stephen Wistar, and James Z Wang. 2016. Shape matching using skeleton context for automated bow echo detection. In Proc. of the IEEE International Conference on Big Data. IEEE, 901--908.Google ScholarCross Ref"",""Mohammad Mahdi Kamani, Farshid Farhat, Stephen Wistar, and James Z Wang. 2018. Skeleton matching with applications in severe weather detection. Applied Soft Computing 70 (2018), 1154--1166.Google ScholarCross Ref"",""Mohammad Mahdi Kamani, Farzin Haddadpour, Rana Forsati, and Mehrdad Mahdavi. 2019. Efficient Fair Principal Component Analysis. arXiv preprint arXiv:1911.04931 (2019).Google Scholar"",""Faisal Kamiran and Toon Calders. 2012. Data preprocessing techniques for classification without discrimination. Knowledge and Information Systems 33, 1 (2012), 1--33.Google ScholarDigital Library"",""Salman H Khan, Munawar Hayat, Mohammed Bennamoun, Ferdous A Sohel, and Roberto Togneri. 2018. Cost-sensitive learning of deep feature representations from imbalanced data. IEEE Transactions on Neural Networks and Learning Systems 29, 8 (2018), 3573--3587.Google ScholarCross Ref"",""Pang Wei Koh and Percy Liang. 2017. Understanding black-box predictions via influence functions. In Proc. of the International Conference on Machine Learning- Volume 70. JMLR. org, 1885--1894.Google Scholar"",""David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Remi Le Priol, and Aaron Courville. 2020. Out-of-distribution generalization via risk extrapolation (rex). arXiv preprint arXiv:2003.00688 (2020).Google Scholar"",""Yann LeCun, Léon Bottou, Yoshua Bengio, Patrick Haffner, et al. 1998. Gradient-based learning applied to document recognition. Proceedings of the IEEE 86, 11 (1998), 2278--2324.Google ScholarCross Ref"",""Or Litany and Daniel Freedman. 2018. SOSELETO: A Unified Approach to Transfer Learning and Training with Noisy Labels. arXiv preprint arXiv:1805.09622 (2018).Google Scholar"",""Wanli Ouyang, Xiaogang Wang, Cong Zhang, and Xiaokang Yang. 2016. Factors in finetuning deep model for object detection with long-tail distribution. In Proc. of the IEEE Conference on Computer Vision and Pattern Recognition. 864--873.Google ScholarCross Ref"",""Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. 2017. Automatic differentiation in PyTorch. In Proc. of the NIPS Autodiff Workshop: The Future of Gradient-based Machine Learning Software and Techniques.Google Scholar"",""Geoff Pleiss, Manish Raghavan, FelixWu, Jon Kleinberg, and Kilian QWeinberger. 2017. On fairness and calibration. In Advances in Neural Information Processing Systems. 5680--5689.Google Scholar"",""Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urtasun. 2018. Learning to Reweight Examples for Robust Deep Learning. In Proc. of the International Conference on Machine Learning. 4334--4343.Google Scholar"",""Shiv Shankar, Vihari Piratla, Soumen Chakrabarti, Siddhartha Chaudhuri, Preethi Jyothi, and Sunita Sarawagi. 2018. Generalizing across domains via cross-gradient training. arXiv preprint arXiv:1804.10745 (2018).Google Scholar"",""Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei A Efros, and Moritz Hardt. 2019. Test-time training for out-of-distribution generalization. arXiv preprint arXiv:1909.13231 (2019).Google Scholar"",""Kai Ming Ting. 2000. A comparative study of cost-sensitive boosting algorithms. In Proc. of the International Conference on Machine Learning. Citeseer.Google Scholar"",""Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rodriguez, and Krishna P Gummadi. 2017. Fairness beyond disparate treatment \u0026 disparate impact: Learning classification without disparate mistreatment. In Proc. of the International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 1171--1180.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403132,Neural Dynamics on Complex Networks,"Learning continuous-time dynamics on complex networks is crucial for understanding, predicting, and controlling complex systems in science and engineering. However, this task is very challenging due to the combinatorial complexities in the structures of high dimensional systems, their elusive continuous-time nonlinear dynamics, and their structural-dynamic dependencies. To address these challenges, we propose to combine Ordinary Differential Equation Systems (ODEs) and Graph Neural Networks (GNNs) to learn continuous-time dynamics on complex networks in a data-driven manner. We model differential equation systems by GNNs. Instead of mapping through a discrete number of neural layers in the forward process, we integrate GNN layers over continuous time numerically, leading to capturing continuous-time dynamics on graphs. Our model can be interpreted as a Continuous-time GNN model or a Graph Neural ODEs model. Our model can be utilized for continuous-time network dynamics prediction, structured sequence prediction (a regularly-sampled case), and node semi-supervised classification tasks (a one-snapshot case) in a unified framework. We validate our model by extensive experiments in the above three scenarios. The promising experimental results demonstrate our model's capability of jointly capturing the structure and dynamics of complex systems in a unified framework.","[{""name"":""Chengxi Zang"",""id"":""/profile/99659060484""},{""name"":""Fei Wang"",""id"":""/profile/99658710924""},{""name"":""Chengxi Zang"",""id"":""/profile/99659060484""},{""name"":""Fei Wang"",""id"":""/profile/99658710924""}]","[""Warder Clyde Allee, Orlando Park, Alfred Edwards Emerson, Thomas Park, Karl Patterson Schmidt, et al. 1949. Principles of animal ecology. Technical Report. Saunders Company Philadelphia, Pennsylvania, USA.Google Scholar"",""Uri Alon. 2006. An introduction to systems biology: design principles of biological circuits .Chapman and Hall/CRC.Google Scholar"",""Albert-László Barabási and Réka Albert. 1999. Emergence of scaling in random networks. science, Vol. 286, 5439 (1999), 509--512.Google Scholar"",""Baruch Barzel, Yang-Yu Liu, and Albert-László Barabási. 2015. Constructing minimal models for complex system dynamics. Nature communications (2015).Google Scholar"",""Amir Bashan, Travis E Gibson, Jonathan Friedman, Vincent J Carey, Scott T Weiss, Elizabeth L Hohmann, and Yang-Yu Liu. 2016. Universality of human microbial dynamics. Nature, Vol. 534, 7606 (2016), 259.Google ScholarCross Ref"",""Martin Benning, Elena Celledoni, Matthias J Ehrhardt, Brynjulf Owren, and Carola-Bibiane Schönlieb. 2019. Deep learning as optimal control problems: models and numerical methods. arXiv preprint arXiv:1904.05657 (2019).Google Scholar"",""William E Boyce, Richard C DiPrima, and Douglas B Meade. 1992. Elementary differential equations and boundary value problems. Vol. 9. Wiley New York.Google Scholar"",""Tian Qi Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud. 2018. Neural ordinary differential equations. In Advances in Neural Information Processing Systems. 6571--6583.Google Scholar"",""John R Dormand. 1996. Numerical methods for differential equations: a computational approach. Vol. 3. CRC Press.Google Scholar"",""Emilien Dupont, Arnaud Doucet, and Yee Whye Teh. 2019. Augmented neural odes. arXiv preprint arXiv:1904.01681 (2019).Google Scholar"",""P Erdos and A Renyi. 1959. On random graphs I. Publ. Math. Debrecen, Vol. 6 (1959).Google Scholar"",""Santo Fortunato. 2010. Community detection in graphs. Physics reports, Vol. 486, 3--5 (2010), 75--174.Google Scholar"",""Jianxi Gao, Baruch Barzel, and Albert-László Barabási. 2016. Universal resilience patterns in complex networks. Nature, Vol. 530, 7590 (2016), 307.Google Scholar"",""Wulfram Gerstner, Werner M Kistler, Richard Naud, and Liam Paninski. 2014. Neuronal dynamics: From single neurons to networks and models of cognition. Cambridge University Press.Google Scholar"",""Jiequn Han, Qianxiao Li, et al. 2018. A mean-field optimal control formulation of deep learning. arXiv preprint arXiv:1807.01083 (2018).Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition. 770--778.Google ScholarCross Ref"",""Seyed Mehran Kazemi, Rishab Goel, Kshitij Jain, Ivan Kobyzev, Akshay Sethi, Peter Forsyth, and Pascal Poupart. 2019. Relational Representation Learning for Dynamic (Knowledge) Graphs: A Survey. arXiv preprint arXiv:1905.11485 (2019).Google Scholar"",""Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Optimization. In ICLR 2015.Google Scholar"",""Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In ICLR 2017.Google Scholar"",""Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep learning. nature, Vol. 521, 7553 (2015), 436.Google Scholar"",""Haoyang Li, Peng Cui, Chengxi Zang, Tianyang Zhang, Wenwu Zhu, and Yishi Lin. 2019. Fates of Microscopic Social Ecosystems: Keep Alive or Dead?. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 668--676.Google ScholarDigital Library"",""Qimai Li, Zhichao Han, and Xiao-Ming Wu. 2018. Deeper insights into graph convolutional networks for semi-supervised learning. In Thirty-Second AAAI Conference on Artificial Intelligence.Google Scholar"",""Zachary C Lipton, John Berkowitz, and Charles Elkan. 2015. A critical review of recurrent neural networks for sequence learning. preprint arXiv:1506.00019 (2015).Google Scholar"",""Yunfei Lu, Linyun Yu, Tianyang Zhang, Chengxi Zang, Peng Cui, Chaoming Song, and Wenwu Zhu. 2018. Collective Human Behavior in Cascading System: Discovery, Modeling and Applications. In 2018 IEEE International Conference on Data Mining (ICDM). IEEE, 297--306.Google ScholarCross Ref"",""Yiping Lu, Aoxiao Zhong, Quanzheng Li, and Bin Dong. 2017. Beyond finite layer neural networks: Bridging deep architectures and numerical differential equations. arXiv preprint arXiv:1710.10121 (2017).Google Scholar"",""A v Luikov. 2012. Analytical heat diffusion theory .Elsevier.Google Scholar"",""Niall M Mangan, Steven L Brunton, Joshua L Proctor, and J Nathan Kutz. 2016. Inferring biological networks by sparse identification of nonlinear dynamics. IEEE Transactions on Molecular, Biological and Multi-Scale Communications, Vol. 2, 1 (2016), 52--63.Google ScholarCross Ref"",""Apurva Narayan and Peter HO?? Roe. 2018. Learning graph dynamics using deep neural networks. IFAC-PapersOnLine, Vol. 51, 2 (2018), 433--438.Google ScholarCross Ref"",""Mark Newman. 2010. Networks: an introduction .Oxford U. press.Google Scholar"",""Mark Newman, Albert-Laszlo Barabasi, and Duncan J Watts. 2011. The structure and dynamics of networks. Vol. 12. Princeton University Press.Google Scholar"",""Tong Qin, Kailiang Wu, and Dongbin Xiu. 2018. Data driven governing equations approximation using deep neural networks. arXiv preprint arXiv:1811.05537 (2018).Google Scholar"",""Maziar Raissi. 2018. Deep hidden physics models: Deep learning of nonlinear partial differential equations. The Journal of Machine Learning Research, Vol. 19, 1 (2018), 932--955.Google ScholarDigital Library"",""Maziar Raissi, Paris Perdikaris, and George Em Karniadakis. 2018. Multistep neural networks for data-driven discovery of nonlinear dynamical systems. arXiv preprint arXiv:1801.01236 (2018).Google Scholar"",""Samuel H Rudy, Steven L Brunton, Joshua L Proctor, and J Nathan Kutz. 2017. Data-driven discovery of partial differential equations. Science Advances, Vol. 3, 4 (2017), e1602614.Google ScholarCross Ref"",""Lars Ruthotto and Eldad Haber. 2018. Deep neural networks motivated by partial differential equations. arXiv preprint arXiv:1804.04272 (2018).Google Scholar"",""Youngjoo Seo, Michaël Defferrard, Pierre Vandergheynst, and Xavier Bresson. 2018. Structured sequence modeling with graph convolutional recurrent networks. In International Conference on Neural Information Processing. 362--373.Google ScholarCross Ref"",""Jean-Jacques E Slotine, Weiping Li, et al. 1991. Applied nonlinear control. Vol. 199. Prentice hall Englewood Cliffs, NJ.Google Scholar"",""Steven H Strogatz. 2018. Nonlinear Dynamics and Chaos with Student Solutions Manual: With Applications to Physics, Biology, Chemistry, and Engineering.Google Scholar"",""Kiran K Thekumparampil, Chong Wang, Sewoong Oh, and Li-Jia Li. 2018. Attention-based graph neural network for semi-supervised learning. arXiv preprint arXiv:1803.03735 (2018).Google Scholar"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph attention networks. arXiv preprint arXiv:1710.10903 (2017).Google Scholar"",""Duncan J Watts and Steven H Strogatz. 1998. Collective dynamics of \""mall-world\"" networks. nature, Vol. 393, 6684 (1998), 440.Google Scholar"",""Felix Wu, Tianyi Zhang, Amauri H. Souza Jr., Christopher Fifty, Tao Yu, and Kilian Q. Weinberger. 2019 b. Simplifying Graph Convolutional Networks. CoRR (2019).Google Scholar"",""Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and Philip S Yu. 2019 a. A comprehensive survey on graph neural networks. arXiv preprint arXiv:1901.00596 (2019).Google Scholar"",""Zhilin Yang, William W. Cohen, and Ruslan Salakhutdinov. 2016. Revisiting Semi-Supervised Learning with Graph Embeddings. In ICML 2016. 40--48.Google Scholar"",""Bing Yu, Haoteng Yin, and Zhanxing Zhu. 2017. Spatio-temporal graph convolutional networks: A deep learning framework for traffic forecasting. arXiv preprint arXiv:1709.04875 (2017).Google Scholar"",""Chengxi Zang, Peng Cui, and Christos Faloutsos. 2016. Beyond sigmoids: The nettide model for social network growth, and its applications. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. 2015--2024.Google ScholarDigital Library"",""Chengxi Zang, Peng Cui, Christos Faloutsos, and Wenwu Zhu. 2018. On Power Law Growth of Social Networks. IEEE Transactions on Knowledge and Data Engineering, Vol. 30, 9 (2018), 1727--1740.Google ScholarCross Ref"",""Chengxi Zang, Peng Cui, Chaoming Song, Wenwu Zhu, and Fei Wang. 2019 a. Uncovering Pattern Formation of Information Flow. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1691--1699.Google ScholarDigital Library"",""Chengxi Zang, Peng Cui, Wenwu Zhu, and Fei Wang. 2019 b. Dynamical Origins of Distribution Functions. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 469--478.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403133,Grammatically Recognizing Images with Tree Convolution,"Similar to language, understanding an image can be considered as a hierarchical decomposition process from scenes to objects, parts, pixels, and the corresponding spatial/contextual relations. However, the existing convolutional networks concentrate on stacking redundant convolutional layers with a large number of kernels in a hierarchical organization to implicitly approximate this decomposition. This may limit the network to learn the semantic information conveyed in the internal feature maps that may reveal minor yet crucial differences for visual understanding. Attempting to tackle this problem, this paper proposes a simple yet effective tree convolution (TreeConv) operation for deep neural networks. Specifically, inspired by the image grammar techniques[73] that serve as a unified framework of object representation, learning, and recognition, our TreeConv designs a generative image grammar, i.e., tree generation rule, to parse the hierarchy of internal feature maps by generating tree structures and implicitly learning the specific visual grammars for each object category. Extensive experiments on a variety of benchmarks, i.e., classification (ImageNet / CIFAR), detection & segmentation (COCO 2017), and person re-identification (CUHK03), demonstrate the superiority of our TreeConv in both boosting the accuracy and reducing the computational cost. The source code will be available at: https://github.com/wanggrun/TreeConv.","[{""name"":""Guangrun Wang"",""id"":""/profile/99658725816""},{""name"":""Guangcong Wang"",""id"":""/profile/99659573203""},{""name"":""Keze Wang"",""id"":""/profile/99658645153""},{""name"":""Xiaodan Liang"",""id"":""/profile/83358869457""},{""name"":""Liang Lin"",""id"":""/profile/81414605478""},{""name"":""Guangrun Wang"",""id"":""/profile/99658725816""},{""name"":""Guangcong Wang"",""id"":""/profile/99659573203""},{""name"":""Keze Wang"",""id"":""/profile/99658645153""},{""name"":""Xiaodan Liang"",""id"":""/profile/83358869457""},{""name"":""Liang Lin"",""id"":""/profile/81414605478""}]","[""Chun-Fu (Richard) Chen, Quanfu Fan, Neil Mallinar, Tom Sercu, and Rogé rio Schmidt Feris. 2019 a. Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition. In Proceedings of International Conference on Learning Representations (ICLR).Google Scholar"",""Tianshui Chen, Liang Lin, Wangmeng Zuo, Xiaonan Luo, and Lei Zhang. 2018. Learning a wavelet-like auto-encoder to accelerate deep neural networks. In Proceedings of Association for the Advancement of Artificial Intelligence (AAAI).Google Scholar"",""Yunpeng Chen, Haoqi Fan, Bing Xu, Zhicheng Yan, Yannis Kalantidis, Marcus Rohrbach, Shuicheng Yan, and Jiashi Feng. 2019 b. Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution. Proceedings of International Conference on Computer Vision (ICCV) (2019).Google ScholarCross Ref"",""Yanbei Chen, Xiatian Zhu, and Shaogang Gong. 2017. Person Re-Identification by Deep Learning Multi-Scale Representations. In Proceedings of Computer Vision and Pattern Recognition (CVPR). 2590--2600.Google ScholarCross Ref"",""Francc ois Chollet. 2017. Xception: Deep Learning with Depthwise Separable Convolutions. In Proceedings of Computer Vision and Pattern Recognition (CVPR). 1800--1807.Google ScholarCross Ref"",""Jifeng Dai, Haozhi Qi, Yuwen Xiong, Yi Li, Guodong Zhang, Han Hu, and Yichen Wei. 2017. Deformable Convolutional Networks. In Proceedings of International Conference on Computer Vision (ICCV).Google ScholarCross Ref"",""Hehe Fan, Liang Zheng, Chenggang Yan, and Yi Yang. 2018. Unsupervised Person Re-identification: Clustering and Fine-tuning. TOMM, Vol. 14, 4 (2018), 83:1--83:18.Google ScholarDigital Library"",""Hongyang Gao and Shuiwang Ji. 2019. Graph Representation Learning via Hard and Channel-Wise Attention Networks. In Proceedings of International Conference on Knowledge Discovery \u0026 Data Mining (KDD). 741--749.Google ScholarDigital Library"",""G. Gazdar. 1985. Generalized phrase structure grammar .Harvard University Press.Google Scholar"",""Dileep George, Wolfgang Lehrach, Ken Kansky, Miguel Lázaro-Gredilla, Christopher Laan, Bhaskara Marthi, Xinghua Lou, Zhaoshi Meng, Yi Liu, Huayan Wang, et al. 2017a. A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs. Science, Vol. 358, 6368 (2017), eaag2612.Google Scholar"",""D. George, W. Lehrach, K. Kansky, M. Lazaro-Gredilla, C. Laan, B. Marthi, X. Lou, Z. Meng, Y. Liu, H. Wang, A. Lavin, and D. S. Phoenix. 2017b. A generative vision model that trains with high data efficiency and breaks text-based captchas. Science (2017).Google Scholar"",""F. Han and S.-C. Zhu. 2009. Bottom-up/top-down image parsing with attribute grammar. IEEE transactions on pattern analysis and machine intelligence, Vol. 31, 1 (2009), 59--73.Google Scholar"",""D. G. Hays. 1964. Dependency theory: A formalism and some observations. Language, Vol. 40, 4 (1964), 511--525.Google ScholarCross Ref"",""Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick. 2017. Mask r-cnn. In Proceedings of International Conference on Computer Vision (ICCV). IEEE, 2980--2988.Google ScholarCross Ref"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016a. Deep Residual Learning for Image Recognition. In Proceedings of Computer Vision and Pattern Recognition (CVPR).Google ScholarCross Ref"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016b. Deep residual learning for image recognition. In Proceedings of Computer Vision and Pattern Recognition (CVPR). 770--778.Google ScholarCross Ref"",""Sepp Hochreiter and Jü rgen Schmidhuber. 1997. Long Short-Term Memory. Neural Computation, Vol. 9, 8 (1997), 1735--1780. https://doi.org/10.1162/neco.1997.9.8.1735Google ScholarDigital Library"",""Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. 2017. MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications. CoRR, Vol. abs/1704.04861 (2017).Google Scholar"",""Han Hu, Zheng Zhang, Zhenda Xie, and Stephen Lin. 2019. Local Relation Networks for Image Recognition. Proceedings of International Conference on Computer Vision (ICCV) (2019).Google ScholarCross Ref"",""Jie Hu, Li Shen, and Gang Sun. 2018. Squeeze-and-Excitation Networks. In Proceedings of Computer Vision and Pattern Recognition (CVPR). 7132--7141.Google Scholar"",""Gao Huang, Zhuang Liu, Kilian Q Weinberger, and Laurens van der Maaten. 2017. Densely connected convolutional networks. In Proceedings of Computer Vision and Pattern Recognition (CVPR).Google Scholar"",""Tsung-Wei Ke, Michael Maire, and Stella X Yu. 2017. Multigrid neural architectures. In Proceedings of Computer Vision and Pattern Recognition (CVPR). 6665--6673.Google ScholarCross Ref"",""Pan Li, Zhen Qin, Xuanhui Wang, and Donald Metzler. 2019 a. Combining Decision Trees and Neural Networks for Learning-to-Rank in Personal Search. In Proceedings of International Conference on Knowledge Discovery \u0026 Data Mining (KDD). 2032--2040.Google ScholarDigital Library"",""Wei Li, Rui Zhao, Tong Xiao, and Xiaogang Wang. 2014. Deepreid: Deep filter pairing neural network for person re-identification. In Proceedings of Computer Vision and Pattern Recognition (CVPR). 152--159.Google ScholarDigital Library"",""Xilai Li, Xi Song, and Tianfu Wu. 2019 b. AOGNets: Compositional Grammatical Architectures for Deep Learning. In Proceedings of Computer Vision and Pattern Recognition (CVPR). 6220--6230.Google ScholarCross Ref"",""Shengcai Liao, Yang Hu, Xiangyu Zhu, and Stan Z Li. 2015. Person re-identification by local maximal occurrence representation and metric learning. In Proceedings of Computer Vision and Pattern Recognition (CVPR). 2197--2206.Google ScholarCross Ref"",""Liang Lin, Guangrun Wang, Rui Zhang, Ruimao Zhang, Xiaodan Liang, and Wangmeng Zuo. 2016. Deep structured scene parsing by learning with image descriptions. In Proceedings of Computer Vision and Pattern Recognition (CVPR). 2276--2284.Google ScholarCross Ref"",""Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C Lawrence Zitnick. 2014. Microsoft coco: Common objects in context. In Proceedings of European Conference on Computer Vision (ECCV). Springer, 740--755.Google ScholarCross Ref"",""Tony Lindeberg. 2013. Scale-space theory in computer vision. Vol. 256. Springer Science \u0026 Business Media.Google Scholar"",""Tal Linzen, Emmanuel Dupoux, and Yoav Goldberg. 2016. Assessing the ability of LSTMs to learn syntax-sensitive dependencies. Transactions of the Association for Computational Linguistics, Vol. 4 (2016), 521--535.Google ScholarCross Ref"",""Chenxi Liu, Barret Zoph, Maxim Neumann, Jonathon Shlens, Wei Hua, Li-Jia Li, Li Fei-Fei, Alan Yuille, Jonathan Huang, and Kevin Murphy. 2018. Progressive neural architecture search. In Proceedings of European Conference on Computer Vision (ECCV). 19--34.Google ScholarCross Ref"",""Donghua Liu, Jing Li, Bo Du, Jun Chang, and Rong Gao. 2019 a. DAML: Dual Attention Mutual Learning between Ratings and Reviews for Item Recommendation. In Proceedings of International Conference on Knowledge Discovery \u0026 Data Mining (KDD). 344--352.Google ScholarDigital Library"",""Hanxiao Liu, Karen Simonyan, and Yiming Yang. 2019 b. DARTS: Differentiable Architecture Search. In Proceedings of International Conference on Learning Representations (ICLR).Google Scholar"",""David Lopez-Paz, Robert Nishihara, Soumith Chintala, Bernhard Scholkopf, and Léon Bottou. 2017. Discovering causal signals in images. In Proceedings of Computer Vision and Pattern Recognition (CVPR). 6979--6987.Google ScholarCross Ref"",""Lili Mou, Ge Li, Lu Zhang, Tao Wang, and Zhi Jin. 2016. Convolutional Neural Networks over Tree Structures for Programming Language Processing. In Proceedings of Association for the Advancement of Artificial Intelligence (AAAI). 1287--1293.Google Scholar"",""Hieu Pham, Melody Y. Guan, Barret Zoph, Quoc V. Le, and Jeff Dean. 2018. Efficient Neural Architecture Search via Parameter Sharing. In Proceedings of International Conference on Machine Learning (ICML). 4092--4101.Google Scholar"",""Esteban Real, Alok Aggarwal, Yanping Huang, and Quoc V. Le. 2019. Regularized Evolution for Image Classifier Architecture Search. In Proceedings of Association for the Advancement of Artificial Intelligence (AAAI). 4780--4789.Google Scholar"",""Deboleena Roy, Priyadarshini Panda, and Kaushik Roy. 2020. Tree-CNN: A hierarchical Deep Convolutional Neural Network for incremental learning. Neural Networks, Vol. 121 (2020), 148--160.Google ScholarCross Ref"",""Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. 2015. Imagenet large scale visual recognition challenge. International Journal of Computer Vision, Vol. 115, 3 (2015), 211--252.Google ScholarDigital Library"",""Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. 2018. Mobilenetv2: Inverted residuals and linear bottlenecks. In Proceedings of Computer Vision and Pattern Recognition (CVPR). 4510--4520.Google ScholarCross Ref"",""Yikang Shen, Zhouhan Lin, Chin-Wei Huang, and Aaron C. Courville. 2018. Neural Language Modeling by Jointly Learning Syntax and Lexicon. In Proceedings of International Conference on Learning Representations (ICLR).Google Scholar"",""Yikang Shen, Shawn Tan, Alessandro Sordoni, and Aaron Courville. 2019. Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks. Proceedings of International Conference on Learning Representations (ICLR) (2019).Google Scholar"",""Yifan Sun, Liang Zheng, Weijian Deng, and Shengjin Wang. 2017. SVDNet for Pedestrian Retrieval. In Proceedings of International Conference on Computer Vision (ICCV). 3820--3828.Google ScholarCross Ref"",""Mingxing Tan and Quoc V. Le. 2019. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. In Proceedings of International Conference on Machine Learning (ICML).Google Scholar"",""Wei Tang, Pei Yu, and Ying Wu. 2018. Deeply learned compositional models for human pose estimation. In Proceedings of European Conference on Computer Vision (ECCV). 190--206.Google ScholarCross Ref"",""Wei Tang, Pei Yu, Jiahuan Zhou, and Ying Wu. 2017. Towards a unified compositional model for visual pattern modeling. In Proceedings of Computer Vision and Pattern Recognition (CVPR). 2784--2793.Google ScholarCross Ref"",""Xiaoli Tang, Tengyun Wang, Haizhi Yang, and Hengjie Song. 2019. AKUPM: Attention-Enhanced Knowledge-Aware User Preference Model for Recommendation. In Proceedings of International Conference on Knowledge Discovery \u0026 Data Mining (KDD). 1891--1899.Google ScholarDigital Library"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In Advances in Neural Information Processing Systems (NeurIPS). 5998--6008.Google Scholar"",""Guangcong Wang, Jianhuang Lai, Peigen Huang, and Xiaohua Xie. 2019 b. Spatial-Temporal Person Re-Identification. In The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artificial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019, Honolulu, Hawaii, USA, January 27 - February 1, 2019. 8933--8940. https://doi.org/10.1609/aaai.v33i01.33018933Google Scholar"",""Guangcong Wang, Jianhuang Lai, and Xiaohua Xie. 2018b. P2SNet: Can an Image Match a Video for Person Re-Identification in an End-to-End Way? IEEE Trans. Circuits Syst. Video Techn., Vol. 28, 10 (2018), 2777--2787.Google ScholarDigital Library"",""Guangcong Wang, Jian-Huang Lai, Wenqi Liang, and Guangrun Wang. 2020 a. Smoothing Adversarial Domain Attack and P-Memory Reconsolidation for Cross-Domain Person Re-Identification. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR).Google Scholar"",""Guangrun Wang, Guangcong Wang, Xujie Zhang, Jianhuang Lai, Zhengtao Yu, and Liang Lin. 2020 b. Weakly Supervised Person Re-ID: Differentiable Graphical Learning and A New Benchmark. In IEEE Transactions on Neural Networks and Learning Systems (T-NNLS).Google Scholar"",""Guangrun Wang, Keze Wang, and Liang Lin. 2019 c. Adaptively Connected Neural Networks. In Proceedings of Computer Vision and Pattern Recognition (CVPR). 1781--1790.Google ScholarCross Ref"",""Guanshuo Wang, Yufeng Yuan, Xiong Chen, Jiwei Li, and Xi Zhou. 2018c. Learning Discriminative Features with Multiple Granularities for Person Re-Identification. In Proceedings of ACM Multimedia Conference on Multimedia Conference (ACM MM). 274--282.Google ScholarDigital Library"",""Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He. 2018a. Non-local neural networks. In Proceedings of Computer Vision and Pattern Recognition (CVPR). 7794--7803.Google ScholarCross Ref"",""Xiang Wang, Xiangnan He, Yixin Cao, Meng Liu, and Tat-Seng Chua. 2019 a. KGAT: Knowledge Graph Attention Network for Recommendation. In Proceedings of International Conference on Knowledge Discovery \u0026 Data Mining (KDD). 950--958.Google ScholarDigital Library"",""Yuanlu Xu, Liang Lin, Wei-Shi Zheng, and Xiaobai Liu. 2013. Human re-identification by matching compositional template with cluster sampling. In Proceedings of International Conference on Computer Vision (ICCV). 3152--3159.Google ScholarDigital Library"",""Y. Xu, X. Liu, Y. Liu, and S.-C. Zhu. 2016. Multi-view people tracking via hierarchical trajectory composition. In Proceedings of Computer Vision and Pattern Recognition (CVPR).Google ScholarCross Ref"",""Dani Yogatama, Yishu Miao, Gabor Melis, Wang Ling, Adhiguna Kuncoro, Chris Dyer, and Phil Blunsom. 2018. Memory architectures in recurrent neural network language models. In Proceedings of International Conference on Learning Representations (ICLR).Google Scholar"",""Jiahui Yu, Zhe Lin, Jimei Yang, Xiaohui Shen, Xin Lu, and Thomas S. Huang. 2019. Free-Form Image Inpainting With Gated Convolution. In Proceedings of International Conference on Computer Vision (ICCV). 4470--4479. https://doi.org/10.1109/ICCV.2019.00457Google Scholar"",""Rui Yu, Zhichao Zhou, Song Bai, and Xiang Bai. 2017. Divide and Fuse: A Re-ranking Approach for Person Re-identification. In Proceedings of British Machine Vision Conference (BMVC).Google ScholarCross Ref"",""Han Zhang, Ian J. Goodfellow, Dimitris N. Metaxas, and Augustus Odena. 2019 a. Self-Attention Generative Adversarial Networks. In Proceedings of International Conference on Machine Learning (ICML). 7354--7363.Google Scholar"",""Ruimao Zhang, Liang Lin, Guangrun Wang, Meng Wang, and Wangmeng Zuo. 2019 b. Hierarchical scene parsing by weakly supervised learning with image descriptions. IEEE transactions on pattern analysis and machine intelligence, Vol. 41, 3 (2019), 596--610.Google Scholar"",""Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, and Jian Sun. 2018. Shufflenet: An extremely efficient convolutional neural network for mobile devices. In Proceedings of Computer Vision and Pattern Recognition (CVPR). 6848--6856.Google ScholarCross Ref"",""Y. Zhao and S.-C. Zhu. 2011. Image parsing with stochastic scene grammar. In Advances in Neural Information Processing Systems (NeurIPS).Google Scholar"",""Liang Zheng, Liyue Shen, Lu Tian, Shengjin Wang, Jingdong Wang, and Qi Tian. 2015. Scalable person re-identification: A benchmark. In Proceedings of International Conference on Computer Vision (ICCV).Google ScholarCross Ref"",""Liang Zheng, Yi Yang, and Alexander G Hauptmann. 2016. Person re-identification: Past, present and future. arXiv preprint arXiv:1610.02984 (2016).Google Scholar"",""Zhun Zhong, Liang Zheng, Donglin Cao, and Shaozi Li. 2017a. Re-ranking Person Re-identification with k-Reciprocal Encoding. In Proceedings of Computer Vision and Pattern Recognition (CVPR). 3652--3661.Google ScholarCross Ref"",""Zhun Zhong, Liang Zheng, Guoliang Kang, Shaozi Li, and Yi Yang. 2017b. Random Erasing Data Augmentation. arXiv preprint arXiv:1708.04896 (2017).Google Scholar"",""Bolei Zhou, Aditya Khosla, À gata Lapedriza, Aude Oliva, and Antonio Torralba. 2016. Learning Deep Features for Discriminative Localization. In Proceedings of Computer Vision and Pattern Recognition (CVPR). 2921--2929.Google ScholarCross Ref"",""Yichao Zhou, Shaunak Mishra, Jelena Gligorijevic, Tarun Bhatia, and Narayan Bhamidipati. 2019. Understanding Consumer Journey using Attention based Recurrent Neural Networks. In Proceedings of International Conference on Knowledge Discovery \u0026 Data Mining (KDD). 3102--3111.Google ScholarDigital Library"",""Han Zhu, Xiang Li, Pengye Zhang, Guozheng Li, Jie He, Han Li, and Kun Gai. 2018. Learning Tree-based Deep Model for Recommender Systems. In Proceedings of International Conference on Knowledge Discovery \u0026 Data Mining (KDD). 1079--1088.Google ScholarDigital Library"",""Song-Chun Zhu and David Mumford. 2007. A Stochastic Grammar of Images .Now Publishers Inc., Hanover, MA, USA.Google Scholar"",""Xizhou Zhu, Han Hu, Stephen Lin, and Jifeng Dai. 2019. Deformable ConvNets V2: More Deformable, Better Results. In Proceedings of Computer Vision and Pattern Recognition (CVPR). 9308--9316.Google Scholar"",""Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V Le. 2018. Learning transferable architectures for scalable image recognition. In Proceedings of Computer Vision and Pattern Recognition (CVPR). 8697--8710.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403134,Generic Outlier Detection in Multi-Armed Bandit,"In this paper, we study the problem of outlier arm detection in multi-armed bandit settings, which finds plenty of applications in many high-impact domains such as finance, healthcare, and online advertising. For this problem, a learner aims to identify the arms whose expected rewards deviate significantly from most of the other arms. Different from existing work, we target the generic outlier arms or outlier arm groups whose expected rewards can be larger, smaller, or even in between those of normal arms. To this end, we start by providing a comprehensive definition of such generic outlier arms and outlier arm groups. Then we propose a novel pulling algorithm named GOLD to identify such generic outlier arms. It builds a real-time neighborhood graph based on upper confidence bounds and catches the behavior pattern of outliers from normal arms. We also analyze its performance from various aspects. In the experiments conducted on both synthetic and real-world data sets, the proposed algorithm achieves 98% accuracy while saving 83% exploration cost on average compared with state-of-the-art techniques.","[{""name"":""Yikun Ban"",""id"":""/profile/99659573851""},{""name"":""Jingrui He"",""id"":""/profile/81540269856""},{""name"":""Yikun Ban"",""id"":""/profile/99659573851""},{""name"":""Jingrui He"",""id"":""/profile/81540269856""}]","[""Alan Agresti and Brent A Coull. 1998. Approximate is better than \""exact\"" for interval estimation of binomial proportions. The American Statistician, Vol. 52, 2 (1998), 119--126.Google Scholar"",""Leman Akoglu, Hanghang Tong, and Danai Koutra. 2015. Graph based anomaly detection and description: a survey. Data mining and knowledge discovery, Vol. 29, 3 (2015), 626--688.Google Scholar"",""András Antos, Varun Grover, and Csaba Szepesvári. 2010. Active learning in heteroscedastic noise. Theoretical Computer Science, Vol. 411, 29--30 (2010), 2712--2728.Google ScholarDigital Library"",""Jean-Yves Audibert and Sébastien Bubeck. 2010. Best arm identification in multi-armed bandits. In Conference on Learning Theory (COLT). 41--53.Google Scholar"",""Peter Auer. 2002. Using confidence bounds for exploitation-exploration trade-offs. Journal of Machine Learning Research, Vol. 3, Nov (2002), 397--422.Google ScholarDigital Library"",""Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer. 2002. Finite-time analysis of the multiarmed bandit problem. Machine learning, Vol. 47, 2--3 (2002), 235--256.Google Scholar"",""Sébastien Bubeck, Rémi Munos, and Gilles Stoltz. 2009. Pure exploration in multi-armed bandits problems. In International conference on Algorithmic learning theory. Springer, 23--37.Google ScholarDigital Library"",""Sébastien Bubeck, Rémi Munos, and Gilles Stoltz. 2011. Pure exploration in finitely-armed and continuous-armed bandits. Theoretical Computer Science, Vol. 412, 19 (2011), 1832--1852.Google ScholarDigital Library"",""Séebastian Bubeck, Tengyao Wang, and Nitin Viswanathan. 2013. Multiple identifications in multi-armed bandits. In International Conference on Machine Learning. 258--265.Google Scholar"",""Alexandra Carpentier and Andrea Locatelli. 2016. Tight (lower) bounds for the fixed budget best arm identification bandit problem. In Conference on Learning Theory. 590--604.Google Scholar"",""Varun Chandola, Arindam Banerjee, and Vipin Kumar. 2009. Anomaly detection: A survey. ACM computing surveys (CSUR), Vol. 41, 3 (2009), 1--58.Google Scholar"",""Shouyuan Chen, Tian Lin, Irwin King, Michael R Lyu, and Wei Chen. 2014. Combinatorial pure exploration of multi-armed bandits. In Advances in Neural Information Processing Systems. 379--387.Google Scholar"",""Xi Chen, Qihang Lin, and Dengyong Zhou. 2015. Statistical decision making for optimal budget allocation in crowd labeling. The Journal of Machine Learning Research, Vol. 16, 1 (2015), 1--46.Google ScholarDigital Library"",""Pinar Donmez, Jaime G Carbonell, and Jeff Schneider. 2009. Efficiently learning the accuracy of labeling sources for selective sampling. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining. 259--268.Google ScholarDigital Library"",""Eyal Even-Dar, Shie Mannor, and Yishay Mansour. 2002. PAC bounds for multi-armed bandit and Markov decision processes. In International Conference on Computational Learning Theory. Springer, 255--270.Google ScholarCross Ref"",""Eyal Even-Dar, Shie Mannor, and Yishay Mansour. 2006. Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems. Journal of machine learning research, Vol. 7, Jun (2006), 1079--1105.Google ScholarDigital Library"",""Victor Gabillon, Mohammad Ghavamzadeh, and Alessandro Lazaric. 2012. Best arm identification: A unified approach to fixed budget and fixed confidence. In Advances in Neural Information Processing Systems. 3212--3220.Google Scholar"",""Sigurour E Guttormsson, RJ Marks, MA El-Sharkawi, and I Kerszenbaum. 1999. Elliptical novelty grouping for on-line short-turn detection of excited running rotors. IEEE Transactions on Energy Conversion, Vol. 14, 1 (1999), 16--22.Google ScholarCross Ref"",""Jiawei Han, Jian Pei, and Micheline Kamber. 2011. Data mining: concepts and techniques. Elsevier.Google Scholar"",""Kevin Jamieson, Matthew Malloy, Robert Nowak, and Sébastien Bubeck. 2014. lil' ucb: An optimal exploration algorithm for multi-armed bandits. In Conference on Learning Theory. 423--439.Google Scholar"",""Shivaram Kalyanakrishnan, Ambuj Tewari, Peter Auer, and Peter Stone. 2012. PAC Subset Selection in Stochastic Multi-armed Bandits. In ICML, Vol. 12. 655--662.Google Scholar"",""Emilie Kaufmann, Olivier Cappé, and Aurélien Garivier. 2016. On the complexity of best-arm identification in multi-armed bandit models. The Journal of Machine Learning Research, Vol. 17, 1 (2016), 1--42.Google ScholarDigital Library"",""Yufeng Kou, Chang-Tien Lu, and Dechang Chen. 2006. Spatial weighted outlier detection. In Proceedings of the 2006 SIAM international conference on data mining. SIAM, 614--618.Google ScholarCross Ref"",""Lihong Li, Wei Chu, John Langford, and Robert E Schapire. 2010. A contextual-bandit approach to personalized news article recommendation. In Proceedings of the 19th international conference on World wide web. ACM, 661--670.Google ScholarDigital Library"",""Andrea Locatelli, Maurilio Gutzeit, and Alexandra Carpentier. 2016. An optimal algorithm for the thresholding bandit problem. In Proceedings of the 33rd International Conference on International Conference on Machine Learning-Volume 48. 1690--1698.Google ScholarDigital Library"",""Oded Maron and Andrew W Moore. 1994. Hoeffding races: Accelerating model selection search for classification and function approximation. In Advances in neural information processing systems. 59--66.Google Scholar"",""Edward Paulson et al. 1964. A sequential procedure for selecting the population with the largest mean from $ k $ normal populations. The Annals of Mathematical Statistics, Vol. 35, 1 (1964), 174--180.Google ScholarCross Ref"",""Branko Ristic, Barbara La Scala, Mark Morelande, and Neil Gordon. 2008. Statistical analysis of motion patterns in AIS data: Anomaly detection and motion prediction. In 2008 11th International Conference on Information Fusion. IEEE, 1--7.Google Scholar"",""Augustin Soule, Kavé Salamatian, and Nina Taft. 2005. Combining filtering and statistical methods for anomaly detection. In Proceedings of the 5th ACM SIGCOMM conference on Internet Measurement. 31--31.Google ScholarDigital Library"",""Chao Tao, Saúl Blanco, Jian Peng, and Yuan Zhou. 2019. Thresholding Bandit with Optimal Aggregate Regret. In Advances in Neural Information Processing Systems. 11659--11668.Google Scholar"",""William R Thompson. 1933. On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. Biometrika, Vol. 25, 3/4 (1933), 285--294.Google ScholarCross Ref"",""Qingyun Wu, Huazheng Wang, Yanen Li, and Hongning Wang. 2019. Dynamic Ensemble of Contextual Bandits to Satisfy Users' Changing Interests. In The World Wide Web Conference. 2080--2090.Google ScholarDigital Library"",""Ban Yikun, Liu Xin, Huang Ling, Duan Yitao, Liu Xue, and Xu Wei. 2019. No place to hide: Catching fraudulent entities in tensors. In The World Wide Web Conference. 83--93.Google ScholarDigital Library"",""Si Zhang, Dawei Zhou, Mehmet Yigit Yildirim, Scott Alcorn, Jingrui He, Hasan Davulcu, and Hanghang Tong. 2017. Hidden: hierarchical dense subgraph detection with application to financial fraud detection. In Proceedings of the 2017 SIAM International Conference on Data Mining. SIAM, 570--578.Google ScholarCross Ref"",""Dawei Zhou, Jingrui He, K Seluk Candan, and Hasan Davulcu. 2015. MUVIR: multi-view rare category detection. In Twenty-Fourth International Joint Conference on Artificial Intelligence .Google Scholar"",""Dawei Zhou, Jingrui He, Hongxia Yang, and Wei Fan. 2018a. Sparc: Self-paced network representation for few-shot rare category characterization. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 2807--2816.Google ScholarDigital Library"",""Yao Zhou, Arun Reddy Nelakurthi, and Jingrui He. 2018b. Unlearn What You Have Learned: Adaptive Crowd Teaching with Exponentially Decayed Memory Learners. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining, KDD 2018, London, UK, August 19--23, 2018. ACM, 2817--2826.Google ScholarDigital Library"",""Yao Zhou, Arun Reddy Nelakurthi, Ross Maciejewski, Wei Fan, and Jingrui He. 2020. Crowd Teaching with Imperfect Labels. In WWW '20: The Web Conference 2020, Taipei, Taiwan, April 20--24, 2020. ACM / IW3C2, 110--121.Google Scholar"",""Honglei Zhuang, Chi Wang, and Yifan Wang. 2017. Identifying outlier arms in multi-armed bandit. In Advances in Neural Information Processing Systems (NIPS). 5204--5213.Google Scholar""]"
https://doi.org/10.1145/3394486.3403135,Robust Spammer Detection by Nash Reinforcement Learning,"Online reviews provide product evaluations for customers to make decisions. Unfortunately, the evaluations can be manipulated using fake reviews (""spams"") by professional spammers, who have learned increasingly insidious and powerful spamming strategies by adapting to the deployed detectors. Spamming strategies are hard to capture, as they can be varying quickly along time, different across spammers and target products, and more critically, remained unknown in most cases. Furthermore, most existing detectors focus on detection accuracy, which is not well-aligned with the goal of maintaining the trustworthiness of product evaluations. To address the challenges, we formulate a minimax game where the spammers and spam detectors compete with each other on their practical goals that are not solely based on detection accuracy. Nash equilibria of the game lead to stable detectors that are agnostic to any mixed detection strategies. However, the game has no closed-form solution and is not differentiable to admit the typical gradient-based algorithms. We turn the game into two dependent Markov Decision Processes (MDPs) to allow efficient stochastic optimization based on multi-armed bandit and policy gradient. We experiment on three large review datasets using various state-of-the-art spamming and detection strategies and show that the optimization algorithm can reliably find an equilibrial detector that can robustly and effectively prevent spammers with any mixed spamming strategies from attaining their practical goal. Our code is available at https://github.com/YingtongDou/Nash-Detect.","[{""name"":""Yingtong Dou"",""id"":""/profile/99659492416""},{""name"":""Guixiang Ma"",""id"":""/profile/99659163259""},{""name"":""Philip S. Yu"",""id"":""/profile/81556177556""},{""name"":""Sihong Xie"",""id"":""/profile/81501659353""},{""name"":""Yingtong Dou"",""id"":""/profile/99659492416""},{""name"":""Guixiang Ma"",""id"":""/profile/99659163259""},{""name"":""Philip S. Yu"",""id"":""/profile/81556177556""},{""name"":""Sihong Xie"",""id"":""/profile/81501659353""}]","[""L. Akoglu, R. Chandy, and C. Faloutsos. 2013. Opinion fraud detection in online reviews by network effects. In ICWSM.Google Scholar"",""B. Biggio, G. Fumera, and F. Roli. 2013. Security evaluation of pattern classifiers under attack. In ICDE.Google Scholar"",""A. Breuer, R. Eilat, and U. Weinsberg. 2020. Friend or Faux: Graph-Based Early Detection of Fake Accounts on Social Networks. In WWW.Google Scholar"",""S. Bubeck and N. Cesa-Bianchi. 2012. Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems. FTML (2012).Google Scholar"",""Y. Chen, Y. Nadji, A. Kountouras, F. Monrose, R. Perdisci, M. Antonakakis, and N. Vasiloglou. 2017. Practical Attacks Against Graph-based Clustering. In CCS.Google Scholar"",""W. Dai, G. Z. Jin, J. Lee, and M. Luca. 2012. Optimal aggregation of consumer ratings: an application to yelp. com. NBER WPS (2012).Google Scholar"",""C. Elkan. 2001. The foundations of cost-sensitive learning. In IJCAI.Google Scholar"",""C. Forman, A. Ghose, and B. Wiesenfeld. 2008. Examining the relationship between reviews and sales: The role of reviewer identity disclosure in electronic markets. ISR (2008).Google Scholar"",""S. Ge, G. Ma, S. Xie, and P. S. Yu. 2018. Securing Behavior-based Opinion Spam Detection. In IEEE Big DATA.Google Scholar"",""B. Hooi, H. A. Song, A. Beutel, N. Shah, K. Shin, and C. Faloutsos. 2016. FRAUDAR: Bounding Graph Fraud in the Face of Camouflage. In KDD.Google ScholarDigital Library"",""J. Hu and M. P. Wellman. 2003. Nash Q-learning for General-sum Stochastic Games. JMLR (2003).Google Scholar"",""P. Kaghazgaran, M. Alfifi, and J. Caverlee. 2019 a. TOmCAT: Target-Oriented Crowd Review Attacks and Countermeasures. In ICWSM.Google Scholar"",""P. Kaghazgaran, M. Alfifi, and J. Caverlee. 2019 b. Wide-Ranging Review Manipulation Attacks: Model, Empirical Study, and Countermeasures. In CIKM.Google Scholar"",""P. Kaghazgaran, J. Caverlee, and A. Squicciarini. 2018. Combating crowdsourced review manipulators: A neighborhood-based approach. In WSDM.Google Scholar"",""C. Kim, G. Lin, and H. Bang. 2015. Discovering Yelp Elites: Reifying Yelp Elite Selection Criterion. UCSD (2015).Google Scholar"",""S. Kumar, B. Hooi, D. Makhija, M. Kumar, C. Faloutsos, and VS Subrahmanian. 2018. Rev2: Fraudulent user prediction in rating platforms. In WSDM.Google Scholar"",""T. Lappas, G. Sabnis, and G. Valkanas. 2016. The impact of fake reviews on online visibility: A vulnerability assessment of the hotel industry. ISR (2016).Google Scholar"",""X. Li, S. Liu, Z. Li, X. Han, C. Shi, B. Hooi, H. Huang, and X. Cheng. 2020. FlowScope: Spotting Money Laundering Based on Graphs. In AAAI.Google Scholar"",""M. L Littman. 1994. Markov Games As a Framework for Multi-agent Reinforcement Learning. In ICML.Google Scholar"",""Z. Liu, Y. Dou, P. S. Yu, Y. Deng, and H. Peng. 2020. Alleviating the Inconsistency Problem of Applying Graph Neural Network to Fraud Detection. SIGIR.Google Scholar"",""M. Luca. 2016. Reviews, reputation, and revenue: The case of Yelp. com. HBS Working Paper (2016).Google Scholar"",""M. Luca and G. Zervas. 2016. Fake it till you make it: Reputation, competition, and Yelp review fraud. Management Science (2016).Google Scholar"",""A. Mukherjee, A. Kumar, B. Liu, J. Wang, M. Hsu, M. Castellanos, and R. Ghosh. 2013a. Spotting opinion spammers using behavioral footprints. In KDD.Google Scholar"",""A. Mukherjee, V. Venkataraman, B. Liu, and N. S. Glance. 2013b. What Yelp Fake Review Filter Might Be Doing?. In ICWSM.Google Scholar"",""K. Murphy, Y. Weiss, and M. Jordan. 1999. Loopy belief propagation for approximate inference: An empirical study. In UAI.Google Scholar"",""M. Rahman, N. Hernandez, R. Recabarren, S. I. Ahmed, and B. Carbunar. 2019. The Art and Craft of Fraudulent App Promotion in Google Play. In CCS.Google Scholar"",""S. Rayana and L. Akoglu. 2015. Collective Opinion Spam Detection: Bridging Review Networks and Metadata. In KDD.Google Scholar"",""Y. Ren, H. Zhu, J. ZHang, P. Dai, and L. Bo. 2019. EnsemFDet: An Ensemble Approach to Fraud Detection based on Bipartite Graph. arXiv preprint arXiv:1912.11113 (2019).Google Scholar"",""ReviewMeta. 2019. How It Works. https://bit.ly/3edwG3xGoogle Scholar"",""N. Shah, A. Beutel, B. Gallagher, and C. Faloutsos. 2014. Spotting Suspicious Link Behavior with fBox: An Adversarial Perspective. In ICDM.Google Scholar"",""L. Sun, Y. Dou, C. Yang, J. Wang, P. S. Yu, and B. Li. 2018. Adversarial Attack and Defense on Graph Data: A Survey. arXiv preprint arXiv:1812.10528 (2018).Google Scholar"",""R. S. Sutton and A. G. Barto. 1998. Introduction to Reinforcement Learning.Google Scholar"",""J. Swearingen. 2017. Amazon Is Filled With Sketchy Reviews. Here's How to Spot Them. https://slct.al/2TBXDpTGoogle Scholar"",""M. Tan. 1993. Multi-Agent Reinforcement Learning: Independent vs. Cooperative Agents. In ICML.Google Scholar"",""TheVerge. 2013. Samsung fined $340,000 for faking online comments. https://bit.ly/2WXKfOVGoogle Scholar"",""J. Uesato, B. O'Donoghue, P. Kohli, and A. Oord. 2018. Adversarial Risk and the Dangers of Evaluating Against Weak Attacks. In ICML.Google Scholar"",""B. Wang and N. Z. Gong. 2019. Attacking Graph-based Classification via Manipulating the Graph Structure. In CCS.Google Scholar"",""B. Wang, N. Z. Gong, and H. Fu. 2017a. GANG: Detecting Fraudulent Users in Online Social Networks via Guilt-by-Association on Directed Graphs. In ICDM.Google Scholar"",""X. Wang, K. Liu, and J. Zhao. 2017b. Handling cold-start problem in review spam detection by jointly embedding texts and behaviors. In ACL.Google Scholar"",""S. Xie, G. Wang, S. Lin, and P. S. Yu. 2012. Review Spam Detection via Temporal Pattern Discovery. In KDD.Google Scholar"",""C. Yang, H. Wang, L. Sun, and B. Li. 2020. Secure Network Release with Link Privacy. arXiv preprint arXiv:2005.00455 (2020).Google Scholar"",""Y. Yao, B. Viswanath, J. Cryan, H. Zheng, and B. Y. Zhao. 2017. Automated crowdturfing attacks and defenses in online review systems. In CCS.Google Scholar"",""Q. Ye, R. Law, B. Gu, and W. Chen. 2011. The influence of user-generated content on traveler behavior: An empirical investigation on the effects of e-word-of-mouth to hotel online bookings. CHB (2011).Google Scholar"",""Yelp. 2019. What is Yelp's Elite Squad? https://bit.ly/2A1dqYiGoogle Scholar"",""H. Zheng, M. Xue, H. Lu, S. Hao, H. Zhu, X. Liang, and K. Ross. 2018. Smoke screener or straight shooter: Detecting elite sybil attacks in user-review social networks. NDSS (2018).Google Scholar"",""B. Zhou, Y. Yao, and J. Luo. 2014. Cost-sensitive three-way email spam filtering. JIIS (2014).Google Scholar"",""D. Zügner, A. Akbarnejad, and S. Günnemann. 2018. Adversarial attacks on neural networks for graph data. In KDD.Google Scholar""]"
https://doi.org/10.1145/3394486.3403136,Mining Persistent Activity in Continually Evolving Networks,"Frequent pattern mining is a key area of study that gives insights into the structure and dynamics of evolving networks, such as social or road networks. However, not only does a network evolve, but often the way that it evolves, itself evolves. Thus, knowing, in addition to patterns' frequencies, for how long and how regularly they have occurred-i.e., their persistence-can add to our understanding of evolving networks. In this work, we propose the problem of mining activity that persists through time in continually evolving networks-i.e., activity that repeatedly and consistently occurs. We extend the notion of temporal motifs to capture activity among specific nodes, in what we call activity snippets, which are small sequences of edge-updates that reoccur. We propose axioms and properties that a measure of persistence should satisfy, and develop such a persistence measure. We also propose PENminer, an efficient framework for mining activity snippets' Persistence in Evolving Networks, and design both offline and streaming algorithms. We apply PENminer to numerous real, large-scale evolving networks and edge streams, and find activity that is surprisingly regular over a long period of time, but too infrequent to be discovered by aggregate count alone, and bursts of activity exposed by their lack of persistence. Our findings with PENminer include neighborhoods in NYC where taxi traffic persisted through Hurricane Sandy, the opening of new bike-stations, characteristics of social network users, and more. Moreover, we use PENminer towards identifying anomalies in multiple networks, outperforming baselines at identifying subtle anomalies by 9.8-48% in AUC.","[{""name"":""Caleb Belth"",""id"":""/profile/99659495614""},{""name"":""Xinyi Zheng"",""id"":""/profile/99659478447""},{""name"":""Danai Koutra"",""id"":""/profile/81488671041""},{""name"":""Caleb Belth"",""id"":""/profile/99659495614""},{""name"":""Xinyi Zheng"",""id"":""/profile/99659478447""},{""name"":""Danai Koutra"",""id"":""/profile/81488671041""}]","[""Motivate International Inc. https://www.motivateco.com/where-we-do-it/.Google Scholar"",""NYC Taxi \u0026 Limousine Commission. https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page.Google Scholar"",""Ehab Abdelhamid, Mustafa Canim, Mohammad Sadoghi, Bishwaranjan Bhattacharjee, Yuan-Chi Chang, and Panos Kalnis. Incremental frequent subgraph mining on large evolving graphs. IEEE TKDE, 29(12):2710--2723, 2017.Google Scholar"",""Charu C Aggarwal, Yao Li, Philip S Yu, and Ruoming Jin. On dense pattern mining in graph streams. PVLDB, 3(1--2):975--984, 2010.Google Scholar"",""Rezwan Ahmed and George Karypis. Algorithms for mining the coevolving relational motifs in dynamic networks. ACM TKDD, 10(1):1--31, 2015.Google ScholarDigital Library"",""Cigdem Aslay, Muhammad Anis Uddin Nasir, Gianmarco De Francisci Morales, and Aristides Gionis. Mining frequent patterns in evolving graphs. In CIKM, pages 923--932. ACM, 2018.Google ScholarDigital Library"",""Siddharth Bhatia, Bryan Hooi, Minji Yoon, Kijung Shin, and Christos Faloutsos. MIDAS: Microcluster-Based Detector of Anomalies in Edge Streams. In AAAI, 2020.Google ScholarCross Ref"",""Thomas M Cover and Joy A Thomas. Elements of information theory. Wiley, 2012.Google ScholarDigital Library"",""Haipeng Dai, Muhammad Shahzad, Alex X Liu, and Yuankun Zhong. Finding persistent items in data streams. PVLDB, 10(4):289--300, 2016.Google ScholarDigital Library"",""Mohammed Elseidy, Ehab Abdelhamid, Spiros Skiadopoulos, and Panos Kalnis. Grami: Frequent subgraph and pattern mining in a single large graph. PVLDB, 7(7):517--528, 2014.Google ScholarDigital Library"",""Dhivya Eswaran and Christos Faloutsos. Sedanspot: Detecting anomalies in edge streams. In ICDM, pages 953--958. IEEE, 2018.Google Scholar"",""Wenjie Feng, Shenghua Liu, Danai Koutra, Huawei Shen, and Xueqi Cheng. Unified dense subgraph detection. In ECML/PKDD, 2020.Google Scholar"",""Sudipto Guha, Nina Mishra, Gourav Roy, and Okke Schrijvers. Robust random cut forest based anomaly detection on streams. In ICML, pages 2712--2721, 2016.Google Scholar"",""Saket Gurukar, Sayan Ranu, and Balaraman Ravindran. Commit: A scalable approach to mining communication motifs from dynamic networks. In SIGMOD, pages 475--489. ACM, 2015.Google ScholarDigital Library"",""Chuntao Jiang, Frans Coenen, and Michele Zito. A survey of frequent subgraph mining algorithms. The Knowledge Engineering Review, 28(1):75--105, 2013.Google ScholarCross Ref"",""Chrysanthi Kosyfaki, Nikos Mamoulis, Evaggelia Pitoura, and Panayiotis Tsaparas. Flow motifs in interaction networks. In EDBT, 2018.Google Scholar"",""Lauri Kovanen, Márton Karsai, Kimmo Kaski, János Kertész, and Jari Saram\""aki. Temporal motifs in time-dependent networks. JSTAT, 2011(11):P11005, 2011.Google ScholarCross Ref"",""Jure Leskovec and Andrej Krevl. SNAP Datasets: Stanford large network dataset collection. http://snap.stanford.edu/data, June 2020.Google Scholar"",""Rong-Hua Li, Jiao Su, Lu Qin, Jeffrey Xu Yu, and Qiangqiang Dai. Persistent community search in temporal networks. In ICDE, pages 797--808. IEEE, 2018.Google ScholarCross Ref"",""Richard Lippmann, Robert K Cunningham, David J Fried, Isaac Graf, Kris R Kendall, Seth E Webster, and Marc A Zissman. Results of the darpa 1998 offline intrusion detection evaluation. In RAID, volume 99, pages 829--835, 1999.Google Scholar"",""Paul Liu, Austin R. Benson, and Moses Charikar. Sampling methods for counting temporal motifs. In WSDM, 2019.Google ScholarDigital Library"",""Yike Liu, Tara Safavi, Abhilash Dighe, and Danai Koutra. Graph summarization methods and applications: A survey. ACM Comput. Surv., 51(3), 2018.Google Scholar"",""Ron Milo, Shai S Shen-Orr, Shalev Itzkovitz, Nadav Kashtan, D. Chklovskii, and Uri Alon. Network motifs: simple building blocks of complex networks. Science, 298 5594:824--7, 2002.Google ScholarCross Ref"",""Ashwin Paranjape, Austin R Benson, and Jure Leskovec. Motifs in temporal networks. In WSDM, pages 601--610. ACM, 2017.Google ScholarDigital Library"",""Abhik Ray, Larry Holder, and Sutanay Choudhury. Frequent subgraph discovery in large attributed streaming graphs. In BigMine, pages 166--181, 2014.Google Scholar"",""Konstantinos Semertzidis, Evaggelia Pitoura, Evimaria Terzi, and Panayiotis Tsaparas. Finding lasting dense subgraphs. DAMI, 33(5):1417--1445, 2019.Google Scholar"",""Neil Shah, Danai Koutra, Tianmin Zou, Brian Gallagher, and Christos Faloutsos. Timecrunch: Interpretable dynamic graph summarization. In KDD, pages 1055--1064. ACM, 2015.Google ScholarDigital Library"",""Lorenzo De Stefani, Alessandro Epasto, Matteo Riondato, and Eli Upfal. Triest: Counting local and global triangles in fully dynamic streams with fixed memory size. ACM TKDD, 11(4):1--50, 2017.Google ScholarDigital Library"",""Maciej Walczyszyn, Shalin Patel, Maly Oron, and Bushra Mina. Battling superstorm sandy at lenox hill hospital: When the hospital is ground zero. Critical care clinics, 35(4):711--715, 2019.Google Scholar"",""Qiankun Zhao, Yuan Tian, Qi He, Nuria Oliver, Ruoming Jin, and Wang-Chien Lee. Communication motifs: a tool to characterize social communications. In CIKM. ACM, 2010.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403137,Towards Automated Neural Interaction Discovery for Click-Through Rate Prediction,"Click-Through Rate (CTR) prediction is one of the most important machine learning tasks in recommender systems, driving personalized experience for billions of consumers. Neural architecture search (NAS), as an emerging field, has demonstrated its capabilities in discovering powerful neural network architectures, which motivates us to explore its potential for CTR predictions. Due to 1) diverse unstructured feature interactions, 2) heterogeneous feature space, and 3) high data volume and intrinsic data randomness, it is challenging to construct, search, and compare different architectures effectively for recommendation models. To address these challenges, we propose an automated interaction architecture discovering framework for CTR prediction named AutoCTR. Via modularizing simple yet representative interactions as virtual building blocks and wiring them into a space of direct acyclic graphs, AutoCTR performs evolutionary architecture exploration with learning-to-rank guidance at the architecture level and achieves acceleration using low-fidelity model. Empirical analysis demonstrates the effectiveness of AutoCTR on different datasets comparing to human-crafted architectures. The discovered architecture also enjoys generalizability and transferability among different datasets.","[{""name"":""Qingquan Song"",""id"":""/profile/99659193820""},{""name"":""Dehua Cheng"",""id"":""/profile/99659574275""},{""name"":""Hanning Zhou"",""id"":""/profile/99659573170""},{""name"":""Jiyan Yang"",""id"":""/profile/99659574931""},{""name"":""Yuandong Tian"",""id"":""/profile/99659300719""},{""name"":""Xia Hu"",""id"":""/profile/99659128094""},{""name"":""Qingquan Song"",""id"":""/profile/99659193820""},{""name"":""Dehua Cheng"",""id"":""/profile/99659574275""},{""name"":""Hanning Zhou"",""id"":""/profile/99659573170""},{""name"":""Jiyan Yang"",""id"":""/profile/99659574931""},{""name"":""Yuandong Tian"",""id"":""/profile/99659300719""},{""name"":""Xia Hu"",""id"":""/profile/99659128094""}]","[""Thomas Back. 1994. Selective pressure in evolutionary algorithms: A characterization of selection mechanisms. In WCCI.Google Scholar"",""Tobias Blickle and Lothar Thiele. 1996. A comparison of selection schemes used in evolutionary algorithms. Evolutionary Computation (1996).Google Scholar"",""Christopher JC Burges. 2010. From ranknet to lambdarank to lambdamart: An overview. Learning (2010).Google Scholar"",""Guillaume MJ-B Chaslot, Mark HM Winands, and H Jaap van Den Herik. [n.d.]. Parallel monte-carlo tree search. In ICCG.Google Scholar"",""Yukang Chen, Gaofeng Meng, Qian Zhang, Shiming Xiang, Chang Huang, Lisen Mu, and Xinggang Wang. 2019 a. RENAS: Reinforced Evolutionary Neural Architecture Search. In CVPR.Google Scholar"",""Yi-Wei Chen, Qingquan Song, and Xia Hu. 2019 b. Techniques for Automated Machine Learning. arXiv preprint arXiv:1907.08908 (2019).Google Scholar"",""Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al. 2016. Wide \u0026 deep learning for recommender systems. In RecSys Workshop.Google ScholarDigital Library"",""Thomas Elsken, Jan Hendrik Metzen, and Frank Hutter. 2019. Neural Architecture Search: A Survey. JMLR (2019).Google Scholar"",""Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: a factorization-machine based neural network for CTR prediction. In IJCAI.Google Scholar"",""Xiangnan He and Tat-Seng Chua. 2017. Neural factorization machines for sparse predictive analytics. In SIGIR.Google Scholar"",""Xinran He, Junfeng Pan, Ou Jin, Tianbing Xu, Bo Liu, Tao Xu, Yanxin Shi, Antoine Atallah, Ralf Herbrich, Stuart Bowers, et al. 2014. Practical lessons from predicting clicks on ads at facebook. In ADKDD Workshop.Google ScholarDigital Library"",""Yang Jiang, Cong Zhao, and Lei Pang. 2019. Neural Architecture Refinement: A Practical Way for Avoiding Overfitting in NAS. arXiv:1905.02341 (2019).Google Scholar"",""Haifeng Jin, Qingquan Song, and Xia Hu. 2019. Auto-keras: An efficient neural architecture search system. In SIGKDD.Google Scholar"",""Yuchin Juan, Yong Zhuang, Wei-Sheng Chin, and Chih-Jen Lin. 2016. Field-aware factorization machines for CTR prediction. In RecSys.Google Scholar"",""Liam Li and Ameet Talwalkar. 2019. Random search and reproducibility for neural architecture search. arXiv:1902.07638 (2019).Google Scholar"",""Jianxun Lian, Xiaohuan Zhou, Fuzheng Zhang, Zhongxia Chen, Xing Xie, and Guangzhong Sun. 2018. xdeepfm: Combining explicit and implicit feature interactions for recommender systems. In SIGKDD.Google Scholar"",""Chenxi Liu, Liang-Chieh Chen, Florian Schroff, Hartwig Adam, Wei Hua, Alan Yuille, and Fei-Fei Li. 2019 a. Auto-deeplab: Hierarchical Neural Architecture Search for Semantic Image Segmentation. In CVPR.Google Scholar"",""Hanxiao Liu, Karen Simonyan, and Yiming Yang. 2019 b. DARTS: Differentiable Architecture Search. In ICLR.Google Scholar"",""Qiang Liu, Feng Yu, Shu Wu, and Liang Wang. 2015. A convolutional click prediction model. In CIKM.Google Scholar"",""H Brendan McMahan, Gary Holt, David Sculley, Michael Young, Dietmar Ebner, Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, et al. 2013. Ad click prediction: a view from the trenches. In SIGKDD.Google Scholar"",""Maxim Naumov, Dheevatsa Mudigere, Hao-Jun Michael Shi, Jianyu Huang, Narayanan Sundaraman, Jongsoo Park, Xiaodong Wang, Udit Gupta, Carole-Jean Wu, Alisson G Azzolini, et al. 2019. Deep Learning Recommendation Model for Personalization and Recommendation Systems. arXiv:1906.00091 (2019).Google Scholar"",""Hieu Pham, Melody Guan, Barret Zoph, Quoc Le, and Jeff Dean. 2018. Efficient Neural Architecture Search via Parameters Sharing. In ICML.Google Scholar"",""Yanru Qu, Han Cai, Kan Ren, Weinan Zhang, Yong Yu, Ying Wen, and Jun Wang. 2016. Product-based neural networks for user response prediction. In ICDM.Google Scholar"",""Esteban Real, Alok Aggarwal, Yanping Huang, and Quoc V Le. 2019. Regularized evolution for image classifier architecture search. In AAAI.Google Scholar"",""Esteban Real, Sherry Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon Suematsu, Jie Tan, Quoc V. Le, and Alexey Kurakin. 2017. Large-Scale Evolution of Image Classifiers. In ICML.Google Scholar"",""Steffen Rendle. 2010. Factorization machines. In ICDM.Google Scholar"",""Christian Sciuto, Kaicheng Yu, Martin Jaggi, Claudiu Musat, and Mathieu Salzmann. 2019. Evaluating the search phase of neural architecture search. arXiv:1902.08142 (2019).Google Scholar"",""Weiping Song, Chence Shi, Zhiping Xiao, Zhijian Duan, Yewen Xu, Ming Zhang, and Jian Tang. 2019. Autoint: Automatic feature interaction learning via self-attentive neural networks. In CIKM.Google ScholarDigital Library"",""Linnan Wang, Saining Xie, Teng Li, Rodrigo Fonseca, and Yuandong Tian. 2019. Sample-Efficient Neural Architecture Search by Learning Action Space. arXiv:1906.06832 (2019).Google Scholar"",""Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. 2017. Deep \u0026 cross network for ad click predictions. In ADKDD.Google Scholar"",""Martin Wistuba and Tejaswini Pedapati. 2019. Inductive Transfer for Neural Architecture Optimization. arXiv:1903.03536 (2019).Google Scholar"",""Ling Yan, Wu-Jun Li, Gui-Rong Xue, and Dingyi Han. 2014. Coupled group lasso for web-scale ctr prediction in display advertising. In ICML.Google Scholar"",""Arber Zela, Thomas Elsken, Tonmoy Saikia, Yassine Marrakchi, Thomas Brox, and Frank Hutter. 2020. Understanding and Robustifying Differentiable Architecture Search. ICLR (2020).Google Scholar"",""Byoung-Tak Zhang and Jung-Jib Kim. 2000. Comparison of selection methods for evolutionary optimization. Evolutionary Optimization (2000).Google Scholar"",""Weinan Zhang, Tianming Du, and Jun Wang. 2016. Deep learning over multi-field categorical data. In ECIR.Google Scholar"",""Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through rate prediction. In SIGKDD.Google Scholar"",""Barret Zoph and Quoc V Le. 2017. Neural architecture search with reinforcement learning. In ICLR.Google Scholar"",""Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V Le. 2018. Learning transferable architectures for scalable image recognition. In CVPR.Google Scholar""]"
https://doi.org/10.1145/3394486.3403138,High-Dimensional Similarity Search with Quantum-Assisted Variational Autoencoder,"Recent progress in quantum algorithms and hardware indicates the potential importance of quantum computing in the near future. However, finding suitable application areas remains an active area of research. Quantum machine learning is touted as a potential approach to demonstrate quantum advantage within both the gate-model and the adiabatic schemes. For instance, the Quantum-assisted Variational Autoencoder (QVAE) has been proposed as a quantum enhancement to the discrete VAE. We extend on previous work and study the real-world applicability of a QVAE by presenting a proof-of-concept for similarity search in large-scale high-dimensional datasets. While exact and fast similarity search algorithms are available for low dimensional datasets, scaling to high-dimensional data is non-trivial. We show how to construct a space-efficient search index based on the latent space representation of a QVAE. Our experiments show a correlation between the Hamming distance in the embedded space and the Euclidean distance in the original space on the Moderate Resolution Imaging Spectroradiometer (MODIS) dataset.Further, we find real-world speedups compared to linear search and demonstrate memory-efficient scaling to half a billion data points.","[{""name"":""Nicholas Gao"",""id"":""/profile/99659575208""},{""name"":""Max Wilson"",""id"":""/profile/99659575049""},{""name"":""Thomas Vandal"",""id"":""/profile/99659193778""},{""name"":""Walter Vinci"",""id"":""/profile/99659573253""},{""name"":""Ramakrishna Nemani"",""id"":""/profile/82658638957""},{""name"":""Eleanor Rieffel"",""id"":""/profile/81100157332""},{""name"":""Nicholas Gao"",""id"":""/profile/99659575208""},{""name"":""Max Wilson"",""id"":""/profile/99659575049""},{""name"":""Thomas Vandal"",""id"":""/profile/99659193778""},{""name"":""Walter Vinci"",""id"":""/profile/99659573253""},{""name"":""Ramakrishna Nemani"",""id"":""/profile/82658638957""},{""name"":""Eleanor Rieffel"",""id"":""/profile/81100157332""}]","[""J. Biamonte, P. Wittek, N. Pancotti, P. Rebentrost, N. Wiebe, and S. Lloyd, \""Quantum machine learning,\"" Nature, vol. 549, no. 7671, pp. 195--202, 2017.Google ScholarCross Ref"",""S. Lloyd, M. Mohseni, and P. Rebentrost, \""Quantum principal component analysis,\"" Nature Physics, vol. 10, no. 9, pp. 631--633, 2014.Google ScholarCross Ref"",""P. Rebentrost, M. Mohseni, and S. Lloyd, \""Quantum support vector machine for big data classification,\"" Physical review letters, vol. 113, no. 13, p. 130503, 2014.Google ScholarCross Ref"",""A. Mott, J. Job, J.-R. Vlimant, D. Lidar, and M. Spiropulu, \""Solving a higgs optimization problem with quantum annealing for machine learning,\"" Nature, vol. 550, no. 7676, pp. 375--379, 2017.Google ScholarCross Ref"",""W. Vinci, L. Buffoni, H. Sadeghi, A. Khoshaman, E. Andriyash, and M. H. Amin, \""A path towards quantum advantage in training deep generative models with quantum annealers,\"" arXiv preprint arXiv:1912.02119, 2019.Google Scholar"",""A. Khoshaman, W. Vinci, B. Denis, E. Andriyash, and M. H. Amin, \""Quantum variational autoencoder,\"" Quantum Science and Technology, vol. 4, no. 1, p. 014001, 2018.Google ScholarCross Ref"",""J. T. Rolfe, \""Discrete Variational Autoencoders,\"" arXiv:1609.02200 [cs, stat], Sept. 2016. arXiv: 1609.02200.Google Scholar"",""J. Preskill, \""Quantum computing in the nisq era and beyond,\"" Quantum, vol. 2, p. 79, 2018.Google ScholarCross Ref"",""F. Arute, K. Arya, R. Babbush, D. Bacon, J. C. Bardin, R. Barends, R. Biswas, S. Boixo, F. G. Brandao, D. A. Buell, et al., \""Quantum supremacy using a programmable superconducting processor,\"" Nature, vol. 574, no. 7779, pp. 505--510, 2019.Google ScholarCross Ref"",""D. P. Kingma and M. Welling, \""Auto-encoding variational bayes,\"" arXiv preprint arXiv:1312.6114, 2013.Google Scholar"",""M. H. Amin, E. Andriyash, J. Rolfe, B. Kulchytskyy, and R. Melko, \""Quantum boltzmann machine,\"" Physical Review X, vol. 8, no. 2, p. 021050, 2018.Google ScholarCross Ref"",""P. Long and R. Servedio, \""Restricted Boltzmann Machines are Hard to Approximately Evaluate or Simulate ,\"" in ICML 2010 - Proceedings, 27th International Conference on Machine Learning , pp. 703--710, Aug. 2010.Google Scholar"",""W. Li, Y. Zhang, Y. Sun, W. Wang, W. Zhang, and X. Lin, \""Approximate Nearest Neighbor Search on High Dimensional Data -- Experiments , Analyses, and Improvement (v1.0),\"" arXiv:1610.02455 [cs], Oct. 2016.Google Scholar"",""A. Camerra, J. Shieh, T. Palpanas, T. Rakthanmanon, and E. Keogh, \""Beyond one billion time series: indexing and mining very large time series collections with isax2+,\"" Knowledge and information systems, vol. 39, no. 1, pp. 123--151, 2014.Google Scholar"",""J. Johnson, M. Douze, and H. Jégou, \""Billion-scale similarity search with GPUs ,\"" arXiv:1702.08734 [cs], Feb. 2017.Google Scholar"",""D. E. Yagoubi, R. Akbarinia, F. Masseglia, and D. Shasha, \""RadiusSketch: Massively distributed indexing of time series,\"" in 2017 IEEE International Conference on Data Science and Advanced Analytics (DSAA), pp. 262--271, IEEE, 2017.Google Scholar"",""T.-T. Do, A.-D. Doan, and N.-M. Cheung, \""Learning to Hash with Binary Deep Neural Network,\"" arXiv:1607.05140 [cs], July 2016. arXiv: 1607.05140.Google Scholar"",""N. Srivastava, E. Mansimov, and R. Salakhutdinov, \""Unsupervised Learning of Video Representations using LSTMs,\"" arXiv:1502.04681 [cs], Feb. 2015. arXiv: 1502.04681.Google Scholar"",""M. A. Carreira-Perpinan and R. Raziperchikolaei, \""Hashing with binary autoencoders,\"" in 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), (Boston, MA, USA), pp. 557--566, IEEE, June 2015.Google Scholar"",""Y. Cao, M. Long, J. Wang, and H. Zhu, \""Correlation autoencoder hashing for supervised cross-modal search,\"" in Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval - ICMR '16, pp. 197--204, ACM Press, 2016.Google Scholar"",""S. S. Board, N. R. Council, et al., Earth science and applications from space: national imperatives for the next decade and beyond. National Academies Press, 2007.Google Scholar"",""R. Wright, L. Flynn, H. Garbeil, A. Harris, and E. Pilger, \""Automated volcanic eruption detection using modis,\"" Remote sensing of environment, vol. 82, no. 1, pp. 135--155, 2002.Google ScholarCross Ref"",""X. Zhang, M. A. Friedl, C. B. Schaaf, A. H. Strahler, J. C. Hodges, F. Gao, B. C. Reed, and A. Huete, \""Monitoring vegetation phenology using modis,\"" Remote sensing of environment, vol. 84, no. 3, pp. 471--475, 2003.Google ScholarCross Ref"",""L. A. Remer, Y. Kaufman, D. Tanré, S. Mattoo, D. Chu, J. V. Martins, R.-R. Li, C. Ichoku, R. Levy, R. Kleidman, et al., \""The modis aerosol algorithm, products, and validation,\"" Journal of the atmospheric sciences, vol. 62, no. 4, pp. 947--973, 2005.Google ScholarCross Ref"",""S. Boriah, V. Kumar, C. Potter, M. Steinbach, and S. Klooster, \""Land cover change detection using data mining techniques,\"" Technical Report March 14, 2008.Google Scholar"",""K. Steinhaeuser, A. R. Ganguly, and N. V. Chawla, \""Multivariate and multiscale dependence in the global climate system revealed through complex networks,\"" Climate dynamics, vol. 39, no. 3--4, pp. 889--895, 2012.Google Scholar"",""C. Kamath, \""On mining scientific datasets,\"" in Data Mining for Scientific and Engineering Applications, pp. 1--21, Springer, 2001.Google Scholar"",""D. Zhou, A. Gozolchiani, Y. Ashkenazy, and S. Havlin, \""Teleconnection paths via climate network direct link detection,\"" Physical review letters, vol. 115, no. 26, p. 268501, 2015.Google ScholarCross Ref"",""P. Indyk and R. Motwani, \""Approximate nearest neighbors: towards removing the curse of dimensionality,\"" in Proceedings of the thirtieth annual ACM symposium on Theory of computing, pp. 604--613, ACM, 1998.Google Scholar"",""A. Gionis, P. Indyk, and R. Motwani, \""Similarity search in high dimensions via hashing,\"" in Vldb, vol. 99, pp. 518--529, 1999.Google ScholarDigital Library"",""M. D. Hoffman, D. M. Blei, C. Wang, and J. Paisley, \""Stochastic variational inference,\"" The Journal of Machine Learning Research, vol. 14, no. 1, pp. 1303--1347, 2013.Google ScholarDigital Library"",""A. H. Khoshaman and M. Amin, \""Gumbolt: extending gumbel trick to boltzmann priors,\"" in Advances in Neural Information Processing Systems, pp. 4061--4070, 2018.Google Scholar"",""M. D. Hoffman and M. J. Johnson, \""Elbo surgery: Yet another way to carve up the variational evidence lower bound,\"" in Workshop in Advances in Approximate Bayesian Inference, NIPS , vol. 1, p. 2, 2016.Google Scholar"",""C. K. Sø nderby, T. Raiko, L. Maalø e, S. r. K. Sø nderby, and O. Winther, \""Ladder Variational Autoencoders ,\"" in Advances in Neural Information Processing Systems 29 (D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett, eds.), pp. 3738--3746, Curran Associates, Inc., 2016.Google Scholar"",""F. P. Casale, A. Dalca, L. Saglietti, J. Listgarten, and N. Fusi, \""Gaussian Process Prior Variational Autoencoders ,\"" in Advances in Neural Information Processing Systems 31 (S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, eds.), pp. 10369--10380, Curran Associates, Inc., 2018.Google Scholar"",""G. E. Hinton, \""Training products of experts by minimizing contrastive divergence,\"" Neural computation, vol. 14, no. 8, pp. 1771--1800, 2002.Google ScholarDigital Library"",""T. Tieleman and G. Hinton, \""Using fast weights to improve persistent contrastive divergence,\"" in Proceedings of the 26th Annual International Conference on Machine Learning, pp. 1033--1040, 2009.Google Scholar"",""D. Koller, N. Friedman, L. Getoor, and B. Taskar, \""Graphical models in a nutshell,\"" Introduction to statistical relational learning, pp. 13--55, 2007.Google Scholar"",""E. G. Rieffel, S. Hadfield, T. Hogg, S. Mandrà, J. Marshall, G. Mossi, B. O'Gorman, E. Plamadeala, N. M. Tubman, D. Venturelli, et al., \""From ans\""atze to z-gates: a NASA view of quantum computing,\"" arXiv preprint arXiv:1905.02860, 2019.Google Scholar"",""T. F. Rønnow, Z. Wang, J. Job, S. Boixo, S. V. Isakov, D. Wecker, J. M. Martinis, D. A. Lidar, and M. Troyer, \""Defining and detecting quantum speedup,\"" Science, vol. 345, no. 6195, pp. 420--424, 2014.Google ScholarCross Ref"",""H. G. Katzgraber, F. Hamze, and R. S. Andrist, \""Glassy chimeras could be blind to quantum speedup: Designing better benchmarks for quantum annealing machines,\"" Physical Review X, vol. 4, no. 2, p. 021008, 2014.Google ScholarCross Ref"",""R. Biswas, Z. Jiang, K. Kechezhi, S. Knysh, S. Mandra, B. O'Gorman, A. Perdomo-Ortiz, A. Petukhov, J. Realpe-Gómez, E. Rieffel, et al., \""A NASA perspective on quantum computing: Opportunities and challenges,\"" Parallel Computing, vol. 64, pp. 81--98, 2017.Google ScholarDigital Library"",""S. H. Adachi and M. P. Henderson, \""Application of quantum annealing to training of deep neural networks,\"" arXiv preprint arXiv:1510.06356, 2015.Google Scholar"",""D. P. Kingma and J. Ba, \""Adam: A Method for Stochastic Optimization ,\"" arXiv:1412.6980 [cs], Jan. 2017.Google Scholar"",""E. Gull, A. J. Millis, A. I. Lichtenstein, A. N. Rubtsov, M. Troyer, and P. Werner, \""Continuous-time monte carlo methods for quantum impurity models,\"" Reviews of Modern Physics, vol. 83, no. 2, p. 349, 2011.Google ScholarCross Ref"",""C. O. Justice, E. Vermote, J. R. Townshend, R. Defries, D. P. Roy, D. K. Hall, V. V. Salomonson, J. L. Privette, G. Riggs, A. Strahler, et al., \""The moderate resolution imaging spectroradiometer (modis): Land remote sensing for global change research,\"" IEEE transactions on geoscience and remote sensing, vol. 36, no. 4, pp. 1228--1249, 1998.Google Scholar"",""R. Solano, K. Didan, A. Jacobson, and A. Huete, \""Modis vegetation index user's guide (mod13 series),\"" Vegetation Index and Phenology Lab, The University of Arizona, pp. 1--38, 2010.Google Scholar"",""Y. A. Malkov and D. A. Yashunin, \""Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs,\"" arXiv:1603.09320 [cs], Aug. 2018.Google Scholar"",""J. Marshall, A. Di Gioacchino, and E. G. Rieffel, \""The Perils of Embedding for Sampling Problems,\"" arXiv:1909.12184 [cond-mat, physics:quant-ph], Sept. 2019.Google Scholar""]"
https://doi.org/10.1145/3394486.3403139,Off-policy Bandits with Deficient Support,"Learning effective contextual-bandit policies from past actions of a deployed system is highly desirable in many settings (e.g. voice assistants, recommendation, search), since it enables the reuse of large amounts of log data. State-of-the-art methods for such off-policy learning, however, are based on inverse propensity score (IPS) weighting. A key theoretical requirement of IPS weighting is that the policy that logged the data has ""full support"", which typically translates into requiring non-zero probability for any action in any context. Unfortunately, many real-world systems produce support deficient data, especially when the action space is large, and we show how existing methods can fail catastrophically. To overcome this gap between theory and applications, we identify three approaches that provide various guarantees for IPS-based learning despite the inherent limitations of support-deficient data: restricting the action space, reward extrapolation, and restricting the policy space. We systematically analyze the statistical and computational properties of these three approaches, and we empirically evaluate their effectiveness. In addition to providing the first systematic analysis of support-deficiency in contextual-bandit learning, we conclude with recommendations that provide practical guidance.","[{""name"":""Noveen Sachdeva"",""id"":""/profile/99659310088""},{""name"":""Yi Su"",""id"":""/profile/99659574415""},{""name"":""Thorsten Joachims"",""id"":""/profile/81100184551""},{""name"":""Noveen Sachdeva"",""id"":""/profile/99659310088""},{""name"":""Yi Su"",""id"":""/profile/99659574415""},{""name"":""Thorsten Joachims"",""id"":""/profile/81100184551""}]","[""Alekh Agarwal, Daniel Hsu, Satyen Kale, John Langford, Lihong Li, and Robert Schapire. 2014. Taming the monster: A fast and simple algorithm for contextual bandits. In ICML.Google Scholar"",""Alina Beygelzimer and John Langford. 2009. The offset tree for learning with partial labels. In KDD. ACM, 129--138.Google Scholar"",""Léon Bottou, Jonas Peters, Joaquin Qui nonero-Candela, Denis X Charles, D Max Chickering, Elon Portugaly, Dipankar Ray, Patrice Simard, and Ed Snelson. 2013. Counterfactual reasoning and learning systems: The example of computational advertising. JMLR, Vol. 14, 1 (2013), 3207--3260.Google ScholarDigital Library"",""Andrea Dal Pozzolo, Olivier Caelen, Reid A Johnson, and Gianluca Bontempi. 2015. Calibrating probability with undersampling for unbalanced classification. In 2015 SSCI. IEEE, 159--166.Google Scholar"",""Miroslav Dud'ik, John Langford, and Lihong Li. 2011. Doubly Robust Policy Evaluation and Learning. In ICML.Google Scholar"",""Mehrdad Farajtabar, Yinlam Chow, and Mohammad Ghavamzadeh. 2018. More Robust Doubly Robust Off-policy Evaluation. In ICML. 1446--1455.Google Scholar"",""Scott Fujimoto, David Meger, and Doina Precup. 2018. Off-policy deep reinforcement learning without exploration. arXiv preprint arXiv:1812.02900 (2018).Google Scholar"",""Evan Greensmith, Peter L Bartlett, and Jonathan Baxter. 2004. Variance reduction techniques for gradient estimates in reinforcement learning. JMLR, Vol. 5, Nov (2004), 1471--1530.Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In CVPR. 770--778.Google Scholar"",""Nan Jiang and Lihong Li. 2016. Doubly Robust Off-policy Value Evaluation for Reinforcement Learning. In ICML. 652--661.Google Scholar"",""T. Joachims, A. Swaminathan, and M. de Rijke. 2018. Deep Learning with Logged Bandit Feedback. In ICLR.Google Scholar"",""T. Joachims, A. Swaminathan, and T. Schnabel. 2017. Unbiased Learning-to-Rank with Biased Feedback. In WSDM.Google Scholar"",""Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. 2014. The cifar-10 dataset. online: http://www. cs. toronto. edu/kriz/cifar. html, Vol. 55 (2014).Google Scholar"",""Aviral Kumar, Justin Fu, Matthew Soh, George Tucker, and Sergey Levine. 2019. Stabilizing off-policy q-learning via bootstrapping error reduction. In NeurIPS. 11761--11771.Google Scholar"",""John Langford and Tong Zhang. 2008. The epoch-greedy algorithm for multi-armed bandits with side information. In NeurIPS. 817--824.Google Scholar"",""Romain Laroche, Paul Trichelair, and Rémi Tachet des Combes. 2017. Safe policy improvement with baseline bootstrapping. arXiv preprint arXiv:1712.06924 (2017).Google Scholar"",""Lihong Li, Shunbao Chen, Jim Kleban, and Ankur Gupta. 2015. Counterfactual estimation and optimization of click metrics in search engines: A case study. In WWW. ACM, 929--934.Google Scholar"",""Lihong Li, Wei Chu, John Langford, and Xuanhui Wang. 2011. Unbiased offline evaluation of contextual-bandit-based news article recommendation algorithms. In WSDM. ACM, 297--306.Google Scholar"",""Yao Liu, Adith Swaminathan, Alekh Agarwal, and Emma Brunskill. 2019. Off-Policy Policy Gradient with State Distribution Correction. arXiv preprint arXiv:1904.08473 (2019).Google Scholar"",""Ben London and Ted Sandler. 2019. Bayesian Counterfactual Risk Minimization. In ICML. 4125--4133.Google Scholar"",""Alex Strehl, John Langford, Lihong Li, and Sham M Kakade. 2011. Learning from Logged Implicit Exploration Data. In NeurIPS.Google Scholar"",""Yi Su, Lequn Wang, Michele Santacatterina, and Thorsten Joachims. 2019. CAB: Continuous Adaptive Blending for Policy Evaluation and Learning. In ICML. 6005--6014.Google Scholar"",""Richard S Sutton and Andrew G Barto. 2018. Reinforcement learning: An introduction .MIT press.Google Scholar"",""A. Swaminathan and T. Joachims. 2015a. Batch Learning from Logged Bandit Feedback through Counterfactual Risk Minimization. JMLR, Vol. 16 (Sep 2015), 1731--1755. Special Issue in Memory of Alexey Chervonenkis.Google Scholar"",""A. Swaminathan and T. Joachims. 2015b. The Self-Normalized Estimator for Counterfactual Learning. In NeurIPS.Google Scholar"",""Philip Thomas and Emma Brunskill. 2016. Data-efficient Off-policy Policy Evaluation for Reinforcement Learning. In ICML.Google Scholar"",""Yu-Xiang Wang, Alekh Agarwal, and Miroslav Dudik. 2017. Optimal and Adaptive Off-policy Evaluation in Contextual Bandits. In ICML.Google Scholar"",""Christopher JCH Watkins and Peter Dayan. 1992. Q-learning. Machine learning, Vol. 8, 3--4 (1992), 279--292.Google Scholar"",""Ronald J Williams. 1992. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning, Vol. 8, 3--4 (1992), 229--256.Google Scholar""]"
https://doi.org/10.1145/3394486.3403140,Adaptive Graph Encoder for Attributed Graph Embedding,"Attributed graph embedding, which learns vector representations from graph topology and node features, is a challenging task for graph analysis. Recently, methods based on graph convolutional networks (GCNs) have made great progress on this task. However,existing GCN-based methods have three major drawbacks. Firstly,our experiments indicate that the entanglement of graph convolutional filters and weight matrices will harm both the performance and robustness. Secondly, we show that graph convolutional filters in these methods reveal to be special cases of generalized Laplacian smoothing filters, but they do not preserve optimal low-pass characteristics. Finally, the training objectives of existing algorithms are usually recovering the adjacency matrix or feature matrix, which are not always consistent with real-world applications. To address these issues, we propose Adaptive Graph Encoder (AGE), a novel attributed graph embedding framework. AGE consists of two modules: (1) To better alleviate the high-frequency noises in the node features, AGE first applies a carefully-designed Laplacian smoothing filter. (2) AGE employs an adaptive encoder that iteratively strengthens the filtered features for better node embeddings. We conduct experiments using four public benchmark datasets to validate AGE on node clustering and link prediction tasks. Experimental results show that AGE consistently outperforms state-of-the-artgraph embedding methods considerably on these tasks.","[{""name"":""Ganqu Cui"",""id"":""/profile/99659574927""},{""name"":""Jie Zhou"",""id"":""/profile/99659572975""},{""name"":""Cheng Yang"",""id"":""/profile/99659575127""},{""name"":""Zhiyuan Liu"",""id"":""/profile/81418597384""},{""name"":""Ganqu Cui"",""id"":""/profile/99659574927""},{""name"":""Jie Zhou"",""id"":""/profile/99659572975""},{""name"":""Cheng Yang"",""id"":""/profile/99659575127""},{""name"":""Zhiyuan Liu"",""id"":""/profile/81418597384""}]","[""Yoshua Bengio, Jérôme Louradour, Ronan Collobert, and Jason Weston. 2009. Curriculum learning. In Proceedings of ICML. 41--48.Google ScholarDigital Library"",""Aleksandar Bojchevski and Stephan Günnemann. 2018. Bayesian robust attributed graph clustering: Joint learning of partial anomalies and group structure. In Proceedings of AAAI. 2738--2745.Google Scholar"",""Shaosheng Cao, Wei Lu, and Qiongkai Xu. 2015. Grarep: Learning graph representations with global structural information. In Proceedings of CIKM. 891--900.Google ScholarDigital Library"",""Shaosheng Cao, Wei Lu, and Qiongkai Xu. 2016. Deep neural networks for learning graph representations. In Proceedings of AAAI. 1145--1152.Google Scholar"",""Jonathan Chang and David Blei. 2009. Relational topic models for document networks. In Artificial Intelligence and Statistics. 81--88.Google Scholar"",""Jianlong Chang, Lingfeng Wang, Gaofeng Meng, Shiming Xiang, and Chunhong Pan. 2017. Deep adaptive image clustering. In Proceedings of ICCV. 5879--5887.Google ScholarCross Ref"",""Fan RK Chung and Fan Chung Graham. 1997. Spectral graph theory. American Mathematical Soc.Google Scholar"",""David L Davies and DonaldWBouldin. 1979. A cluster separation measure. IEEE transactions on pattern analysis and machine intelligence 2 (1979), 224--227.Google Scholar"",""Guojun Gan, Chaoqun Ma, and Jianhong Wu. 2007. Data clustering: Theory, algorithms, and applications. Vol. 20. Siam.Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In Proceedings of SIGKDD. 855--864.Google ScholarDigital Library"",""William L. Hamilton, Rex Ying, and Jure Leskovec. 2017. Representation learning on graphs: Methods and applications. IEEE Data(base) Engineering Bulletin 40, 3 (2017), 52--74.Google Scholar"",""Matthew B Hastings. 2006. Community detection as an inference problem. Physical Review E 74, 3 (2006), 035--102.Google ScholarCross Ref"",""Roger A Horn and Charles R Johnson. 2012. Matrix analysis. Cambridge university press.Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2015. Adam: A method for stochastic optimization. In Proceedings of ICLR. 15.Google Scholar"",""Thomas N Kipf and Max Welling. 2016. Variational graph auto-encoders. In NIPS Workshop on Bayesian Deep Learning. 3.Google Scholar"",""Thomas N Kipf and MaxWelling. 2017. Semi-supervised classification with graph convolutional networks. In Proceedings of ICLR. 14.Google Scholar"",""Quoc Le and Tomas Mikolov. 2014. Distributed representations of sentences and documents. In Proceedings of ICML. 1188--1196.Google Scholar"",""Qimai Li, Zhichao Han, and Xiao-Ming Wu. 2018. Deeper insights into graph convolutional networks for semi-supervised learning. In Proceedings of AAAI. 3538--3545.Google Scholar"",""Ye Li, Chaofeng Sha, Xin Huang, and Yanchun Zhang. 2018. Community detection in attributed graphs: an embedding approach. In Proceedings of AAAI. 338--345.Google Scholar"",""Stuart Lloyd. 1982. Least squares quantization in PCM. IEEE transactions on information theory 28, 2 (1982), 129--137.Google Scholar"",""Mark EJ Newman. 2006. Finding community structure in networks using the eigenvectors of matrices. Physical review E 74, 3 (2006), 036--104.Google Scholar"",""Andrew Y Ng, Michael I Jordan, and Yair Weiss. 2002. On spectral clustering: Analysis and an algorithm. In Proceedings of NIPS. 849--856.Google Scholar"",""Shirui Pan, Ruiqi Hu, Guodong Long, Jing Jiang, Lina Yao, and Chengqi Zhang. 2018. Adversarially regularized graph autoencoder for graph embedding. In Proceedings of IJCAI. 2609--2615.Google ScholarCross Ref"",""Jiwoong Park, Minsik Lee, Hyung Jin Chang, Kyuewang Lee, and Jin Young Choi. 2019. Symmetric graph convolutional autoencoder for unsupervised graph representation learning. In Proceedings of ICCV. 6519--6528.Google ScholarCross Ref"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In Proceedings of SIGKDD. 701--710.Google ScholarDigital Library"",""Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, and Tina Eliassi-Rad. 2008. Collective classification in network data. AI magazine 29, 3 (2008), 93--93.Google Scholar"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. In Proceedings ofWWW. 1067--1077.Google ScholarDigital Library"",""Gabriel Taubin. 1995. A signal processing approach to fair surface design. In Proceedings of the 22nd annual conference on Computer graphics and interactive techniques. 351--358.Google ScholarDigital Library"",""Laurens Van Der Maaten. 2014. Accelerating t-SNE using tree-based algorithms. The journal of machine learning research 15, 1 (2014), 3221--3245.Google Scholar"","", Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2018. Graph attention networks. In Proceedings of ICLR. 8.Google Scholar"",""ChunWang, Shirui Pan, Ruiqi Hu, Guodong Long, Jing Jiang, and Chengqi Zhang. 2019. Attributed graph clustering: A deep attentional embedding approach. In Proceedings of IJCAI. 3670--3676.Google Scholar"",""Chun Wang, Shirui Pan, Guodong Long, Xingquan Zhu, and Jing Jiang. 2017. Mgae: Marginalized graph autoencoder for graph clustering. In Proceedings of CIKM. 889--898.Google ScholarDigital Library"",""Daixin Wang, Peng Cui, and Wenwu Zhu. 2016. Structural deep network embedding. In Proceedings of SIGKDD. 1225--1234.Google ScholarDigital Library"",""Xiao Wang, Di Jin, Xiaochun Cao, Liang Yang, and Weixiong Zhang. 2016. Semantic community identification in large attribute networks. In Proceedings of AAAI. 265--271.Google Scholar"",""Felix Wu, Tianyi Zhang, Amauri Holanda de Souza Jr, Christopher Fifty, Tao Yu, and Kilian Q Weinberger. 2019. Simplifying graph convolutional networks. In Proceedings of ICML. 6861--6871.Google Scholar"",""Cheng Yang, Zhiyuan Liu, Deli Zhao, Maosong Sun, and Edward Chang. 2015. Network representation learning with rich text information. In Proceedings of IJCAI. 2111--2117.Google Scholar"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale recommender systems. In Proceedings of SIGKDD. 974--983.Google ScholarDigital Library"",""Xiaotong Zhang, Han Liu, Qimai Li, and Xiao-Ming Wu. 2019. Attributed graph clustering via adaptive graph convolution. In Proceedings of IJCAI. 4327--4333.Google ScholarCross Ref"",""Jie Zhou, Ganqu Cui, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li, and Maosong Sun. 2018. Graph neural networks: A review of methods and applications. arXiv preprint arXiv:1812.08434 (2018).Google Scholar""]"
https://doi.org/10.1145/3394486.3403141,NetTrans: Neural Cross-Network Transformation,"Finding node associations across different networks is the cornerstone behind a wealth of high-impact data mining applications. Traditional approaches are often, explicitly or implicitly, built upon the linearity and/or consistency assumptions. On the other hand, the recent network embedding based methods promise a natural way to handle the non-linearity, yet they could suffer from the disparate node embedding space of different networks. In this paper, we address these limitations and tackle cross-network node associations from a new angle, i.e., cross-network transformation. We ask a generic question: Given two different networks, how can we transform one network to another? We propose an end-to-end model that learns a composition of nonlinear operations so that one network can be transformed to another in a hierarchical manner. The proposed model bears three distinctive advantages. First (composite transformation), it goes beyond the linearity/consistency assumptions and performs the cross-network transformation through a composition of nonlinear computations. Second (representation power), it can learn the transformation of both network structures and node attributes at different resolutions while identifying the cross-network node associations. Third (generality), it can be applied to various tasks, including network alignment, recommendation, cross-layer dependency inference. Extensive experiments on different tasks validate and verify the effectiveness of the proposed model.","[{""name"":""Si Zhang"",""id"":""/profile/99659061581""},{""name"":""Hanghang Tong"",""id"":""/profile/81337494052""},{""name"":""Yinglong Xia"",""id"":""/profile/99659478024""},{""name"":""Liang Xiong"",""id"":""/profile/99659575121""},{""name"":""Jiejun Xu"",""id"":""/profile/89758726257""},{""name"":""Si Zhang"",""id"":""/profile/99659061581""},{""name"":""Hanghang Tong"",""id"":""/profile/81337494052""},{""name"":""Yinglong Xia"",""id"":""/profile/99659478024""},{""name"":""Liang Xiong"",""id"":""/profile/99659575121""},{""name"":""Jiejun Xu"",""id"":""/profile/89758726257""}]","[""Chen Chen, Hanghang Tong, Lei Xie, Lei Ying, and Qing He. 2016. FASCINATE: fast cross-layer dependency inference on multi-layered networks. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 765--774.Google ScholarDigital Library"",""Jiawei Chen, Can Wang, Sheng Zhou, Qihao Shi, Yan Feng, and Chun Chen. 2019. Samwalker: Social recommendation with informative sampling strategy. In The World Wide Web Conference. 228--239.Google ScholarDigital Library"",""Xiaokai Chu, Xinxin Fan, Di Yao, Zhihua Zhu, Jianhui Huang, and Jingping Bi. 2019. Cross-Network Embedding for Multi-Network Alignment. In The World Wide Web Conference. 273--284.Google Scholar"",""Boxin Du and Hanghang Tong. 2018. FASTEN: Fast Sylvester equation solver for graph mining. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1339--1347.Google ScholarDigital Library"",""Boxin Du and Hanghang Tong. 2019. MrMine: Multi-resolution Multi-network Embedding. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management. 479--488.Google ScholarDigital Library"",""Wenqi Fan, Yao Ma, Qing Li, Yuan He, Eric Zhao, Jiliang Tang, and Dawei Yin. 2019 a. Graph neural networks for social recommendation. In The World Wide Web Conference. 417--426.Google ScholarDigital Library"",""Wenqi Fan, Yao Ma, Dawei Yin, Jianping Wang, Jiliang Tang, and Qing Li. 2019 b. Deep social collaborative filtering. In Proceedings of the 13th ACM Conference on Recommender Systems. 305--313.Google ScholarDigital Library"",""Matthias Fey and Jan Eric Lenssen. 2019. Fast graph representation learning with PyTorch Geometric. arXiv preprint arXiv:1903.02428 (2019).Google Scholar"",""Hongyang Gao and Shuiwang Ji. 2019. Graph u-nets. arXiv preprint arXiv:1905.05178 (2019).Google Scholar"",""Xiaojie Guo, Liang Zhao, Cameron Nowzari, Setareh Rafatirad, Houman Homayoun, and Sai Manoj Pudukotai Dinakarrao. 2019. Deep Multi-attributed Graph Translation with Node-Edge Co-evolution. In The 19th International Conference on Data Mining (ICDM 2019), pp. to appear .Google Scholar"",""Mark Heimann, Haoming Shen, Tara Safavi, and Danai Koutra. 2018. Regal: Representation learning-based graph alignment. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management. 117--126.Google ScholarDigital Library"",""Eric Jang, Shixiang Gu, and Ben Poole. 2016. Categorical reparameterization with gumbel-softmax. arXiv preprint arXiv:1611.01144 (2016).Google Scholar"",""Wengong Jin, Kevin Yang, Regina Barzilay, and Tommi Jaakkola. 2018. Learning multimodal graph-to-graph translation for molecular optimization. arXiv preprint arXiv:1812.01070 (2018).Google Scholar"",""Jian Kang and Hanghang Tong. 2019. N2N: Network Derivative Mining. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management. 861--870.Google ScholarDigital Library"",""Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).Google Scholar"",""Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix factorization techniques for recommender systems. Computer, Vol. 42, 8 (2009), 30--37.Google ScholarDigital Library"",""Danai Koutra, Hanghang Tong, and David Lubensky. 2013. Big-align: Fast bipartite graph alignment. In 2013 IEEE 13th International Conference on Data Mining. IEEE, 389--398.Google ScholarCross Ref"",""Quoc Le and Tomas Mikolov. 2014. Distributed representations of sentences and documents. In International conference on machine learning. 1188--1196.Google ScholarDigital Library"",""Junhyun Lee, Inyeop Lee, and Jaewoo Kang. 2019. Self-attention graph pooling. arXiv preprint arXiv:1904.08082 (2019).Google Scholar"",""Jundong Li, Chen Chen, Hanghang Tong, and Huan Liu. 2018. Multi-layered network embedding. In Proceedings of the 2018 SIAM International Conference on Data Mining. SIAM, 684--692.Google ScholarCross Ref"",""Li Liu, William K Cheung, Xin Li, and Lejian Liao. 2016. Aligning Users across Social Networks Using Network Embedding.. In Ijcai. 1774--1780.Google Scholar"",""Qiao Liu, Chen Chen, Annie Gao, Hang Hang Tong, and Lei Xie. 2017. VariFunNet, an integrated multiscale modeling framework to study the effects of rare non-coding variants in genome-wide association studies: Applied to Alzheimer's disease. In 2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). IEEE, 2177--2182.Google ScholarCross Ref"",""Zhining Liu, Dawei Zhou, and Jingrui He. 2019. Towards Explainable Representation of Time-Evolving Graphs via Spatial-Temporal Graph Attention Networks. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management. 2137--2140.Google ScholarDigital Library"",""Hao Ma, Haixuan Yang, Michael R Lyu, and Irwin King. 2008. Sorec: social recommendation using probabilistic matrix factorization. In Proceedings of the 17th ACM conference on Information and knowledge management. 931--940.Google ScholarDigital Library"",""Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2012. BPR: Bayesian personalized ranking from implicit feedback. arXiv preprint arXiv:1205.2618 (2012).Google Scholar"",""Dorit Ron, Ilya Safro, and Achi Brandt. 2011. Relaxation-based coarsening and multiscale graph organization. Multiscale Modeling \u0026 Simulation, Vol. 9, 1 (2011), 407--423.Google ScholarCross Ref"",""Jiliang Tang, Huiji Gao, and Huan Liu. 2012. mTrust: discerning multi-faceted trust in a connected world. In Proceedings of the fifth ACM international conference on Web search and data mining. 93--102.Google ScholarDigital Library"",""Jie Tang, Jing Zhang, Limin Yao, Juanzi Li, Li Zhang, and Zhong Su. 2008. Arnetminer: extraction and mining of academic social networks. In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. 990--998.Google ScholarDigital Library"",""Shinji Umeyama. 1988. An eigendecomposition approach to weighted graph matching problems. IEEE transactions on pattern analysis and machine intelligence, Vol. 10, 5 (1988), 695--703.Google Scholar"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph attention networks. arXiv preprint arXiv:1710.10903 (2017).Google Scholar"",""Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019. Neural graph collaborative filtering. In Proceedings of the 42nd international ACM SIGIR conference on Research and development in Information Retrieval. 165--174.Google ScholarDigital Library"",""Bo Yang, Yu Lei, Jiming Liu, and Wenjie Li. 2016b. Social collaborative filtering by trust. IEEE transactions on pattern analysis and machine intelligence, Vol. 39, 8 (2016), 1633--1647.Google Scholar"",""Zhilin Yang, William W Cohen, and Ruslan Salakhutdinov. 2016a. Revisiting semi-supervised learning with graph embeddings. arXiv preprint arXiv:1603.08861 (2016).Google Scholar"",""Yuan Yao, Hanghang Tong, Guo Yan, Feng Xu, Xiang Zhang, Boleslaw K Szymanski, and Jian Lu. 2014. Dual-regularized one-class collaborative filtering. In Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management. 759--768.Google ScholarDigital Library"",""Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, and Jure Leskovec. 2018. Hierarchical graph representation learning with differentiable pooling. In Advances in neural information processing systems. 4800--4810.Google Scholar"",""Jiawei Zhang and S Yu Philip. 2015a. Integrated anchor and social link predictions across social networks. In Twenty-Fourth International Joint Conference on Artificial Intelligence .Google Scholar"",""Jiawei Zhang and S Yu Philip. 2015b. Multiple anonymized social networks alignment. In 2015 IEEE International Conference on Data Mining. IEEE, 599--608.Google ScholarDigital Library"",""Si Zhang and Hanghang Tong. 2016. Final: Fast attributed network alignment. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 1345--1354.Google ScholarDigital Library"",""Si Zhang and Hanghang Tong. 2018. Attributed Network Alignment: Problem Definitions and Fast Solutions. IEEE Transactions on Knowledge and Data Engineering, Vol. 31, 9 (2018), 1680--1692.Google ScholarDigital Library"",""Si Zhang, Hanghang Tong, Jiejun Xu, Yifan Hu, and Ross Maciejewski. 2019 b. Origin: Non-rigid network alignment. In 2019 IEEE International Conference on Big Data (Big Data). IEEE, 998--1007.Google ScholarCross Ref"",""Si Zhang, Hanghang Tong, Jiejun Xu, and Ross Maciejewski. 2019 a. Graph convolutional networks: a comprehensive review. Computational Social Networks, Vol. 6, 1 (2019), 11.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403142,Redundancy-Free Computation for Graph Neural Networks,"Graph Neural Networks (GNNs) are based on repeated aggregations of information from nodes' neighbors in a graph. However, because nodes share many neighbors, a naive implementation leads to repeated and inefficient aggregations and represents significant computational overhead. Here we propose Hierarchically Aggregated computation Graphs(HAGs), a new GNN representation technique that explicitly avoids redundancy by managing intermediate aggregation results hierarchically and eliminates repeated computations and unnecessary data transfers in GNN training and inference. HAGs perform the same computations and give the same models/accuracy as traditional GNNs, but in a much shorter time dueto optimized computations. To identify redundant computations,we introduce an accurate cost function and use a novel search algorithm to find optimized HAGs. Experiments show that the HAG representation significantly outperforms the standard GNN by increasing the end-to-end training throughput by up to 2.8× and reducing the aggregations and data transfers in GNN training byup to 6.3× and 5.6×, with only 0.1% memory overhead. Overall,our results represent an important advancement in speeding-up and scaling-up GNNs without any loss in model predictive performance.","[{""name"":""Zhihao Jia"",""id"":""/profile/99658763006""},{""name"":""Sina Lin"",""id"":""/profile/99659574412""},{""name"":""Rex Ying"",""id"":""/profile/99659110092""},{""name"":""Jiaxuan You"",""id"":""/profile/99659327318""},{""name"":""Jure Leskovec"",""id"":""/profile/81367595814""},{""name"":""Alex Aiken"",""id"":""/profile/81100399954""},{""name"":""Zhihao Jia"",""id"":""/profile/99658763006""},{""name"":""Sina Lin"",""id"":""/profile/99659574412""},{""name"":""Rex Ying"",""id"":""/profile/99659110092""},{""name"":""Jiaxuan You"",""id"":""/profile/99659327318""},{""name"":""Jure Leskovec"",""id"":""/profile/81367595814""},{""name"":""Alex Aiken"",""id"":""/profile/81100399954""}]","[""Aaron B Adcock, Blair D Sullivan, and Michael W Mahoney. 2016. Tree decompositions and social graphs. Internet Mathematics, Vol. 12, 5 (2016), 315--361.Google ScholarCross Ref"",""Stefan Arnborg, Derek G Corneil, and Andrzej Proskurowski. 1987. Complexity of finding embeddings in ak-tree. SIAM Journal on Algebraic Discrete Methods, Vol. 8, 2 (1987), 277--284.Google ScholarDigital Library"",""Peter W Battaglia, Jessica B Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, et al. 2018. Relational inductive biases, deep learning, and graph networks. arXiv preprint arXiv:1806.01261 (2018).Google Scholar"",""Jie Chen, Tengfei Ma, and Cao Xiao. 2018a. FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling. ICLR (2018).Google Scholar"",""Jianfei Chen, Jun Zhu, and Le Song. 2018b. Stochastic training of graph convolutional networks with variance reduction. In ICML.Google Scholar"",""Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, and Cho-Jui Hsieh. 2019. Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks. In KDD.Google ScholarDigital Library"",""Jörg Flum, Markus Frick, and Martin Grohe. 2002. Query Evaluation via Tree-decompositions. J. ACM (2002).Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017a. Inductive Representation Learning on Large Graphs. In NeurIPS.Google Scholar"",""William L Hamilton, Rex Ying, and Jure Leskovec. 2017b. Representation learning on graphs: Methods and applications. IEEE Data Engineering Bulletin (2017).Google Scholar"",""Song Han, Huizi Mao, and William J. Dally. 2016. Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding. CoRR (2016).Google Scholar"",""Song Han, Jeff Pool, John Tran, and William J. Dally. 2015. Learning Both Weights and Connections for Efficient Neural Networks. In NeurIPS.Google Scholar"",""Wenbing Huang, Tong Zhang, Yu Rong, and Junzhou Huang. 2018. Adaptive sampling towards fast graph representation learning. In NeurIPS.Google Scholar"",""Zhihao Jia, Yongkee Kwon, Galen Shipman, Pat McCormick, Mattan Erez, and Alex Aiken. 2017. A Distributed Multi-GPU System for Fast Graph Processing. PVLDB (2017).Google Scholar"",""Thomas N Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. ICLR (2017).Google Scholar"",""Nils Kriege and Petra Mutzel. 2012. Subgraph matching kernels for attributed graphs. ICML (2012).Google Scholar"",""Lingxiao Ma, Zhi Yang, Youshan Miao, Jilong Xue, Ming Wu, Lidong Zhou, and Yafei Dai. 2018. Towards Efficient Large-Scale Graph Neural Network Computing. CoRR (2018).Google Scholar"",""Elchanan Mossel and Sebastien Roch. 2007. On the submodularity of influence in social networks. In STOC.Google Scholar"",""Kai Sheng Tai, Richard Socher, and Christopher D Manning. 2015. Improved semantic representations from tree-structured long short-term memory networks. ACL (2015).Google Scholar"",""Ruo-Chun Tzeng and Shan-Hung Wu. 2019. Distributed, Egocentric Representations of Graphs for Detecting Critical Structures. In ICML.Google Scholar"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2018. Graph attention networks. ICLR (2018).Google Scholar"",""Duncan J Watts and Steven H Strogatz. 1998. Collective dynamics of small-world networks. Nature, Vol. 393, 6684 (1998), 440.Google Scholar"",""Felix Wu, Tianyi Zhang, Amauri H. Souza Jr., Christopher Fifty, Tao Yu, and Kilian Q. Weinberger. 2019 b. Simplifying Graph Convolutional Networks. ICML (2019).Google Scholar"",""Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and Philip S Yu. 2019 a. A comprehensive survey on graph neural networks. arXiv preprint arXiv:1901.00596 (2019).Google Scholar"",""Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2019. How Powerful are Graph Neural Networks?. In ICLR.Google Scholar"",""Pinar Yanardag and S.V.N. Vishwanathan. 2015. Deep Graph Kernels. In KDD.Google Scholar"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. 2018a. Graph convolutional neural networks for web-scale recommender systems. In KDD.Google Scholar"",""Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, and Jure Leskovec. 2018b. Hierarchical graph representation learning with differentiable pooling. In NeurIPS.Google Scholar"",""Jiaxuan You, Rex Ying, and Jure Leskovec. 2018. Position-aware graph neural networks. ICML (2018).Google Scholar"",""Hanqing Zeng, Hongkuan Zhou, Ajitesh Srivastava, Rajgopal Kannan, and Viktor Prasanna. 2020. Graphsaint: Graph sampling based inductive learning method. In ICLR.Google Scholar"",""Marinka Zitnik and Jure Leskovec. 2017. Predicting multicellular function through multi-layer tissue networks. ISMB (2017).Google Scholar""]"
https://doi.org/10.1145/3394486.3403143,Improving Conversational Recommender Systems via Knowledge Graph based Semantic Fusion,"Conversational recommender systems (CRS) aim to recommend high-quality items to users through interactive conversations. Although several efforts have been made for CRS, two major issues still remain to be solved. First, the conversation data itself lacks of sufficient contextual information for accurately understanding users' preference. Second, there is a semantic gap between natural language expression and item-level user preference.To address these issues, we incorporate both word-oriented and entity-oriented knowledge graphs~(KG) to enhance the data representations in CRSs, and adopt Mutual Information Maximization to align the word-level and entity-level semantic spaces. Based on the aligned semantic representations, we further develop a KG-enhanced recommender component for making accurate recommendations, and a KG-enhanced dialog component that can generate informative keywords or entities in the response text. Extensive experiments have demonstrated the effectiveness of our approach in yielding better performance on both recommendation and conversation tasks.","[{""name"":""Kun Zhou"",""id"":""/profile/99659573187""},{""name"":""Wayne Xin Zhao"",""id"":""/profile/81472652704""},{""name"":""Shuqing Bian"",""id"":""/profile/99659572999""},{""name"":""Yuanhang Zhou"",""id"":""/profile/99659573325""},{""name"":""Ji-Rong Wen"",""id"":""/profile/81100357094""},{""name"":""Jingsong Yu"",""id"":""/profile/99659573592""},{""name"":""Kun Zhou"",""id"":""/profile/99659573187""},{""name"":""Wayne Xin Zhao"",""id"":""/profile/81472652704""},{""name"":""Shuqing Bian"",""id"":""/profile/99659572999""},{""name"":""Yuanhang Zhou"",""id"":""/profile/99659573325""},{""name"":""Ji-Rong Wen"",""id"":""/profile/81100357094""},{""name"":""Jingsong Yu"",""id"":""/profile/99659573592""}]","[""Yang Bao, Hui Fang, and Jie Zhang. 2014. TopicMF: Simultaneously Exploiting Ratings and Reviews for Recommendation. In AAAI 2014. 2--8.Google Scholar"",""Christian Bizer, Jens Lehmann, Georgi Kobilarov, Sören Auer, Christian Becker, Richard Cyganiak, and Sebastian Hellmann. 2009. DBpedia - A crystallization point for the Web of Data. J. Web Semant., Vol. 7 (2009), 154--165.Google ScholarDigital Library"",""Jesú s Bobadilla, Fernando Ortega, Antonio Hernando, and Abraham Gutié rrez. 2013. Recommender systems survey. Knowl. Based Syst., Vol. 46 (2013), 109--132.Google ScholarDigital Library"",""Qibin Chen, Junyang Lin, Yichang Zhang, Ming Ding, Yukuo Cen, Hongxia Yang, and Jie Tang. 2019. Towards Knowledge-Based Recommender Dialog System. (2019), 1803--1813.Google Scholar"",""Konstantina Christakopoulou, Filip Radlinski, and Katja Hofmann. 2016. Towards Conversational Recommender Systems. In SIGKDD 2016. 815--824.Google Scholar"",""Michael Edwards and Xianghua Xie. 2016. Graph Convolutional Neural Network. In BMVC 2016.Google Scholar"",""Jiatao Gu, Zhengdong Lu, Hang Li, and Victor O. K. Li. 2016. Incorporating Copying Mechanism in Sequence-to-Sequence Learning. In ACL 2016.Google Scholar"",""Junhua He, Hankz Hankui Zhuo, and Jarvan Law. 2017. Distributed-Representation Based Hybrid Recommender System with Short Item Descriptions. arxiv: cs.IR/1703.04854Google Scholar"",""Jin Huang, Zhaochun Ren, Wayne Xin Zhao, Gaole He, Ji-Rong Wen, and Daxiang Dong. 2019. Taxonomy-Aware Multi-Hop Reasoning Networks for Sequential Recommendation. In WSDM 2019. 573--581.Google Scholar"",""Jin Huang, Wayne Xin Zhao, Hong-Jian Dou, Ji-Rong Wen, and Edward Y. Chang. 2018. Improving Sequential Recommendation with Knowledge-Enhanced Memory Networks. In SIGIR 2018. 505--514.Google Scholar"",""Zongcheng Ji, Zhengdong Lu, and Hang Li. 2014. An Information Retrieval Approach to Short Text Conversation. ArXiv, Vol. abs/1408.6988 (2014).Google Scholar"",""Yoon Kim. 2014. Convolutional Neural Networks for Sentence Classification. In EMNLP 2014. 1746--1751.Google Scholar"",""Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Optimization. In ICLR 2015.Google Scholar"",""Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In ICLR 2017.Google Scholar"",""Yehuda Koren. 2008. Factorization meets the neighborhood: a multifaceted collaborative filtering model. In SIGKDD. 426--434.Google Scholar"",""Wenqiang Lei, Xiangnan He, Yisong Miao, Qingyun Wu, Richang Hong, Min-Yen Kan, and Tat-Seng Chua. 2020. Estimation-Action-Reflection: Towards Deep Interaction Between Conversational and Recommender Systems. In WSDM 20. 304--312.Google Scholar"",""Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and William B. Dolan. 2015. A Diversity-Promoting Objective Function for Neural Conversation Models. In NAACL-HLT.Google Scholar"",""Raymond Li, Samira Ebrahimi Kahou, Hannes Schulz, Vincent Michalski, Laurent Charlin, and Chris Pal. 2018. Towards Deep Conversational Recommendations. (2018), 9748--9758.Google Scholar"",""Lizi Liao, Ryuichi Takanobu, Yunshan Ma, Xun Yang, Minlie Huang, and Tat-Seng Chua. 2019. Deep Conversational Recommender in Travel. ArXiv, Vol. abs/1907.00710 (2019).Google Scholar"",""Michael Schlichtkrull, Thomas N. Kipf, Peter Bloem, Rianne van den Berg, Ivan Titov, and Max Welling. 2018. Modeling Relational Data with Graph Convolutional Networks. Lecture Notes in Computer Science (2018), 593--607.Google Scholar"",""Iulian Serban, Alessandro Sordoni, Yoshua Bengio, Aaron C. Courville, and Joelle Pineau. 2015. Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models. In AAAI.Google Scholar"",""Iulian Vlad Serban, Alessandro Sordoni, Ryan Lowe, Laurent Charlin, Joelle Pineau, Aaron C Courville, and Yoshua Bengio. 2017. A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues.. In AAAI.Google Scholar"",""Robyn Speer, Joshua Chin, and Catherine Havasi. 2017. ConceptNet 5.5: An Open Multilingual Graph of General Knowledge. In AAAI 2017. 4444--4451.Google Scholar"",""Sandeep Subramanian, Adam Trischler, Yoshua Bengio, and Christopher J. Pal. 2018. Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning. In ICLR 2018.Google Scholar"",""Fan-Yun Sun, Jordan Hoffmann, Vikas Verma, and Jian Tang. 2020. InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization. (2020).Google Scholar"",""Yueming Sun and Yi Zhang. 2018. Conversational Recommender System. In SIGIR 2018. 235--244.Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need., 5998--6008 pages.Google Scholar"",""Petar Velickovic, William Fedus, William L. Hamilton, Pietro Liò, Yoshua Bengio, and R. Devon Hjelm. 2019. Deep Graph Infomax.Google Scholar"",""Oriol Vinyals and Quoc V. Le. 2015. A Neural Conversational Model. CoRR, Vol. abs/1506.05869 (2015).Google Scholar"",""Chong Wang and David M. Blei. 2011. Collaborative topic modeling for recommending scientific articles. In SIGKDD 2011. 448--456.Google Scholar"",""Xiang Wang, Dingxian Wang, Canran Xu, Xiangnan He, Yixin Cao, and Tat-Seng Chua. 2019. Explainable reasoning over knowledge graphs for recommendation. In AAAI. 5329--5336.Google Scholar"",""Yuehua Wu, Wei Wu, Chen Xing, Ming Zhou, and Zhoujun Li. 2016. Sequential Matching Network: A New Architecture for Multi-turn Response Selection in Retrieval-Based Chatbots. In ACL.Google Scholar"",""Yi-Ting Yeh and Yun-Nung Chen. 2019. QAInfomax: Learning Robust Question Answering System by Mutual Information Maximization. (2019), 3368--3373.Google Scholar"",""Xiaoying Zhang, Hong Xie, Hang Li, and John C. S. Lui. 2019. Toward Building Conversational Recommender Systems: A Contextual Bandit Approach. arxiv: cs.LG/1906.01219Google Scholar"",""Yongfeng Zhang, Xu Chen, Qingyao Ai, Liu Yang, and W. Bruce Croft. 2018. Towards Conversational Search and Recommendation: System Ask, User Respond. In CIKM 2018. 177--186.Google Scholar"",""Wayne Xin Zhao, Yanwei Guo, Yulan He, Han Jiang, Yuexin Wu, and Xiaoming Li. 2014. We know what you want to buy: a demographic-based system for product recommendation on microblogs. In SIGKDD. 1935--1944.Google Scholar"",""Wayne Xin Zhao, Gaole He, Kunlin Yang, Hong-Jian Dou, Jin Huang, Siqi Ouyang, and Ji-Rong Wen. 2019. KB4Rec: A Data Set for Linking Knowledge Bases with Recommender Systems. Data Intelligence, Vol. 1, 2 (2019), 121--136.Google ScholarCross Ref"",""Hao Zhou, Tom Young, Minlie Huang, Haizhou Zhao, Jingfang Xu, and Xiaoyan Zhu. 2018. Commonsense Knowledge Aware Conversation Generation with Graph Attention. In IJCAI.Google Scholar"",""Kun Zhou, Kai Zhang, Yu Wu, Shujie Liu, and Jingsong Yu. 2019. Unsupervised Context Rewriting for Open Domain Conversation. In EMNLP-IJCNLP 2019. 1834--1844.Google Scholar"",""Xiangyang Zhou, Daxiang Dong, Hua Wu, Shiqi Zhao, Dianhai Yu, Hao Tian, Xuan Liu, and Rui Yan. 2016. Multi-view Response Selection for Human-Computer Conversation. In EMNLP.Google Scholar""]"
https://doi.org/10.1145/3394486.3403144,Sliding Sketches: A Framework using Time Zones for Data Stream Processing in Sliding Windows,"Data stream processing has become a hot issue in recent years due to the arrival of big data era. There are three fundamental stream processing tasks: membership query, frequency query and heavy hitter query. While most existing solutions address these queries in fixed windows, this paper focuses on a more challenging task: answering these queries in sliding windows. While most existing solutions address different kinds of queries by using different algorithms, this paper focuses on a generic framework. In this paper, we propose a generic framework, namely Sliding sketches, which can be applied to many existing solutions for the above three queries, and enable them to support queries in sliding windows. We apply our framework to five state-of-the-art sketches for the above three kinds of queries. Theoretical analysis and extensive experimental results show that after using our framework, the accuracy of existing sketches that do not support sliding windows becomes much higher than the corresponding best prior art. We released all the source code at Github.","[{""name"":""Xiangyang Gou"",""id"":""/profile/99659572909""},{""name"":""Long He"",""id"":""/profile/99659574441""},{""name"":""Yinda Zhang"",""id"":""/profile/99659575105""},{""name"":""Ke Wang"",""id"":""/profile/99659572965""},{""name"":""Xilai Liu"",""id"":""/profile/99659574117""},{""name"":""Tong Yang"",""id"":""/profile/99658630798""},{""name"":""Yi Wang"",""id"":""/profile/81549429356""},{""name"":""Bin Cui"",""id"":""/profile/81502785823""},{""name"":""Xiangyang Gou"",""id"":""/profile/99659572909""},{""name"":""Long He"",""id"":""/profile/99659574441""},{""name"":""Yinda Zhang"",""id"":""/profile/99659575105""},{""name"":""Ke Wang"",""id"":""/profile/99659572965""},{""name"":""Xilai Liu"",""id"":""/profile/99659574117""},{""name"":""Tong Yang"",""id"":""/profile/99658630798""},{""name"":""Yi Wang"",""id"":""/profile/81549429356""},{""name"":""Bin Cui"",""id"":""/profile/81502785823""}]","[""Sang Hyun Oh, Jin Suk Kang, Yung Cheol Byun, Taikyeong T Jeong, and Won Suk Lee. Anomaly intrusion detection based on clustering a data stream. In Acis International Conference on Software Engineering Research, Management and Applications, pages 220--227, 2006.Google ScholarDigital Library"",""Mustafa Amir Faisal, Zeyar Aung, John R. Williams, and Abel Sanchez. Securing advanced metering infrastructure using intrusion detection system with data stream mining. In Pacific Asia Conference on Intelligence and Security Informatics, pages 96--111, 2012.Google ScholarDigital Library"",""Bryan Ball, Mark Flood, H. V. Jagadish, Joe Langsam, Louiqa Raschid, and Peratham Wiriyathammabhum. A flexible and extensible contract aggregation framework (caf) for financial data stream analytics. pages 1--6, 2014.Google Scholar"",""Lajos Gergely Gyurkó, Terry Lyons, Mark Kontkowski, and Jonathan Field. Extracting information from the signature of a financial data stream. Quantitative Finance, 2013.Google Scholar"",""Ruo Hu. Stability analysis of wireless sensor network service via data stream methods. Applied Mathematics \u0026 Information Sciences, 6(3):793--798, 2012.Google Scholar"",""Carlos M. S. Figueiredo, Carlos M. S. Figueiredo, Eduardo F. Nakamura, Luciana S. Buriol, Antonio A. F. Loureiro, Antnio Otvio Fernandes, and Claudionor J. N. Jr Coelho. Data stream based algorithms for wireless sensor network applications. In International Conference on Advanced Information NETWORKING and Applications, pages 869--876, 2007.Google Scholar"",""FPGA data sheet [on line]. http://www.xilinx.com/support/documentation/data_sheets/ds180_7Series_Overview.pdf.Google Scholar"",""Burton H Bloom. Space/time trade-offs in hash coding with allowable errors. Communications of the ACM, 13(7):422--426, 1970.Google ScholarDigital Library"",""Graham Cormode and S Muthukrishnan. An improved data stream summary: the count-min sketch and its applications. Journal of Algorithms, 55(1):58--75, 2005.Google ScholarDigital Library"",""Cristian Estan and George Varghese. New directions in traffic measurement and accounting. ACM SIGMCOMM CCR, 32(4), 2002.Google Scholar"",""Mayur Datar, Aristides Gionis, Piotr Indyk, and Rajeev Motwani. Maintaining stream statistics over sliding windows. Siam Journal on Computing, 31(6):1794--1813, 2002.Google ScholarDigital Library"",""F. Chang, Wu Chang Feng, and Kang Li. Approximate caches for packet classification. In Joint Conference of the IEEE Computer and Communications Societies, pages 2196--2207 vol.4, 2004.Google ScholarCross Ref"",""Rajath Subramanyam, Indranil Gupta, Luke M. Leslie, and Wenting Wang. Idempotent distributed counters using a forgetful bloom filter. Cluster Computing, 19(2):879--892, 2016.Google ScholarDigital Library"",""Yoon. Aging bloom filter with two active buffers for dynamic sets. IEEE Transactions on Knowledge \u0026 Data Engineering, 22(1):134--138, 2009.Google ScholarCross Ref"",""Odysseas Papapetrou, Minos Garofalakis, and Antonios Deligiannakis. Sketch-based querying of distributed sliding-window data streams. Proceedings of the VLDB Endowment, 5(10):992--1003, 2012.Google ScholarDigital Library"",""Nicoló Rivetti, Yann Busnel, and Achour Mostefaoui. Efficiently Summarizing Distributed Data Streams over Sliding Windows. PhD thesis, LINA-University of Nantes; Centre de Recherche en Économie et Statistique; Inria Rennes Bretagne Atlantique, 2015.Google Scholar"",""Ho Leung Chan, Tak Wah Lam, Lap Kei Lee, and Hing Fung Ting. Continuous Monitoring of Distributed Data Streams over a Time-Based Sliding Window. 2009.Google Scholar"",""Graham Cormode and Ke Yi. Tracking distributed aggregates over time-based sliding windows. In ACM Sigact-Sigops Symposium on Principles of Distributed Computing, pages 213--214, 2011.Google ScholarDigital Library"",""Ben Basat Ran, Gil Einziger, Roy Friedman, and Yaron Kassner. Heavy hitters in streams and sliding windows. In IEEE INFOCOM 2016 - the IEEE International Conference on Computer Communications, pages 1--9, 2016.Google Scholar"",""L. K. Lee and H. F. Ting. A simpler and more efficient deterministic scheme for finding frequent items over sliding windows. In ACM Sigmod-Sigact-Sigart Symposium on Principles of Database Systems, pages 290--297, 2006.Google ScholarDigital Library"",""Hung, Y. S Regant, Lee, Lap-Kei, Ting, and H.F. Finding frequent items over sliding windows with constant update time. Information Processing Letters, 110(7):257--260, 2010.Google ScholarDigital Library"",""Moses Charikar, Kevin Chen, and Martin Farach-Colton. Finding frequent items in data streams. In Automata, Languages and Programming. Springer, 2002.Google ScholarDigital Library"",""Junzhi Gong, Tong Yang, Haowei Zhang, Hao Li, Steve Uhlig, Shigang Chen, Lorna Uden, and Xiaoming Li. Heavykeeper: An accurate algorithm for finding top-k elephant flows. In 2018 USENIX Annual Technical Conference (USENIX ATC 18), pages 909--921, Boston, MA, 2018. USENIX Association.Google Scholar"",""\""source code of sliding sketches and other sketches\"". https://github.com/sliding-sketch/Sliding-Sketch.Google Scholar"",""David Nelson. The bloomier filter: An efficient data structure for static support lookup tables. Proc Symposium on Discrete Algorithms, 2004.Google Scholar"",""J. Aguilar-Saborit, P. Trancoso, V. Muntes-Mulero, and J. L. Larriba-Pey. Dynamic count filters. Acm Sigmod Record, 35(1):26--32, 2006.Google ScholarDigital Library"",""Fang Hao, M Kodialam, T. V Lakshman, and Haoyu Song. Fast multiset membership testing using combinatorial bloom filters. In INFOCOM, pages 513--521, 2009.Google ScholarCross Ref"",""Tong Yang, Alex X. Liu, Muhammad Shahzad, Yuankun Zhong, Qiaobin Fu, Zi Li, Gaogang Xie, and Xiaoming Li. A shifting bloom filter framework for set queries. Proceedings of the Vldb Endowment, 9(5):408--419, 2016.Google ScholarDigital Library"",""Tong Yang, Yang Zhou, Hao Jin, Shigang Chen, and Xiaoming Li. Pyramid sketch: a sketch framework for frequency estimation of data streams. Proceedings of the Vldb Endowment, 10(11), 2017.Google ScholarDigital Library"",""Pratanu Roy, Arijit Khan, and Gustavo Alonso. Augmented sketch: Faster and more accurate stream processing. In International Conference on Management of Data, pages 1449--1463, 2016.Google ScholarDigital Library"",""Jiecao Chen and Qin Zhang. Bias-aware sketches. Proceedings of the VLDB Endowment, 10(9):961--972, 2017.Google ScholarDigital Library"",""Tong Yang, Jie Jiang, Peng Liu, Qun Huang, Junzhi Gong, Yang Zhou, Rui Miao, Xiaoming Li, and Steve Uhlig. Elastic sketch: Adaptive and fast network-wide measurements. In ACM SIGCOMM 2018.Google Scholar"",""Yang Zhou, Tong Yang, Jie Jiang, Bin Cui, Minlan Yu, Xiaoming Li, and Steve Uhlig. Cold filter: A meta-framework for faster and more accurate stream processing. In Proceedings of the 2018 International Conference on Management of Data, SIGMOD '18, pages 741--756, New York, NY, USA, 2018. ACM.Google ScholarDigital Library"",""Erik D Demaine, Alejandro López-Ortiz, and J Ian Munro. Frequency estimation of internet packet streams with limited space. In European Symposium on Algorithms, pages 348--360. Springer, 2002.Google ScholarDigital Library"",""Gurmeet Singh Manku and Rajeev Motwani. Approximate frequency counts over data streams. In VLDB'02: Proceedings of the 28th International Conference on Very Large Databases, pages 346--357. Elsevier, 2002.Google ScholarDigital Library"",""Ahmed Metwally, Divyakant Agrawal, and Amr El Abbadi. Efficient computation of frequent and top-k elements in data streams. In International Conference on Database Theory, pages 398--412. Springer, 2005.Google Scholar"",""Daniel Ting. Data sketches for disaggregated subset sum and frequent item estimation. 2017.Google Scholar"",""textCaida anonymized 2016 internet traces. http://www.caida.org/data/overview/.Google Scholar"",""Real-life transactional dataset. http://fimi.ua.ac.be/data/.Google Scholar"",""textThe Network dataset Internet Traces. http://snap.stanford.edu/data/.Google Scholar"",""Alex Rousskov and Duane Wessels. High-performance benchmarking with web polygraph. Software: Practice and Experience, 34(2):187--211, 2004.Google ScholarDigital Library"",""David MW Powers. Applications and explanations of Zipf's law. In ¶roc EMNLP-CoNLL. Association for Computational Linguistics, 1998.Google Scholar"",""Arvind Arasu and Gurmeet Singh Manku. Approximate counts and quantiles over sliding windows. In ACM Sigmod-Sigact-Sigart Symposium on Principles of Database Systems, pages 286--296, 2004.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403145,STEAM: Self-Supervised Taxonomy Expansion with Mini-Paths,"Taxonomies are important knowledge ontologies that underpin numerous applications on a daily basis, but many taxonomies used in practice suffer from the low coverage issue. We study the taxonomy expansion problem, which aims to expand existing taxonomies with new concept terms. We propose a self-supervised taxonomy expansion model named STEAM, which leverages natural supervision in the existing taxonomy for expansion. To generate natural self-supervision signals, STEAM samples mini-paths from the existing taxonomy, and formulates a node attachment prediction task between anchor mini-paths and query terms. To solve the node attachment task, it learns feature representations for query-anchor pairs from multiple views and performs multi-view co-training for prediction. Extensive experiments show that STEAM outperforms state-of-the-art methods for taxonomy expansion by 11.6% in accuracy and 7.0% in mean reciprocal rank on three public benchmarks. The code and data for STEAM can be found at https://github.com/yueyu1030/STEAM.","[{""name"":""Yue Yu"",""id"":""/profile/99659574219""},{""name"":""Yinghao Li"",""id"":""/profile/99659575271""},{""name"":""Jiaming Shen"",""id"":""/profile/99659280737""},{""name"":""Hao Feng"",""id"":""/profile/99659574315""},{""name"":""Jimeng Sun"",""id"":""/profile/81490657940""},{""name"":""Chao Zhang"",""id"":""/profile/99659455279""},{""name"":""Yue Yu"",""id"":""/profile/99659574219""},{""name"":""Yinghao Li"",""id"":""/profile/99659575271""},{""name"":""Jiaming Shen"",""id"":""/profile/99659280737""},{""name"":""Hao Feng"",""id"":""/profile/99659574315""},{""name"":""Jimeng Sun"",""id"":""/profile/81490657940""},{""name"":""Chao Zhang"",""id"":""/profile/99659455279""}]","[""Daniele Alfarone and Jesse Davis. 2015. Unsupervised Learning of an IS-A Taxonomy from a Limited Domain-Specific Corpus. In IJCAL. 1434--1441.Google Scholar"",""Rami Aly, Shantanu Acharya, Alexander Ossa, Arne Köhn, Chris Biemann, and Alexander Panchenko. 2019. Every Child Should Have Parents: A Taxonomy Refinement Algorithm Based on Hyperbolic Term Embeddings. In ACL. 4811--4817.Google Scholar"",""Mohit Bansal, David Burkett, Gerard De Melo, and Dan Klein. 2014. Structured learning for taxonomy induction with belief propagation. In ACL. 1041--1051.Google Scholar"",""Marco Baroni, Raffaella Bernardi, Ngoc-Quynh Do, and Chung-chieh Shan. 2012. Entailment above the word level in distributional semantics. In EACL. 23--32.Google Scholar"",""Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: A Collaboratively Created Graph Database for Structuring Human Knowledge. In SIGMOD. ACM, 1247--1250.Google ScholarDigital Library"",""Georgeta Bordea, Els Lefever, and Paul Buitelaar. 2016. SemEval-2016 Task 13: Taxonomy Extraction Evaluation (TExEval-2). In SemEval-2016. ACL, 1081--1091.Google Scholar"",""Haw-Shiuan Chang, Ziyun Wang, Luke Vilnis, and Andrew McCallum. 2018. Distributional Inclusion Vector Embedding for Unsupervised Hypernymy Detection. In NAACL. 485--495.Google Scholar"",""Anne Cocos, Marianna Apidianaki, and Chris Callison-Burch. 2018. Comparing constraints for taxonomic organization. In NAACL. 323--333.Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In NAACL-HLT. 4171--4186.Google Scholar"",""Doug Downey, Chandra Bhagavatula, and Yi Yang. 2015. Efficient methods for inferring large sparse topic hierarchies. In the ACL. 774--784.Google Scholar"",""Nicolas Rodolfo Fauceglia, Alfio Gliozzo, Sarthak Dash, Md Faisal Mahbub Chowdhury, and Nandana Mihindukulasooriya. 2019. Automatic Taxonomy Induction and Expansion. In EMNLP-IJCNLP Demo. 25--30.Google Scholar"",""Ruiji Fu, Jiang Guo, Bing Qin, Wanxiang Che, Haifeng Wang, and Ting Liu. 2014. Learning semantic hierarchies via word embeddings. In ACL. 1199--1209.Google Scholar"",""Amit Gupta, Rémi Lebret, Hamza Harkous, and Karl Aberer. 2017. Taxonomy induction using hypernym subsequences. In CIKM. 1329--1338.Google Scholar"",""Sanda M Harabagiu, Steven J Maiorano, and Marius A Pacs ca. 2003. Open-domain textual question answering techniques. Natural Language Engineering, Vol. 9, 3 (2003), 231--267.Google ScholarDigital Library"",""Marti A Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In COLING. ACL, 539--545.Google Scholar"",""Giannis Karamanolakis, Jun Ma, and Xin Luna Dong. 2020. TXtract: Taxonomy-Aware Knowledge Extraction for Thousands of Product Categories. In ACL.Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Zornitsa Kozareva and Eduard Hovy. 2010. A semi-supervised method to learn and construct taxonomies using the web. In EMNLP. 1110--1118.Google Scholar"",""Zornitsa Kozareva, Ellen Riloff, and Eduard Hovy. 2008. Semantic Class Learning from the Web with Hyponym Pattern Linkage Graphs. In ACL. 1048--1056.Google Scholar"",""Carolyn E Lipscomb. 2000. Medical subject headings (MeSH). Bulletin of the Medical Library Association, Vol. 88, 3 (2000), 265.Google Scholar"",""Xueqing Liu, Yangqiu Song, Shixia Liu, and Haixun Wang. 2012. Automatic taxonomy construction from keywords. In SIGKDD. 1433--1441.Google Scholar"",""Emaad Manzoor, Rui Li, Dhananjay Shrouty, and Jure Leskovec. 2020. Expanding Taxonomies with Implicit Edge Semantics. In The Web Conference 2020. 2044--2054.Google Scholar"",""Yuning Mao, Xiang Ren, Jiaming Shen, Xiaotao Gu, and Jiawei Han. 2018. End-to-end reinforcement learning for automatic taxonomy induction. In ACL. 2462--2472.Google Scholar"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Distributed Representations of Words and Phrases and Their Compositionality. In NIPS. 3111--3119.Google Scholar"",""George A. Miller. 1995. WordNet: A Lexical Database for English. Commun. ACM, Vol. 38, 11 (Nov. 1995), 39--41.Google ScholarDigital Library"",""Maximillian Nickel and Douwe Kiela. 2017. Poincaré embeddings for learning hierarchical representations. In NIPS. 6338--6347.Google Scholar"",""Alexander Panchenko, Stefano Faralli, Eugen Ruppert, Steffen Remus, Hubert Naets, Cédrick Fairon, Simone Paolo Ponzetto, and Chris Biemann. 2016. TAXI at SemEval-2016 Task 13: a Taxonomy Induction Method based on Lexico-Syntactic Patterns, Substrings and Focused Crawling. In SemEval-2016. ACL, 1320--1327.Google Scholar"",""Jeffrey Pennington, Richard Socher, and Christopher Manning. 2014. Glove: Global Vectors for Word Representation. In EMNLP. ACL, 1532--1543.Google Scholar"",""Stephen Roller, Douwe Kiela, and Maximilian Nickel. 2018. Hearst Patterns Revisited: Automatic Hypernym Detection from Large Text Corpora. In ACL. 358--363.Google Scholar"",""Chao Shang, Sarthak Dash, Md Faisal Mahbub Chowdhury, Nandana Mihindukulasooriya, and Alfio Gliozzo. 2020 a. Taxonomy Construction of Unseen Domains via Graph-based Cross-Domain Knowledge Transfer. In ACL. ACL.Google Scholar"",""Jingbo Shang, Xinyang Zhang, Liyuan Liu, Sha Li, and Jiawei Han. 2020 b. NetTaxo: Automated Topic Taxonomy Construction from Large-Scale Text-Rich Network. In The Web Conference.Google Scholar"",""Jiaming Shen, Zhihong Shen, Chenyan Xiong, Chi Wang, Kuansan Wang, and Jiawei Han. 2020. TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced Graph Neural Network. In The Web Conference 2020. 486--497.Google Scholar"",""Jiaming Shen, Zeqiu Wu, Dongming Lei, Chao Zhang, Xiang Ren, Michelle T Vanni, Brian M Sadler, and Jiawei Han. 2018. Hiexpan: Task-guided taxonomy construction by hierarchical tree expansion. In SIGKDD. 2180--2189.Google ScholarDigital Library"",""Yu Shi, Jiaming Shen, Yuchen Li, Naijing Zhang, Xinwei He, Zhengzhi Lou, Qi Zhu, Matthew Walker, Myunghwan Kim, and Jiawei Han. 2019. Discovering Hypernymy in Text-Rich Heterogeneous Information Network by Exploiting Context Granularity. In CIKM. ACM, 599--608.Google Scholar"",""Vered Shwartz, Yoav Goldberg, and Ido Dagan. 2016. Improving Hypernymy Detection with an Integrated Path-based and Distributional Method. In ACL. ACL, 2389--2398.Google Scholar"",""Nikhita Vedula, Patrick K Nicholson, Deepak Ajwani, Sourav Dutta, Alessandra Sala, and Srinivasan Parthasarathy. 2018. Enriching taxonomies with functional domain knowledge. In SIGIR. 745--754.Google Scholar"",""Denny Vrandevciundefined. 2012. Wikidata: A New Platform for Collaborative Data Collection. In WWW Companion. ACM, 1063--1064.Google Scholar"",""Chi Wang, Marina Danilevsky, Nihit Desai, Yinan Zhang, Phuong Nguyen, Thrivikrama Taula, and Jiawei Han. 2013. A phrase mining framework for recursive construction of a topical hierarchy. In SIGKDD. 437--445.Google Scholar"",""Wentao Wu, Hongsong Li, Haixun Wang, and Kenny Q Zhu. 2012. Probase: A probabilistic taxonomy for text understanding. In SIGMOD. 481--492.Google ScholarDigital Library"",""Xiaoxin Yin and Sarthak Shah. 2010. Building taxonomy of web search intents for name entity queries. In WWW. 1001--1010.Google Scholar"",""Chao Zhang, Fangbo Tao, Xiusi Chen, Jiaming Shen, Meng Jiang, Brian Sadler, Michelle Vanni, and Jiawei Han. 2018. Taxogen: Unsupervised topic taxonomy construction by adaptive term embedding and clustering. In SIGKDD. 2701--2709.Google ScholarDigital Library"",""Hao Zhang, Zhiting Hu, Yuntian Deng, Mrinmaya Sachan, Zhicheng Yan, and Eric Xing. 2016. Learning Concept Taxonomies from Multi-modal Data. In ACL. 1791--1801.Google Scholar"",""Yuchen Zhang, Amr Ahmed, Vanja Josifovski, and Alexander Smola. 2014. Taxonomy discovery for personalized recommendation. In WSDM. 243--252.Google Scholar""]"
https://doi.org/10.1145/3394486.3403147,Probabilistic Metric Learning with Adaptive Margin for Top-K Recommendation,"Personalized recommender systems are playing an increasingly important role as more content and services become available and users struggle to identify what might interest them. Although matrix factorization and deep learning based methods have proved effective in user preference modeling, they violate the triangle inequality and fail to capture fine-grained preference information. To tackle this, we develop a distance-based recommendation model with several novel aspects: (i) each user and item are parameterized by Gaussian distributions to capture the learning uncertainties; (ii) an adaptive margin generation scheme is proposed to generate the margins regarding different training triplets; (iii) explicit user-user/item-item similarity modeling is incorporated in the objective function. The Wasserstein distance is employed to determine preferences because it obeys the triangle inequality and can measure the distance between probabilistic distributions. Via a comparison using five real-world datasets with state-of-the-art methods, the proposed model outperforms the best existing models by 4-22% in terms of [email protected] on Top-K recommendation.","[{""name"":""Chen Ma"",""id"":""/profile/99659317227""},{""name"":""Liheng Ma"",""id"":""/profile/99659574936""},{""name"":""Yingxue Zhang"",""id"":""/profile/99659567130""},{""name"":""Ruiming Tang"",""id"":""/profile/81488661679""},{""name"":""Xue Liu"",""id"":""/profile/99659571486""},{""name"":""Mark Coates"",""id"":""/profile/81100363584""},{""name"":""Chen Ma"",""id"":""/profile/99659317227""},{""name"":""Liheng Ma"",""id"":""/profile/99659574936""},{""name"":""Yingxue Zhang"",""id"":""/profile/99659567130""},{""name"":""Ruiming Tang"",""id"":""/profile/81488661679""},{""name"":""Xue Liu"",""id"":""/profile/99659571486""},{""name"":""Mark Coates"",""id"":""/profile/81100363584""}]","[""Antoine Bordes, Nicolas Usunier, Alberto Garcia-Durán, Jason Weston, and Oksana Yakhnenko. 2013. Translating Embeddings for Modeling Multi-relational Data. In Advances in Neural Information Processing Systems.Google Scholar"",""George Casella and Roger L Berger. 2002. Statistical inference .Duxbury Pacific Grove, CA.Google Scholar"",""Eunjoon Cho, Seth A. Myers, and Jure Leskovec. 2011. Friendship and mobility: user movement in location-based social networks. In Proc. ACM Conf. Knowledge Discovery and Data Mining.Google ScholarDigital Library"",""Beno^i t Colson, Patrice Marcotte, and Gilles Savard. 2007. An overview of bilevel optimization. Annals OR (2007).Google Scholar"",""Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep Neural Networks for YouTube Recommendations. In Proc. ACM Conf. Recommender Systems.Google ScholarDigital Library"",""Clark R. Givens and Rae Michael Shortt. 1984. A class of Wasserstein metrics for probability distributions. The Michigan Mathematical Journal (1984).Google Scholar"",""Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: A Factorization-Machine based Neural Network for CTR Prediction. In Proc. Int. Joint Conf. Artificial Intelligence.Google ScholarCross Ref"",""Ruining He, Wang-Cheng Kang, and Julian McAuley. 2017a. Translation-based Recommendation. In Proc. ACM Conf. Recommender Systems.Google Scholar"",""Ruining He and Julian McAuley. 2016. Ups and Downs: Modeling the Visual Evolution of Fashion Trends with One-Class Collaborative Filtering. In Proc. Int. Conf. World Wide Web.Google ScholarDigital Library"",""Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017b. Neural Collaborative Filtering. In Proc. Int. Conf. World Wide Web.Google ScholarDigital Library"",""Xiangnan He, Hanwang Zhang, Min-Yen Kan, and Tat-Seng Chua. 2016. Fast Matrix Factorization for Online Recommendation with Implicit Feedback. In Proc. ACM Int. Conf. Research and Development in Information Retrieval.Google ScholarDigital Library"",""Cheng-Kang Hsieh, Longqi Yang, Yin Cui, Tsung-Yi Lin, Serge J. Belongie, and Deborah Estrin. 2017. Collaborative Metric Learning. In Proc. Int. Conf. World Wide Web.Google ScholarDigital Library"",""Yifan Hu, Yehuda Koren, and Chris Volinsky. 2008. Collaborative Filtering for Implicit Feedback Datasets. In Proc. IEEE Int. Conf. Data Mining.Google ScholarDigital Library"",""Santosh Kabbur, Xia Ning, and George Karypis. 2013. FISM: factored item similarity models for top-N recommender systems. In Proc. ACM Conf. Knowledge Discovery and Data Mining.Google ScholarDigital Library"",""Diederik P. Kingma and Max Welling. 2014. Auto-Encoding Variational Bayes. In Proc. Int. Conf. Learning Representations.Google Scholar"",""Yehuda Koren, Robert M. Bell, and Chris Volinsky. 2009. Matrix Factorization Techniques for Recommender Systems. IEEE Computer (2009).Google Scholar"",""Mingming Li, Shuai Zhang, Fuqing Zhu, Wanhui Qian, Liangjun Zang, Jizhong Han, and Songlin Hu. 2020. Symmetric Metric Learning with Adaptive Margin for Recommendation. (2020).Google Scholar"",""Hanxiao Liu, Karen Simonyan, and Yiming Yang. 2019. DARTS: Differentiable Architecture Search. In Proc. Int. Conf. Learning Representations.Google Scholar"",""Chen Ma, Peng Kang, and Xue Liu. 2019 a. Hierarchical Gating Networks for Sequential Recommendation. In Proc. ACM Conf. Knowledge Discovery and Data Mining.Google ScholarDigital Library"",""Chen Ma, Peng Kang, Bin Wu, Qinglong Wang, and Xue Liu. 2019 b. Gated Attentive-Autoencoder for Content-Aware Recommendation. In Proc. ACM Int. Conf. Web Search and Data Mining.Google ScholarDigital Library"",""Chen Ma, Liheng Ma, Yingxue Zhang, Jianing Sun, Xue Liu, and Mark Coates. 2020. Memory Augmented Graph Neural Networks for Sequential Recommendation. In AAAI.Google Scholar"",""Chen Ma, Yingxue Zhang, Qinglong Wang, and Xue Liu. 2018. Point-of-Interest Recommendation: Exploiting Self-Attentive Autoencoders with Neighbor-Aware Influence. In Proc. ACM Int. Conf. Information and Knowledge Management.Google ScholarDigital Library"",""Anton Mallasto and Aasa Feragen. 2017. Learning from uncertain curves: The 2-Wasserstein metric for Gaussian processes. In Advances in Neural Information Processing Systems.Google Scholar"",""Xia Ning, Christian Desrosiers, and George Karypis. 2015. A Comprehensive Survey of Neighborhood-Based Recommendation Methods. In Recommender Systems Handbook.Google Scholar"",""Rong Pan, Yunhong Zhou, Bin Cao, Nathan Nan Liu, Rajan M. Lukose, Martin Scholz, and Qiang Yang. 2008. One-Class Collaborative Filtering. In Proc. IEEE Int. Conf. Data Mining.Google ScholarDigital Library"",""Chanyoung Park, Donghyun Kim, Xing Xie, and Hwanjo Yu. 2018. Collaborative Translational Metric Learning. In Proc. IEEE Int. Conf. Data Mining.Google ScholarCross Ref"",""Steffen Rendle. 2012. Learning recommender systems with adaptive regularization. In Proc. ACM Int. Conf. Web Search and Data Mining.Google ScholarDigital Library"",""Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian Personalized Ranking from Implicit Feedback. In Proc. Conf. Uncertainty in Artificial Intelligence.Google Scholar"",""Ruslan Salakhutdinov and Andriy Mnih. 2007. Probabilistic Matrix Factorization. In Advances in Neural Information Processing Systems.Google Scholar"",""Ruslan Salakhutdinov, Andriy Mnih, and Geoffrey E. Hinton. 2007. Restricted Boltzmann machines for collaborative filtering. In Proc. Int. Conf. Machine Learning.Google Scholar"",""Badrul Munir Sarwar, George Karypis, Joseph A. Konstan, and John Riedl. 2001. Item-based collaborative filtering recommendation algorithms. In Proc. Int. Conf. World Wide Web.Google ScholarDigital Library"",""Anshumali Shrivastava and Ping Li. 2014. Asymmetric LSH (ALSH) for Sublinear Time Maximum Inner Product Search (MIPS). In Advances in Neural Information Processing Systems.Google Scholar"",""Ankur Sinha, Pekka Malo, and Kalyanmoy Deb. 2018. A Review on Bilevel Optimization: From Classical to Evolutionary Approaches and Applications. IEEE Trans. Evolutionary Computation (2018).Google Scholar"",""Sashi Mohan Srivastava. 2008. A course on Borel sets .Springer Science \u0026 Business Media.Google Scholar"",""Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. 2015. End-To-End Memory Networks. In Advances in Neural Information Processing Systems.Google Scholar"",""Jianing Sun, Yingxue Zhang, Chen Ma, Mark Coates, Huifeng Guo, Ruiming Tang, and Xiuqiang He. 2019. Multi-graph Convolution Collaborative Filtering. In Proc. IEEE Int. Conf. Data Mining.Google ScholarCross Ref"",""Yi Tay, Luu Anh Tuan, and Siu Cheung Hui. 2018. Latent Relational Metric Learning via Memory-based Attention for Collaborative Ranking. In Proc. Int. Conf. World Wide Web.Google ScholarDigital Library"",""Mengting Wan and Julian McAuley. 2018. Item recommendation on monotonic behavior chains. In Proc. ACM Conf. Recommender Systems.Google ScholarDigital Library"",""Hao Wang, Naiyan Wang, and Dit-Yan Yeung. 2015. Collaborative Deep Learning for Recommender Systems. In Proc. ACM Conf. Knowledge Discovery and Data Mining.Google ScholarDigital Library"",""Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019. Neural Graph Collaborative Filtering. In Proc. ACM Int. Conf. Research and Development in Information Retrieval.Google ScholarDigital Library"",""Jason Weston, Samy Bengio, and Nicolas Usunier. 2010. Large scale image annotation: learning to rank with joint word-image embeddings. Machine Learning (2010).Google Scholar"",""Yao Wu, Christopher DuBois, Alice X. Zheng, and Martin Ester. 2016. Collaborative Denoising Auto-Encoders for Top-N Recommender Systems. In Proc. ACM Int. Conf. Web Search and Data Mining.Google ScholarDigital Library"",""Yujia Xie, Xiangfeng Wang, Ruijia Wang, and Hongyuan Zha. 2019. A Fast Proximal Point Method for Computing Exact Wasserstein Distance. In Proc. Conf. Uncertainty in Artificial Intelligence.Google Scholar"",""Hong-Jian Xue, Xinyu Dai, Jianbing Zhang, Shujian Huang, and Jiajun Chen. 2017. Deep Matrix Factorization Models for Recommender Systems. In Proc. Int. Joint Conf. Artificial Intelligence.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403148,Re-identification Attack to Privacy-Preserving Data Analysis with Noisy Sample-Mean,"In mining sensitive databases, access to sensitive class attributes of individual records is often prohibited by enforcing field-level security, while only aggregate class-specific statistics are allowed to be released. We consider a common privacy-preserving data analytics scenario where only a noisy sample mean of the class of interest can be queried. Such practice is widely found in medical research and business analytics settings. This paper studies the hazard of re-identification of entire class caused by revealing a noisy sample mean of the class. With a novel formulation of the re-identification attack as a generalized positive-unlabeled learning problem, we prove that the risk function of the re-identification problem is closely related to that of learning with complete data. We demonstrate that with a one-sided noisy sample mean, an effective re-identification attack can be devised with existing PU learning algorithms. We then propose a novel algorithm, growPU, that exploits the unique property of sample mean and consistently outperforms existing PU learning algorithms on the re-identification task. GrowPU achieves re-identification accuracy of 93.6% on the MNIST dataset and 88.1% on an online behavioral dataset with noiseless sample mean. With noise that guarantees 0.01-differential privacy, growPU achieves 91.9% on the MNIST dataset and 84.6% on the online behavioral dataset.","[{""name"":""Du Su"",""id"":""/profile/99659573531""},{""name"":""Hieu Tri Huynh"",""id"":""/profile/99659574091""},{""name"":""Ziao Chen"",""id"":""/profile/99659574418""},{""name"":""Yi Lu"",""id"":""/profile/81485647964""},{""name"":""Wenmiao Lu"",""id"":""/profile/99659573129""},{""name"":""Du Su"",""id"":""/profile/99659573531""},{""name"":""Hieu Tri Huynh"",""id"":""/profile/99659574091""},{""name"":""Ziao Chen"",""id"":""/profile/99659574418""},{""name"":""Yi Lu"",""id"":""/profile/81485647964""},{""name"":""Wenmiao Lu"",""id"":""/profile/99659573129""}]","[""Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. 2016. Deep learning with differential privacy. In Proceedings of the 2016 ACMSIGSAC Conference on Computer and Communications Security. 308--318.Google ScholarDigital Library"",""Mathilde Caron, Piotr Bojanowski, Armand Joulin, and Matthijs Douze. 2018. Deep clustering for unsupervised learning of visual features. In Proceedings of the European Conference on Computer Vision (ECCV). 132--149.Google ScholarCross Ref"",""Fay Chang, Jeffrey Dean, Sanjay Ghemawat, Wilson C Hsieh, Deborah AWallach, Mike Burrows, Tushar Chandra, Andrew Fikes, and Robert E Gruber. 2008. Bigtable: A distributed storage system for structured data. ACM Transactions on Computer Systems (TOCS) 26, 2 (2008), 1--26.Google ScholarDigital Library"",""Olivier Chapelle, Bernhard Scholkopf, and Alexander Zien. 2009. Semi-supervised learning (chapelle, o. et al., eds.; 2006)[book reviews]. IEEE Transactions on Neural Networks 20, 3 (2009), 542--542.Google ScholarDigital Library"",""Li Deng. 2012. The mnist database of handwritten digit images for machine learning research [best of the web]. IEEE Signal Processing Magazine 29, 6 (2012), 141--142.Google ScholarCross Ref"",""Marthinus Du Plessis, Gang Niu, and Masashi Sugiyama. 2015. Convex formulation for learning from positive and unlabeled data. In International Conference on Machine Learning. 1386--1394.Google ScholarDigital Library"",""Marthinus C Du Plessis, Gang Niu, and Masashi Sugiyama. 2014. Analysis of learning from positive and unlabeled data. In Advances in neural information processing systems. 703--711.Google Scholar"",""Cynthia Dwork. 2008. Differential privacy: A survey of results. In International conference on theory and applications of models of computation. Springer, 1--19.Google ScholarDigital Library"",""Cynthia Dwork, Aaron Roth, et al. 2014. The algorithmic foundations of differential privacy. Foundations and Trends® in Theoretical Computer Science 9, 3--4 (2014), 211--407.Google Scholar"",""Charles Elkan and Keith Noto. 2008. Learning classifiers from only positive and unlabeled data. In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. 213--220.Google ScholarDigital Library"",""Trevor Hastie, Robert Tibshirani, and Jerome Friedman. 2009. Unsupervised learning. In The elements of statistical learning. Springer, 485--585.Google Scholar"",""Jim Isaak and Mina J Hanna. 2018. User data privacy: Facebook, Cambridge Analytica, and privacy protection. Computer 51, 8 (2018), 56--59.Google ScholarDigital Library"",""Durk P Kingma, Shakir Mohamed, Danilo Jimenez Rezende, and Max Welling. 2014. Semi-supervised learning with deep generative models. In Advances in neural information processing systems. 3581--3589.Google Scholar"",""Ryuichi Kiryo, Gang Niu, Marthinus C du Plessis, and Masashi Sugiyama. 2017. Positive-unlabeled learning with non-negative risk estimator. In Advances in neural information processing systems. 1675--1685.Google Scholar"",""Samuli Laine and Timo Aila. 2016. Temporal ensembling for semi-supervised learning. arXiv preprint arXiv:1610.02242 (2016).Google Scholar"",""Dong-Hyun Lee. 2013. Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks. In Workshop on challenges in representation learning, ICML, Vol. 3. 2.Google Scholar"",""Naresh K Malhotra, Sung S Kim, and James Agarwal. 2004. Internet users' information privacy concerns (IUIPC): The construct, the scale, and a causal model. Information systems research 15, 4 (2004), 336--355.Google Scholar"",""Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. 2018. Virtual adversarial training: a regularization method for supervised and semi-supervised learning. IEEE transactions on pattern analysis and machine intelligence 41, 8 (2018), 1979--1993.Google Scholar"",""Noman Mohammed, Rui Chen, Benjamin Fung, and Philip S Yu. 2011. Differentially private data release for data mining. In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 493--501.Google ScholarDigital Library"",""Rathindra Sarathy and Krishnamurty Muralidhar. 2011. Evaluating Laplace noise addition to satisfy differential privacy for numeric data. Trans. Data Privacy 4, 1 (2011), 1--17.Google ScholarDigital Library"",""Christof Strauch, Ultra-Large Scale Sites, and Walter Kriha. 2011. NoSQL databases. Lecture Notes, Stuttgart Media University 20 (2011), 24.Google Scholar"",""Junyuan Xie, Ross Girshick, and Ali Farhadi. 2016. Unsupervised deep embedding for clustering analysis. In International conference on machine learning. 478--487.Google ScholarDigital Library"",""Lei Xu, Chunxiao Jiang, Jian Wang, Jian Yuan, and Yong Ren. 2014. Information security in big data: privacy and data mining. Ieee Access 2 (2014), 1149--1176.Google ScholarCross Ref"",""Rui Xu and Donald Wunsch. 2005. Survey of clustering algorithms. IEEE Transactions on neural networks 16, 3 (2005), 645--678.Google ScholarDigital Library"",""Rui Xu and Don Wunsch. 2008. Clustering. Vol. 10. John Wiley \u0026 Sons.Google Scholar"",""Bo Yang, Xiao Fu, Nicholas D Sidiropoulos, and Mingyi Hong. 2017. Towards kmeans- friendly spaces: Simultaneous deep learning and clustering. In Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 3861--3870.Google Scholar"",""Zhen-Yu Zhang, Peng Zhao, Yuan Jiang, and Zhi-Hua Zhou. 2019. Learning from incomplete and inaccurate supervision. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1017--1025.Google ScholarDigital Library"",""Xiaojin Zhu and Andrew B Goldberg. 2009. Introduction to semi-supervised learning. Synthesis lectures on artificial intelligence and machine learning 3, 1 (2009), 1--130.Google Scholar""]"
https://doi.org/10.1145/3394486.3403149,BOND: BERT-Assisted Open-Domain Named Entity Recognition with Distant Supervision,"We study the open-domain named entity recognition (NER) problem under distant supervision. The distant supervision, though does not require large amounts of manual annotations, yields highly incomplete and noisy distant labels via external knowledge bases. To address this challenge, we propose a new computational framework -- BOND, which leverages the power of pre-trained language models (e.g., BERT and RoBERTa) to improve the prediction performance of NER models. Specifically, we propose a two-stage training algorithm: In the first stage, we adapt the pre-trained language model to the NER tasks using the distant labels, which can significantly improve the recall and precision; In the second stage, we drop the distant labels, and propose a self-training approach to further improve the model performance. Thorough experiments on 5 benchmark datasets demonstrate the superiority of BOND over existing distantly supervised NER methods. The code and distantly labeled data have been released in https://github.com/cliang1453/BOND.","[{""name"":""Chen Liang"",""id"":""/profile/99659575187""},{""name"":""Yue Yu"",""id"":""/profile/99659574219""},{""name"":""Haoming Jiang"",""id"":""/profile/99659573281""},{""name"":""Siawpeng Er"",""id"":""/profile/99659574106""},{""name"":""Ruijia Wang"",""id"":""/profile/99659574735""},{""name"":""Tuo Zhao"",""id"":""/profile/99659218321""},{""name"":""Chao Zhang"",""id"":""/profile/99659455279""},{""name"":""Chen Liang"",""id"":""/profile/99659575187""},{""name"":""Yue Yu"",""id"":""/profile/99659574219""},{""name"":""Haoming Jiang"",""id"":""/profile/99659573281""},{""name"":""Siawpeng Er"",""id"":""/profile/99659574106""},{""name"":""Ruijia Wang"",""id"":""/profile/99659574735""},{""name"":""Tuo Zhao"",""id"":""/profile/99659218321""},{""name"":""Chao Zhang"",""id"":""/profile/99659455279""}]","[""Dominic Balasuriya, Nicky Ringland, Joel Nothman, Tara Murphy, and James R Curran. 2009. Named entity recognition in wikipedia. In the 2009 Workshop on The People's Web Meets NLP. 10--18.Google ScholarCross Ref"",""Kevin Bowden, Jiaqi Wu, Shereen Oraby, Amita Misra, and Marilyn Walker. 2018. SlugNERDS: A Named Entity Recognition Tool for Open Domain Dialogue Systems. In LREC.Google Scholar"",""Yixin Cao, Zikun Hu, Tat-seng Chua, Zhiyuan Liu, and Heng Ji. 2019. Low-Resource Name Tagging Learned with Weakly Labeled Data. In EMNLP-IJCNLP. 261--270.Google Scholar"",""Kevin Clark, Minh-Thang Luong, Christopher D. Manning, and Quoc V. Le. 2018. Semi-Supervised Sequence Modeling with Cross-View Training. In EMNLP.Google Scholar"",""Ryan Cotterell and Kevin Duh. 2017. Low-Resource Named Entity Recognition with Cross-lingual, Character-Level Neural Conditional Random Fields. In IJCNLP. Asian Federation of Natural Language Processing, 91--96.Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In NAACL-HLT. 4171--4186.Google Scholar"",""Xiaocheng Feng, Xiachong Feng, Bing Qin, Zhangyin Feng, and Ting Liu. 2018. Improving Low Resource Named Entity Recognition using Cross-lingual Knowledge Transfer. In IJCAI. 4071--4077.Google Scholar"",""Jason Fries, Sen Wu, Alex Ratner, and Christopher Ré. 2017. Swellshark: A generative model for biomedical named entity recognition without labeled data. arXiv preprint arXiv:1704.06360 (2017).Google Scholar"",""Athanasios Giannakopoulos, Claudiu Musat, Andreea Hossmann, and Michael Baeriswyl. 2017. Unsupervised Aspect Term Extraction with B-LS™ \u0026 CRF using Automatically Labelled Datasets. In the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis. 180--188.Google Scholar"",""Fréderic Godin, Baptist Vandersmissen, Wesley De Neve, and Rik Van de Walle. 2015. Multimedia [email protected] acl wnut ner shared task: Named entity recognition for twitter microposts using distributed word representations. In WNUT. 146--153.Google Scholar"",""Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirectional LSTM-CRF models for sequence tagging. arXiv preprint arXiv:1508.01991 (2015).Google Scholar"",""Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao, and Tuo Zhao. 2019. SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization. arXiv preprint arXiv:1911.03437 (2019).Google Scholar"",""Deniz Karatay and Pinar Karagoz. 2015. User Interest Modeling in Twitter with Named Entity Recognition. Making Sense of Microposts (# Microposts2015) (2015).Google Scholar"",""Mahboob Alam Khalid, Valentin Jijkoun, and Maarten De Rijke. 2008. The impact of named entity normalization on information retrieval for question answering. In ECIR. Springer, 705--710.Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""John Lafferty, Andrew McCallum, and Fernando CN Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In ICML.Google Scholar"",""Ouyu Lan, Xiao Huang, Bill Yuchen Lin, He Jiang, Liyuan Liu, and Xiang Ren. 2020 b. Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling. In ACL.Google Scholar"",""Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut. 2020 a. ALBERT: A Lite BERT for Self-supervised Learning of Language Representations. In ICLR.Google Scholar"",""Qi Li, Haibo Li, Heng Ji, Wen Wang, Jing Zheng, and Fei Huang. 2012. Joint bilingual name tagging for parallel corpora. In CIKM. 1727--1731.Google Scholar"",""Nut Limsopatham and Nigel Collier. 2016. Bidirectional LSTM for named entity recognition in Twitter messages. (2016).Google Scholar"",""Angli Liu, Jingfei Du, and Veselin Stoyanov. 2019 a. Knowledge-augmented language model and its application to unsupervised named-entity recognition. In NAACL.Google Scholar"",""Liyuan Liu, Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao, and Jiawei Han. 2020. On the Variance of the Adaptive Learning Rate and Beyond. In ICLR.Google Scholar"",""Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019 b. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692 (2019).Google Scholar"",""Edward Loper and Steven Bird. 2002. NLTK: the natural language toolkit. arXiv preprint cs/0205028 (2002).Google Scholar"",""Xuezhe Ma and Eduard Hovy. 2016. End-to-end sequence labeling via bi-directional lstm-cnns-crf. In ACL. 1064--1074.Google Scholar"",""Yu Meng, Jiaming Shen, Chao Zhang, and Jiawei Han. 2018. Weakly-supervised neural text classification. In CIKM. 983--992.Google Scholar"",""Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. 2018. Virtual adversarial training: a regularization method for supervised and semi-supervised learning. IEEE T-PAMI, Vol. 41, 8 (2018), 1979--1993.Google ScholarCross Ref"",""Jian Ni, Georgiana Dinu, and Radu Florian. 2017. Weakly Supervised Cross-Lingual Named Entity Recognition via Effective Annotation and Representation Projection. In ACL. 1470--1480.Google Scholar"",""Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove: Global vectors for word representation. In EMNLP. 1532--1543.Google Scholar"",""Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. Deep Contextualized Word Representations. In NAACL-HLT. 2227--2237.Google Scholar"",""Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2019. Exploring the limits of transfer learning with a unified text-to-text transformer. arXiv preprint arXiv:1910.10683 (2019).Google Scholar"",""Afshin Rahimi, Yuan Li, and Trevor Cohn. 2019. Multilingual NER transfer for low-resource languages. arXiv preprint arXiv:1902.00193 (2019).Google Scholar"",""Lev Ratinov and Dan Roth. 2009. Design challenges and misconceptions in named entity recognition. In CoNLL. 147--155.Google Scholar"",""Chuck Rosenberg, Martial Hebert, and Henry Schneiderman. 2005. Semi-Supervised Self-Training of Object Detection Models. In WACV. 29--36.Google Scholar"",""Erik F Sang and Fien De Meulder. 2003. Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition. arXiv preprint cs/0306050 (2003).Google Scholar"",""Jingbo Shang, Liyuan Liu, Xiaotao Gu, Xiang Ren, Teng Ren, and Jiawei Han. 2018. Learning Named Entity Tagger using Domain-Specific Dictionary. In EMNLP. 2054--2064.Google Scholar"",""Benjamin Strauss, Bethany Toma, Alan Ritter, Marie-Catherine De Marneffe, and Wei Xu. 2016. Results of the wnut16 named entity recognition shared task. In WNUT. 138--144.Google Scholar"",""Antti Tarvainen and Harri Valpola. 2017. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In NIPS. 1195--1204.Google Scholar"",""Erik F. Tjong Kim Sang and Fien De Meulder. 2003. Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition. In CoNLL-2003. 142--147.Google Scholar"",""Denny Vrandevc ić and Markus Krötzsch. 2014. Wikidata: a free collaborative knowledgebase. Commun. ACM, Vol. 57, 10 (2014), 78--85.Google ScholarDigital Library"",""Ralph Weischedel, Martha Palmer, Mitchell Marcus, Eduard Hovy, Sameer Pradhan, Lance Ramshaw, Nianwen Xue, Ann Taylor, Jeff Kaufman, Michelle Franchini, et al. 2013. Ontonotes release 5.0 ldc2013t19. Linguistic Data Consortium, Philadelphia, PA, Vol. 23 (2013).Google Scholar"",""Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. 2016. Google's neural machine translation system: Bridging the gap between human and machine translation. arXiv preprint arXiv:1609.08144 (2016).Google Scholar"",""Junyuan Xie, Ross Girshick, and Ali Farhadi. 2016. Unsupervised deep embedding for clustering analysis. In ICML. 478--487.Google Scholar"",""Jiateng Xie, Zhilin Yang, Graham Neubig, Noah A. Smith, and Jaime Carbonell. 2018. Neural Cross-Lingual Named Entity Recognition with Minimal Resources. In EMNLP. 369--379. https://doi.org/10.18653/v1/D18--1034Google Scholar"",""Yaosheng Yang, Wenliang Chen, Zhenghua Li, Zhengqiu He, and Min Zhang. 2018. Distantly supervised ner with partial annotation learning and reinforcement learning. In COLING. 2159--2169.Google Scholar"",""Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, and Quoc V Le. 2019. Xlnet: Generalized autoregressive pretraining for language understanding. In NeurIPS. 5754--5764.Google Scholar"",""GuoDong Zhou and Jian Su. 2002. Named entity recognition using an HMM-based chunk tagger. In ACL. 473--480.Google Scholar"",""Yukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, and Sanja Fidler. 2015. Aligning books and movies: Towards story-like visual explanations by watching movies and reading books. In ICCV. 19--27.Google Scholar""]"
https://doi.org/10.1145/3394486.3403150,Graph Structural-topic Neural Network,"Graph Convolutional Networks (GCNs) achieved tremendous success by effectively gathering local features for nodes. However, commonly do GCNs focus more on node features but less on graph structures within the neighborhood, especially higher-order structural patterns. However, such local structural patterns are shown to be indicative of node properties in numerous fields. In addition, it is not just single patterns, but the distribution over all these patterns matter, because networks are complex and the neighborhood of each node consists of a mixture of various nodes and structural patterns. Correspondingly, in this paper, we propose Graph Structural topic Neural Network, abbreviated GraphSTONE 1, a GCN model that utilizes topic models of graphs, such that the structural topics capture indicative graph structures broadly from a probabilistic aspect rather than merely a few structures. Specifically, we build topic models upon graphs using anonymous walks and Graph Anchor LDA, an LDA variant that selects significant structural patterns first, so as to alleviate the complexity and generate structural topics efficiently. In addition, we design multi-view GCNs to unify node features and structural topic features and utilize structural topics to guide the aggregation. We evaluate our model through both quantitative and qualitative experiments, where our model exhibits promising performance, high efficiency, and clear interpretability.","[{""name"":""Qingqing Long"",""id"":""/profile/99659479056""},{""name"":""Yilun Jin"",""id"":""/profile/99659471366""},{""name"":""Guojie Song"",""id"":""/profile/81336493047""},{""name"":""Yi Li"",""id"":""/profile/99659575255""},{""name"":""Wei Lin"",""id"":""/profile/99659259418""},{""name"":""Qingqing Long"",""id"":""/profile/99659479056""},{""name"":""Yilun Jin"",""id"":""/profile/99659471366""},{""name"":""Guojie Song"",""id"":""/profile/81336493047""},{""name"":""Yi Li"",""id"":""/profile/99659575255""},{""name"":""Wei Lin"",""id"":""/profile/99659259418""}]","[""Sanjeev Arora, Rong Ge, Yonatan Halpern, David Mimno, Ankur Moitra, David Sontag, Yichen Wu, and Michael Zhu. 2013. A practical algorithm for topic modeling with provable guarantees. In International Conference on Machine Learning. 280--288.Google ScholarDigital Library"",""Sanjeev Arora, Rong Ge, and Ankur Moitra. 2012. Learning topic models--going beyond SVD. In 2012 IEEE 53rd Annual Symposium on Foundations of Computer Science. IEEE, 1--10.Google ScholarDigital Library"",""DavidMBlei, AndrewY Ng, and Michael I Jordan. 2003. Latent dirichlet allocation. Journal of machine Learning research 3, Jan (2003), 993--1022.Google ScholarDigital Library"",""Karsten M Borgwardt and Hans-Peter Kriegel. 2005. Shortest-path kernels on graphs. In Fifth IEEE international conference on data mining. IEEE, 8--pp.Google ScholarDigital Library"",""Claire Donnat, Marinka Zitnik, David Hallac, and Jure Leskovec. 2018. Learning structural node embeddings via diffusion wavelets. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1320--1329.Google ScholarDigital Library"",""Mark S Granovetter. 1977. The strength of weak ties. In Social networks. Elsevier, 347--367.Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In Advances in Neural Information Processing Systems. 1024--1034.Google Scholar"",""Sergey Ivanov and Evgeny Burnaev. 2018. Anonymous Walk Embeddings. In International Conference on Machine Learning. 2191--2200.Google Scholar"",""Di Jin, Xinxin You, Weihao Li, Dongxiao He, Peng Cui, Françoise Fogelman- Soulié, and Tanmoy Chakraborty. 2019. Incorporating network embedding into markov random field for better community detection. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 160--167.Google ScholarCross Ref"",""Yilun Jin, Guojie Song, and Chuan Shi. 2020. GraLSP: Graph Neural Networks with Local Structural Patterns. In The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, New York, NY, USA. AAAI Press, 4361--4368.Google Scholar"",""Noriaki Kawamae. 2019. Topic Structure-Aware Neural Language Model: Unified language model that maintains word and topic ordering by their embedded representations. In The World Wide Web Conference. ACM, 2900--2906.Google ScholarDigital Library"",""Thomas Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In International Conference of Learning Representations.Google Scholar"",""Danai Koutra, U Kang, Jilles Vreeken, and Christos Faloutsos. 2014. Vog: Summarizing and understanding large graphs. In Proceedings of the 2014 SIAM international conference on data mining. SIAM, 91--99.Google ScholarCross Ref"",""Daniel D Lee and H Sebastian Seung. 1999. Learning the parts of objects by non-negative matrix factorization. Nature 401, 6755 (1999), 788.Google Scholar"",""John Boaz Lee, Ryan A Rossi, Xiangnan Kong, Sungchul Kim, Eunyee Koh, and Anup Rao. 2019. Graph Convolutional Networks with Motif-based Attention. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management. 499--508.Google ScholarDigital Library"",""Ziyao Li, Liang Zhang, and Guojie Song. 2019. GCN-LASE: towards adequately incorporating link attributes in graph convolutional networks. In Proceedings of the 28th International Joint Conference on Artificial Intelligence. AAAI Press, 2959--2965.Google ScholarCross Ref"",""Lin Liu, Lin Tang, Libo He, Shaowen Yao, and Wei Zhou. 2017. Predicting protein function via multi-label supervised topic model on gene ontology. Biotechnology \u0026 Biotechnological Equipment 31, 3 (2017), 630--638.Google ScholarCross Ref"",""Yang Liu, Zhiyuan Liu, Tat-Seng Chua, and Maosong Sun. 2015. Topical word embeddings. In Twenty-Ninth AAAI Conference on Artificial Intelligence.Google ScholarDigital Library"",""Qingqing Long, Yiming Wang, Lun Du, Guojie Song, Yilun Jin, andWei Lin. 2019. Hierarchical Community Structure Preserving Network Embedding: A Subspace Approach. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management. 409--418.Google ScholarDigital Library"",""Andreas Loukas. 2020. What graph neural networks cannot learn: depth vs width. In International Conference on Learning Representations. https://openreview.net/ forum?id=B1l2bp4YwSGoogle Scholar"",""Silvio Micali and Zeyuan Allen Zhu. 2016. Reconstructing markov processes from independent and anonymous experiments. Discrete Applied Mathematics 200 (2016), 108--122.Google ScholarDigital Library"",""Ron Milo, Shai Shen-Orr, Shalev Itzkovitz, Nadav Kashtan, Dmitri Chklovskii, and Uri Alon. 2002. Network motifs: simple building blocks of complex networks. Science 298, 5594 (2002), 824--827.Google Scholar"",""Christopher Morris, Martin Ritzert, Matthias Fey, William L Hamilton, Jan Eric Lenssen, Gaurav Rattan, and Martin Grohe. 2019. Weisfeiler and leman go neural: Higher-order graph neural networks. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 4602--4609.Google ScholarCross Ref"",""Kenta Oono and Taiji Suzuki. 2020. Graph Neural Networks Exponentially Lose Expressive Power for Node Classification. In International Conference on Learning Representations. https://openreview.net/forum?id=S1ldO2EFPrGoogle Scholar"",""Leonardo FR Ribeiro, Pedro HP Saverese, and Daniel R Figueiredo. 2017. struc2vec: Learning node representations from structural identity. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 385--394.Google ScholarDigital Library"",""Nino Shervashidze, SVN Vishwanathan, Tobias Petri, Kurt Mehlhorn, and Karsten Borgwardt. 2009. Efficient graphlet kernels for large graph comparison. In Artificial Intelligence and Statistics. 488--495.Google Scholar"",""Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph attention networks. arXiv preprint arXiv:1710.10903 (2017).Google Scholar"",""Keyulu Xu,Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2018. How powerful are graph neural networks? arXiv preprint arXiv:1810.00826 (2018).Google Scholar"",""Yizhou Zhang, Guojie Song, Lun Du, Shuwen Yang, and Yilun Jin. 2019. DANE: Domain Adaptive Network Embedding. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence.Google ScholarCross Ref"",""Lekui Zhou, Yang Yang, Xiang Ren, Fei Wu, and Yueting Zhuang. 2018. Dynamic network embedding by modeling triadic closure process. In Thirty-Second AAAI Conference on Artificial Intelligence.Google Scholar""]"
https://doi.org/10.1145/3394486.3403151,Correlation Networks for Extreme Multi-label Text Classification,"This paper develops the Correlation Networks (CorNet) architecture for the extreme multi-label text classification (XMTC) task, where the objective is to tag an input text sequence with the most relevant subset of labels from an extremely large label set. XMTC can be found in many real-world applications, such as document tagging and product annotation. Recently, deep learning models have achieved outstanding performances in XMTC tasks. However, these deep XMTC models ignore the useful correlation information among different labels. CorNet addresses this limitation by adding an extra CorNet module at the prediction layer of a deep model, which is able to learn label correlations, enhance raw label predictions with correlation knowledge and output augmented label predictions. We show that CorNet can be easily integrated with deep XMTC models and generalize effectively across different datasets. We further demonstrate that CorNet can bring significant improvements over the existing deep XMTC models in terms of both performance and convergence rate. The models and datasets are available at: https://github.com/XunGuangxu/CorNet.","[{""name"":""Guangxu Xun"",""id"":""/profile/99658977012""},{""name"":""Kishlay Jha"",""id"":""/profile/99659287019""},{""name"":""Jianhui Sun"",""id"":""/profile/99659574869""},{""name"":""Aidong Zhang"",""id"":""/profile/99659573207""},{""name"":""Guangxu Xun"",""id"":""/profile/99658977012""},{""name"":""Kishlay Jha"",""id"":""/profile/99659287019""},{""name"":""Jianhui Sun"",""id"":""/profile/99659574869""},{""name"":""Aidong Zhang"",""id"":""/profile/99659573207""}]","[""Rahul Agrawal, Archit Gupta, Yashoteja Prabhu, and Manik Varma. 2013. Multi-label learning with millions of labels: Recommending advertiser bid phrases for web pages. In Proceedings of the 22nd international conference on World Wide Web. 13--24.Google Scholar"",""Rohit Babbar and Bernhard Schölkopf. 2017. Dismec: Distributed sparse machines for extreme multi-label classification. In Proceedings of the Tenth ACM International Conference on Web Search and Data Mining. 721--729.Google Scholar"",""Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473 (2014).Google Scholar"",""Shaojie Bai, J Zico Kolter, and Vladlen Koltun. 2018. An empirical evaluation of generic convolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:1803.01271 (2018).Google Scholar"",""Kush Bhatia, Himanshu Jain, Purushottam Kar, Manik Varma, and Prateek Jain. 2015. Sparse local embeddings for extreme multi-label classification. In Advances in neural information processing systems. 730--738.Google Scholar"",""Wei-Cheng Chang, Hsiang-Fu Yu, Kai Zhong, Yiming Yang, and Inderjit Dhillon. 2019. X-BERT: eXtreme Multi-label Text Classification with BERT. arXiv preprint arXiv:1905.02331 (2019).Google Scholar"",""Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. 2014. Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555 (2014).Google Scholar"",""Djork-Arné Clevert, Thomas Unterthiner, and Sepp Hochreiter. 2015. Fast and accurate deep network learning by exponential linear units (elus). arXiv preprint arXiv:1511.07289 (2015).Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).Google Scholar"",""Amit Garg, Jonathan Noyola, Romil Verma, Ashutosh Saxena, and Aditya Jami. 2015. Exploring correlation between labels to improve multi-label classification. arXiv preprint arXiv:1511.07953 (2015).Google Scholar"",""Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial nets. In Advances in neural information processing systems. 2672--2680.Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition. 770--778.Google Scholar"",""Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural computation, Vol. 9, 8 (1997), 1735--1780.Google Scholar"",""Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov, and Andrew Gordon Wilson. 2018. Averaging weights leads to wider optima and better generalization. arXiv preprint arXiv:1803.05407 (2018).Google Scholar"",""Himanshu Jain, Yashoteja Prabhu, and Manik Varma. 2016. Extreme multi-label loss functions for recommendation, tagging, ranking \u0026 other missing label applications. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 935--944.Google Scholar"",""Kalina Jasinska, Krzysztof Dembczynski, Róbert Busa-Fekete, Karlson Pfannschmidt, Timo Klerx, and Eyke Hullermeier. 2016. Extreme F-measure maximization using sparse probability estimates. In International Conference on Machine Learning. 1435--1444.Google Scholar"",""Qiao Jin, Bhuwan Dhingra, William Cohen, and Xinghua Lu. 2018. AttentionMeSH: Simple, Effective and Interpretable Automatic MeSH Indexer. In Proceedings of the 6th BioASQ Workshop A challenge on large-scale biomedical semantic indexing and question answering. 47--56.Google Scholar"",""Sujay Khandagale, Han Xiao, and Rohit Babbar. 2019. Bonsai-diverse and shallow trees for extreme multi-label classification. arXiv preprint arXiv:1904.08249 (2019).Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen Zhou, and Yoshua Bengio. 2017. A structured self-attentive sentence embedding. arXiv preprint arXiv:1703.03130 (2017).Google Scholar"",""Jingzhou Liu, Wei-Cheng Chang, Yuexin Wu, and Yiming Yang. 2017. Deep learning for extreme multi-label text classification. In Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval. 115--124.Google Scholar"",""Julian McAuley and Jure Leskovec. 2013. Hidden factors and hidden topics: understanding rating dimensions with review text. In Proceedings of the 7th ACM conference on Recommender systems. 165--172.Google Scholar"",""Eneldo Loza Mencia and Johannes Fürnkranz. 2008. Efficient pairwise multilabel classification for large-scale problems in the legal domain. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 50--65.Google Scholar"",""Tien Thanh Nguyen, Thi Thu Thuy Nguyen, Anh Vu Luong, Quoc Viet Hung Nguyen, Alan Wee-Chung Liew, and Bela Stantic. 2019. Multi-label classification via label correlation and first order feature dependance in a data stream. Pattern recognition, Vol. 90 (2019), 35--51.Google Scholar"",""Ioannis Partalas, Aris Kosmopoulos, Nicolas Baskiotis, Thierry Artieres, George Paliouras, Eric Gaussier, Ion Androutsopoulos, Massih-Reza Amini, and Patrick Galinari. 2015. Lshtc: A benchmark for large-scale text classification. arXiv preprint arXiv:1503.08581 (2015).Google Scholar"",""Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove: Global Vectors for Word Representation.. In EMNLP, Vol. 14. 1532--1543.Google Scholar"",""Yashoteja Prabhu, Anil Kag, Shrutendra Harsola, Rahul Agrawal, and Manik Varma. 2018. Parabel: Partitioned label trees for extreme classification with application to dynamic search advertising. In Proceedings of the 2018 World Wide Web Conference. 993--1002.Google Scholar"",""Yashoteja Prabhu and Manik Varma. 2014. Fastxml: A fast, accurate and stable tree-classifier for extreme multi-label learning. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. 263--272.Google Scholar"",""Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Sequence to sequence learning with neural networks. In Advances in neural information processing systems. 3104--3112.Google Scholar"",""Yukihiro Tagami. 2017. Annexml: Approximate nearest neighbor search for extreme multi-label classification. In Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 455--464.Google Scholar"",""George Tsatsaronis, Georgios Balikas, Prodromos Malakasiotis, Ioannis Partalas, Matthias Zschunke, Michael R Alvers, Dirk Weissenborn, Anastasia Krithara, Sergios Petridis, Dimitris Polychronopoulos, Yannis Almirantis, John Pavlopoulos, Nicolas Baskiotis, Patrick Gallinari, Thierry Artieres, Axel Ngonga, Norman Heino, Eric Gaussier, Liliana Barrio-Alvers, Michael Schroeder, Ion Androutsopoulos, and Georgios Paliouras. 2015. An overview of the BIOASQ large-scale biomedical semantic indexing and question answering competition. BMC Bioinformatics, Vol. 16 (2015), 138. https://doi.org/10.1186/s12859-015-0564--6Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems. 5998--6008.Google Scholar"",""Guangxu Xun, Kishlay Jha, Ye Yuan, Yaqing Wang, and Aidong Zhang. 2016. MeSHProbeNet: A Self-attentive Probe Net for MeSH Indexing. Bioinformatics, Vol. 32, 12 (2016), 70--79. https://doi.org/10.1093/bioinformatics/btw294Google Scholar"",""Guangxu Xun, Yaliang Li, Jing Gao, and Aidong Zhang. 2017a. Collaboratively improving topic discovery and word embeddings by coordinating global and local contexts. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 535--543.Google Scholar"",""Guangxu Xun, Yaliang Li, Wayne Xin Zhao, Jing Gao, and Aidong Zhang. 2017b. A Correlated Topic Model Using Word Embeddings. In Proceedings of the 26th International Joint Conference on Artificial Intelligence .Google Scholar"",""Pengcheng Yang, Xu Sun, Wei Li, Shuming Ma, Wei Wu, and Houfeng Wang. 2018. SGM: sequence generation model for multi-label classification. arXiv preprint arXiv:1806.04822 (2018).Google Scholar"",""Ian EH Yen, Xiangru Huang, Wei Dai, Pradeep Ravikumar, Inderjit Dhillon, and Eric Xing. 2017. Ppdsparse: A parallel primal-dual sparse method for extreme classification. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 545--553.Google Scholar"",""Ronghui You, Suyang Dai, Zihan Zhang, Hiroshi Mamitsuka, and Shanfeng Zhu. 2018. Attentionxml: Extreme multi-label text classification with multi-label attention based recurrent neural networks. arXiv preprint arXiv:1811.01727 (2018).Google Scholar""]"
https://doi.org/10.1145/3394486.3403152,Predicting Temporal Sets with Deep Neural Networks,"Given a sequence of sets, where each set contains an arbitrary number of elements, the problem of temporal sets prediction aims to predict the elements in the subsequent set. In practice, temporal sets prediction is much more complex than predictive modelling of temporal events and time series, and is still an open problem. Many possible existing methods, if adapted for the problem of temporal sets prediction, usually follow a two-step strategy by first projecting temporal sets into latent representations and then learning a predictive model with the latent representations. The two-step approach often leads to information loss and unsatisfactory prediction performance. In this paper, we propose an integrated solution based on the deep neural networks for temporal sets prediction. A unique perspective of our approach is to learn element relationship by constructing set-level co-occurrence graph and then perform graph convolutions on the dynamic relationship graphs. Moreover, we design an attention-based module to adaptively learn the temporal dependency of elements and sets. Finally, we provide a gated updating mechanism to find the hidden shared patterns in different sequences and fuse both static and dynamic information to improve the prediction performance. Experiments on real-world data sets demonstrate that our approach can achieve competitive performances even with a portion of the training data and can outperform existing methods with a significant margin.","[{""name"":""Le Yu"",""id"":""/profile/99659574522""},{""name"":""Leilei Sun"",""id"":""/profile/99659060352""},{""name"":""Bowen Du"",""id"":""/profile/81387598511""},{""name"":""Chuanren Liu"",""id"":""/profile/81488659491""},{""name"":""Hui Xiong"",""id"":""/profile/81451596433""},{""name"":""Weifeng Lv"",""id"":""/profile/81309509482""},{""name"":""Le Yu"",""id"":""/profile/99659574522""},{""name"":""Leilei Sun"",""id"":""/profile/99659060352""},{""name"":""Bowen Du"",""id"":""/profile/81387598511""},{""name"":""Chuanren Liu"",""id"":""/profile/81488659491""},{""name"":""Hui Xiong"",""id"":""/profile/81451596433""},{""name"":""Weifeng Lv"",""id"":""/profile/81309509482""}]","[""Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural Machine Translation by Jointly Learning to Align and Translate. In ICLR.Google Scholar"",""Austin R. Benson, Ravi Kumar, and Andrew Tomkins. 2018. Sequences of Sets. In SIGKDD. 1148--1157.Google Scholar"",""Peter J Brockwell, Richard A Davis, and Matthew V Calder. 2002. Introduction to time series and forecasting. Vol. 2. Springer.Google Scholar"",""Zhengping Che, Sanjay Purushotham, Kyunghyun Cho, David Sontag, and Yan Liu. 2018. Recurrent neural networks for multivariate time series with missing values. Scientific reports, Vol. 8, 1 (2018), 6085.Google Scholar"",""Edward Choi, Mohammad Taha Bahadori, Elizabeth Searles, Catherine Coffey, Michael Thompson, James Bost, Javier Tejedor-Sojo, and Jimeng Sun. 2016. Multi-layer representation learning for medical concepts. In SIGKDD. ACM, 1495--1504.Google Scholar"",""Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. 2014. Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555 (2014).Google Scholar"",""Manish Gupta, Jing Gao, Charu C. Aggarwal, and Jiawei Han. 2014. Outlier Detection for Temporal Data: A Survey. IEEE Trans. Knowl. Data Eng., Vol. 26, 9 (2014), 2250--2267.Google ScholarCross Ref"",""William L. Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive Representation Learning on Large Graphs. In Advances in Neural Information Processing Systems. 1024--1034.Google Scholar"",""Sepp Hochreiter and Jü rgen Schmidhuber. 1997. Long Short-Term Memory. Neural Computation, Vol. 9, 8 (1997), 1735--1780.Google ScholarDigital Library"",""Haoji Hu and Xiangnan He. 2019. Sets2Sets: Learning from Sequential Sets with Neural Networks. In SIGKDD. 1491--1499.Google Scholar"",""Sergey Ioffe and Christian Szegedy. 2015. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. In ICML. 448--456.Google ScholarDigital Library"",""Bo Jin, Haoyu Yang, Leilei Sun, Chuanren Liu, Yue Qu, and Jianing Tong. 2018. A treatment engine by predicting next-period prescriptions. In SIGKDD. 1608--1616.Google Scholar"",""Urvashi Khandelwal, He He, Peng Qi, and Dan Jurafsky. 2018. Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context. In ACL. 284--294.Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In ICLR.Google Scholar"",""Srivatsan Laxman and P Shanti Sastry. 2006. A survey of temporal data mining. Sadhana, Vol. 31, 2 (2006), 173--198.Google ScholarCross Ref"",""Juho Lee, Yoonho Lee, Jungtaek Kim, Adam R. Kosiorek, Seungjin Choi, and Yee Whye Teh. 2019. Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks. In ICML. 3744--3753.Google Scholar"",""Liangyue Li, How Jing, Hanghang Tong, Jaewon Yang, Qi He, and Bee-Chung Chen. 2017. Nemo: Next career move prediction with contextual embedding. In Proceedings of the 26th International Conference on World Wide Web Companion. International World Wide Web Conferences Steering Committee, 505--513.Google ScholarDigital Library"",""Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. 2018. Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting. In ICLR.Google Scholar"",""Aravind Sankar, Yanhong Wu, Liang Gou, Wei Zhang, and Hao Yang. 2018. Dynamic Graph Representation Learning via Self-Attention Networks. arXiv preprint arXiv:1812.09430 (2018).Google Scholar"",""Leilei Sun, Chuanren Liu, Chonghui Guo, Hui Xiong, and Yanming Xie. 2016. Data-driven automatic treatment regimen development and recommendation. In SIGKDD. 1865--1874.Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998--6008.Google Scholar"",""Lu Wang, Wei Zhang, Xiaofeng He, and Hongyuan Zha. 2018. Supervised reinforcement learning with recurrent neural network for dynamic treatment recommendation. In SIGKDD. ACM, 2447--2456.Google Scholar"",""Jie Xu, Tianwei Xing, and Mihaela Van Der Schaar. 2016. Personalized course sequence recommendations. IEEE Transactions on Signal Processing, Vol. 64, 20 (2016), 5340--5352.Google ScholarCross Ref"",""Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron C. Courville, Ruslan Salakhutdinov, Richard S. Zemel, and Yoshua Bengio. 2015. Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. In ICML. 2048--2057.Google Scholar"",""Feng Yu, Qiang Liu, Shu Wu, Liang Wang, and Tieniu Tan. 2016. A dynamic recurrent model for next basket recommendation. In SIGIR. ACM, 729--732.Google Scholar"",""Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan R Salakhutdinov, and Alexander J Smola. 2017. Deep sets. In Advances in neural information processing systems. 3391--3401.Google Scholar"",""Jie Zhou, Ganqu Cui, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, and Maosong Sun. 2018. Graph Neural Networks: A Review of Methods and Applications. CoRR, Vol. abs/1812.08434 (2018).Google Scholar""]"
https://doi.org/10.1145/3394486.3403153,FreeDOM: A Transferable Neural Architecture for Structured Information Extraction on Web Documents,"Extracting structured data from HTML documents is a long-studied problem with a broad range of applications like augmenting knowledge bases, supporting faceted search, and providing domain-specific experiences for key verticals like shopping and movies. Previous approaches have either required a small number of examples for each target site or relied on carefully handcrafted heuristics built over visual renderings of websites. In this paper, we present a novel two-stage neural approach, named FreeDOM, which overcomes both these limitations. The first stage learns a representation for each DOM node in the page by combining both the text and markup information. The second stage captures longer range distance and semantic relatedness using a relational neural network. By combining these stages, FreeDOM is able to generalize to unseen sites after training on a small number of seed sites from that vertical without requiring expensive hand-crafted features over visual renderings of the page. Through experiments on a public dataset with 8 different verticals, we show that FreeDOM beats the previous state of the art by nearly 3.7 F1 points on average without requiring features over rendered pages or expensive hand-crafted features.","[{""name"":""Bill Yuchen Lin"",""id"":""/profile/99659533863""},{""name"":""Ying Sheng"",""id"":""/profile/99659572990""},{""name"":""Nguyen Vo"",""id"":""/profile/99659369297""},{""name"":""Sandeep Tata"",""id"":""/profile/99659192915""},{""name"":""Bill Yuchen Lin"",""id"":""/profile/99659533863""},{""name"":""Ying Sheng"",""id"":""/profile/99659572990""},{""name"":""Nguyen Vo"",""id"":""/profile/99659369297""},{""name"":""Sandeep Tata"",""id"":""/profile/99659192915""}]","[""Mohd Amir Bin Mohd Azir and Kamsuriah Ahmad. Wrapper approaches for web data extraction : A review. pages 1--6, 2017.Google Scholar"",""Andrew Carlson and Charles Schafer. Bootstrapping information extraction from semi-structured web pages. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 195--210. Springer, 2008.Google ScholarCross Ref"",""Chia-Hui Chang, Mohammed O. Kayed, Moheb R. Girgis, and Khaled F. Shaalan. A survey of web information extraction systems. IEEE Transactions on Knowledge and Data Engineering, 18: 1411--1428, 2006.Google ScholarDigital Library"",""Joseph Paul Cohen, Wei Ding, and Abraham Bagherjeiran. Semi-supervised web wrapper repair via recursive tree matching. ArXiv, abs/1505.01303, 2015.Google Scholar"",""Valter Crescenzi, Giansalvatore Mecca, and Paolo Merialdo. Roadrunner: Towards automatic data extraction from large web sites. In VLDB, 2001.Google ScholarDigital Library"",""Wanyun Cui, Yanghua Xiao, Haixun Wang, Yangqiu Song, Seung won Hwang, and Wei Yang Wang. Kbqa: Learning question answering over qa corpora and knowledge bases. PVLDB, 10: 565--576, 2017.Google ScholarDigital Library"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. In NAACL-HLT, 2019.Google Scholar"",""Dong, Gabrilovich, Heitz, Horn, Lao, Murphy, Strohmann, Sun, and Zhang]Dong2014KnowledgeVAXin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Ni Lao, Kevin Murphy, Thomas Strohmann, Shaohua Sun, and Wei Zhang. Knowledge vault: a web-scale approach to probabilistic knowledge fusion. In KDD, 2014 a .Google ScholarDigital Library"",""Dong, Gabrilovich, Heitz, Horn, Murphy, Sun, and Zhang]Dong2014FromDFXin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Kevin Murphy, Shaohua Sun, and Wei Zhang. From data fusion to knowledge fusion. PVLDB, 7: 881--892, 2014 b .Google Scholar"",""Emilio Ferrara, Pasquale De Meo, Giacomo Fiumara, and Robert Baumgartner. Web data extraction, applications and techniques: A survey. Knowledge-based systems, 70: 301--323, 2014.Google Scholar"",""Anna Lisa Gentile, Ziqi Zhang, and Fabio Ciravegna. Web scale information extraction with lodie. In AAAI Fall Symposia, 2013.Google Scholar"",""Pankaj Gulhane, Rajeev Rastogi, Srinivasan H. Sengamedu, and Ashwin Tengli. Exploiting content redundancy for web information extraction. In WWW, 2010.Google Scholar"",""Pankaj Gulhane, Amit Madaan, Rupesh R. Mehta, Jeyashankher Ramamirtham, Rajeev Rastogi, Sandeepkumar Satpal, Srinivasan H. Sengamedu, Ashwin Tengli, and Charu Tiwari. Web-scale information extraction with vertex. 2011 IEEE 27th International Conference on Data Engineering, pages 1209--1220, 2011.Google ScholarDigital Library"",""Qiang Hao, Rui Cai, Yanwei Pang, and Lei Zhang. From one tree to a forest: a unified solution for structured web data extraction. In SIGIR, 2011.Google ScholarDigital Library"",""Mandar Joshi, Eunsol Choi, Omer Levy, Daniel Weld, and Luke Zettlemoyer. pair2vec: Compositional word-pair embeddings for cross-sentence inference. In Proceedings of NAACL-HLT, 2019.Google ScholarCross Ref"",""Furkan Kocayusufoglu, Ying Sheng, Nguyen Vo, James Wendt, Qi Zhao, Sandeep Tata, and Marc Najork. Riser: Learning better representations for richly structured emails. In The World Wide Web Conference, pages 886--895. ACM, 2019.Google ScholarDigital Library"",""Nicholas Kushmerick, Daniel S. Weld, and Robert B. Doorenbos. Wrapper induction for information extraction. In IJCAI, 1997.Google ScholarDigital Library"",""John D. Lafferty, Andrew McCallum, and Fernando Pereira. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In ICML, 2001.Google ScholarDigital Library"",""Guillaume Lample, Miguel Ballesteros, Sandeep Subramanian, Kazuya Kawakami, and Chris Dyer. Neural architectures for named entity recognition. In HLT-NAACL, 2016.Google ScholarCross Ref"",""Xiang Li, Yanxu Zhu, Gang Yin, Tao Wang, and Huaimin Wang. Exploiting attribute redundancy in extracting open source forge websites. 2012 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery, pages 13--20, 2012.Google ScholarDigital Library"",""Bill Y. Lin, Frank F. Xu, Zhiyi Luo, and Kenny Q. Zhu. Multi-channel bilstm-crf model for emerging named entity recognition in social media. In [email protected], 2017.Google Scholar"",""Bill Yuchen Lin and Wei Lu. Neural adaptation layers for cross-domain named entity recognition. In EMNLP, 2018.Google ScholarCross Ref"",""Lin, Chen, Chen, and Ren]lin-etal-2019-kagnetBill Yuchen Lin, Xinyue Chen, Jamin Chen, and Xiang Ren. KagNet: Knowledge-aware graph networks for commonsense reasoning. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, 2019 a .Google ScholarCross Ref"",""Lin, Lee, Xu, Lan, and Ren]lin-etal-2019-alpacatagBill Yuchen Lin, Dong-Ho Lee, Frank F. Xu, Ouyu Lan, and Xiang Ren. AlpacaTag: An active learning-based crowd annotation framework for sequence tagging. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, 2019 b .Google ScholarCross Ref"",""Colin Lockard, Xin Luna Dong, Prashant Shiralkar, and Arash Einolghozati. CERES: distantly supervised relation extraction from the semi-structured web. PVLDB, 11 (10): 1084--1096, 2018. 10.14778/3231751.3231758.Google ScholarDigital Library"",""Colin Lockard, Prashant Shiralkar, Xin Dong, and Hannaneh Hajishirzi. Zeroshotceres: Zero-shot relation extraction from semi-structured webpages. In Proceedings of ACL, 2020.Google Scholar"",""Zhiyi Luo, Shanshan Huang, Frank F. Xu, Bill Yuchen Lin, Hanyuan Shi, and Kenny Q. Zhu. Extra: Extracting prominent review aspects from customer feedback. In EMNLP, 2018.Google ScholarCross Ref"",""Weizhi Ma, Min Zhang, Yue Cao, Woojeong Jin, Chenyang Wang, Yiqun Liu, Shaoping Ma, and Xiang Ren. Jointly learning explainable rules for recommendation with knowledge graph. In WWW, 2019.Google Scholar"",""Xuezhe Ma and Eduard Hovy. End-to-end sequence labeling via bi-directional lstm-cnns-crf. arXiv preprint arXiv:1603.01354, 2016.Google Scholar"",""Sergey Melnik, Andrey Gubarev, Jing Jing Long, Geoffrey Romer, Shiva Shivakumar, Matt Tolton, and Theo Vassilakis. Dremel: interactive analysis of web-scale datasets. Commun. ACM, 54: 114--123, 2011.Google ScholarDigital Library"",""Adi Omari, Benny Kimelfeld, Eran Yahav, and Sharon Shoham. Lossless separation of web pages into layout code and data. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, pages 1805--1814, 2016.Google ScholarDigital Library"",""Jeffrey Pennington, Richard Socher, and Christopher D. Manning. Glove: Global vectors for word representation. In Empirical Methods in Natural Language Processing (EMNLP), pages 1532--1543, 2014.Google ScholarCross Ref"",""Dustin Arendt Prasha Shresha, Suraj Maharjan and Svitlana Volkova. Forecasting social interactions from dynamic graphs: A case study of twitter, github, and youtube. In Proceedings of the 15th International Workshop on Mining and Learning with Graphs (MLG), 2019.Google Scholar"",""Yujie Qian, Enrico Santus, Zhijing Jin, Jiang Guo, and Regina Barzilay. Graphie: A graph-based framework for information extraction. In NAACL-HLT, 2018.Google Scholar"",""Xiang Ren, Wenqi He, Meng Qu, Lifu Huang, Heng Ji, and Jiawei Han. Afet: Automatic fine-grained entity typing by hierarchical partial-label embedding. In EMNLP, 2016.Google ScholarCross Ref"",""Adam Santoro, David Raposo, David G. T. Barrett, Mateusz Malinowski, Razvan Pascanu, Peter W. Battaglia, and Timothy P. Lillicrap. A simple neural network module for relational reasoning. In NIPS, 2017.Google ScholarDigital Library"",""ig, and Gaedke]schulz2016practicalAndreas Schulz, Jörg L\""assig, and Martin Gaedke. Practical web data extraction: are we there yet?-a short survey. In 2016 IEEE/WIC/ACM International Conference on Web Intelligence (WI), pages 562--567. IEEE, 2016.Google ScholarCross Ref"",""Hassan A. Sleiman and Rafael Corchuelo. A survey on region extractors from web documents. IEEE Transactions on Knowledge and Data Engineering, 25: 1960--1981, 2013.Google ScholarDigital Library"",""Alon Talmor and Jonathan Berant. The web as a knowledge-base for answering complex questions. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 641--651, New Orleans, Louisiana, June 2018. Association for Computational Linguistics. 10.18653/v1/N18--1059.Google ScholarCross Ref"",""Rakshit Trivedi, Hanjun Dai, Yichen Wang, and Le Song. Know-evolve: Deep temporal reasoning for dynamic knowledge graphs. In ICML, 2017.Google Scholar"",""Hongwei Wang, Fuzheng Zhang, Miao Zhao, Wenjie Li, Xing Xie, and Minyi Guo. Multi-task feature learning for knowledge graph enhanced recommendation. In WWW, 2019.Google Scholar"",""Wu2018FonduerKBSen Wu, Luke Hsiao, Xiao Cheng, Braden Hancock, Theodoros Rekatsinas, Philip Levis, and Christopher Ré. Fonduer: Knowledge base construction from richly formatted data. Proceedings of the 2018 International Conference on Management of Data, 2018.Google Scholar"",""Zichao Yang, Diyi Yang, Chris Dyer, Xiaodong He, Alexander J. Smola, and Eduard H. Hovy. Hierarchical attention networks for document classification. In HLT-NAACL, 2016.Google ScholarCross Ref"",""Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou, and Jun Zhao. Relation classification via convolutional deep neural network. In COLING, 2014.Google Scholar"",""Yanhong Zhai and Bing Liu. Web data extraction based on partial tree alignment. In WWW, 2005.Google Scholar"",""Wenxuan Zhou, Hongtao Lin, Bill Yuchen Lin, Ziqi Wang, Junyi Du, Leonardo Neves, and Xiang Ren. Nero: A neural rule grounding framework for label-efficient relation extraction. In Proceedings of The Web Conference 2020, WWW '20, page 2166--2176, New York, NY, USA, 2020. Association for Computing Machinery. ISBN 9781450370233. 10.1145/3366423.3380282.Google ScholarDigital Library"",""Jun Zhu, Zaiqing Nie, Ji-Rong Wen, Bo Zhang, and Wei-Ying Ma. 2d conditional random fields for web information extraction. In ICML, 2005.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403154,SEAL: Learning Heuristics for Community Detection with Generative Adversarial Networks,"Community detection is an important task with many applications. However, there is no universal definition of communities, and a variety of algorithms have been proposed based on different assumptions. In this paper, we instead study the semi-supervised community detection problem where we are given several communities in a network as training data and aim to discover more communities. This setting makes it possible to learn concepts of communities from data without any prior knowledge. We propose the Seed Expansion with generative Adversarial Learning (SEAL), a framework for learning heuristics for community detection. SEAL contains a generative adversarial network, where the discriminator predicts whether a community is real or fake, and the generator generates communities that cheat the discriminator by implicitly fitting characteristics of real ones. The generator is a graph neural network specialized in sequential decision processes and gets trained by policy gradient. Moreover, a locator is proposed to avoid well-known free-rider effects by forming a dual learning task with the generator. Last but not least, a seed selector is utilized to provide promising seeds to the generator. We evaluate SEAL on 5 real-world networks and prove its effectiveness.","[{""name"":""Yao Zhang"",""id"":""/profile/99659473012""},{""name"":""Yun Xiong"",""id"":""/profile/81100313927""},{""name"":""Yun Ye"",""id"":""/profile/99659574759""},{""name"":""Tengfei Liu"",""id"":""/profile/99659573251""},{""name"":""Weiqiang Wang"",""id"":""/profile/99659573295""},{""name"":""Yangyong Zhu"",""id"":""/profile/81452599411""},{""name"":""Philip S. Yu"",""id"":""/profile/81556177556""},{""name"":""Yao Zhang"",""id"":""/profile/99659473012""},{""name"":""Yun Xiong"",""id"":""/profile/81100313927""},{""name"":""Yun Ye"",""id"":""/profile/99659574759""},{""name"":""Tengfei Liu"",""id"":""/profile/99659573251""},{""name"":""Weiqiang Wang"",""id"":""/profile/99659573295""},{""name"":""Yangyong Zhu"",""id"":""/profile/81452599411""},{""name"":""Philip S. Yu"",""id"":""/profile/81556177556""}]","[""Edoardo M Airoldi, David M Blei, Stephen E Fienberg, and Eric P Xing. 2008. Mixed membership stochastic blockmodels. JMLR , Vol. 9, Sep (2008), 1981--2014.Google Scholar"",""Reid Andersen, Fan Chung, and Kevin Lang. 2006. Local graph partitioning using pagerank vectors. In focs. 475--486.Google Scholar"",""Reid Andersen and Kevin J Lang. 2006. Communities from seed sets. In WWW. 223--232.Google Scholar"",""Arjun Bakshi, Srinivasan Parthasarathy, and Kannan Srinivasan. 2018. Semi-Supervised Community Detection Using Structure and Size. In ICDM. IEEE, 869--874.Google Scholar"",""Vincent D Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefebvre. 2008. Fast unfolding of communities in large networks. JSTAT , Vol. 2008, 10 (2008), P10008.Google ScholarCross Ref"",""Chen Cai and Yusu Wang. 2018. A simple yet effective baseline for non-attributed graph classification. In ICLR Workshop .Google Scholar"",""Sandro Cavallari, Vincent W Zheng, Hongyun Cai, Kevin Chen-Chuan Chang, and Erik Cambria. 2017. Learning community embedding with community detection and node embedding on graphs. In CIKM . 377--386.Google Scholar"",""Zhengdao Chen, Xiang Li, and Joan Bruna. 2017. Supervised community detection with line graph neural networks. In ICLR .Google Scholar"",""Eric Eaton and Rachael Mansbach. 2012. A spin-glass model for semi-supervised community detection. In AAAI .Google Scholar"",""Yixiang Fang, Xin Huang, Lu Qin, Ying Zhang, Wenjie Zhang, Reynold Cheng, and Xuemin Lin. 2019. A survey of community search over big graphs. The VLDB Journal (2019), 1--40.Google Scholar"",""Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial nets. In NeurIPS. 2672--2680.Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In NeurIPS. 1024--1034.Google Scholar"",""Di He, Yingce Xia, Tao Qin, Liwei Wang, Nenghai Yu, Tie-Yan Liu, and Wei-Ying Ma. 2016. Dual learning for machine translation. In NeurIPS. 820--828.Google Scholar"",""Xin Huang and Laks VS Lakshmanan. 2017. Attribute-driven community search. PVLDB , Vol. 10, 9 (2017), 949--960.Google ScholarDigital Library"",""Yuting Jia, Qinqin Zhang, Weinan Zhang, and Xinbing Wang. 2019. Communitygan: Community detection with generative adversarial nets. In WWW . 784--794.Google Scholar"",""Elias Khalil, Hanjun Dai, Yuyu Zhang, Bistra Dilkina, and Le Song. 2017. Learning combinatorial optimization algorithms over graphs. In NeurIPS. 6348--6358.Google Scholar"",""Thomas N Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional networks. In ICLR .Google Scholar"",""Johannes Klicpera, Aleksandar Bojchevski, and Stephan Günnemann. 2019. Predict then Propagate: Graph Neural Networks meet Personalized PageRank. In ICLR .Google Scholar"",""Jiwei Li, Will Monroe, Tianlin Shi, Sébastien Jean, Alan Ritter, and Dan Jurafsky. 2017. Adversarial Learning for Neural Dialogue Generation. In EMNLP . 2157--2169.Google Scholar"",""Ye Li, Chaofeng Sha, Xin Huang, and Yanchun Zhang. 2018b. Community detection in attributed graphs: An embedding approach. In AAAI .Google Scholar"",""Zhuwen Li, Qifeng Chen, and Vladlen Koltun. 2018a. Combinatorial optimization with graph convolutional networks and guided tree search. In NeurIPS . 539--548.Google Scholar"",""Jun Ma, Danqing Zhang, Yun Wang, Yan Zhang, and Alexey Pozdnoukhov. 2018. GraphRAD: A Graph-based Risky Account Detection System. In MLG .Google Scholar"",""Qiang Ma, Suwen Ge, Danyang He, Darshan Thaker, and Iddo Drori. 2019. Combinatorial Optimization by Graph Pointer Networks and Hierarchical Reinforcement Learning. arXiv preprint arXiv:1911.04936 (2019).Google Scholar"",""Akash Mittal, Anuj Dhawan, Sourav Medya, Sayan Ranu, and Ambuj Singh. 2020. Learning heuristics over large graphs via deep reinforcement learning. In AAAI .Google Scholar"",""Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness, Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg Ostrovski, et almbox. 2015. Human-level control through deep reinforcement learning. Nature , Vol. 518, 7540 (2015), 529--533.Google Scholar"",""Gergely Palla, Imre Derényi, Illés Farkas, and Tamás Vicsek. 2005. Uncovering the overlapping community structure of complex networks in nature and society. nature , Vol. 435, 7043 (2005), 814--818.Google Scholar"",""Marcelo Prates, Pedro HC Avelar, Henrique Lemos, Luis C Lamb, and Moshe Y Vardi. 2019. Learning to solve NP-complete problems: A graph neural network for decision TSP. In AAAI . 4731--4738.Google Scholar"",""Jianbo Shi and Jitendra Malik. 2000. Normalized cuts and image segmentation. PAMI , Vol. 22, 8 (2000), 888--905.Google ScholarDigital Library"",""Mauro Sozio and Aristides Gionis. 2010. The community-search problem and how to plan a successful cocktail party. In KDD . 939--948.Google Scholar"",""Richard S Sutton, David A McAllester, Satinder P Singh, and Yishay Mansour. 2000. Policy gradient methods for reinforcement learning with function approximation. In NeurIPS . 1057--1063.Google Scholar"",""Oriol Vinyals, Samy Bengio, and Manjunath Kudlur. 2016. Order matters: Sequence to sequence for sets. In ICLR .Google Scholar"",""Xiao Wang, Di Jin, Xiaochun Cao, Liang Yang, and Weixiong Zhang. 2016. Semantic community identification in large attribute networks. In AAAI .Google Scholar"",""Felix Wu, Amauri Souza, Tianyi Zhang, Christopher Fifty, Tao Yu, and Kilian Weinberger. 2019. Simplifying Graph Convolutional Networks. In ICML. 6861--6871.Google Scholar"",""Yubao Wu, Ruoming Jin, Jing Li, and Xiang Zhang. 2015. Robust local community detection: on free rider effect and its elimination. PVLDB , Vol. 8, 7 (2015), 798--809.Google ScholarDigital Library"",""Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2018. How powerful are graph neural networks?. In ICLR .Google Scholar"",""Jaewon Yang and Jure Leskovec. 2013. Overlapping community detection at scale: a nonnegative matrix factorization approach. In WSDM. 587--596.Google Scholar"",""Jaewon Yang and Jure Leskovec. 2015. Defining and evaluating network communities based on ground-truth. Kais , Vol. 42, 1 (2015), 181--213.Google ScholarDigital Library"",""Jaewon Yang, Julian McAuley, and Jure Leskovec. 2013. Community detection in networks with node attributes. In ICDM . 1151--1156.Google Scholar"",""Lantao Yu, Weinan Zhang, Jun Wang, and Yong Yu. 2017. Seqgan: Sequence generative adversarial nets with policy gradient. In AAAI .Google Scholar"",""Zhong-Yuan Zhang. 2013. Community structure detection in complex networks with partial background information. EPL , Vol. 101, 4 (2013), 48005.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403164,Matrix Profile XXI: A Geometric Approach to Time Series Chains Improves Robustness,"Time series motifs have become a fundamental tool to characterize repeated and conserved structure in systems, such as manufacturing telemetry, economic activities, and both human physiological and cultural behaviors. Recently time series chains were introduced as a generalization of time series motifs to represent evolving patterns in time series, in order to characterize the evolution of systems. Time series chains are a very promising primitive; however, we have observed that the original definition can be brittle in the sense that a small fluctuation in time series may ""cut"" a chain. Furthermore, the original definition does not provide a measure of the ""significance"" of a chain, and therefore cannot support top-k search for chains or provide a mechanism to discard spurious chains that might be discovered when searching large datasets. Inspired by observations from dynamical systems theory, this paper introduces two novel quality metrics for time series chains, directionality and graduality, to improve robustness and to enable top-K search. With extensive empirical work we show that our proposed definition is much more robust to the vagaries of real-word datasets and allows us to find unexpected regularities in time series datasets.","[{""name"":""Makoto Imamura"",""id"":""/profile/81438593536""},{""name"":""Takaaki Nakamura"",""id"":""/profile/99659573440""},{""name"":""Eamonn Keogh"",""id"":""/profile/81100209161""},{""name"":""Makoto Imamura"",""id"":""/profile/81438593536""},{""name"":""Takaaki Nakamura"",""id"":""/profile/99659573440""},{""name"":""Eamonn Keogh"",""id"":""/profile/81100209161""}]","[""Bertens R., Vreeken J., and Siebes A. Keeping it short and simple: Summarising complex event sequences with multivariate patterns. In ACM SIGKDD 2016, pages 735--744, 2016.Google ScholarDigital Library"",""Bögel T., and Gertz M. Time will Tell: Temporal Linking of News Stories. In Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries, pp. 195--204.Google Scholar"",""Ding H., Trajcevski G., Scheuermann P., Wang X., and Keogh E. Querying and Mining of Time Series Data: Experimental Comparison of Representations and Distance Measures. VLDB 2008, 1542--52.Google Scholar"",""Gama J., ?liobait? I., Bifet A., Pechenizkiy M., and Bouchachia A. A survey on concept drift adaptation. ACM Computing Surveys (CSUR), 46,4 (2014): 1--37.Google Scholar"",""Heldt T, Oefinger MB, Hoshiyama M, Mark RG. Circulatory response to passive and active changes in posture. Comput Cardiol, 30:263--266, Sept. 2003.Google Scholar"",""Hirsch, M. W., S, Smale, s. and Devaney, R. L. Differential Equations, Dynamical systems, and an Introduction to Chaos, ELSEVIER (2013): 218--222.Google Scholar"",""Krumme C., Llorente A., Cebrian M., Pentland A., and Moro E. The predictability of consumer visitation patterns. Scientific Reports (1645). 2013.Google Scholar"",""Lovallo W, et. al. Blood pressure response to caffeine shows incomplete tolerance after short-term regular consumption. Hypertension, 43.4 (2004): 760--5.Google ScholarCross Ref"",""Madrid F., et. al. Matrix Profile XX: Finding and Visualizing Time Series Motifs of All Lengths using the Matrix Profile. ICBK 2019: 175--182.Google Scholar"",""Murray D., et. al. A data management platform for personalised real-time energy feedback. In EEDAL, 2015.Google Scholar"",""Syed Z., et al. Motif discovery in physiological datasets: a methodology for inferring predictive elements. TKDD, 4.1(2010): 2.Google Scholar"",""Wang S., Yuan Y., and Li H. Discovering All-Chain Set in Streaming Time Series. PAKDD (1) 2019: 306--31.Google Scholar"",""Yeh C.C.M., et. al. 2018. Time series joins, motifs, discords and shapelets: a unifying view that exploits the matrix profile. Data Mining and Knowledge Discovery, 32(1), pp.83--123.Google ScholarDigital Library"",""Yeh C.C.M., et. al. Matrix Profile I: All Pairs Similarity Joins for Time Series: A Unifying View that Includes Motifs, Discords and Shapelets. IEEE ICDM 2016, pp. 1317--1322.Google Scholar"",""Zhu Y., Imamura M., Nikovski D., and Keogh E. Matrix Profile VII: Time Series Chains: A New Primitive for Time Series Data Mining. 2017 IEEE ICDM, New Orleans, LA, 2017, pp. 695--704.Google Scholar"",""Zhu Y., Imamura M., Nikovski D., and Keogh E. Introducing time series chains: a new primitive for time series data mining. Knowl. Inf. Syst. 60(2): 1135--1161.Google ScholarDigital Library"",""Zhu, Y., et al., Matrix Profile II: Exploiting a Novel Algorithm and GPUs to Break the One Hundred Million Barrier for Time Series Motifs and Joins. ICDM 2016.Google ScholarCross Ref"",""Supporting Webpage: https://sites.google.com/site/timeserieschains/Google Scholar""]"
https://doi.org/10.1145/3394486.3403165,Retrospective Loss: Looking Back to Improve Training of Deep Neural Networks,"Deep neural networks (DNNs) are powerful learning machines that have enabled breakthroughs in several domains. In this work, we introduce a new retrospective loss to improve the training of deep neural network models by utilizing the prior experience available in past model states during training. Minimizing the retrospective loss, along with the task-specific loss, pushes the parameter state at the current training step towards the optimal parameter state while pulling it away from the parameter state at a previous training step. Although a simple idea, we analyze the method as well as to conduct comprehensive sets of experiments across domains - images, speech, text, and graphs - to show that the proposed loss results in improved performance across input domains, tasks, and architectures.","[{""name"":""Surgan Jandial"",""id"":""/profile/99659574771""},{""name"":""Ayush Chopra"",""id"":""/profile/99659575124""},{""name"":""Mausoom Sarkar"",""id"":""/profile/99659574042""},{""name"":""Piyush Gupta"",""id"":""/profile/99659533869""},{""name"":""Balaji Krishnamurthy"",""id"":""/profile/99659179645""},{""name"":""Vineeth Balasubramanian"",""id"":""/profile/81351598929""},{""name"":""Surgan Jandial"",""id"":""/profile/99659574771""},{""name"":""Ayush Chopra"",""id"":""/profile/99659575124""},{""name"":""Mausoom Sarkar"",""id"":""/profile/99659574042""},{""name"":""Piyush Gupta"",""id"":""/profile/99659533869""},{""name"":""Balaji Krishnamurthy"",""id"":""/profile/99659179645""},{""name"":""Vineeth Balasubramanian"",""id"":""/profile/81351598929""}]","[""[n.d.]. ACGAN-Pytorch. https://github.com/eriklindernoren/PyTorch-GANGoogle Scholar"",""[n.d.]. DCGAN-Pytorch. https://github.com/pytorch/examples/tree/master/dcganGoogle Scholar"",""2018. Inception Score Code. https://github.com/sbarratt/inception-score-pytorchGoogle Scholar"",""Filippo Maria Bianchi, Daniele Grattarola, Cesare Alippi, and Lorenzo Livi. 2019.Graph Neural Networks with convolutional ARMA filters. arXiv:arXiv:1901.01343Google Scholar"",""Carlos Busso, Murtaza Bulut, Chi-Chun Lee, Abe Kazemzadeh, Emily Mower, Samuel Kim, Jeannette N Chang, Sungbok Lee, and Shrikanth S Narayanan. 2008. IEMOCAP: Interactive emotional dyadic motion capture database. Language resources and evaluation 42, 4 (2008), 335.Google Scholar"",""Gal Chechik, Varun Sharma, Uri Shalit, and Samy Bengio. 2010. Large scaleonline learning of image similarity through ranking.Journal of Machine Learning Research 11, Mar (2010), 1109--1135.Google Scholar"",""Wei-Yu Chen, Yen-Cheng Liu, Zsolt Kira, Yu-Chiang Frank Wang, and Jia-BinHuang. 2019. A Closer Look at Few-shot Classification.CoRRabs/1904.04232(2019). arXiv:1904.04232 http://arxiv.org/abs/1904.04232Google Scholar"",""Wei-Yu Chen. 2019. https://github.com/wyharveychen/CloserLookFewShot.URL(2019).Google Scholar"",""Sentic-Emotion Co. 2019. https://github.com/SenticNet/conv-emotion.URL(2019).Google Scholar"",""Matthias Fey and Jan E. Lenssen. 2019. Fast Graph Representation Learning with PyTorch Geometric. In ICLR Workshop on Representation Learning on Graphs and Manifolds.Google Scholar"",""Raia Hadsell, Sumit Chopra, and Yann LeCun. 2006. Dimensionality reduction by learning an invariant mapping. In 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), Vol. 2. IEEE, 1735--1742.Google Scholar"",""Song Han, Jeff Pool, Sharan Narang, Huizi Mao, Enhao Gong, Shijian Tang, Erich Elsen, Peter Vajda, Manohar Paluri, John Tran, Bryan Catanzaro, and William J.Dally. 2016. DSD: Dense-Sparse-Dense Training for Deep Neural Networks. In ICLR.Google Scholar"",""Hado V. Hasselt. 2010. Double Q-learning. In Advances in Neural Information Processing Systems 23, J. D. Lafferty, C. K. I. Williams, J. Shawe-Taylor, R. S. Zemel,and A. Culotta (Eds.). Curran Associates, Inc., 2613--2621.Google ScholarDigital Library"",""Haowei He, Gao Huang, and Yang Yuan. 2019. Asymmetric Valleys: Beyond Sharpand Flat Local Minima. In Advances in Neural Information Processing Systems 32,H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett(Eds.). Curran Associates, Inc., 2553--2564. http://papers.nips.cc/paper/8524-asymmetric-valleys-beyond-sharp-and-flat-local-minima.pdfGoogle Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In CVPR. 770--778.Google Scholar"",""Elad Hoffer and Nir Ailon. 2015. Deep metric learning using triplet network. In International Workshop on Similarity-Based Pattern Recognition. Springer, 84--92.Google ScholarCross Ref"",""Yann N. Dauphin David Lopez-Paz Hongyi Zhang, Moustapha Cisse. 2018. mixup:Beyond Empirical Risk Minimization. International Conference on Learning Representations(2018). https://openreview.net/forum?id=r1Ddp1-RbGoogle Scholar"",""Chi Jin, Praneeth Netrapalli, and Michael I. Jordan. 2018. Accelerated Gradient Descent Escapes Saddle Points Faster than Gradient Descent. In Proceedings of the31st Conference On Learning Theory (Proceedings of Machine Learning Research), Sébastien Bubeck, Vianney Perchet, and Philippe Rigollet (Eds.), Vol. 75. PMLR, 1042--1085. http://proceedings.mlr.press/v75/jin18a.htmlGoogle Scholar"",""Rie Johnson and Tong Zhang. 2013. Accelerating Stochastic Gradient Descent Using Predictive Variance Reduction. In Neural Information Processing Systems(Lake Tahoe, Nevada).Google Scholar"",""Hansohl Kim. 2016. Residual Networks for Tiny ImageNet. Stanford CS231Nreports 2016(2016).Google Scholar"",""Diederik P. Kingma and Jimmy Ba. 2014. Adam: A Method for Stochastic Optimization. arXiv: arXiv:1412.6980Google Scholar"",""Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In International Conference on Learning Representations (ICLR).Google Scholar"",""Alex Krizhevsky. 2009. Learning Multiple Layers of Features from Tiny Images.Google Scholar"",""Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. 2012. Image Net Classification with Deep Convolutional Neural Networks. In Neural Information Processing Systems(Lake Tahoe, Nevada). 1097--1105.Google Scholar"",""Yann Lecun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. 2001. Gradient-based learning applied to document recognition. IEEE Press, 306--351.Google Scholar"",""Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihalcea,Alexander Gelbukh, and Erik Cambria. 2019. Dialogue Rnn: An attentive rnn for emotion detection in conversations. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 6818--6825.Google ScholarCross Ref"",""Xudong Mao, Qing Li, Haoran Xie, Raymond Y. K. Lau, Zhen Wang, and Stephen Paul Smolley. 2016. Least Squares Generative Adversarial Networks.arXiv:arXiv:1611.04076Google Scholar"",""Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A. Rusu, Joel Veness, Marc G. Bellemare, Alex Graves, Martin Riedmiller, Andreas K. Fidjeland, Georg Ostrovski, Stig Petersen, Charles Beattie, Amir Sadik, Ioannis Antonoglou, Helen King, Dharshan Kumaran, Daan Wierstra, Shane Legg, and Demis Hassabis. 2015.Human-level control through deep reinforcement learning.Nature518, 7540(Feb. 2015), 529--533. http://dx.doi.org/10.1038/nature14236Google Scholar"",""Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y. Ng. 2011. Reading Digits in Natural Images with Unsupervised Feature Learning. In NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011. http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdfGoogle Scholar"",""Lam M. Nguyen, Jie Liu, Katya Scheinberg, and Martin Takác. 2017. SARAH: A Novel Method for Machine Learning Problems Using Stochastic Recursive Gradient. In Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6--11 August 2017. 2613--2621.Google Scholar"",""Hyeonwoo Noh, Tackgeun You, Jonghwan Mun, and Bohyung Han. 2017. Regularizing Deep Neural Networks by Noise: Its Interpretation and Optimization. In NIPS'17(Long Beach, California, USA). Curran Associates Inc., USA, 5115--5124. http://dl.acm.org/citation.cfm?id=3295222.3295264Google Scholar"",""Augustus Odena, Christopher Olah, and Jonathon Shlens. 2016. Conditional Image Synthesis With Auxiliary Classifier GANs. arXiv:arXiv:1610.09585Google Scholar"",""Nhan H. Pham, Lam M. Nguyen, Dzung T. Phan, and Quoc Tran-Dinh. 2019. ProxSARAH: An Efficient Algorithmic Framework for Stochastic Composite Nonconvex Optimization. arXiv: arXiv:1902.05679Google Scholar"",""Alec Radford, Luke Metz, and Soumith Chintala. 2015. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. arXiv:arXiv:1511.06434Google Scholar"",""Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. 2015. Image Net Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV)115, 3 (2015), 211--252. https://doi.org/10.1007/s11263-015-0816-yGoogle Scholar"",""Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. 2016. Improved Techniques for Training GANs. arXiv:arXiv:1606.03498Google Scholar"",""Florian Schroff, Dmitry Kalenichenko, and James Philbin. 2015. Facenet: A unified embedding for face recognition and clustering. In Proceedings of the IEEE conference on computer vision and pattern recognition. 815--823.Google ScholarCross Ref"",""Björn Schuller, Michel Valster, Florian Eyben, Roddy Cowie, and Maja Pantic. 2012. AVEC 2012: the continuous audio/visual emotion challenge. In Proceedings of the 14th ACM international conference on Multimodal interaction. ACM, 449--456.Google Scholar"",""John Schulman, Sergey Levine, Philipp Moritz, Michael Jordan, and Pieter Abbeel. 2015. Trust Region Policy Optimization. In ICML(Lille, France). JMLR.org, 1889--1897. http://dl.acm.org/citation.cfm?id=3045118.3045319Google Scholar"",""John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.2017. Proximal Policy Optimization Algorithms. ArXivabs/1707.06347 (2017).Google Scholar"",""Prithviraj Sen, Galileo Mark Namata, Mustafa Bilgic, Lise Getoor, Brian Gallagher, and Tina Eliassi-Rad. 2008. Collective Classification in Network Data. AI Magazine 29, 3 (2008), 93--106. http://www.cs.iit.edu/~ml/pdfs/sen-aimag08.pdfGoogle ScholarCross Ref"",""Karen Simonyan and Andrew Zisserman. 2015. Very Deep Convolutional Networks for Large-Scale Image Recognition. In International Conference on Learning Representations.Google Scholar"",""Jake Snell, Kevin Swersky, and Richard Zemel. 2017. Prototypical networks for few-shot learning. In Neural Information Processing Systems. 4077--4087.Google Scholar"",""Ilya Sutskever, James Martens, George Dahl, and Geoffrey Hinton. 2013. On the Importance of Initialization and Momentum in Deep Learning. In ICML(Atlanta, GA, USA). JMLR.org, III--1139--III--1147.Google Scholar"",""Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna. 2016. Rethinking the Inception Architecture for Computer Vision. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition,.Google Scholar"",""C. Wah, S. Branson, P. Welinder, P. Perona, and S. Belongie. 2011. The Caltech-UCSD Birds-200--2011 Dataset. Technical Report.Google Scholar"",""Pete Warden. 2017. https://ai.googleblog.com/2017/08/launching-speech-commands-dataset.html. Google AI Blog 1 (2017), URL.Google Scholar"",""Han Xiao, Kashif Rasul, and Roland Vollgraf. 2017. Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms.arXiv:cs.LG/cs.LG/1708.07747Google Scholar"",""Zhun Zhong, Liang Zheng, Guoliang Kang, Shaozi Li, and Yi Yang. 2020. Random Erasing Data Augmentation. In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI).Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403166,Average Sensitivity of Spectral Clustering,"Spectral clustering is one of the most popular clustering methods for finding clusters in a graph, which has found many applications in data mining. However, the input graph in those applications may have many missing edges due to error in measurement, withholding for a privacy reason, or arbitrariness in data conversion. To make reliable and efficient decisions based on spectral clustering, we assess the stability of spectral clustering against edge perturbations in the input graph using the notion of average sensitivity, which is the expected size of the symmetric difference of the output clusters before and after we randomly remove edges. We first prove that the average sensitivity of spectral clustering is proportional to $łambda_2/łambda_3^2$, where $łambda_i$ is the i-th smallest eigenvalue of the (normalized) Laplacian. We also prove an analogous bound for k-way spectral clustering, which partitions the graph into k clusters. Then, we empirically confirm our theoretical bounds by conducting experiments on synthetic and real networks. Our results suggest that spectral clustering is stable against edge perturbations when there is a cluster structure in the input graph.","[{""name"":""Pan Peng"",""id"":""/profile/99658724181""},{""name"":""Yuichi Yoshida"",""id"":""/profile/99659574217""},{""name"":""Pan Peng"",""id"":""/profile/99658724181""},{""name"":""Yuichi Yoshida"",""id"":""/profile/99659574217""}]","[""Noga Alon. 1986. Eigenvalues and expanders. Combinatorica , Vol. 6, 2 (1986), 83--96.Google ScholarDigital Library"",""Noga Alon and V D Milman. 1985. $łambda_1$, Isoperimetric inequalities for graphs, and superconcentrators. Journal of Combinatorial Theory, Series B , Vol. 38, 1 (1985), 73--88.Google ScholarCross Ref"",""Mikhail Belkin and Partha Niyogi. 2001. Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering. In NIPS . 585--591.Google Scholar"",""Yonatan Bilu and Nathan Linial. 2012. Are stable instances easy? Combinatorics, Probability and Computing , Vol. 21, 5 (2012), 643--660.Google ScholarDigital Library"",""Charles J Colbourn. 1987. The combinatorics of network reliability .Oxford University Press, Inc.Google Scholar"",""Justin Eldridge, Mikhail Belkin, and Yusu Wang. 2018. Unperturbed: spectral analysis beyond Davis-Kahan. In Algorithmic Learning Theory . 321--358.Google Scholar"",""Miroslav Fiedler. 1973. Algebraic connectivity of graphs. Czechoslovak mathematical journal , Vol. 23, 2 (1973), 298--305.Google Scholar"",""Santo Fortunato. 2010. Community detection in graphs. Physics Reports , Vol. 486, 3--5 (2010), 75--174.Google ScholarCross Ref"",""David Gfeller, Jean-Cédric Chappelier, and Paolo De Los Rios. 2005. Finding instabilities in the community structure of complex networks. Physical Review E , Vol. 72, 5 (2005), 056135.Google ScholarCross Ref"",""Heng Guo and Mark Jerrum. 2019. A polynomial-time approximation algorithm for all-terminal network reliability. SIAM J. Comput. , Vol. 48, 3 (2019), 964--978.Google ScholarCross Ref"",""Shlomo Hoory, Nathan Linial, and Avi Wigderson. 2006. Expander graphs and their applications. Bull. Amer. Math. Soc. , Vol. 43, 4 (2006), 439--561.Google ScholarCross Ref"",""Ling Huang, Donghui Yan, Michael I. Jordan, and Nina Taft. 2008. Spectral Clustering with Perturbed Data. In NIPS. 705--712.Google Scholar"",""Brian Karrer, Elizaveta Levina, and Mark EJ Newman. 2008. Robustness of community structure in networks. Physical review E , Vol. 77, 4 (2008), 046119.Google Scholar"",""Tosio Kato. 2013. Perturbation theory for linear operators . Vol. 132. Springer Science \u0026 Business Media.Google Scholar"",""Tsz Chiu Kwok, Lap Chi Lau, Yin Tat Lee, Shayan Oveis Gharan, and Luca Trevisan. 2013a. Improved Cheeger's inequality: Analysis of spectral partitioning algorithms through higher order spectral gap. In STOC. 11--20.Google Scholar"",""Tsz Chiu Kwok, Lap Chi Lau, Yin Tat Lee, Shayan Oveis Gharan, and Luca Trevisan. 2013b. Improved Cheeger's Inequality: Analysis of Spectral Partitioning Algorithms through Higher Order Spectral Gap. arXiv preprint arXiv:1301.5584 (2013).Google Scholar"",""Andrea Lancichinetti, Santo Fortunato, and Filippo Radicchi. 2008. Benchmark graphs for testing community detection algorithms. Physical Review E , Vol. 78, 4 (2008).Google ScholarCross Ref"",""James R Lee, Shayan Oveis Gharan, and Luca Trevisan. 2014. Multiway spectral partitioning and higher-order cheeger inequalities. J. ACM , Vol. 61, 6 (2014), 37.Google ScholarDigital Library"",""J. MacQueen. 1967. Some methods for classification and analysis of multivariate observations. In Proceedings of the 5th Berkeley Symposium on Mathematical Statistics and Probability . Vol. I: Statistics, pp. 281--297.Google Scholar"",""Pan Peng and Yuichi Yoshida. 2020. Average Sensitivity of Spectral Clustering. CoRR , Vol. abs/2006.04094 (2020). arxiv: 2006.04094Google Scholar"",""Richard Peng, He Sun, and Luca Zanetti. 2017. Partitioning Well-Clustered Graphs: Spectral Clustering Works! SIAM J. Comput. , Vol. 46, 2 (2017), 710--743.Google Scholar"",""Jianbo Shi and J. Malik. 2000. Normalized cuts and image segmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence , Vol. 22, 8 (2000), 888--905.Google ScholarDigital Library"",""G.W. Stewart and J.G. Sun. 1990. Matrix Perturbation Theory .ACADEMIC PRESS, INC.Google Scholar"",""Joel A Tropp et almbox. 2015. An introduction to matrix concentration inequalities. Foundations and Trends® in Machine Learning , Vol. 8, 1--2 (2015), 1--230.Google Scholar"",""Nithin Varma and Yuichi Yoshida. 2019. Average Sensitivity of Graph Algorithms. CoRR , Vol. abs/1904.03248 (2019). arxiv: 1904.03248Google Scholar"",""Ulrike von Luxburg. 2007. A tutorial on spectral clustering. Statistics and Computing , Vol. 17, 4 (2007), 395--416.Google ScholarDigital Library"",""Yilin Zhang and Karl Rohe. 2018. Understanding regularized spectral clustering via graph conductance. In NeurIPS . 10631--10640.Google Scholar""]"
https://doi.org/10.1145/3394486.3403167,Semi-Supervised Multi-Label Learning from Crowds via Deep Sequential Generative Model,"Multi-label classification (MLC) is pervasive in real-world applications. Conventional MLC algorithms assume that enough ground truth labels are available for training a classifier. While in reality, obtaining ground truth labels is expensive and time-consuming. In the field of data mining, it is more efficient to use crowdsourcing for label collection. In this setting, an MLC algorithm needs to deal with the noisiness of the crowdsourced labels as well as the remaining massive unlabeled data. In this paper, we propose a deep generative model to describe the label generation process for this semi-supervised multi-label learning problem. Although deep generative models are widely used for MLC problems, no previous work could address the noisy crowdsourced multi-labels and unlabeled data simultaneously. To address this challenging problem, our novel generative model incorporates latent variables to describe the labeled/unlabeled data as well as the labeling process of crowdsourcing. We introduce an efficient sequential inference model to approximate the model posterior and infer the ground truth labels. Our experimental results on various scales of datasets demonstrate the effectiveness of our proposed model. It performs favorably against four state-of-the-art deep generative models.","[{""name"":""Wanli Shi"",""id"":""/profile/99659574295""},{""name"":""Victor S. Sheng"",""id"":""/profile/81317489690""},{""name"":""Xiang Li"",""id"":""/profile/99658751567""},{""name"":""Bin Gu"",""id"":""/profile/99659573742""},{""name"":""Wanli Shi"",""id"":""/profile/99659574295""},{""name"":""Victor S. Sheng"",""id"":""/profile/81317489690""},{""name"":""Xiang Li"",""id"":""/profile/99658751567""},{""name"":""Bin Gu"",""id"":""/profile/99659573742""}]","[""Ryan Prescott Adams and Zoubin Ghahramani. 2009. Archipelago: nonparametric Bayesian semi-supervised learning. In Proceedings of the 26th Annual International Conference on Machine Learning. ACM, 1--8.Google ScholarDigital Library"",""M. L. Antonie and O. R. Zaiane. 2003. Text document categorization by term association. In 2002 IEEE International Conference on Data Mining, 2002. Proceedings.Google Scholar"",""Kyohei Atarashi, Satoshi Oyama, and Masahito Kurihara. 2018. Semi-supervised learning from crowds using deep generative models. In Thirty-Second AAAI Conference on Artificial Intelligence.Google Scholar"",""Jonathan Bragg, Mausam, and Daniel S. Weld. 2013. Crowdsourcing Multi-Label Classification for Taxonomy Creation. In HCOMP.Google Scholar"",""Darin Brezeale and Diane J. Cook. 2008. Automatic Video Classification: A Survey of the Literature. IEEE Transactions on Systems Man and Cybernetics Part C, Vol. 38, 3 (2008), 416--430.Google ScholarDigital Library"",""Gang Chen, Yangqiu Song, Fei Wang, and Changshui Zhang. 2008. Semi-supervised multi-label learning by solving a sylvester equation. In Proceedings of the 2008 SIAM International Conference on Data Mining. SIAM, 410--419.Google ScholarCross Ref"",""Weiwei Cheng, Eyke Hüllermeier, and Krzysztof J Dembczynski. 2010. Bayes optimal multilabel classification via probabilistic classifier chains. In Proceedings of the 27th international conference on machine learning (ICML-10). 279--286.Google Scholar"",""Lydia B Chilton, Greg Little, Darren Edge, Daniel S Weld, and James A Landay. 2013. Cascade: Crowdsourcing taxonomy creation. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 1999--2008.Google ScholarDigital Library"",""Hong-Min Chu, Chih-Kuan Yeh, and Yu-Chiang Frank Wang. 2018. Deep Generative Models for Weakly-Supervised Multi-Label Classification. In Proceedings of the European Conference on Computer Vision (ECCV). 400--415.Google ScholarCross Ref"",""Alexander Philip Dawid and Allan M Skene. 1979. Maximum likelihood estimation of observer error-rates using the EM algorithm. Journal of the Royal Statistical Society: Series C (Applied Statistics), Vol. 28, 1 (1979), 20--28.Google ScholarCross Ref"",""Lei Duan, Satoshi Oyama, Masahito Kurihara, and Haruhiko Sato. 2015. Crowdsourced semantic matching of multi-label annotations. In Twenty-Fourth International Joint Conference on Artificial Intelligence.Google Scholar"",""Lei Duan, Satoshi Oyama, Haruhiko Sato, and Masahito Kurihara. 2014. Separate or joint? Estimation of multiple labels from crowdsourced annotations. Expert Syst. Appl., Vol. 41 (2014), 5723--5732.Google ScholarCross Ref"",""Anca Dumitrache, Lora Aroyo, and Chris Welty. 2018. Crowdsourcing ground truth for medical relation extraction. ACM Transactions on Interactive Intelligent Systems (TiiS), Vol. 8, 2 (2018), 11.Google Scholar"",""Xiang Geng, Bin Gu, Xiang Li, Wanli Shi, Guansheng Zheng, and Heng Huang. 2019. Scalable Semi-Supervised SVM via Triply Stochastic Gradients. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19. International Joint Conferences on Artificial Intelligence Organization, 2364--2370. https://doi.org/10.24963/ijcai.2019/328Google ScholarCross Ref"",""Bin Guo, Huihui Chen, Yan Liu, Chao Chen, Qi Han, and Zhiwen Yu. 2019. From crowdsourcing to crowdmining: using implicit human intelligence for better understanding of crowdsourced data. World Wide Web (2019), 1--25.Google Scholar"",""Yuhong Guo and Dale Schuurmans. 2012. Semi-supervised multi-label classification. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 355--370.Google ScholarCross Ref"",""Xiao-Yuan Jing, Fei Wu, Zhiqiang Li, Ruimin Hu, and David Zhang. 2016. Multi-label dictionary learning for image annotation. IEEE Transactions on Image Processing, Vol. 25, 6 (2016), 2712--2725.Google ScholarDigital Library"",""Eun-Sol Kim, Kyoung-Woon On, Jongseok Kim, Yu-Jung Heo, Seong-Ho Choi, Hyun-Dong Lee, and Byoung-Tak Zhang. 2018. Temporal attention mechanism with conditional inference for large-scale multi-label video classification. In Proceedings of the European Conference on Computer Vision (ECCV). 0--0.Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Durk P Kingma, Shakir Mohamed, Danilo Jimenez Rezende, and Max Welling. 2014. Semi-supervised learning with deep generative models. In Advances in neural information processing systems. 3581--3589.Google Scholar"",""Diederik P Kingma and Max Welling. 2013. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 (2013).Google Scholar"",""Xiangnan Kong, Michael K Ng, and Zhi-Hua Zhou. 2011. Transductive multilabel learning via label set propagation. IEEE Transactions on Knowledge and Data Engineering, Vol. 25, 3 (2011), 704--719.Google ScholarDigital Library"",""Adriana Kovashka, Olga Russakovsky, Li Fei-Fei, Kristen Grauman, et al. 2016. Crowdsourcing in computer vision. Foundations and Trends® in computer graphics and Vision, Vol. 10, 3 (2016), 177--243.Google Scholar"",""Solomon Kullback and R. A. Leibler. 1951. ON INFORMATION AND SUFFICIENCY.Google Scholar"",""Shao Yuan Li, Jiang Yuan, Chawla Nitesh, and Zhou Zhi-Hua. [n.d.]. Multi-Label Learning from Crowds. IEEE Transactions on Knowledge and Data Engineering ( [n.,d.]), 1--1.Google Scholar"",""Xin Li, Hsinchun Chen, Jiexun Li, and Zhu Zhang. 2010. Gene Function Prediction With Gene Interaction Networks: A Context Graph Kernel Approach. IEEE Transactions on Information Technology in Biomedicine, Vol. 14, 1 (2010), 119--128.Google ScholarDigital Library"",""Feng Liu, Tao Xiang, Timothy M Hospedales, Wankou Yang, and Changyin Sun. 2017b. Semantic regularisation for recurrent image annotation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2872--2880.Google ScholarCross Ref"",""Jingzhou Liu, Wei-Cheng Chang, Yuexin Wu, and Yiming Yang. 2017a. Deep learning for extreme multi-label text classification. In Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval. 115--124.Google ScholarDigital Library"",""Wenyin Liu, Susan Dumais, Yanfeng Sun, Hongjiang Zhang, Mary Czerwinski, and Brent Field. 2001. Semi-automatic image annotation., Vol. 8048 (2001), 266--273.Google Scholar"",""Lars Maaløe, Casper Kaae Sønderby, Søren Kaae Sønderby, and Ole Winther. 2016. Auxiliary deep generative models. arXiv preprint arXiv:1602.05473 (2016).Google Scholar"",""Andrew McCallum. 1999. Multi-label text classification with a mixture model trained by EM. In AAAI workshop on Text Learning. 1--7.Google Scholar"",""Jinseok Nam, Eneldo Loza Menc'ia, Hyunwoo J Kim, and Johannes Fürnkranz. 2017. Maximizing subset accuracy with recurrent neural networks in multi-label classification. In Advances in neural information processing systems. 5413--5423.Google Scholar"",""Thanh Tam Nguyen. 2016. Multi-label answer aggregation for crowdsourcing. Technical Report.Google Scholar"",""Hao Peng, Jianxin Li, Senzhang Wang, Lihong Wang, Qiran Gong, Renyu Yang, Bo Li, Philip Yu, and Lifang He. 2019. Hierarchical taxonomy-aware and attentional graph capsule RCNNs for large-scale multi-label text classification. IEEE Transactions on Knowledge and Data Engineering (2019).Google Scholar"",""Jesse Read, Bernhard Pfahringer, Geoff Holmes, and Eibe Frank. 2009. Classifier Chains for Multi-label Classification. In Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases: Part II.Google ScholarCross Ref"",""Filipe Rodrigues, Francisco Pereira, and Bernardete Ribeiro. 2013. Learning from multiple annotators: distinguishing good from random labelers. Pattern Recognition Letters, Vol. 34, 12 (2013), 1428--1436.Google ScholarDigital Library"",""Victor Sheng, Jing Zhang, Bin Gu, and Xindong Wu. 2017. Majority voting and pairing with multiple noisy labeling. IEEE Transactions on Knowledge and Data Engineering (2017).Google Scholar"",""Victor S Sheng, Foster Provost, and Panagiotis G Ipeirotis. 2008. Get another label? improving data quality and data mining using multiple, noisy labelers. In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. 614--622.Google ScholarDigital Library"",""Wanli Shi, Bin Gu, Xiang Li, Xiang Geng, and Heng Huang. 2019 b. Quadruply Stochastic Gradients for Large Scale Nonlinear Semi-Supervised AUC Optimization. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19. International Joint Conferences on Artificial Intelligence Organization, 3418--3424. https://doi.org/10.24963/ijcai.2019/474Google ScholarCross Ref"",""Wanli Shi, Bin Gu, Xinag Li, and Heng Huang. 2019 a. Quadruply Stochastic Gradient Method for Large Scale Nonlinear Semi-Supervised Ordinal Regression AUC Optimization. arXiv preprint arXiv:1912.11193 (2019).Google Scholar"",""Kwangsoo Shin, Junhyeong Jeon, Seungbin Lee, Boyoung Lim, Minsoo Jeong, and Jongho Nang. 2018. Approach for video classification with multi-label on Youtube-8M dataset. In Proceedings of the European Conference on Computer Vision (ECCV). 0--0.Google Scholar"",""Yuyin Sun, Adish Singla, Dieter Fox, and Andreas Krause. 2015. Building hierarchies of concepts via crowdsourcing. In Twenty-Fourth International Joint Conference on Artificial Intelligence.Google Scholar"",""Chang Tang, Xinwang Liu, Pichao Wang, Changqing Zhang, Miaomiao Li, and Lizhe Wang. 2019. Adaptive hypergraph embedded semi-supervised multi-label image annotation. IEEE Transactions on Multimedia, Vol. 21, 11 (2019), 2837--2849.Google ScholarCross Ref"",""Grigorios Tsoumakas, Ioannis Katakis, and Ioannis Vlahavas. 2010. Mining Multi-label Data.Google Scholar"",""Brendan Van Rooyen, Aditya Menon, and Robert C Williamson. 2015. Learning with symmetric label noise: The importance of being unhinged. In Advances in Neural Information Processing Systems. 10--18.Google Scholar"",""Aobo Wang, Cong Duy Vu Hoang, and Min-Yen Kan. 2013. Perspectives on crowdsourcing annotations for natural language processing. Language resources and evaluation, Vol. 47, 1 (2013), 9--31.Google Scholar"",""Daniel S Weld, Christopher H Lin, and Jonathan Bragg. 2015. Artificial intelligence and collective intelligence. Handbook of Collective Intelligence (2015), 89--114.Google Scholar"",""Peter Welinder, Steve Branson, Pietro Perona, and Serge J Belongie. 2010. The multidimensional wisdom of crowds. In Advances in neural information processing systems. 2424--2432.Google Scholar"",""Guo Xintong, Wang Hongzhi, Yangqiu Song, and Gao Hong. [n.d.]. Brief survey of crowdsourcing for data mining. Expert Systems with Applications, Vol. 41, 17 ( [n.,d.]), 7987--7994.Google Scholar"",""Yan Yan, Rómer Rosales, Glenn Fung, Mark Schmidt, Gerardo Hermosillo, Luca Bogoni, Linda Moy, and Jennifer Dy. 2010. Modeling annotator expertise: Learning when everybody knows a bit of something. In Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics. 932--939.Google Scholar"",""Li'ang Yin, Jianhua Han, Weinan Zhang, and Yong Yu. 2017. Aggregating Crowd Wisdoms with Label-aware Autoencoders. In IJCAI.Google Scholar"",""Shuyang Yu, Bin Gu, Kunpeng Ning, Haiyan Chen, Jian Pei, and Heng Huang. 2019. Tackle balancing constraint for incremental semi-supervised support vector learning. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1587--1595.Google ScholarDigital Library"",""Jing Zhang and Xindong Wu. 2018. Multi-label inference for crowdsourcing. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 2738--2747.Google ScholarDigital Library"",""Jing Zhang, Xindong Wu, and Victor S Sheng. 2016. Learning from crowdsourced labeled data: a survey. Artificial Intelligence Review, Vol. 46, 4 (2016), 543--576.Google ScholarDigital Library"",""Liye Zhang, Shahrokh Valaee, Yubin Xu, Lin Ma, and Farhang Vedadi. 2017. Graph-based semi-supervised learning for indoor localization using crowdsourced data. Applied Sciences, Vol. 7, 5 (2017), 467.Google ScholarCross Ref"",""Min-Ling Zhang and Zhi-Hua Zhou. 2013. A review on multi-label learning algorithms. IEEE transactions on knowledge and data engineering, Vol. 26, 8 (2013), 1819--1837.Google Scholar"",""Yudian Zheng, Guoliang Li, Yuanbing Li, Caihua Shan, and Reynold Cheng. 2017. Truth inference in crowdsourcing: Is the problem solved? Proceedings of the VLDB Endowment, Vol. 10, 5 (2017), 541--552.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403168,GCC: Graph Contrastive Coding for Graph Neural Network Pre-Training,"Graph representation learning has emerged as a powerful technique for addressing real-world problems. Various downstream graph learning tasks have benefited from its recent developments, such as node classification, similarity search, and graph classification. However, prior arts on graph representation learning focus on domain specific problems and train a dedicated model for each graph dataset, which is usually non-transferable to out-of-domain data. Inspired by the recent advances in pre-training from natural language processing and computer vision, we design Graph Contrastive Coding (GCC) --- a self-supervised graph neural network pre-training framework --- to capture the universal network topological properties across multiple networks. We design GCC's pre-training task as subgraph instance discrimination in and across networks and leverage contrastive learning to empower graph neural networks to learn the intrinsic and transferable structural representations. We conduct extensive experiments on three graph learning tasks and ten graph datasets. The results show that GCC pre-trained on a collection of diverse datasets can achieve competitive or better performance to its task-specific and trained-from-scratch counterparts. This suggests that the pre-training and fine-tuning paradigm presents great potential for graph representation learning.","[{""name"":""Jiezhong Qiu"",""id"":""/profile/99658983102""},{""name"":""Qibin Chen"",""id"":""/profile/99659454172""},{""name"":""Yuxiao Dong"",""id"":""/profile/81556305356""},{""name"":""Jing Zhang"",""id"":""/profile/81408596200""},{""name"":""Hongxia Yang"",""id"":""/profile/99659259298""},{""name"":""Ming Ding"",""id"":""/profile/99659316268""},{""name"":""Kuansan Wang"",""id"":""/profile/81451595141""},{""name"":""Jie Tang"",""id"":""/profile/81548005696""},{""name"":""Jiezhong Qiu"",""id"":""/profile/99658983102""},{""name"":""Qibin Chen"",""id"":""/profile/99659454172""},{""name"":""Yuxiao Dong"",""id"":""/profile/81556305356""},{""name"":""Jing Zhang"",""id"":""/profile/81408596200""},{""name"":""Hongxia Yang"",""id"":""/profile/99659259298""},{""name"":""Ming Ding"",""id"":""/profile/99659316268""},{""name"":""Kuansan Wang"",""id"":""/profile/81451595141""},{""name"":""Jie Tang"",""id"":""/profile/81548005696""}]","[""Réka Albert and Albert-László Barabási. 2002. Statistical mechanics of complex networks. Reviews of modern physics, Vol. 74, 1 (2002), 47.Google Scholar"",""J Ignacio Alvarez-Hamelin, Luca Dall'Asta, Alain Barrat, and Alessandro Vespignani. 2006. Large scale networks fingerprinting and visualization using the k-core decomposition. In Advances in neural information processing systems. 41--50.Google Scholar"",""Lars Backstrom, Dan Huttenlocher, Jon Kleinberg, and Xiangyang Lan. 2006. Group formation in large social networks: membership, growth, and evolution. In KDD '06 . 44--54.Google ScholarDigital Library"",""Peter W Battaglia, Jessica B Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, et almbox. 2018. Relational inductive biases, deep learning, and graph networks. arXiv preprint arXiv:1806.01261 (2018).Google Scholar"",""Austin R Benson, David F Gleich, and Jure Leskovec. 2016. Higher-order organization of complex networks. Science , Vol. 353, 6295 (2016), 163--166.Google Scholar"",""Stephen P Borgatti and Martin G Everett. 2000. Models of core/periphery structures. Social networks, Vol. 21, 4 (2000), 375--395.Google Scholar"",""Ronald S Burt. 2009. Structural holes: The social structure of competition .Harvard university press.Google Scholar"",""Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A library for support vector machines. ACM transactions on intelligent systems and technology (TIST) , Vol. 2, 3 (2011), 1--27.Google ScholarDigital Library"",""Kevin Clark, Minh-Thang Luong, Quoc V Le, and Christopher D Manning. 2019. ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators. In ICLR '19 .Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In NAACL-HLT '19. 4171--4186.Google Scholar"",""Yuxiao Dong, Nitesh V Chawla, and Ananthram Swami. 2017. metapath2vec: Scalable representation learning for heterogeneous networks. In KDD '17 . 135--144.Google ScholarDigital Library"",""Claire Donnat, Marinka Zitnik, David Hallac, and Jure Leskovec. 2018. Learning structural node embeddings via diffusion wavelets. In KDD '18 . 1320--1329.Google ScholarDigital Library"",""Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. 2017. Neural message passing for quantum chemistry. In ICML '17. JMLR. org, 1263--1272.Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In KDD '16. 855--864.Google ScholarDigital Library"",""Raia Hadsell, Sumit Chopra, and Yann LeCun. 2006. Dimensionality reduction by learning an invariant mapping. In CVPR '06, Vol. 2. IEEE, 1735--1742.Google ScholarDigital Library"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In Advances in neural information processing systems. 1024--1034.Google Scholar"",""Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. 2020. Momentum contrast for unsupervised visual representation learning. In CVPR '20 . 9729--9738.Google ScholarCross Ref"",""Keith Henderson, Brian Gallagher, Tina Eliassi-Rad, Hanghang Tong, Sugato Basu, Leman Akoglu, Danai Koutra, Christos Faloutsos, and Lei Li. 2012. Rolx: structural role extraction \u0026 mining in large graphs. In KDD '12. 1231--1239.Google ScholarDigital Library"",""Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay Pande, and Jure Leskovec. 2019 b. Pre-training graph neural networks. In ICLR '19 .Google Scholar"",""Ziniu Hu, Changjun Fan, Ting Chen, Kai-Wei Chang, and Yizhou Sun. 2019 a. Unsupervised Pre-Training of Graph Convolutional Networks. ICLR 2019 Workshop: Representation Learning on Graphs and Manifolds (2019).Google Scholar"",""Glen Jeh and Jennifer Widom. 2002. SimRank: a measure of structural-context similarity. In KDD '02 . 538--543.Google ScholarDigital Library"",""Yilun Jin, Guojie Song, and Chuan Shi. 2019. GraLSP: Graph Neural Networks with Local Structural Patterns. arXiv preprint arXiv:1911.07675 (2019).Google Scholar"",""Kristian Kersting, Nils M. Kriege, Christopher Morris, Petra Mutzel, and Marion Neumann. 2016. Benchmark Data Sets for Graph Kernels. http://graphkernels.cs.tu-dortmund.deGoogle Scholar"",""Diederik P Kingma and Jimmy Ba. 2015. Adam: A method for stochastic optimization. ICLR '15 .Google Scholar"",""Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In ICLR '17 .Google Scholar"",""Elizabeth A Leicht, Petter Holme, and Mark EJ Newman. 2006. Vertex similarity in networks. Physical Review E , Vol. 73, 2 (2006), 026120.Google ScholarCross Ref"",""Jure Leskovec and Christos Faloutsos. 2006. Sampling from large graphs. In KDD '06. 631--636.Google ScholarDigital Library"",""Jure Leskovec, Jon Kleinberg, and Christos Faloutsos. 2005. Graphs over time: densification laws, shrinking diameters and possible explanations. In KDD '05 . 177--187.Google ScholarDigital Library"",""Silvio Micali and Zeyuan Allen Zhu. 2016. Reconstructing markov processes from independent and anonymous experiments. Discrete Applied Mathematics , Vol. 200 (2016), 108--122.Google ScholarDigital Library"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems. 3111--3119.Google Scholar"",""Ron Milo, Shalev Itzkovitz, Nadav Kashtan, Reuven Levitt, Shai Shen-Orr, Inbal Ayzenshtat, Michal Sheffer, and Uri Alon. 2004. Superfamilies of evolved and designed networks. Science , Vol. 303, 5663 (2004), 1538--1542.Google Scholar"",""Ron Milo, Shai Shen-Orr, Shalev Itzkovitz, Nadav Kashtan, Dmitri Chklovskii, and Uri Alon. 2002. Network motifs: simple building blocks of complex networks. Science , Vol. 298, 5594 (2002), 824--827.Google Scholar"",""Annamalai Narayanan, Mahinthan Chandramohan, Rajasekar Venkatesan, Lihui Chen, Yang Liu, and Shantanu Jaiswal. 2017. graph2vec: Learning distributed representations of graphs. arXiv preprint arXiv:1707.05005 (2017).Google Scholar"",""Mark EJ Newman. 2006. Modularity and community structure in networks. Proceedings of the national academy of sciences , Vol. 103, 23 (2006), 8577--8582.Google ScholarCross Ref"",""Aaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018. Representation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748 (2018).Google Scholar"",""Jia-Yu Pan, Hyung-Jeong Yang, Christos Faloutsos, and Pinar Duygulu. 2004. Automatic multimedia cross-modal correlation discovery. In KDD '04 . 653--658.Google ScholarDigital Library"",""Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. 2019. PyTorch: An Imperative Style, High-Performance Deep Learning Library. In Advances in Neural Information Processing Systems. 8024--8035.Google Scholar"",""Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et almbox. 2011. Scikit-learn: Machine learning in Python. Journal of machine learning research , Vol. 12, Oct (2011), 2825--2830.Google ScholarDigital Library"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In KDD '14 . 701--710.Google ScholarDigital Library"",""Jiezhong Qiu, Yuxiao Dong, Hao Ma, Jian Li, Chi Wang, Kuansan Wang, and Jie Tang. 2019. Netsmf: Large-scale network embedding as sparse matrix factorization. In The World Wide Web Conference. 1509--1520.Google ScholarDigital Library"",""Jiezhong Qiu, Yuxiao Dong, Hao Ma, Jian Li, Kuansan Wang, and Jie Tang. 2018a. Network embedding as matrix factorization: Unifying deepwalk, line, pte, and node2vec. In WSDM '18 . 459--467.Google ScholarDigital Library"",""Jiezhong Qiu, Jian Tang, Hao Ma, Yuxiao Dong, Kuansan Wang, and Jie Tang. 2018b. Deepinf: Social influence prediction with deep learning. In KDD '18 . 2110--2119.Google ScholarDigital Library"",""Leonardo FR Ribeiro, Pedro HP Saverese, and Daniel R Figueiredo. 2017. struc2vec: Learning node representations from structural identity. In KDD '17 . 385--394.Google ScholarDigital Library"",""Scott C Ritchie, Stephen Watts, Liam G Fearnley, Kathryn E Holt, Gad Abraham, and Michael Inouye. 2016. A scalable permutation approach reveals replication and preservation patterns of network modules in large datasets. Cell systems , Vol. 3, 1 (2016), 71--82.Google Scholar"",""Daniel A Spielman and Shang-Hua Teng. 2013. A local clustering algorithm for massive graphs and its application to nearly linear time graph partitioning. SIAM Journal on computing , Vol. 42, 1 (2013), 1--26.Google Scholar"",""Fan-Yun Sun, Jordan Hoffman, Vikas Verma, and Jian Tang. 2019. InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization. In ICLR '19 .Google Scholar"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. In WWW '15. 1067--1077.Google ScholarDigital Library"",""Shang-Hua Teng et almbox. 2016. Scalable algorithms for data and network analysis. Foundations and Trends® in Theoretical Computer Science , Vol. 12, 1--2 (2016), 1--274.Google Scholar"",""Yonglong Tian, Dilip Krishnan, and Phillip Isola. 2019. Contrastive multiview coding. arXiv preprint arXiv:1906.05849 (2019).Google Scholar"",""Hanghang Tong, Christos Faloutsos, and Jia-Yu Pan. 2006. Fast random walk with restart and its applications. In ICDM '06. IEEE, 613--622.Google ScholarDigital Library"",""Johan Ugander, Lars Backstrom, Cameron Marlow, and Jon Kleinberg. 2012. Structural diversity in social contagion. Proceedings of the National Academy of Sciences , Vol. 109, 16 (2012), 5962--5966.Google ScholarCross Ref"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998--6008.Google Scholar"",""Petar Velivc ković , Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2018. Graph attention networks. ICLR '18 (2018).Google Scholar"",""Ulrike Von Luxburg. 2007. A tutorial on spectral clustering. Statistics and computing , Vol. 17, 4 (2007), 395--416.Google Scholar"",""Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman. 2019 a. GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding. In ICLR '19 .Google Scholar"",""Minjie Wang, Lingfan Yu, Da Zheng, Quan Gan, Yu Gai, Zihao Ye, Mufei Li, Jinjing Zhou, Qi Huang, Chao Ma, et almbox. 2019 b. Deep graph library: Towards efficient and scalable deep learning on graphs. arXiv preprint arXiv:1909.01315 (2019).Google Scholar"",""Duncan J Watts and Steven H Strogatz. 1998. Collective dynamics of small-world networks. nature , Vol. 393, 6684 (1998), 440.Google Scholar"",""Zhirong Wu, Yuanjun Xiong, Stella X Yu, and Dahua Lin. 2018. Unsupervised feature learning via non-parametric instance discrimination. In CVPR '18 . 3733--3742.Google ScholarCross Ref"",""Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2019. How Powerful are Graph Neural Networks?. In ICLR '19 .Google Scholar"",""Pinar Yanardag and SVN Vishwanathan. 2015. Deep graph kernels. In KDD '15. 1365--1374.Google ScholarDigital Library"",""Jaewon Yang and Jure Leskovec. 2015. Defining and evaluating network communities based on ground-truth. Knowledge and Information Systems , Vol. 42, 1 (2015), 181--213.Google ScholarDigital Library"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale recommender systems. In KDD '18 . 974--983.Google ScholarDigital Library"",""Fanjin Zhang, Xiao Liu, Jie Tang, Yuxiao Dong, Peiran Yao, Jie Zhang, Xiaotao Gu, Yan Wang, Bin Shao, Rui Li, and et al. 2019 b. OAG: Toward Linking Large-Scale Heterogeneous Entity Graphs. In KDD '19 . 2585--2595.Google Scholar"",""Jie Zhang, Yuxiao Dong, Yan Wang, Jie Tang, and Ming Ding. 2019 a. ProNE: fast and scalable network representation learning. In IJCAI '19 . 4278--4284.Google ScholarCross Ref"",""Jing Zhang, Jie Tang, Cong Ma, Hanghang Tong, Yu Jing, and Juanzi Li. 2015. Panther: Fast top-k similarity search on large networks. In KDD '15 . 1445--1454.Google ScholarDigital Library"",""Muhan Zhang, Zhicheng Cui, Marion Neumann, and Yixin Chen. 2018. An end-to-end deep learning architecture for graph classification. In AAAI '18 .Google Scholar""]"
https://doi.org/10.1145/3394486.3403169,HGCN: A Heterogeneous Graph Convolutional Network-Based Deep Learning Model Toward Collective Classification,"Collective classification, as an important technique to study networked data, aims to exploit the label autocorrelation for a group of inter-connected entities with complex dependencies. As the emergence of various heterogeneous information networks (HINs), collective classification at present is confronting several severe challenges stemming from the heterogeneity of HINs, such as complex relational hierarchy, potential incompatible semantics and node-context relational semantics. To address the challenges, in this paper, we propose a novel heterogeneous graph convolutional network-based deep learning model, called HGCN, to collectively categorize the entities in HINs. Our work involves three primary contributions: i) HGCN not only learns the latent relations from the relation-sophisticated HINs via multi-layer heterogeneous convolutions, but also captures the semantic incompatibility among relations with properly-learned edge-level filter parameters; ii) to preserve the fine-grained relational semantics of different-type nodes, we propose a heterogeneous graph convolution to directly tackle the original HINs without any in advance transforming the network from heterogeneity to homogeneity; iii) we perform extensive experiments using four real-world datasets to validate our proposed HGCN, the multi-facet results show that our proposed HGCN can significantly improve the performance of collective classification compared with the state-of-the-art baseline methods.","[{""name"":""Zhihua Zhu"",""id"":""/profile/99659369136""},{""name"":""Xinxin Fan"",""id"":""/profile/81548019870""},{""name"":""Xiaokai Chu"",""id"":""/profile/99659371523""},{""name"":""Jingping Bi"",""id"":""/profile/81547917656""},{""name"":""Zhihua Zhu"",""id"":""/profile/99659369136""},{""name"":""Xinxin Fan"",""id"":""/profile/81548019870""},{""name"":""Xiaokai Chu"",""id"":""/profile/99659371523""},{""name"":""Jingping Bi"",""id"":""/profile/81547917656""}]","[""Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. 2014. Spectral Networks and Locally Connected Networks on Graphs. In ICLR.Google Scholar"",""Bin Chen, Ying Ding, and David J. Wild. 2012. Assessing Drug Target Association Using Semantic Linked Data. PLoS Computational Biology, Vol. 8, 7 (2012).Google Scholar"",""Morakot Choetkiertikul, Hoa Khanh Dam, Truyen Tran, and Aditya Ghose. 2015. Predicting Delays in Software Projects Using Networked Classification (T). In ASE. 353--364.Google Scholar"",""Michaë l Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering. In NeurIPS. 3837--3845.Google Scholar"",""Yuxiao Dong, Nitesh V. Chawla, and Ananthram Swami. 2017. metapath2vec: Scalable Representation Learning for Heterogeneous Networks. In KDD. 135--144.Google Scholar"",""Tao-Yang Fu, Wang-Chien Lee, and Zhen Lei. 2017. HIN2Vec: Explore Meta-paths in Heterogeneous Information Networks for Representation Learning. In CIKM. 1797--1806.Google Scholar"",""William L. Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive Representation Learning on Large Graphs. In NeurIPS. 1024--1034.Google Scholar"",""Zhipeng Huang and Nikos Mamoulis. 2017. Heterogeneous Information Network Embedding for Meta Path based Proximity. CoRR, Vol. abs/1701.05291 (2017).Google Scholar"",""David D. Jensen, Jennifer Neville, and Brian Gallagher. 2004. Why collective inference improves relational classification. In KDD. 593--598.Google Scholar"",""Ming Ji, Jiawei Han, and Marina Danilevsky. 2011. Ranking-based classification of heterogeneous information networks. In KDD. 1298--1306.Google Scholar"",""Ming Ji, Yizhou Sun, Marina Danilevsky, Jiawei Han, and Jing Gao. 2010. Graph Regularized Transductive Classification on Heterogeneous Information Networks. In ECML PKDD. 570--586.Google Scholar"",""Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In ICLR.Google Scholar"",""Xiangnan Kong, Bokai Cao, and Philip S. Yu. 2013. Multi-label classification by mining label and instance correlations from heterogeneous information networks. In KDD. 614--622.Google Scholar"",""Xiangnan Kong, Philip S. Yu, Ying Ding, and David J. Wild. 2012. Meta path-based collective classification in heterogeneous information networks. In CIKM. 1567--1571.Google Scholar"",""Zhenzhen Kou and William W. Cohen. 2007. Stacked Graphical Models for Efficient Inference in Markov Random Fields. In SDM. 533--538.Google Scholar"",""Frank Lin and William W. Cohen. 2010. Semi-Supervised Classification of Network Data Using Very Few Labels. In ASONAM. 192--199.Google Scholar"",""Qing Lu and Lise Getoor. 2003. Link-based Classification. In ICML. 496--503.Google Scholar"",""Sofus A Macskassy and Foster Provost. 2003. A simple relational classifier. Technical Report. NEW YORK UNIV NY STERN SCHOOL OF BUSINESS.Google Scholar"",""Andrew McCallum, Kamal Nigam, Jason Rennie, and Kristie Seymore. 2000. Automating the Construction of Internet Portals with Machine Learning. Inf. Retr., Vol. 3, 2 (2000), 127--163.Google ScholarDigital Library"",""Luke K. McDowell and David W. Aha. 2012. Semi-Supervised Collective Classification via Hybrid Label Regularization. In ICML.Google Scholar"",""Luke K. McDowell and David W. Aha. 2013. Labels or attributes?: rethinking the neighbors for collective classification in sparsely-labeled networks. In CIKM. 847--852.Google Scholar"",""John Moore and Jennifer Neville. 2017. Deep Collective Inference. In AAAI. 2364--2372.Google Scholar"",""Trang Pham, Truyen Tran, Dinh Q. Phung, and Svetha Venkatesh. 2017. Column Networks for Collective Classification. In AAAI. 2485--2491.Google Scholar"",""Paulo E. Rauber, Alexandre X. Falc a o, and Alexandru C. Telea. 2016. Visualizing Time-Dependent Data Using Dynamic t-SNE. In EuroVis. 73--77.Google Scholar"",""Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Gallagher, and Tina Eliassi-Rad. 2008. Collective Classification in Network Data. AI Magazine, Vol. 29, 3 (2008), 93--106.Google ScholarCross Ref"",""Yu Shi, Qi Zhu, Fang Guo, Chao Zhang, and Jiawei Han. 2018. Easing Embedding Learning by Comprehensive Transcription of Heterogeneous Information Networks. In KDD. 2190--2199.Google Scholar"",""Rupesh Kumar Srivastava, Klaus Greff, and Jü rgen Schmidhuber. 2015. Highway Networks. CoRR, Vol. abs/1505.00387 (2015).Google Scholar"",""Yizhou Sun and Jiawei Han. 2012. Mining Heterogeneous Information Networks: Principles and Methodologies .Morgan \u0026 Claypool Publishers.Google Scholar"",""Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott E. Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. 2015. Going deeper with convolutions. In CVPR. 1--9.Google Scholar"",""Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. 2018. Graph Attention Networks. In ICLR.Google Scholar"",""Xi Wang and Gita Sukthankar. 2013. Multi-label relational neighbor classification using social context features. In KDD. 464--472.Google Scholar"",""Yizhou Zhang, Yun Xiong, Xiangnan Kong, Shanshan Li, Jinhong Mi, and Yangyong Zhu. 2018. Deep Collective Classification in Heterogeneous Information Networks. In WWW. 399--408.Google Scholar"",""Yizhou Zhang, Yun Xiong, Xiangnan Kong, and Yangyong Zhu. 2016. NetCycle: Collective Evolution Inference in Heterogeneous Information Networks. In KDD. 1365--1374.Google Scholar""]"
https://doi.org/10.1145/3394486.3403170,Handling Information Loss of Graph Neural Networks for Session-based Recommendation,"Recently, graph neural networks (GNNs) have gained increasing popularity due to their convincing performance in various applications. Many previous studies also attempted to apply GNNs to session-based recommendation and obtained promising results. However, we spot that there are two information loss problems in these GNN-based methods for session-based recommendation, namely the lossy session encoding problem and the ineffective long-range dependency capturing problem. The first problem is the lossy session encoding problem. Some sequential information about item transitions is ignored because of the lossy encoding from sessions to graphs and the permutation-invariant aggregation during message passing. The second problem is the ineffective long-range dependency capturing problem. Some long-range dependencies within sessions cannot be captured due to the limited number of layers. To solve the first problem, we propose a lossless encoding scheme and an edge-order preserving aggregation layer based on GRU that is dedicatedly designed to process the losslessly encoded graphs. To solve the second problem, we propose a shortcut graph attention layer that effectively captures long-range dependencies by propagating information along shortcut connections. By combining the two kinds of layers, we are able to build a model that does not have the information loss problems and outperforms the state-of-the-art models on three public datasets.","[{""name"":""Tianwen Chen"",""id"":""/profile/99659439790""},{""name"":""Raymond Chi-Wing Wong"",""id"":""/profile/81406592097""},{""name"":""Tianwen Chen"",""id"":""/profile/99659439790""},{""name"":""Raymond Chi-Wing Wong"",""id"":""/profile/81406592097""}]","[""Shuo Chen, Josh L. Moore, Douglas Turnbull, and Thorsten Joachims. 2012. Playlist Prediction via Metric Embedding. In KDD. 714--722.Google Scholar"",""Tianwen Chen and Raymond Chi-Wing Wong. 2019. Session-based Recommendation with Local Invariance. In ICDM. 994--999.Google Scholar"",""Zhiyong Cheng, Jialie Shen, Lei Zhu, Mohan S. Kankanhalli, and Liqiang Nie. 2017. Exploiting Music Play Sequence for Music Recommendation. In IJCAI. 3654--3660.Google Scholar"",""James Davidson, Benjamin Liebald, Junning Liu, Palash Nandy, Taylor Van Vleet, Ullas Gargi, Sujoy Gupta, Yu He, Mike Lambert, Blake Livingston, and Dasarathi Sampath. 2010. The YouTube Video Recommendation System. In RecSys. 293--296.Google Scholar"",""Ricardo Dias and Manuel J. Fonseca. 2013. Improving Music Recommendation in Session-based Collaborative Filtering by Using Temporal Context. In ICTAI. 783--788.Google Scholar"",""Lei Guo, Hongzhi Yin, Qinyong Wang, Tong Chen, Alexander Zhou, and Nguyen Quoc Viet Hung. 2019. Streaming Session-based Recommendation. In KDD. 1569--1577.Google Scholar"",""William L. Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive Representation Learning on Large Graphs. In NIPS. 1024--1034.Google Scholar"",""Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2016a. Session-based Recommendations with Recurrent Neural Networks. In ICLR.Google Scholar"",""Balázs Hidasi, Massimo Quadrana, Alexandros Karatzoglou, and Domonkos Tikk. 2016b. Parallel Recurrent Neural Network Architectures for Feature-rich Session-based Recommendations. In RecSys. 241--248.Google Scholar"",""Gao Huang, Zhuang Liu, Laurens van der Maaten, and Kilian Q. Weinberger. 2017. Densely Connected Convolutional Networks. In CVPR. 2261--2269.Google Scholar"",""Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, and Jun Ma. 2017. Neural Attentive Session-based Recommendation. In CIKM. 1419--1428.Google Scholar"",""Qimai Li, Zhichao Han, and Xiaoming Wu. 2018. Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning. In AAAI. 3538--3545.Google Scholar"",""Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard S. Zemel. 2016. Gated Graph Sequence Neural Networks.. In ICLR.Google Scholar"",""Qiao Liu, Yifu Zeng, Refuoe Mokhosi, and Haibin Zhang. 2018. STAMP: Short-Term Attention/Memory Priority Model for Session-based Recommendation. In KDD. 1831--1839.Google ScholarDigital Library"",""Sung Eun Park, Sangkeun Lee, and Sang goo Lee. 2011. Session-based Collaborative Filtering for Predicting the Next Song. In CNSI. 353--358.Google Scholar"",""Ruihong Qiu, Jingjing Li, Zi Huang, and Hongzhi Yin. 2019. Rethinking the Item Order in Session-based Recommendation with Graph Neural Networks. In CIKM. 579--588.Google Scholar"",""Pengjie Ren, Zhumin Chen, Jing Li, Zhaochun Ren, Jun Ma, and Maarten de Rijke. 2019. RepeatNet: A Repeat Aware Neural Recommendation Machine for Session-based Recommendation. In AAAI. 4806--4813.Google Scholar"",""Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Factorizing Personalized Markov Chains for Next-basket Recommendation. In WWW. 811--820.Google Scholar"",""Guy Shani, David Heckerman, and Ronen I. Brafman. 2005. An MDP-Based Recommender System. JMLR, Vol. 6 (2005), 1265--1295.Google ScholarDigital Library"",""Jing Song, Hong Shen, Zijing Ou, Junyi Zhang, Teng Xiao, and Shangsong Liang. 2019. ISLF: Interest Shift and Latent Factors Combination Model for Session-based Recommendation. In IJCAI. 5765--5771.Google Scholar"",""Jiaxi Tang and Ke Wang. 2018. Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding. In WSDM. 565--573.Google Scholar"",""Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. 2018. Graph Attention Networks. In ICLR.Google Scholar"",""Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, and Tieniu Tan. 2019 a. Session-based Recommendation with Graph Neural Network. In AAAI. 346--353.Google Scholar"",""Shu Wu, Mengqi Zhang, Xin Jiang, Ke Xu, and Liang Wang. 2019 b. Personalizing Graph Neural Networks with Attention Mechanism for Session-based Recommendation. TKDE, Vol. 31 (2019).Google Scholar"",""Chengfeng Xu, Pengpeng Zhao, Yanchi Liu, Victor S. Sheng, Jiajie Xu, Fuzhen Zhuang, Junhua Fang, and Xiaofang Zhou. 2019. Graph Contextualized Self-Attention Network for Session-based Recommendation. In IJCAI. 3940--3946.Google Scholar"",""Keyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken ichi Kawarabayashi, and Stefanie Jegelka. 2018. Representation Learning on Graphs with Jumping Knowledge Networks. In ICML. 5449--5458.Google Scholar"",""Fajie Yuan, Alexandros Karatzoglou, Ioannis Arapakis, Joemon M. Jose, and Xiangnan He. 2019. A Simple Convolutional Generative Network for Next Item Recommendation. In WSDM. 582--590.Google Scholar""]"
https://doi.org/10.1145/3394486.3403171,Ultrafast Local Outlier Detection from a Data Stream with Stationary Region Skipping,"Real-time outlier detection from a data stream is an increasingly important problem, especially as sensor-generated data streams abound in many applications owing to the prevalence of IoT and emergence of digital twins. Several density-based approaches have been proposed to address this problem, but arguably none of them is fast enough to meet the performance demand of real applications. This paper is founded upon a novel observation that, in many regions of the data space, data distributions hardly change across window slides. We propose a new algorithm, abbr. STARE, which identifies local regions in which data distributions hardly change and then skips updating the densities in those regions-a notion called stationary region skipping. Two techniques, data distribution approximation and cumulative net-change-based skip, are employed to efficiently and effectively implement the notion. Extensive experiments using synthetic and real data streams as well as a case study show that STARE is several orders of magnitude faster than the existing algorithms while achieving comparable or higher accuracy.","[{""name"":""Susik Yoon"",""id"":""/profile/99659019361""},{""name"":""Jae-Gil Lee"",""id"":""/profile/81351605693""},{""name"":""Byung Suk Lee"",""id"":""/profile/81351609354""},{""name"":""Susik Yoon"",""id"":""/profile/99659019361""},{""name"":""Jae-Gil Lee"",""id"":""/profile/81351605693""},{""name"":""Byung Suk Lee"",""id"":""/profile/81351609354""}]","[""KDD Cup 99. http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html. Accessed: 2020-06-01.Google Scholar"",""M. M. Breunig, H.-P. Kriegel, R. T. Ng, and J. Sander. LOF: Identifying density-based local outliers. ACM SIGMOD Record, 29(2):93--104, 2000.Google ScholarDigital Library"",""G. O. Campos, A. Zimek, J. Sander, R. J. Campello, B. Micenková, E. Schubert, I. Assent, and M. E. Houle. On the evaluation of unsupervised outlier detection: Measures, datasets, and an empirical study. Data Mining and Knowledge Discovery, 30(4):891--927, 2016.Google ScholarDigital Library"",""N. Craswell. R-Precision, Encyclopedia of Database Systems. Springer US, Boston, MA, 2009.Google Scholar"",""K. Frank, M. J. Vera Nadales, P. Robertson, and T. Pfeifer. Bayesian recognition of motion related activities with inertial sensors. In Proc. UbiComp, pages 445--446, 2010.Google ScholarDigital Library"",""E. Gan and P. Bailis. Scalable kernel density classification via threshold-based pruning. In Proc. SIGMOD, pages 945--959, 2017.Google ScholarDigital Library"",""F. J. G. Gisbert. Weighted samples, kernel density estimators and convergence. Empirical Economics, 28(2):335--351, 2003.Google ScholarCross Ref"",""M. Gupta, J. Gao, C. C. Aggarwal, and J. Han. Outlier detection for temporal data: A survey. IEEE Trans. on Knowledge and Data Engineering, 26(9):2250--2267, 2013.Google ScholarCross Ref"",""W. Jin, A. K. Tung, and J. Han. Mining top-n local outliers in large databases. In Proc. KDD, pages 293--298, 2001.Google ScholarDigital Library"",""L. J. Latecki, A. Lazarevic, and D. Pokrajac. Outlier detection with kernel density functions. In Proc. MLDM, pages 61--75, 2007.Google ScholarDigital Library"",""Y. Lin, B. S. Lee, and D. Lustgarten. Continuous detection of abnormal heartbeats from ECG using online outlier detection. In Proc. SIMBig, pages 349--366, 2018.Google Scholar"",""M. Mubashir, L. Shao, and L. Seed. A survey on fall detection: Principles and approaches. Neurocomputing, 100:144--152, 2013.Google ScholarDigital Library"",""G. S. Na, D. Kim, and H. Yu. DILOF: Effective and memory efficient local outlier detection in data streams. In Proc. KDD, pages 1993--2002, 2018.Google ScholarDigital Library"",""D. Pokrajac, A. Lazarevic, and L. J. Latecki. Incremental local outlier detection for data streams. In Proc. CIDM, pages 504--515, 2007.Google ScholarCross Ref"",""X. Qin, L. Cao, E. A. Rundensteiner, and S. Madden. Scalable kernel density estimation-based local outlier detection over large data streams. In Proc. EDBT, pages 421--432, 2019.Google Scholar"",""M. Salehi, C. Leckie, J. C. Bezdek, T. Vaithianathan, and X. Zhang. Fast memory efficient local outlier detection in data streams. IEEE Trans. on Knowledge and Data Engineering, 28(12):3246--3260, 2016.Google ScholarDigital Library"",""E. Schubert, A. Zimek, and H.-P. Kriegel. Generalized outlier detection with flexible kernel density estimates. In Proc. SDM, pages 542--550, 2014.Google ScholarCross Ref"",""D. W. Scott. Multivariate Density Estimation: Theory, Practice, and Visualization. John Wiley \u0026 Sons, 2015.Google ScholarCross Ref"",""S. J. Sheather and M. C. Jones. A reliable data-based bandwidth selection method for kernel density estimation. Journal of the Royal Statistical Society: Series B (Methodological), 53(3):683--690, 1991.Google ScholarCross Ref"",""B. W. Silverman. Density Estimation for Statistics and Data Analysis. 2018.Google Scholar"",""F. Tao, H. Zhang, A. Liu, and A. Y. Nee. Digital twin in industry: State-of-the-art. IEEE Trans. on Industrial Informatics, 15(4):2405--2415, 2018.Google ScholarCross Ref"",""G. R. Terrell, D. W. Scott, et al. Variable kernel density estimation. The Annals of Statistics, 20(3):1236--1265, 1992.Google ScholarCross Ref"",""L. Tran, L. Fan, and C. Shahabi. Distance-based outlier detection in data streams. Proceedings of the VLDB Endowment, 9(12):1089--1100, 2016.Google ScholarDigital Library"",""Yahoo! Webscope. ydata-labeled-time-series-anomalies-v1_0. https://webscope.sandbox.yahoo.com. Accessed: 2020-06-01.Google Scholar"",""S. Yoon, J. G. Lee, and B. S. Lee. NETS: Extremely fast outlier detection from a data stream via set-based processing. Proceedings of the VLDB Endowment, 12(11):1303--1315, 2019.Google ScholarDigital Library"",""E. Zhang and Y. Zhang. Average Precision, Encyclopedia of Database Systems. Springer US, Boston, MA, 2009.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403172,LayoutLM: Pre-training of Text and Layout for Document Image Understanding,"Pre-training techniques have been verified successfully in a variety of NLP tasks in recent years. Despite the widespread use of pre-training models for NLP applications, they almost exclusively focus on text-level manipulation, while neglecting layout and style information that is vital for document image understanding. In this paper, we propose the LayoutLM to jointly model interactions between text and layout information across scanned document images, which is beneficial for a great number of real-world document image understanding tasks such as information extraction from scanned documents. Furthermore, we also leverage image features to incorporate words' visual information into LayoutLM. To the best of our knowledge, this is the first time that text and layout are jointly learned in a single framework for document-level pre-training. It achieves new state-of-the-art results in several downstream tasks, including form understanding (from 70.72 to 79.27), receipt understanding (from 94.02 to 95.24) and document image classification (from 93.07 to 94.42). The code and pre-trained LayoutLM models are publicly available at https://aka.ms/layoutlm.","[{""name"":""Yiheng Xu"",""id"":""/profile/99659574347""},{""name"":""Minghao Li"",""id"":""/profile/99659574160""},{""name"":""Lei Cui"",""id"":""/profile/99659573249""},{""name"":""Shaohan Huang"",""id"":""/profile/99659574289""},{""name"":""Furu Wei"",""id"":""/profile/81363592787""},{""name"":""Ming Zhou"",""id"":""/profile/81329493277""},{""name"":""Yiheng Xu"",""id"":""/profile/99659574347""},{""name"":""Minghao Li"",""id"":""/profile/99659574160""},{""name"":""Lei Cui"",""id"":""/profile/99659573249""},{""name"":""Shaohan Huang"",""id"":""/profile/99659574289""},{""name"":""Furu Wei"",""id"":""/profile/81363592787""},{""name"":""Ming Zhou"",""id"":""/profile/81329493277""}]","[""Muhammad Zeshan Afzal, Andreas Kölsch, Sheraz Ahmed, and Marcus Liwicki. 2017. Cutting the Error by Half: Investigation of Very Deep CNN and Advanced Training Strategies for Document Image Classification. 2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR), Vol. 01 (2017), 883--888.Google ScholarCross Ref"",""Arindam Das, Saikat Roy, and Ujjwal Bhattacharya. 2018. Document Image Classification with Intra-Domain Transfer Learning and Stacked Generalization of Deep Convolutional Neural Networks. 2018 24th International Conference on Pattern Recognition (ICPR) (2018), 3180--3185.Google Scholar"",""Tyler Dauphinee, Nikunj Patel, and Mohammad Mehdi Rashidi. 2019. Modular Multimodal Architecture for Document Classification. ArXiv, Vol. abs/1912.04376 (2019).Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). Association for Computational Linguistics, Minneapolis, Minnesota, 4171--4186. https://doi.org/10.18653/v1/N19--1423Google Scholar"",""Jaekyu Ha, Robert M Haralick, and Ihsin T Phillips. 1995 a. Document page decomposition by the bounding-box project. In Proceedings of 3rd International Conference on Document Analysis and Recognition, Vol. 2. IEEE, 1119--1122.Google Scholar"",""Jaekyu Ha, Robert M Haralick, and Ihsin T Phillips. 1995 b. Recursive XY cut using bounding boxes of connected components. In Proceedings of 3rd International Conference on Document Analysis and Recognition, Vol. 2. IEEE, 952--955.Google Scholar"",""Leipeng Hao, Liangcai Gao, Xiaohan Yi, and Zhi Tang. 2016. A Table Detection Method for PDF Documents Based on Convolutional Neural Networks. 2016 12th IAPR Workshop on Document Analysis Systems (DAS) (2016), 287--292.Google ScholarCross Ref"",""Adam W. Harley, Alex Ufkes, and Konstantinos G. Derpanis. 2015. Evaluation of deep convolutional nets for document image classification and retrieval. 2015 13th International Conference on Document Analysis and Recognition (ICDAR) (2015), 991--995.Google ScholarDigital Library"",""Kaiming He, Georgia Gkioxari, Piotr Dollá r, and Ross B. Girshick. 2017. Mask R-CNN. CoRR, Vol. abs/1703.06870 (2017). arxiv: 1703.06870 http://arxiv.org/abs/1703.06870Google Scholar"",""Guillaume Jaume, Hazim Kemal Ekenel, and Jean-Philippe Thiran. 2019. FUNSD: A Dataset for Form Understanding in Noisy Scanned Documents. 2019 International Conference on Document Analysis and Recognition Workshops (ICDARW), Vol. 2 (2019), 1--6.Google Scholar"",""Anoop R Katti, Christian Reisswig, Cordula Guder, Sebastian Brarda, Steffen Bickel, Johannes Höhne, and Jean Baptiste Faddoul. 2018. Chargrid: Towards Understanding 2D Documents. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Brussels, Belgium, 4459--4469. https://doi.org/10.18653/v1/D18--1476Google ScholarCross Ref"",""Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David A Shamma, Michael Bernstein, and Li Fei-Fei. 2016. Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations. https://arxiv.org/abs/1602.07332Google Scholar"",""Frank Lebourgeois, Z Bublinski, and H Emptoz. 1992. A fast and efficient method for extracting text paragraphs and graphics from unconstrained documents. In Proceedings., 11th IAPR International Conference on Pattern Recognition. Vol. II. Conference B: Pattern Recognition Methodology and Systems. IEEE, 272--276.Google ScholarCross Ref"",""D. Lewis, G. Agam, S. Argamon, O. Frieder, D. Grossman, and J. Heard. 2006. Building a Test Collection for Complex Document Information Processing. In Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (Seattle, Washington, USA) (SIGIR '06). ACM, New York, NY, USA, 665--666. https://doi.org/10.1145/1148170.1148307Google Scholar"",""Xiaojing Liu, Feiyu Gao, Qiong Zhang, and Huasha Zhao. 2019 a. Graph Convolution for Multimodal Information Extraction from Visually Rich Documents. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers). Association for Computational Linguistics, Minneapolis, Minnesota, 32--39. https://doi.org/10.18653/v1/N19--2005Google ScholarCross Ref"",""Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke S. Zettlemoyer, and Veselin Stoyanov. 2019 b. RoBERTa: A Robustly Optimized BERT Pretraining Approach. ArXiv, Vol. abs/1907.11692 (2019).Google Scholar"",""S. Marinai, M. Gori, and G. Soda. 2005. Artificial neural networks for document analysis and recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 27, 1 (Jan 2005), 23--35. https://doi.org/10.1109/TPAMI.2005.4Google ScholarDigital Library"",""L. O'Gorman. 1993. The document spectrum for page layout analysis. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 15, 11 (Nov 1993), 1162--1173. https://doi.org/10.1109/34.244677Google ScholarDigital Library"",""Shaoqing Ren, Kaiming He, Ross B. Girshick, and Jian Sun. 2015. Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 39 (2015), 1137--1149.Google ScholarDigital Library"",""Ritesh Sarkhel and Arnab Nandi. 2019. Deterministic Routing between Layout Abstractions for Multi-Scale Classification of Visually Rich Documents. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19. International Joint Conferences on Artificial Intelligence Organization, 3360--3366. https://doi.org/10.24963/ijcai.2019/466Google ScholarCross Ref"",""Sebastian Schreiber, Stefan Agne, Ivo Wolf, Andreas Dengel, and Sheraz Ahmed. 2017. DeepDeSRT: Deep Learning for Detection and Structure Recognition of Tables in Document Images. 2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR), Vol. 01 (2017), 1162--1167.Google Scholar"",""Michael Shilman, Percy Liang, and Paul Viola. 2005. Learning nongenerative grammatical models for document analysis. In Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1, Vol. 2. IEEE, 962--969.Google ScholarDigital Library"",""Anikó Simon, J-C Pret, and A Peter Johnson. 1997. A fast algorithm for bottom-up document layout analysis. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 19, 3 (1997), 273--277.Google ScholarDigital Library"",""Carlos Soto and Shinjae Yoo. 2019. Visual Detection with Context for Document Layout Analysis. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). Association for Computational Linguistics, Hong Kong, China, 3462--3468. https://doi.org/10.18653/v1/D19--1348Google Scholar"",""Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, and Alex Alemi. 2016. Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning. In AAAI .Google Scholar"",""Matheus Palhares Viana and Dário Augusto Borges Oliveira. 2017. Fast CNN-Based Document Layout Analysis. 2017 IEEE International Conference on Computer Vision Workshops (ICCVW) (2017), 1173--1180.Google Scholar"",""H. Wei, M. Baechler, F. Slimane, and R. Ingold. 2013. Evaluation of SVM, MLP and GMM Classifiers for Layout Analysis of Historical Documents. In 2013 12th International Conference on Document Analysis and Recognition. 1220--1224. https://doi.org/10.1109/ICDAR.2013.247Google Scholar"",""Xiaowei Yang, Ersin Yumer, Paul Asente, Mike Kraley, Daniel Kifer, and C. Lee Giles. 2017. Learning to Extract Semantic Structure from Documents Using Multimodal Fully Convolutional Neural Networks. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017), 4342--4351.Google ScholarCross Ref"",""Xu Zhong, Jianbin Tang, and Antonio Jimeno-Yepes. 2019. PubLayNet: largest dataset ever for document layout analysis. ArXiv, Vol. abs/1908.07836 (2019).Google Scholar""]"
https://doi.org/10.1145/3394486.3403173,Block Model Guided Unsupervised Feature Selection,"Feature selection is a core area of data mining with a recent innovation of graph-driven unsupervised feature selection for linked data. In this setting we have a dataset Y consisting of n instances each with m features and a corresponding n node graph (whose adjacency matrix is A) with an edge indicating that the two instances are similar. Existing efforts for unsupervised feature selection on attributed networks have explored either directly regenerating the links by solving for f such that f(yi,yj) ~ Ai,j or finding community structure in A and using the features in Y to predict these communities. However, graph-driven unsupervised feature selection remains an understudied area with respect to exploring more complex guidance. Here we take the novel approach of first building a block model on the graph and then using the block model for feature selection. That is, we discover FMFT ~ A and then find a subset of features S that induces another graph to preserve both F and M. We call our approach Block Model Guided Unsupervised Feature Selection (BMGUFS). Experimental results show that our method outperforms the state of the art on several real-world public datasets in finding high-quality features for clustering.","[{""name"":""Zilong Bai"",""id"":""/profile/99659193210""},{""name"":""Hoa Nguyen"",""id"":""/profile/99659574659""},{""name"":""Ian Davidson"",""id"":""/profile/81488655446""},{""name"":""Zilong Bai"",""id"":""/profile/99659193210""},{""name"":""Hoa Nguyen"",""id"":""/profile/99659574659""},{""name"":""Ian Davidson"",""id"":""/profile/81488655446""}]","[""Emmanuel Abbe. 2017. Community detection and stochastic block models: recent developments. JMLR, Vol. 18, 1 (2017), 6446--6531.Google ScholarDigital Library"",""Christopher Aicher, Abigail Z Jacobs, and Aaron Clauset. 2015. Learning latent block structure in weighted networks. Journal of Complex Networks, Vol. 3, 2 (2015).Google ScholarCross Ref"",""Zilong Bai, Buyue Qian, and Ian Davidson. 2018a. Discovering models from structural and behavioral brain imaging data. In SIGKDD. 1128--1137.Google Scholar"",""Zilong Bai, Peter Walker, and Ian Davidson. 2018b. Mixtures of block models for brain networks. In SDM. 46--54.Google Scholar"",""Zilong Bai, Peter Walker, Anna Tschiffely, Fei Wang, and Ian Davidson. 2017. Unsupervised network discovery for brain imaging data. In SIGKDD. 55--64.Google Scholar"",""Mikhail Belkin and Partha Niyogi. 2002. Laplacian eigenmaps and spectral techniques for embedding and clustering. In NIPS. 585--591.Google Scholar"",""Chris Ding, Tao Li, Wei Peng, and Haesun Park. 2006. Orthogonal nonnegative matrix t-factorizations for clustering. In SIGKDD. 126--135.Google Scholar"",""Liang Du and Yi-Dong Shen. 2015. Unsupervised feature selection with adaptive structure learning. In SIGKDD. 209--218.Google Scholar"",""Liang Du, Zhiyong Shen, Xuan Li, Peng Zhou, and Yi-Dong Shen. 2013. Local and global discriminative learning for unsupervised feature selection. In IEEE ICDM. 131--140.Google Scholar"",""Jennifer G Dy and Carla E Brodley. 2004. Feature selection for unsupervised learning. JMLR, Vol. 5, Aug (2004), 845--889.Google Scholar"",""Mohadeseh Ganji, Jeffrey Chan, Peter J Stuckey, James Bailey, Christopher Leckie, Kotagiri Ramamohanarao, and Ian Davidson. 2018. Image constrained blockmodelling: a constraint programming approach. In SDM. 19--27.Google Scholar"",""Michelle Girvan and Mark EJ Newman. 2002. Community structure in social and biological networks. PNAS, Vol. 99, 12 (2002), 7821--7826.Google ScholarCross Ref"",""Quanquan Gu, Marina Danilevsky, Zhenhui Li, and Jiawei Han. 2012. Locality preserving feature learning. In AISTATS. 477--485.Google Scholar"",""Xiaofei He, Deng Cai, and Partha Niyogi. 2006. Laplacian score for feature selection. In NIPS. 507--514.Google Scholar"",""Chenping Hou, Feiping Nie, Dongyun Yi, and Yi Wu. 2011. Feature selection via joint embedding learning and sparse regression. In IJCAI.Google Scholar"",""Xiao Huang, Jundong Li, and Xia Hu. 2017. Label Informed Attributed Network Embedding. In WSDM. 731--739.Google Scholar"",""Xiao Huang, Qingquan Song, Jundong Li, and Xia Hu. 2018. Exploring expert cognition for attributed network embedding. In WSDM. 270--278.Google Scholar"",""Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. ICLR (2016).Google Scholar"",""Ron Kohavi, George H John, et al. 1997. Wrappers for feature subset selection. (1997).Google Scholar"",""Solomon Kullback. 1997. Information theory and statistics .Courier Corporation.Google Scholar"",""Jundong Li, Kewei Cheng, Suhang Wang, Fred Morstatter, Robert P Trevino, Jiliang Tang, and Huan Liu. 2017. Feature selection: A data perspective. ACM Computing Surveys (CSUR), Vol. 50, 6 (2017), 1--45.Google ScholarDigital Library"",""Jundong Li, Ruocheng Guo, Chenghao Liu, and Huan Liu. 2019. Adaptive unsupervised feature selection on attributed networks. In SIGKDD. 92--100.Google Scholar"",""Jundong Li, Xia Hu, Liang Wu, and Huan Liu. 2016. Robust unsupervised feature selection on networked data. In SDM. 387--395.Google Scholar"",""Zechao Li, Yi Yang, Jing Liu, Xiaofang Zhou, and Hanqing Lu. 2012. Unsupervised feature selection using nonnegative spectral analysis. In AAAI.Google Scholar"",""Chih-Jen Lin. 2007. Projected gradient methods for nonnegative matrix factorization. Neural computation, Vol. 19, 10 (2007), 2756--2779.Google Scholar"",""Huan Liu, Fred Morstatter, Jiliang Tang, and Reza Zafarani. 2016. The good, the bad, and the ugly: uncovering novel research opportunities in social media mining. International Journal of Data Science and Analytics, Vol. 1, 3--4 (2016), 137--143.Google ScholarCross Ref"",""Alex Mattenet, Ian Davidson, Siegfried Nijssen, and Pierre Schaus. 2019. Generic Constraint-Based Block Modeling Using Constraint Programming. In CP. Springer, 656--673.Google Scholar"",""Berndt Müller, Joachim Reinhardt, and Michael T Strickland. 2012. Neural networks: an introduction .Springer Science \u0026 Business Media.Google Scholar"",""Subhadeep Paul and Yuguo Chen. 2016. Orthogonal symmetric non-negative matrix factorization under the stochastic block model. arXiv preprint arXiv:1605.05349 (2016).Google Scholar"",""Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. 2011. Scikit-learn: Machine learning in Python. JMLR, Vol. 12 (2011), 2825--2830.Google ScholarDigital Library"",""Mingjie Qian and Chengxiang Zhai. 2013. Robust unsupervised feature selection. In IJCAI.Google Scholar"",""Nahid Safari-Alighiarloo, Mohammad Taghizadeh, Mostafa Rezaei-Tavirani, Bahram Goliaei, and Ali Asghar Peyvandi. 2014. Protein-protein interaction networks (PPI) and complex diseases. Gastroenterol Hepatol Bed Bench (2014).Google Scholar"",""Patricia Iglesias Sánchez, Emmanuel Müller, Uwe Leo Korn, Klemens Böhm, Andrea Kappes, Tanja Hartmann, and Dorothea Wagner. 2015. Efficient algorithms for a robust modularity-driven clustering of attributed graphs. In SDM. 100--108.Google Scholar"",""Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, and Tina Eliassi-Rad. 2008. Collective classification in network data. AI magazine, Vol. 29, 3 (2008), 93--93.Google Scholar"",""Lei Shi, Liang Du, and Yi-Dong Shen. 2014. Robust spectral learning for unsupervised feature selection. In IEEE ICDM. 977--982.Google Scholar"",""Jiliang Tang and Huan Liu. 2012. Unsupervised feature selection for linked social media data. In SIGKDD. 904--912.Google Scholar"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. In WWW. 1067--1077.Google ScholarDigital Library"",""Lei Tang and Huan Liu. 2009. Relational learning via latent social dimensions. In SIGKDD. 817--826.Google Scholar"",""Io Taxidou and Peter M Fischer. 2014. Online analysis of information diffusion in twitter. In WWW. 1313--1318.Google Scholar"",""Xiaokai Wei, Bokai Cao, and S Yu Philip. 2016. Unsupervised feature selection on networks: a generative view. In AAAI.Google Scholar"",""Xiaokai Wei, Sihong Xie, and Philip S Yu. 2015. Efficient partial order preserving unsupervised feature selection on networks. In SDM. 82--90.Google Scholar"",""Yi Yang, Heng Tao Shen, Zhigang Ma, Zi Huang, and Xiaofang Zhou. 2011. L2, 1-norm regularized discriminative feature selection for unsupervised. In IJCAI.Google Scholar"",""Daokun Zhang, Jie Yin, Xingquan Zhu, and Chengqi Zhang. 2018b. Network representation learning: A survey. IEEE transactions on Big Data (2018).Google Scholar"",""Zhong-Yuan Zhang, Yujie Gai, Yu-Fei Wang, Hui-Min Cheng, and Xin Liu. 2018a. On equivalence of likelihood maximization of stochastic block model and constrained nonnegative matrix factorization. Physica A: Statistical Mechanics and its Applications, Vol. 503 (2018), 687--697.Google Scholar"",""Zheng Zhao and Huan Liu. 2007. Spectral feature selection for supervised and unsupervised learning. In ICML. 1151--1157.Google Scholar"",""Chen Zhe, Aixin Sun, and Xiaokui Xiao. 2019. Community detection on large complex attribute network. In SIGKDD. 2041--2049.Google Scholar""]"
https://doi.org/10.1145/3394486.3403174,Data Compression as a Comprehensive Framework for Graph Drawing and Representation Learning,"Embedding a graph into feature space is a promising approach to understand its structure. Embedding into 2D or 3D space enables visualization; representation in higher-dimensional vector space (typically >100D) enables the application of data mining techniques. For the success of knowledge discovery it is essential that the distances between the embedded vertices truly reflect the structure of the graph. Our fundamental idea is to compress the adjacency matrix by predicting the existence of an edge from the Euclidean distance between the corresponding vertices in the embedding, and to use the achieved compression as a quality measure for the embedding. We call this quality measure Predictive Entropy (PE). PE uses a sigmoid function to define the probability which is monotonically decreasing with the Euclidean distance. We use this sigmoid probability to compress the adjacency matrix of the graph by an entropy coding. While PE could be used to assess the result of any graph drawing or representation learning method we particularly use it as objective function in our new method GEMPE (Graph Embedding by Minimizing the Predictive Entropy). We demonstrate in our experiments that GEMPE clearly outperforms comparison methods with respect to quality of the visual result, clustering and node-labeling accuracy on the discovered coordinates.","[{""name"":""Claudia Plant"",""id"":""/profile/81321496970""},{""name"":""Sonja Biedermann"",""id"":""/profile/99659573884""},{""name"":""Christian Böhm"",""id"":""/profile/81100395758""},{""name"":""Claudia Plant"",""id"":""/profile/81321496970""},{""name"":""Sonja Biedermann"",""id"":""/profile/99659573884""},{""name"":""Christian Böhm"",""id"":""/profile/81100395758""}]","[""Christian Bö hm, Martin Perdacher, and Claudia Plant. 2017. Multi-core K-means. In SIAM Int. Conf. Data Mining. 273--281.Google Scholar"",""Ulrik Brandes and Christian Pich. 2006. Eigensolver Methods for Progressive Multidimensional Scaling of Large Data. In Int. Symp. on Graph Drawing. 42--53.Google Scholar"",""Ulrik Brandes and Christian Pich. 2008. An Experimental Study on Distance-Based Graph Drawing. In Int. Symp. on Graph Drawing. 218--229.Google Scholar"",""Jing Feng, Xiao He, Nina Hubig, Christian Böhm, and Claudia Plant. 2013. Compression-Based Graph Mining Exploiting Structure Primitives. In ICDM. 181--190.Google Scholar"",""Jing Feng, Xiao He, Bettina Konte, Christian Böhm, and Claudia Plant. 2012. Summarization-based mining bipartite graphs. In KDD conference. 1249--1257.Google ScholarDigital Library"",""Linton C. Freeman. 2004. Graphic Techniques for Exploring Social Network Data. In in Models and Methods in Social Network Analysis. Univ Press.Google Scholar"",""Arne Frick, Andreas Ludwig, and Heiko Mehldau. 1994. A Fast Adaptive Layout Algorithm for Undirected Graphs. In DIMACS Graph Drawing Worksh. 388--403.Google Scholar"",""Thomas M. J. Fruchterman and Edward M. Reingold. 1991. Graph Drawing by Force-directed Placement. Softw., Pract. Exper., Vol. 21, 11 (1991), 1129--1164.Google ScholarDigital Library"",""Pawel Gajer and Stephen G. Kobourov. 2002. GRIP: Graph Drawing with Intelligent Placement. J. Graph Algorithms Appl., Vol. 6, 3 (2002), 203--224.Google ScholarCross Ref"",""Emden R. Gansner, Yehuda Koren, and Stephen C. North. 2004. Graph Drawing by Stress Majorization. In Int. Symp. on Graph Drawing. 239--250.Google Scholar"",""Helen Gibson, Joe Faith, and Paul Vickers. 2013. A survey of two-dimensional graph layout techniques for information visualisation. Information Visualization, Vol. 12, 3--4 (2013), 324--357.Google ScholarCross Ref"",""Sebastian Goebl, Annika Tonch, Christian Bö hm, and Claudia Plant. 2016. MeGS: Partitioning Meaningful Subgraph Structures Using Minimum Description Length. In ICDM. 889--894.Google Scholar"",""Martin Gronemann. 2009. Engineering the Fast-Multipole-Multilevel Method for multicore and SIMD architectures. Master's thesis. Technische Univ. Dortmund.Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable Feature Learning for Networks. In KDD. 855--864.Google Scholar"",""Stefan Hachul and Michael Jü nger. 2004. Drawing Large Graphs with a Potential-Field-Based Multilevel Algorithm. In Int. Symp. on Graph Drawing. 285--295.Google Scholar"",""William L. Hamilton, Rex Ying, and Jure Leskovec. 2017. Representation Learning on Graphs: Methods and Applications. IEEE Data Eng. Bull., Vol. 40, 3 (2017), 52--74.Google Scholar"",""Henning Meyerhenke, Martin Nö llenburg, and Christian Schulz. 2018. Drawing Large Graphs by Multilevel Maxent-Stress Optimization. IEEE Trans. Vis. Comput. Graph., Vol. 24, 5 (2018), 1814--1827.Google ScholarCross Ref"",""Andreas Noack. 2007. Energy Models for Graph Clustering. J. Graph Algorithms Appl., Vol. 11, 2 (2007), 453--480.Google ScholarCross Ref"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. DeepWalk: online learning of social representations. In KDD Conference. 701--710.Google ScholarDigital Library"",""Leonardo Filipe Rodrigues Ribeiro, Pedro H. P. Saverese, and Daniel R. Figueiredo. 2017. struc2vec: Learning Node Representations from Structural Identity. In KDD. 385--394.Google Scholar"",""Blake Shaw and Tony Jebara. 2009. Structure Preserving Embedding. In ICML Conference. 937--944.Google Scholar"",""Noah A. Smith and Jason Eisner. 2005. Contrastive Estimation: Training Log-Linear Models on Unlabeled Data. In ACL Conf. 354--362.Google Scholar"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. LINE: Large-scale Information Network Embedding. In WWW Conf. 1067--1077.Google ScholarDigital Library"",""Anton Tsitsulin, Davide Mottin, Panagiotis Karras, and Emmanuel Müller. 2018. VERSE: Versatile Graph Embeddings from Similarity Measures. In WWW Conf. 539--548.Google ScholarDigital Library"",""Laurens van der Maaten and Geoffrey E. Hinton. 2008. Visualizing High-Dimensional Data Using t-SNE. Journal of Machine Learning Research, Vol. 9 (2008), 2579--2605.Google Scholar"",""Nguyen Xuan Vinh, Julien Epps, and James Bailey. 2010. Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance. Journal of Machine Learning Research, Vol. 11 (2010), 2837--2854.Google ScholarDigital Library"",""Daixin Wang, Peng Cui, and Wenwu Zhu. 2016. Structural Deep Network Embedding. In KDD. 1225--1234.Google Scholar"",""Ziwei Zhang, Peng Cui, Xiao Wang, Jian Pei, Xuanrong Yao, and Wenwu Zhu. 2018. Arbitrary-Order Proximity Preserved Network Embedding. In KDD. 2778--2786.Google Scholar""]"
https://doi.org/10.1145/3394486.3403175,Joint Policy-Value Learning for Recommendation,"Conventional approaches to recommendation often do not explicitly take into account information on previously shown recommendations and their recorded responses. One reason is that, since we do not know the outcome of actions the system did not take, learning directly from such logs is not a straightforward task. Several methods for off-policy or counterfactual learning have been proposed in recent years, but their efficacy for the recommendation task remains understudied. Due to the limitations of offline datasets and the lack of access of most academic researchers to online experiments, this is a non-trivial task. Simulation environments can provide a reproducible solution to this problem.In this work, we conduct the first broad empirical study of counterfactual learning methods for recommendation, in a simulated environment. We consider various different policy-based methods that make use of the Inverse Propensity Score (IPS) to perform Counterfactual Risk Minimisation (CRM), as well as value-based methods based on Maximum Likelihood Estimation (MLE). We highlight how existing off-policy learning methods fail due to stochastic and sparse rewards, and show how a logarithmic variant of the traditional IPS estimator can solve these issues, whilst convexifying the objective and thus facilitating its optimisation. Additionally, under certain assumptions the value- and policy-based methods have an identical parameterisation, allowing us to propose a new model that combines both the MLE and CRM objectives. Extensive experiments show that this ""Dual Bandit"" approach achieves state-of-the-art performance in a wide range of scenarios, for varying logging policies, action spaces and training sample sizes.","[{""name"":""Olivier Jeunen"",""id"":""/profile/99659463663""},{""name"":""David Rohde"",""id"":""/profile/99659549416""},{""name"":""Flavian Vasile"",""id"":""/profile/81392602246""},{""name"":""Martin Bompaire"",""id"":""/profile/99659287849""},{""name"":""Olivier Jeunen"",""id"":""/profile/99659463663""},{""name"":""David Rohde"",""id"":""/profile/99659549416""},{""name"":""Flavian Vasile"",""id"":""/profile/81392602246""},{""name"":""Martin Bompaire"",""id"":""/profile/99659287849""}]","[""A. Agarwal, X. Wang, C. Li, M. Bendersky, and M. Najork. 2019. Addressing Trust Bias for Unbiased Learning-to-Rank. In Proc. of the 2019 World Wide Web Conference (WWW '19). ACM, 4--14.Google Scholar"",""L. Bottou, J. Peters, J. Quiñonero-Candela, D. Charles, D. Chickering, E. Portugaly, D. Ray, P. Simard, and E. Snelson. 2013. Counterfactual reasoning and learning systems: The example of computational advertising. The Journal of Machine Learning Research 14, 1 (2013), 3207--3260.Google ScholarDigital Library"",""O. Chapelle and L. Li. 2011. An Empirical Evaluation of Thompson Sampling. In Proc. of the 24th International Conference on Neural Information Processing Systems(NIPS'11). 2249--2257.Google Scholar"",""M. Chen, A. Beutel, P. Covington, S. Jain, F. Belletti, and E. H. Chi. 2019. Top-K Off-Policy Correction for a REINFORCE Recommender System. In Proc. of the 12th ACM International Conference on Web Search and Data Mining (WSDM '19). ACM, 456--464.Google Scholar"",""M. F. Dacrema, P. Cremonesi, and D. Jannach. 2019. Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches. In Proc. of the 13th ACM Conference on Recommender Systems (RecSys '19). ACM,101--109.Google Scholar"",""M. Dudík, J. Langford, and L. Li. 2011. Doubly Robust Policy Evaluation and Learning. In Proc. of the 28th International Conference on International Conference on Machine Learning (ICML'11). 1097--1104.Google Scholar"",""M. Farajtabar, Y. Chow, and M. Ghavamzadeh. 2018. More Robust Doubly Robust Off-policy Evaluation. In Proc. of the 35th International Conference on Machine Learning (ICML'18, Vol. 80). PMLR, 1447--1456.Google Scholar"",""F. Garcin, B. Faltings, O. Donatsch, A. Alazzawi, C. Bruttin, and A. Huber. 2014. Offline and Online Evaluation of News Recommender Systems at Swiss info. Ch. In Proc. of the 8th ACM Conference on Recommender Systems (RecSys '14). 169--176.Google Scholar"",""A. Gilotte, C. Calauzènes, T. Nedelec, A. Abraham, and S. Dollé. 2018. Offline A/B Testing for Recommender Systems. InProc. of the Eleventh ACM International Conference on Web Search and Data Mining (WSDM '18). ACM, 198--206.Google Scholar"",""A. Gruson, P. Chandar, C. Charbuillet, J. McInerney, S. Hansen, D. Tardieu, and B. Carterette. 2019. Offline Evaluation to Make Decisions About Playlist Recommendation Algorithms. In Proceedings of the 12th ACM International Conference on Web Search and Data Mining (WSDM '19). ACM, 420--428.Google Scholar"",""D. Hosmer Jr., S. Lemeshow, and R. Sturdivant. 2013.Applied logistic regression. Vol. 398. John Wiley \u0026 Sons.Google Scholar"",""E. Ie, C. Hsu, M. Mladenov, V. Jain, S. Narvekar, J. Wang, R. Wu, and C. Boutilier. 2019. RecSim: A Configurable Simulation Platform for Recommender Systems. arXiv:1909.04847 [cs.LG]Google Scholar"",""R. Jagerman, H. Oosterhuis, and M. de Rijke. 2019. To Model or to Intervene: A Comparison of Counterfactual and Online Learning to Rank from User Interactions. In Proc. of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR'19). ACM, 15--24.Google ScholarDigital Library"",""O. Jeunen. 2019. Revisiting Offline Evaluation for Implicit-feedback Recommender Systems. In Proc. of the 13th ACM Conference on Recommender Systems (RecSys'19). ACM, 596--600.Google ScholarDigital Library"",""O. Jeunen, D. Mykhaylov, D. Rohde, F. Vasile, A. Gilotte, and M. Bompaire. 2019. Learning from Bandit Feedback: An Overview of the State-of-the-art. arXiv:1909.08471 [cs.IR]Google Scholar"",""O. Jeunen, D. Rohde, and F. Vasile. 2019. On the Value of Bandit Feedback for Offline Recommender System Evaluation. arXiv:1907.12384 [cs.IR]Google Scholar"",""T. Joachims, A. Swaminathan, and M. de Rijke. 2018. Deep Learning with Logged Bandit Feedback. In Proc. of the 6th International Conference on Learning Representations (ICLR '18).Google Scholar"",""Y. Koren, R. Bell, and C. Volinsky. 2009. Matrix Factorization Techniques for Recommender Systems. Computer 42, 8 (Aug. 2009), 30--37.Google ScholarDigital Library"",""Q. Le, J. Ngiam, A. Coates, A. Lahiri, B. Prochnow, and A. Ng. 2011. On optimization methods for deep learning. InProc. of the 28th International Conference on International Conference on Machine Learning (ICML '11). 265--272.Google Scholar"",""D. Lefortier, A. Swaminathan, X. Gu, T. Joachims, and M. de Rijke. 2016. Large-scale validation of counterfactual learning methods: A test-bed. arXiv preprint arXiv:1612.00367(2016).Google Scholar"",""A. S. Lewis and M. L. Overton. 2013. Nonsmooth optimization via quasi-Newton methods. Mathematical Programming141, 1--2 (2013), 135--163.Google Scholar"",""L. Li, W. Chu, J. Langford, and R. E. Schapire. 2010. A Contextual-Bandit Approach to Personalized News Article Recommendation. In Proc. of the 19th International Conference on World Wide Web (WWW '10). ACM, 661--670.Google Scholar"",""S. Li, A. Karatzoglou, and C. Gentile. 2016. Collaborative Filtering Bandits. In Proc. of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '16). ACM, 539--548.Google Scholar"",""D. Liang, R. G. Krishnan, M. D Hoffman, and T. Jebara. 2018. Variational autoencoders for collaborative filtering. In Proc. of the 2018 World Wide Web Conference(WWW '18). ACM, 689--698.Google Scholar"",""B. London and T. Sandler. 2019. Bayesian Counterfactual Risk Minimization. In Proc. of the 36th International Conference on Machine Learning (ICML '19, Vol. 97). PMLR, 4125--4133.Google Scholar"",""J. Ma, Z. Zhao, X. Yi, J. Yang, M. Chen, J. Tang, L. Hong, and E. H. Chi. 2020. Off-Policy Learning in Two-Stage Recommender Systems. In Proc. of the 2020World Wide Web Conference (WWW '20). ACM.Google Scholar"",""Y. Ma, Y. Wang, and B. Narayanaswamy. 2019. Imitation-Regularized Offline Learning. In Proc. of the 22nd International Conference on Artificial Intelligence and Statistics (AISTATS) (AI Stats '19, Vol. 89). PMLR, 2956--2965.Google Scholar"",""H. B. McMahan, G. Holt, D. Sculley, M. Young, D. Ebner, J. Grady, L. Nie, T.Phillips, E. Davydov, D. Golovin, et al. 2013. Ad click prediction: a view from the trenches. In Proc. of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 1222--1230.Google ScholarDigital Library"",""D. Mykhaylov, D. Rohde, F. Vasile, M. Bompaire, and O. Jeunen. 2019. Three Methods for Training on Bandit Feedback. arXiv:1904.10799 [cs.IR]Google Scholar"",""A. B. Owen. 2013.Monte Carlo theory, methods and examples.Google Scholar"",""A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin,N. Gimelshein, L. Antiga, A. Desmaison, A. Kopf, E. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai, and S. Chintala. 2019. PyTorch: An Imperative Style, High-Performance Deep Learning Library. In Advances in Neural Information Processing Systems 32. 8026--8037.Google Scholar"",""S. Rendle. 2019. Evaluation Metrics for Item Recommendation under Sampling. arXiv:1912.02263 [cs.IR]Google Scholar"",""S. Rendle, L. Zhang, and Y. Koren. 2019. On the Difficulty of Evaluating Baselines: A Study on Recommender Systems. arXiv:1905.01395 [cs.IR]Google Scholar"",""D. Rohde, S. Bonner, T. Dunlop, F. Vasile, and A. Karatzoglou. 2018. RecoGym: A Reinforcement Learning Environment for the problem of Product Recommendation in Online Advertising. ArXiv e-prints(Aug. 2018). arXiv:1808.00720 [cs.IR]Google Scholar"",""M. Rossetti, F. Stella, and M. Zanker. 2016. Contrasting Offline and Online Results when Evaluating Recommendation Algorithms. In Proc. of the 10th ACM Conference on Recommender Systems (RecSys '16). ACM, 31--34.Google Scholar"",""O. Sakhi, S. Bonner, D. Rohde, and F. Vasile. 2020. BLOB : A Probabilistic Model for Recommendation that Combines Organic and Bandit Signals. In Proc. of the 26th ACM Conference on Knowledge Discovery \u0026 Data Mining (KDD '20). ACM.Google Scholar"",""R. Salakhutdinov and A. Mnih. 2008. Bayesian Probabilistic Matrix Factorization Using Markov Chain Monte Carlo. In Proc. of the 25th International Conference on Machine Learning (ICML '08). ACM, 880--887.Google Scholar"",""I. Shenbin, A. Alekseev, E. Tutubalina, V. Malykh, and S. I. Nikolenko. 2020. RecVAE: A New Variational Autoencoder for Top-N Recommendations with Implicit Feedback. In Proc. of the 13th International Conference on Web Search and Data Mining (WSDM '20). ACM, 528--536.Google Scholar"",""H. Shimodaira. 2000. Improving predictive inference under covariate shift by weighting the log-likelihood function. Journal of Statistical Planning and Inference 90, 2 (2000), 227 -- 244.Google ScholarCross Ref"",""J. E. Smith and R. L. Winkler. 2006. The Optimizer's Curse: Skepticism and Post decision Surprise in Decision Analysis. Management Science 52, 3 (2006),311--322.Google ScholarDigital Library"",""H. Steck. 2013. Evaluation of Recommendations: Rating-prediction and Ranking. In Proc. of the 7th ACM Conference on Recommender Systems (RecSys '13). ACM, 213--220.Google ScholarDigital Library"",""H. Steck. 2019. Embarrassingly Shallow Autoencoders for Sparse Data. In The World Wide Web Conference (WWW '19). ACM, 3251--3257.Google Scholar"",""A. Storkey. 2009. When training and test sets are different: characterizing learning transfer. Dataset shift in machine learning(2009), 3--28.Google Scholar"",""Y. Su, L. Wang, M. Santacatterina, and T. Joachims. 2019. CAB: Continuous Adaptive Blending for Policy Evaluation and Learning. In International Conference on Machine Learning (ICML'19). 6005--6014.Google Scholar"",""R. S. Sutton and A. G. Barto. 1998. Introduction to reinforcement learning. Vol. 135.Google Scholar"",""R. S. Sutton, D. McAllester, S. Singh, and Y. Mansour. 1999. Policy Gradient Methods for Reinforcement Learning with Function Approximation. In Advances in Neural Information Processing Systems (NIPS'99). 1057--1063.Google Scholar"",""A. Swaminathan and T. Joachims. 2015. Batch learning from logged bandit feedback through counterfactual risk minimization. Journal of Machine Learning Research 16, 1 (2015), 1731--1755.Google ScholarDigital Library"",""A. Swaminathan and T. Joachims. 2015. The Self-Normalized Estimator for Counterfactual Learning. In Advances in Neural Information Processing Systems. 3231--3239.Google Scholar"",""N. Vlassis, A. Bibaut, M. Dimakopoulou, and T. Jebara. 2019. On the Design of Estimators for Bandit Off-Policy Evaluation. In Proc. of the 36th International Conference on Machine Learning (ICML'19, Vol. 97). PMLR, 6468--6476.Google Scholar"",""R. J. Williams. 1992. Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning. Machine Learning 8, 3--4 (May 1992), 229--256.Google ScholarDigital Library"",""J. Yu, S.V.N. Vishwanathan, S. Günter, and N. Schraudolph. 2010. A quasi-Newton approach to non-smooth convex optimization problems in machine learning. Journal of Machine Learning Research11, Mar (2010), 1145--1200.Google Scholar"",""H. Zou, K. Kuang, B. Chen, P. Chen, and P. Cui. 2019. Focused Context Balancing for Robust Offline Policy Evaluation. In Proc. of the 25th ACM Conference on Knowledge Discovery \u0026 Data Mining (KDD '19). ACM, 696--704.Google Scholar""]"
https://doi.org/10.1145/3394486.3403176,FedFast: Going Beyond Average for Faster Training of Federated Recommender Systems,"Federated learning (FL) is quickly becoming the de facto standard for the distributed training of deep recommendation models, using on-device user data and reducing server costs. In a typical FL process, a central server tasks end-users to train a shared recommendation model using their local data. The local models are trained over several rounds on the users' devices and the server combines them into a global model, which is sent to the devices for the purpose of providing recommendations. Standard FL approaches use randomly selected users for training at each round, and simply average their local models to compute the global model. The resulting federated recommendation models require significant client effort to train and many communication rounds before they converge to a satisfactory accuracy. Users are left with poor quality recommendations until the late stages of training. We present a novel technique, FedFast, to accelerate distributed learning which achieves good accuracy for all users very early in the training process. We achieve this by sampling from a diverse set of participating clients in each training round and applying an active aggregation method that propagates the updated model to the other clients. Consequently, with FedFast the users benefit from far lower communication costs and more accurate models that can be consumed anytime during the training process even at the very early stages. We demonstrate the efficacy of our approach across a variety of benchmark datasets and in comparison to state-of-the-art recommendation techniques.","[{""name"":""Khalil Muhammad"",""id"":""/profile/99658988583""},{""name"":""Qinqin Wang"",""id"":""/profile/99659573929""},{""name"":""Diarmuid O'Reilly-Morgan"",""id"":""/profile/99659574175""},{""name"":""Elias Tragos"",""id"":""/profile/81339533028""},{""name"":""Barry Smyth"",""id"":""/profile/81100297638""},{""name"":""Neil Hurley"",""id"":""/profile/81100444485""},{""name"":""James Geraci"",""id"":""/profile/81466640605""},{""name"":""Aonghus Lawlor"",""id"":""/profile/81508708314""},{""name"":""Khalil Muhammad"",""id"":""/profile/99658988583""},{""name"":""Qinqin Wang"",""id"":""/profile/99659573929""},{""name"":""Diarmuid O'Reilly-Morgan"",""id"":""/profile/99659574175""},{""name"":""Elias Tragos"",""id"":""/profile/81339533028""},{""name"":""Barry Smyth"",""id"":""/profile/81100297638""},{""name"":""Neil Hurley"",""id"":""/profile/81100444485""},{""name"":""James Geraci"",""id"":""/profile/81466640605""},{""name"":""Aonghus Lawlor"",""id"":""/profile/81508708314""}]","[""Marharyta Aleksandrova, Armelle Brun, Anne Boyer, and Oleg Chertov. 2017. Identifying Representative Users in Matrix Factorization-based Recommender Systems: Application to Solving the Content-less New Item Cold-Start Problem. Journal of Intelligent Information Systems, Vol. 48, 2 (2017), 365--397.Google ScholarDigital Library"",""Muhammad Ammad-ud-din, Elena Ivannikova, Suleiman A. Khan, Were Oyomno, Qiang Fu, Kuan Eeik Tan, and Adrian Flanagan. 2019. Federated Collaborative Filtering for Privacy-Preserving Personalized Recommendation System. CoRR, Vol. abs/1901.09888 (2019), 1--12. arxiv: 1901.09888Google Scholar"",""Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman, Vladimir Ivanov, Chloé Kiddon, Jakub Konecný, Stefano Mazzocchi, H. Brendan McMahan, Timon Van Overveldt, David Petrou, Daniel Ramage, and Jason Roselander. 2019. Towards Federated Learning at Scale: System Design. CoRR, Vol. abs/1902.01046 (2019), 1--15. arxiv: 1902.01046Google Scholar"",""Fei Chen, Mi Luo, Zhenhua Dong, Zhenguo Li, and Xiuqiang He. 2018. Federated Meta-Learning with Fast Convergence and Efficient Communication. arxiv: cs.LG/1802.07876Google Scholar"",""Ting Chen, Yizhou Sun, Yue Shi, and Liangjie Hong. 2017. On Sampling Strategies for Neural Network-based Collaborative Filtering. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, New York, USA, 767--776.Google ScholarDigital Library"",""Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep Neural Networks for YouTube Recommendations. In Proceedings of the 10th ACM Conference on Recommender Systems. ACM, New York, USA, 191--198.Google ScholarDigital Library"",""Mukund Deshpande and George Karypis. 2004. Item-based Top-N Recommendation Algorithms. ACM Transactions on Information Systems, Vol. 22, 1 (2004), 143--177.Google ScholarDigital Library"",""Ruihai Dong, Michael P O'Mahony, Markus Schaal, Kevin McCarthy, and Barry Smyth. 2016. Combining Similarity and Sentiment in Opinion Mining for Product Recommendation. Journal of Intelligent Information Systems, Vol. 46, 2 (2016), 285--312.Google ScholarDigital Library"",""Ali Mamdouh Elkahky, Yang Song, and Xiaodong He. 2015. A Multi-View Deep Learning Approach for Cross Domain User Modeling in Recommendation Systems. In Proceedings of the 24th International Conference on World Wide Web (WWW '15). International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, Switzerland, 278--288.Google ScholarDigital Library"",""Jack Goetz, Kshitiz Malik, Duc Bui, Seungwhan Moon, Honglei Liu, and Anuj Kumar. 2019. Active Federated Learning. arxiv: 1909.12641Google Scholar"",""Joshua Grass and Shlomo Zilberstein. 1996. Anytime Algorithm Development Tools. ACM SIGART Bulletin, Vol. 7, 2 (Apr 1996), 20--27.Google ScholarDigital Library"",""Xiangnan He, Xiaoyu Du, Xiang Wang, Feng Tian, Jinhui Tang, and Tat-Seng Chua. 2018. Outer Product-based Neural Collaborative Filtering. In Proceedings of the 27th International Joint Conference on Artificial Intelligence, Vol. abs/1808.03912. IJCAI, Stockholm, Sweden, 2227--2233.Google ScholarCross Ref"",""Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural Collaborative Filtering. In Proceedings of the 26th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, International World Wide Web Conferences Steering Committee, Geneva, Switzerland, 173--182.Google ScholarDigital Library"",""Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. 2017. MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications. arxiv: cs.CV/1704.04861Google Scholar"",""Jakub Konecný, H. Brendan McMahan, Felix X. Yu, Peter Richtá rik, Ananda Theertha Suresh, and Dave Bacon. 2016. Federated Learning: Strategies for Improving Communication Efficiency. arxiv: cs.LG/1610.05492Google Scholar"",""Yehuda Koren. 2008. Factorization Meets the Neighborhood: A Multifaceted Collaborative Filtering Model. In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, ACM, New York, USA, 426--434.Google ScholarDigital Library"",""Yehuda Koren, Robert M. Bell, and Chris Volinsky. 2009. Matrix Factorization Techniques for Recommender Systems. IEEE Computer, Vol. 42, 8 (Aug 2009), 30--37.Google ScholarDigital Library"",""Bin Li, Qiang Yang, and Xiangyang Xue. 2009. Transfer Learning for Collaborative Filtering via a Rating-matrix Generative Model. In Proceedings of the 26th Annual International Conference on Machine Learning. ACM, New York, USA, 617--624.Google ScholarDigital Library"",""Nathan N. Liu, Xiangrui Meng, Chao Liu, and Qiang Yang. 2011. Wisdom of the Better Few: Cold Start Recommendation via Representative Based Rating Elicitation. In Proceedings of the Fifth ACM Conference on Recommender Systems. ACM, ACM, New York, USA, 37--44.Google ScholarDigital Library"",""Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Agü era y Arcas. 2017. Communication-Efficient Learning of Deep Networks from Decentralized Data. In Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, Aarti Singh and Xiaojin (Jerry) Zhu (Eds.), Vol. 54. PMLR, Fort Lauderdale, USA, 1273--1282.Google Scholar"",""Milad Nasr, Reza Shokri, and Amir Houmansadr. 2019. Comprehensive Privacy Analysis of Deep Learning: Passive and Active White-box Inference Attacks against Centralized and Federated Learning. 2019 IEEE Symposium on Security and Privacy, Vol. 1, 1 (May 2019), 1--15.Google ScholarCross Ref"",""Weike Pan, Evan Wei Xiang, Nathan Nan Liu, and Qiang Yang. 2010. Transfer Learning in Collaborative Filtering for Sparsity Reduction. In Proceedings of the 24th Conference on Artificial Intelligence. AAAI Press, Atlanta, Georgia, 230--234.Google Scholar"",""Dan Pelleg and Andrew W. Moore. 1999. Accelerating Exact k-means Algorithms with Geometric Reasoning. In Proceedings of the 5th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, New York, USA, 277--281.Google Scholar"",""Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian Personalized Ranking from Implicit Feedback. In Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence. AUAI Press, Montreal, Canada, 452--461.Google ScholarDigital Library"",""Suvash Sedhain, Aditya Krishna Menon, Scott Sanner, and Lexing Xie. 2015. AutoRec: Autoencoders Meet Collaborative Filtering. In Proceedings of the 24th International Conference on World Wide Web. Association for Computing Machinery, New York, USA, 111--112.Google ScholarDigital Library"",""Lei Shi, Wayne Xin Zhao, and Yi-Dong Shen. 2017. Local Representative-Based Matrix Factorization for Cold-Start Recommendation. ACM Transactions on Information Systems, Vol. 36, 2 (2017), 22:1--22:28.Google ScholarDigital Library"",""Bo Zhang, Na Wang, and Hongxia Jin. 2014. Privacy Concerns in Online Recommender Systems: Influences of Control and User Data Input. In 10th Symposium On Usable Privacy and Security (SOUPS 2014). USENIX Association, Menlo Park, CA, 159--173.Google Scholar"",""Shuai Zhang, Lina Yao, Aixin Sun, and Yi Tay. 2019. Deep Learning Based Recommender System: A Survey and New Perspectives. ACM Computing Surveys (CSUR), Vol. 52, 1, Article 5 (Feb 2019), 38 pages.Google ScholarDigital Library"",""Weinan Zhang, Tianqi Chen, Jun Wang, and Yong Yu. 2013. Optimizing top-N Collaborative Filtering via Dynamic Negative Item Sampling. In Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM, New York, USA, 785--788.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403177,AM-GCN: Adaptive Multi-channel Graph Convolutional Networks,"Graph Convolutional Networks (GCNs) have gained great popularity in tackling various analytics tasks on graph and network data. However, some recent studies raise concerns about whether GCNs can optimally integrate node features and topological structures in a complex graph with rich information. In this paper, we first present an experimental investigation. Surprisingly, our experimental results clearly show that the capability of the state-of-the-art GCNs in fusing node features and topological structures is distant from optimal or even satisfactory. The weakness may severely hinder the capability of GCNs in some classification tasks, since GCNs may not be able to adaptively learn some deep correlation information between topological structures and node features. Can we remedy the weakness and design a new type of GCNs that can retain the advantages of the state-of-the-art GCNs and, at the same time, enhance the capability of fusing topological structures and node features substantially? We tackle the challenge and propose an adaptive multi-channel graph convolutional networks for semi-supervised classification (AM-GCN). The central idea is that we extract the specific and common embeddings from node features, topological structures, and their combinations simultaneously, and use the attention mechanism to learn adaptive importance weights of the embeddings. Our extensive experiments on benchmark data sets clearly show that AM-GCN extracts the most correlated information from both node features and topological structures substantially, and improves the classification accuracy with a clear margin.","[{""name"":""Xiao Wang"",""id"":""/profile/99659114057""},{""name"":""Meiqi Zhu"",""id"":""/profile/99659534346""},{""name"":""Deyu Bo"",""id"":""/profile/99659537834""},{""name"":""Peng Cui"",""id"":""/profile/81413596063""},{""name"":""Chuan Shi"",""id"":""/profile/81496666708""},{""name"":""Jian Pei"",""id"":""/profile/81100323054""},{""name"":""Xiao Wang"",""id"":""/profile/99659114057""},{""name"":""Meiqi Zhu"",""id"":""/profile/99659534346""},{""name"":""Deyu Bo"",""id"":""/profile/99659537834""},{""name"":""Peng Cui"",""id"":""/profile/81413596063""},{""name"":""Chuan Shi"",""id"":""/profile/81496666708""},{""name"":""Jian Pei"",""id"":""/profile/81100323054""}]","[""Sami Abu-El-Haija, Bryan Perozzi, Amol Kapoor, Nazanin Alipourfard, Kristina Lerman, Hrayr Harutyunyan, Greg Ver Steeg, and Aram Galstyan. 2019. MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing. In ICML. 21--29.Google Scholar"",""Aleksandar Bojchevski and Stephan Günnemann. 2018. Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking. In ICLR.Google Scholar"",""Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. 2014. Spectral Networks and Locally Connected Networks on Graphs. In ICLR.Google Scholar"",""Jie Chen, Tengfei Ma, and Cao Xiao. 2018. FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling. In ICLR.Google Scholar"",""Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolutional neural networks on graphs with fast localized spectral filtering. In NeurIPS. 3844--3852.Google Scholar"",""Wenqi Fan, Yao Ma, Qing Li, Yuan He, Eric Zhao, Jiliang Tang, and Dawei Yin. 2019. Graph Neural Networks for Social Recommendation. In WWW. 417--426.Google Scholar"",""Hongyang Gao and Shuiwang Ji. 2019. Graph U-Nets. In ICML. 2083--2092.Google Scholar"",""Hongchang Gao, Jian Pei, and Heng Huang. 2019. Conditional Random Field Enhanced Graph Convolutional Neural Networks. In SIGKDD. 276--284.Google Scholar"",""Hongyang Gao, Zhengyang Wang, and Shuiwang Ji. 2018. Large-Scale Learnable Graph Convolutional Networks. In SIGKDD. 1416--1424.Google Scholar"",""Arthur Gretton, Olivier Bousquet, Alex Smola, and Bernhard Schölkopf. 2005. Measuring statistical dependence with hilbert-schmidt norms. In ALT. 63--77.Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In NeurIPS. 1024--1034.Google Scholar"",""Brian Karrer and M. E. J. Newman. 2011. Stochastic blockmodels and community structure in networks. Physical Review E, Vol. 83, 1 (2011), 16107.Google ScholarCross Ref"",""Thomas N. Kipf and Max Welling. 2016. Variational Graph Auto-Encoders. arXiv preprint arXiv:1611.07308.Google Scholar"",""Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In ICLR.Google Scholar"",""Qimai Li, Zhichao Han, and Xiaoming Wu. 2018. Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning. In AAAI. 3538--3545.Google Scholar"",""Jianxin Ma, Peng Cui, Kun Kuang, Xin Wang, and wenwu zhu. 2019 a. Disentangled Graph Convolutional Networks. In ICML. 4212--4221.Google Scholar"",""Yao Ma, Suhang Wang, Charu C. Aggarwal, and Jiliang Tang. 2019 b. Graph Convolutional Networks with EigenPooling. In SIGKDD. 723--731.Google Scholar"",""Zaiqiao Meng, Shangsong Liang, Hongyan Bao, and Xiangliang Zhang. 2019. Co-Embedding Attributed Networks. In WSDM. 393--401.Google Scholar"",""Donglin Niu, Jennifer G. Dy, and Michael I. Jordan. 2010. Multiple Non-Redundant Spectral Clustering Views. In ICML. 831--838.Google Scholar"",""Hoang Nt and Takanori Maehara. 2019. Revisiting Graph Neural Networks: All We Have is Low-Pass Filters. arXiv preprint arXiv:1905.09550 (2019).Google Scholar"",""S.K. Pal and S. Mitra. 1992. Multilayer perceptron, fuzzy sets, and classification. IEEE Transactions on Neural Networks, Vol. 3, 5 (1992), 683--697.Google ScholarDigital Library"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In SIGKDD. 701--710.Google ScholarDigital Library"",""Meng Qu, Yoshua Bengio, and Jian Tang. 2019. GMNN: Graph Markov Neural Networks. In ICML. 5241--5250.Google Scholar"",""Le Song, Alex Smola, Arthur Gretton, Karsten M. Borgwardt, and Justin Bedo. 2007. Supervised feature selection via dependence estimation. In ICML. 823--830.Google Scholar"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. In WWW. 1067--1077.Google ScholarDigital Library"",""Laurens van der Maaten and Geoffrey Hinton. 2008. Visualizing Data using t-SNE. Journal of Machine Learning Research, Vol. 9 (2008), 2579--2605.Google Scholar"",""Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. 2018. Graph Attention Networks. In ICLR.Google Scholar"",""Wenjun Wang, Xiao Liu, Pengfei Jiao, Xue Chen, and Di Jin. 2018. A Unified Weakly Supervised Framework for Community Detection and Semantic Matching. In PAKDD. 218--230.Google Scholar"",""Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, and Philip S Yu. 2019. Heterogeneous Graph Attention Network. In WWW. 2022--2032.Google Scholar"",""Felix Wu, Tianyi Zhang, Amauri Holanda de Souza, Christopher Fifty, Tao Yu, and Kilian Q. Weinberger. 2019. Simplifying Graph Convolutional Networks. In ICML. 6861--6871.Google Scholar"",""Jun Wu, Jingrui He, and Jiejun Xu. 2019 a. Demo-net: Degree-specific graph neural networks for node and graph classification. In SIGKDD. 406--415.Google Scholar"",""Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and Philip S Yu. 2019 b. A comprehensive survey on graph neural networks. arXiv preprint arXiv:1901.00596 (2019).Google Scholar"",""Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2019. How Powerful are Graph Neural Networks. In ICLR.Google Scholar"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L. Hamilton, and Jure Leskovec. 2018. Graph Convolutional Neural Networks for Web-Scale Recommender Systems. In SIGKDD. 974--983.Google Scholar"",""Zhitao Ying, Ines Chami, Christopher Ré, and Jure Leskovec. 2019. Hyperbolic Graph Convolutional Neural Networks. In NeurIPS. 4869--4880.Google Scholar"",""Jiaxuan You, Rex, and Jure Leskovec. 2019. Position-aware Graph Neural Networks. In ICML. 7134--7143.Google Scholar"",""Muhan Zhang, Zhicheng Cui, Marion Neumann, and Chen Yixin. 2018. An End-to-End Deep Learning Architecture for Graph Classification. In AAAI. 4438--4445.Google Scholar"",""Ziwei Zhang, Peng Cui, and Wenwu Zhu. 2018. Deep learning on graphs: A survey. arXiv preprint arXiv:1812.04202 (2018).Google Scholar""]"
https://doi.org/10.1145/3394486.3403178,Discovering Approximate Functional Dependencies using Smoothed Mutual Information,"We consider the task of discovering the top-K reliable approximate functional dependencies X -> Y from high dimensional data. While naively maximizing mutual information involving high dimensional entropies over empirical data is subject to false discoveries, correcting the empirical estimator against data sparsity can lead to efficient exact algorithms for robust dependency discovery. Previous approaches focused on correcting by subtracting expected values of different null hypothesis models. In this paper, we consider a different correction strategy and counter data sparsity using uniform priors and smoothing techniques, that leads to an efficient and robust estimating process. In addition, we derive an admissible and tight bounding function for the smoothed estimator that allows us to efficiently solve via branch-and-bound the hard search problem for the top-K dependencies. Our experiments show that our approach is much faster than previous proposals, and leads to the discovery of sparse and informative functional dependencies.","[{""name"":""Frédéric Pennerath"",""id"":""/profile/81387608706""},{""name"":""Panagiotis Mandros"",""id"":""/profile/99659193035""},{""name"":""Jilles Vreeken"",""id"":""/profile/81335499054""},{""name"":""Frédéric Pennerath"",""id"":""/profile/81387608706""},{""name"":""Panagiotis Mandros"",""id"":""/profile/99659193035""},{""name"":""Jilles Vreeken"",""id"":""/profile/81335499054""}]","[""András Antos and Ioannis Kontoyiannis. 2001. Convergence properties of functional estimates for discrete distributions. Random Struct. Algor., Vol. 19, 3--4 (2001), 163--193.Google ScholarDigital Library"",""Gavin Brown, Adam Pocock, Ming-Jie Zhao, and Mikel Luján. 2012. Conditional Likelihood Maximisation: A Unifying Framework for Information Theoretic Feature Selection. J. Mach. Learn. Res., Vol. 13 (2012), 27--66.Google ScholarDigital Library"",""Thomas M. Cover and Joy A. Thomas. 2006. Elements of Information Theory. Wiley.Google Scholar"",""Luca M Ghiringhelli, Jan Vybiral, Sergey V Levchenko, Claudia Draxl, and Matthias Scheffler. 2015. Big data of materials science: Critical role of the descriptor. Phys. rev. lett., Vol. 114, 10 (2015), 105503.Google Scholar"",""Chris Giannella and Edward L. Robertson. 2004. On approximation measures for functional dependencies. Inform. Syst., Vol. 29, 6 (2004), 483--507.Google ScholarDigital Library"",""Bryan R Goldsmith, Mario Boley, Jilles Vreeken, Matthias Scheffler, and Luca M Ghiringhelli. 2017. Uncovering structure-property relationships of materials by subgroup discovery. New J. Phys., Vol. 19, 1 (2017), 013031.Google ScholarCross Ref"",""Isabelle Guyon and André Elisseeff. 2003. An Introduction to Variable and Feature Selection. J. Mach. Learn. Res., Vol. 3 (2003), 1157--1182.Google ScholarDigital Library"",""Jiawei Han, Jian Pei, Yiwen Yin, and Runying Mao. 2004. Mining Frequent Patterns without Candidate Generation: A Frequent-Pattern Tree Approach. Data Min. Knowl. Discov., Vol. 8, 1 (2004), 53--87.Google ScholarDigital Library"",""Yk\""a Huhtala, Juha K\""arkk\""ainen, Pasi Porkka, and Hannu Toivonen. 1999. TANE: An efficient algorithm for discovering functional and approximate dependencies. Computer J., Vol. 42, 2 (1999), 100--111.Google Scholar"",""Panagiotis Mandros, Mario Boley, and Jilles Vreeken. 2017. Discovering Reliable Approximate Functional Dependencies. In KDD. ACM, 355--363.Google Scholar"",""Panagiotis Mandros, Mario Boley, and Jilles Vreeken. 2018. Discovering Reliable Dependencies from Data: Hardness and Improved Algorithms. In ICDM. IEEE Comuter Society, 317--326.Google Scholar"",""Xuan Vinh Nguyen, Jeffrey Chan, and James Bailey. 2014. Reconsidering Mutual Information Based Feature Selection: A Statistical Significance View. In AAAI. AAAI Press, 2092--2098.Google Scholar"",""Thorsten Papenbrock, Jens Ehrlich, Jannik Marten, Tommy Neubert, Jan-Peer Rudolph, Martin Schönberg, Jakob Zwiener, and Felix Naumann. 2015. Functional dependency discovery: An experimental evaluation of seven algorithms. VLDB J., Vol. 8, 10 (2015), 1082--1093.Google ScholarDigital Library"",""Fré dé ric Pennerath. 2018. An Efficient Algorithm for Computing Entropic Measures of Feature Subsets. In ECML-PKDD (LNCS), Vol. 11052. Springer, 483--499.Google Scholar"",""Simone Romano, Nguyen Xuan Vinh, James Bailey, and Karin Verspoor. 2016. A Framework to Adjust Dependency Measure Estimates for Chance. In SDM. SIAM, 423--431.Google Scholar"",""Mark S Roulston. 1999. Estimating the errors on measured entropy and mutual information. Physica D, Vol. 125, 3 (1999), 285--294.Google ScholarDigital Library"",""Steffen Schober. 2013. Some worst-case bounds for Bayesian estimators of discrete distributions. In ISIT. IEEE, 2194--2198.Google Scholar"",""Thomas Schürmann and Peter Grassberger. 1996. Entropy estimation of symbol sequences. Chaos, Vol. 6, 3 (1996), 414--427.Google ScholarCross Ref"",""Joe Suzuki. 1993. A construction of Bayesian networks from databases based on an MDL principle. In UAI. Morgan Kaufmann, 266--273.Google Scholar"",""Joe Suzuki. 2019. Mutual Information Estimation: Independence Detection and Consistency. In ISIT. IEEE, 2514--2518.Google Scholar"",""Ioannis Tsamardinos, Constantin Aliferis, Alexander Statnikov, and Er Statnikov. 2003. Algorithms for Large Scale Markov Blanket Discovery. In FLAIRS. AAAI Press, 376--380.Google Scholar""]"
https://doi.org/10.1145/3394486.3403179,Competitive Analysis for Points of Interest,"The competitive relationship of Points of Interest (POIs) refers to the degree of competition between two POIs for business opportunities from third parties in an urban area. Existing studies for competitive analysis usually focus on mining competitive relationships of entities, such as companies or products, from textual data. However, there are few studies which have a focus on competitive analysis for POIs. Indeed, the growing availability of user behavior data about POIs, such as POI reviews and human mobility data, enables a new paradigm for understanding the competitive relationships among POIs. To this end, in this paper, we study how to predict the POI competitive relationship. Along this line, a very first challenge is how to integrate heterogeneous user behavior data with the spatial features of POIs. As a solution, we first build a heterogeneous POI information network (HPIN) from POI reviews and map search data. Then, we develop a graph neural network-based deep learning framework, named DeepR, for POI competitive relationship prediction based on HPIN. Specifically, DeepR contains two components: a spatial adaptive graph neural network (SA-GNN) and a POI pairwise knowledge extraction learning (PKE) model. The SA-GNN is a novel GNN architecture with incorporating POI's spatial information and location distribution by a specially designed spatial oriented aggregation layer and spatial-dependency attentive propagation mechanism. In addition, PKE is devised to distill the POI pairwise knowledge in HPIN being useful for relationship prediction into condensate vectors with relational graph convolution and cross attention. Finally, extensive experiments on two real-world datasets demonstrate the effectiveness of our method.","[{""name"":""Shuangli Li"",""id"":""/profile/99659564918""},{""name"":""Jingbo Zhou"",""id"":""/profile/99659520172""},{""name"":""Tong Xu"",""id"":""/profile/81550320556""},{""name"":""Hao Liu"",""id"":""/profile/99659566196""},{""name"":""Xinjiang Lu"",""id"":""/profile/84459957757""},{""name"":""Hui Xiong"",""id"":""/profile/81451596433""},{""name"":""Shuangli Li"",""id"":""/profile/99659564918""},{""name"":""Jingbo Zhou"",""id"":""/profile/99659520172""},{""name"":""Tong Xu"",""id"":""/profile/81550320556""},{""name"":""Hao Liu"",""id"":""/profile/99659566196""},{""name"":""Xinjiang Lu"",""id"":""/profile/84459957757""},{""name"":""Hui Xiong"",""id"":""/profile/81451596433""}]","[""Tianqi Chen and Carlos Guestrin. 2016. Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining. ACM, 785--794.Google ScholarDigital Library"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 855--864.Google ScholarDigital Library"",""Mahdi Jalili, Yasin Orouskhani, Milad Asgari, Nazanin Alipourfard, and Matjavz Perc. 2017. Link prediction in multiplex online social networks. Royal Society open science, Vol. 4, 2 (2017), 160863.Google Scholar"",""Nitin Jindal and Bing Liu. 2006. Identifying comparative sentences in text documents. In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval. ACM, 244--251.Google ScholarDigital Library"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).Google Scholar"",""Rui Li, Shenghua Bao, Jin Wang, Yong Yu, and Yunbo Cao. 2006. Cominer: An effective algorithm for mining competitors from the web. In Sixth International Conference on Data Mining (ICDM'06). IEEE, 948--952.Google ScholarDigital Library"",""David Liben-Nowell and Jon Kleinberg. 2007. The link-prediction problem for social networks. Journal of the American society for information science and technology, Vol. 58, 7 (2007), 1019--1031.Google ScholarDigital Library"",""Hao Liu, Ting Li, Renjun Hu, Yanjie Fu, Jingjing Gu, and Hui Xiong. 2019 a. Joint Representation Learning for Multi-Modal Transportation Recommendation. In Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence. 1036--1043.Google ScholarCross Ref"",""Hao Liu, Yongxin Tong, Panpan Zhang, Xinjiang Lu, Jianguo Duan, and Hui Xiong. 2019 b. Hydra: A Personalized and Context-Aware Multi-Modal Transportation Recommendation System. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 2314--2324.Google ScholarDigital Library"",""Weiping Liu and Linyuan Lü. 2010. Link prediction based on local random walk. EPL (Europhysics Letters), Vol. 89, 5 (2010), 58007.Google ScholarCross Ref"",""Zhongming Ma, Gautam Pant, and Olivia RL Sheng. 2011. Mining competitor relationships from online news: A network-based approach. Electronic Commerce Research and Applications, Vol. 10, 4 (2011), 418--427.Google ScholarDigital Library"",""Xing Niu, Xinruo Sun, Haofen Wang, Shu Rong, Guilin Qi, and Yong Yu. 2011. Zhishi. me-weaving chinese linking open data. In International Semantic Web Conference. Springer, 205--220.Google Scholar"",""Hongbin Pei, Bingzhe Wei, Kevin Chen-Chuan Chang, Yu Lei, and Bo Yang. 2020. Geom-GCN: Geometric Graph Convolutional Networks. In International Conference on Learning Representations (ICLR).Google Scholar"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 701--710.Google ScholarDigital Library"",""Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den Berg, Ivan Titov, and Max Welling. 2018. Modeling relational data with graph convolutional networks. In European Semantic Web Conference. Springer, 593--607.Google ScholarCross Ref"",""George Valkanas, Theodoros Lappas, and Dimitrios Gunopulos. 2017. Mining Competitors from Large Unstructured Datasets. IEEE Transactions on Knowledge and Data Engineering, Vol. 29, 9 (2017), 1971--1984.Google ScholarCross Ref"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph attention networks. arXiv preprint arXiv:1710.10903 (2017).Google Scholar"",""Hao Wang, Tong Xu, Qi Liu, Defu Lian, Enhong Chen, Dongfang Du, Han Wu, and Wen Su. 2019 b. MCNE: An End-to-End Framework for Learning Multiple Conditional Network Representations of Social Network. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1064--1072.Google ScholarDigital Library"",""Hongwei Wang, Fuzheng Zhang, Min Hou, Xing Xie, Minyi Guo, and Qi Liu. 2018. Shine: Signed heterogeneous information network embedding for sentiment link prediction. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. ACM, 592--600.Google ScholarDigital Library"",""Peng Wang, BaoWen Xu, YuRong Wu, and XiaoYu Zhou. 2015. Link prediction in social networks: the state-of-the-art. Science China Information Sciences, Vol. 58, 1 (2015), 1--38.Google Scholar"",""Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, and Philip S Yu. 2019 a. Heterogeneous Graph Attention Network. In The World Wide Web Conference. ACM, 2022--2032.Google Scholar"",""Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and Philip S Yu. 2019. A comprehensive survey on graph neural networks. arXiv preprint arXiv:1901.00596 (2019).Google Scholar"",""Jin Xu, Jingbo Zhou, Yongpo Jia, Jian Li, and Xiong Hui. 2020. An Adaptive Master-Slave Regularized Model for Unexpected Revenue Prediction Enhanced with Alternative Data. In IEEE 36th International Conference on Data Engineering. IEEE, 601--612.Google Scholar"",""Kaiquan Xu, Stephen Shaoyi Liao, Jiexun Li, and Yuxia Song. 2011. Mining comparative opinions from customer reviews for competitive intelligence. Decision support systems, Vol. 50, 4 (2011), 743--754.Google Scholar"",""Yang Yang, Jie Tang, Jacklyne Keomany, Yanting Zhao, Juanzi Li, Ying Ding, Tian Li, and Liangwei Wang. 2012. Mining competitive relationships by learning across heterogeneous networks. In Proceedings of the 21st ACM international conference on Information and knowledge management. ACM, 1432--1441.Google ScholarDigital Library"",""Liang Yao, Chengsheng Mao, and Yuan Luo. 2019. Graph convolutional networks for text classification. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 7370--7377.Google ScholarCross Ref"",""Zikai Yin, Tong Xu, Hengshu Zhu, Chen Zhu, Enhong Chen, and Hui Xiong. 2019. Matching of social events and users: a two-way selection perspective. World Wide Web (2019), 1--19.Google Scholar"",""Le Zhang, Tong Xu, Hengshu Zhu, Chuan Qin, Qingxin Meng, Hui Xiong, and Enhong Chen. 2020 b. Large-Scale Talent Flow Embedding for Company Competitive Analysis. In Proceedings of The Web Conference 2020. 2354--2364.Google ScholarDigital Library"",""Muhan Zhang and Yixin Chen. 2018. Link prediction based on graph neural networks. In Advances in Neural Information Processing Systems. 5165--5175.Google Scholar"",""Weijia Zhang, Hao Liu, Yanchi Liu, Jingbo Zhou, and Hui Xiong. 2020 a. Semi-Supervised Hierarchical Recurrent Graph Neural Network for City-Wide Parking Availability Prediction.Google Scholar"",""Jingbo Zhou, Shan Gou, Renjun Hu, Dongxiang Zhang, Jin Xu, Airong Jiang, Ying Li, and Hui Xiong. 2019. A Collaborative Learning Framework to Tag Refinement for Points of Interest. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1752--1761.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403180,HOPS: Probabilistic Subtree Mining for Small and Large Graphs,"Frequent subgraph mining, i.e., the identification of relevant patterns in graph databases, is a well-known data mining problem with high practical relevance, since next to summarizing the data, the resulting patterns can also be used to define powerful domain-specific similarity functions for prediction. In recent years, significant progress has been made towards subgraph mining algorithms that scale to complex graphs by focusing on tree patterns and probabilistically allowing a small amount of incompleteness in the result. Nonetheless, the complexity of the pattern matching component used for deciding subtree isomorphism on arbitrary graphs has significantly limited the scalability of existing approaches. In this paper, we adapt sampling techniques from mathematical combinatorics to the problem of probabilistic subtree mining in arbitrary databases of many small to medium-size graphs or a single large graph. By restricting on tree patterns, we provide an algorithm that approximately counts or decides subtree isomorphism for arbitrary transaction graphs in sub-linear time with one-sided error. Our empirical evaluation on a range of benchmark graph datasets shows that the novel algorithm substantially outperforms state-of-the-art approaches both in the task of approximate counting of embeddings in single large graphs and in probabilistic frequent subtree mining in large databases of small to medium sized graphs.","[{""name"":""Pascal Welke"",""id"":""/profile/99659041597""},{""name"":""Florian Seiffarth"",""id"":""/profile/99659573609""},{""name"":""Michael Kamp"",""id"":""/profile/87258911757""},{""name"":""Stefan Wrobel"",""id"":""/profile/81100099179""},{""name"":""Pascal Welke"",""id"":""/profile/99659041597""},{""name"":""Florian Seiffarth"",""id"":""/profile/99659573609""},{""name"":""Michael Kamp"",""id"":""/profile/87258911757""},{""name"":""Stefan Wrobel"",""id"":""/profile/81100099179""}]","[""Marco Bressan, Stefano Leucci, and Alessandro Panconesi. 2019. Motivo: Fast Motif Counting via Succinct Color Coding and Adaptive Sampling. PVLDB, Vol. 12, 11 (2019), 1651--1663. https://doi.org/10.14778/3342263.3342640Google ScholarDigital Library"",""Mukund Deshpande, Michihiro Kuramochi, Nikil Wale, and George Karypis. 2005. Frequent substructure-based approaches for classifying chemical compounds. Transactions on Knowledge and Data Engineering, Vol. 17, 8 (Aug. 2005), 1036--1050. https://doi.org/10.1109/tkde.2005.127Google ScholarDigital Library"",""Martin Fü rer and Shiva Prasad Kasiviswanathan. 2014. Approximately Counting Embeddings into Random Graphs. Combinatorics, Probability \u0026 Computing, Vol. 23, 6 (2014), 1028--1056. https://doi.org/10.1017/S0963548314000339Google ScholarCross Ref"",""Michael R. Garey and David S. Johnson. 1979. Computers and Intractability: A Guide to the Theory of NP-Completeness. W. H. Freeman.Google Scholar"",""Jiawei Han, Hong Cheng, Dong Xin, and Xifeng Yan. 2007. Frequent pattern mining: current status and future directions. Data Mining and Knowledge Discovery, Vol. 15, 1 (2007), 55--86. https://doi.org/10.1007/s10618-006-0059--1Google ScholarDigital Library"",""Tamás Horváth and Jan Ramon. 2010. Efficient frequent connected subgraph mining in graphs of bounded tree-width. Theoretical Computer Science, Vol. 411, 31--33 (2010), 2784--2797. https://doi.org/10.1016/j.tcs.2010.03.030Google ScholarDigital Library"",""Mark Jerrum, Alistair Sinclair, and Eric Vigoda. 2004. A polynomial-time approximation algorithm for the permanent of a matrix with nonnegative entries. J. ACM, Vol. 51, 4 (2004), 671--697. https://doi.org/10.1145/1008731.1008738Google ScholarDigital Library"",""Ashraf M. Kibriya and Jan Ramon. 2013. Nearly exact mining of frequent trees in large networks. Data Mining and Knowledge Discovery, Vol. 27, 3 (2013), 478--504. https://doi.org/10.1007/s10618-013-0321--2Google ScholarCross Ref"",""Donald E. Knuth. 1998. The art of computer programming, volume 2: (2nd ed.) seminumerical algorithms .Addison Wesley Longman Publishing Co., Inc., Redwood City, CA, USA.Google Scholar"",""Ioannis Koutis and Ryan Williams. 2009. Limits and Applications of Group Algebras for Parameterized Problems. In International Colloquium on Automata, Languages and Programming (ICALP) Proceedings, Part I (Lecture Notes in Computer Science, Vol. 5555). Springer, 653--664. https://doi.org/10.1007/978--3--642-02927--1_54Google Scholar"",""Jure Leskovec and Andrej Krevl. 2014. SNAP Datasets: Stanford Large Network Dataset Collection. http://snap.stanford.edu/data .Google Scholar"",""Jure Leskovec and Rok Sosivc. 2016. SNAP: A General-Purpose Network Analysis and Graph-Mining Library. ACM Transactions on Intelligent Systems and Technology (TIST), Vol. 8, 1 (2016), 1.Google ScholarDigital Library"",""Kirill Paramonov, Dmitry Shemetov, and James Sharpnack. 2019. Estimating Graphlet Statistics via Lifting. In ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining, (KDD) Proceedings. ACM, 587--595. https://doi.org/10.1145/3292500.3330995Google ScholarDigital Library"",""Irma Ravkic, Martin vZ nidarvs ivc, Jan Ramon, and Jesse Davis. 2018. Graph sampling with applications to estimating the number of pattern embeddings and the parameters of a statistical relational model. Data Mining and Knowledge Discovery, Vol. 32, 4 (2018), 913--948. https://doi.org/10.1007/s10618-018-0553--2Google ScholarDigital Library"",""Pedro Ribeiro, Pedro Paredes, Miguel E. P. Silva, David Aparicio, and Fernando Silva. 2019. A Survey on Subgraph Counting: Concepts, Algorithms and Applications to Network Motifs and Graphlets. CoRR, Vol. abs/1910.13011 (2019), 1--35. arxiv: 1910.13011 http://arxiv.org/abs/1910.13011Google Scholar"",""Till Hendrik Schulz, Tamá s Horvá th, Pascal Welke, and Stefan Wrobel. 2018. Mining Tree Patterns with Partially Injective Homomorphisms. In European Conference on Machine Learning and Knowledge Discovery in Databases ECML PKDD Proceedings, Part II (Lecture Notes in Computer Science, Vol. 11052). Springer, 585--601. https://doi.org/10.1007/978--3-030--10928--8_35Google Scholar"",""Julian R. Ullmann. 1976. An Algorithm for Subgraph Isomorphism. J. ACM, Vol. 23, 1 (Jan. 1976), 31--42. https://doi.org/10.1145/321921.321925Google ScholarDigital Library"",""Takeaki Uno. 1997. Algorithms for Enumerating All Perfect, Maximum and Maximal Matchings in Bipartite Graphs. In International Symposium on Algorithms and Computation (ISAAC) Proceedings (Lecture Notes in Computer Science, Vol. 1350). Springer, 92--101. https://doi.org/10.1007/3--540--63890--3_11Google Scholar"",""Pascal Welke, Tamás Horváth, and Stefan Wrobel. 2018. Probabilistic Frequent Subtrees for Efficient Graph Classification and Retrieval. Machine Learning, Vol. 107, 11 (2018), 1847--1873. https://doi.org/10.1007/s10994-017--5688--7Google ScholarDigital Library"",""Pascal Welke, Tamás Horváth, and Stefan Wrobel. 2019. Probabilistic and Exact Frequent Subtree Mining in Graphs Beyond Forests. Machine Learning, Vol. 108, 7 (2019), 1137--1164. https://doi.org/10.1007/s10994-019-05779--1Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403181,The NodeHopper: Enabling Low Latency Ranking with Constraints via a Fast Dual Solver,"Modern recommender systems need to deal with multiple objectives like balancing user engagement with recommending diverse and fresh content. An appealing way to optimally trade these off is by imposing constraints on the ranking according to which items are presented to a user. This results in a constrained ranking optimization problem that can be solved as a linear program (LP). However, off-the-shelf LP solvers are unable to meet the severe latency constraints in systems that serve live traffic. To address this challenge, we exploit the structure of the dual optimization problem to develop a fast solver. We analyze theoretical properties of our solver and show experimentally that it is able to solve constrained ranking problems on synthetic and real-world recommendation datasets an order of magnitude faster than off-the-shelf solvers, thereby enabling their deployment under severe latency constraints.","[{""name"":""Anton Zhernov"",""id"":""/profile/99659574865""},{""name"":""Krishnamurthy Dj Dvijotham"",""id"":""/profile/81384619037""},{""name"":""Ivan Lobov"",""id"":""/profile/99659573457""},{""name"":""Dan A. Calian"",""id"":""/profile/99659574948""},{""name"":""Michelle Gong"",""id"":""/profile/99659573937""},{""name"":""Natarajan Chandrashekar"",""id"":""/profile/99659574863""},{""name"":""Timothy A. Mann"",""id"":""/profile/99659574436""},{""name"":""Anton Zhernov"",""id"":""/profile/99659574865""},{""name"":""Krishnamurthy Dj Dvijotham"",""id"":""/profile/81384619037""},{""name"":""Ivan Lobov"",""id"":""/profile/99659573457""},{""name"":""Dan A. Calian"",""id"":""/profile/99659574948""},{""name"":""Michelle Gong"",""id"":""/profile/99659573937""},{""name"":""Natarajan Chandrashekar"",""id"":""/profile/99659574863""},{""name"":""Timothy A. Mann"",""id"":""/profile/99659574436""}]","[""Deepak Agarwal, Shaunak Chatterjee, Yang Yang, and Liang Zhang. 2015. Constrained Optimization for Homepage Relevance. In Proceedings of the 24th International Conference on World Wide Web (Florence, Italy) (WWW 2015 Companion). Association for Computing Machinery, New York, NY, USA, 375 ­- 384. https://doi.org/10.1145/2740908.2745398Google ScholarDigital Library"",""Deepak Agarwal, Bee-Chung Chen, Pradheep Elango, and Xuanhui Wang. 2011. Click Shaping to Optimize Multiple Objectives. In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (San Diego, California, USA) (KDD 2011). Association for Computing Machinery, New York, NY, USA, 132--140. https://doi.org/10.1145/2020408.2020435Google ScholarDigital Library"",""Erling D. Anderson, Jacek Gondzio, Csaba Mészáros, and Xiaojie Xu. 1996. Implementation of Interior-Point Methods for Large Scale Linear Programs .Springer US, Boston, MA, 189--252. https://doi.org/10.1007/978--1--4613--3449--1_6Google Scholar"",""Asia J. Biega, Krishna P. Gummadi, and Gerhard Weikum. 2018. Equity of Attention: Amortizing Individual Fairness in Rankings. In The 41st International ACM SIGIR Conference on Research \u0026 Development in Information Retrieval (Ann Arbor, MI, USA) (SIGIR '18). Association for Computing Machinery, New York, NY, USA, 405--414. https://doi.org/10.1145/3209978.3210063Google ScholarDigital Library"",""Stephen Boyd and Lieven Vandenberghe. 2004. Convex Optimization .Cambridge University Press, USA.Google Scholar"",""Chris Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds, Nicole Hamilton, and Greg Hullender. 2005. Learning to Rank Using Gradient Descent. In Proceedings of the 22nd International Conference on Machine Learning (Bonn, Germany) (ICML '05). Association for Computing Machinery, New York, NY, USA, 89----96. https://doi.org/10.1145/1102351.1102363Google ScholarDigital Library"",""L. Elisa Celis, Damian Straszak, and Nisheeth K. Vishnoi. 2018. Ranking with Fairness Constraints. In 45th International Colloquium on Automata, Languages, and Programming (ICALP 2018) (Leibniz International Proceedings in Informatics (LIPIcs), Vol. 107), Ioannis Chatzigiannakis, Christos Kaklamanis, Dániel Marx, and Donald Sannella (Eds.). Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik, Dagstuhl, Germany, 28:1--28:15. https://doi.org/10.4230/LIPIcs.ICALP.2018.28Google Scholar"",""Nick Craswell, Onno Zoeter, Michael Taylor, and Bill Ramsey. 2008. An Experimental Comparison of Click Position-Bias Models. In Proceedings of the 2008 International Conference on Web Search and Data Mining (Palo Alto, California, USA) (WSDM 2008). Association for Computing Machinery, New York, NY, USA, 87--94. https://doi.org/10.1145/1341531.1341545Google ScholarDigital Library"",""Scott Deerwester, Susan T Dumais, George W Furnas, Thomas K Landauer, and Richard Harshman. 1990. Indexing by latent semantic analysis. Journal of the American society for information science, Vol. 41, 6 (1990), 391--407.Google ScholarCross Ref"",""Weicong Ding, Dinesh Govindaraj, and S V N Vishwanathan. 2019. Whole Page Optimization with Global Constraints. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining (Anchorage, AK, USA) (KDD 2019). Association for Computing Machinery, New York, NY, USA, 3153--3161. https://doi.org/10.1145/3292500.3330675Google ScholarDigital Library"",""Iain S Duff and Jacko Koster. 2001. On algorithms for permuting large entries to the diagonal of a sparse matrix. SIAM J. Matrix Anal. Appl., Vol. 22, 4 (2001), 973--996.Google ScholarDigital Library"",""Fanny Dufossé and Bora Ucc ar. 2016. Notes on Birkhoff--von Neumann decomposition of doubly stochastic matrices. Linear Algebra Appl., Vol. 497 (2016), 108--115.Google ScholarCross Ref"",""Lester Randolph Ford Jr and Delbert R Fulkerson. 1958. A suggested computation for maximal multi-commodity network flows. Management Science, Vol. 5, 1 (1958), 97--101.Google ScholarDigital Library"",""Dietmar Jannach, Paul Resnick, Alexander Tuzhilin, and Markus Zanker. 2016. Recommender Systems - beyond Matrix Completion. Commun. ACM, Vol. 59, 11 (Oct. 2016), 94--102. https://doi.org/10.1145/2891406Google Scholar"",""Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schütze. 2008. Introduction to Information Retrieval .Cambridge University Press, USA.Google Scholar"",""Robert B. Miller. 1968. Response Time in Man-Computer Conversational Transactions. In Proceedings of the December 9--11, 1968, Fall Joint Computer Conference, Part I (San Francisco, California) (AFIPS 1968 (Fall, part I)). Association for Computing Machinery, New York, NY, USA, 267--277. https://doi.org/10.1145/1476589.1476628Google Scholar"",""Filip Radlinski, Robert Kleinberg, and Thorsten Joachims. 2008. Learning Diverse Rankings with Multi-Armed Bandits. In Proceedings of the 25th International Conference on Machine Learning (Helsinki, Finland) (ICML 2008). Association for Computing Machinery, New York, NY, USA, 784--791. https://doi.org/10.1145/1390156.1390255Google ScholarDigital Library"",""Parikshit Shah, Akshay Soni, and Troy Chevalier. 2017. Online Ranking with Constraints: A Primal-Dual Algorithm and Applications to Web Traffic-Shaping. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (Halifax, NS, Canada) (KDD 2017). Association for Computing Machinery, New York, NY, USA, 405--414. https://doi.org/10.1145/3097983.3098025Google ScholarDigital Library"",""Ashudeep Singh and Thorsten Joachims. 2018. Fairness of Exposure in Rankings. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining (London, United Kingdom) (KDD 2018). Association for Computing Machinery, New York, NY, USA, 2219--2228. https://doi.org/10.1145/3219819.3220088Google ScholarDigital Library"",""Jaehyun Park Stephen Boyd. 2014. Lecture note on subgradient methods. Stanford university. https://web.stanford.edu/class/ee364b/lectures/subgrad_method_notes.pdfGoogle Scholar"",""Masrour Zoghi, Tomas Tunys, Mohammad Ghavamzadeh, Branislav Kveton, Csaba Szepesvari, and Zheng Wen. 2017. Online Learning to Rank in Stochastic Click Models. In Proceedings of the 34th International Conference on Machine Learning - Volume 70 (ICML'17). JMLR.org, Sydney, NSW, Australia, 4199--4208.Google Scholar""]"
https://doi.org/10.1145/3394486.3403182,HGMF: Heterogeneous Graph-based Fusion for Multimodal Data with Incompleteness,"With the advances in data collection techniques, large amounts of multimodal data collected from multiple sources are becoming available. Such multimodal data can provide complementary information that can reveal fundamental characteristics of real-world subjects. Thus, multimodal machine learning has become an active research area. Extensive works have been developed to exploit multimodal interactions and integrate multi-source information. However, multimodal data in the real world usually comes with missing modalities due to various reasons, such as sensor damage, data corruption, and human mistakes in recording. Effectively integrating and analyzing multimodal data with incompleteness remains a challenging problem. We propose a Heterogeneous Graph-based Multimodal Fusion (HGMF) approach to enable multimodal fusion of incomplete data within a heterogeneous graph structure. The proposed approach develops a unique strategy for learning on incomplete multimodal data without data deletion or data imputation. More specifically, we construct a heterogeneous hypernode graph to model the multimodal data having different combinations of missing modalities, and then we formulate a graph neural network based transductive learning framework to project the heterogeneous incomplete data onto a unified embedding space, and multi-modalities are fused along the way. The learning framework captures modality interactions from available data, and leverages the relationships between different incompleteness patterns. Our experimental results demonstrate that the proposed method outperforms existing graph-based as well as non-graph based baselines on three different datasets.","[{""name"":""Jiayi Chen"",""id"":""/profile/99659573476""},{""name"":""Aidong Zhang"",""id"":""/profile/99659573207""},{""name"":""Jiayi Chen"",""id"":""/profile/99659573476""},{""name"":""Aidong Zhang"",""id"":""/profile/99659573207""}]","[""Carlos Busso, Murtaza Bulut, Chi-Chun Lee, Abe Kazemzadeh, Emily Mower, Samuel Kim, Jeannette N Chang, Sungbok Lee, and Shrikanth S Narayanan. 2008. IEMOCAP: Interactive emotional dyadic motion capture database. Language resources and evaluation, Vol. 42, 4 (2008), 335.Google Scholar"",""Lei Cai, Zhengyang Wang, Hongyang Gao, Dinggang Shen, and Shuiwang Ji. 2018. Deep adversarial learning for multi-modality missing data completion. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM.Google ScholarDigital Library"",""Ding-Yun Chen, Xiao-Pei Tian, Yu-Te Shen, and Ming Ouhyoung. 2003. On visual similarity based 3D model retrieval. In Computer graphics forum, Vol. 22. Wiley Online Library, 223--232.Google Scholar"",""Gilles Degottex, John Kane, Thomas Drugman, Tuomo Raitio, and Stefan Scherer. 2014. COVAREP-A collaborative voice analysis repository for speech technologies. In 2014 ieee international conference on acoustics, speech and signal processing (icassp). IEEE, 960--964.Google Scholar"",""Zhengming Ding, Handong Zhao, and Yun Fu. 2018. Learning representation for multi-view data analysis: models and applications. Springer.Google Scholar"",""Yifan Feng, Haoxuan You, Zizhao Zhang, Rongrong Ji, and Yue Gao. 2019. Hypergraph neural networks. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 3558--3565.Google ScholarCross Ref"",""Yifan Feng, Zizhao Zhang, Xibin Zhao, Rongrong Ji, and Yue Gao. 2018. GVCNN: Group-view convolutional neural networks for 3D shape recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 264--272.Google ScholarCross Ref"",""iMotions. [n.d.]. Facial expression analysis.Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).Google Scholar"",""Dana Lahat, Tü lay Adali, and Christian Jutten. 2015. Multimodal Data Fusion: An Overview of Methods, Challenges, and Prospects. Proc. IEEE, Vol. 103, 9 (2015), 1449--1477. https://doi.org/10.1109/JPROC.2015.2460697Google Scholar"",""Yan Li, Tao Yang, Jiayu Zhou, and Jieping Ye. 2018. Multi-Task Learning based Survival Analysis for Predicting Alzheimer's Disease Progression with Multi-Source Block-wise Missing Data. In SDM. 288--296.Google Scholar"",""Mingxia Liu, Yue Gao, Pew-Thian Yap, and Dinggang Shen. 2017. Multi-Hypergraph Learning for Incomplete Multimodality Data. IEEE journal of biomedical and health informatics, Vol. 22, 4 (2017), 1197--1208.Google Scholar"",""Zhun Liu, Ying Shen, Varun Bharadhwaj Lakshminarasimhan, Paul Pu Liang, AmirAli Bagher Zadeh, and Louis-Philippe Morency. 2018. Efficient Low-rank Multimodal Fusion With Modality-Specific Factors. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2247--2256.Google ScholarCross Ref"",""Jeffrey Pennington, Richard Socher, and Christopher Manning. 2014. Glove: Global vectors for word representation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP). 1532--1543.Google ScholarCross Ref"",""Verónica Pérez-Rosas, Rada Mihalcea, and Louis-Philippe Morency. 2013. Utterance-level multimodal sentiment analysis. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 973--982.Google Scholar"",""Soujanya Poria, Iti Chaturvedi, Erik Cambria, and Amir Hussain. 2016. Convolutional MKL based multimodal emotion recognition and sentiment analysis. In 2016 IEEE 16th international conference on data mining (ICDM). IEEE, 439--448.Google ScholarCross Ref"",""Chao Shang, Aaron Palmer, Jiangwen Sun, Ko-Shin Chen, Jin Lu, and Jinbo Bi. 2017. VIGAN: Missing view imputation with generative adversarial networks. In Big Data (Big Data), 2017 IEEE International Conference on. IEEE.Google ScholarCross Ref"",""Hang Su, Subhransu Maji, Evangelos Kalogerakis, and Erik Learned-Miller. 2015. Multi-view convolutional neural networks for 3d shape recognition. In Proceedings of the IEEE international conference on computer vision. 945--953.Google ScholarDigital Library"",""Qiuling Suo, Weida Zhong, Fenglong Ma, Ye Yuan, Jing Gao, and Aidong Zhang. 2019. Metric learning on healthcare data with incomplete modalities. In Proceedings of the 28th International Joint Conference on Artificial Intelligence. AAAI Press, 3534--3540.Google ScholarCross Ref"",""Luan Tran, Xiaoming Liu, Jiayu Zhou, and Rong Jin. 2017. Missing modalities imputation via cascaded residual autoencoder. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 1405--1414.Google ScholarCross Ref"",""Yao-Hung Hubert Tsai, Paul Pu Liang, Amir Zadeh, Louis-Philippe Morency, and Ruslan Salakhutdinov. 2018. Learning factorized multimodal representations. arXiv preprint arXiv:1806.06176 (2018).Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998--6008.Google Scholar"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2018. Graph attention networks. In Proceedings of the 7th International Conference on Learning Representations.Google Scholar"",""Haohan Wang, Aaksha Meghawat, Louis-Philippe Morency, and Eric P Xing. 2017. Select-additive learning: Improving generalization in multimodal sentiment analysis. In 2017 IEEE International Conference on Multimedia and Expo (ICME). IEEE, 949--954.Google ScholarCross Ref"",""Qianqian Wang, Zhengming Ding, Zhiqiang Tao, Quanxue Gao, and Yun Fu. 2018. Partial Multi-view Clustering via Consistent GAN. In 2018 IEEE International Conference on Data Mining (ICDM). IEEE.Google ScholarCross Ref"",""Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, and Philip S Yu. 2019. Heterogeneous Graph Attention Network. In The World Wide Web Conference. ACM, 2022--2032.Google Scholar"",""Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, and Jianxiong Xiao. 2015. 3d shapenets: A deep representation for volumetric shapes. In Proceedings of the IEEE conference on computer vision and pattern recognition. 1912--1920.Google Scholar"",""Shuo Xiang, Lei Yuan, Wei Fan, Yalin Wang, Paul M Thompson, and Jieping Ye. 2013. Multi-source learning with block-wise missing data for Alzheimer's disease prediction. In Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 185--193.Google ScholarDigital Library"",""Lei Yuan, Yalin Wang, Paul M Thompson, Vaibhav A Narayan, Jieping Ye, Alzheimer's Disease Neuroimaging Initiative, et al. 2012. Multi-source feature learning for joint analysis of incomplete multiple heterogeneous neuroimaging data. NeuroImage, Vol. 61, 3 (2012), 622--632.Google ScholarCross Ref"",""Amir Zadeh, Minghai Chen, Soujanya Poria, Erik Cambria, and Louis-Philippe Morency. 2017. Tensor Fusion Network for Multimodal Sentiment Analysis. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. 1103--1114.Google ScholarCross Ref"",""Amir Zadeh, Paul Pu Liang, Navonil Mazumder, Soujanya Poria, Erik Cambria, and Louis-Philippe Morency. 2018a. Memory fusion network for multi-view sequential learning. In Thirty-Second AAAI Conference on Artificial Intelligence.Google Scholar"",""Amir Zadeh, Paul Pu Liang, Soujanya Poria, Prateek Vij, Erik Cambria, and Louis-Philippe Morency. 2018b. Multi-attention recurrent network for human communication comprehension. In Thirty-Second AAAI Conference on Artificial Intelligence. https://github.com/A2Zadeh/Carnegie Mellon University-MultimodalSDKGoogle Scholar"",""Amir Zadeh, Rowan Zellers, Eli Pincus, and Louis-Philippe Morency. 2016. Mosi: multimodal corpus of sentiment intensity and subjectivity analysis in online opinion videos. arXiv preprint arXiv:1606.06259 (2016).Google Scholar"",""Chuxu Zhang, Dongjin Song, Chao Huang, Ananthram Swami, and Nitesh V Chawla. 2019. Heterogeneous Graph Neural Network. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 793--803.Google ScholarDigital Library"",""Lei Zhang, Yao Zhao, Zhenfeng Zhu, Dinggang Shen, and Shuiwang Ji. 2018. Multi-view missing data completion. IEEE Transactions on Knowledge and Data Engineering, Vol. 30, 7 (2018), 1296--1309.Google ScholarCross Ref"",""Ziyuan Zhao, Huiying Zhu, Zehao Xue, Zhao Liu, Jing Tian, Matthew Chin Heng Chua, and Maofu Liu. 2019. An image-text consistency driven multimodal sentiment analysis approach for social media. Information Processing \u0026 Management, Vol. 56, 6 (2019), 102097.Google ScholarCross Ref"",""Dengyong Zhou, Jiayuan Huang, and Bernhard Schölkopf. 2007. Learning with hypergraphs: Clustering, classification, and embedding. In Advances in neural information processing systems. 1601--1608.Google Scholar""]"
https://doi.org/10.1145/3394486.3403183,ST-SiameseNet: Spatio-Temporal Siamese Networks for Human Mobility Signature Identification,"Given the historical movement trajectories of a set of individual human agents (e.g., pedestrians, taxi drivers) and a set of new trajectories claimed to be generated by a specific agent, the Human Mobility Signature Identification (HuMID) problem aims at validating if the incoming trajectories were indeed generated by the claimed agent. This problem is important in many real-world applications such as driver verification in ride-sharing services, risk analysis for auto insurance companies, and criminal identification. Prior work on identifying human mobility behaviors requires additional data from other sources besides the trajectories, e.g., sensor readings in the vehicle for driving behavior identification. However, these data might not be universally available and is costly to obtain. To deal with this challenge, in this work, we make the first attempt to match identities of human agents only from the observed location trajectory data by proposing a novel and efficient framework named Spatio-temporal Siamese Networks (ST-SiameseNet). For each human agent, we extract a set of profile and online features from his/her trajectories. We train ST-SiameseNet to predict the mobility signature similarity between each pair of agents, where each agent is represented by his/her trajectories and the extracted features. Experimental results on a real-world taxi trajectory dataset show that our proposed ST-SiamesNet can achieve an $F_1$ score of $0.8508$, which significantly outperforms the state-of-the-art techniques.","[{""name"":""Huimin Ren"",""id"":""/profile/99659573877""},{""name"":""Menghai Pan"",""id"":""/profile/99659495929""},{""name"":""Yanhua Li"",""id"":""/profile/81548016057""},{""name"":""Xun Zhou"",""id"":""/profile/81488657016""},{""name"":""Jun Luo"",""id"":""/profile/99659232654""},{""name"":""Huimin Ren"",""id"":""/profile/99659573877""},{""name"":""Menghai Pan"",""id"":""/profile/99659495929""},{""name"":""Yanhua Li"",""id"":""/profile/81548016057""},{""name"":""Xun Zhou"",""id"":""/profile/81488657016""},{""name"":""Jun Luo"",""id"":""/profile/99659232654""}]","[""OpenStreetMap. http://www.openstreetmap.org/.Google Scholar"",""Taxi, Uber, and Lyft Usage in New York City. http://toddwschneider.com/posts/taxi-uber-lyft-usage-new-york-city/.Google Scholar"",""J. Bromley, I. Guyon, Y. LeCun, E. Säckinger, and R. Shah. Signature verification using a \""siamese\"" time delay neural network. InNIPS, pages 737--744, 1994.Google ScholarCross Ref"",""F. Chollet et al. Keras. https://keras.io, 2015.Google Scholar"",""S. Chopra, R. Hadsell, and Y. LeCun. Learning a similarity metric discriminatively, with application to face verification. In CVPR, pages 539--546. IEEE, 2005.Google ScholarDigital Library"",""A. Chowdhury, T. Chakravarty, A. Ghose, T. Banerjee, and P. Balamuralidhar. Investigations on driver unique identification from smartphone's GPS data alone. Journal of Advanced Transportation, 2018, 2018.Google Scholar"",""Y. Ding, Y. Li, K. Deng, H. Tan, M. Yuan, and L. M. Ni. Detecting and analyzing urban regions with high impact of weather change on transport.IEEE Transactions on Big Data, 2016.Google Scholar"",""W. Dong, J. Li, R. Yao, C. Li, T. Yuan, and L. Wang. Characterizing driving styles with deep learning. arXiv preprint arXiv:1607.03611, 2016.Google Scholar"",""S. Ezzini, I. Berrada, and M. Ghogho. Who is behind the wheel? driver identification and fingerprinting. Journal of Big Data, 5(1):9, 2018.Google ScholarCross Ref"",""D. Hallac, A. Sharang, R. Stahlmann, A. Lamprecht, M. Huber, M. Roehder, J. Leskovec, et al. Driver identification using automobile sensor data from a single turn. In 2016 IEEE 19th ITSC, pages 953--958. IEEE, 2016.Google ScholarCross Ref"",""S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural computation, 9(8): 1735--1780, 1997.Google Scholar"",""E. Hoffer and N. Ailon. Deep metric learning using triplet network. In International Workshop on Similarity-Based Pattern Recognition. Springer, 2015.Google ScholarCross Ref"",""B. Hu, Z. Lu, H. Li, and Q. Chen. Convolutional neural network architectures for matching natural language sentences. In NIPS, pages 2042--2050, 2014.Google ScholarDigital Library"",""J. Yuan, Y. Zheng, L. Zhang, X. Xie. T-Finder: A Recommender System for Finding Passengers and Vacant Taxis. IEEE TKDE, 25(10):2390--2403, 2013.Google Scholar"",""H. Kamper, W. Wang, and K. Livescu. Deep convolutional acoustic word embeddings using word-pair side information. In ICASSP, pages 4950--4954. IEEE,2016.Google ScholarCross Ref"",""A. V. Khezerlou, X. Zhou, L. Li, Z. Shafiq, A. X. Liu, and F. Zhang. A traffic flow approach to early detection of gathering events: Comprehensive results. ACM TIST, 8(6):74, 2017.Google Scholar"",""T. Kieu, B. Yang, C. Guo, and C. S. Jensen. Distinguishing trajectories from different drivers using incompletely labeled trajectories. In Proceedings of the27th ACM International CIKM, pages 863--872. ACM, 2018.Google ScholarDigital Library"",""Y. Li, J. Luo, C.-Y. Chow, K.-L. Chan, Y. Ding, and F. Zhang. Growing the charging station network for electric vehicles with trajectory data analytics. In ICDE, 2015.Google ScholarCross Ref"",""Y. Li, M. Steiner, J. Bao, L. Wang, and T. Zhu. Region sampling and estimation of geosocial data with dynamic range calibration. In ICDE, 2014.Google ScholarCross Ref"",""C. Liu, K. Deng, C. Li, J. Li, Y. Li, and J. Luo. The optimal distribution of electric-vehicle chargers across a city. In ICDM. IEEE, 2016.Google ScholarCross Ref"",""J. O. López, A. C. C. Pinilla, et al. Driver behavior classification model based on an intelligent driving diagnosis system. In 15th ITS, pages 894--899. IEEE, 2012.Google Scholar"",""B. Lyu, S. Li, Y. Li, J. Fu, A. C. Trapp, H. Xie, and Y. Liao. Scalable user assignment in power grids: a data driven approach. In SIGSPATIAL GIS. ACM, 2016.Google ScholarDigital Library"",""M. Qu, H. Zhu, J. Liu, G. Liu, H. Xiong. A Cost-Effective Recommender System for Taxi Drivers. In The 20th SIGKDD'14, pages 45--54, New York, NY, 2014. ACM.Google ScholarDigital Library"",""A. MARSHALL. Uber's New Features Put a Focus on Rider Safety. https://www.wired.com/story/ubers-new-features-focus-rider-safety/, 09 2019.Google Scholar"",""M.-h. Oh and G. Iyengar. Sequential anomaly detection using inverse reinforcement learning. In Proceedings of the 25th ACM SIGKDD, pages 1480--1490, 2019.Google Scholar"",""M. Pan, Y. Li, X. Zhou, Z. Liu, R. Song, H. Lu, and J. Luo. Dissecting the learning curve of taxi drivers: A data-driven approach. In Proceedings of the 2019 SIAMSDM, pages 783--791. SIAM, 2019.Google Scholar"",""F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825--2830, 2011.Google ScholarDigital Library"",""H. Rong, X. Zhou, C. Yang, Z. Shafiq, and A. Liu. The rich and the poor: A markov decision process approach to optimizing taxi driver revenue efficiency. In Proceedings of the 25th CIKM, pages 2329--2334. ACM, 2016.Google ScholarDigital Library"",""W. S. Ma, Y. Zheng. A large-scale dynamic taxi ride sharing service. In The 29th ICDE'13, pages 410--421, New York, NY, 2013. IEEE.Google Scholar"",""F. Siddiqui. Uber makes changes amid swarm of criticism over rider safety. https://www.washingtonpost.com/technology/2019/09/26/uber-makes-safety-changes-amid-swarm-criticism-over-protection-riders/, 19.Google Scholar"",""G. Synnaeve, T. Schatz, and E. Dupoux. Phonetics embedding learning with side information. In 2014 IEEE SLT, pages 106--111. IEEE, 2014.Google ScholarCross Ref"",""Y. Taigman, M. Yang, M. Ranzato, and L. Wolf. Deepface: Closing the gap to human-level performance in face verification. In Proceedings of the IEEE conference on CVPR, pages 1701--1708, 2014.Google ScholarDigital Library"",""T. Xu, H. Zhu, X. Zhao, Q. Liu, H. Zhong, E. Chen, and H. Xiong. Taxi driving behavior analysis in latent vehicle-to-vehicle networks: A social influence perspective. In Proceedings of the 22nd SIGKDD, pages 1285--1294. ACM, 2016.Google ScholarDigital Library"",""Y. Ge and H. Xiong and A. Tuzhilin and K. Xiao and M. Gruteser. An energy-efficient mobile recommender system. In The the 16th International Conference on KDD, pages 899--908, New York, NY, 2010. ACM.Google ScholarDigital Library"",""Y. Ge, C. Liu, H. Xiong, J. Chen. A Taxi Business Intelligence System. In The 17th International Conference on KDD, pages 735--738, New York, NY, 2011. ACM.Google ScholarDigital Library"",""J. Yuan, Y. Zheng, L. Zhang, X. Xie, and G. Sun. Where to find my next passenger. In Proceedings of the 13th Ubicomp, pages 109--118, New York, NY, 2011. ACM.Google ScholarDigital Library"",""Z. Yuan, X. Zhou, and T. Yang. Hetero-convlstm: A deep learning approach to traffic accident prediction on heterogeneous spatio-temporal data. In Proceedings of the 24th ACM SIGKDD, pages 984--992. ACM, 2018.Google ScholarDigital Library"",""X. Zhang, X. Zhao, and J. Rong. A study of individual characteristics of driving behavior based on hidden Markov model. Sensors \u0026 Transducers, 167(3):194, 2014.Google Scholar""]"
https://doi.org/10.1145/3394486.3403184,A Novel Deep Learning Model by Stacking Conditional Restricted Boltzmann Machine and Deep Neural Network,"A real-world system often exhibits complex dynamics arising from interaction among its subunits. In machine learning and data mining, these interactions are usually formulated as dependency and correlation among system variables. Similar to Convolution Neural Network dealing with spatially correlated features and Recurrent Neural Network with temporally correlated features, in this paper we present a novel deep learning model to tackle functionally interactive features by stacking a Conditional Restricted Boltzmann Machine and a Deep Neural Network (CRBM-DNN). Variables with their dependency relationships are organized into a bipartite graph, which is further converted into a Restricted Boltzmann Machine conditioned by domain knowledge. We integrate this CRBM and a DNN into one deep learning model constrained by one overall cost function. CRBM-DNN can solve both supervised and unsupervised learning problems. Compared to a regular neural network of the same size, CRBM-DNN has fewer parameters so they require fewer training samples. We perform extensive comparative studies with a large number of supervised learning and unsupervised learning methods using several challenging real-world datasets, and achieve significant superior performance.","[{""name"":""Tianyu Kang"",""id"":""/profile/99659574468""},{""name"":""Ping Chen"",""id"":""/profile/81100107312""},{""name"":""John Quackenbush"",""id"":""/profile/81100497174""},{""name"":""Wei Ding"",""id"":""/profile/81408597754""},{""name"":""Tianyu Kang"",""id"":""/profile/99659574468""},{""name"":""Ping Chen"",""id"":""/profile/81100107312""},{""name"":""John Quackenbush"",""id"":""/profile/81100497174""},{""name"":""Wei Ding"",""id"":""/profile/81408597754""}]","[""Martín Abadi and Leslie Lamport. 1993. Composing specifications. ACM Transactions on Programming Languages and Systems (TOPLAS)15, 1 (1993), 73--132.Google Scholar"",""I Arijs, K Li, G Toedter, R Quintens, L Van Lommel, K Van Steen, P Leemans,G De Hertogh, K Lemaire, M Ferrante, F Schnitzler, L Thorrez, K Ma, X-Y R Song, C Marano, G Van Assche, S Vermeire, K Geboes, F Schuit, F Baribaud, and P Rutgeerts. 2009. Mucosal gene signatures to predict response to infliximab inpatients with ulcerative colitis. Gut58, 12 (Dec 2009), 1612--9. https://doi.org/10.1136/gut.2009.178665Google Scholar"",""Yoshua Bengio, Pascal Lamblin, Dan Popovici, and Hugo Larochelle. 2007. Greedy layer-wise training of deep networks. In Advances in neural information processing systems. 153--160.Google Scholar"",""Mohamed Bennasar, Yulia Hicks, and Rossitza Setchi. 2015. Feature selection using joint mutual information maximisation. Expert Systems with Applications 42, 22 (2015), 8520--8532.Google ScholarDigital Library"",""Deng Cai, Xiaofei He, Xiaoyun Wu, and Jiawei Han. 2008. Non-negative matrix factorization on manifold. In 2008 Eighth IEEE International Conference on Data Mining. IEEE, 63--72.Google ScholarDigital Library"",""Yuan Cao and Quanquan Gu. 2019. Generalization Bounds of Stochastic Gradient Descent for Wide and Deep Neural Networks. arXiv preprint arXiv:1905.13210(2019).Google Scholar"",""Penghe Chen, Yu Lu, Vincent W Zheng, and Yang Pian. 2018. Prerequisite-driven deep knowledge tracing. In 2018 IEEE International Conference on Data Mining(ICDM). IEEE, 39--48.Google ScholarCross Ref"",""Tim Dettmers, Pasquale Minervini, Pontus Stenetorp, and Sebastian Riedel. 2018. Convolutional 2d knowledge graph embeddings. In Thirty-Second AAAI Conference on Artificial Intelligence.Google Scholar"",""Gunilla Einecke, Jeff Reeve, Banu Sis, Michael Mengel, Luis Hidalgo, Konrad S Famulski, Arthur Matas, Bert Kasiske, Bruce Kaplan, and Philip F Halloran. 2010. A molecular classifier for predicting future graft loss in late kidney transplant biopsies. The Journal of clinical investigation 120, 6 (Jun 2010), 1862--72. https://doi.org/10.1172/JCI41789Google ScholarCross Ref"",""Jean-Claude Fort, Patrick Letremy, and Marie Cottrell. 2002. Advantages and drawbacks of the Batch Kohonen algorithm. In ESANN, Vol. 2. 223--230.Google Scholar"",""Robert C Gentleman, Vincent J Carey, Douglas M Bates, Ben Bolstad, Marcel Dettling, Sandrine Dudoit, Byron Ellis, Laurent Gautier, Yongchao Ge, Jeff Gentry,Kurt Hornik, Torsten Hothorn, Wolfgang Huber, Stefano Iacus, Rafael Irizarry, Friedrich Leisch, Cheng Li, Martin Maechler, Anthony J Rossini, Gunther Sawitzki, Colin Smith, Gordon Smyth, Luke Tierney, Jean Y H Yang, and Jianhua Zhang. 2004. Bioconductor: open software development for computational biology and bioinformatics.Genome Biology 5, 10 (Jan 2004), R80. https://doi.org/10.1186/gb-2004--5--10-r80Google Scholar"",""Robert L Grossman, Allison P Heath, Vincent Ferretti, Harold E Varmus, Douglas R Lowy, Warren A Kibbe, and Louis M Staudt. 2016. Toward a shared vision for cancer genomic data. New England Journal of Medicine 375, 12 (2016),1109--1112.Google ScholarCross Ref"",""Trevor Hastie, Robert Tibshirani, and J. H. Friedman. 2004. The elements of statistical learning: data mining, inference, and prediction: with 200 full-color illustrations. Springer.Google Scholar"",""Health IT Analytics. 2019. FDA: Real-World Data, Machine Learning Critical for Clinical Trials. https://healthitanalytics.com/news/fda-real-world-data-machine-learning-critical-for-clinical-trialsGoogle Scholar"",""Matan Hofree, John P Shen, Hannah Carter, Andrew Gross, and Trey Ideker. 2013. Network-based stratification of tumor mutations. Nature methods 10, 11 (2013),1108.Google Scholar"",""Ridwan Al Iqbal. 2011. A generalized method for integrating rule-based knowledge into inductive methods through virtual sample creation. arXiv preprint arXiv:1101.4924(2011).Google Scholar"",""Aleks Jakulin. 2005.Machine learning based on attribute interactions. Ph.D. Dissertation. Univerza v Ljubljani.Google Scholar"",""Purvesh Khatri, Silke Roedder, Naoyuki Kimura, Katrien De Vusser, Alexander A Morgan, Yongquan Gong, Michael P Fischbein, Robert C Robbins, Maarten Naesens, Atul J Butte, and Minnie M Sarwal. 2013. A common rejection module (CRM) for acute rejection across multiple organs identifies novel therapeutics for organ transplantation. J Exp Med 210, 11 (Oct 2013), 2205--21.https://doi.org/10.1084/jem.20122709Google ScholarCross Ref"",""Kenji Kira and Larry A Rendell. 1992. A practical approach to feature selection. In Machine Learning Proceedings 1992. Elsevier, 249--256.Google ScholarDigital Library"",""Konstantina Kourou, Themis P Exarchos, Konstantinos P Exarchos, Michalis VKaramouzis, and Dimitrios I Fotiadis. 2015. Machine learning applications in cancer prognosis and prediction. Computational and structural biotechnologyjournal13 (2015), 8--17.Google Scholar"",""Hugo Larochelle and Yoshua Bengio. 2008. Classification using discriminative restricted Boltzmann machines. In Proceedings of the 25th international conference on Machine learning. 536--543.Google ScholarDigital Library"",""Yann LeCun, Sumit Chopra, Raia Hadsell, M Ranzato, and F Huang. 2006. A tutorial on energy-based learning. Predicting structured data 1, 0 (2006).Google Scholar"",""Andrew C. Leon. 1998. Descriptive and Inferential Statistics. Comprehensive Clinical Psychology(1998), 243--285. https://doi.org/10.1016/b0080--4270(73)00264--9Google Scholar"",""Zhuwen Li, Qifeng Chen, and Vladlen Koltun. 2018. Combinatorial optimization with graph convolutional networks and guided tree search. In Advances in Neural Information Processing Systems. 539--548.Google Scholar"",""Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu. 2015. Learning entity and relation embeddings for knowledge graph completion. In Twenty-ninth AAAI conference on artificial intelligence.Google ScholarDigital Library"",""Stuart Lloyd. 1982. Least squares quantization in PCM. IEEE transactions on information theory 28, 2 (1982), 129--137.Google Scholar"",""Yulong Pei, Nilanjan Chakraborty, and Katia Sycara. 2015. Nonnegative matrix tri-factorization with graph regularization for community detection in social net-works. In Twenty-Fourth International Joint Conference on Artificial Intelligence.Google Scholar"",""GP Purja Pun, R Batra, R Ramprasad, and Y Mishin. 2019. Physically informed artificial neural networks for atomistic modeling of materials. Nature communications 10, 1 (2019), 1--10.Google Scholar"",""Maziar Raissi, Paris Perdikaris, and George E Karniadakis. 2019. Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. J. Comput. Phys.378(2019), 686--707.Google ScholarCross Ref"",""Jürgen Schmidhuber. 2015. Deep learning in neural networks: An overview. Neural networks 61 (2015), 85--117.Google Scholar"",""Leming Shi, Laura H Reid, Wendell D Jones, Richard Shippy, Janet A Warrington, Shawn C Baker, Patrick J Collins, Francoise De Longueville, Ernest S Kawasaki, Kathleen Y Lee, et al. 2006. The MicroArray Quality Control (MAQC) project shows inter-and intraplatform reproducibility of gene expression measurements. Nature biotechnology 24, 9 (2006), 1151.Google Scholar"",""Deepti Sisodia, Lokesh Singh, Sheetal Sisodia, and Khushboo Saxena. 2012. Clustering techniques: a brief survey of different clustering algorithms. International Journal of Latest Trends in Engineering and Technology (IJLTET)1, 3 (2012), 82--87.Google Scholar"",""Damian Szklarczyk, Annika L Gable, David Lyon, Alexander Junge, Stefan Wyder, Jaime Huerta-Cepas, Milan Simonovic, Nadezhda T Doncheva, John H Morris, Peer Bork, et al. 2018. STRING v11: protein--protein association networks with increased coverage, supporting functional discovery in genome-wide experimental datasets. Nucleic acids research 47, D1 (2018), D607--D613.Google Scholar"",""Daifeng Wang, Shuang Liu, Jonathan Warrell, Hyejung Won, Xu Shi, Fabio CP Navarro, Declan Clarke, Mengting Gu, Prashant Emani, Yucheng T Yang, et al.2018. Comprehensive functional genomic resource and integrative model for the human brain. Science 362, 6420 (2018), eaat8464.Google Scholar"",""Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. 2014. Knowledge graph embedding by translating on hyper planes. In Twenty-Eighth AAAI conference on artificial intelligence.Google ScholarDigital Library"",""Linda A. Winters-Miner. 2015. Obesity -- Individual.Practical Predictive Analytics and Decisioning Systems for Medicine(2015), 446--461. https://doi.org/10.1016/b978-0--12--411643--6.00022--3Google Scholar""]"
https://doi.org/10.1145/3394486.3403185,InfiniteWalk: Deep Network Embeddings as Laplacian Embeddings with a Nonlinearity,"The skip-gram model for learning word embeddings (Mikolov et al. 2013) has been widely popular, and DeepWalk (Perozzi et al. 2014), among other methods, has extended the model to learning node representations from networks. Recent work of Qiu et al. (2018) provides a closed-form expression for the DeepWalk objective, obviating the need for sampling for small datasets and improving accuracy. In these methods, the ""window size"" T within which words or nodes are considered to co-occur is a key hyperparameter. We study the objective in the limit as T goes to infinity, which allows us to simplify the expression of Qiu et al. We prove that this limiting objective corresponds to factoring a simple transformation of the pseudoinverse of the graph Laplacian, linking DeepWalk to extensive prior work in spectral graph embeddings. Further, we show that by a applying a simple nonlinear entrywise transformation to this pseudoinverse, we recover a good approximation of the finite-T objective and embeddings that are competitive with those from DeepWalk and other skip-gram methods in multi-label classification. Surprisingly, we find that even simple binary thresholding of the Laplacian pseudoinverse is often competitive, suggesting that the core advancement of recent methods is a nonlinearity on top of the classical spectral embedding approach.","[{""name"":""Sudhanshu Chanpuriya"",""id"":""/profile/99659573801""},{""name"":""Cameron Musco"",""id"":""/profile/99659574563""},{""name"":""Sudhanshu Chanpuriya"",""id"":""/profile/99659573801""},{""name"":""Cameron Musco"",""id"":""/profile/99659574563""}]","[""Nitin Agarwal, Huan Liu, Sudheendra Murthy, Arunabha Sen, and Xufei Wang. 2009. A social identity approach to identify familiar strangers in a social network. In Third International AAAI Conference on Weblogs and Social Media.Google Scholar"",""Carl Allen, Ivana Balazevic, and Timothy Hospedales. 2019. What the vec? Towards probabilistically grounded embeddings. In Advances in Neural Information Processing Systems. 7465--7475.Google Scholar"",""Carl Allen and Timothy Hospedales. 2019. Analogies Explained: Towards Understanding Word Embeddings. In International Conference on Machine Learning. 223--231.Google Scholar"",""Sanjeev Arora, Yuanzhi Li, Yingyu Liang, Tengyu Ma, and Andrej Risteski. 2016. A latent variable model approach to pmi-based word embeddings. Transactions of the Association for Computational Linguistics, Vol. 4 (2016), 385--399.Google ScholarCross Ref"",""Mikhail Belkin and Partha Niyogi. 2003. Laplacian eigenmaps for dimensionality reduction and data representation. Neural computation , Vol. 15, 6 (2003), 1373--1396.Google Scholar"",""Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolutional neural networks on graphs with fast localized spectral filtering. In Advances in neural information processing systems. 3844--3852.Google Scholar"",""Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin. 2008. LIBLINEAR: A library for large linear classification. Journal of machine learning research , Vol. 9, Aug (2008), 1871--1874.Google ScholarDigital Library"",""Alex Gittens, Dimitris Achlioptas, and Michael W Mahoney. 2017. Skip-Gram- ZipfGoogle Scholar"",""Uniform= Vector Additivity. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) . 69--76.Google Scholar"",""Yoav Goldberg and Omer Levy. 2014. word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding method. arXiv preprint arXiv:1402.3722 (2014).Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 855--864.Google ScholarDigital Library"",""Eric Jones, Travis Oliphant, Pearu Peterson, et almbox. 2001--. SciPy: Open source scientific tools for Python . http://www.scipy.org/Google Scholar"",""Jonathan A Kelner, Lorenzo Orecchia, Aaron Sidford, and Zeyuan Allen Zhu. 2013. A simple, combinatorial algorithm for solving SDD systems in nearly-linear time. In Proceedings of the forty-fifth annual ACM symposium on Theory of computing . 911--920.Google ScholarDigital Library"",""Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).Google Scholar"",""Ioannis Koutis, Gary L Miller, and Richard Peng. 2014. Approaching optimality for solving SDD linear systems. SIAM J. Comput. , Vol. 43, 1 (2014), 337--354.Google ScholarCross Ref"",""Richard B Lehoucq, Danny C Sorensen, and Chao Yang. 1998. ARPACK users' guide: solution of large-scale eigenvalue problems with implicitly restarted Arnoldi methods . Vol. 6. Siam.Google Scholar"",""Howard Levinson. [n.d.]. An eigenvalue representation for random walk hitting times and its application to the rook graph. https://www.math.upenn.edu/ levh/rookgraph.pdfGoogle Scholar"",""Omer Levy and Yoav Goldberg. 2014. Neural Word Embedding as Implicit Matrix Factorization. In Advances in Neural Information Processing Systems 27, Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger (Eds.). Curran Associates, Inc., 2177--2185. http://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization.pdfGoogle Scholar"",""Yitan Li, Linli Xu, Fei Tian, Liang Jiang, Xiaowei Zhong, and Enhong Chen. 2015. Word embedding revisited: A new representation learning and explicit matrix factorization perspective. In Twenty-Fourth International Joint Conference on Artificial Intelligence .Google Scholar"",""Frank McSherry. 2001. Spectral partitioning of random graphs. In Proceedings 42nd IEEE Symposium on Foundations of Computer Science. IEEE, 529--537.Google ScholarCross Ref"",""Carl D Meyer, Jr. 1973. Generalized inversion of modified matrices. SIAM J. Appl. Math. , Vol. 24, 3 (1973), 315--323.Google ScholarCross Ref"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems. 3111--3119.Google Scholar"",""Andrew Y Ng, Michael I Jordan, and Yair Weiss. 2002. On spectral clustering: Analysis and an algorithm. In Advances in Neural Information Processing Systems. 849--856.Google Scholar"",""Travis E Oliphant. 2006. A guide to NumPy . Vol. 1. Trelgol Publishing USA.Google Scholar"",""Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et almbox. 2011. Scikit-learn: Machine learning in Python. Journal of machine learning research , Vol. 12, Oct (2011), 2825--2830.Google ScholarDigital Library"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining . ACM, 701--710.Google ScholarDigital Library"",""Jiezhong Qiu, Yuxiao Dong, Hao Ma, Jian Li, Kuansan Wang, and Jie Tang. 2018. Network embedding as matrix factorization: Unifying deepwalk, line, pte, and node2vec. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining . ACM, 459--467.Google ScholarDigital Library"",""Gyan Ranjan, Zhi-Li Zhang, and Daniel Boley. 2014. Incremental computation of pseudo-inverse of Laplacian. In International Conference on Combinatorial Optimization and Applications. Springer, 729--749.Google ScholarCross Ref"",""Jianbo Shi and Jitendra Malik. 2000. Normalized cuts and image segmentation. IEEE Transactions on pattern analysis and machine intelligence , Vol. 22, 8 (2000), 888--905.Google ScholarDigital Library"",""Daniel A Spielman and Shang-Hua Teng. 2004. Nearly-linear time algorithms for graph partitioning, graph sparsification, and solving linear systems. In Proceedings of the thirty-sixth annual ACM symposium on Theory of computing. 81--90.Google ScholarDigital Library"",""Chris Stark, Bobby-Joe Breitkreutz, Andrew Chatr-Aryamontri, Lorrie Boucher, Rose Oughtred, Michael S Livstone, Julie Nixon, Kimberly Van Auken, Xiaodong Wang, Xiaoqi Shi, et almbox. 2010. The BioGRID interaction database: 2011 update. Nucleic acids research , Vol. 39, suppl_1 (2010), D698--D704.Google Scholar"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. In Proceedings of the 24th international conference on world wide web. International World Wide Web Conferences Steering Committee, 1067--1077.Google ScholarDigital Library"",""Petar Velivc ković , William Fedus, William L Hamilton, Pietro Liò, Yoshua Bengio, and R Devon Hjelm. 2018. Deep graph infomax. arXiv preprint arXiv:1809.10341 (2018).Google Scholar"",""Felix Wu, Tianyi Zhang, Amaur Holanda de Souza, Christopher Fifty, Tao Yu, and Kilian Q Weinberger. 2019. Simplifying graph convolutional networks. Proceedings of Machine Learning Research (2019).Google Scholar"",""Shuicheng Yan, Dong Xu, Benyu Zhang, Hong-Jiang Zhang, Qiang Yang, and Stephen Lin. 2006. Graph embedding and extensions: A general framework for dimensionality reduction. IEEE transactions on pattern analysis and machine intelligence , Vol. 29, 1 (2006), 40--51.Google Scholar""]"
https://doi.org/10.1145/3394486.3403186,xGAIL: Explainable Generative Adversarial Imitation Learning for Explainable Human Decision Analysis,"To make daily decisions, human agents devise their own ""strategies"" governing their mobility dynamics (e.g., taxi drivers have preferred working regions and times, and urban commuters have preferred routes and transit modes). Recent research such as generative adversarial imitation learning (GAIL) demonstrates successes in learning human decision-making strategies from their behavior data using deep neural networks (DNNs), which can accurately mimic how humans behave in various scenarios, e.g., playing video games, etc. However, such DNN-based models are ""black box"" models in nature, making it hard to explain what knowledge the models have learned from human, and how the models make such decisions, which was not addressed in the literature of imitation learning. This paper addresses this research gap by proposing xGAIL, the first explainable generative adversarial imitation learning framework. The proposed xGAIL framework consists of two novel components, including Spatial Activation Maximization (SpatialAM) and Spatial Randomized Input Sampling Explanation (SpatialRISE), to extract both global and local knowledge from a well-trained GAIL model that explains how a human agent makes decisions. Especially, we take taxi drivers' passenger-seeking strategy as an example to validate the effectiveness of the proposed xGAIL framework. Our analysis on a large-scale real-world taxi trajectory data shows promising results from two aspects: i) global explainable knowledge of what nearby traffic condition impels a taxi driver to choose a particular direction to find the next passenger, and ii) local explainable knowledge of what key (sometimes hidden) factors a taxi driver considers when making a particular decision.","[{""name"":""Menghai Pan"",""id"":""/profile/99659495929""},{""name"":""Weixiao Huang"",""id"":""/profile/99659477641""},{""name"":""Yanhua Li"",""id"":""/profile/81548016057""},{""name"":""Xun Zhou"",""id"":""/profile/81488657016""},{""name"":""Jun Luo"",""id"":""/profile/99659232654""},{""name"":""Menghai Pan"",""id"":""/profile/99659495929""},{""name"":""Weixiao Huang"",""id"":""/profile/99659477641""},{""name"":""Yanhua Li"",""id"":""/profile/81548016057""},{""name"":""Xun Zhou"",""id"":""/profile/81488657016""},{""name"":""Jun Luo"",""id"":""/profile/99659232654""}]","[""OpenStreetMap. http://www.openstreetmap.org/.Google Scholar"",""H. Anton and C. Rorres. Elementary linear algebra. 10. auflage. hoboken, 2010.Google Scholar"",""M. G. Augasta and T. Kathirvalavakumar. Reverse engineering the neural networks for rule extraction in classification problems. Neural processing letters, 35(2):131--150, 2012.Google ScholarDigital Library"",""A. Boularias, J. Kober, and J. Peters. Relative entropy inverse reinforcement learning. In Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, pages 182--189, 2011.Google Scholar"",""M. Du, N. Liu, and X. Hu. Techniques for interpretable machine learning. Communications of the ACM, 63(1):68--77, 2019.Google ScholarDigital Library"",""J. Fu, K. Luo, and S. Levine. Learning robust rewards with adversarial inverse reinforcement learning. arXiv preprint arXiv:1710.11248, 2017.Google Scholar"",""A. Getis and J. K. Ord. The analysis of spatial association by use of distance statistics. In Perspectives on Spatial Data Analysis, pages 127--145. Springer, 2010.Google ScholarCross Ref"",""I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In Advances in neural information processing systems, pages 2672--2680, 2014.Google ScholarDigital Library"",""R. Hecht-Nielsen. Theory of the backpropagation neural network. In Neural networks for perception, pages 65--93. Elsevier, 1992.Google ScholarCross Ref"",""J. Ho and S. Ermon. Generative adversarial imitation learning. In Advances in Neural Information Processing Systems, pages 4565--4573, 2016.Google ScholarDigital Library"",""A. Kádár, G. Chrupa?a, and A. Alishahi. Representation of linguistic form and function in recurrent neural networks. Computational Linguistics, 43(4):761--780, 2017.Google ScholarDigital Library"",""A. Karpathy, J. Johnson, and L. Fei-Fei. Visualizing and understanding recurrent networks. arXiv preprint arXiv:1506.02078, 2015.Google Scholar"",""Y. LeCun, B. E. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. E. Hubbard, and L. D. Jackel. Handwritten digit recognition with a back-propagation network. In NeurIPS, pages 396--404, 1990.Google Scholar"",""P. Li, S. Bhulai, and J. van Essen. Optimization of the revenue of the new york city taxi service using markov decision processes. In 6th International Conference on Data Analytics, Barcelona (Spain), November 12--16, pages 47--52. IARIA, 2017.Google Scholar"",""L. Liu, C. Andris, A. Biderman, and C. Ratti. Revealing taxi driver's mobility intelligence through his trace. In Movement-Aware Applications for Sustainable Mobility: Technologies and Approaches, pages 105--120. IGI Global, 2010.Google ScholarCross Ref"",""N. Liu, M. Du, and X. Hu. Representation interpretation with spatial encoding and multimodal analytics. In Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining, pages 60--68, 2019.Google ScholarDigital Library"",""A. Nguyen, A. Dosovitskiy, J. Yosinski, T. Brox, and J. Clune. Synthesizing the preferred inputs for neurons in neural networks via deep generator networks. In Advances in Neural Information Processing Systems, pages 3387--3395, 2016.Google ScholarDigital Library"",""M. Pan, W. Huang, Y. Li, X. Zhou, Z. Liu, R. Song, H. Lu, Z. Tian, and J. Luo. Dhpa: Dynamic human preference analytics framework: A case study on taxi drivers' learning curve analysis. ACM Trans. Intell. Syst. Technol., 11(1), Jan. 2020.Google ScholarDigital Library"",""M. Pan, Y. Li, X. Zhou, Z. Liu, R. Song, and J. Luo. Dissecting the learning curve of taxi drivers: A data-driven approach. In Proceedings of the 2019 SIAM International Conference on Data Mining. SIAM, 2019.Google ScholarCross Ref"",""V. Petsiuk, A. Das, and K. Saenko. Rise: Randomized input sampling for explanation of black-box models. arXiv preprint arXiv:1806.07421, 2018.Google Scholar"",""M. T. Ribeiro, S. Singh, and C. Guestrin. Why should i trust you?: Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, pages 1135--1144. ACM, 2016.Google ScholarDigital Library"",""M. T. Ribeiro, S. Singh, and C. Guestrin. Anchors: High-precision model-agnostic explanations. In Thirty-Second AAAI Conference on Artificial Intelligence, 2018.Google Scholar"",""H. Rong, X. Zhou, C. Yang, Z. Shafiq, and A. Liu. The rich and the poor: A markov decision process approach to optimizing taxi driver revenue efficiency. In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management, pages 2329--2334. ACM, 2016.Google ScholarDigital Library"",""K. Simonyan, A. Vedaldi, and A. Zisserman. Deep inside convolutional networks: Visualising image classification models and saliency maps. arXiv preprint arXiv:1312.6034, 2013.Google Scholar"",""R. S. Sutton, A. G. Barto, et al. Introduction to reinforcement learning, volume 135. MIT press Cambridge, 1998.Google Scholar"",""G. Vandewiele, O. Janssens, F. Ongenae, F. De Turck, and S. Van Hoecke. Genesim: genetic extraction of a single interpretable model. arXiv preprint arXiv:1611.05722, 2016.Google Scholar"",""G. Wu, Y. Li, J. Bao, Y. Zheng, J. Ye, and J. Luo. Human-centric urban transit evaluation and planning. In 2018 IEEE International Conference on Data Mining (ICDM), pages 547--556. IEEE, 2018.Google ScholarCross Ref"",""J. Yosinski, J. Clune, A. Nguyen, T. Fuchs, and H. Lipson. Understanding neural networks through deep visualization. arXiv preprint arXiv:1506.06579, 2015.Google Scholar"",""H. Yuan, Y. Chen, X. Hu, and S. Ji. Interpreting deep models for text analysis via optimization and regularization methods. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 5717--5724, 2019.Google ScholarCross Ref"",""C. Zeng and N. Oren. Dynamic taxi pricing. Frontiers in Artificial Intelligence and Applications, 263:1135--1136, 01 2014.Google Scholar"",""X. Zhang, Y. Li, X. Zhou, and J. Luo. Unveiling taxi drivers' strategies via cgail-conditional generative adversarial imitation learning. In 2019 IEEE International Conference on Data Mining (ICDM). IEEE, 2019.Google ScholarCross Ref"",""X. Zhou, H. Rong, C. Yang, Q. Zhang, A. V. Khezerlou, H. Zheng, M. Z. Shafiq, and A. X. Liu. Optimizing taxi driver profit efficiency: A spatial network-based markov decision process approach. IEEE Transactions on Big Data, 2018.Google Scholar"",""B. D. Ziebart, J. A. Bagnell, and A. K. Dey. Modeling interaction via the principle of maximum causal entropy. 2010.Google Scholar"",""B. D. Ziebart, A. L. Maas, J. A. Bagnell, and A. K. Dey. Maximum entropy inverse reinforcement learning. In AAAI, volume 8, pages 1433--1438. Chicago, IL, USA, 2008.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403187,Catalysis Clustering with GAN by Incorporating Domain Knowledge,"Clustering is an important unsupervised learning method with serious challenges when data is sparse and high-dimensional. Generated clusters are often evaluated with general measures, which may not be meaningful or useful for practical applications and domains. Using a distance metric, a clustering algorithm searches through the data space, groups close items into one cluster, and assigns far away samples to different clusters. In many real-world applications, the number of dimensions is high and data space becomes very sparse. Selection of a suitable distance metric is very difficult and becomes even harder when categorical data is involved. Moreover, existing distance metrics are mostly generic, and clusters created based on them will not necessarily make sense to domain-specific applications. One option to address these challenges is to integrate domain-defined rules and guidelines into the clustering process. In this work we propose a GAN-based approach called Catalysis Clustering to incorporate domain knowledge into the clustering process. With GANs we generate catalysts, which are special synthetic points drawn from the original data distribution and verified to improve clustering quality when measured by a domain-specific metric. We then perform clustering analysis using both catalysts and real data. Final clusters are produced after catalyst points are removed. Experiments on two challenging real-world datasets clearly show that our approach is effective and can generate clusters that are meaningful and useful for real-world applications.","[{""name"":""Olga Andreeva"",""id"":""/profile/99659166013""},{""name"":""Wei Li"",""id"":""/profile/99659573424""},{""name"":""Wei Ding"",""id"":""/profile/81408597754""},{""name"":""Marieke Kuijjer"",""id"":""/profile/99659574587""},{""name"":""John Quackenbush"",""id"":""/profile/81100497174""},{""name"":""Ping Chen"",""id"":""/profile/81100107312""},{""name"":""Olga Andreeva"",""id"":""/profile/99659166013""},{""name"":""Wei Li"",""id"":""/profile/99659573424""},{""name"":""Wei Ding"",""id"":""/profile/81408597754""},{""name"":""Marieke Kuijjer"",""id"":""/profile/99659574587""},{""name"":""John Quackenbush"",""id"":""/profile/81100497174""},{""name"":""Ping Chen"",""id"":""/profile/81100107312""}]","[""L. N. Allen and L. C. Rose. 2006. Financial Survival Analysis of Defaulted Debtors. The Journal of the Operational Research Society, Vol. 57, 6 (2006), 630 -- 636.Google ScholarCross Ref"",""Martin Arjovsky, Soumith Chintala, and Léon Bottou. 2017. Wasserstein gan. arXiv preprint arXiv:1701.07875 (2017).Google Scholar"",""Yale Chang, Junxiang Chen, Michael H Cho, Peter J Castaidi, Edwin K Silverman, and Jennifer G Dy. 2017. Clustering with domain-specific usefulness scores. In Proceedings of the 2017 SIAM International Conference on Data Mining. SIAM, 207--215.Google ScholarCross Ref"",""Nitesh V Chawla, Kevin W Bowyer, Lawrence O Hall, and W Philip Kegelmeyer. 2002. SMOTE: synthetic minority over-sampling technique. Journal of artificial intelligence research, Vol. 16 (2002), 321--357.Google ScholarDigital Library"",""Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. 2016. Infogan: Interpretable representation learning by information maximizing generative adversarial nets. In Advances in neural information processing systems. 2172--2180.Google ScholarDigital Library"",""The International Cancer Genome Consortium. 2010. International network of cancer genome projects. Nature, Vol. 464 (15 04 2010), 993 -- 998. http://dx.doi.org/10.1038/nature08987Google Scholar"",""Pietro Coretto, Angela Serra, Roberto Tagliaferri, and Jonathan Wren. 2018. Robust clustering of noisy high-dimensional gene expression data for patients subtyping. Bioinformatics (2018).Google Scholar"",""Kamran Ghasedi, Xiaoqian Wang, Cheng Deng, and Heng Huang. 2019. Balanced self-paced learning for generative adversarial clustering network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 4391--4400.Google ScholarCross Ref"",""Manish Kumar Goel, Pardeep Khanna, and Jugal Kishore. 2010. Understanding survival analysis: Kaplan-Meier estimate. International journal of Ayurveda research, Vol. 1, 4 (2010), 274.Google Scholar"",""Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial nets. In Advances in neural information processing systems. 2672--2680.Google Scholar"",""Pranab Haldar, Ian D Pavord, Dominic E Shaw, Michael A Berry, Michael Thomas, Christopher E Brightling, Andrew J Wardlaw, and Ruth H Green. 2008. Cluster analysis and clinical asthma phenotypes. American journal of respiratory and critical care medicine, Vol. 178, 3 (2008), 218--224.Google Scholar"",""Hui Han, Wen-Yuan Wang, and Bing-Huan Mao. 2005. Borderline-SMOTE: a new over-sampling method in imbalanced data sets learning. In International Conference on Intelligent Computing. Springer, 878--887.Google ScholarDigital Library"",""J. A. Hartigan and M. A. Wong. 1979. Algorithm AS 136: A K-Means Clustering Algorithm. Journal of the Royal Statistical Society. Series C (Applied Statistics), Vol. 28, 1 (1979), 100--108. https://doi.org/10.2307/2346830Google ScholarCross Ref"",""Haibo He, Yang Bai, Edwardo A Garcia, and Shutao Li. 2008. ADASYN: Adaptive synthetic sampling approach for imbalanced learning. In Neural Networks, 2008. IJCNN 2008.(IEEE World Congress on Computational Intelligence). IEEE International Joint Conference on. IEEE, 1322--1328.Google Scholar"",""Haibo He and Edwardo A Garcia. 2009. Learning from imbalanced data. IEEE Transactions on knowledge and data engineering, Vol. 21, 9 (2009), 1263--1284.Google ScholarDigital Library"",""Matan Hofree, John P Shen, Hannah Carter, Andrew Gross, and Trey Ideker. 2013. Network-based stratification of tumor mutations. Nature Methods, Vol. 10 (15 09 2013), 1108 -- 1115. http://dx.doi.org/10.1038/nmeth.2651Google ScholarCross Ref"",""Christian O Jacke, Iris Reinhard, and Ute S Albert. 2013. Using relative survival measures for cross-sectional and longitudinal benchmarks of countries, states, and districts: the BenchRelSurv-and BenchRelSurvPlot-macros. BMC public health, Vol. 13, 1 (2013), 34.Google Scholar"",""Michael S Lawrence, Petar Stojanov, Craig H Mermel, James T Robinson, Levi A Garraway, Todd R Golub, Matthew Meyerson, Stacey B Gabriel, Eric S Lander, and Gad Getz. 2014. Discovery and saturation analysis of cancer genes across 21 tumour types. Nature, Vol. 505, 7484 (2014), 495.Google Scholar"",""Michael S Lawrence, Petar Stojanov, Paz Polak, Gregory V Kryukov, Kristian Cibulskis, Andrey Sivachenko, Scott L Carter, Chip Stewart, Craig H Mermel, Steven A Roberts, et al. 2013. Mutational heterogeneity in cancer and the search for new cancer-associated genes. Nature, Vol. 499, 7457 (2013), 214.Google Scholar"",""Daniel D Lee and H Sebastian Seung. 1999. Learning the parts of objects by non-negative matrix factorization. Nature, Vol. 401, 6755 (1999), 788--791.Google Scholar"",""Fang Liu, Licheng Jiao, and Xu Tang. 2019. Task-oriented GAN for PolSAR image classification and clustering. IEEE transactions on neural networks and learning systems, Vol. 30, 9 (2019), 2707--2719.Google Scholar"",""Stefano Monti, Pablo Tamayo, Jill Mesirov, and Todd Golub. 2003. Consensus clustering: a resampling-based method for class discovery and visualization of gene expression microarray data. Machine learning, Vol. 52, 1--2 (2003), 91--118.Google Scholar"",""Sudipto Mukherjee, Himanshu Asnani, Eugene Lin, and Sreeram Kannan. 2019. Clustergan: Latent space clustering in generative adversarial networks. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 4610--4617.Google ScholarCross Ref"",""The Cancer Genome Atlas Research Network. 2011. Integrated genomic analyses of ovarian carcinoma. Nature, Vol. 474 (29 06 2011), 609 -- 615. http://dx.doi.org/10.1038/nature10166Google Scholar"",""The Cancer Genome Atlas Research Network. 2013. Integrated genomic characterization of endometrial carcinoma. Nature, Vol. 497 (01 05 2013), 67 -- 73. http://dx.doi.org/10.1038/nature12113Google Scholar"",""José Pereira. 2014. Survival Analysis Employed in Predicting Corporate Failure: A Forecasting Model Proposal., Vol. 7 (04 2014).Google Scholar"",""Catherine R Planey and Olivier Gevaert. 2016. CoINcIDE: A framework for discovery of patient subtypes across multiple datasets. Genome medicine, Vol. 8, 1 (2016), 27.Google Scholar"",""Jost Tobias Springenberg. 2015. Unsupervised and semi-supervised learning with categorical generative adversarial networks. arXiv preprint arXiv:1511.06390 (2015).Google Scholar"",""Michael Steinbach, Levent Ertöz, and Vipin Kumar. 2004. The challenges of clustering high dimensional data. In New directions in statistical physics. Springer, 273--309.Google Scholar"",""Mark Stevenson and IVABS EpiCentre. 2009. An introduction to survival analysis. EpiCentre, IVABS, Massey University (2009).Google Scholar"",""Mike Stoolmiller and James Snyder. 2013. Embedding multilevel survival analysis of dyadic social interaction in structural equation models: hazard rates as both outcomes and predictors. Journal of pediatric psychology, Vol. 39, 2 (2013), 222--232.Google ScholarCross Ref"",""Kelly C Vranas, Jeffrey K Jopling, Timothy E Sweeney, Meghan C Ramsey, Arnold S Milstein, Christopher G Slatore, Gabriel J Escobar, and Vincent X Liu. 2017. Identifying Distinct Subgroups of Intensive Care Unit Patients: a Machine Learning Approach. Critical care medicine, Vol. 45, 10 (2017), 1607.Google Scholar""]"
https://doi.org/10.1145/3394486.3403188,Prediction and Profiling of Audience Competition for Online Television Series,"Understanding the target audience for popular television series is valuable for online video platform to manage advertising sales, purchase video copyrights, and compete with other video service platforms. Existing studies in this domain generally focus on using data mining and machine learning techniques to recommend television series to individual users or predict the popularity of television series. Knowing only the popularity of television series may, however, limit our ability to answer more in-depth questions and develop more intelligent applications. In this paper, we develop a data-driven framework to model and predict audience competition patterns for popular online television series. Specifically, we first construct a sequence of dynamic competition networks of television series by mining the detailed viewership records. Then, we design the Dynamic Deep Network Factorization (DDNF), a hybrid modeling framework for predicting the future competition networks. Our framework adopts the deep neural network (DNN) and the knowledge-base (KB) embedding to incorporate static features, and integrates the Long Short-Term Memory (LSTM) network to learn dynamic features of the television series. Finally, extensive experiments on real-world data sets validate the effectiveness of our approach compared with state-of-the-art baselines in predicting the audience competition for existing and new television series.","[{""name"":""Peng Zhang"",""id"":""/profile/99659573699""},{""name"":""Chuanren Liu"",""id"":""/profile/81488659491""},{""name"":""Kefeng Ning"",""id"":""/profile/99659573024""},{""name"":""Wenxiang Zhu"",""id"":""/profile/99659573890""},{""name"":""Yu Zhang"",""id"":""/profile/99659575113""},{""name"":""Peng Zhang"",""id"":""/profile/99659573699""},{""name"":""Chuanren Liu"",""id"":""/profile/81488659491""},{""name"":""Kefeng Ning"",""id"":""/profile/99659573024""},{""name"":""Wenxiang Zhu"",""id"":""/profile/99659573890""},{""name"":""Yu Zhang"",""id"":""/profile/99659575113""}]","[""Charu C Aggarwal et al. Recommender systems. Springer, 2016.Google Scholar"",""Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of the ACM SIGMOD International Conference on Management of Data, pages 1247--1250, 2008.Google Scholar"",""Srinivas Bollapragada and Marc Garbiras. Scheduling commercials on broadcast television. Operations Research, 52 (3): 337--345, 2004.Google ScholarDigital Library"",""Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko. Translating embeddings for modeling multi-relational data. In Advances in neural information processing systems, pages 2787--2795, 2013.Google ScholarDigital Library"",""Antoine Bordes, Xavier Glorot, Jason Weston, and Yoshua Bengio. A semantic matching energy function for learning with multi-relational data. Machine Learning, 94 (2): 233--259, 2014.Google ScholarDigital Library"",""Fidel Cacheda, Victor Carneiro, Diego Fernández, and Vreixo Formoso. Comparison of collaborative filtering algorithms: Limitations of current techniques and proposals for scalable, high-performance recommender systems. ACM Transactions on the Web (TWEB), 5 (1): 1--33, 2011.Google Scholar"",""Biao Chang, Hengshu Zhu, Yong Ge, Enhong Chen, Hui Xiong, and Chang Tan. Predicting the popularity of online serials with autoregressive models. In Proceedings of the ACM International Conference on Information and Knowledge Management, pages 1339--1348. ACM, 2014.Google ScholarDigital Library"",""James Davidson, Benjamin Liebald, Junning Liu, Palash Nandy, Taylor Van Vleet, Ullas Gargi, Sujoy Gupta, Yu He, Mike Lambert, Blake Livingston, et al. The youtube video recommendation system. In Proceedings of the fourth ACM conference on recommender systems, pages 293--296. ACM, 2010.Google ScholarDigital Library"",""Bowen Du, Wenjun Zhou, Chuanren Liu, Yifeng Cui, and Hui Xiong. Transit pattern detection using tensor factorization. INFORMS Journal on Computing, 31 (2): 193--206, 2019.Google ScholarDigital Library"",""Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation, 9 (8): 1735--1780, 1997.Google Scholar"",""Christina ML Kelton and Linda G Schneider Stone. Optimal television schedules in alternative competitive environments. European Journal of Operational Research, 104 (3): 451--473, 1998.Google ScholarCross Ref"",""Yehuda Koren. Collaborative filtering with temporal dynamics. In Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 447--456, 2009.Google ScholarDigital Library"",""Daniel D Lee and H Sebastian Seung. Algorithms for non-negative matrix factorization. In Advances in neural information processing systems, pages 556--562, 2001.Google ScholarDigital Library"",""Haitao Li, Xiaoqiang Ma, Feng Wang, Jiangchuan Liu, and Ke Xu. On popularity prediction of videos shared in online social networks. In Proceedings of the ACM International Conference on Information and Knowledge Management, pages 169--178. ACM, 2013.Google ScholarDigital Library"",""Carolyn A Lin. Audience fragmentation in a competitive video marketplace. Journal of Advertising Research, 34 (6): 30--39, 1994.Google Scholar"",""Q. Liu, X. Zeng, C. Liu, H. Zhu, E. Chen, H. Xiong, and X. Xie. Mining indecisiveness in customer behaviors. In IEEE International Conference on Data Mining, pages 281--290. IEEE, 2015.Google ScholarDigital Library"",""Changsha Ma, Zhisheng Yan, and Chang Wen Chen. Larm: A lifetime aware regression model for predicting youtube video popularity. In Proceedings of the ACM International Conference on Information and Knowledge Management, pages 467--476. ACM, 2017.Google Scholar"",""Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. In International Conference on Learning Representations (Workshop Poster), 2013.Google Scholar"",""Andriy Mnih and Russ R Salakhutdinov. Probabilistic matrix factorization. In Advances in neural information processing systems, pages 1257--1264, 2008.Google ScholarDigital Library"",""Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. A three-way model for collective learning on multi-relational data. In International Conference on Machine Learning, volume 11, pages 809--816, 2011.Google Scholar"",""Yi Ouyang, Bin Guo, Xinjiang Lu, Qi Han, Tong Guo, and Zhiwen Yu. Competitivebike: Competitive analysis and popularity prediction of bike-sharing apps using multi-source data. IEEE Transactions on Mobile Computing, 2018.Google Scholar"",""Shinjini Pandey, Goutam Dutta, and Harit Joshi. Survey on revenue management in media and broadcasting. Interfaces, 47 (3): 195--213, 2017.Google ScholarDigital Library"",""Sunho Park, Yong-Deok Kim, and Seungjin Choi. Hierarchical bayesian matrix factorization with side information. In International Joint Conference on Artificial Intelligence, 2013.Google Scholar"",""Henrique Pinto, Jussara M Almeida, and Marcos A Goncc alves. Using early view patterns to predict the popularity of youtube videos. In Proceedings of the ACM international conference on web search and data mining, pages 365--374. ACM, 2013.Google ScholarDigital Library"",""Ian Porteous, Arthur Asuncion, and Max Welling. Bayesian matrix factorization with side information and dirichlet process mixtures. In AAAI Conference on Artificial Intelligence, 2010.Google Scholar"",""Michael E Porter. Competitive strategy: Techniques for analyzing industries and competitors. Simon and Schuster, 2008.Google Scholar"",""Steffen Rendle, Zeno Gantner, Christoph Freudenthaler, and Lars Schmidt-Thieme. Fast context-aware recommendations with factorization machines. In Proceedings of the ACM SIGIR Conference on Research and Development in Information Retrieval, pages 635--644, 2011.Google ScholarDigital Library"",""Suman Deb Roy, Tao Mei, Wenjun Zeng, and Shipeng Li. Towards cross-domain learning for social video popularity prediction. IEEE Transactions on Multimedia, 15 (6): 1255--1267, 2013.Google ScholarDigital Library"",""Tomasz Trzcinski and Przemysław Rokita. Predicting popularity of online videos using support vector regression. IEEE Transactions on Multimedia, 19 (11): 2561--2570, 2017.Google ScholarCross Ref"",""George Valkanas, Theodoros Lappas, and Dimitrios Gunopulos. Mining competitors from large unstructured datasets. IEEE Transactions on Knowledge and Data Engineering, 29 (9): 1971--1984, 2017.Google ScholarCross Ref"",""Chenyi Zhang, Ke Wang, Hongkun Yu, Jianling Sun, and Ee-Peng Lim. Latent factor transition for dynamic collaborative filtering. In Proceedings of the SIAM International Conference on Data Mining, pages 452--460. SIAM, 2014.Google ScholarCross Ref"",""Le Zhang, Hengshu Zhu, Tong Xu, Chen Zhu, Chuan Qin, Hui Xiong, and Enhong Chen. Large-scale talent flow forecast with dynamic latent factor model. In The World Wide Web Conference, pages 2312--2322. ACM, 2019.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403189,Multi-Class Data Description for Out-of-distribution Detection,"The capability of reliably detecting out-of-distribution samples is one of the key factors in deploying a good classifier, as the test distribution always does not match with the training distribution in most real-world applications. In this work, we present a deep multi-class data description, termed as Deep-MCDD, which is effective to detect out-of-distribution (OOD) samples as well as classify in-distribution (ID) samples. Unlike the softmax classifier that only focuses on the linear decision boundary partitioning its latent space into multiple regions, our Deep-MCDD aims to find a spherical decision boundary for each class which determines whether a test sample belongs to the class or not. By integrating the concept of Gaussian discriminant analysis into deep neural networks, we propose a deep learning objective to learn class-conditional distributions that are explicitly modeled as separable Gaussian distributions. Thereby, we can define the confidence score by the distance of a test sample from each class-conditional distribution, and utilize it for identifying OOD samples. Our empirical evaluation on multi-class tabular and image datasets demonstrates that Deep-MCDD achieves the best performances in distinguishing OOD samples while showing the classification accuracy as high as the other competitors.","[{""name"":""Dongha Lee"",""id"":""/profile/99659128708""},{""name"":""Sehun Yu"",""id"":""/profile/99659573629""},{""name"":""Hwanjo Yu"",""id"":""/profile/81452596142""},{""name"":""Dongha Lee"",""id"":""/profile/99659128708""},{""name"":""Sehun Yu"",""id"":""/profile/99659573629""},{""name"":""Hwanjo Yu"",""id"":""/profile/81452596142""}]","[""Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. Imagenet: A large-scale hierarchical image database. In CVPR. 248--255.Google Scholar"",""Terrance DeVries and Graham W Taylor. 2018. Learning confidence for out-of-distribution detection in neural networks. arXiv preprint arXiv:1802.04865 (2018).Google Scholar"",""John Duchi, Elad Hazan, and Yoram Singer. 2011. Adaptive subgradient methods for online learning and stochastic optimization. JMLR, Vol. 12, Jul (2011), 2121--2159.Google ScholarDigital Library"",""Yarin Gal. 2016. Uncertainty in deep learning. Ph.D. Dissertation. PhD thesis, University of Cambridge.Google Scholar"",""Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2014. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572 (2014).Google Scholar"",""Samantha Guerriero, Barbara Caputo, and Thomas Mensink. 2018. Deep nearest class mean classifiers. In ICLR Workshop.Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In CVPR. 770--778.Google Scholar"",""Dan Hendrycks and Kevin Gimpel. 2017. A baseline for detecting misclassified and out-of-distribution examples in neural networks. In ICLR.Google Scholar"",""Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531 (2015).Google Scholar"",""Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. 2017. Densely connected convolutional networks. In CVPR. 4700--4708.Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Durk P Kingma and Prafulla Dhariwal. 2018. Glow: Generative flow with invertible 1x1 convolutions. In NeurIPS. 10215--10224.Google Scholar"",""Alex Krizhevsky, Geoffrey Hinton, et al. 2009. Learning multiple layers of features from tiny images. Technical Report. Citeseer.Google Scholar"",""Kimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin. 2018. A simple unified framework for detecting out-of-distribution samples and adversarial attacks. In NeurIPS. 7167--7177.Google Scholar"",""Shiyu Liang, Yixuan Li, and R Srikant. 2018. Enhancing the reliability of out-of-distribution image detection in neural networks. In ICLR.Google Scholar"",""Andrey Malinin and Mark Gales. 2018. Predictive uncertainty estimation via prior networks. In NeurIPS. 7047--7058.Google Scholar"",""Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, and Pascal Frossard. 2017. Universal adversarial perturbations. In CVPR. 1765--1773.Google Scholar"",""Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. 2011. Reading digits in natural images with unsupervised feature learning. (2011).Google Scholar"",""Jie Ren, Peter J Liu, Emily Fertig, Jasper Snoek, Ryan Poplin, Mark A DePristo, Joshua V Dillon, and Balaji Lakshminarayanan. 2019. Likelihood Ratios for Out-of-Distribution Detection. In NeurIPS.Google Scholar"",""Lukas Ruff, Robert Vandermeulen, Nico Goernitz, Lucas Deecke, Shoaib Ahmed Siddiqui, Alexander Binder, Emmanuel Müller, and Marius Kloft. 2018. Deep one-class classification. In ICML. 4393--4402.Google Scholar"",""Lukas Ruff, Robert A Vandermeulen, Nico Görnitz, Alexander Binder, Emmanuel Müller, Klaus-Robert Müller, and Marius Kloft. 2019. Deep Semi-Supervised Anomaly Detection. arXiv preprint arXiv:1906.02694 (2019).Google Scholar"",""Tim Salimans, Andrej Karpathy, Xi Chen, and Diederik P. Kingma. 2017. PixelCNN+: A PixelCNN Implementation with Discretized Logistic Mixture Likelihood and Other Modifications. In ICLR.Google Scholar"",""Bernhard Schölkopf, John C Platt, John Shawe-Taylor, Alex J Smola, and Robert C Williamson. 2001. Estimating the support of a high-dimensional distribution. Neural computation, Vol. 13, 7 (2001), 1443--1471.Google Scholar"",""Bernhard SchölkopfÜ, Robert C Williamson, Alex SmolaÜ, and John Shawe-TaylorÝ. 1999. SV estimation of a distribution's support. (1999), 7167--7177.Google Scholar"",""Jake Snell, Kevin Swersky, and Richard Zemel. 2017. Prototypical networks for few-shot learning. In NeurIPS. 4077--4087.Google Scholar"",""Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. 2014. Intriguing properties of neural networks. In ICLR.Google Scholar"",""David MJ Tax and Robert PW Duin. 1999. Support vector domain description. Pattern recognition letters, Vol. 20, 11--13 (1999), 1191--1199.Google Scholar"",""David MJ Tax and Robert PW Duin. 2004. Support vector data description. Machine learning, Vol. 54, 1 (2004), 45--66.Google Scholar"",""Mattias Teye, Hossein Azizpour, and Kevin Smith. 2018. Bayesian Uncertainty Estimation for Batch Normalized Deep Networks. In ICML. 4914--4923.Google Scholar"",""Fisher Yu, Ari Seff, Yinda Zhang, Shuran Song, Thomas Funkhouser, and Jianxiong Xiao. 2015. Lsun: Construction of a large-scale image dataset using deep learning with humans in the loop. arXiv preprint arXiv:1506.03365 (2015).Google Scholar"",""Houssam Zenati, Manon Romain, Chuan-Sheng Foo, Bruno Lecouat, and Vijay Chandrasekhar. 2018. Adversarially Learned Anomaly Detection. In ICDM. 727--736.Google Scholar""]"
https://doi.org/10.1145/3394486.3403190,In and Out: Optimizing Overall Interaction in Probabilistic Graphs under Clustering Constraints,"We study two novel clustering problems in which the pairwise interactions between entities are characterized by probability distributions and conditioned by external factors within the environment where the entities interact. This covers any scenario where a set of actions can alter the entities' interaction behavior. In particular, we consider the case where the interaction conditioning factors can be modeled as cluster memberships of entities in a graph and the goal is to partition a set of entities such as to maximize the overall vertex interactions or, equivalently, minimize the loss of interactions in the graph. We show that both problems are NP-hard and they are equivalent in terms of optimality. However, we focus on the minimization formulation as it enables the possibility of devising both practical and efficient approximation algorithms and heuristics. Experimental evaluation of our algorithms, on both synthetic and real network datasets, has shown evidence of their meaningfulness as well as superiority with respect to competing methods, both in terms of effectiveness and efficiency.","[{""name"":""Domenico Mandaglio"",""id"":""/profile/99659496099""},{""name"":""Andrea Tagarelli"",""id"":""/profile/81100286971""},{""name"":""Francesco Gullo"",""id"":""/profile/81335491254""},{""name"":""Domenico Mandaglio"",""id"":""/profile/99659496099""},{""name"":""Andrea Tagarelli"",""id"":""/profile/81100286971""},{""name"":""Francesco Gullo"",""id"":""/profile/81335491254""}]","[""N. Ailon, M. Charikar, and A. Newman. 2008. Aggregating inconsistent information: Ranking and clustering. JACM, Vol. 55, 5 (2008), 23:1--23:27.Google Scholar"",""N. Bansal, A. Blum, and S. Chawla. 2004. Correlation Clustering. Machine Learning, Vol. 56, 1 (2004), 89--113.Google ScholarDigital Library"",""F. Bonchi, F. Gullo, A. Kaltenbrunner, and Y. Volkovich. 2014. Core decomposition of uncertain graphs. In Proc. ACM KDD Conf. 1316--1325.Google Scholar"",""M. Ceccarello, C. Fantozzi, A. Pietracaprina, G. Pucci, and F. Vandin. 2017. Clustering Uncertain Graphs. PVLDB, Vol. 11, 4 (2017), 472--484.Google Scholar"",""M. Charikar, V. Guruswami, and A. Wirth. 2005. Clustering with qualitative information. JCSS, Vol. 71, 3 (2005), 360--383.Google ScholarDigital Library"",""E. D. Demaine, D. Emanuel, A. Fiat, and N. Immorlica. 2006. Correlation clustering in general weighted graphs. TCS, Vol. 361, 2--3 (2006), 172--187.Google ScholarDigital Library"",""P. Esmailian and M. Jalili. 2015. Community detection in signed networks: the role of negative ties in different scales. Scientific reports, Vol. 5 (2015), 14339.Google Scholar"",""Yu G., Chunpeng G., Gao C., and Ge Y. 2014. Effective and Efficient Clustering Methods for Correlated Probabilistic Graphs. IEEE TKDE, Vol. 26, 5 (2014), 1117--1130.Google Scholar"",""S. Gómez, P. Jensen, and A. Arenas. 2009. Analysis of community structure in networks of correlated data. Physical Review E, Vol. 80, 1 (2009), 016114.Google ScholarCross Ref"",""Z. Halim, M. Waqas, and S. F. Hussain. 2015. Clustering large probabilistic graphs using multi-population evolutionary algorithm. Inf. Sci., Vol. 317 (2015), 78--95.Google ScholarDigital Library"",""K. Han, F. Gui, X. Xiao, J. Tang, Y. He, Z. Cao, and H. Huang. 2019. Efficient and Effective Algorithms for Clustering Uncertain Graphs. PVLDB, Vol. 12, 6 (2019), 667--680.Google ScholarDigital Library"",""A. Khan, F. Bonchi, A. Gionis, and F. Gullo. 2014. Fast Reliability Search in Uncertain Graphs. In Proc. EDBT Conf. 535--546.Google Scholar"",""A. Khan, F. Bonchi, F. Gullo, and A. Nufer. 2018a. Conditional Reliability in Uncertain Graphs. IEEE TKDE, Vol. 30, 11 (2018), 2078--2092.Google Scholar"",""A. Khan, Y. Ye, and L. Chen. 2018b. On Uncertain Graphs .Morgan \u0026 Claypool.Google Scholar"",""G. Kollios, M. Potamias, and E. Terzi. 2013. Clustering Large Probabilistic Graphs. IEEE TKDE, Vol. 25, 2 (2013), 325--336.Google Scholar"",""Y. Li, X. Kong, C. Jia, and J. Li. 2018. Clustering Uncertain Graphs with Node Attributes. In Proc. ACML Conf. 232--247.Google Scholar"",""L. Liu, R. Jin, C. C. Aggarwal, and Y. Shen. 2012. Reliable Clustering on Uncertain Graphs. In Proc. IEEE ICDM Conf. 459--468.Google Scholar"",""D. Pandove, S. Goel, and R. Rani. 2018. Correlation clustering methodologies and their fundamental results. Expert Systems, Vol. 35, 1 (2018).Google Scholar"",""P. Parchas, F. Gullo, D. Papadias, and F. Bonchi. 2015. Uncertain Graph Processing through Representative Instances. ACM TODS, Vol. 40, 3 (2015), 20:1--20:39.Google Scholar"",""C. Swamy. 2004. Correlation Clustering: maximizing agreements via semidefinite programming. In Proc. ACM-SIAM SODA Conf. 526--527.Google Scholar"",""V. A. Traag and J. Bruggeman. 2009. Community detection in networks with positive and negative links. Physical Review E, Vol. 80, 3 (2009), 036115.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403191,Recurrent Halting Chain for Early Multi-label Classification,"Early multi-label classification of time series, the assignment of a label set to a time series before the series is entirely observed, is critical for time-sensitive domains such as healthcare. In such cases, waiting too long to classify can render predictions useless, regardless of their accuracy, while predicting prematurely can result in potentially costly erroneous results. When predicting multiple labels (for example, types of infections), dependencies between labels can be learned and leveraged to improve overall accuracy. Together, reliably predicting the correct label set of a time series while observing as few timesteps as possible is challenging because these goals are contradictory in that fewer timesteps often means worse accuracy. To achieve early yet sufficiently accurate predictions, correlations between labels must be accounted for since direct evidence of some labels may only appear late in the series. We design an effective solution to this open problem, the Recurrent Halting Chain (RHC), that for the first time integrates key innovations in both Early and Multi-label Classification into one multi-objective model. RHC uses a recurrent neural network to jointly model raw time series as well as correlations between labels, resulting in a novel order-free classifier chain that tackles this time-sensitive multi-label learning task. Further, RHC employs a reinforcement learning-based halting network to decide at each timestep which, if any, classes should be predicted, learning to build the label set over time. Using two real-world time-sensitive datasets and popular multi-label metrics, we show that RHC outperforms recent alternatives by predicting more-accurate label sets earlier.","[{""name"":""Thomas Hartvigsen"",""id"":""/profile/99659453882""},{""name"":""Cansu Sen"",""id"":""/profile/99659455092""},{""name"":""Xiangnan Kong"",""id"":""/profile/81466643630""},{""name"":""Elke Rundensteiner"",""id"":""/profile/81408601880""},{""name"":""Thomas Hartvigsen"",""id"":""/profile/99659453882""},{""name"":""Cansu Sen"",""id"":""/profile/99659455092""},{""name"":""Xiangnan Kong"",""id"":""/profile/81466643630""},{""name"":""Elke Rundensteiner"",""id"":""/profile/81408601880""}]","[""D. Anguita, A. Ghio, L. Oneto, X. Parra, and J. Reyes-Ortiz. 2013. A public domain dataset for human activity recognition using smartphones.. In ESANN.Google Scholar"",""M. Boutell, J. Luo, X. Shen, and C. Brown. 2004. Learning multi-label scene classification. Pattern Recognition, Vol. 37, 9 (2004), 1757 -- 1771.Google ScholarCross Ref"",""Y.-C. Chen, S.-F.and Chen, C.-K. Yeh, and Y.-C. Wang. 2018. Order-free RNN with visual attention for multi-label classification. In AAAI.Google Scholar"",""D. Dennis, C. Pabbaraju, H. Simhadri, and P. Jain. 2018. Multiple instance learning for efficient sequential data classification on resource-constrained devices. In NeurIPS. 10953--10964.Google Scholar"",""Y. Fujita, N. Kanda, S. Horiguchi, K. Nagamatsu, and S. Watanabe. 2019. End-to-End Neural Speaker Diarization with Permutation-Free Objectives. In Interspeech.Google Scholar"",""M. Ghalwash and Z. Obradovic. 2012. Early classification of multivariate temporal observations by extraction of interpretable shapelets. BMC Bioinformatics, Vol. 13, 1 (2012), 195.Google ScholarCross Ref"",""M. Ghalwash, V. Radosavljevic, and Z. Obradovic. 2013. Extraction of interpretable multivariate patterns for early diagnostics. In ICDM. 201--210.Google Scholar"",""M. Ghalwash, V. Radosavljevic, and Z. Obradovic. 2014. Utilizing temporal patterns for estimating uncertainty in interpretable early decision making. In SIGKDD. 402--411.Google Scholar"",""A. Gupta, H. P. Gupta, B. Biswas, and T. Dutta. 2020. An Early Classification Approach for Multivariate Time Series of On-Vehicle Sensors in Transportation. IEEE Transactions on Intelligent Transportation Systems (2020).Google Scholar"",""T. Hartvigsen, C. Sen, S. Brownell, E. Teeple, X. Kong, and E. Rundensteiner. 2018. Early Prediction of MRSA Infections using Electronic Health Records. In HEALTHINF. 156--167.Google Scholar"",""T. Hartvigsen, C. Sen, X. Kong, and E. Rundensteiner. 2019. Adaptive-Halting Policy Network for Early Classification. In SIGKDD. 101--110.Google Scholar"",""G. He, Y. Duan, R. Peng, X. Jing, T. Qian, and L. Wang. 2015. Early classification on multivariate time series. Neurocomputing, Vol. 149 (2015), 777--787.Google ScholarDigital Library"",""S. Hochreiter and J. Schmidhuber. 1997. Long short-term memory. Neural Computation, Vol. 9, 8 (1997), 1735--1780.Google ScholarDigital Library"",""Z. Huang, Z. Ye, S. Li, and R. Pan. 2017. Length Adaptive Recurrent Model for Text Classification. In CIKM. 1019--1027.Google Scholar"",""D. Kingma and J. Ba. 2014. Adam: A method for stochastic optimization. In ICLR.Google Scholar"",""Y.-F. Lin, H.-H. Chen, V. Tseng, and J. Pei. 2015. Reliable early classification on multivariate time series with numerical and categorical attributes. In PAKDD. 199--211.Google Scholar"",""S. Ma, L. Sigal, and S. Sclaroff. 2016. Learning activity progression in lstms for activity detection and early detection. In CVPR. 1942--1950.Google Scholar"",""C. Martinez, E. Ramasso, G. Perrin, and M. Rombaut. 2019. Adaptive early classification of temporal sequences using deep reinforcement learning. Knowledge-Based Systems (2019).Google Scholar"",""V. Mnih, K. Kavukcuoglu, D. Silver, A. Graves, I. Antonoglou, D. Wierstra, and M. Riedmiller. 2013. Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602 (2013).Google Scholar"",""U. Mori, A. Mendiburu, S. Dasgupta, and J. Lozano. 2018. Early classification of time series by simultaneously optimizing the accuracy and earliness. IEEE transactions on neural networks and learning systems, Vol. 29, 10 (2018), 4569 -- 4578.Google Scholar"",""U. Mori, A. Mendiburu, E. Keogh, and J. Lozano. 2017. Reliable early classification of time series based on discriminating the classes over time. Data Mining and Knowledge Discovery, Vol. 31, 1 (2017), 233--263.Google ScholarDigital Library"",""J. Nam, Y.-B. Kim, E. Mencia, S. Park, R. Sarikaya, and J. Fürnkranz. 2019. Learning Context-dependent Label Permutations for Multi-label Classification. In ICML. 4733--4742.Google Scholar"",""J. Nam, E. Menc'ia, H. Kim, and J. Fürnkranz. 2017. Maximizing subset accuracy with recurrent neural networks in multi-label classification. In NeurIPS. 5413--5423.Google Scholar"",""J. Schulman, N. Heess, T. Weber, and P. Abbeel. 2015. Gradient estimation using stochastic computation graphs. In NeurIPS. 3528--3536.Google Scholar"",""D. Silver, A. Huang, C. Maddison, A. Guez, L. Sifre, G. Van Den Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershelvam, M. Lanctot, et al. 2016. Mastering the game of Go with deep neural networks and tree search. nature, Vol. 529, 7587 (2016), 484.Google Scholar"",""R. Sutton, D. McAllester, S. Singh, and Y. Mansour. 2000. Policy gradient methods for reinforcement learning with function approximation. In NeurIPS. 1057--1063.Google Scholar"",""C.-P. Tsai and H.-Y. Lee. 2020. Order-free Learning Alleviating Exposure Bias in Multi-label Classification. In AAAI.Google Scholar"",""Y. Vaizman, K. Ellis, and G. Lanckriet. 2017. Recognizing detailed human context in the wild from smartphones and smartwatches. IEEE Pervasive Computing, Vol. 16, 4 (2017), 62--74.Google ScholarCross Ref"",""O. Vinyals, S. Bengio, and M. Kudlur. 2017. Order matters: Sequence to sequence for sets. In ICLR.Google Scholar"",""J. Wang, Y. Yang, J. Mao, Z. Huang, C. Huang, and W. Xu. 2016. CNN-RNN: A unified framework for multi-label image classification. In CVPR. 2285--2294.Google Scholar"",""R. Williams. 1992. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine Learning, Vol. 8, 3--4 (1992), 229--256.Google ScholarDigital Library"",""Z. Xing, J. Pei, and P. Yu. 2009. Early Prediction on Time Series: A Nearest Neighbor Approach. In IJCAI. 1297--1302.Google Scholar"",""Z. Xing, J. Pei, and P. Yu. 2012. Early classification on time series. Knowledge and Information Systems, Vol. 31, 1 (2012), 105--127.Google ScholarDigital Library"",""Z. Xing, J. Pei, P. Yu, and K. Wang. 2011. Extracting interpretable features for early classification on time series. In SDM. 247--258.Google Scholar"",""P. Yang, X. Sun, W. Li, S. Ma, W. Wu, and H. Wang. 2018. SGM: Sequence Generation Model for Multi-label Classification. In COLING. 3915--3926.Google Scholar"",""L. Yao, E. Poblenz, D. Dagunts, B. Covington, D. Bernard, and K. Lyman. 2017. Learning to diagnose from scratch by exploiting dependencies among labels. arXiv preprint arXiv:1710.10501 (2017).Google Scholar"",""W. Zhang, D. Jha, E. Laftchiev, and D. Nikovski. 2020. Multi-label Prediction in Time Series Data using Deep Neural Networks. arXiv preprint, Vol. abs/2001.10098 (2020).Google Scholar""]"
https://doi.org/10.1145/3394486.3403192,Minimal Variance Sampling with Provable Guarantees for Fast Training of Graph Neural Networks,"Sampling methods (e.g., node-wise, layer-wise, or subgraph) has become an indispensable strategy to speed up training large-scale Graph Neural Networks (GNNs). However, existing sampling methods are mostly based on the graph structural information and ignore the dynamicity of optimization, which leads to high variance in estimating the stochastic gradients. The high variance issue can be very pronounced in extremely large graphs, where it results in slow convergence and poor generalization. In this paper, we theoretically analyze the variance of sampling methods and show that, due to the composite structure of empirical risk, the variance of any sampling method can be decomposed intoembedding approximation variance in the forward stage andstochastic gradient variance in the backward stage that necessities mitigating both types of variance to obtain faster convergence rate. We propose a decoupled variance reduction strategy that employs (approximate) gradient information to adaptively sample nodes with minimal variance, and explicitly reduces the variance introduced by embedding approximation. We show theoretically and empirically that the proposed method, even with smaller mini-batch sizes, enjoys a faster convergence rate and entails a better generalization compared to the existing methods.","[{""name"":""Weilin Cong"",""id"":""/profile/99659554861""},{""name"":""Rana Forsati"",""id"":""/profile/81414617230""},{""name"":""Mahmut Kandemir"",""id"":""/profile/81100186744""},{""name"":""Mehrdad Mahdavi"",""id"":""/profile/81418595722""},{""name"":""Weilin Cong"",""id"":""/profile/99659554861""},{""name"":""Rana Forsati"",""id"":""/profile/81414617230""},{""name"":""Mahmut Kandemir"",""id"":""/profile/81100186744""},{""name"":""Mehrdad Mahdavi"",""id"":""/profile/81418595722""}]","[""Mart'in Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al. 2016. Tensorflow: A system for large-scale machine learning. In 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16). 265--283.Google ScholarDigital Library"",""Rianne van den Berg, Thomas N Kipf, and Max Welling. 2017. Graph convolutional matrix completion. arXiv preprint arXiv:1706.02263 (2017).Google Scholar"",""Jie Chen, Tengfei Ma, and Cao Xiao. 2018. Fastgcn: fast learning with graph convolutional networks via importance sampling. arXiv preprint arXiv:1801.10247 (2018).Google Scholar"",""Jianfei Chen, Jun Zhu, and Le Song. 2017. Stochastic training of graph convolutional networks with variance reduction. arXiv preprint arXiv:1710.10568 (2017).Google Scholar"",""Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, and Cho-Jui Hsieh. 2019. Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 257--266.Google ScholarDigital Library"",""Dominik Csiba, Zheng Qu, and Peter Richtárik. 2015. Stochastic dual coordinate ascent with adaptive probabilities. In ICML. 674--683.Google Scholar"",""Zhiyong Cui, Kristian Henrickson, Ruimin Ke, and Yinhai Wang. 2019. Traffic graph convolutional recurrent neural network: A deep learning framework for network-scale traffic learning and forecasting. IEEE Transactions on Intelligent Transportation Systems (2019).Google Scholar"",""Songgaojun Deng, Huzefa Rangwala, and Yue Ning. 2019. Learning Dynamic Context Graphs for Predicting Social Events. In KDD. 1007--1016.Google Scholar"",""Kien Do, Truyen Tran, and Svetha Venkatesh. 2019. Graph transformation policy network for chemical reaction prediction. In KDD. 750--760.Google Scholar"",""David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Alán Aspuru-Guzik, and Ryan P Adams. 2015. Convolutional networks on graphs for learning molecular fingerprints. In NeurIPS. 2224--2232.Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In NeurIPS. 1024--1034.Google Scholar"",""Angelos Katharopoulos and Francc ois Fleuret. 2018. Not all samples are created equal: Deep learning with importance sampling. arXiv preprint arXiv:1803.00942 (2018).Google Scholar"",""Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).Google Scholar"",""Srijan Kumar, Xikun Zhang, and Jure Leskovec. 2019. Predicting dynamic embedding trajectory in temporal interaction networks. In KDD. 1269--1278.Google Scholar"",""Jia Li, Zhichao Han, Hong Cheng, Jiao Su, Pengyun Wang, Jianfeng Zhang, and Lujia Pan. 2019. Predicting Path Failure In Time-Evolving Graphs. In KDD. 1279--1289.Google Scholar"",""Ruoyu Li, Sheng Wang, Feiyun Zhu, and Junzhou Huang. 2018. Adaptive graph convolutional neural networks. In AAAI .Google Scholar"",""Guillaume Papa, Pascal Bianchi, and Stéphan Clémencc on. 2015. Adaptive sampling for incremental optimization using stochastic gradient descent. In ALT. Springer, 317--331.Google Scholar"",""Namyong Park, Andrey Kan, Xin Luna Dong, Tong Zhao, and Christos Faloutsos. 2019. Estimating node importance in knowledge graphs using graph neural networks. In KDD. 596--606.Google Scholar"",""Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. 2019. PyTorch: An imperative style, high-performance deep learning library. In NeurIPS. 8024--8035.Google Scholar"",""Jiezhong Qiu, Jian Tang, Hao Ma, Yuxiao Dong, Kuansan Wang, and Jie Tang. 2018. DeepInf: Modeling influence locality in large social networks. In KDD .Google Scholar"",""Afshin Rahimi, Trevor Cohn, and Timothy Baldwin. 2018. Semi-supervised user geolocation via graph convolutional networks. arXiv preprint arXiv:1804.08049 (2018).Google Scholar"",""Farnood Salehi, Patrick Thiran, and Elisa Celis. 2018. Coordinate descent with bandit sampling. In NeurIPS. 9247--9257.Google Scholar"",""Sebastian U Stich, Anant Raj, and Martin Jaggi. 2017. Safe adaptive importance sampling. In NeurIPS. 4381--4391.Google Scholar"",""Hao Wang, Tong Xu, Qi Liu, Defu Lian, Enhong Chen, Dongfang Du, Han Wu, and Wen Su. 2019 b. MCNE: An End-to-End Framework for Learning Multiple Conditional Network Representations of Social Network. In KDD. 1064--1072.Google Scholar"",""Hongwei Wang, Fuzheng Zhang, Mengdi Zhang, Jure Leskovec, Miao Zhao, Wenjie Li, and Zhongyuan Wang. 2019 c. Knowledge-aware graph neural networks with label smoothness regularization for recommender systems. In KDD. 968--977.Google Scholar"",""Xiang Wang, Xiangnan He, Yixin Cao, Meng Liu, and Tat-Seng Chua. 2019 a. Kgat: Knowledge graph attention network for recommendation. In KDD. 950--958.Google Scholar"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale recommender systems. In KDD. 974--983.Google Scholar"",""Hanqing Zeng, Hongkuan Zhou, Ajitesh Srivastava, Rajgopal Kannan, and Viktor Prasanna. 2019. Graphsaint: Graph sampling based inductive learning method. arXiv preprint arXiv:1907.04931 (2019).Google Scholar"",""Cheng Zhang, Hedvig Kjellstrom, and Stephan Mandt. 2017. Determinantal point processes for mini-batch diversification. arXiv preprint arXiv:1705.00607 (2017).Google Scholar"",""Peilin Zhao and Tong Zhang. 2015. Stochastic optimization with importance sampling for regularized loss minimization. In ICML. 1--9.Google Scholar"",""Q Zheng, P Richtárik, and T Zhang. 2014. Randomized dual coordinate ascent with arbitrary sampling.Google Scholar"",""Rong Zhu. 2016. Gradient-based sampling: An adaptive importance sampling for least-squares. In NeurIPS. 406--414.Google Scholar"",""Difan Zou, Ziniu Hu, Yewen Wang, Song Jiang, Yizhou Sun, and Quanquan Gu. 2019. Layer-Dependent Importance Sampling for Training Deep and Large Graph Convolutional Networks. In NeurIPS. 11247--11256.Google Scholar""]"
https://doi.org/10.1145/3394486.3403193,Discovering Functional Dependencies from Mixed-Type Data,"Given complex data collections, practitioners can perform non-parametric functional dependency discovery (FDD) to uncover relationships between variables that were previously unknown. However, known FDD methods are applicable to nominal data, and in practice non-nominal variables are discretized, e.g., in a pre-processing step. This is problematic because, as soon as a mix of discrete and continuous variables is involved, the interaction of discretization with the various dependency measures from the literature is poorly understood. In particular, it is unclear whether a given discretization method even leads to a consistent dependency estimate. In this paper, we analyze these fundamental questions and derive formal criteria as to when a discretization process applied to a mixed set of random variables leads to consistent estimates of mutual information. With these insights, we derive an estimator framework applicable to any task that involves estimating mutual information from multivariate and mixed-type data. Last, we extend with this framework a previously proposed FDD approach for reliable dependencies. Experimental evaluation shows that the derived reliable estimator is both computationally and statistically efficient, and leads to effective FDD algorithms for mixed-type data.","[{""name"":""Panagiotis Mandros"",""id"":""/profile/99659193035""},{""name"":""David Kaltenpoth"",""id"":""/profile/99659574573""},{""name"":""Mario Boley"",""id"":""/profile/81384606148""},{""name"":""Jilles Vreeken"",""id"":""/profile/81335499054""},{""name"":""Panagiotis Mandros"",""id"":""/profile/99659193035""},{""name"":""David Kaltenpoth"",""id"":""/profile/99659574573""},{""name"":""Mario Boley"",""id"":""/profile/81384606148""},{""name"":""Jilles Vreeken"",""id"":""/profile/81335499054""}]","[""J. Alcalà-Fdez, A. Fernàndez, J. Luengo, J. Derrac, and S. Garcìa. 2011. KEEL Data-Mining Software Tool: Data Set Repository, Integration of Algorithms and Experimental Analysis Framework. J Mult-Valued Log S, Vol. 17 (2011), 255--287.Google Scholar"",""T. Berrett, R. Samworth, and M. Yuan. 2016. Efficient multivariate entropy estimation via k-nearest neighbour distances. Ann. Stat., Vol. 47 (2016), 288--318.Google ScholarCross Ref"",""T. M. Cover and J. A. Thomas. 2006. Elements of Information Theory .Wiley-Interscience New York.Google Scholar"",""G. A. Darbellay and I. Vajda. 1999. Estimation of the information by an adaptive partitioning of the observation space. IEEETIT, Vol. 45 (1999), 1315--1321.Google ScholarDigital Library"",""P. Fr\""anti and S. Sieranoja. 2018. K-means properties on six clustering benchmark datasets. Appl. Intell., Vol. 48 (2018), 4743--4759.Google ScholarDigital Library"",""S. Gao, G. V. Steeg, and A. Galstyan. 2015. Estimating Mutual Information by Local Gaussian Approximation. In UAI. 278--287.Google Scholar"",""W. Gao, S. Kannan, S. Oh, and P. Viswanath. 2017. Estimating Mutual Information for Discrete-Continuous Mixtures. In NIPS. 5988----5999.Google Scholar"",""C. Giannella and E. L. Robertson. 2004. On approximation measures for functional dependencies. Information Systems, Vol. 29 (2004), 483--507.Google ScholarDigital Library"",""B. R. Goldsmith, M. Boley, J. Vreeken, M. Scheffler, and L. M. Ghiringhelli. 2017. Uncovering structure-property relationships of materials by subgroup discovery. New Journal of Physics, Vol. 19, Article 013031 (2017), 14 pages.Google ScholarCross Ref"",""T. Hey, S. Tansley, K. M. Tolle, and others. 2009. The fourth paradigm: data-intensive scientific discovery. Vol. 1. Microsoft research Redmond, WA.Google Scholar"",""J. Jiao, K. Venkat, Y. Han, and T. Weissman. 2015. Minimax Estimation of Functionals of Discrete Distributions. IEEETIT, Vol. 61, 5 (May 2015), 2835--2885.Google Scholar"",""J. B. Kinney and G. S. Atwal. 2014. Equitability, mutual information, and the maximal information coefficient. PNAS, Vol. 111 (2014), 3354--3359.Google ScholarCross Ref"",""A. Kraskov, H. Stögbauer, and P. Grassberger. 2004. Estimating mutual information. Phys. Rev. E, Vol. 69 (2004), 066138.Google ScholarCross Ref"",""H. Lancaster. 1969. The chi-squared distribution. Wiley.Google Scholar"",""P. Mandros, M. Boley, and J. Vreeken. 2017. Discovering reliable approximate functional dependencies. In KDD. 355--363.Google Scholar"",""P. Mandros, M. Boley, and J. Vreeken. 2018. Discovering reliable dependencies from data: Hardness and improved algorithms. In ICDM. 317--326.Google Scholar"",""M. Nielsen. 2011. Reinventing discovery: the new era of networked science .Princeton University Press.Google Scholar"",""L. Paninski and M. Yajima. 2008. Undersmoothed Kernel Entropy Estimators. IEEETIT, Vol. 54 (2008), 4384--4388.Google ScholarDigital Library"",""T. Papenbrock, J. Ehrlich, J. Marten, T. Neubert, J.-P. Rudolph, M. Schönberg, J. Zwiener, and F. Naumann. 2015. Functional dependency discovery: An experimental evaluation of seven algorithms. PVLDB, Vol. 8 (2015), 1082--1093.Google ScholarDigital Library"",""F. Pennerath. 2018. An Efficient Algorithm for Computing Entropic Measures of Feature Subsets. In ECML-PKDD. Springer, 483--499.Google Scholar"",""D. N. Reshef, Y. A. Reshef, H. K. Finucane, S. R. Grossman, G. McVean, P. J. Turnbaugh, E. S. Lander, M. Mitzenmacher, and P. C. Sabeti. 2011. Detecting Novel Associations in Large Data Sets. Science, Vol. 334 (2011), 1518--1524.Google ScholarCross Ref"",""S. Romano, N. X. Vinh, J. Bailey, and K. Verspoor. 2016. A Framework to Adjust Dependency Measure Estimates for Chance. In SDM. 423--431.Google Scholar"",""M. S. Roulston. 1999. Estimating the errors on measured entropy and mutual information. Physica D, Vol. 125 (1999), 285--294.Google ScholarDigital Library"",""J. Silva and S. Narayanan. 2010. Nonproduct Data-Dependent Partitions for Mutual Information Estimation: Strong Consistency and Applications. IEEE Trans. Sig. Proc., Vol. 58 (2010), 3497--3511.Google ScholarDigital Library"",""M. Sugiyama and K. M. Borgwardt. 2013. Measuring Statistical Dependence via the Mutual Information Dimension. In IJCAI. 1692----1698.Google Scholar"",""J. Suzuki. 2019. Mutual Information Estimation: Independence Detection and Consistency. In ISIT. 2514--2518.Google Scholar"",""I. Tsamardinos, C. Aliferis, A. Statnikov, and E. Statnikov. 2003. Algorithms for Large Scale Markov Blanket Discovery. In FLAIRS. 376--380.Google Scholar"",""N. X. Vinh, J. Chan, and J. Bailey. 2014. Reconsidering mutual information based feature selection: A statistical significance view. In AAAI.Google Scholar"",""N. X. Vinh, J. Epps, and J. Bailey. 2009. Information theoretic measures for clusterings comparison: is a correction for chance necessary?. In ICML. 1073--1080.Google Scholar""]"
https://doi.org/10.1145/3394486.3403194,Attackability Characterization of Adversarial Evasion Attack on Discrete Data,"Evasion attack on discrete data is a challenging, while practically interesting research topic. It is intrinsically an NP-hard combinatorial optimization problem. Characterizing the conditions guaranteeing the solvability of an evasion attack task thus becomes the key to understand the adversarial threat. Our study is inspired by the weak submodularity theory. We characterize the attackability of a targeted classifier on discrete data in evasion attack by bridging the attackability measurement and the regularity of the targeted classifier. Based on our attackability analysis, we propose a computationally efficient orthogonal matching pursuit-guided attack method for evasion attack on discrete data. It provides provably computational efficiency and attack performances. Substantial experimental results on real-world datasets validate the proposed attackability conditions and the effectiveness of the proposed attack method.","[{""name"":""Yutong Wang"",""id"":""/profile/99659574540""},{""name"":""Yufei Han"",""id"":""/profile/99659575219""},{""name"":""Hongyan Bao"",""id"":""/profile/99659573850""},{""name"":""Yun Shen"",""id"":""/profile/99659573076""},{""name"":""Fenglong Ma"",""id"":""/profile/99659575182""},{""name"":""Jin Li"",""id"":""/profile/81442601483""},{""name"":""Xiangliang Zhang"",""id"":""/profile/81436599318""},{""name"":""Yutong Wang"",""id"":""/profile/99659574540""},{""name"":""Yufei Han"",""id"":""/profile/99659575219""},{""name"":""Hongyan Bao"",""id"":""/profile/99659573850""},{""name"":""Yun Shen"",""id"":""/profile/99659573076""},{""name"":""Fenglong Ma"",""id"":""/profile/99659575182""},{""name"":""Jin Li"",""id"":""/profile/81442601483""},{""name"":""Xiangliang Zhang"",""id"":""/profile/81436599318""}]","[""A. Akbarnejad and S. Günnemann. Adversarial attacks on node embedding via graph poisoning. In ICML, 2019.Google Scholar"",""I.M. Alabdulmohsin., X. Gao, and X. Zhang. Adding robustness to support vector machines against adversarial reverse engineering. In CIKM, page 231--240, 2014.Google Scholar"",""I.M. Alabdulmohsin., X. Gao, and X. Zhang. Efficient active learning of halfspaces via query synthesis. In AAAI, page 2483--2489, 2015.Google Scholar"",""B. Nelson B. Biggio and P. Laskov. Poisoning attacks against support vector machines. In ICML, 2012.Google ScholarDigital Library"",""J. Bilmes and W. Bai. Deep submodular functions. arXiv preprint arXiv:1701.08939, 2017.Google Scholar"",""Nicholas Carlini and David Wagner. Towards evaluating the robustness of neural networks. In IEEE S\u0026P, 2017.Google Scholar"",""Nicholas Carlini and David Wagner. Audio adversarial examples: Targeted attacks on speech-to-text. In SPW, 2018.Google ScholarCross Ref"",""L. Chen, M. Feldman, and A. Karbasi. Weakly submodular maximization beyond cardinality constraints: Does randomization help greedy? In ICML, 2017.Google Scholar"",""A. Akbarnejad D. Zügner and S. Günnemann. Adversarial attacks on neural networks for graph data. In KDD, 2018.Google ScholarDigital Library"",""A. Das and D. Kempe. Submodular meets spectral: Greedy algorithms for subset selection, sparse approximation and dictionary selection. In ICML, 2011.Google ScholarDigital Library"",""D. Zugner, A. Akbarnejad, and S. Gunnemann. Adversarial attacks on neural networks for graph data. In IJCAI, 2019.Google ScholarCross Ref"",""Javid Ebrahimi, Anyi Rao, Daniel Lowd, and Dejing Dou. HotFlip: White-box adversarial examples for text classification. In ACL, 2018.Google ScholarCross Ref"",""E. R. Elenberg, R. Khanna, A. G. Dimakis, and Sahand Negahban. Restricted strong convexity implies weak submodularity. Annuals of Statistics, 2016.Google Scholar"",""J. Gao F. Ma, Q. Suo, Q. You, J. Zhou, and A. Zhang. Risk prediction on electronic health records with prior medical knowledge. In KDD, 2018.Google ScholarDigital Library"",""J. Gao, J. Lanchantin, M. L. Soffa, and Y. Qi. Black-box generation of adversarial text sequences to evade deep learning classifiers. In SPW, pages 50--56, 2018.Google ScholarCross Ref"",""Z. Gong, W. Wang, B. Li, D. Song, and W. Ku. Adversarial texts with gradient methods. ArXiv, abs/1801.07175, 2018.Google Scholar"",""I. Goodfellow, J. Shlens, and C. Szegedy. Explaining and harnessing adversarial examples. In ICLR, 2015.Google Scholar"",""A. Hassidim and Y. Singer. Robust guarantees of stochastic greedy algorithms. In ICLR, 2017.Google Scholar"",""K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In CVPR, 2016.Google ScholarCross Ref"",""C. JE, C. GR, Chai T, M. M, Tang Y, B. DR, B. NJ, V. SA, C. GJ, B. I, B.JA, M. SA, S. C, S. JL, and S. CO. Photosynthetic control of atmospheric carbonyl sulfide during the growing season. Science, 322, 2008.Google Scholar"",""V. Kuleshov, S. Thakoor, T. Lau, and S. Ermon. Adversarial examples for natural language classification problems. In ICLR, 2018.Google Scholar"",""T. Miyato, A. M. Dai, and I.J. Goodfellow. Adversarial training methods for semi-supervised text classification. In ICLR, 2016.Google Scholar"",""G. Nemhauser M.L. Fisher and L.A. Wolsey. An analysis of approximations for maximizing submodular set functions. Mathematical Programming, 8, 1978.Google Scholar"",""G. Nemhauser and L.A. Wolsey. An anlaysis of approximations for maximizing submodular set functions. Mathematical Programming, 14, 1978.Google ScholarDigital Library"",""G. Nemhauser and L.A. Wolsey. Best algorithms for approximating the maximum of a submodular set function. Mathematics of Operations Research, 3, 1978.Google Scholar"",""Christos H. Papadimitriou and Kenneth Steiglitz. Combinatorial Optimization: Algorithms and Complexity. Prentice-Hall, Inc., 1982.Google Scholar"",""N. Papernot, P. D. McDaniel, A. Swami, and R. E. Harang. Crafting adversarial input sequences for recurrent neural networks. In MILCOM, 2016.Google ScholarCross Ref"",""Y. C. Pati, R. Rezaiifar, and P. S. Krishnaprasad. Orthogonal matching pursuit: recursive function approximation with applications to wavelet decomposition. In ACSSC, 1993.Google ScholarCross Ref"",""L. Qi, L. Wu, P. Chen, A. Dimakis, and and M. Witbrock I. Dhillon. Discrete attacks and submodular optimization with applications to text classification. In SysML, 2019.Google Scholar"",""S. Samanta and S. Mehta. Towards crafting text adversarial samples. CoRR, abs/1707.02812, 2017.Google Scholar"",""C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. J. Goodfellow, and R. Fergus. Intriguing properties of neural networks. In ICLR, 2013.Google Scholar"",""H. Xu, Y. Ma, H. Liu, D. Deb, H. Liu, J. Tang, and A. K. Jain. Adversarial attacks and defenses in images, graphs and text: A review, 2019.Google Scholar"",""P. Yang, J. Chen, C. Hsieh, J. Wang, and M. I. Jordan. Greedy attack and gumbel attack: Generating adversarial examples for discrete data. ArXiv, abs/1805.12316, 2018.Google Scholar"",""Y. Yao, B. Viswanath, J. Cryan, H. Zheng, and B. Zhao. Automated crowdturfing attacks and defenses in online review systems. In ACM CCS, 2017.Google ScholarDigital Library"",""F. Zhang, P. P. K. Chan, B. Biggio, D. S. Yeung, and F. Roli. Adversarial feature selection against evasion attacks. IEEE Transactions on Cybernetics, 46, 2016.Google Scholar""]"
https://doi.org/10.1145/3394486.3403195,The Spectral Zoo of Networks: Embedding and Visualizing Networks with Spectral Moments,"Network embedding methods have been widely and successfully used in network-based applications such as node classification and link prediction. However, an ideal network embedding should not only be useful for machine learning, but interpretable. We introduce a spectral embedding method for a network, its Spectral Point, which is basically the first few spectral moments of a network. Spectral moments are interpretable, where we prove their close relationships to network structure (e.g. number of triangles and squares) and various network properties (e.g. degree distribution, clustering coefficient, and network connectivity). Using spectral points, we introduce a visualizable and bounded 3D embedding space for all possible graphs, in which one can characterize various types of graphs (e.g., cycles), or real-world networks from different categories (e.g., social or biological networks). We demonstrate that spectral points can be used for network identification (i.e., what network is this subgraph sampled from?) and that by using just the first few moments one does not lose much predictive power.","[{""name"":""Shengmin Jin"",""id"":""/profile/99659217048""},{""name"":""Reza Zafarani"",""id"":""/profile/81309493801""},{""name"":""Shengmin Jin"",""id"":""/profile/99659217048""},{""name"":""Reza Zafarani"",""id"":""/profile/81309493801""}]","[""Lada A Adamic, Rajan M Lukose, Amit R Puniyani, and Bernardo A Huberman. 2001. Search in power-law networks. Physical review E, Vol. 64, 4 (2001), 046135.Google Scholar"",""Lars Backstrom and Jure Leskovec. 2011. Supervised random walks: predicting and recommending links in social networks. In Proceedings of the fourth ACM international conference on Web search and data mining. ACM, 635--644.Google ScholarDigital Library"",""Albert-László Barabási and Eric Bonabeau. 2003. Scale-free networks. Scientific american, Vol. 288, 5 (2003), 60--69.Google Scholar"",""Stephen P Borgatti and Martin G Everett. 2000. Models of core/periphery structures. Soc. networks, Vol. 21, 4 (2000), 375--395.Google Scholar"",""Anna D Broido and Aaron Clauset. 2019. Scale-free networks are rare. Nature communications, Vol. 10, 1 (2019), 1--10.Google Scholar"",""Xiaodan Chen and Jianguo Qian. 2014. Bounds on the number of closed walks in a graph and its applications. Journal of Inequalities and Applications, Vol. 2014, 1 (2014), 1--9.Google ScholarCross Ref"",""Fan RK Chung and Fan Chung Graham. 1997. Spectral graph theory. Number 92. American Mathematical Soc.Google Scholar"",""David Cohen-Steiner, Weihao Kong, Christian Sohler, and Gregory Valiant. 2018. Approximating the Spectrum of a Graph. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 1263--1271.Google ScholarDigital Library"",""Kun Dong, Austin R Benson, and David Bindel. 2019. Network Density of States. arXiv preprint arXiv:1905.09758 (2019).Google Scholar"",""Ernesto Estrada. 2002. Characterization of the folding degree of proteins. Bioinformatics, Vol. 18, 5 (2002), 697--704.Google ScholarCross Ref"",""Michalis Faloutsos, Petros Faloutsos, and Christos Faloutsos. 1999. On power-law relationships of the internet topology. ACM SIGCOMM computer communication review, Vol. 29, 4 (1999), 251--262.Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In Proceedings of the 22nd ACM SIGKDD conference. ACM, 855--864.Google ScholarDigital Library"",""William L Hamilton, Rex Ying, and Jure Leskovec. 2017. Representation Learning on Graphs: Methods and Applications. arXiv preprint arXiv:1709.05584 (2017).Google Scholar"",""Alan J Hoffman. 2003. On eigenvalues and colorings of graphs. In Selected Papers Of Alan J Hoffman: With Commentary. World Scientific, 407--419.Google Scholar"",""Hawoong Jeong, Bálint Tombor, Réka Albert, Zoltan N Oltvai, and A-L Barabási. 2000. The large-scale organization of metabolic networks. Nature, Vol. 407, 6804 (2000), 651--654.Google ScholarCross Ref"",""Shengmin Jin, Vir V Phoha, and Reza Zafarani. 2019. Network Identification and Authentication. In 2019 IEEE International Conference on Data Mining (ICDM). IEEE.Google Scholar"",""Shengmin Jin and Reza Zafarani. 2018. Representing Networks with 3D Shapes. In 2018 IEEE International Conference on Data Mining (ICDM). IEEE, 177--186.Google ScholarCross Ref"",""Danai Koutra, Ankur Parikh, Aaditya Ramdas, and Jing Xiang. 2011. Algorithms for graph similarity and subgraph matching. In Proc. Ecol. Inference Conf.Google Scholar"",""Jure Leskovec and Andrej Krevl. 2014. SNAP Datasets: Stanford Large Network Dataset Collection. http://snap.stanford.edu/data.Google Scholar"",""Feng Luo, Bo Li, Xiu-Feng Wan, and Richard H Scheuermann. 2009. Core and periphery structures in protein interaction networks. In Bmc Bioinformatics, Vol. 10. BioMed Central, S8.Google ScholarCross Ref"",""Stanley Milgram. 1967. The small world problem. Psychology today, Vol. 2, 1 (1967), 60--67.Google Scholar"",""Ron Milo, Shai Shen-Orr, Shalev Itzkovitz, Nadav Kashtan, Dmitri Chklovskii, and Uri Alon. 2002. Network motifs: simple building blocks of complex networks. Science, Vol. 298, 5594 (2002), 824--827.Google Scholar"",""Andrew Y Ng, Michael I Jordan, and Yair Weiss. 2002. On spectral clustering: Analysis and an algorithm. In Advances in neural information processing systems. 849--856.Google Scholar"",""Giuliano Andrea Pagani and Marco Aiello. 2013. The power grid as a complex network: a survey. Physica A: Statistical Mechanics and its Applications, Vol. 392, 11 (2013), 2688--2700.Google Scholar"",""Iosif Pinelis. 2011. Relations between the first four moments. arXiv preprint arXiv:1111.6220 (2011).Google Scholar"",""Victor M Preciado and Ali Jadbabaie. 2012. Moment-based spectral analysis of large-scale networks using local structural information. IEEE/ACM Transactions on Networking, Vol. 21, 2 (2012), 373--382.Google ScholarDigital Library"",""Victor M Preciado, Ali Jadbabaie, and George C Verghese. 2013. Structural analysis of Laplacian spectral properties of large-scale networks. IEEE Trans. Automat. Control, Vol. 58, 9 (2013), 2338--2343.Google ScholarCross Ref"",""Ryan Rossi and Nesreen Ahmed. 2015. The Network Data Repository with Interactive Graph Analytics and Visualization.. In AAAI, Vol. 15. 4292--4293.Google Scholar"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. In Proceedings of the 24th International Conference on World Wide Web. 1067--1077.Google ScholarDigital Library"",""Kevin Tian, Weihao Kong, and Gregory Valiant. 2017. Learning populations of parameters. In Advances in neural information processing systems. 5778--5787.Google Scholar"",""Lloyd N Trefethen. 2013. Approximation theory and approximation practice. Vol. 128. Siam.Google Scholar"",""Anton Tsitsulin, Davide Mottin, Panagiotis Karras, Alexander Bronstein, and Emmanuel Müller. 2018. Netlsd: hearing the shape of a graph. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 2347--2356.Google ScholarDigital Library"",""Johan Ugander, Brian Karrer, Lars Backstrom, and Cameron Marlow. 2011. The anatomy of the facebook social graph. arXiv preprint arXiv:1111.4503 (2011).Google Scholar"",""Saurabh Verma and Zhi-Li Zhang. 2017. Hunt for the unique, stable, sparse and fast feature learning on graphs. In Advances in Neural Information Processing Systems. 88--98.Google Scholar"",""Duncan J Watts and Steven H Strogatz. 1998. Collective dynamics of 'small-world'networks. nature, Vol. 393, 6684 (1998), 440.Google Scholar"",""Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2018. How powerful are graph neural networks? arXiv preprint arXiv:1810.00826 (2018).Google Scholar"",""Soon-Hyung Yook, Zoltán N Oltvai, and Albert-László Barabási. 2004. Functional and topological characterization of protein interaction networks. Proteomics, Vol. 4, 4 (2004), 928--942.Google ScholarCross Ref"",""R. Zafarani and H. Liu. 2009. Social Computing Data Repository at ASU. http://socialcomputing.asu.eduGoogle Scholar"",""Xiao Zhang, Travis Martin, and Mark EJ Newman. 2015a. Identification of core-periphery structure in networks. Physical Review E, Vol. 91, 3 (2015), 032803.Google ScholarCross Ref"",""Yutao Zhang, Jie Tang, Zhilin Yang, Jian Pei, and Philip S Yu. 2015b. Cosnet: Connecting heterogeneous social networks with local and global consistency. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 1485--1494.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403196,Unsupervised Differentiable Multi-aspect Network Embedding,"Network embedding is an influential graph mining technique for representing nodes in a graph as distributed vectors. However, the majority of network embedding methods focus on learning a single vector representation for each node, which has been recently criticized for not being capable of modeling multiple aspects of a node. To capture the multiple aspects of each node, existing studies mainly rely on offline graph clustering performed prior to the actual embedding, which results in the cluster membership of each node (i.e., node aspect distribution) fixed throughout training of the embedding model. We argue that this not only makes each node always have the same aspect distribution regardless of its dynamic context, but also hinders the end-to-end training of the model that eventually leads to the final embedding quality largely dependent on the clustering. In this paper, we propose a novel end-to-end framework for multi-aspect network embedding, called asp2vec, in which the aspects of each node are dynamically assigned based on its local context. More precisely, among multiple aspects, we dynamically assign a single aspect to each node based on its current context, and our aspect selection module is end-to-end differentiable via the Gumbel-Softmax trick. We also introduce the aspect regularization framework to capture the interactions among the multiple aspects in terms of relatedness and diversity. We further demonstrate that our proposed framework can be readily extended to heterogeneous networks. Extensive experiments towards various downstream tasks on various types of homogeneous networks and a heterogeneous network demonstrate the superiority of asp2vec.","[{""name"":""Chanyoung Park"",""id"":""/profile/99658745207""},{""name"":""Carl Yang"",""id"":""/profile/99659154893""},{""name"":""Qi Zhu"",""id"":""/profile/99659259437""},{""name"":""Donghyun Kim"",""id"":""/profile/99658748702""},{""name"":""Hwanjo Yu"",""id"":""/profile/81452596142""},{""name"":""Jiawei Han"",""id"":""/profile/81548005096""},{""name"":""Chanyoung Park"",""id"":""/profile/99658745207""},{""name"":""Carl Yang"",""id"":""/profile/99659154893""},{""name"":""Qi Zhu"",""id"":""/profile/99659259437""},{""name"":""Donghyun Kim"",""id"":""/profile/99658748702""},{""name"":""Hwanjo Yu"",""id"":""/profile/81452596142""},{""name"":""Jiawei Han"",""id"":""/profile/81548005096""}]","[""Sami Abu-El-Haija, Bryan Perozzi, and Rami Al-Rfou. 2017. Learning edge representations via low-rank asymmetric projections. In CIKM.Google Scholar"",""Babajide O Ayinde, Tamer Inanc, and Jacek M Zurada. 2019. Regularizing deep neural networks by enhancing diversity in feature extraction. TNNLS (2019).Google Scholar"",""Hongxu Chen, Hongzhi Yin, Weiqing Wang, Hao Wang, Quoc Viet Hung Nguyen, and Xue Li. 2018. PME: projected metric embedding on heterogeneous networks for link prediction. In KDD.Google Scholar"",""Ting Chen and Yizhou Sun. 2017. Task-guided and path-augmented heterogeneous network embedding for author identification. In WSDM.Google Scholar"",""Yuxiao Dong, Nitesh V Chawla, and Ananthram Swami. 2017. metapath2vec: Scalable representation learning for heterogeneous networks. In KDD.Google Scholar"",""Alessandro Epasto and Bryan Perozzi. 2019. Is a single embedding enough? learning node representations that capture multiple social contexts. In WWW.Google Scholar"",""Tao-yang Fu, Wang-Chien Lee, and Zhen Lei. 2017. Hin2vec: Explore meta-paths in heterogeneous information networks for representation learning. In CIKM.Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In KDD.Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In NeurIPS.Google Scholar"",""Binbin Hu, Chuan Shi, Wayne Xin Zhao, and Philip S Yu. 2018. Leveraging meta-path based context for top-n recommendation with a neural co-attention model. In KDD.Google Scholar"",""Rana Hussein, Dingqi Yang, and Philippe Cudré-Mauroux. 2018. Are Meta-Paths Necessary? Revisiting Heterogeneous Graph Embeddings. In CIKM.Google Scholar"",""Eric Jang, Shixiang Gu, and Ben Poole. 2016. Categorical reparameterization with gumbel-softmax. arXiv preprint arXiv:1611.01144 (2016).Google Scholar"",""Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).Google Scholar"",""Qimai Li, Zhichao Han, and Xiao-Ming Wu. 2018. Deeper insights into graph convolutional networks for semi-supervised learning. In AAAI.Google Scholar"",""Ninghao Liu, Qiaoyu Tan, Yuening Li, Hongxia Yang, Jingren Zhou, and Xia Hu. 2019. Is a single vector enough? exploring node polysemy for network embedding. In KDD.Google Scholar"",""Jianxin Ma, Peng Cui, Kun Kuang, Xin Wang, and Wenwu Zhu. 2019. Disentangled graph convolutional networks. In ICML.Google Scholar"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In NeurIPS.Google Scholar"",""Chanyoung Park, Donghyun Kim, Jiawei Han, and Hwanjo Yu. 2019 a. Unsupervised Attributed Multiplex Network Embedding. arXiv preprint arXiv:1911.06750 (2019).Google Scholar"",""Chanyoung Park, Donghyun Kim, Qi Zhu, Jiawei Han, and Hwanjo Yu. 2019 b. Task-Guided Pair Embedding in Heterogeneous Network. In CIKM.Google Scholar"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In KDD.Google ScholarDigital Library"",""Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2012. BPR: Bayesian personalized ranking from implicit feedback. arXiv preprint arXiv:1205.2618 (2012).Google Scholar"",""Leonardo FR Ribeiro, Pedro HP Saverese, and Daniel R Figueiredo. 2017. struc2vec: Learning node representations from structural identity. In KDD.Google Scholar"",""Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den Berg, Ivan Titov, and Max Welling. 2018. Modeling relational data with graph convolutional networks. In ESWC.Google Scholar"",""Yu Shi, Qi Zhu, Fang Guo, Chao Zhang, and Jiawei Han. 2018. Easing embedding learning by comprehensive transcription of heterogeneous information networks. In KDD.Google Scholar"",""Fan-Yun Sun, Meng Qu, Jordan Hoffmann, Chin-Wei Huang, and Jian Tang. 2019. vGraph: A Generative Model for Joint Community Detection and Node Representation Learning. In NeurIPS.Google Scholar"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph attention networks. arXiv preprint arXiv:1710.10903 (2017).Google Scholar"",""Petar Velivc ković, William Fedus, William L Hamilton, Pietro Liò, Yoshua Bengio, and R Devon Hjelm. 2018. Deep graph infomax. arXiv preprint arXiv:1809.10341 (2018).Google Scholar"",""Hao Wang, Tong Xu, Qi Liu, Defu Lian, Enhong Chen, Dongfang Du, Han Wu, and Wen Su. 2019 b. MCNE: An End-to-End Framework for Learning Multiple Conditional Network Representations of Social Network. In KDD.Google Scholar"",""Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, and Philip S Yu. 2019 a. Heterogeneous graph attention network. In WWW.Google Scholar"",""Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and Philip S Yu. 2019. A comprehensive survey on graph neural networks. arXiv preprint arXiv:1901.00596 (2019).Google Scholar"",""Liang Yang, Yuanfang Guo, and Xiaochun Cao. 2018. Multi-facet network embedding: Beyond the general solution of detection and representation. In AAAI.Google Scholar"",""Chuxu Zhang, Chao Huang, Lu Yu, Xiangliang Zhang, and Nitesh V Chawla. 2018. Camel: Content-aware and meta-path augmented metric learning for author identification. In WWW.Google Scholar"",""Peng Zhou, Wei Shi, Jun Tian, Zhenyu Qi, Bingchen Li, Hongwei Hao, and Bo Xu. 2016. Attention-based bidirectional long short-term memory networks for relation classification. In ACL.Google Scholar""]"
https://doi.org/10.1145/3394486.3403197,AutoML Pipeline Selection: Efficiently Navigating the Combinatorial Space,"Data scientists seeking a good supervised learning model on a dataset have many choices to make: they must preprocess the data, select features, possibly reduce the dimension, select an estimation algorithm, and choose hyperparameters for each of these pipeline components. With new pipeline components comes a combinatorial explosion in the number of choices! In this work, we design a new AutoML system TensorOboe to address this challenge: an automated system to design a supervised learning pipeline. TensorOboe uses low rank tensor decomposition as a surrogate model for efficient pipeline search. We also develop a new greedy experiment design protocol to gather information about a new dataset efficiently. Experiments on large corpora of real-world classification problems demonstrate the effectiveness of our approach.","[{""name"":""Chengrun Yang"",""id"":""/profile/99659454891""},{""name"":""Jicong Fan"",""id"":""/profile/99659575025""},{""name"":""Ziyang Wu"",""id"":""/profile/99659573028""},{""name"":""Madeleine Udell"",""id"":""/profile/99658655855""},{""name"":""Chengrun Yang"",""id"":""/profile/99659454891""},{""name"":""Jicong Fan"",""id"":""/profile/99659575025""},{""name"":""Ziyang Wu"",""id"":""/profile/99659573028""},{""name"":""Madeleine Udell"",""id"":""/profile/99658655855""}]","[""Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W Hoffman, David Pfau, Tom Schaul, Brendan Shillingford, and Nando De Freitas. 2016. Learning to learn by gradient descent by gradient descent. In Advances in neural information processing systems. 3981--3989.Google Scholar"",""George EP Box. 1976. Science and statistics. J. Amer. Statist. Assoc., Vol. 71, 356 (1976), 791--799.Google ScholarCross Ref"",""Stephen Boyd and Lieven Vandenberghe. 2004. Convex optimization. Cambridge University Press.Google Scholar"",""Leo Breiman. 1996. Bagging predictors. Machine learning, Vol. 24, 2 (1996), 123--140.Google Scholar"",""J Douglas Carroll and Jih-Jie Chang. 1970. Analysis of individual differences in multidimensional scaling via an N-way generalization of “Eckart-Young\"" decomposition. Psychometrika, Vol. 35, 3 (1970), 283--319.Google ScholarCross Ref"",""Arthur P Dempster, Nan M Laird, and Donald B Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society: Series B (Methodological), Vol. 39, 1 (1977), 1--22.Google ScholarCross Ref"",""Thomas G Dietterich. 2000. Ensemble methods in machine learning. In International workshop on multiple classifier systems. Springer, 1--15.Google ScholarDigital Library"",""Iddo Drori, Yamuna Krishnamurthy, Remi Rampin, Raoni Lourencc o, J One, Kyunghyun Cho, Claudio Silva, and Juliana Freire. 2018. AlphaD3M: Machine learning pipeline synthesis. In AutoML Workshop at ICML.Google Scholar"",""Iddo Drori, Lu Liu, Yi Nian, Sharath C Koorathota, Jie S Li, Antonio Khalil Moretti, Juliana Freire, and Madeleine Udell. 2019. AutoML using Metadata Language Embeddings. arXiv preprint arXiv:1910.03698 (2019).Google Scholar"",""Dheeru Dua and Casey Graff. 2017. UCI Machine Learning Repository. http://archive.ics.uci.edu/mlGoogle Scholar"",""Matthias Feurer, Aaron Klein, Katharina Eggensperger, Jost Springenberg, Manuel Blum, and Frank Hutter. 2015. Efficient and robust automated machine learning. In Advances in neural information processing systems. 2962--2970.Google Scholar"",""Matthias Feurer, Jost Tobias Springenberg, and Frank Hutter. 2014. Using meta-learning to initialize Bayesian optimization of hyperparameters. In International Conference on Meta-learning and Algorithm Selection. Citeseer, 3--10.Google ScholarDigital Library"",""Matthias Feurer, Jan N van Rijn, Arlind Kadra, Pieter Gijsbers, Neeratyoy Mallik, Sahithya Ravi, Andreas Müller, Joaquin Vanschoren, and Frank Hutter. 2019. OpenML-Python: an extensible Python API for OpenML. arXiv preprint arXiv:1911.02490 (2019).Google Scholar"",""Nicolo Fusi, Rishit Sheth, and Melih Elibol. 2018. Probabilistic matrix factorization for automated machine learning. In Advances in Neural Information Processing Systems. 3348--3357.Google Scholar"",""Timur Garipov, Pavel Izmailov, Dmitrii Podoprikhin, Dmitry P Vetrov, and Andrew G Wilson. 2018. Loss surfaces, mode connectivity, and fast ensembling of dnns. In Advances in Neural Information Processing Systems. 8789--8798.Google Scholar"",""Gene H Golub and Charles F Van Loan. 2012. Matrix computations. Vol. 3. JHU press.Google Scholar"",""Ming Gu and Stanley C Eisenstat. 1996. Efficient algorithms for computing a strong rank-revealing QR factorization. SIAM Journal on Scientific Computing, Vol. 17, 4 (1996), 848--869.Google ScholarDigital Library"",""William W Hager. 1989. Updating the inverse of a matrix. SIAM review, Vol. 31, 2 (1989), 221--239.Google Scholar"",""Richard A Harshman et al. 1970. Foundations of the PARAFAC procedure: Models and conditions for an \""explanatory\"" multimodal factor analysis. (1970).Google Scholar"",""David A Harville. 1998. Matrix algebra from a statistician's perspective.Google Scholar"",""Frank Hutter, Lin Xu, Holger H Hoos, and Kevin Leyton-Brown. 2014. Algorithm runtime prediction: Methods \u0026 evaluation. Artificial Intelligence, Vol. 206 (2014), 79--111.Google ScholarDigital Library"",""RC St John and Norman R Draper. 1975. D-optimality for regression designs: a review. Technometrics, Vol. 17, 1 (1975), 15--23.Google ScholarCross Ref"",""Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping Tak Peter Tang. 2017. On large-batch training for deep learning: Generalization gap and sharp minima. (2017).Google Scholar"",""Tamara G Kolda and Brett W Bader. 2009. Tensor decompositions and applications. SIAM review, Vol. 51, 3 (2009), 455--500.Google Scholar"",""Brenden M Lake, Tomer D Ullman, Joshua B Tenenbaum, and Samuel J Gershman. 2017. Building machines that learn and think like people. Behavioral and brain sciences, Vol. 40 (2017).Google Scholar"",""Hao Li, Zheng Xu, Gavin Taylor, Christoph Studer, and Tom Goldstein. 2018. Visualizing the loss landscape of neural nets. In Advances in Neural Information Processing Systems. 6389--6399.Google Scholar"",""Sijia Liu, Parikshit Ram, Deepak Vijaykeerthy, Djallel Bouneffouf, Gregory Bramble, Horst Samulowitz, Dakuo Wang, Andrew Conn, and Alexander Gray. 2019. An ADMM Based Framework for AutoML Pipeline Configuration. arXiv preprint arXiv:1905.00424 (2019).Google Scholar"",""Vivek Madan, Mohit Singh, Uthaipon Tantipongpipat, and Weijun Xie. 2019. Combinatorial Algorithms for Optimal Design. In Conference on Learning Theory. 2210--2258.Google Scholar"",""George L Nemhauser, Laurence A Wolsey, and Marshall L Fisher. 1978. An analysis of approximations for maximizing submodular set functions-I. Mathematical programming, Vol. 14, 1 (1978), 265--294.Google Scholar"",""Randal S Olson and Jason H Moore. 2019. TPOT: A tree-based pipeline optimization tool for automating machine learning. In Automated Machine Learning. Springer, 151--160.Google Scholar"",""Ivan V Oseledets. 2011. Tensor-train decomposition. SIAM Journal on Scientific Computing, Vol. 33, 5 (2011), 2295--2317.Google ScholarDigital Library"",""F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011. Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, Vol. 12 (2011), 2825--2830.Google ScholarDigital Library"",""Bernhard Pfahringer, Hilan Bensusan, and Christophe G Giraud-Carrier. 2000. Meta-Learning by Landmarking Various Learning Algorithms. In ICML. 743--750.Google Scholar"",""Friedrich Pukelsheim. 1993. Optimal design of experiments. Vol. 50. SIAM.Google Scholar"",""Robert E Schapire. 2003. The boosting approach to machine learning: An overview. In Nonlinear estimation and classification. Springer, 149--171.Google Scholar"",""Zeyuan Shang, Emanuel Zgraggen, Benedetto Buratti, Ferdinand Kossmann, Philipp Eichmann, Yeounoh Chung, Carsten Binnig, Eli Upfal, and Tim Kraska. 2019. Democratizing data science through interactive curation of ml pipelines. In Proceedings of the 2019 International Conference on Management of Data. 1171--1188.Google ScholarDigital Library"",""Jack Sherman and Winifred J Morrison. 1950. Adjustment of an inverse matrix corresponding to a change in one element of a given matrix. The Annals of Mathematical Statistics, Vol. 21, 1 (1950), 124--127.Google ScholarCross Ref"",""Qingquan Song, Hancheng Ge, James Caverlee, and Xia Hu. 2019. Tensor completion algorithms in big data analytics. ACM Transactions on Knowledge Discovery from Data (TKDD), Vol. 13, 1 (2019), 1--48.Google Scholar"",""Sebastian Thrun and Lorien Pratt. 2012. Learning to learn .Springer Science \u0026 Business Media.Google Scholar"",""Ledyard R Tucker. 1966. Some mathematical notes on three-mode factor analysis. Psychometrika, Vol. 31, 3 (1966), 279--311.Google ScholarCross Ref"",""Joaquin Vanschoren. 2018. Meta-learning: A survey. arXiv preprint arXiv:1810.03548 (2018).Google Scholar"",""Joaquin Vanschoren, Jan N. van Rijn, Bernd Bischl, and Luis Torgo. 2013. OpenML: Networked Science in Machine Learning. SIGKDD Explorations, Vol. 15, 2 (2013), 49--60. https://doi.org/10.1145/2641190.2641198Google ScholarDigital Library"",""Abraham Wald. 1943. On the efficient design of statistical investigations. The Annals of Mathematical Statistics, Vol. 14, 2 (1943), 134--140.Google ScholarCross Ref"",""M. Wistuba, N. Schilling, and L. Schmidt-Thieme. 2015. Learning hyperparameter optimization initializations. In IEEE International Conference on Data Science and Advanced Analytics. 1--10. https://doi.org/10.1109/DSAA.2015.7344817Google Scholar"",""David H Wolpert. 1992. Stacked generalization. Neural networks, Vol. 5, 2 (1992), 241--259.Google Scholar"",""David H Wolpert and William G Macready. 1997. No free lunch theorems for optimization. IEEE transactions on evolutionary computation, Vol. 1, 1 (1997), 67--82.Google Scholar"",""Chengrun Yang, Yuji Akimoto, Dae Won Kim, and Madeleine Udell. 2019. OBOE: Collaborative filtering for AutoML model selection. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1173--1183.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403198,Towards Physics-informed Deep Learning for Turbulent Flow Prediction,"While deep learning has shown tremendous success in a wide range of domains, it remains a grand challenge to incorporate physical principles in a systematic manner to the design, training, and inference of such models. In this paper, we aim to predict turbulent flow by learning its highly nonlinear dynamics from spatiotemporal velocity fields of large-scale fluid flow simulations of relevance to turbulence modeling and climate modeling. We adopt a hybrid approach by marrying two well-established turbulent flow simulation techniques with deep learning. Specifically, we introduce trainable spectral filters in a coupled model of Reynolds-averaged Navier-Stokes (RANS) and Large Eddy Simulation (LES), followed by a specialized U-net for prediction. Our approach, which we call Turbulent-Flow Net, is grounded in a principled physics model, yet offers the flexibility of learned representations. We compare our model with state-of-the-art baselines and observe significant reductions in error for predictions 60 frames ahead. Most importantly, our method predicts physical fields that obey desirable physical characteristics, such as conservation of mass, whilst faithfully emulating the turbulent kinetic energy field and spectrum, which are critical for accurate prediction of turbulent flows.","[{""name"":""Rui Wang"",""id"":""/profile/99659574736""},{""name"":""Karthik Kashinath"",""id"":""/profile/99659035088""},{""name"":""Mustafa Mustafa"",""id"":""/profile/99659573040""},{""name"":""Adrian Albert"",""id"":""/profile/81553377356""},{""name"":""Rose Yu"",""id"":""/profile/99659573955""},{""name"":""Rui Wang"",""id"":""/profile/99659574736""},{""name"":""Karthik Kashinath"",""id"":""/profile/99659035088""},{""name"":""Mustafa Mustafa"",""id"":""/profile/99659573040""},{""name"":""Adrian Albert"",""id"":""/profile/81553377356""},{""name"":""Rose Yu"",""id"":""/profile/99659573955""}]","[""Jordan Read Vipin Kumar Anuj Karpatne, WilliamWatkins. 2017. Physics-guided Neural Networks (PGNN): An Application in Lake Temperature Modeling. arXiv Preprint arXiv:1710.11431 (2017).Google Scholar"",""Michael Chertkov Daniel Livescu Arvind Mohan, Don Daniel. 2019. Compressed Convolutional LSTM: An Efficient Deep Learning Framework to Model High Fidelity 3D Turbulence. arXiv:1903.00033 (2019).Google Scholar"",""Bruno Chaoua. 2017. The State of the Art of Hybrid RANS/LES Modeling for the Simulation of Turbulent Flows. 99 (2017), 279--327. https://doi.org/10.1007/ s10494-017--9828--8Google Scholar"",""Sergey Levine Chelsea Finn, Ian Goodfellow. 2016. Unsupervised Learning for Physical Interaction through Video Prediction. arXiv:1605.07157v4 (2016).Google Scholar"",""D. B. Chirila. 2018. Towards lattice boltzmann models for climate sciences: The GeLB programming language with application. (2018).Google Scholar"",""Mengyu Chu and Nils Thuerey. 2017. Data-driven synthesis of smoke flows with CNN-based feature descriptors. ACM Transactions on Graphics (TOG) 36, 4 (2017), 69.Google ScholarDigital Library"",""P. Sagaut E. Labourasse. 2004. Advance in RANS-LES Coupling, a Review and an Insight on the NLDE Approach. Archives of Computational Methods in Engineering 11 (2004), 199--256.Google ScholarCross Ref"",""Patrick Gallinari Emmanuel de Bezenac, Arthur Pajot. 2018. Deep Learning for Physical Processes: Incorporating Prior Scientific Knowledge. arXiv:1505.04597 (2018).Google Scholar"",""Rui Fang, David Sondak, Pavlos Protopapas, and Sauro Succi. 2018. Deep learning for turbulent channel flow. arXiv preprint arXiv:1812.02241 (2018).Google Scholar"",""Chelsea Finn, Ian Goodfellow, and Sergey Levine. 2016. Unsupervised learning for physical interaction through video prediction. In Advances in neural information processing systems. 64--72.Google Scholar"",""Eugene M. Izhikevich. 2007. Dynamical systems in neuroscience. MIT press.Google Scholar"",""Xiaowei Jia, Jared Willard, Anuj Karpatne, Jordan Read, Jacob Zwart, Michael Steinbach, and Vipin Kumar. 2019. Physics guided RNNs for modeling dynamical systems: A case study in simulating lake temperature profiles. In Proceedings of the 2019 SIAM International Conference on Data Mining. SIAM, 558--566.Google ScholarCross Ref"",""Pablo Sprechmann Ken Perlin Jonathan Tompson, Kristofer Schlachter. 2017. Accelerating eulerian fluid simulation with convolutional networks. In ICML'17 Proceedings of the 34th International Conference on Machine Learning, Vol. 70. 3424--3433.Google Scholar"",""Shaoqing Ren Jian Sun Kaiming He, Xiangyu Zhang. 2015. Deep Residual Learning for Image Recognition. arXiv:1505.04597 (2015).Google Scholar"",""Junhyuk Kim and Changhoon Lee. 2019. Deep unsupervised learning of turbulence for inflow generation at various Reynolds numbers. arXiv:1908.10515 (2019).Google Scholar"",""Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. 2018. Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting. In International Conference on Learning Representations (ICLR).Google Scholar"",""Julia Ling, Andrew Kurzawski, and Jeremy Templeton. 2016. Reynolds averaged turbulence modeling using deep neural networks with embedded invariance. Journal of Fluid Mechanics 807 (2016), 155--166.Google ScholarCross Ref"",""Michael Mathieu, Camille Couprie, and Yann LeCun. 2015. Deep multi-scale video prediction beyond mean square error. arXiv preprint arXiv:1511.05440 (2015).Google Scholar"",""George Em Karniadakis Maziar Raissi. 2018. Hidden physics models: Machine learning of nonlinear partial differential equations. J. Comput. Phys. 357 (2018), 125--141.Google ScholarCross Ref"",""George E Karniadakis Maziar Raissi, Paris Perdikaris. 2019. Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. J. Comput. Phys. 378 (2019), 686--707.Google ScholarCross Ref"",""J. M. McDonough. 2007. Introductory Lectures on Turbulence. Mechanical Engineering Textbook Gallery. https://uknowledge.uky.edu/me_textbooks/2Google Scholar"",""James M McDonough. 2007. Introductory lectures on turbulence: physics, mathematics and modeling. (2007).Google Scholar"",""L. Prantl Xiangyu Hu N. Thuerey, K.Weibenow. 2019. Deep Learning Methods for Reynolds-Averaged Navier-Stokes Simulations of Airfoil Flows. arXiv:1810.08217 (2019).Google Scholar"",""Thomas Brox Olaf Ronneberger, Philipp Fischer. 2015. U-Net: Convolutional Networks for Biomedical Image Segmentation. arXiv:1512.03385 (2015).Google Scholar"",""Marc Terracol Pierre Sagaut, Sebastien Deck. 2006. Multiscale and Multiresolution Approaches in Turbulence. Imperial College Press.Google Scholar"",""Maziar Raissi. 2018. Deep Hidden Physics Models: Deep Learning of Nonlinear Partial Differential Equations. Journal of Machine Learning Research (2018).Google Scholar"",""Maziar Raissi, Paris Perdikaris, and George Em Karniadakis. 2017. Physics Informed Deep Learning (Part I): Data-driven solutions of nonlinear partial differential equations. arXiv preprint arXiv:1711.10561 (2017).Google Scholar"",""Markus Reichstein, Gustau Camps-Valls, Bjorn Stevens, Martin Jung, Joachim Denzler, Nuno Carvalhais, and Prabhat. 2019. Deep learning and process understanding for data-driven Earth system science. Nature 566, 7743 (2019), 195--204. https://doi.org/10.1038/s41586-019-0912--1Google Scholar"",""Rose Yu Rui Wang, Robin Walters. 2019. Incorporating Symmetry into Deep Dynamics Models for Improved Generalization. ArXiv Preprint arXiv:2002.03061 (2019).Google Scholar"",""Pierre Sagaut. 2001. Large Eddy Simulation for Incompressible Flows. Springer- Verlag Berlin Heidelberg. https://doi.org/10.1007/978--3--662-04416--2Google Scholar"",""Nils Thuerey Steffen Wiewel, Moritz Becher. 2019. Latent-space Physics: Towards Learning the Temporal Evolution of Fluid Flow. Computer Graphics Forum 38 (2019). Issue 2.Google Scholar"",""Petros Koumoutsakos Steven Brunton, Bernd Noack. 2019. Machine Learning for Fluid Mechanics. arXiv:1905.11075 (2019).Google Scholar"",""Steven H. Strogatz. 2018. Nonlinear dynamics and chaos: with applications to physics, biology, chemistry, and engineering. CRC press.Google Scholar"",""Stephan Rasp Pierre Gentine Jordan Ott-Pierre Baldi Tom Beucler, Michael Pritchard. 2019. Enforcing Analytic Constraints in Neural-Networks Emulating Physical Systems. arXiv:1909.00912v2 (2019).Google Scholar"",""Jonathan Tompson, Kristofer Schlachter, Pablo Sprechmann, and Ken Perlin. 2017. Accelerating eulerian fluid simulation with convolutional networks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 3424--3433.Google ScholarDigital Library"",""Ruben Villegas, Jimei Yang, Seunghoon Hong, Xunyu Lin, and Honglak Lee. 2017. Decomposing motion and content for natural video sequence prediction. arXiv:1706.08033 (2017).Google Scholar"",""John Wainwright and George Francis Rayner Ellis. 2005. Dynamical systems in cosmology. Cambridge University Press.Google Scholar"",""Jin-Long Wu, Karthik Kashinath, Adrian Albert, Dragos Chirila, Prabhat, and Heng Xiao. 2019. Enforcing Statistical Constraints in Generative Adversarial Networks for Modeling Chaotic Dynamical Systems. arXiv e-prints (May 2019). arXiv:physics.comp-ph/1905.06841Google Scholar"",""You Xie, Erik Franz, Mengyu Chu, and Nils Thuerey. 2018. tempogan: A temporally coherent, volumetric gan for super-resolution fluid flow. ACM Transactions on Graphics (TOG) 37, 4 (2018), 95.Google ScholarDigital Library"",""SHI Xingjian, Zhourong Chen, Hao Wang, Dit-Yan Yeung, Wai-Kin Wong, and Wang-chun Woo. 2015. Convolutional LSTM network: A machine learning approach for precipitation nowcasting. In Advances in neural information processing systems. 802--810.Google Scholar"",""Hao Wang Dit-Yan Yeung Wai-kin Wong Wang-chun Woo Xingjian Shi, Zhourong Chen. 2015. Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting. arXiv:1506.04214 (2015).Google Scholar"",""Tianfan Xue, Jiajun Wu, Katherine Bouman, and Bill Freeman. 2016. Visual dynamics: Probabilistic future frame synthesis via cross convolutional networks. In Advances in neural information processing systems. 91--99.Google Scholar"",""Huaxiu Yao, Fei Wu, Jintao Ke, Xianfeng Tang, Yitian Jia, Siyu Lu, Pinghua Gong, Jieping Ye, and Zhenhui Li. 2018. Deep multi-view spatial-temporal network for taxi demand prediction. In Thirty-Second AAAI Conference on Artificial Intelligence.Google Scholar"",""Xiuwen Yi, Junbo Zhang, ZhaoyuanWang, Tianrui Li, and Yu Zheng. 2018. Deep distributed fusion network for air quality prediction. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 965--973.Google ScholarDigital Library"",""Saibal Mukhopadhyay Yun Long, Xueyuan She. 2019. HybridNet: Integrating Model-based and Data-driven Learning to Predict Evolution of Dynamical Systems. ArXiv Preprint arXiv:1806.07439 (2019).Google Scholar""]"
https://doi.org/10.1145/3394486.3403199,Evaluating Fairness Using Permutation Tests,"Machine learning models are central to people's lives and impact society in ways as fundamental as determining how people access information. The gravity of these models imparts a responsibility to model developers to ensure that they are treating users in a fair and equitable manner. Before deploying a model into production, it is crucial to examine the extent to which its predictions demonstrate biases. This paper deals with the detection of bias exhibited by a machine learning model through statistical hypothesis testing. We propose a permutation testing methodology that performs a hypothesis test that a model is fair across two groups with respect to any given metric. There are increasingly many notions of fairness that can speak to different aspects of model fairness. Our aim is to provide a flexible framework that empowers practitioners to identify significant biases in any metric they wish to study. We provide a formal testing mechanism as well as extensive experiments to show how this method works in practice.","[{""name"":""Cyrus DiCiccio"",""id"":""/profile/99659573164""},{""name"":""Sriram Vasudevan"",""id"":""/profile/99659573909""},{""name"":""Kinjal Basu"",""id"":""/profile/99658746285""},{""name"":""Krishnaram Kenthapadi"",""id"":""/profile/81342500095""},{""name"":""Deepak Agarwal"",""id"":""/profile/81100632698""},{""name"":""Cyrus DiCiccio"",""id"":""/profile/99659573164""},{""name"":""Sriram Vasudevan"",""id"":""/profile/99659573909""},{""name"":""Kinjal Basu"",""id"":""/profile/99658746285""},{""name"":""Krishnaram Kenthapadi"",""id"":""/profile/81342500095""},{""name"":""Deepak Agarwal"",""id"":""/profile/81100632698""}]","[""Alekh Agarwal, Alina Beygelzimer, Miroslav Dudik, John Langford, and Hanna Wallach. 2018. A Reductions Approach to Fair Classification. In International Conference on Machine Learning. 60--69.Google Scholar"",""Alan Agresti and Brent A Coull. 1998. Approximate is better than \""exact\"" for interval estimation of binomial proportions. The American Statistician 52, 2 (1998), 119--126.Google Scholar"",""Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. 2016. Machine bias. ProPublica (2016).Google Scholar"",""Apache Spark Team. 2014. Apache Spark: A fast and general engine for large-scale data processing. https://spark.apache.org, Last accessed on 2019-09--10.Google Scholar"",""Solon Barocas and Moritz Hardt. 2017. Fairness in Machine Learning. In NIPS Tutorial.Google Scholar"",""Alex Beutel, Jilin Chen, Tulsee Doshi, Hai Qian, Allison Woodruff, Christine Luu, Pierre Kreitmann, Jonathan Bischof, and Ed H Chi. 2019. Putting fairness principles into practice: Challenges, metrics, and improvements. arXiv preprint arXiv:1901.04562 (2019).Google Scholar"",""Tolga Bolukbasi, Kai-Wei Chang, James Y Zou, Venkatesh Saligrama, and Adam T Kalai. 2016. Man is to computer programmer as woman is to homemaker? Debiasing word embeddings. In NIPS.Google Scholar"",""Lawrence D Brown, T Tony Cai, and Anirban DasGupta. 2001. Interval estimation for a binomial proportion. Statistical science (2001), 101--117.Google Scholar"",""Aylin Caliskan, Joanna J Bryson, and Arvind Narayanan. 2017. Semantics derived automatically from language corpora contain human-like biases. Science 356, 6334 (2017).Google Scholar"",""EunYi Chung and Joseph P. Romano. 2013. Exact and asymptotically robust permutation tests. Ann. Statist. 41, 2 (04 2013), 484--507.Google Scholar"",""EunYi Chung and Joseph P. Romano. 2016. Asymptotically valid and exact permutation tests based on two-sample U-statistics. Journal of Statistical Planning and Inference 168 (2016), 97 -- 105.Google ScholarCross Ref"",""Cynthia Dwork, Moritz Hardt, Toniann Pitassi, and Richard Zemel Omer Reingold. 2012. Fairness through awareness. In ITCS.Google Scholar"",""Alexander D'Amour, Hansa Srinivasan, James Atwood, Pallavi Baljekar, D. Sculley, and Yoni Halpern. 2020. Fairness is Not Static: Deeper Understanding of Long Term Fairness via Simulation Studies. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (FAT* '20). Association for Computing Machinery, 525--534.Google Scholar"",""Sainyam Galhotra, Yuriy Brun, and Alexandra Meliou. 2017. Fairness Testing: Testing Software for Discrimination. In Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering. Association for Computing Machinery, 498--510.Google ScholarDigital Library"",""P.I. Good. 2000. Permutation Tests: A Practical Guide to Resampling Methods for Testing Hypotheses. Springer.Google ScholarCross Ref"",""S. Hajian, F. Bonchi, and C. Castillo. 2016. Algorithmic Bias: From Discrimination Discovery to Fairness-aware Data Mining. In KDD Tutorial on Algorithmic Bias.Google ScholarDigital Library"",""Matthew Kay, Cynthia Matuszek, and Sean A. Munson. 2015. Unequal Representation and Gender Stereotypes in Image Search Results for Occupations. In CHI.Google Scholar"",""Ron Kohavi. 1996. Scaling up the accuracy of Naive-Bayes classifiers: A decisiontree hybrid. In KDD.Google Scholar"",""Jeff Larson, Surya Mattu, Lauren Kirchner, and Julia Angwin. 2016. Data and analysis for 'How we analyzed the COMPAS recidivism algorithm'. https://github.com/propublica/compas-analysis, Last accessed on 2019-09--10.Google Scholar"",""Jérémie Mary, Clément Calauzenes, and Noureddine El Karoui. 2019. Fairnessaware learning for continuous attributes and treatments. In International Conference on Machine Learning. 4382--4391.Google Scholar"",""Markus Ojala and Gemma C. Garriga. 2010. Permutation Tests for Studying Classifier Performance. Journal of Machine Learning Research 11 (2010), 1833-- 1863.Google ScholarDigital Library"",""Dino Pedreschi, Salvatore Ruggieri, and Franco Turini. 2009. Measuring discrimination in socially-sensitive decision records. In SDM.Google Scholar"",""Ya'acov Ritov, Yuekai Sun, and Ruofei Zhao. 2017. On conditional parity as a notion of non-discrimination in machine learning. arXiv preprint arXiv:1706.08519 (2017).Google Scholar"",""Till Speicher, Hoda Heidari, Nina Grgic-Hlaca, Krishna P Gummadi, Adish Singla, AdrianWeller, and Muhammad Bilal Zafar. 2018. A Unified Approach to Quantifying Algorithmic Unfairness: Measuring Individual \u0026Group Unfairness via Inequality Indices. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 2239--2248.Google ScholarDigital Library"",""F. Tramèr, V. Atlidakis, R. Geambasu, D. Hsu, J. Hubaux, M. Humbert, A. Juels, and H. Lin. 2017. FairTest: Discovering Unwarranted Associations in Data-Driven Applications. In 2017 IEEE European Symposium on Security and Privacy (EuroS . 401--416.Google Scholar"",""Edwin B Wilson. 1927. Probable inference, the law of succession, and statistical inference. J. Amer. Statist. Assoc. 22, 158 (1927), 209--212.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403200,Leveraging Model Inherent Variable Importance for Stable Online Feature Selection,"Feature selection can be a crucial factor in obtaining robust and accurate predictions. Online feature selection models, however, operate under considerable restrictions; they need to efficiently extract salient input features based on a bounded set of observations, while enabling robust and accurate predictions. In this work, we introduce FIRES, a novel framework for online feature selection. The proposed feature weighting mechanism leverages the importance information inherent in the parameters of a predictive model. By treating model parameters as random variables, we can penalize features with high uncertainty and thus generate more stable feature sets. Our framework is generic in that it leaves the choice of the underlying model to the user. Strikingly, experiments suggest that the model complexity has only a minor effect on the discriminative power and stability of the selected feature sets. In fact, using a simple linear model, FIRES obtains feature sets that compete with state-of-the-art methods, while dramatically reducing computation time. In addition, experiments show that the proposed framework is clearly superior in terms of feature selection stability.","[{""name"":""Johannes Haug"",""id"":""/profile/99659573199""},{""name"":""Martin Pawelczyk"",""id"":""/profile/99659534641""},{""name"":""Klaus Broelemann"",""id"":""/profile/81442616644""},{""name"":""Gjergji Kasneci"",""id"":""/profile/81329489813""},{""name"":""Johannes Haug"",""id"":""/profile/99659573199""},{""name"":""Martin Pawelczyk"",""id"":""/profile/99659534641""},{""name"":""Klaus Broelemann"",""id"":""/profile/81442616644""},{""name"":""Gjergji Kasneci"",""id"":""/profile/81329489813""}]","[""Jean Paul Barddal, Fabricio Enembreck, Heitor Murilo Gomes, Albert Bifet, and Bernhard Pfahringer. 2019. Boosting decision stumps for dynamic feature selection on data streams. Information Systems, Vol. 83 (2019), 13--29.Google ScholarCross Ref"",""Albert Bifet, Gianmarco de Francisci Morales, Jesse Read, Geoff Holmes, and Bernhard Pfahringer. 2015. Efficient online evaluation of big data stream classifiers. In Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining. 59--68.Google ScholarDigital Library"",""Verónica Bolón-Canedo, Noelia Sánchez-Maro no, and Amparo Alonso-Betanzos. 2015. Recent advances and emerging challenges of feature selection in the context of big data. Knowledge-Based Systems, Vol. 86 (2015), 33--45.Google ScholarDigital Library"",""Vadim Borisov, Johannes Haug, and Gjergji Kasneci. 2019. CancelOut: A Layer for Feature Selection in Deep Neural Networks. In International Conference on Artificial Neural Networks. Springer, 72--83.Google Scholar"",""Olivier Bousquet and André Elisseeff. 2002. Stability and generalization. Journal of machine learning research, Vol. 2, Mar (2002), 499--526.Google ScholarDigital Library"",""Tamara Broderick, Nicholas Boyd, Andre Wibisono, Ashia C Wilson, and Michael I Jordan. 2013. Streaming variational bayes. In Advances in neural information processing systems. 1727--1735.Google Scholar"",""Vitor R Carvalho and William W Cohen. 2006. Single-pass online learning: Performance, voting schemes and online feature selection. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 548--553.Google ScholarDigital Library"",""Girish Chandrashekar and Ferat Sahin. 2014. A survey on feature selection methods. Computers \u0026 Electrical Engineering, Vol. 40, 1 (2014), 16--28.Google ScholarDigital Library"",""Pedro Domingos and Geoff Hulten. 2000. Mining high-speed data streams. In Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining. 71--80.Google ScholarDigital Library"",""Dheeru Dua and Casey Graff. 2017. UCI Machine Learning Repository. http://archive.ics.uci.edu/mlGoogle Scholar"",""Nicholas Frosst and Geoffrey Hinton. 2017. Distilling a neural network into a soft decision tree. arXiv preprint arXiv:1711.09784 (2017).Google Scholar"",""Jo ao Gama, Indr.e vZ liobait.e, Albert Bifet, Mykola Pechenizkiy, and Abdelhamid Bouchachia. 2014. A survey on concept drift adaptation. ACM computing surveys (CSUR), Vol. 46, 4 (2014), 44.Google Scholar"",""Ian Goodfellow, Patrick McDaniel, and Nicolas Papernot. 2018. Making machine learning robust against adversarial inputs. Commun. ACM, Vol. 61, 7 (2018), 56--66.Google ScholarDigital Library"",""Isabelle Guyon and André Elisseeff. 2003. An introduction to variable and feature selection. Journal of machine learning research, Vol. 3, Mar (2003), 1157--1182.Google ScholarDigital Library"",""Ronan Hamon, Henrik Junklewitz, and Ignacio Sanchez. 2020. Robustness and Explainability of Artificial Intelligence. Publications Office of the European Union (2020).Google Scholar"",""Hao Huang, Shinjae Yoo, and Shiva Prasad Kasiviswanathan. 2015. Unsupervised feature selection on data streams. In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management. ACM, 1031--1040.Google ScholarDigital Library"",""Ozan Irsoy, Olcay Taner Yildiz, and Ethem Alpaydin. 2012. Soft decision trees. In Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012). IEEE, 1819--1822.Google Scholar"",""Alexandros Kalousis, Julien Prados, and Melanie Hilario. 2005. Stability of feature selection algorithms. In Fifth IEEE International Conference on Data Mining (ICDM'05). IEEE, 8--pp.Google ScholarDigital Library"",""Gjergji Kasneci and Thomas Gottron. 2016. Licon: A linear weighting scheme for the contribution of input variables in deep artificial neural networks. In Proceedings of the 25th ACM International Conference on Information and Knowledge Management. 45--54.Google ScholarDigital Library"",""Ioannis Katakis, Grigorios Tsoumakas, and Ioannis Vlahavas. 2005. On the utility of incremental feature selection for the classification of textual data streams. In Panhellenic Conference on Informatics. Springer, 338--348.Google ScholarDigital Library"",""Haiguang Li, Xindong Wu, Zhao Li, and Wei Ding. 2013. Online group feature selection from feature streams. In Twenty-seventh AAAI conference on artificial intelligence .Google ScholarDigital Library"",""Jundong Li, Kewei Cheng, Suhang Wang, Fred Morstatter, Robert P Trevino, Jiliang Tang, and Huan Liu. 2018. Feature selection: A data perspective. ACM Computing Surveys (CSUR), Vol. 50, 6 (2018), 94.Google ScholarDigital Library"",""Yanbin Liu, Yan Yan, Ling Chen, Yahong Han, and Yi Yang. 2019. Adaptive Sparse Confidence-Weighted Learning for Online Feature Selection. Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33, 01 (2019), 4408--4415. https://doi.org/10.1609/aaai.v33i01.33014408Google ScholarCross Ref"",""Mohammad M Masud, Qing Chen, Jing Gao, Latifur Khan, Jiawei Han, and Bhavani Thuraisingham. 2010. Classification and novel class detection of data streams in a dynamic feature space. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 337--352.Google ScholarDigital Library"",""Jacob Montiel, Jesse Read, Albert Bifet, and Talel Abdessalem. 2018. Scikit-multiflow: a multi-output streaming framework. The Journal of Machine Learning Research, Vol. 19, 1 (2018), 2915--2914.Google ScholarDigital Library"",""John Ashworth Nelder and Robert WM Wedderburn. 1972. Generalized linear models. Journal of the Royal Statistical Society: Series A (General), Vol. 135, 3 (1972), 370--384.Google ScholarCross Ref"",""Hai-Long Nguyen, Yew-Kwong Woon, Wee-Keong Ng, and Li Wan. 2012. Heterogeneous ensemble for feature drifts in data streams. In Pacific-Asia conference on knowledge discovery and data mining. Springer, 1--12.Google ScholarDigital Library"",""Sarah Nogueira, Konstantinos Sechidis, and Gavin Brown. 2017. On the Stability of Feature Selection Algorithms. Journal of Machine Learning Research, Vol. 18 (2017), 174--1.Google Scholar"",""Simon Perkins, Kevin Lacker, and James Theiler. 2003. Grafting: Fast, incremental feature selection by gradient descent in function space. Journal of machine learning research, Vol. 3, Mar (2003), 1333--1356.Google ScholarDigital Library"",""Sergio Ramirez-Gallego, Bartosz Krawczyk, Salvador Garcia, Michał Wozniak, and Francisco Herrera. 2017. A survey on data preprocessing for data stream mining: Current status and future directions. Neurocomputing, Vol. 239 (2017), 39--57.Google ScholarDigital Library"",""Cynthia Rudin. 2019. Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead. Nature Machine Intelligence, Vol. 1, 5 (2019), 206--215.Google ScholarCross Ref"",""Peter Turney. 1995. Bias and the quantification of stability. Machine Learning, Vol. 20, 1--2 (1995), 23--33.Google ScholarDigital Library"",""Boyu Wang and Joelle Pineau. 2016. Online bagging and boosting for imbalanced data streams. IEEE Transactions on Knowledge and Data Engineering, Vol. 28, 12 (2016), 3353--3366.Google ScholarDigital Library"",""Jing Wang, Jie Shen, and Ping Li. 2018. Provable variable selection for streaming features. In International Conference on Machine Learning. 5158--5166.Google Scholar"",""Jialei Wang, Peilin Zhao, Steven CH Hoi, and Rong Jin. 2013. Online feature selection and its applications. IEEE Transactions on Knowledge and Data Engineering, Vol. 26, 3 (2013), 698--710.Google ScholarDigital Library"",""Xindong Wu, Kui Yu, Wei Ding, Hao Wang, and Xingquan Zhu. 2012. Online feature selection with streaming features. IEEE transactions on pattern analysis and machine intelligence, Vol. 35, 5 (2012), 1178--1192.Google Scholar"",""Kui Yu, Xindong Wu, Wei Ding, and Jian Pei. 2014. Towards scalable and accurate online feature selection for big data. In 2014 IEEE International Conference on Data Mining. IEEE, 660--669.Google ScholarDigital Library"",""Jing Zhou, Dean P Foster, Robert A Stine, and Lyle H Ungar. 2006. Streamwise feature selection. Journal of Machine Learning Research, Vol. 7, Sep (2006), 1861--1885.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403201,Multi-level Graph Convolutional Networks for Cross-platform Anchor Link Prediction,"Cross-platform account matching plays a significant role in social network analytics, and is beneficial for a wide range of applications. However, existing methods either heavily rely on high-quality user generated content (including user profiles) or suffer from data insufficiency problem if only focusing on network topology, which brings researchers into an insoluble dilemma of model selection. In this paper, to address this problem, we propose a novel framework that considers multi-level graph convolutions on both local network structure and hypergraph structure in a unified manner. The proposed method overcomes data insufficiency problem of existing work and does not necessarily rely on user demographic information. Moreover, to adapt the proposed method to be capable of handling large-scale social networks, we propose a two-phase space reconciliation mechanism to align the embedding spaces in both network partitioning based parallel training and account matching across different social networks. Extensive experiments have been conducted on two large-scale real-life social networks. The experimental results demonstrate that the proposed method outperforms the state-of-the-art models with a big margin.","[{""name"":""Hongxu Chen"",""id"":""/profile/99659155111""},{""name"":""Hongzhi YIN"",""id"":""/profile/81501665075""},{""name"":""Xiangguo Sun"",""id"":""/profile/99659573838""},{""name"":""Tong Chen"",""id"":""/profile/99659154431""},{""name"":""Bogdan Gabrys"",""id"":""/profile/81100043874""},{""name"":""Katarzyna Musial"",""id"":""/profile/81384617182""},{""name"":""Hongxu Chen"",""id"":""/profile/99659155111""},{""name"":""Hongzhi YIN"",""id"":""/profile/81501665075""},{""name"":""Xiangguo Sun"",""id"":""/profile/99659573838""},{""name"":""Tong Chen"",""id"":""/profile/99659154431""},{""name"":""Bogdan Gabrys"",""id"":""/profile/81100043874""},{""name"":""Katarzyna Musial"",""id"":""/profile/81384617182""}]","[""M.A. Ahmad, Z. Borbora, J. Srivastava, and N. Contractor. Link prediction across multiple social networks. In ICDMW. IEEE, 2010.Google ScholarDigital Library"",""A. Ahmed, N. Shervashidze, S. Narayanamurthy, V. Josifovski, and A.J. Smola. Distributed large-scale natural graph factorization. In WWW 13.Google Scholar"",""M. Bayati, M. Gerritsen, D.F. Gleich, A. Saberi, and Y. Wang. Algorithms for large, sparse network alignment problems. In ICDM. IEEE, 2009.Google ScholarDigital Library"",""V.D. Blondel, J.L. Guillaume, R. Lambiotte, and E. Lefebvre. Fast unfolding of communities in large networks. Journal of statistical mechanics: theory and experiment, 2008.Google Scholar"",""X. Caoand Y. Yu. Bass: A boot strapping approach for aligning heterogenous social networks. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 2016.Google Scholar"",""H. Chen, H. Yin, T. Chen, Q.V.H. Nguyen, W.-C. Peng, and X. Li. Exploiting centrality information with graph convolutions for network representation learning. In ICDE. IEEE, 2019.Google ScholarCross Ref"",""H. Chen, H. Yin, W. Wang, H. Wang, Q.V.H. Nguyen, and X. Li. Pme: projected metric embedding on heterogeneous networks for link prediction. In KDD, 2018.Google ScholarDigital Library"",""T. Chen, H. Yin, Q.V.H. Nguyen, W.-C. Peng, X. Li, and X. Zhou. Sequence aware factorization machines for temporal predictive analytics. In ICDE, 2020.Google ScholarCross Ref"",""T. Chen, H. Yin, G. Ye, Z. Huang, Y. Wang, and M. Wang. Try this instead: Personalized and interpretable substitute recommendation. arXiv preprint, 2020.Google Scholar"",""W. Chen, H. Yin, W. Wang, L. Zhao, and X. Zhou. Effective and efficient user account linkage across location based social networks. In ICDE, pages 1085--1096. IEEE, 2018.Google ScholarCross Ref"",""A. Cheng, C. Zhou, H. Yang, J. Wu, L. Li, J. Tan, and L. Guo. Deep active learning for anchor user prediction. IJCAI, 2019.Google ScholarCross Ref"",""M. Defferrard, X. Bresson, and P. Vandergheynst. Convolutional neural networks on graphs with fast localized spectral filtering. In NIPS, 2016.Google ScholarDigital Library"",""F.E. Faisal, H. Zhao, and T. Milenkovic. Global network alignment in the context of aging. Transactions on Computational Biology and Bioinformatics, 2014.Google Scholar"",""Y. Feng, H. You, Z. Zhang, R. Ji, and Y. Gao. Hypergraph neural networks. In Proceedings of the AAAI Conference on Artificial Intelligence, 2019.Google ScholarCross Ref"",""O. Goga, P. Loiseau, R. Sommer, R. Teixeira, and K.P. Gummadi. On the reliability of profile matching across large online social networks. In KDD, 2015.Google ScholarDigital Library"",""A. Grover and J. Leskovec. node2vec: Scalable feature learning for networks. In KDD, 2016.Google ScholarDigital Library"",""W. Hamilton, Z. Ying, and J. Leskovec. Inductive representation learning on large graphs. In NIPS, 2017.Google ScholarDigital Library"",""M. Heimann, H. Shen, T. Safavi, and D. Koutra. Regal: Representation learning-based graph alignment. In CIKM, 2018.Google ScholarDigital Library"",""T. Iofciu, P. Fankhauser, F. Abel, and K. Bischoff. Identifying users across social tagging systems. In AAAI Conference on Weblogs and Social Media, 2011.Google Scholar"",""J. Jiang, Y. Wei, Y. Feng, J. Cao, and Y. Gao. Dynamic hyper graph neural networks. In IJCAI, pages 2635--2641, 2019.Google Scholar"",""T.N. Kipf and M. Welling. Semi-supervised classification with graph convolutional networks. ICLR, 2017.Google Scholar"",""J. Liu, F. Zhang, X. Song, Y.-I. Song, C.-Y. Lin, and H.W. Hon. What's in a name? an unsupervised approach to link users across communities. In WSDM, 2013.Google ScholarDigital Library"",""L. Liu, W.K. Cheung, X. Li, and L. Liao. Aligning users across social networks using network embedding. In Ijcai, pages 1774--1780, 2016.Google ScholarDigital Library"",""A. Malhotra, L. Totti, W. Meira Jr, P. Kumaraguru, and V. Almeida. Studying user footprints in different online social networks. In ASONAM. IEEE, 2012.Google ScholarDigital Library"",""T. Man, H. Shen, J. Huang, and X. Cheng. Context-adaptive matrix factorization for multi-context recommendation. In CIKM, 2015.Google ScholarDigital Library"",""T. Man, H. Shen, S. Liu, X. Jin, and X. Cheng. Predict anchor links across social networks via an embedding approach. In IJCAI, 2016.Google ScholarDigital Library"",""K. Musia? and P. Kazienko. Social networks on the internet. WWW, 2013.Google Scholar"",""A. Narayanan and V. Shmatikov. Deanonymizing social networks. In 2009 30th IEEE symposium on security and privacy. IEEE, 2009.Google ScholarDigital Library"",""A.Y. Ng, M.I. Jordan, and Y. Weiss. On spectral clustering: Analysis and an algorithm. In NIPS, 2002.Google ScholarDigital Library"",""B. Perozzi, R. Al-Rfou, and S. Skiena. Deepwalk: Online learning of social representations. In KDD, 2014.Google ScholarDigital Library"",""C. Riederer, Y. Kim, A. Chaintreau, N. Korula, and S. Lattanzi. Linking users across domains with location data: Theory and validation. In WWW, 2016.Google ScholarDigital Library"",""G. Salha, S. Limnios, R. Hennequin, V.-A. Tran, and M. Vazirgiannis. Gravity-inspired graph autoencoders for directed link prediction. In CIKM, 2019.Google ScholarDigital Library"",""R. Singh, J. Xu, and B. Berger. Global alignment of multiple protein interaction networks with application to functional orthology detection. Proceedings of the National Academy of Sciences, 2008.Google ScholarCross Ref"",""S. Tan, Z. Guan, D. Cai, X. Qin, J. Bu, and C. Chen. Mapping users across networks by manifold alignment on hypergraph. In AAAI, 2014.Google ScholarDigital Library"",""J. Tang, H. Gao, H. Liu, and A. DasSarma. etrust: Understanding trust evolution in an online world. In KDD, 2012.Google ScholarDigital Library"",""J. Tang, M. Qu, M. Wang, M. Zhang, J. Yan, and Q. Mei. Line: Large-scale information network embedding. In WWW, 2015.Google ScholarDigital Library"",""H.T. Trung, N.T. Toan, T. Van Vinh, H.T. Dat, D.C. Thang, N.Q.V. Hung, and A. Sattar. A comparative study on network alignment techniques. Expert Systems with Applications, 2020.Google ScholarCross Ref"",""W. Wang, H. Yin, X. Du, W. Hua, Y. Li, and Q.V.H. Nguyen. Online user representation learning across heterogeneous social networks. In SIGIR, 2019.Google ScholarDigital Library"",""N. Yadati, M. Nimishakavi, P. Yadav, V. Nitin, A. Louis, and P. Talukdar. Hyper-gcn: A new method for training graph convolutional networks on hypergraphs. In NIPS, 2019.Google Scholar"",""H. Yin, Q. Wang, K. Zheng, Z. Li, J. Yang, and X. Zhou. Social influence-based group representation learning for group recommendation. In ICDE. IEEE, 2019.Google ScholarCross Ref"",""H. Yin, L. Zou, Q.V.H. Nguyen, Z. Huang, and X. Zhou. Joint event-partner recommendation in event-based social networks. In ICDE. IEEE, 2018.Google ScholarCross Ref"",""J. Zhang and S.Y. Philip. Integrated anchor and social link predictions across social networks. In AAAI, 2015.Google Scholar"",""S. Zhang and H. Tong. Final: Fast attributed network alignment. In KDD, 2016.Google ScholarDigital Library"",""Y. Zhang, J. Tang, Z. Yang, J. Pei, and P.S. Yu. Cosnet: Connecting heterogeneous social networks with local and global consistency. In KDD, 2015.Google ScholarDigital Library"",""F. Zhou, L. Liu, K. Zhang, G. Trajcevski, J. Wu, and T. Zhong. Deeplink: A deep learning approach for user identity linkage. In IEEE INFOCOM. IEEE, 2018.Google ScholarCross Ref"",""X. Zhou, X. Liang, H. Zhang, and Y. Ma. Cross-platform identification of anonymous identical users in multiple social media networks. TKDE, 2015.Google Scholar"",""L. Zlatkov. Multidimensional scaling(mds). 1978.Google Scholar""]"
https://doi.org/10.1145/3394486.3403202,Evaluating Conversational Recommender Systems via User Simulation,"Conversational information access is an emerging research area. Currently, human evaluation is used for end-to-end system evaluation, which is both very time and resource intensive at scale, and thus becomes a bottleneck of progress. As an alternative, we propose automated evaluation by means of simulating users. Our user simulator aims to generate responses that a real human would give by considering both individual preferences and the general flow of interaction with the system. We evaluate our simulation approach on an item recommendation task by comparing three existing conversational recommender systems. We show that preference modeling and task-specific interaction models both contribute to more realistic simulations, and can help achieve high correlation between automatic evaluation measures and manual human assessments.","[{""name"":""Shuo Zhang"",""id"":""/profile/99659191444""},{""name"":""Krisztian Balog"",""id"":""/profile/81314480915""},{""name"":""Shuo Zhang"",""id"":""/profile/99659191444""},{""name"":""Krisztian Balog"",""id"":""/profile/81314480915""}]","[""Mohammad Aliannejadi, Hamed Zamani, Fabio Crestani, and W. Bruce Croft. 2019. Asking Clarifying Questions in Open-Domain Information-Seeking Conversations. In Proc. of SIGIR '19. 475--484.Google Scholar"",""Layla El Asri, Jing He, and Kaheer Suleman. 2016. A Sequence-to-Sequence Model for User Simulation in Spoken Dialogue Systems. In Proc. of Interspeech '16, 2016. 1151--1155.Google ScholarCross Ref"",""Leif Azzopardi, Mateusz Dubiel, Martin Halvey, and Jeffery Dalton. 2018. Conceptualizing Agent-human Interactions during the Conversational Search Process. In Proc. of CAIR '18.Google Scholar"",""Krisztian Balog and Tom Kenter. 2019. Personal Knowledge Graphs: A Research Agenda. In Proc. of ICTIR '19. 217--220.Google ScholarDigital Library"",""Anja Belz and Ehud Reiter. 2006. Comparing Automatic and Human Evaluation of NLG Systems. In Proc. of EACL '06.Google Scholar"",""Keping Bi, Qingyao Ai, Yongfeng Zhang, and W Bruce Croft. 2019. Conversational Product Search Based on Negative Feedback. In Proc. of CIKM '19. 359--368.Google ScholarDigital Library"",""Hongshen Chen, Xiaorui Liu, Dawei Yin, and Jiliang Tang. 2017. A Survey on Dialogue Systems: Recent Advances and New Frontiers. SIGKDD Explor. Newsl., Vol. 19, 2 (Nov. 2017), 25--35.Google ScholarDigital Library"",""Konstantina Christakopoulou, Filip Radlinski, and Katja Hofmann. 2016. Towards Conversational Recommender Systems. In Proc. of KDD '16. 815--824.Google ScholarDigital Library"",""Grace Chung. 2004. Developing a Flexible Spoken Dialog System Using Simulation. In Proc. of ACL '04.Google ScholarDigital Library"",""J. Shane Culpepper, Fernando Diaz, and Mark D. Smucker. 2018. Research Frontiers in Information Retrieval: Report from the Third Strategic Workshop on Information Retrieval in Lorne (SWIRL 2018). SIGIR Forum, Vol. 52, 1 (2018), 34--90.Google ScholarDigital Library"",""Jeff Dalton, Chenyan Xiong, and Jamie Callan. 2019. TREC Conversational Assistance Track. http://www.treccast.ai/.Google Scholar"",""David Griol, Javier Carbó, and José M. Molina. 2013. An Automatic Dialog Simulation Technique to Develop and Evaluate Interactive Conversational Agents. Appl. Artif. Intell., Vol. 27, 9 (oct 2013), 759--780.Google Scholar"",""F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Trans. Interact. Intell. Syst., Vol. 5, 4, Article 19 (2015).Google Scholar"",""Katja Hofmann, Lihong Li, and Filip Radlinski. 2016. Online Evaluation for Information Retrieval. Found. Trends Inf. Retr., Vol. 10, 1 (2016), 1--117.Google ScholarDigital Library"",""Dan Jurafsky and James H. Martin. 2019. Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition, 3nd Edition draft .Prentice Hall, Pearson Education International.Google Scholar"",""Diane Kelly. 2009. Methods for Evaluating Interactive Information Retrieval Systems with Users. Found. Trends Inf. Retr., Vol. 3, 1--2 (jan 2009), 1--224.Google ScholarDigital Library"",""Florian Kreyssig, I n igo Casanueva, Pawel Budzianowski, and Milica Gasic. 2018. Neural User Simulation for Corpus-based Policy Optimisation of Spoken Dialogue Systems. In Proc. of SIGDIAL '18. 60--69.Google ScholarCross Ref"",""Jiwei Li, Will Monroe, Alan Ritter, Dan Jurafsky, Michel Galley, and Jianfeng Gao. 2016. Deep Reinforcement Learning for Dialogue Generation. In Proc. of EMNLP '16. 1192--1202.Google ScholarCross Ref"",""Jiwei Li, Will Monroe, Tianlin Shi, Sé bastien Jean, Alan Ritter, and Dan Jurafsky. 2017b. Adversarial Learning for Neural Dialogue Generation. In Proc. of EMNLP '17. 2157--2169.Google ScholarCross Ref"",""Xiujun Li, Yun-Nung Chen, Lihong Li, Jianfeng Gao, and Asli Celikyilmaz. 2017a. End-to-End Task-Completion Neural Dialogue Systems. In Proc. of IJCNLP '17. 733--743.Google Scholar"",""Chia-Wei Liu, Ryan Lowe, Iulian Serban, Mike Noseworthy, Laurent Charlin, and Joelle Pineau. 2016. How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation. In Proc. of EMNLP '16. 2122--2132.Google ScholarCross Ref"",""David Martin Maxwell. 2019. Modelling search and stopping in interactive information retrieval. Ph.D. Dissertation. University of Glasgow.Google Scholar"",""Alexandros Papangelis, Yi-Chia Wang, Piero Molino, and Gokhan Tur. 2019. Collaborative Multi-Agent Dialogue Model Training Via Reinforcement Learning. In Proc. of SIGDIAL '19. 92--102.Google ScholarCross Ref"",""Baolin Peng, Xiujun Li, Jianfeng Gao, Jingjing Liu, and Kam-Fai Wong. 2018. Deep Dyna-Q: Integrating Planning for Task-Completion Dialogue Policy Learning. In Proc. of ACL '18. 2182--2192.Google ScholarCross Ref"",""Olivier Pietquin and Helen Hastie. 2013. A survey on metrics for the evaluation of user simulations. The Knowledge Engineering Review, Vol. 28, 1 (2013), 59--73.Google ScholarCross Ref"",""Chen Qu, Liu Yang, W. Bruce Croft, Yongfeng Zhang, Johanne R. Trippas, and Minghui Qiu. 2019. User Intent Prediction in Information-Seeking Conversations. In Proc. of CHIIR '19. 25--33.Google ScholarDigital Library"",""Filip Radlinski and Nick Craswell. 2017. A Theoretical Framework for Conversational Search. In Proc. of CHIIR '17. 117--126.Google ScholarDigital Library"",""Mark Sanderson. 2010. Test Collection Based Evaluation of Information Retrieval Systems. Found. Trends Inf. Retr., Vol. 4, 4 (2010), 247--375.Google ScholarCross Ref"",""Jost Schatzmann, Kallirroi Georgila, and Steve Young. 2005. Quantitative Evaluation of User Simulation Techniques for Spoken Dialogue Systems. In Proc. of SIGDIAL '05. 45--54.Google Scholar"",""Jost Schatzmann, Blaise Thomson, Karl Weilhammer, Hui Ye, and Steve Young. 2007. Agenda-based User Simulation for Bootstrapping a POMDP Dialogue System. In Proc. of NAACL-Short '07. 149--152.Google ScholarCross Ref"",""Jost Schatzmann, Karl Weilhammer, Matt Stuttle, and Steve Young. 2006. A Survey of Statistical User Simulation Techniques for Reinforcement-Learning of Dialogue Management Strategies. Knowl. Eng. Rev., Vol. 21, 2 (June 2006), 97--126.Google ScholarDigital Library"",""Iulian Vlad Serban, Ryan Lowe, Peter Henderson, Laurent Charlin, and Joelle Pineau. 2018. A Survey of Available Corpora For Building Data-Driven Dialogue Systems: The Journal Version. D \u0026 D, Vol. 9, 1 (2018), 1--49.Google Scholar"",""Johanne R. Trippas. 2019. Spoken Conversational Search: Audio-only Interactive Information Retrieval. Ph.D. Dissertation. RMIT University.Google Scholar"",""Svitlana Vakulenko. 2019. Knowledge-based Conversational Search. Ph.D. Dissertation. TU Wien.Google Scholar"",""Svitlana Vakulenko, Kate Revoredo, Claudio Di Ciccio, and Maarten de Rijke. 2019. QRFA: A Data-Driven Model of Information Seeking Dialogues. In Advances in Information Retrieval. 541--557.Google Scholar"",""Liu Yang, Minghui Qiu, Chen Qu, Jiafeng Guo, Yongfeng Zhang, W. Bruce Croft, Jun Huang, and Haiqing Chen. 2018. Response Ranking with Deep Matching Networks and External Knowledge in Information-Seeking Conversation Systems. In Proc. of SIGIR '18. 245--254.Google ScholarDigital Library"",""Yongfeng Zhang, Xu Chen, Qingyao Ai, Liu Yang, and W. Bruce Croft. 2018. Towards Conversational Search and Recommendation: System Ask, User Respond. In Proc. of CIKM '18. 177--186.Google Scholar""]"
https://doi.org/10.1145/3394486.3403203,Measuring Model Complexity of Neural Networks with Curve Activation Functions,"It is fundamental to measure model complexity of deep neural networks. A good model complexity measure can help to tackle many challenging problems, such as overfitting detection, model selection, and performance improvement. The existing literature on model complexity mainly focuses on neural networks with piecewise linear activation functions. Model complexity of neural networks with general curve activation functions remains an open problem. To tackle the challenge, in this paper, we first propose linear approximation neural network (LANN for short), a piecewise linear framework to approximate a given deep model with curve activation function. LANN constructs individual piecewise linear approximation for the activation function of each neuron, and minimizes the number of linear regions to satisfy a required approximation degree. Then, we analyze the upper bound of the number of linear regions formed by LANNs, and derive the complexity measure based on the upper bound. To examine the usefulness of the complexity measure, we experimentally explore the training process of neural networks and detect overfitting. Our results demonstrate that the occurrence of overfitting is positively correlated with the increase of model complexity during training. We find that the L1 and L2 regularizations suppress the increase of model complexity. Finally, we propose two approaches to prevent overfitting by directly constraining model complexity, namely neuron pruning and customized L1 regularization.","[{""name"":""Xia Hu"",""id"":""/profile/99659287397""},{""name"":""Weiqing Liu"",""id"":""/profile/99659242714""},{""name"":""Jiang Bian"",""id"":""/profile/81350602276""},{""name"":""Jian Pei"",""id"":""/profile/81100323054""},{""name"":""Xia Hu"",""id"":""/profile/99659287397""},{""name"":""Weiqing Liu"",""id"":""/profile/99659242714""},{""name"":""Jiang Bian"",""id"":""/profile/81350602276""},{""name"":""Jian Pei"",""id"":""/profile/81100323054""}]","[""Andrew R Barron. 1993. Universal approximation bounds for superpositions of a sigmoidal function. IEEE Transactions on Information theory, Vol. 39, 3 (1993), 930--945.Google ScholarDigital Library"",""Yoshua Bengio and Olivier Delalleau. 2011. On the expressive power of deep architectures. In International Conference on Algorithmic Learning Theory. Springer, 18--36.Google ScholarCross Ref"",""Monica Bianchini and Franco Scarselli. 2014. On the complexity of shallow and deep neural network classifiers. In ESANN.Google Scholar"",""Christopher M Bishop. 2006. Pattern recognition and machine learning .springer.Google Scholar"",""Chung-Cheng Chiu, Tara N Sainath, Yonghui Wu, Rohit Prabhavalkar, et al. 2018. State-of-the-art speech recognition with sequence-to-sequence models. In 2018 IEEE ICASSP. IEEE, 4774--4778.Google Scholar"",""Nadav Cohen, Or Sharir, and Amnon Shashua. 2016. On the expressive power of deep learning: A tensor analysis. In Conference on Learning Theory. 698--728.Google Scholar"",""George Cybenko. 1989. Approximation by superpositions of a sigmoidal function. Mathematics of control, signals and systems, Vol. 2, 4 (1989), 303--314.Google Scholar"",""Olivier Delalleau and Yoshua Bengio. 2011. Shallow vs. deep sum-product networks. In Advances in NIPS. 666--674.Google Scholar"",""Xiao Ding, Yue Zhang, Ting Liu, and Junwen Duan. 2015. Deep learning for event-driven stock prediction. In Proceeding of the 24th IJCAI.Google Scholar"",""Simon S Du and Jason D Lee. 2018. On the power of over-parametrization in neural networks with quadratic activation. arXiv preprint arXiv:1803.01206 (2018).Google Scholar"",""Ronen Eldan and Ohad Shamir. 2016. The power of depth for feedforward neural networks. In Conference on learning theory. 907--940.Google Scholar"",""Brendan J Frey and Geoffrey E Hinton. 1999. Variational learning in nonlinear Gaussian belief networks. Neural Computation, Vol. 11, 1 (1999), 193--213.Google ScholarDigital Library"",""Hongyang Gao and Shuiwang Ji. 2019. Graph representation learning via hard and channel-wise attention networks. In Proceedings of the 25th ACM SIGKDD. 741--749.Google ScholarDigital Library"",""Xavier Glorot and Yoshua Bengio. 2010. Understanding the difficulty of training deep feedforward neural networks. In Proceedings of the 13th AISTATS. 249--256.Google Scholar"",""Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. Deep learning .MIT press.Google Scholar"",""Douglas M Hawkins. 2004. The problem of overfitting. Journal of chemical information and computer sciences, Vol. 44, 1 (2004), 1--12.Google ScholarCross Ref"",""Soufiane Hayou, Arnaud Doucet, and Judith Rousseau. 2018. On the selection of initialization and activation function for deep neural networks. arXiv preprint arXiv:1805.08266 (2018).Google Scholar"",""Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015. Distilling the Knowledge in a Neural Network. stat, Vol. 1050 (2015), 9.Google Scholar"",""Kurt Hornik, Maxwell Stinchcombe, and Halbert White. 1989. Multilayer feedforward networks are universal approximators. Neural networks, Vol. 2, 5 (1989), 359--366.Google Scholar"",""Sergey Ioffe and Christian Szegedy. 2015. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167 (2015).Google Scholar"",""Barry L Kalman and Stan C Kwasny. 1992. Why tanh: choosing a sigmoidal function. In [Proceedings 1992] IJCNN, Vol. 4. IEEE, 578--581.Google Scholar"",""Joe Kilian and Hava T Siegelmann. 1993. On the power of sigmoid neural networks. In Proceedings of the 6th annual conference on Computational learning theory. 137--143.Google ScholarDigital Library"",""Alex Krizhevsky and Geoffrey Hinton. 2009. Learning multiple layers of features from tiny images. Master's thesis, Department of Computer Science, University of Toronto (2009).Google Scholar"",""Yann LeCun, Léon Bottou, Yoshua Bengio, et al. 1998. Gradient-based learning applied to document recognition. Proc. IEEE, Vol. 86, 11 (1998), 2278--2324.Google ScholarCross Ref"",""Zhou Lu, Hongming Pu, Feicheng Wang, Zhiqiang Hu, and Liwei Wang. 2017. The expressive power of neural networks: A view from the width. In Advances in NIPS. 6231--6239.Google Scholar"",""Wolfgang Maass, Georg Schnitger, and Eduardo D Sontag. 1994. A comparison of the computational power of sigmoid and Boolean threshold circuits. In Theoretical Advances in Neural Computation and Learning. Springer, 127--151.Google Scholar"",""Guido F Montufar, Razvan Pascanu, Kyunghyun Cho, and Yoshua Bengio. 2014. On the number of linear regions of deep neural networks. In Advances in NIPS. 2924--2932.Google Scholar"",""Vinod Nair and Geoffrey E Hinton. 2010. Rectified linear units improve restricted boltzmann machines. In Proceedings of the 27th ICML. 807--814.Google Scholar"",""Roman Novak, Yasaman Bahri, Daniel A. Abolafia, Jeffrey Pennington, and Jascha Sohl-Dickstein. 2018. Sensitivity and Generalization in Neural Networks: an Empirical Study. In ICLR.Google Scholar"",""Chigozie Nwankpa, Winifred Ijomah, Anthony Gachagan, and Stephen Marshall. 2018. Activation functions: Comparison of trends in practice and research for deep learning. arXiv preprint arXiv:1811.03378 (2018).Google Scholar"",""Razvan Pascanu, Guido Montufar, and Yoshua Bengio. 2013. On the number of response regions of deep feed forward networks with piece-wise linear activations. arXiv preprint arXiv:1312.6098 (2013).Google Scholar"",""Ben Poole, Subhaneil Lahiri, Maithra Raghu, Jascha Sohl-Dickstein, and Surya Ganguli. 2016. Exponential expressivity in deep neural networks through transient chaos. In Advances in NIPS. 3360--3368.Google Scholar"",""Maithra Raghu, Ben Poole, Jon Kleinberg, Surya Ganguli, and Jascha Sohl Dickstein. 2017. On the expressive power of deep neural networks. In Proceedings of the 34th ICML-Volume 70. JMLR, 2847--2854.Google Scholar"",""Bernard W Silverman. 2018. Density estimation for statistics and data analysis. Routledge.Google Scholar"",""Wei-Hung Weng, Yu-An Chung, and Peter Szolovits. 2019. Unsupervised Clinical Language Translation. Proceedings of the 25th ACM SIGKDD (2019).Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403204,Diverse Rule Sets,"While machine-learning models are flourishing and transforming many aspects of everyday life, the inability of humans to understand complex models poses difficulties for these models to be fully trusted and embraced. Thus, interpretability of models has been recognized as an equally important quality as their predictive power. In particular, rule-based systems are experiencing a renaissance owing to their intuitive if-then representation.However, simply being rule-based does not ensure interpretability. For example, overlapped rules spawn ambiguity and hinder interpretation. Here we propose a novel approach of inferring diverse rule sets, by optimizing small overlap among decision rules with a 2-approximation guarantee under the framework of Max-Sum diversification. We formulate the problem as maximizing a weighted sum of discriminative quality and diversity of a rule set.In order to overcome an exponential-size search space of association rules, we investigate several natural options for a small candidate set of high-quality rules, including frequent and accurate rules, and examine their hardness. Leveraging the special structure in our formulation, we then devise an efficient randomized algorithm, which samples rules that are highly discriminative and have small overlap. The proposed sampling algorithm analytically targets a distribution of rules that is tailored to our objective.We demonstrate the superior predictive power and interpretability of our model with a comprehensive empirical study against strong baselines.","[{""name"":""Guangyi Zhang"",""id"":""/profile/99659574551""},{""name"":""Aristides Gionis"",""id"":""/profile/81100631289""},{""name"":""Guangyi Zhang"",""id"":""/profile/99659574551""},{""name"":""Aristides Gionis"",""id"":""/profile/81100631289""}]","[""Rakesh Agrawal, Ramakrishnan Srikant, et al. 1994. Fast algorithms for mining association rules. In VLDB, Vol. 1215. 487--499.Google ScholarDigital Library"",""Mohammad Al Hasan and Mohammed Zaki. 2009a. Musk: Uniform sampling of k maximal patterns. In ICDM. SIAM, 650--661.Google Scholar"",""Mohammad Al Hasan and Mohammed J Zaki. 2009b. Output space sampling for graph patterns. VLDB, Vol. 2, 1 (2009), 730--741.Google Scholar"",""Elaine Angelino, Nicholas Larus-Stone, Daniel Alabi, Margo Seltzer, and Cynthia Rudin. 2017. Learning certifiably optimal rule lists for categorical data. JMLR, Vol. 18, 1 (2017), 8753--8830.Google ScholarDigital Library"",""Roberto J Bayardo, Rakesh Agrawal, and Dimitrios Gunopulos. 1999. Constraint-based rule mining in large, dense databases. In ICDE. IEEE, 188--197.Google Scholar"",""Mario Boley. 2007. On approximating minimum infrequent and maximum frequent sets. In International Conference on Discovery Science. Springer, 68--77.Google ScholarCross Ref"",""Mario Boley, Thomas G\""artner, and Henrik Grosskreutz. 2010. Formal concept sampling for counting and threshold-free local pattern mining. In SDM. SIAM, 177--188.Google Scholar"",""Mario Boley and Henrik Grosskreutz. 2008. A randomized approach for approximating the number of frequent sets. In ICDM. IEEE, 43--52.Google Scholar"",""Mario Boley, Claudio Lucchese, Daniel Paurat, and Thomas G\""artner. 2011. Direct local pattern sampling by efficient two-step random procedures. In KDD. ACM, 582--590.Google Scholar"",""Mario Boley, Sandy Moens, and Thomas Gartner. 2012. Linear space direct pattern sampling using coupling from the past. In KDD. ACM, 69--77.Google Scholar"",""Allan Borodin, Hyun Chul Lee, and Yuli Ye. 2012. Max-sum diversification, monotone submodular functions and dynamic updates. In PODS.Google Scholar"",""Endre Boros, Vladimir Gurvich, Leonid Khachiyan, and Kazuhisa Makino. 2002. On the complexity of generating maximal frequent and minimal infrequent sets. In STACS. Springer, 133--141.Google Scholar"",""Niv Buchbinder, Moran Feldman, Joseph Seffi, and Roy Schwartz. 2015. A tight linear time (1/2)-approximation for unconstrained submodular maximization. SIAM J. Comput., Vol. 44, 5 (2015), 1384--1402.Google ScholarCross Ref"",""Vineet Chaoji, Mohammad Al Hasan, Saeed Salem, Jeremy Besson, and Mohammed J. Zaki. 2008. Origami: A novel and effective approach for mining representative orthogonal graph patterns. SADM, Vol. 1, 2 (2008), 67--84.Google Scholar"",""Hong Cheng, Xifeng Yan, Jiawei Han, and Chih-Wei Hsu. 2007. Discriminative frequent pattern analysis for effective classification. In ICDE. IEEE, 716--725.Google Scholar"",""Peter Clark and Tim Niblett. 1989. The CN2 induction algorithm. Machine learning, Vol. 3, 4 (1989), 261--283.Google Scholar"",""William W Cohen. 1995. Fast effective rule induction. In Machine learning proceedings 1995. Elsevier, 115--123.Google Scholar"",""Sanjeeb Dash, Oktay Gunluk, and Dennis Wei. 2018. Boolean decision rules via column generation. In NeuIPS. 4655--4665.Google Scholar"",""Dheeru Dua and Casey Graff. 2017. UCI Machine Learning Repository. http://archive.ics.uci.edu/mlGoogle Scholar"",""Alex A Freitas. 2014. Comprehensible classification models: a position paper. KDD, Vol. 15, 1 (2014), 1--10.Google Scholar"",""Johannes Fürnkranz, Dragan Gamberger, and Nada Lavravc. 2012. Foundations of rule learning .Springer Science \u0026 Business Media.Google Scholar"",""Michael R Garey and David S Johnson. 2002. Computers and intractability. Vol. 29. wh freeman New York.Google Scholar"",""Leilani H Gilpin, David Bau, Ben Z Yuan, Ayesha Bajwa, Michael Specter, and Lalana Kagal. 2018. Explaining explanations: An overview of interpretability of machine learning. In DSAA. IEEE, 80--89.Google Scholar"",""Sreenivas Gollapudi and Aneesh Sharma. 2009. An axiomatic approach for result diversification. In WWW.Google Scholar"",""Dimitrios Gunopulos, Roni Khardon, Heikki Mannila, Sanjeev Saluja, Hannu Toivonen, and Ram Sewak Sharma. 2003. Discovering all most specific sentences. TODS, Vol. 28, 2 (2003), 140--174.Google ScholarDigital Library"",""Jiawei Han, Jian Pei, and Micheline Kamber. 2011. Data mining: concepts and techniques .Elsevier.Google Scholar"",""Mark Jerrum. 2003. Counting, sampling and integrating: algorithms and complexity .Springer Science \u0026 Business Media.Google Scholar"",""Subhash Khot. 2004. Ruling Out PTAS for Graph Min-Bisection, Densest Subgraph and Bipartite Clique ?. (2004).Google Scholar"",""Arno J Knobbe and Eric KY Ho. 2006. Pattern teams. In ECML PKDD. Springer, 577--584.Google Scholar"",""Himabindu Lakkaraju, Stephen H Bach, and Jure Leskovec. 2016. Interpretable decision sets: A joint framework for description and prediction. In KDD. ACM, 1675--1684.Google Scholar"",""Dennis Leman, Ad Feelders, and Arno Knobbe. 2008. Exceptional model mining. In ECML PKDD. Springer, 1--16.Google Scholar"",""Zachary C Lipton. 2018. The mythos of model interpretability. Queue, Vol. 16, 3 (2018), 31--57.Google ScholarDigital Library"",""Bing Liu, Wynne Hsu, Yiming Ma, et al. 1998. Integrating classification and association rule mining.. In KDD, Vol. 98. 80--86.Google Scholar"",""Dmitry Malioutov and Kush Varshney. 2013. Exact rule learning via boolean compressed sensing. In ICML. 765--773.Google Scholar"",""Sekharipuram S Ravi, Daniel J Rosenkrantz, and Giri Kumar Tayi. 1994. Heuristic and special case algorithms for dispersion problems. Operations Research (1994).Google Scholar"",""Guolong Su, Dennis Wei, Kush R Varshney, and Dmitry M Malioutov. 2015. Interpretable two-level boolean rule learning for classification. arXiv preprint arXiv:1511.07361 (2015).Google Scholar"",""Hannu Toivonen et al. 1996. Sampling large databases for association rules. In VLDB, Vol. 96. 134--145.Google Scholar"",""Leslie G Valiant. 1984. A theory of the learnable. Commun. ACM, Vol. 27, 11 (1984), 1134--1142.Google ScholarDigital Library"",""Tong Wang, Cynthia Rudin, Finale Doshi-Velez, Yimin Liu, Erica Klampfl, and Perry MacNeille. 2017. A bayesian framework for learning rule sets for interpretable classification. JMLR, Vol. 18, 1 (2017), 2357--2393.Google ScholarDigital Library"",""Guizhen Yang. 2004. The complexity of mining maximal frequent itemsets and maximal frequent patterns. In KDD. ACM, 344--353.Google Scholar""]"
https://doi.org/10.1145/3394486.3403205,Vamsa: Automated Provenance Tracking in Data Science Scripts,"There has recently been a lot of ongoing research in the areas of fairness, bias and explainability of machine learning (ML) models due to the self-evident or regulatory requirements of various ML applications. We make the following observation: All of these approaches require a robust understanding of the relationship between ML models and the data used to train them. In this work, we introduce the ML provenance tracking problem: the fundamental idea is to automatically track which columns in a dataset have been used to derive the features/labels of an ML model. We discuss the challenges in capturing such information in the context of Python, the most common language used by data scientists.We then present Vamsa, a modular system that extracts provenance from Python scripts without requiring any changes to the users' code. Using 26K real data science scripts, we verify the effectiveness of Vamsa in terms of coverage, and performance. We also evaluate Vamsa's accuracy on a smaller subset of manually labeled data. Our analysis shows that Vamsa's precision and recall range from 90.4% to 99.1% and its latency is in the order of milliseconds for average size scripts. Drawing from our experience in deploying ML models in production, we also present an example in which Vamsa helps automatically identify models that are affected by data corruption issues.","[{""name"":""Mohammad Hossein Namaki"",""id"":""/profile/86158882657""},{""name"":""Avrilia Floratou"",""id"":""/profile/81485655713""},{""name"":""Fotis Psallidas"",""id"":""/profile/99658715105""},{""name"":""Subru Krishnan"",""id"":""/profile/99658654915""},{""name"":""Ashvin Agrawal"",""id"":""/profile/99659198410""},{""name"":""Yinghui Wu"",""id"":""/profile/99659573362""},{""name"":""Yiwen Zhu"",""id"":""/profile/99659455197""},{""name"":""Markus Weimer"",""id"":""/profile/81363605401""},{""name"":""Mohammad Hossein Namaki"",""id"":""/profile/86158882657""},{""name"":""Avrilia Floratou"",""id"":""/profile/81485655713""},{""name"":""Fotis Psallidas"",""id"":""/profile/99658715105""},{""name"":""Subru Krishnan"",""id"":""/profile/99658654915""},{""name"":""Ashvin Agrawal"",""id"":""/profile/99659198410""},{""name"":""Yinghui Wu"",""id"":""/profile/99659573362""},{""name"":""Yiwen Zhu"",""id"":""/profile/99659455197""},{""name"":""Markus Weimer"",""id"":""/profile/81363605401""}]","[""Xgboost. https://xgboost.readthedocs.io/en/latest/index.html, 2014.Google Scholar"",""EU GDPR Regulations. https://ec.europa.eu/commission/priorities/justice-and-fundamental-rights/data-protection/2018-reform-eu-data-protection-rules/eu-data-protection-rules_en, 2018.Google Scholar"",""Kaggle Heart Disease. https://www.kaggle.com/ronitf/heart-disease-uci, 2018.Google Scholar"",""Kaggle survey. https://www.kaggle.com/kaggle/kaggle-survey-2018, 2018.Google Scholar"",""Official Kaggle API. https://github.com/Kaggle/kaggle-api, 2018.Google Scholar"",""Abstract syntax trees. https://docs.python.org/3/library/ast.html, 2019.Google Scholar"",""Explainable AI in Industry. https://sites.google.com/view/kdd19-explainable-ai-tutorial, 2019.Google Scholar"",""Explainable AI/ML (XAI) for Accountability, Fairness, and Transparency. https://xai.kdd2019.a.intuit.com/, 2019.Google Scholar"",""Fairness-Aware Machine Learning: Practical Challenges and Lessons learned. https://sites.google.com/view/kdd19-fairness-tutorial, 2019.Google Scholar"",""Kubeflow. https://www.kubeflow.org/, 2019.Google Scholar"",""Mlflow. https://github.com/mlflow/mlflow/, 2019.Google Scholar"",""Python AST docs. https://greentreesnakes.readthedocs.io/en/latest/, 2019.Google Scholar"",""Python language. https://towardsdatascience.com/programming-languages-for-data-scientists-afde2eaf5cc5, 2019.Google Scholar"",""PyTorch. https://pytorch.org/, 2019.Google Scholar"",""Typeshed. https://github.com/python/typeshed, 2019.Google Scholar"",""Vamsa. aka.ms/vamsa, 2020.Google Scholar"",""E. Angelino et al. Provenance integration requires reconciliation. In TaPP, 2011.Google Scholar"",""E. Angelino, D. Yamins, and M. Seltzer. Starflow: A script-centric data analysis environment. In IPAW, 2010.Google ScholarCross Ref"",""J. Cheney et al. Provenance in databases: Why, how, and where. TRDB, pages 379--474, 2009.Google Scholar"",""L. Chiticariu, W. C. Tan, and G. Vijayvargiya. Dbnotes: A post-it system for relational databases based on provenance. In SIGMOD, pages 942--944, 2005.Google ScholarDigital Library"",""Y. Cui, J. Widom, and J. L. Wiener. Tracing the lineage of view data in a warehousing environment. TODS, 25(2):179--227, 2000.Google ScholarDigital Library"",""D. Deutch, N. Frost, and A. Gilad. Provenance for natural language queries. PVLDB, 10(5):577--588, 2017.Google ScholarDigital Library"",""J. Freire and M. Anand. Provenance in scientific workflow systems. IEEE Data Engineering Bulletin, 2007.Google Scholar"",""R. Garcia et al. Context: The missing piece in the machine learning lifecycle. In KDD CMI Workshop, 2018.Google Scholar"",""T. Gebru et al. Datasheets for datasets, 2018.Google Scholar"",""R. Ikeda and J. Widom. Data lineage: A survey. Technical report, Stanford InfoLab, 2009.Google Scholar"",""Z. Ives et al. Dataset relationship management. In CIDR, 2019.Google Scholar"",""M. R. Lee and M. Shen. Winner's Curse: Bias Estimation for Total Effects of Features in Online Controlled Experiments. In KDD '18, 2018.Google ScholarDigital Library"",""T. McPhillips et al. Yesworkflow: A user-oriented, language-independent tool for recovering workflow information from scripts. IJDC, pages 298--313, 2015.Google ScholarCross Ref"",""X. Meng et al. Mllib: Machine learning in apache spark. JMLR, pages 1235--1241, 2016.Google Scholar"",""H. Miao and A. Deshpande. Provdb: Provenance-enabled lifecycle management of collaborative data analysis workflows. IEEE Data Eng. Bull., pages 26--38, 2018.Google Scholar"",""H. Miao et al. Modelhub: Deep learning lifecycle management. In ICDE, 2017.Google ScholarCross Ref"",""H. Miao et al. Towards unified data and lifecycle management for deep learning. In ICDE, 2017.Google ScholarCross Ref"",""M. H. Namaki et al. Answering why-questions by exemplars in attributed graphs. In SIGMOD, pages 1481--1498, 2019.Google ScholarDigital Library"",""M. H. Namaki et al. Vamsa: Tracking provenance in data science scripts (technical report). arXiv preprint arXiv:2001.01861, 2020.Google Scholar"",""F. Pedregosa et al. Scikit-learn: Machine learning in python. JMLR, pages 2825--2830, 2011.Google ScholarDigital Library"",""J. F. Pimentel et al. noworkflow: a tool for collecting, analyzing, and managing provenance from python scripts. VLDB, 2017.Google Scholar"",""L. Prokhorenkova et al. Catboost: unbiased boosting with categorical features. In NIPS, 2018.Google Scholar"",""F. Psallidas et al. Data science through the looking glass and what we found there. arXiv preprint arXiv:1912.09536, 2019.Google Scholar"",""F. Psallidas and E. Wu. Provenance for interactive visualizations. 2018.Google Scholar"",""F. Psallidas and E. Wu. Smoke: Fine-grained lineage at interactive speed. VLDB, pages 719--732, 2018.Google Scholar"",""E. D. Ragan, A. Endert, J. Sanyal, and J. Chen. Characterizing provenance in visualization and data analysis: an organizational framework of provenance types and purposes. IEEE Transactions on Visualization and Computer Graphics, 22(1):31--40, 2016.Google ScholarCross Ref"",""A. Rule, A. Tabard, and J. D. Hollan. Exploration and explanation in computational notebooks. In CHI, page 32, 2018.Google Scholar"",""S. Schelter et al. Automatically tracking metadata and provenance of machine learning experiments. In Machine Learning Systems workshop at NIPS, 2017.Google Scholar"",""S. Schelter et al. On challenges in machine learning model management. IEEE Data Eng. Bull., pages 5--15, 2018.Google Scholar"",""L. Shao et al. Griffon: Reasoning about job anomalies with unlabeled data in cloud-based platforms. SoCC '19, 2019.Google ScholarDigital Library"",""K. Shu et al. dEFEND: Explainable Fake News Detection. In ACM SIGKDD, pages 395--405. ACM, 2019.Google Scholar"",""L. Torczon and K. Cooper. Engineering A Compiler. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 2nd edition, 2011.Google Scholar"",""M. Vartak et al. Modeldb: a system for machine learning model management. In HILDA, 2016.Google Scholar"",""M. Vartak et al. Mistique: A system to store and query model intermediates for model diagnosis. In SIGMOD, 2018.Google ScholarDigital Library"",""E. Wu and S. Madden. Scorpion: Explaining away outliers in aggregate queries. PVLDB, 6(8):553--564, 2013.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403206,Deep State-Space Generative Model For Correlated Time-to-Event Predictions,"Capturing the inter-dependencies among multiple types of clinically-critical events is critical not only to accurate future event prediction, but also to better treatment planning. In this work, we propose a deep latent state-space generative model to capture the interactions among different types of correlated clinical events (e.g., kidney failure, mortality) by explicitly modeling the temporal dynamics of patients' latent states. Based on these learned patient states, we further develop a new general discrete-time formulation of the hazard rate function to estimate the survival distribution of patients with significantly improved accuracy. Extensive evaluations over real EMR data show that our proposed model compares favorably to various state-of-the-art baselines. Furthermore, our method also uncovers meaningful insights about the latent correlations among mortality and different types of organ failures.","[{""name"":""Yuan Xue"",""id"":""/profile/99659574253""},{""name"":""Denny Zhou"",""id"":""/profile/99659573824""},{""name"":""Nan Du"",""id"":""/profile/99659218449""},{""name"":""Andrew M. Dai"",""id"":""/profile/99659048763""},{""name"":""Zhen Xu"",""id"":""/profile/99659573736""},{""name"":""Kun Zhang"",""id"":""/profile/99659574479""},{""name"":""Claire Cui"",""id"":""/profile/99659574793""},{""name"":""Yuan Xue"",""id"":""/profile/99659574253""},{""name"":""Denny Zhou"",""id"":""/profile/99659573824""},{""name"":""Nan Du"",""id"":""/profile/99659218449""},{""name"":""Andrew M. Dai"",""id"":""/profile/99659048763""},{""name"":""Zhen Xu"",""id"":""/profile/99659573736""},{""name"":""Kun Zhang"",""id"":""/profile/99659574479""},{""name"":""Claire Cui"",""id"":""/profile/99659574793""}]","[""Martín Abadi and et al. 2015. TensorFlow: A System for Large-Scale Machine Learning.Google Scholar"",""Ahmed M. Alaa and Mihaela van der Schaar. 2017. Deep Multi-task Gaussian Processes for Survival Analysis with Competing Risks. In NIPS. 2329--2337.Google Scholar"",""Ahmed M. Alaa and Mihaela van der Schaar. 2019. Attentive State-Space Modeling of Disease Progression. In NeurIPS.Google Scholar"",""James E. Barretta and Anthony C. C. Coolena. 2010. Gaussian process regression for survival data with competing risks.Google Scholar"",""Alexis Bellot and Mihaela van der Schaar. 2018. Multitask Boosting for Survival Analysis with Competing Risks. In NeurIPS.Google Scholar"",""Paidamoyo Chapfuwa, Chenyang Tao, Chunyuan Li, Courtney Page, Benjamin Goldstein, Lawrence Carin, and Ricardo Henao. 2018. Adversarial Time-to-Event Modeling. In ICML.Google Scholar"",""Zhengping Che, Sanjay Purushotham, Kyunghyun Cho, David Sontag, and YanLiu. 2018. Recurrent Neural Networks for Multivariate Time Series with Missing Values. Sci. Rep.8, 1 (2018).Google Scholar"",""Edward Choi, Mohammad Taha Bahadori, Andy Schuetz, Walter F Stewart, and Jimeng Sun. 2015. Doctor AI: Predicting Clinical Events via Recurrent Neural Networks. (Nov. 2015). arXiv:1511.05942Google Scholar"",""D. R. Cox. 1992. Regression models and life-tables. In Breakthroughs in statistics. 527--541.Google Scholar"",""Tamara Fernandez, Nicolas Rivera, and Yee Whye Teh. 2016. Gaussian Processes for Survival Analysis. In NIPS. 5021--5029.Google Scholar"",""J. P. Fine and R. J. Gray. 1999. A Proportional Hazards Model for the Sub distribution of a Competing Risk. Journal of the American statistical association 94, 446(1999), 496--509.Google ScholarCross Ref"",""Marco Fraccaro, Simon Kamronn, Ulrich Paquet, and Ole Winther. 2017. A Disentangled Recognition and Nonlinear Dynamics Model for Unsupervised Learning. In NIPS.Google Scholar"",""Marco Fraccaro, Søren Kaae Sønderby, Ulrich Paquet, and Ole Winther. 2016. Sequential Neural Models with Stochastic Layers. In NIPS.Google Scholar"",""Marzyeh Ghassemi, Mike Wu, Michael C. Hughes, Peter Szolovits, and Finale Doshi-Velez. 2017. Predicting intervention onset in the ICU with switching state space models. American Medical Informatics Association (AMIA),.Google Scholar"",""E. Giunchiglia, A. Nemchenko, and M. van der Schaar. 2018. RNN-SURV: A Deep Recurrent Model for Survival Analysis. In International Conference on Artificial Neural Networks (ICANN).Google Scholar"",""Alistair E.W. Johnson, Tom J. Pollard, Lu Shen, Li wei H. Lehman, Mengling Feng,Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, andRoger G. Mark. 2016. MIMIC-III, A Freely Accessible Critical Care Database. Scientific Data 3 (2016). Article number: 160035.Google Scholar"",""Alan E. Jones, Stephen Trzeciak, and MD Jeffrey A. Kline. 2010. The Sequential Organ Failure Assessment score for predicting outcome in patients with severe sepsis and evidence of hypoper fusion at the time of emergency department presentation.Google Scholar"",""Maximilian Karl, Maximilian Soelch, Justin Bayer, and Patrick van der Smagt. 2017. Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data. In ICLR.Google Scholar"",""Jared L. Katzman, Uri Shaham, Alexander Cloninger, Jonathan Bates, Tingting Jiang, and Yuval Kluger. 2018. DeepSurv: personalized treatment recommender system using a Cox proportional hazards deep neural network. BMC Medical Research Methodology 18, 1 (2018), 24.Google ScholarCross Ref"",""Rahul G. Krishnan, Uri Shalit, and David Sontag. 2015. Deep Kalman Filters. CoRRabs/1511.05121 (2015).Google Scholar"",""Rahul G Krishnan, Uri Shalit, and David Sontag. 2017. Structured Inference Networks for Nonlinear State Space Models. In AAAI.Google Scholar"",""Changhee Lee, William R. Zame, Jinsung Yoon, and Mihaela van der Schaar. 2018. DeepHit: A Deep Learning Approach to Survival Analysis with Competing Risks. In AAAI.Google Scholar"",""Zachary C Lipton, David C Kale, Charles Elkan, and Randall Wetzel. 2016. Learning to Diagnose with LSTM Recurrent Neural Networks. In International Conference on Learning Representations (ICLR).Google Scholar"",""Zitao Liu and Milos Hauskrecht. 2013. Clinical Time Series Prediction with a Hierarchical Dynamical System.Artificial Intelligence in Medicine(2013), 227--237.Google Scholar"",""Zitao Liu and Milos Hauskrecht. 2016. Learning Adaptive Forecasting Models from Irregularly Sampled Multivariate Clinical Data. In AAAI.Google Scholar"",""Jiayu Zhou Dongxiao Zhu Lu Wang, Yan Li and Jieping Ye. 2017. Multi-task Survival Analysis. In IEEE International Conference on Data Mining.Google Scholar"",""Wu M, Ghassemi M, Feng M, Celi LA, Szolovits P, and Doshi-Velez F. 2017. Understanding vasopressor intervention and weaning: risk prediction in a public heterogeneous clinical time series database. J Am Med Inform Assoc(2017),488--495.Google Scholar"",""Aniruddh Raghu, Matthieu Komorowski, Leo Anthony Celi, Peter Szolovits, and Marzyeh Ghassemi. 2017. Continuous State-Space Models for Optimal Sepsis Treatment: a Deep Reinforcement Learning Approach. In Proceedings of the 2nd Machine Learning for Healthcare Conference. 147--163.Google Scholar"",""Alvin Rajkomar and et al. 2018. Scalable and Accurate Deep Learning with Electronic Health Records. Digital Medicine1 (2018). Article number: 18.Google Scholar"",""Rajesh Ranganath, Adler Perotte, Noémie Elhadad, and David Blei. 2016. Deep Survival Analysis. In Proceedings of Machine Learning Research. Vol. 56. 101--114.Google Scholar"",""Kan Ren, Jiarui Qin, Lei Zheng, Zhengyu Yang, Weinan Zhang, Lin Qiu, and Yong Yu. 2019. Deep Recurrent Survival Analysis. In AAAI.Google Scholar"",""Ying Sha and May D Wang. 2017. Interpretable Predictions of Clinical Out-comes with An Attention-based Recurrent Neural Network. In Proceedings of the 8th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics.Google Scholar"",""Huan Song, Deepta Rajan, Jayaraman J Thiagarajan, and Andreas Spanias. 2018.Attend and Diagnose: Clinical Time Series Analysis Using Attention Models. InAAAI.Google Scholar"",""Yuan Xue, Denny Zhou, Nan Du, Andrew M. Dai, Zhen Xu, Kun Zhang, and Claire Cui. 2019. Deep Physiological State Space Model for Clinical Forecasting. In NeurIPS Workshop on Machine Learning for Health.Google Scholar"",""Jieping Ye Yan Li, Jie Wang and Chandan K. Reddy. 2016. A Multi-Task Learning Formulation for Survival Analysis. In 22nd ACM SIGKDD.Google Scholar"",""Quan Zhang and Mingyuan Zhou. 2018. Nonparametric Bayesian Lomax delegate racing for survival analysis with competing risks. In NeurIPS.Google Scholar""]"
https://doi.org/10.1145/3394486.3403207,Meta-learning on Heterogeneous Information Networks for Cold-start Recommendation,"Cold-start recommendation has been a challenging problem due to sparse user-item interactions for new users or items. Existing efforts have alleviated the cold-start issue to some extent, most of which approach the problem at the data level. Earlier methods often incorporate auxiliary data as user or item features, while more recent methods leverage heterogeneous information networks (HIN) to capture richer semantics via higher-order graph structures. On the other hand, recent meta-learning paradigm sheds light on addressing cold-start recommendation at the model level, given its ability to rapidly adapt to new tasks with scarce labeled data, or in the context of cold-start recommendation, new users and items with very few interactions. Thus, we are inspired to develop a novel meta-learning approach named MetaHIN to address cold-start recommendation on HINs, to exploit the power of meta-learning at the model level and HINs at the data level simultaneously. The solution is non-trivial, for how to capture HIN-based semantics in the meta-learning setting, and how to learn the general knowledge that can be easily adapted to multifaceted semantics, remain open questions. In MetaHIN, we propose a novel semantic-enhanced tasks constructor and a co-adaptation meta-learner to address the two questions. Extensive experiments demonstrate that MetaHIN significantly outperforms the state of the arts in various cold-start scenarios. (Code and dataset are available at https://github.com/rootlu/MetaHIN.)","[{""name"":""Yuanfu Lu"",""id"":""/profile/99659477494""},{""name"":""Yuan Fang"",""id"":""/profile/81479651646""},{""name"":""Chuan Shi"",""id"":""/profile/81496666708""},{""name"":""Yuanfu Lu"",""id"":""/profile/99659477494""},{""name"":""Yuan Fang"",""id"":""/profile/81479651646""},{""name"":""Chuan Shi"",""id"":""/profile/81496666708""}]","[""Rianne van den Berg, Thomas N Kipf, and Max Welling. 2017. Graph convolutional matrix completion. arXiv preprint arXiv:1706.02263 (2017).Google Scholar"",""Tianfeng Chai and Roland R Draxler. 2014. Root mean square error (RMSE) or mean absolute error (MAE)?--Arguments against avoiding RMSE in the literature. Geoscientific model development, Vol. 7, 3 (2014), 1247--1250.Google Scholar"",""Maurizio Ferrari Dacrema, Paolo Cremonesi, and Dietmar Jannach. 2019. Are we really making much progress? A worrying analysis of recent neural recommendation approaches. In RecSys. 101--109.Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In NAACL-HLT, Jill Burstein, Christy Doran, and Thamar Solorio (Eds.). 4171--4186.Google Scholar"",""Yuxiao Dong, Nitesh V Chawla, and Ananthram Swami. 2017. metapath2vec: Scalable representation learning for heterogeneous networks. In SIGKDD. 135--144.Google Scholar"",""Zhengxiao Du, Xiaowei Wang, Hongxia Yang, Jingren Zhou, and Jie Tang. 2019. Sequential Scenario-Specific Meta Learner for Online Recommendation. In SIGKDD. 2895--2904.Google Scholar"",""Yuan Fang, Wenqing Lin, Vincent W Zheng, Min Wu, Kevin Chen-Chuan Chang, and Xiao-Li Li. 2016. Semantic proximity search on graphs with metagraph-based learning. In ICDE. IEEE, 277--288.Google Scholar"",""Yuan Fang, Wenqing Lin, Vincent W Zheng, Min Wu, Jiaqi Shi, Kevin Chang, and Xiaoli Li. 2019. Metagraph-based Learning on Heterogeneous Graphs. IEEE TKDE (2019).Google Scholar"",""Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017. Model-agnostic meta-learning for fast adaptation of deep networks. In ICML. 1126--1135.Google Scholar"",""Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In WWW. 173--182.Google Scholar"",""Binbin Hu, Chuan Shi, Wayne Xin Zhao, and Philip S Yu. 2018a. Leveraging meta-path based context for top-n recommendation with a neural co-attention model. In SIGKDD. 1531--1540.Google Scholar"",""Guangneng Hu, Yu Zhang, and Qiang Yang. 2018b. Conet: Collaborative cross networks for cross-domain recommendation. In CIKM. 667--676.Google ScholarDigital Library"",""SeongKu Kang, Junyoung Hwang, Dongha Lee, and Hwanjo Yu. 2019. Semi-Supervised Learning for Cross-Domain Recommendation to Cold-Start Users. In CIKM. 1563--1572.Google Scholar"",""Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In ICLR .Google Scholar"",""Duc-Trong Le, Yuan Fang, and Hady W Lauw. 2016. Modeling sequential preferences with dynamic user and context factors. In ECML-PKDD. Springer, 145--161.Google Scholar"",""Hoyeop Lee, Jinbae Im, Seongwon Jang, Hyunsouk Cho, and Sehee Chung. 2019. MeLU: Meta-Learned User Preference Estimator for Cold-Start Recommendation. In SIGKDD. 1073--1082.Google Scholar"",""Xiaopeng Li and James She. 2017. Collaborative variational autoencoder for recommender systems. In SIGKDD. 305--314.Google Scholar"",""Tsendsuren Munkhdalai and Hong Yu. 2017. Meta networks. In ICML. 2554--2563.Google Scholar"",""Feiyang Pan, Shuokai Li, Xiang Ao, Pingzhong Tang, and Qing He. 2019. Warm Up Cold-start Advertisements: Improving CTR Predictions via Learning to Learn ID Embeddings. In SIGIR. 695--704.Google Scholar"",""Steffen Rendle, Zeno Gantner, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2011. Fast context-aware recommendations with factorization machines. In SIGIR. 635--644.Google Scholar"",""Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy Lillicrap. 2016. Meta-learning with memory-augmented neural networks. In ICML. 1842--1850.Google Scholar"",""Chuan Shi, Binbin Hu, Wayne Xin Zhao, and Philip S. Yu. 2018. Heterogeneous Information Network Embedding for Recommendation. IEEE TKDE, Vol. 31, 2 (2018), 357--370.Google Scholar"",""Chuan Shi, Yitong Li, Jiawei Zhang, Yizhou Sun, and S Yu Philip. 2017. A survey of heterogeneous information network analysis. IEEE TKDE, Vol. 29, 1 (2017), 17--37.Google Scholar"",""Jake Snell, Kevin Swersky, and Richard Zemel. 2017. Prototypical networks for few-shot learning. In NeurIPS. 4077--4087.Google Scholar"",""Yizhou Sun, Jiawei Han, Xifeng Yan, Philip S. Yu, and Tianyi Wu. 2011. PathSim: Meta Path-Based Top-K Similarity Search in Heterogeneous Information Networks. PVLDB, Vol. 4, 11 (2011), 992--1003.Google ScholarDigital Library"",""Flood Sung, Yongxin Yang, Li Zhang, Tao Xiang, Philip HS Torr, and Timothy M Hospedales. 2018. Learning to compare: Relation network for few-shot learning. In CVPR. 1199--1208.Google Scholar"",""Manasi Vartak, Arvind Thiagarajan, Conrado Miranda, Jeshua Bratman, and Hugo Larochelle. 2017. A meta-learning perspective on cold-start recommendations for items. In NeurIPS. 6904--6914.Google Scholar"",""Ricardo Vilalta and Youssef Drissi. 2002. A perspective view and survey of meta-learning. Artificial intelligence review, Vol. 18, 2 (2002), 77--95.Google Scholar"",""Maksims Volkovs, Guangwei Yu, and Tomi Poutanen. 2017. Dropoutnet: Addressing cold start in recommender systems. In NeurIPS. 4957--4966.Google Scholar"",""Xiang Wang, Xiangnan He, Yixin Cao, Meng Liu, and Tat-Seng Chua. 2019 a. Kgat: Knowledge graph attention network for recommendation. In SIGKDD. 950--958.Google Scholar"",""Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019 b. Neural Graph Collaborative Filtering. In SIGIR. 165--174.Google Scholar"",""Huaxiu Yao, Ying Wei, Junzhou Huang, and Zhenhui Li. 2019. Hierarchically Structured Meta-learning. In ICML. 7045--7054.Google Scholar"",""Xi Sheryl Zhang, Fengyi Tang, Hiroko H Dodge, Jiayu Zhou, and Fei Wang. 2019. Metapred: Meta-learning for clinical risk prediction with limited patient electronic health records. In SIGKDD. 2487--2495.Google ScholarDigital Library"",""Yongfeng Zhang, Qingyao Ai, Xu Chen, and W Bruce Croft. 2017. Joint representation learning for top-n recommendation with heterogeneous information sources. In CIKM. 1449--1458.Google Scholar"",""Yu Zhu, Jinghao Lin, Shibi He, Beidou Wang, Ziyu Guan, Haifeng Liu, and Deng Cai. 2019. Addressing the item cold-start problem by attribute-driven active learning. IEEE TKDE (2019).Google Scholar""]"
https://doi.org/10.1145/3394486.3403208,WavingSketch: An Unbiased and Generic Sketch for Finding Top-k Items in Data Streams,"Finding top-k items in data streams is a fundamental problem in data mining. Existing algorithms that can achieve unbiased estimation suffer from poor accuracy. In this paper, we propose a new sketch, WavingSketch, which is much more accurate than existing unbiased algorithms. WavingSketch is generic, and we show how it can be applied to four applications: finding top-k frequent items, finding top-k heavy changes, finding top-k persistent items, and finding top-k Super-Spreaders. We theoretically prove that WavingSketch can provide unbiased estimation, and then give an error bound of our algorithm. Our experimental results show that, compared with the state-of-the-art, WavingSketch has 4.50 times higher insertion speed and up to 9 x 106 times (2 x 104 times in average) lower error rate in finding frequent items when memory size is tight. For other applications, WavingSketch can also achieve up to 286 times lower error rate. All related codes are open-sourced and available at Github anonymously.","[{""name"":""Jizhou Li"",""id"":""/profile/99659574973""},{""name"":""Zikun Li"",""id"":""/profile/99659574839""},{""name"":""Yifei Xu"",""id"":""/profile/99659574346""},{""name"":""Shiqi Jiang"",""id"":""/profile/99659574461""},{""name"":""Tong Yang"",""id"":""/profile/99658630798""},{""name"":""Bin Cui"",""id"":""/profile/81502785823""},{""name"":""Yafei Dai"",""id"":""/profile/81323489020""},{""name"":""Gong Zhang"",""id"":""/profile/99659058990""},{""name"":""Jizhou Li"",""id"":""/profile/99659574973""},{""name"":""Zikun Li"",""id"":""/profile/99659574839""},{""name"":""Yifei Xu"",""id"":""/profile/99659574346""},{""name"":""Shiqi Jiang"",""id"":""/profile/99659574461""},{""name"":""Tong Yang"",""id"":""/profile/99658630798""},{""name"":""Bin Cui"",""id"":""/profile/81502785823""},{""name"":""Yafei Dai"",""id"":""/profile/81323489020""},{""name"":""Gong Zhang"",""id"":""/profile/99659058990""}]","[""G. Lukasz, D. David, D. Erik D, L. Alejandro, and M. J Ian. Identifying frequent items in sliding windows over on-line packet streams. In IMC. ACM, 2003.Google Scholar"",""Richard M Karp, Scott Shenker, and Christos H Papadimitriou. A simple algorithm for finding frequent elements in streams and bags. ACM Transactions on Database Systems (TODS), 28(1):51--55, 2003.Google Scholar"",""M. Nishad and P. Themis. Frequent items in streaming data: An experimental evaluation of the state-of-the-art. Data \u0026 Knowledge Engineering, 2009.Google Scholar"",""Moses Charikar, Kevin Chen, and Martin Farach-Colton. Finding frequent items in data streams. In Automata, Languages and Programming. Springer, 2002.Google ScholarDigital Library"",""Zhewei Wei, Ge Luo, Ke Yi, Xiaoyong Du, and Ji-Rong Wen. Persistent data sketching. In ¶roc ACM SIGMOD, pages 795--810. ACM, 2015.Google Scholar"",""Robert Schweller, Zhichun Li, Yan Chen, et al. Reversible sketches: enabling monitoring and analysis over high-speed data streams. IEEE/ACM Transactions on Networking (ToN), 15(5):1059--1072, 2007.Google Scholar"",""K. Balachander, S. Subhabrata, Z. Yin, and C. Yan. Sketch-based change detection: methods, evaluation, and applications. In Proceedings of the 3rd ACM SIGCOMM conference on Internet measurement, pages 234--247. ACM, 2003.Google Scholar"",""Yuliang Li, Rui Miao, Changhoon Kim, and Minlan Yu. Flowradar: a better netflow for data centers. In USENIX NSDI, pages 311--324. USENIX Association, 2016.Google ScholarDigital Library"",""D. Haipeng, S. Muhammad, L. Alex X, and Z. Yuankun. Finding persistent items in data streams. ¶roc VLDB, 2016.Google Scholar"",""S. Venkataraman, D. Xiaodong Song, P. B. Gibbons, and A. Blum. New streaming algorithms for fast detection of superspreaders. In NDSS, 2005.Google Scholar"",""Graham Cormode and S Muthukrishnan. An improved data stream summary: the count-min sketch and its applications. Journal of Algorithms, 55(1), 2005.Google ScholarDigital Library"",""Cristian Estan and George Varghese. New directions in traffic measurement and accounting. ACM SIGMCOMM CCR, 32(4), 2002.Google Scholar"",""Ahmed Metwally, Divyakant Agrawal, and Amr El Abbadi. Efficient computation of frequent and top-k elements in data streams. In International Conference on Database Theory. Springer, 2005.Google Scholar"",""M. Gurmeet Singh and M. Rajeev. Approximate frequency counts over data streams. In ¶roc VLDB, pages 346--357, 2002.Google Scholar"",""Daniel Ting. Data sketches for disaggregated subset sum and frequent item estimation. In SIGMOD Conference, 2018.Google ScholarDigital Library"",""Ming Ji, Jun Yan, Siyu Gu, Jiawei Han, Xiaofei He, Wei Vivian Zhang, and Zheng Chen. Learning search tasks in queries and web pages via graph regularization. In ¶roc ACM SIGIR, pages 55--64. ACM, 2011.Google Scholar"",""Source code related to aname. https://github.com/WavingSketch/Waving-Sketch.Google Scholar"",""Graham Cormode. Sketch techniques for approximate query processing. Foundations and Trends in Databases. NOW publishers, 2011.Google Scholar"",""Pinghui Wang, Yiyan Qi, Yuanming Zhang, Qiaozhu Zhai, Chenxu Wang, John CS Lui, and Xiaohong Guan. A memory-efficient sketch method for estimating high similarities in streaming sets. In SIGKDD, pages 25--33, 2019.Google ScholarDigital Library"",""Jiawei Jiang, Fangcheng Fu, Tong Yang, and Bin Cui. Sketchml: Accelerating distributed machine learning with data sketches. In SIGMOD. ACM, 2018.Google Scholar"",""Tong Yang, Jie Jiang, Peng Liu, Qun Huang, Junzhi Gong, Yang Zhou, Rui Miao, Xiaoming Li, and Steve Uhlig. Elastic sketch: Adaptive and fast network-wide measurements. In ACM SIGCOMM 2018, pages 561--575, 2018.Google Scholar"",""Tong Yang, Yang Zhou, Hao Jin, Shigang Chen, and Xiaoming Li. Pyramid sketch: A sketch framework for frequency estimation of data streams. Proc. VLDB Endow., 10(11):1442--1453, August 2017.Google ScholarDigital Library"",""Tong Yang, Alex X Liu, Muhammad Shahzad, Yuankun Zhong, Qiaobin Fu, Zi Li, Gaogang Xie, and Xiaoming Li. A shifting bloom filter framework for set queries. Proceedings of the VLDB Endowment, 9(5):408--419, 2016.Google ScholarDigital Library"",""Yang Zhou, Tong Yang, Jie Jiang, Bin Cui, Minlan Yu, Xiaoming Li, and Steve Uhlig. Cold filter: A meta-framework for faster and more accurate stream processing. In SIGMOD Conference, 2018.Google Scholar"",""Bofang Li, Aleksandr Drozd, and et al. Scaling word2vec on big corpus. Data Science and Engineering, pages 1--19, 2019.Google Scholar"",""Stephen Bonner, Ibad Kureshi, and et al. Exploring the semantic content of unsupervised graph embeddings: An empirical study. Data Science and Engineering, 4(3):269--289, 2019.Google ScholarCross Ref"",""Yinghui Wang, Peng Lin, and Yiguang Hong. Distributed regression estimation with incomplete data in multi-agent networks. Science China Information Sciences, 61(9):092202, 2018.Google ScholarCross Ref"",""Tongya Zheng, Gang Chen, and et al. Real-time intelligent big data processing: technology, platform, and applications. Science China Information Sciences, 62(8):82101, 2019.Google ScholarCross Ref"",""R. Pratanu, K. Arijit, and A. Gustavo. Augmented sketch: Faster and more accurate stream processing. In ¶roc ACM SIGMOD, 2016.Google Scholar"",""C. Graham and H. Marios. Finding frequent items in data streams. VLDB, 2008.Google Scholar"",""Tong Yang, Junzhi Gong, Haowei Zhang, Lei Zou, Lei Shi, and Xiaoming Li. Heavyguardian: Separate and guard hot items in data streams. In SIGKDD, 2018.Google Scholar"",""A. Shokrollahi. Raptor codes. IEEE Transactions Information Theory, 52(6), 2006.Google ScholarDigital Library"",""Bibudh Lahiri, Jaideep Chandrashekar, and Srikanta Tirthapura. Space-efficient tracking of persistent items in a massive data stream. Statistical Analysis and Data Mining, 7:70--92, 2011.Google ScholarDigital Library"",""Minlan Yu, Lavanya Jose, and Rui Miao. Software defined traffic measurement with opensketch. In NSDI 2013, 2013.Google Scholar"",""Michael Flynn. Some computer organizations and their effectiveness. ieee trans comput c-21:948. Computers, IEEE Transactions on, C-21:948 -- 960, 10 1972.Google Scholar"",""Burton H Bloom. Space/time trade-offs in hash coding with allowable errors. Communications of the ACM, 13(7):422--426, 1970.Google ScholarDigital Library"",""Hash website. http://burtleburtle.net/bob/hash/evahash.html.Google Scholar"",""David MW Powers. Applications and explanations of Zipf's law. In ¶roc EMNLP-CoNLL. Association for Computational Linguistics, 1998.Google Scholar"",""Alex Rousskov and Duane Wessels. High-performance benchmarking with web polygraph. Software: Practice and Experience, 2004.Google Scholar"",""The caida anonymized 2016 traces. http://www.caida.org/data/overview/.Google Scholar"",""Real-life transactional dataset. http://fimi.ua.ac.be/data/.Google Scholar"",""The Network dataset Internet Traces. http://snap.stanford.edu/data/.Google Scholar""]"
https://doi.org/10.1145/3394486.3403209,Dynamic Knowledge Graph based Multi-Event Forecasting,"Modeling concurrent events of multiple types and their involved actors from open-source social sensors is an important task for many domains such as health care, disaster relief, and financial analysis. Forecasting events in the future can help human analysts better understand global social dynamics and make quick and accurate decisions. Anticipating participants or actors who may be involved in these activities can also help stakeholders to better respond to unexpected events. However, achieving these goals is challenging due to several factors: (i) it is hard to filter relevant information from large-scale input, (ii) the input data is usually high dimensional, unstructured, and Non-IID (Non-independent and identically distributed) and (iii) associated text features are dynamic and vary over time. Recently, graph neural networks have demonstrated strengths in learning complex and relational data. In this paper, we study a temporal graph learning method with heterogeneous data fusion for predicting concurrent events of multiple types and inferring multiple candidate actors simultaneously. In order to capture temporal information from historical data, we propose Glean, a graph learning framework based on event knowledge graphs to incorporate both relational and word contexts. We present a context-aware embedding fusion module to enrich hidden features for event actors. We conducted extensive experiments on multiple real-world datasets and show that the proposed method is competitive against various state-of-the-art methods for social event prediction and also provides much-need interpretation capabilities.","[{""name"":""Songgaojun Deng"",""id"":""/profile/99659453521""},{""name"":""Huzefa Rangwala"",""id"":""/profile/81323495082""},{""name"":""Yue Ning"",""id"":""/profile/81488642258""},{""name"":""Songgaojun Deng"",""id"":""/profile/99659453521""},{""name"":""Huzefa Rangwala"",""id"":""/profile/81323495082""},{""name"":""Yue Ning"",""id"":""/profile/81488642258""}]","[""Fernando Benites and Elena Sapozhnikova. 2015. Haram: a hierarchical aram neural network for large-scale text classification. In ICDMW. IEEE, 847--854.Google Scholar"",""Johan Bollen, Huina Mao, and Xiaojun Zeng. 2011. Twitter mood predicts the stock market. Journal of computational science, Vol. 2, 1 (2011), 1--8.Google ScholarCross Ref"",""Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko. 2013. Translating embeddings for modeling multi-relational data. In NIPS. 2787--2795.Google Scholar"",""Elizabeth Boschee, Jennifer Lautenschlager, Sean O'Brien, Steve Shellman, James Starz, and Michael Ward. 2015. ICEWS Coded Event Data.Google Scholar"",""Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning Phrase Representations using RNN Encoder--Decoder for Statistical Machine Translation. In EMNLP. Association for Computational Linguistics, 1724--1734.Google Scholar"",""Kenneth Ward Church and Patrick Hanks. 1990. Word Association Norms, Mutual Information, and Lexicography. Comput. Linguist., Vol. 16, 1 (March 1990), 22--29.Google ScholarDigital Library"",""Shib Sankar Dasgupta, Swayambhu Nath Ray, and Partha Talukdar. 2018. Hyte: Hyperplane-based temporally aware knowledge graph embedding. In EMNLP. 2001--2011.Google Scholar"",""Songgaojun Deng, Huzefa Rangwala, and Yue Ning. 2019. Learning Dynamic Context Graphs for Predicting Social Events. In KDD. ACM, 1007--1016.Google Scholar"",""Tim Dettmers, Pasquale Minervini, Pontus Stenetorp, and Sebastian Riedel. 2018. Convolutional 2d knowledge graph embeddings. In AAAI.Google Scholar"",""Alex Fout, Jonathon Byrd, Basir Shariat, and Asa Ben-Hur. 2017. Protein Interface Prediction Using Graph Convolutional Networks. In NIPS (NIPS'17). Curran Associates Inc., Red Hook, NY, USA, 6533--6542.Google Scholar"",""Yuyang Gao, Liang Zhao, Lingfei Wu, Yanfang Ye, Hui Xiong, and Chaowei Yang. 2019. Incomplete Label Multi-Task Deep Learning for Spatio-Temporal Event Subtype Forecasting. In AAAI, Vol. 33. 3638--3646.Google ScholarCross Ref"",""Alberto Garc'ia-Durán, Sebastijan Dumanvc ić, and Mathias Niepert. 2018. Learning sequence encoders for temporal knowledge graph completion. arXiv preprint arXiv:1809.03202 (2018).Google Scholar"",""Xavier Glorot and Yoshua Bengio. 2010. Understanding the difficulty of training deep feedforward neural networks. In AISTATS. 249--256.Google Scholar"",""Woojeong Jin, Changlin Zhang, Pedro Szekely, and Xiang Ren. 2019. Recurrent event network for reasoning over temporal knowledge graphs. arXiv preprint arXiv:1904.05530 (2019).Google Scholar"",""D Kinga and J Ba Adam. 2015. A method for stochastic optimization. In ICLR, Vol. 5.Google Scholar"",""Thomas N Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional networks. In ICLR.Google Scholar"",""Julien Leblay and Melisachew Wudage Chekol. 2018. Deriving validity time in knowledge graph. In WWW. International World Wide Web Conferences Steering Committee, 1771--1776.Google ScholarDigital Library"",""Minh-Thang Luong, Hieu Pham, and Christopher D Manning. 2015. Effective approaches to attention-based neural machine translation. arXiv preprint arXiv:1508.04025 (2015).Google Scholar"",""Dhruv Mahajan, Ross Girshick, Vignesh Ramanathan, Kaiming He, Manohar Paluri, Yixuan Li, Ashwin Bharambe, and Laurens van der Maaten. 2018. Exploring the limits of weakly supervised pretraining. In ECCV. 181--196.Google Scholar"",""Diego Marcheggiani and Ivan Titov. 2017. Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling. In EMNLP. Association for Computational Linguistics, 1506--1515.Google Scholar"",""Aditya K Menon, Ankit Singh Rawat, Sashank Reddi, and Sanjiv Kumar. 2019. Multilabel reductions: what is my loss optimising?. In NIPS. 10599--10610.Google Scholar"",""Vinod Nair and Geoffrey E Hinton. 2010. Rectified linear units improve restricted boltzmann machines. In ICML. 807--814.Google Scholar"",""Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. 2011. A three-way model for collective learning on multi-relational data.. In ICML, Vol. 11. 809--816.Google ScholarDigital Library"",""Yue Ning, Sathappan Muthiah, Huzefa Rangwala, and Naren Ramakrishnan. 2016. Modeling precursors for event forecasting via nested multi-instance learning. In KDD. ACM, 1095--1104.Google Scholar"",""Yue Ning, Rongrong Tao, Chandan K Reddy, Huzefa Rangwala, James C Starz, and Naren Ramakrishnan. 2018. STAPLE: Spatio-Temporal Precursor Learning for Event Forecasting. In SIAM. SIAM, 99--107.Google Scholar"",""Jiezhong Qiu, Jian Tang, Hao Ma, Yuxiao Dong, Kuansan Wang, and Jie Tang. 2018. DeepInf: Modeling influence locality in large social networks. In KDD.Google Scholar"",""Sashank J Reddi, Satyen Kale, Felix Yu, Dan Holtmann-Rice, Jiecao Chen, and Sanjiv Kumar. 2018. Stochastic negative mining for learning with large output spaces. arXiv preprint arXiv:1810.07076 (2018).Google Scholar"",""Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den Berg, Ivan Titov, and Max Welling. 2018. Modeling relational data with graph convolutional networks. In ESWC. Springer, 593--607.Google Scholar"",""Alessio Signorini, Alberto Maria Segre, and Philip M Polgreen. 2011. The use of Twitter to track levels of disease activity and public concern in the US during the influenza A H1N1 pandemic. PloS one, Vol. 6, 5 (2011), e19467.Google ScholarCross Ref"",""Eleftherios Spyromitros, Grigorios Tsoumakas, and Ioannis Vlahavas. 2008. An empirical study of lazy multilabel classification algorithms. In Hellenic conference on artificial intelligence. Springer, 401--406.Google ScholarDigital Library"",""Rakshit Trivedi, Hanjun Dai, Yichen Wang, and Le Song. 2017. Know-evolve: Deep temporal reasoning for dynamic knowledge graphs. In ICML. JMLR. org, 3462--3471.Google Scholar"",""Théo Trouillon, Johannes Welbl, Sebastian Riedel, Éric Gaussier, and Guillaume Bouchard. 2016. Complex embeddings for simple link prediction. In ICML. 2071--2080.Google Scholar"",""Shikhar Vashishth, Soumya Sanyal, Vikram Nitin, and Partha Talukdar. 2019. Composition-based multi-relational graph convolutional networks. arXiv preprint arXiv:1911.03082 (2019).Google Scholar"",""Xiaofeng Wang, Matthew S Gerber, and Donald E Brown. 2012. Automatic crime prediction using events extracted from twitter posts. In International conference on social computing, behavioral-cultural modeling, and prediction. Springer, 231--238.Google ScholarDigital Library"",""Jianshu Weng and Bu-Sung Lee. 2011. Event detection in twitter. ICWSM, Vol. 11 (2011), 401--408.Google Scholar"",""Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. 2014. Embedding entities and relations for learning and inference in knowledge bases. arXiv preprint arXiv:1412.6575 (2014).Google Scholar"",""Min-Ling Zhang and Zhi-Hua Zhou. 2007. ML-KNN: A lazy learning approach to multi-label learning. Pattern recognition, Vol. 40, 7 (2007), 2038--2048.Google Scholar"",""Ling Zhao, Yujiao Song, Chao Zhang, Yu Liu, Pu Wang, Tao Lin, Min Deng, and Haifeng Li. 2019. T-gcn: A temporal graph convolutional network for traffic prediction. IEEE Transactions on Intelligent Transportation Systems (2019).Google Scholar"",""Liang Zhao, Qian Sun, Jieping Ye, Feng Chen, Chang-Tien Lu, and Naren Ramakrishnan. 2015. Multi-task learning for spatio-temporal event forecasting. In KDD. ACM, 1503--1512.Google Scholar""]"
https://doi.org/10.1145/3394486.3403210,A Geometric Approach to Predicting Bounds of Downstream Model Performance,"This paper presents the motivation and methodology for including model application criteria into baseline analysis. We will focus on detailing the interplay between the common measures of mean square error (MSE) and accuracy as it relates to perceived model performance. MSE is a common aggregate measure for the performance of predictive regression models. The advantages are numerous. MSE is agnostic to the choice of model given that the set of possible outcome values are defined on the appropriate metric space. In practice, decisions on how to subsequently use a trained model are based on predictive performance, relative to a baseline where input features are not used - colloquially a ""random model"". However, the relative performance gains of a model in terms of MSE to the baseline does not guarantee commensurate gains when deployed in downstream applications, systems, or processes. This paper demonstrates one derivation of a distribution to qualify MSE performance for multi-class decision making systems desiring a certain level of accuracy. The model error is qualified through comparison to relevant baselines tied to the application suited to evaluating individual outcome performance criteria.","[{""name"":""Brian J. Goode"",""id"":""/profile/99659356259""},{""name"":""Debanjan Datta"",""id"":""/profile/99659575149""},{""name"":""Brian J. Goode"",""id"":""/profile/99659356259""},{""name"":""Debanjan Datta"",""id"":""/profile/99659575149""}]","[""Yoshua Bengio, Nicolas L Roux, Pascal Vincent, Olivier Delalleau, and Patrice Marcotte. 2006. Convex neural networks. In Advances in neural information processing systems 18 ed.). MIT Press, Cambridge, 123--130.Google Scholar"",""Rich Caruana and Alexandru Niculescu-Mizil. 2006. An empirical comparison of supervised learning algorithms. In Proceedings of the 23rd international conference on Machine learning. Association for Computing Machinery, New York, NY, USA, 161--168.Google ScholarDigital Library"",""R Dennis Cook and Sanford Weisberg. 1982. Residuals and influence in regression .New York: Chapman and Hall, New York, NY, USA.Google Scholar"",""Pedro Domingos. 2000. A unified bias-variance decomposition for zero-one and squared loss. AAAI/IAAI, Vol. 2000 (2000), 564--569.Google Scholar"",""Richard C. Dorf and Robert H. Bishop. 2000. Modern Control Systems 9th ed.). Prentice-Hall, Inc., Upper Saddle River, NJ, USA.Google Scholar"",""Matthew J. Salganik et al. 2020. Measuring the predictability of life outcomes with a scientific mass collaboration. Proceedings of the National Academy of Sciences, Vol. 117, 15 (2020), 8398--8403. https://doi.org/10.1073/pnas.1915006117Google ScholarCross Ref"",""Y. Ren et al. 2018. Generative Modeling of Human Behavior and Social Interactions Using Abductive Analysis. In 2018 IEEE/ACM Int. Conf. on Adv in Soc. Networks Analysis and Mining. IEEE, Barcelona, 413--420. https://doi.org/10.1109/ASONAM.2018.8508282Google Scholar"",""C. Ferri, J. Hernández-Orallo, and R. Modroiu. 2009. An Experimental Comparison of Performance Measures for Classification. Pattern Recogn. Lett., Vol. 30, 1 (Jan. 2009), 27--38. https://doi.org/10.1016/j.patrec.2008.08.010Google ScholarDigital Library"",""Lisa Gaudette and Nathalie Japkowicz. 2009. Evaluation Methods for Ordinal Classification. In Advances in Artificial Intelligence, 22nd Canadian Conference on Artificial Intelligence, Canadian AI 2009, Kelowna, Canada, May 25--27, 2009, Proceedings. Springer Berlin Heidelberg, Berlin, Heidelberg, 207--210. https://doi.org/10.1007/978--3--642-01818--3_25Google Scholar"",""Brian J. Goode, Debanjan Datta, and Naren Ramakrishnan. 2019. Imputing Data for the Fragile Families Challenge: Identifying Similar Survey Questions with Semiautomated Methods. Socius, Vol. 5 (2019).Google ScholarCross Ref"",""Brian J. Goode and Bianica Pires. 2019. Training and Application Error for Decision Models. Journal of Policy \u0026 Complex Systems, Vol. 5, 2 (2019), 165--180.Google ScholarCross Ref"",""José Hernández-Orallo, Peter Flach, and Cèsar Ferri. 2012. A Unified View of Performance Metrics: Translating Threshold Choice into Expected Classification Loss. J. Mach. Learn. Res., Vol. 13, 1 (Oct. 2012), 2813--2869. http://dl.acm.org/citation.cfm?id=2503308.2503332Google Scholar"",""Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. An introduction to statistical learning. Vol. 112. Springer, New York, NY, USA.Google Scholar"",""W. Krauth. 2006. Statistical Mechanics: Algorithms and Computations .Oxford University Press, Oxford.Google Scholar"",""Scott M Lundberg and Su-In Lee. 2017. A unified approach to interpreting model predictions. In Advances in Neural Information Processing Systems. Curran Associates, Inc., Red Hook, NY, USA, 4765--4774.Google Scholar"",""Christopher Meek. 2016. A characterization of prediction errors.Google Scholar"",""Allan H. Murphy. 1973. A New Vector Partition of the Probability Score. Journal of Applied Meteorology (1962--1982), Vol. 12, 4 (1973), 595--600. http://www.jstor.org/stable/26176769Google Scholar"",""Nancy E. Reichman, Julien O.Teitler, Irwin Garfinkel, and Sara S.McLanahan. 2001. Fragile Families: sample and design. Children and Youth Services Review, Vol. 23, 4 (2001), 303--326. https://doi.org/10.1016/S0190--7409(01)00141--4Google ScholarCross Ref"",""Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. Why should i trust you?: Explaining the predictions of any classifier., 1135--1144 pages.Google Scholar"",""Philip E. Tetlock. 2006. Expert Political Judgement: How Good Is It? How Can We Know? Princeton University Press, Princeton, New Jersey.Google Scholar"",""Paul Tseng. 2010. Approximation accuracy, gradient methods, and error bound for structured convex optimization. Mathematical Programming, Vol. 125, 2 (01 Oct 2010), 263--295. https://doi.org/10.1007/s10107-010-0394--2Google Scholar""]"
https://doi.org/10.1145/3394486.3403211,Context-to-Session Matching: Utilizing Whole Session for Response Selection in Information-Seeking Dialogue Systems,"We study the retrieval-based multi-turn information-seeking dialogue systems, which are widely used in many scenarios. Most of the previous works select the response according to the matching degree between the query's context and the candidate responses. Though great progress has been made, existing works ignore the contexts of the responses, which could provide rich information for selecting the most appropriate response. The more similar the query's context and certain response's context are, the more likely they are to indicate the same question, and thus, the more likely this response is to answer the query. In this paper, we consider the response and its context as a whole session and explore the task of matching the query's context with the sessions. More specifically, we propose to match between the query's context and response's context and integrate the context-to-context matching with context-to-response matching. Experiment results prove that our proposed context-to-session method outperforms the strong baselines significantly.","[{""name"":""Zhenxin Fu"",""id"":""/profile/99659335672""},{""name"":""Shaobo Cui"",""id"":""/profile/99659573552""},{""name"":""Mingyue Shang"",""id"":""/profile/99659335073""},{""name"":""Feng Ji"",""id"":""/profile/81490670707""},{""name"":""Dongyan Zhao"",""id"":""/profile/81453611245""},{""name"":""Haiqing Chen"",""id"":""/profile/99659217477""},{""name"":""Rui Yan"",""id"":""/profile/81482653383""},{""name"":""Zhenxin Fu"",""id"":""/profile/99659335672""},{""name"":""Shaobo Cui"",""id"":""/profile/99659573552""},{""name"":""Mingyue Shang"",""id"":""/profile/99659335073""},{""name"":""Feng Ji"",""id"":""/profile/81490670707""},{""name"":""Dongyan Zhao"",""id"":""/profile/81453611245""},{""name"":""Haiqing Chen"",""id"":""/profile/99659217477""},{""name"":""Rui Yan"",""id"":""/profile/81482653383""}]","[""Ricardo Baeza-Yates, Berthier Ribeiro-Neto, et al. 1999. Modern information retrieval. Vol. 463. ACM press New York.Google Scholar"",""Zhangming Chan, Juntao Li, Xiaopeng Yang, Xiuying Chen, Wenpeng Hu, Dongyan Zhao, and Rui Yan. 2019. Modeling Personalization in Continuous Space for Response Generation via Augmented Wasserstein Autoencoders. In EMNLP-IJCNLP. 1931--1940.Google Scholar"",""Qian Chen and Wen Wang. 2019. Sequential Attention-based Network for Noetic End-to-End Response Selection. arXiv preprint arXiv:1901.02609 (2019).Google Scholar"",""Qian Chen, Xiaodan Zhu, Zhen-Hua Ling, Si Wei, Hui Jiang, and Diana Inkpen. 2017. Enhanced LSTM for Natural Language Inference. In ACL. 1657--1668.Google Scholar"",""Weijian Chen, Yulong Gu, Zhaochun Ren, Xiangnan He, Hongtao Xie, Tong Guo, Dawei Yin, and Yongdong Zhang. 2019. Semi-supervised user profiling with heterogeneous graph attention networks. In IJCAI. AAAI Press, 2116--2122.Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In NAACL. Minneapolis, Minnesota, 4171--4186.Google Scholar"",""Devin Didericksen, Oleg Rokhlenko Kevin Small Li Zhou, and Jared Kramer. [n.d.]. Collaboration-based User Simulation for Goal-oriented Dialog Systems. ( [n.,d.]).Google Scholar"",""Zhenxin Fu, Feng Ji, Wenpeng Hu, Wei Zhou, Dongyan Zhao, Haiqing Chen, and Rui Yan. 2019. Query-bag Matching with Mutual Coverage for Information-seeking Conversations in E-commerce. In CIKM. 2337--2340.Google Scholar"",""Shen Gao, Xiuying Chen, Chang Liu, Li Liu, Dongyan Zhao, and Rui Yan. 2020. Learning to Respond with Stickers: A Framework of Unifying Multi-Modality in Multi-Turn Dialog. In WWW. 1138--1148.Google Scholar"",""Yichen Gong, Heng Luo, and Jian Zhang. 2017. Natural language inference over interaction space. arXiv preprint arXiv:1709.04348 (2017).Google Scholar"",""Jia-Chen Gu, Zhen-Hua Ling, and Quan Liu. 2019. Interactive Matching Network for Multi-Turn Response Selection in Retrieval-Based Chatbots. (2019).Google Scholar"",""Hua He, Kevin Gimpel, and Jimmy Lin. 2015. Multi-perspective sentence similarity modeling with convolutional neural networks. In EMNLP. 1576--1586.Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In CVPR. 770--778.Google Scholar"",""Binxuan Huang and Kathleen M Carley. 2019. Syntax-Aware Aspect Level Sentiment Classification with Graph Attention Networks. In EMNLP-IJCNLP. 5472--5480.Google Scholar"",""Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero, and Larry Heck. 2013. Learning deep structured semantic models for web search using clickthrough data. In CIKM. ACM, 2333--2338.Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep learning. nature, Vol. 521, 7553 (2015), 436.Google Scholar"",""Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. 2016. Layer normalization. arXiv preprint arXiv:1607.06450 (2016).Google Scholar"",""Feng-Lin Li, Minghui Qiu, Haiqing Chen, Xiongwei Wang, Xing Gao, Jun Huang, Juwei Ren, Zhongzhou Zhao, Weipeng Zhao, Lei Wang, et al. 2017. AliMe assist: an intelligent assistant for creating an innovative e-commerce experience. In CIKM. ACM, 2495--2498.Google Scholar"",""Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan. 2016. A Diversity-Promoting Objective Function for Neural Conversation Models. In NAACL. 110--119.Google Scholar"",""Ryan Lowe, Nissan Pow, Iulian Serban, and Joelle Pineau. 2015. The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems. In SIGDIAL. 285--294.Google Scholar"",""Wentao Ma, Yiming Cui, Nan Shao, Su He, Wei-Nan Zhang, Ting Liu, Shijin Wang, and Guoping Hu. 2019. TripleNet: Triple Attention Network for Multi-Turn Response Selection in Retrieval-Based Chatbots. In CoNLL. Association for Computational Linguistics, Hong Kong, China, 737--746.Google Scholar"",""Jeffrey Pennington, Richard Socher, and Christopher Manning. 2014. Glove: Global vectors for word representation. In EMNLP. 1532--1543.Google Scholar"",""Minghui Qiu, Liu Yang, Feng Ji, Wei Zhou, Jun Huang, Haiqing Chen, Bruce Croft, and Wei Lin. 2018. Transfer Learning for Context-Aware Question Matching in Information-seeking Conversations in E-commerce. In ACL. 208--213.Google Scholar"",""Chen Qu, Liu Yang, W Bruce Croft, Yongfeng Zhang, Johanne R Trippas, and Minghui Qiu. 2019 a. User intent prediction in information-seeking conversations. In CHIIR. ACM, 25--33.Google Scholar"",""Chen Qu, Liu Yang, Minghui Qiu, W. Bruce Croft, Yongfeng Zhang, and Mohit Iyyer. 2019 b. BERT with History Answer Embedding for Conversational Question Answering. In SIGIR (Paris, France). ACM, New York, NY, USA, 1133--1136.Google Scholar"",""Paul Solomon. 1997. Conversation in information-seeking contexts: A test of an analytical framework. Library \u0026 Information Science Research, Vol. 19, 3 (1997), 217--248.Google ScholarCross Ref"",""Chongyang Tao, Wei Wu, Can Xu, Wenpeng Hu, Dongyan Zhao, and Rui Yan. 2019 a. Multi-Representation Fusion Network for Multi-Turn Response Selection in Retrieval-Based Chatbots. In WSDM. ACM, 267--275.Google Scholar"",""Chongyang Tao, Wei Wu, Can Xu, Wenpeng Hu, Dongyan Zhao, and Rui Yan. 2019 b. One Time of Interaction May Not Be Enough: Go Deep with an Interaction-over-Interaction Network for Response Selection in Dialogues. In ACL. Association for Computational Linguistics, Florence, Italy, 1--11.Google Scholar"",""Paul Thomas, Daniel McDuff, Mary Czerwinski, and Nick Craswell. 2017. MISC: A data set of information-seeking conversations. In CAIR'17, Vol. 5.Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998--6008.Google Scholar"",""Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. 2018. Graph Attention Networks. In ICLR.Google Scholar"",""Ellen M Voorhees et al. [n.d.]. The TREC-8 question answering track report. Citeseer.Google Scholar"",""Heyuan Wang, Ziyi Wu, and Junyu Chen. 2019 b. Multi-Turn Response Selection in Retrieval-Based Chatbots with Iterated Attentive Convolution Matching Network. In CIKM. ACM, 1081--1090.Google Scholar"",""Xiang Wang, Xiangnan He, Yixin Cao, Meng Liu, and Tat-Seng Chua. 2019 a. Kgat: Knowledge graph attention network for recommendation. In KDD. 950--958.Google Scholar"",""Zhiguo Wang, Wael Hamza, and Radu Florian. 2017. Bilateral multi-perspective matching for natural language sentences. In AAAI. AAAI Press, 4144--4150.Google Scholar"",""Yu Wu, Wei Wu, Chen Xing, Ming Zhou, and Zhoujun Li. 2017. Sequential Matching Network: A New Architecture for Multi-turn Response Selection in Retrieval-Based Chatbots. In ACL. 496--505.Google Scholar"",""Rui Yan, Yiping Song, and Hua Wu. 2016. Learning to respond with deep neural networks for retrieval-based human-computer conversation system. In SIGIR. ACM, 55--64.Google Scholar"",""Rui Yan and Dongyan Zhao. 2018. Coupled context modeling for deep chit-chat: towards conversations between human and computer. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 2574--2583.Google ScholarDigital Library"",""Liu Yang, Minghui Qiu, Chen Qu, Jiafeng Guo, Yongfeng Zhang, W Bruce Croft, Jun Huang, and Haiqing Chen. 2018. Response ranking with deep matching networks and external knowledge in information-seeking conversation systems. In SIGIR. ACM, 245--254.Google Scholar"",""Jianfei Yu, Minghui Qiu, Jing Jiang, Jun Huang, Shuangyong Song, Wei Chu, and Haiqing Chen. 2018. Modelling domain relationships for transfer learning on retrieval-based question answering systems in e-commerce. In WSDM. ACM, 682--690.Google Scholar"",""Chunyuan Yuan, Wei Zhou, Mingming Li, Shangwen Lv, Fuqing Zhu, Jizhong Han, and Songlin Hu. 2019. Multi-hop Selector Network for Multi-turn Response Selection in Retrieval-based Chatbots. In EMNLP-IJCNLP. Association for Computational Linguistics, Hong Kong, China, 111--120.Google Scholar"",""Zhuosheng Zhang, Jiangtong Li, Pengfei Zhu, Hai Zhao, and Gongshen Liu. 2018. Modeling Multi-turn Conversation with Deep Utterance Aggregation. In COLING. ACL, Santa Fe, New Mexico, USA, 3740--3752.Google Scholar"",""Xiangyang Zhou, Daxiang Dong, Hua Wu, Shiqi Zhao, Dianhai Yu, Hao Tian, Xuan Liu, and Rui Yan. 2016. Multi-view response selection for human-computer conversation. In EMNLP. 372--381.Google Scholar"",""Xiangyang Zhou, Lu Li, Daxiang Dong, Yi Liu, Ying Chen, Wayne Xin Zhao, Dianhai Yu, and Hua Wu. 2018. Multi-turn response selection for chatbots with deep attention matching network. In ACL. 1118--1127.Google Scholar""]"
https://doi.org/10.1145/3394486.3403212,HOLMES: Health OnLine Model Ensemble Serving for Deep Learning Models in Intensive Care Units,"Deep learning models have achieved expert-level performance in healthcare with an exclusive focus on training accurate models. However, in many clinical environments such as intensive care unit (ICU), real-time model serving is equally if not more important than accuracy, because in ICU patient care is simultaneously more urgent and more expensive. Clinical decisions and their timeliness, therefore, directly affect both the patient outcome and the cost of care. To make timely decisions, we argue the underlying serving system must be latency-aware. To compound the challenge, health analytic applications often require a combination of models instead of a single model, to better specialize individual models for different targets, multi-modal data, different prediction windows, and potentially personalized predictions. To address these challenges, we propose HOLMES---an online model ensemble serving framework for healthcare applications. HOLMES dynamically identifies the best performing set of models to ensemble for highest accuracy, while also satisfying sub-second latency constraints on end-to-end prediction. We demonstrate that HOLMES is able to navigate the accuracy/latency tradeoff efficiently, compose the ensemble, and serve the model ensemble pipeline, scaling to simultaneously streaming data from 100 patients, each producing waveform data at 250~Hz. HOLMES outperforms the conventional offline batch-processed inference for the same clinical task in terms of accuracy and latency (by order of magnitude). HOLMES is tested on risk prediction task on pediatric cardio ICU data with above 95% prediction accuracy and sub-second latency on 64-bed simulation.","[{""name"":""Shenda Hong"",""id"":""/profile/99659535081""},{""name"":""Yanbo Xu"",""id"":""/profile/99659286849""},{""name"":""Alind Khare"",""id"":""/profile/99659573026""},{""name"":""Satria Priambada"",""id"":""/profile/99659357195""},{""name"":""Kevin Maher"",""id"":""/profile/81501659303""},{""name"":""Alaa Aljiffry"",""id"":""/profile/99659574482""},{""name"":""Jimeng Sun"",""id"":""/profile/81490657940""},{""name"":""Alexey Tumanov"",""id"":""/profile/81484658089""},{""name"":""Shenda Hong"",""id"":""/profile/99659535081""},{""name"":""Yanbo Xu"",""id"":""/profile/99659286849""},{""name"":""Alind Khare"",""id"":""/profile/99659573026""},{""name"":""Satria Priambada"",""id"":""/profile/99659357195""},{""name"":""Kevin Maher"",""id"":""/profile/81501659303""},{""name"":""Alaa Aljiffry"",""id"":""/profile/99659574482""},{""name"":""Jimeng Sun"",""id"":""/profile/81490657940""},{""name"":""Alexey Tumanov"",""id"":""/profile/81484658089""}]","[""Sébastien Bailly, Geert Meyfroidt, and Jean-François Timsit. 2018. What's new in ICU in 2050: big data and machine learning. Intensive care medicine 44, 9 (2018),1524--1527.Google Scholar"",""James Bergstra and Yoshua Bengio. 2012. Random search for hyper-parameter optimization. Journal of machine learning research 13, Feb (2012), 281--305.Google ScholarDigital Library"",""James Bergstra, Daniel Yamins, and David Daniel Cox. 2013. Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures. JMLR(2013).Google Scholar"",""James S Bergstra, Rémi Bardenet, Yoshua Bengio, and Balázs Kégl. 2011. Algorithms for hyper-parameter optimization. In Advances in neural information processing systems. 2546--2554.Google Scholar"",""Leo Breiman. 1996. Bagging Predictors. Mach. Learn.24, 2 (Aug. 1996), 123--140. https://doi.org/10.1023/A:1018054314350Google ScholarCross Ref"",""Leo Breiman. 2001. Random forests. Machine learning 45, 1 (2001), 5--32.Google Scholar"",""Han Cai, Ligeng Zhu, and Song Han. 2018. Proxylessnas: Direct neural architecture search on target task and hardware.arXiv:1812.00332(2018).Google Scholar"",""Leo Anthony Celi, Roger G Mark, David J Stone, and Robert A Montgomery. 2013. \""Big data\"" in the intensive care unit. Closing the data loop.American journal of respiratory and critical care medicine 187, 11 (2013), 1157.Google Scholar"",""Daniel Crankshaw, Xin Wang, Giulio Zhou, Michael J. Franklin, Joseph E. Gonzalez, and Ion Stoica. 2016. Clipper: A Low-Latency Online Prediction Serving System. CoRRabs/1612.03079 (2016). arXiv:1612.03079 http://arxiv.org/abs/1612.03079Google Scholar"",""Thomas Elsken, Jan Hendrik Metzen, and Frank Hutter. 2018. Neural architecture search: A survey. arXiv preprint arXiv:1808.05377(2018).Google Scholar"",""Hayley B Gershengorn, Allan Garland, and Michelle N Gong. 2015. Patterns of daily costs differ for medical and surgical intensive care unit patients.Annals of the American Thoracic Society 12, 12 (2015), 1831--1836.Google Scholar"",""Varun Gulshan, Lily Peng, Marc Coram, Martin C. Stumpe, Derek Wu, Arunachalam Narayanaswamy, Subhashini Venugopalan, Kasumi Widner, Tom Madams,Jorge Cuadros, Ramasamy Kim, Rajiv Raman, Philip C. Nelson, Jessica L. Mega,and Dale R. Webster. 2016. Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs. JAMA 316, 22 (12 2016), 2402--2410. https://doi.org/10.1001/jama.2016.17216arXiv:https://jamanetwork.com/journals/jama/articlepdf/2588763/joi160132.pdfGoogle Scholar"",""Neil A Halpern and Stephen M Pastores. 2015. Critical care medicine beds, use, occupancy and costs in the United States: a methodological review. Critical care medicine 43, 11 (2015), 2452.Google Scholar"",""Awni Y Hannun, Pranav Rajpurkar, Masoumeh Haghpanahi, Geoffrey H Tison, Codie Bourn, Mintu P Turakhia, and Andrew Y Ng. 2019. Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms usinga deep neural network. Nature medicine 25, 1 (2019), 65.Google Scholar"",""Hrayr Harutyunyan, Hrant Khachatrian, David C Kale, Greg Ver Steeg, and Aram Galstyan. 2017. Multitask learning and benchmarking with clinical time series data. arXiv preprint arXiv:1703.07771(2017).Google Scholar"",""Shenda Hong, Yuxi Zhou, Junyuan Shang, Cao Xiao, and Jimeng Sun. 2020. Opportunities and challenges of deep learning methods for electrocardiogram data: A systematic review. Computers in Biology and Medicine(2020), 103801.Google Scholar"",""Frank Hutter, Holger H Hoos, and Kevin Leyton-Brown. 2011. Sequential model-based optimization for general algorithm configuration. In International conference on learning and intelligent optimization. Springer, 507--523.Google ScholarDigital Library"",""Slawomir Koziel and Leifur Leifsson. 2013. Surrogate-based modeling and optimization. Springer.Google Scholar"",""Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep learning. nature 521, 7553 (2015), 436.Google Scholar"",""Julien-Charles Lévesque, Christian Gagné, and Robert Sabourin. 2016. Bayesian hyperparameter optimization for ensemble learning. In Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence. 437--446.Google ScholarDigital Library"",""Zachary C Lipton, David C Kale, Charles Elkan, and Randall Wetzel. 2016. Learning to diagnose with LSTM recurrent neural networks. ICLR.Google Scholar"",""Chenxi Liu, Barret Zoph, Maxim Neumann, Jonathon Shlens, Wei Hua, Li-Jia Li,Li Fei-Fei, Alan Yuille, Jonathan Huang, and Kevin Murphy. 2018. Progressive neural architecture search. In ECCV. 19--34.Google Scholar"",""Xiangrui Meng, Joseph Bradley, Burak Yavuz, Evan Sparks, Shivaram Venkataraman, Davies Liu, Jeremy Freeman, DB Tsai, Manish Amde, Sean Owen, Doris Xin, Reynold Xin, Michael J. Franklin, Reza Zadeh, Matei Zaharia, and Ameet Talwalkar. 2015. MLlib: Machine Learning in Apache Spark. arXiv:1505.06807 [cs.LG]Google Scholar"",""Jonas Mockus. 2012.Bayesian approach to global optimization: theory and applications. Vol. 37. Springer Science \u0026 Business Media.Google Scholar"",""Philipp Moritz, Robert Nishihara, Stephanie Wang, Alexey Tumanov, RichardLiaw, Eric Liang, Melih Elibol, Zongheng Yang, William Paul, Michael I Jordan,et al. 2018. Ray: A distributed framework for emerging AI applications. In 13th USENIX Symposium on Operating Systems Design and Implementation (OSDI'18). 561--577.Google Scholar"",""Phuoc Nguyen, Truyen Tran, and Svetha Venkatesh. 2017. Deep learning to attend to risk in ICU. arXiv preprint arXiv: 1707.05010(2017).Google Scholar"",""Christopher Olston, Noah Fiedel, Kiril Gorovoy, Jeremiah Harmsen, Li Lao, Fang-wei Li, Vinu Rajashekhar, Sukriti Ramesh, and Jordan Soyke. 2017. Tensorflow-serving: Flexible, high-performance ml serving. arXiv:1712.06139(2017).Google Scholar"",""Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. 2019. PyTorch: An imperative style, high-performance deep learning library. In Advances in Neural Information Processing Systems. 8024--8035.Google Scholar"",""Alvin Rajkomar, Eyal Oren, Kai Chen, Andrew M Dai, Nissan Hajaj, Michaela Hardt, Peter J Liu, Xiaobing Liu, Jake Marcus, Mimi Sun, et al.2018. Scalable and accurate deep learning with electronic health records. NPJ Digital Medicine 1, 1(2018), 18.Google ScholarCross Ref"",""Pranav Rajpurkar, Jeremy Irvin, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony Duan, Daisy Ding, Aarti Bagul, Curtis Langlotz, Katie Shpanskaya, et al. 2017. Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning. arXiv preprint arXiv:1711.05225(2017).Google Scholar"",""Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P Adams, and Nando De Freitas. 2015. Taking the human out of the loop: A review of Bayesian optimization. Proc. IEEE 104, 1 (2015), 148--175.Google ScholarCross Ref"",""Jasper Snoek, Hugo Larochelle, and Ryan P Adams. 2012. Practical bayesian optimization of machine learning algorithms. In Advances in neural information processing systems. 2951--2959.Google Scholar"",""Lu Wang, Wei Zhang, Xiaofeng He, and Hongyuan Zha. 2018. Supervised reinforcement learning with recurrent neural network for dynamic treatment recommendation. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 2447--2456.Google ScholarDigital Library"",""Darrell Whitley. 1994. A genetic algorithm tutorial.Statistics and computing 4, 2(1994), 65--85.Google Scholar"",""Cao Xiao, Edward Choi, and Jimeng Sun. 2018. Opportunities and challenges in developing deep learning models using electronic health records data: a systematic review. JAMIA25, 10 (2018), 1419--1428.Google Scholar"",""Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, and Kaiming He. 2017. Aggregated residual transformations for deep neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition. 1492--1500.Google ScholarCross Ref"",""Yanbo Xu, Siddharth Biswal, Shriprasad R Deshpande, Kevin O Maher, and Jimeng Sun. 2018. Raim: Recurrent attentive and intensive model of multimodal patient monitoring data. In KDD. ACM, 2565--2573.Google ScholarDigital Library"",""Zhi-Hua Zhou. 2012. Ensemble methods: foundations and algorithms. Chapman and Hall/CRC.Google Scholar"",""Barret Zoph and Quoc V Le. 2016. Neural architecture search with reinforcement learning. arXiv preprint arXiv:1611.01578(2016).Google Scholar""]"
https://doi.org/10.1145/3394486.3403213,LogPar: Logistic PARAFAC2 Factorization for Temporal Binary Data with Missing Values,"Binary data with one-class missing values are ubiquitous in real-world applications. They can be represented by irregular tensors with varying sizes in one dimension, where value one means presence of a feature while zero means unknown (i.e., either presence or absence of a feature). Learning accurate low-rank approximations from such binary irregular tensors is a challenging task. However, none of the existing models developed for factorizing irregular tensors take the missing values into account, and they assume Gaussian distributions, resulting in a distribution mismatch when applied to binary data. In this paper, we propose Logistic PARAFAC2 (LogPar) by modeling the binary irregular tensor with Bernoulli distribution parameterized by an underlying real-valued tensor. Then we approximate the underlying tensor with a positive-unlabeled learning loss function to account for the missing values. We also incorporate uniqueness and temporal smoothness regularization to enhance the interpretability. Extensive experiments using large-scale real-world datasets show that LogPar outperforms all baselines in both irregular tensor completion and downstream predictive tasks. For the irregular tensor completion, LogPar achieves up to 26% relative improvement compared to the best baseline. Besides, LogPar obtains relative improvement of 13.2% for heart failure prediction and 14% for mortality prediction on average compared to the state-of-the-art PARAFAC2 models.","[{""name"":""Kejing Yin"",""id"":""/profile/99659338173""},{""name"":""Ardavan Afshar"",""id"":""/profile/99659232861""},{""name"":""Joyce C. Ho"",""id"":""/profile/87958670857""},{""name"":""William K. Cheung"",""id"":""/profile/81416597690""},{""name"":""Chao Zhang"",""id"":""/profile/99659455279""},{""name"":""Jimeng Sun"",""id"":""/profile/81490657940""},{""name"":""Kejing Yin"",""id"":""/profile/99659338173""},{""name"":""Ardavan Afshar"",""id"":""/profile/99659232861""},{""name"":""Joyce C. Ho"",""id"":""/profile/87958670857""},{""name"":""William K. Cheung"",""id"":""/profile/81416597690""},{""name"":""Chao Zhang"",""id"":""/profile/99659455279""},{""name"":""Jimeng Sun"",""id"":""/profile/81490657940""}]","[""Ardavan Afshar, Joyce C Ho, Bistra Dilkina, Ioakeim Perros, Elias B Khalil, Li Xiong, and Vaidy Sunderam. 2017. CP-ORTHO: An orthogonal tensor factorization framework for spatio-temporal data. In Proceedings of the 25th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems. 1--4.Google ScholarDigital Library"",""Ardavan Afshar, Ioakeim Perros, Evangelos E Papalexakis, Elizabeth Searles, Joyce Ho, and Jimeng Sun. 2018. COPA: Constrained PARAFAC2 for sparse \u0026 large datasets. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management. ACM, 793--802.Google ScholarDigital Library"",""Ardavan Afshar, Ioakeim Perros, Haesun Park, Christopher deFilippi, Xiaowei Yan, Walter Stewart, Joyce Ho, and Jimeng Sun. 2020. TASTE: Temporal and static tensor factorization for phenotyping electronic health records. In Proceedings of the ACM Conference on Health, Inference, and Learning. 193--203.Google ScholarDigital Library"",""Eric C Chi and Tamara G Kolda. 2012. On tensors, sparsity, and nonnegative factorizations. SIAM J. Matrix Anal. Appl., Vol. 33, 4 (2012), 1272--1299.Google ScholarCross Ref"",""Jeremy E Cohen and Rasmus Bro. 2018. Nonnegative PARAFAC2: A flexible coupling approach. In International Conference on Latent Variable Analysis and Signal Separation. Springer, 89--98.Google ScholarCross Ref"",""Mark A Davenport, Yaniv Plan, Ewout Van Den Berg, and Mary Wootters. 2014. 1-Bit matrix completion. Information and Inference: A Journal of the IMA, Vol. 3, 3 (2014), 189--223.Google ScholarCross Ref"",""Marthinus C Du Plessis, Gang Niu, and Masashi Sugiyama. 2014. Analysis of learning from positive and unlabeled data. In Advances in Neural Information Processing Systems. 703--711.Google Scholar"",""Xiawei Guo, Quanming Yao, and James Tin-Yau Kwok. 2017. Efficient sparse low-rank tensor completion using the Frank-Wolfe algorithm. In Thirty-First AAAI Conference on Artificial Intelligence.Google ScholarDigital Library"",""Richard A Harshman. 1972. PARAFAC2: Mathematical and technical notes. UCLA working papers in phonetics, Vol. 22, 3044 (1972), 122215.Google Scholar"",""Joyce C Ho, Joydeep Ghosh, Steve R Steinhubl, Walter F Stewart, Joshua C Denny, Bradley A Malin, and Jimeng Sun. 2014b. Limestone: High-throughput candidate phenotype generation via tensor factorization. Journal of biomedical informatics, Vol. 52 (2014), 199--211.Google ScholarDigital Library"",""Joyce C Ho, Joydeep Ghosh, and Jimeng Sun. 2014a. Marble: High-throughput phenotyping from electronic health records via sparse nonnegative tensor factorization. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 115--124.Google ScholarDigital Library"",""David Hong, Tamara G Kolda, and Jed A Duersch. 2020. Generalized canonical polyadic tensor decomposition. SIAM Rev., Vol. 62, 1 (2020), 133--163.Google ScholarDigital Library"",""Cho-Jui Hsieh, Nagarajan Natarajan, and Inderjit S Dhillon. 2015. PU learning for matrix completion. In Proceedings of the 32nd International Conference on International Conference on Machine Learning-Volume 37. JMLR. org, 2445--2453.Google Scholar"",""Alistair EW Johnson, Tom J Pollard, Lu Shen, H Lehman Li-wei, Mengling Feng, Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G Mark. 2016. MIMIC-III, a freely accessible critical care database. Scientific Data, Vol. 3 (2016), 160035.Google ScholarCross Ref"",""Alexandros Karatzoglou, Xavier Amatriain, Linas Baltrunas, and Nuria Oliver. 2010. Multiverse recommendation: n-dimensional tensor factorization for context-aware collaborative filtering. In Proceedings of the fourth ACM conference on Recommender systems. 79--86.Google ScholarDigital Library"",""Henk AL Kiers, Jos MF Ten Berge, and Rasmus Bro. 1999. PARAFAC2-Part I. A direct fitting algorithm for the PARAFAC2 model. Journal of Chemometrics: A Journal of the Chemometrics Society, Vol. 13, 3--4 (1999), 275--294.Google ScholarCross Ref"",""Yejin Kim, Robert El-Kareh, Jimeng Sun, Hwanjo Yu, and Xiaoqian Jiang. 2017. Discriminative and Distinct Phenotyping by Constrained Tensor Factorization. Scientific Reports, Vol. 7, 1 (2017), 1114.Google ScholarCross Ref"",""Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Optimization. In 3rd International Conference on Learning Representations (ICLR).Google Scholar"",""Ryuichi Kiryo, Gang Niu, Marthinus C du Plessis, and Masashi Sugiyama. 2017. Positive-unlabeled learning with non-negative risk estimator. In Advances in Neural Information Processing Systems. 1675--1685.Google Scholar"",""Tamara G Kolda and Brett W Bader. 2009. Tensor decompositions and applications. SIAM Rev., Vol. 51, 3 (2009), 455--500.Google ScholarDigital Library"",""Daniel D Lee and H Sebastian Seung. 1999. Learning the parts of objects by non-negative matrix factorization. Nature, Vol. 401, 6755 (1999), 788--791.Google Scholar"",""Xutao Li, Yunming Ye, and Xiaofei Xu. 2017. Low-rank tensor completion with total variation for visual data inpainting. In Thirty-First AAAI Conference on Artificial Intelligence.Google ScholarDigital Library"",""Hanpeng Liu, Yaguang Li, Michael Tsang, and Yan Liu. 2019. CoSTCo: A Neural Tensor Completion Model for Sparse Tensors. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 324--334.Google ScholarDigital Library"",""Ken-ichiro Moridomi, Kohei Hatano, and Eiji Takimoto. 2018. Tighter generalization bounds for matrix completion via factorization into constrained matrices. IEICE TRANSACTIONS on Information and Systems, Vol. 101, 8 (2018), 1997--2004.Google Scholar"",""Nagarajan Natarajan, Inderjit S Dhillon, Pradeep K Ravikumar, and Ambuj Tewari. 2013. Learning with noisy labels. In Advances in Neural Information Processing Systems. 1196--1204.Google Scholar"",""Sahand Negahban and Martin J Wainwright. 2012. Restricted strong convexity and weighted matrix completion: Optimal bounds with noise. Journal of Machine Learning Research, Vol. 13, May (2012), 1665--1697.Google ScholarDigital Library"",""Rong Pan, Yunhong Zhou, Bin Cao, Nathan N Liu, Rajan Lukose, Martin Scholz, and Qiang Yang. 2008. One-class collaborative filtering. In 2008 Eighth IEEE International Conference on Data Mining. IEEE, 502--511.Google ScholarDigital Library"",""Ioakeim Perros, Evangelos E Papalexakis, Richard Vuduc, Elizabeth Searles, and Jimeng Sun. 2019. Temporal phenotyping of medically complex children via PARAFAC2 tensor factorization. Journal of Biomedical Informatics, Vol. 93 (2019).Google ScholarCross Ref"",""Ioakeim Perros, Evangelos E Papalexakis, Fei Wang, Richard Vuduc, Elizabeth Searles, Michael Thompson, and Jimeng Sun. 2017. SPARTan: Scalable PARAFAC2 for large \u0026 sparse data. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 375--384.Google ScholarDigital Library"",""Steffen Rendle and Lars Schmidt-Thieme. 2010. Pairwise interaction tensor factorization for personalized tag recommendation. In Proceedings of the Third ACM International Conference on Web Search and Data Mining. 81--90.Google ScholarDigital Library"",""Marie Roald, Suchita Bhinge, Chunying Jia, Vince Calhoun, Tülay Adali, and Evrim Acar. 2019. Tracing Network Evolution Using the PARAFAC2 Model. arXiv preprint arXiv:1911.02926 (2019).Google Scholar"",""Qiquan Shi, Haiping Lu, and Yiu-Ming Cheung. 2017. Rank-one matrix completion with automatic rank estimation via L1-norm regularization. IEEE Transactions on Neural Networks and Learning Systems, Vol. 29, 10 (2017), 4744--4757.Google ScholarCross Ref"",""Vikas Sindhwani, Serhat S Bucak, Jianying Hu, and Aleksandra Mojsilovic. 2010. One-class matrix completion with low-density factorizations. In 2010 IEEE International Conference on Data Mining. IEEE, 1055--1060.Google ScholarDigital Library"",""Kejing Yin, William K Cheung, Yang Liu, Benjamin C. M. Fung, and Jonathan Poon. 2018. Joint learning of phenotypes and diagnosis-medication correspondence via hidden interaction tensor factorization. In Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI-18). AAAI Press, 3627--3633.Google ScholarCross Ref"",""Kejing Yin, Dong Qian, William K. Cheung, Benjamin C. M. Fung, and Jonathan Poon. 2019. Learning phenotypes and dynamic patient representations via RNN regularized collective non-negative tensor factorization. In Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence. AAAI Press, 1246--1253.Google ScholarCross Ref"",""Hsiang-Fu Yu, Mikhail Bilenko, and Chih-Jen Lin. 2017. Selection of negative samples for one-class matrix factorization. In Proceedings of the 2017 SIAM International Conference on Data Mining. SIAM, 363--371.Google ScholarCross Ref"",""Pan Zhou, Canyi Lu, Zhouchen Lin, and Chao Zhang. 2017. Tensor factorization for low-rank tensor completion. IEEE Transactions on Image Processing, Vol. 27, 3 (2017), 1152--1163.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403214,RECORD: Resource Constrained Semi-Supervised Learning under Distribution Shift,"Semi-supervised learning (SSL) tries to improve performance with the use of massive unlabeled data, which typically works in an offline manner with two assumptions. i) Data distribution is static; ii) Data storage overhead is unlimited. In many online tasks, however, none of the above assumptions is valid. For example, in online image classification, a large amount of unlabeled images increases sharply, which makes it difficult to store them in full; meanwhile, the content of unlabeled images changes constantly, and it is no longer suitable to assume a fixed distribution. We call such a novel setting Resource Constrained SSL under Distribution Shift (or Record for short) and to our best knowledge, it has not been thoroughly studied yet. This paper presents a systemic solution Record consisting of three sub-steps, that is, distribution tracking, sample selection and model updating. Specifically, we propose an effective method to track the distribution changes and locate distribution shifted samples. A novel influence-based approach is used to select the most influential samples for the distribution change based on resource constraints. Finally, we free up memory to put the latest unlabeled data with its pseudo-label for the next distribution tracking. Extensive empirical results confirm the effectiveness of our scheme. In the case of diverse and unknown distribution shifts, our solution is consistently and clearly better than many baseline and SOTA methods along with the memory budget and in some cases it can even approximate the performance of oracle.","[{""name"":""Lan-Zhe Guo"",""id"":""/profile/99659250530""},{""name"":""Zhi Zhou"",""id"":""/profile/99659574511""},{""name"":""Yu-Feng Li"",""id"":""/profile/81442606442""},{""name"":""Lan-Zhe Guo"",""id"":""/profile/99659250530""},{""name"":""Zhi Zhou"",""id"":""/profile/99659574511""},{""name"":""Yu-Feng Li"",""id"":""/profile/81442606442""}]","[""David Berthelot, Nicholas Carlini, Ian J. Goodfellow, Nicolas Papernot, Avital Oliver, and Colin Raffel. 2019. MixMatch: A Holistic Approach to Semi-Supervised Learning. In NeurIPS. 5050--5060.Google Scholar"",""Albert Bifet, Geoffrey Holmes, Bernhard Pfahringer, and Ricard Gavaldà. 2011. Detecting Sentiment Change in Twitter Streaming Data. In WAPA. 5--11.Google Scholar"",""Olivier Chapelle, Bernhard Schö lkopf, and Alexander Zien (Eds.). 2006. Semi-Supervised Learning .The MIT Press.Google Scholar"",""Gregory Ditzler and Robi Polikar. 2011. Semi-Supervised Learning in Nonstationary Environments. In IJCNN. 2741--2748.Google Scholar"",""Karl B Dyer, Robert Capo, and Robi Polikar. 2013. Compose: A Semi-Supervised Learning Framework for Initially Labeled Nonstationary Streaming Data. IEEE Transactions on Neural Networks and Learning Systems, Vol. 25, 1 (2013), 12--26.Google ScholarCross Ref"",""Sandra Ebert, Mario Fritz, and Bernt Schiele. 2012. Semi-Supervised Learning on a Budget: Scaling Up to Large Datasets. In ACCV. 232--245.Google Scholar"",""Andrew B Goldberg, Ming Li, and Xiaojin Zhu. 2008. Online Manifold Regularization: A New Learning Setting and Empirical Study. In ECML/PKDD. 393--407.Google Scholar"",""Andrew B Goldberg, Xiaojin Zhu, Alex Furger, and Jun-Ming Xu. 2011. Oasis: Online Active Semi-Supervised Learning. In AAAI. 362--367.Google Scholar"",""C Gong, D Tao, SJ Maybank, W Liu, G Kang, and J Yang. 2016. Multi-modal curriculum learning for semi-supervised image classification. IEEE Transactions on Image Processing, Vol. 25, 7 (2016), 3249--3260.Google ScholarCross Ref"",""Lan-Zhe Guo and Yu-Feng Li. 2018. A General Formulation for Safely Exploiting Weakly Supervised Data. In AAAI. 3126--3133.Google Scholar"",""Lan-Zhe Guo, Zhen-Yu Zhang, Yuan Jiang, Yu-Feng Li, and Zhi-Hua Zhou. 2020 b. Safe Deep Semi-Supervised Learning for Unseen-Class Unlabeled Data. In ICML.Google Scholar"",""Lan-Zhe Guo, Tao Han, and Yu-Feng Li. 2019. Robust Semi-supervised Representation Learning for Graph-Structured Data. In PAKDD. 131--143.Google Scholar"",""Lan-Zhe Guo, Feng Kuang, Zhang-Xun Liu, Yu-Feng Li, Nan Ma, and Xiao-Hu Qie. 2020 a. Weakly Supervised Learning Meets Ride-Sharing User Experience Enhancement. In AAAI.Google Scholar"",""Ahsanul Haque, Latifur Khan, and Michael Baron. 2016. Sand: Semi-Supervised Adaptive Novel Class Detection and Classification over Data Stream. In AAAI. 1652--1658.Google Scholar"",""Dan Hendrycks and Kevin Gimpel. 2017. A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks. In ICLR.Google Scholar"",""Lei Huang, Xianglong Liu, Binqiang Ma, and Bo Lang. 2015. Online Semi-Supervised Annotation via Proxy-Based Local Consistency Propagation. Neurocomputing, Vol. 149 (2015), 1573--1586.Google ScholarCross Ref"",""Pang Wei Koh and Percy Liang. 2017. Understanding Black-Box Predictions via Influence Functions. In ICML. 1885--1894.Google Scholar"",""Georg Krempl, Indre Zliobaite, Dariusz Brzezi'nski, Eyke Hüllermeier, Mark Last, Vincent Lemaire, Tino Noack, Ammar Shaker, Sonja Sievi, Myra Spiliopoulou, et al. 2014. Open Challenges for Data Stream Mining Research. SIGKDD Explorations, Vol. 16, 1 (2014), 1--10.Google ScholarDigital Library"",""Trung Le, Phuong Duong, Mi Dinh, Tu Dinh Nguyen, Vu Nguyen, and Dinh Q Phung. 2016. Budgeted Semi-supervised Support Vector Machine.. In UAI. 377--386.Google Scholar"",""Pei-Pei Li, Xindong Wu, and Xuegang Hu. 2010. Mining Recurring Concept Drifts with Limited Labeled Streaming Data. In ACML. 241--252.Google Scholar"",""Yu-Feng Li, Lan-Zhe Guo, and Zhi-Hua Zhou. 2019. Towards Safe Weakly Supervised Learning. IEEE Transactions on Pattern Analysis and Machine Intelligence (2019).Google Scholar"",""Yu-Feng Li and De-Ming Liang. 2019. Safe Semi-Supervised Learning: A Brief Introduction. Frontiers of Computer Science, Vol. 13, 4 (2019), 669--676.Google ScholarDigital Library"",""Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. 2018. Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 41, 8 (2018), 1979--1993.Google ScholarCross Ref"",""Avital Oliver, Augustus Odena, Colin A Raffel, Ekin Dogus Cubuk, and Ian Goodfellow. 2018. Realistic Evaluation of Deep Semi-Supervised Learning Algorithms. In NeurIPS. 3235--3246.Google Scholar"",""Antti Rasmus, Mathias Berglund, Mikko Honkala, Harri Valpola, and Tapani Raiko. 2015. Semi-Supervised Learning with Ladder Networks. In NeurIPS. 3546--3554.Google Scholar"",""Mehdi Sajjadi, Mehran Javanmardi, and Tolga Tasdizen. 2016. Regularization with Stochastic Transformations and Perturbations for Deep Semi-Supervised Learning. In NeurIPS. 1163--1171.Google Scholar"",""V. M. A. Souza, D. F. Silva, J. Gama, and G. E. A. P. A. Batista. 2015. Data Stream Classification Guided by Clustering on Nonstationary Environments and Extreme Verification Latency. In ICDM. 873--881.Google Scholar"",""Antti Tarvainen and Harri Valpola. 2017. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In NeurIPS. 1195--1204.Google Scholar"",""Tal Wagner, Sudipto Guha, Shiva Kasiviswanathan, and Nina Mishra. 2018. Semi-Supervised Learning on Data Streams via Temporal Label Propagation. In ICML. 5095--5104.Google Scholar"",""Peng Zhao, Xinqiang Wang, Siyu Xie, Lei Guo, and Zhi-Hua Zhou. 2019. Distribution-free one-pass learning. IEEE Transactions on Knowledge and Data Engineering (2019).Google Scholar"",""Zhi-Hua Zhou. 2017. A Brief Introduction to Weakly Supervised Learning. National Science Review, Vol. 5, 1 (2017), 44--53.Google ScholarCross Ref"",""Zhi-Hua Zhou. 2019. Abductive learning: Towards bridging machine learning and logical reasoning. Science China Information Sciences, Vol. 62, 7 (2019), 76101:1--76101:3.Google ScholarCross Ref"",""Zhi-Hua Zhou, Michael Ng, Qiao-Qiao She, and Yuan Jiang. 2009. Budget Semi-Supervised Learning. In PAKDD. 588--595.Google Scholar"",""Yong-Nan Zhu and Yu-Feng Li. 2020. Semi-Supervised Streaming Learning with Emerging New Labels. In AAAI.Google Scholar""]"
https://doi.org/10.1145/3394486.3403215,Statistically Significant Pattern Mining with Ordinal Utility,"Statistically significant patterns mining (SSPM) is an essential and challenging data mining task in the field of knowledge discovery in databases (KDD), in which each pattern is evaluated via a hypothesis test. Our study aims to introduce a preference relation into patterns and to discover the most preferred patterns under the constraint of statistical significance, which has never been considered in existing SSPM problems. We propose an iterative multiple testing procedure that can alternately reject a hypothesis and safely ignore the hypotheses that are less useful than the rejected hypothesis. One advantage of filtering out patterns with low utility is that it avoids consumption of the significance budget by rejection of useless (that is, uninteresting) patterns. This allows the significance budget to be focused on useful patterns, leading to more useful discoveries. We show that the proposed method can control the familywise error rate (FWER) under certain assumptions, that can be satisfied by a realistic problem class in SSPM. We also show that the proposed method always discovers a set of patterns that is at least equally or more useful than those discovered using the standard Tarone-Bonferroni method SSPM. Finally, we conducted several experiments with both synthetic and real-world data to evaluate the performance of our method. As a result, in the experiments with real-world datasets, the proposed method discovered a larger number of more useful patterns than the existing method for all five conducted tasks.","[{""name"":""Thien Q. Tran"",""id"":""/profile/99659453038""},{""name"":""Kazuto Fukuchi"",""id"":""/profile/99659545120""},{""name"":""Youhei Akimoto"",""id"":""/profile/81363591775""},{""name"":""Jun Sakuma"",""id"":""/profile/81100536439""},{""name"":""Thien Q. Tran"",""id"":""/profile/99659453038""},{""name"":""Kazuto Fukuchi"",""id"":""/profile/99659545120""},{""name"":""Youhei Akimoto"",""id"":""/profile/81363591775""},{""name"":""Jun Sakuma"",""id"":""/profile/81100536439""}]","[""Rakesh Agrawal, Ramakrishnan Srikant, et al. 1994. Fast algorithms for mining association rules. In Proc. 20th int. conf. very large data bases, VLDB, Vol. 1215. 487--499.Google ScholarDigital Library"",""Yoav Benjamini and Yosef Hochberg. 2000. On the adaptive control of the false discovery rate in multiple testing with independent statistics. Journal of educational and Behavioral Statistics, Vol. 25, 1 (2000), 60--83.Google ScholarCross Ref"",""Ronald Aylmer Fisher et al. 1950. Statistical methods for research workers. Statistical methods for research workers. llth ed. revised (1950).Google Scholar"",""Wensheng Gan, Jerry Chun-Wei Lin, Philippe Fournier-Viger, Han-Chieh Chao, Vincent S Tseng, and Philip S Yu. 2018. A survey of utility-oriented pattern mining. arXiv preprint arXiv:1805.10511 (2018).Google Scholar"",""Wilhelmiina Hamalainen. 2012. Kingfisher: an efficient algorithm for searching for both positive and negative dependency rules with statistical significance measures. Knowledge and information systems, Vol. 32, 2 (2012), 383--414.Google Scholar"",""Sture Holm. 1979. A simple sequentially rejective multiple test procedure. Scandinavian journal of statistics (1979), 65--70.Google Scholar"",""Ronny Kohavi and barry Becker. 1996. Adult Data Set.Google Scholar"",""Junpei Komiyama, Masakazu Ishihata, Hiroki Arimura, Takashi Nishibayashi, and Shin-ichi Minato. 2017. Statistical emerging pattern mining with multiple testing correction. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 897--906.Google ScholarDigital Library"",""Dongwon Lee, Sung-Hyuk Park, and Songchun Moon. 2013. Utility-based association rule mining: A marketing solution for cross-selling. Expert Systems with applications, Vol. 40, 7 (2013), 2715--2725.Google Scholar"",""Felipe Llinares-López, Laetitia Papaxanthos, Dean Bodenham, Damian Roqueiro, COPDGene Investigators, and Karsten Borgwardt. 2017. Genome-wide genetic heterogeneity discovery with categorical covariates. Bioinformatics, Vol. 33, 12 (2017), 1820--1828.Google ScholarCross Ref"",""Felipe Llinares-López, Mahito Sugiyama, Laetitia Papaxanthos, and Karsten Borgwardt. 2015. Fast and memory-efficient significant pattern mining via permutation testing. In Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining. ACM, 725--734.Google ScholarDigital Library"",""Shin-ichi Minato, Takeaki Uno, Koji Tsuda, Aika Terada, and Jun Sese. 2014. A fast method of statistical assessment for combinatorial hypotheses based on frequent itemset enumeration. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 422--436.Google Scholar"",""Leonardo Pellegrina, Matteo Riondato, and Fabio Vandin. 2019. SPuManTE: Significant Pattern Mining with Unconditional Testing.Google Scholar"",""Robert Rosenthal and Donald B Rubin. 1983. Ensemble-adjusted p values. Psychological Bulletin, Vol. 94, 3 (1983), 540.Google ScholarCross Ref"",""MCG ESB Service. 2015. Crime.Google Scholar"",""MCG ESB Service. 2017. Crash Reporting - Drivers Data.Google Scholar"",""Bai-En Shie, S Yu Philip, and Vincent S Tseng. 2012. Efficient algorithms for mining maximal high utility itemsets from data streams with different models. Expert Systems with Applications, Vol. 39, 17 (2012), 12947--12960.Google ScholarDigital Library"",""Mahito Sugiyama and Karsten Borgwardt. 2019. Finding statistically significant interactions between continuous features. In Proceedings of the 28th International Joint Conference on Artificial Intelligence. AAAI Press, 3490--3498.Google ScholarCross Ref"",""Robert E Tarone. 1990. A modified Bonferroni method for discrete data. Biometrics (1990), 515--522.Google Scholar"",""Aika Terada, Mariko Okada-Hatakeyama, Koji Tsuda, and Jun Sese. 2013. Statistical significance of combinatorial regulations. Proceedings of the National Academy of Sciences, Vol. 110, 32 (2013), 12996--13001.Google ScholarCross Ref"",""Aika Terada, Koji Tsuda, et al. 2016. Significant pattern mining with confounding variables. In Pacific-Asia Conference on Knowledge Discovery and Data Mining. Springer, 277--289.Google ScholarCross Ref"",""Geoffrey I Webb. 2007. Discovering significant patterns. Machine learning, Vol. 68, 1 (2007), 1--33.Google Scholar"",""Geoffrey I Webb and Francois Petitjean. 2016. A multiple test correction for streams and cascades of statistical hypothesis tests. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 1255--1264.Google ScholarDigital Library"",""Hong Yao and Howard J Hamilton. 2006. Mining itemset utilities from transaction databases. Data \u0026 Knowledge Engineering, Vol. 59, 3 (2006).Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403217,Certifiable Robustness of Graph Convolutional Networks under Structure Perturbations,"Recent works show that message-passing neural networks (MPNNs) can be fooled by adversarial attacks on both the node attributes and the graph structure. Since MPNNs are currently being rapidly adopted in real-world applications, it is thus crucial to improve their reliablility and robustness. While there has been progress on robustness certification of MPNNs under perturbation of the node attributes, no existing method can handle structural perturbations. These perturbations are especially challenging because they alter the message passing scheme itself. In this work we close this gap and propose the first method to certify robustness of Graph Convolutional Networks (GCNs) under perturbations of the graph structure. We show how this problem can be expressed as a jointly constrained bilinear program - a challenging, yet well-studied class of problems - and propose a novel branch-and-bound algorithm to obtain lower bounds on the global optimum. These lower bounds are significantly tighter and can certify up to twice as many nodes compared to a standard linear relaxation.","[{""name"":""Daniel Zügner"",""id"":""/profile/99659286550""},{""name"":""Stephan Günnemann"",""id"":""/profile/81447604694""},{""name"":""Daniel Zügner"",""id"":""/profile/99659286550""},{""name"":""Stephan Günnemann"",""id"":""/profile/81447604694""}]","[""Faiz A. Al-Khayyal and James E. Falk. 1983. Jointly Constrained Biconvex Programming. Mathematics of Operations Research, Vol. 8, 2 (May 1983), 273--286.Google ScholarCross Ref"",""Aleksandar Bojchevski and Stephan Günnemann. 2019. Adversarial Attacks on Node Embeddings via Graph Poisoning. In ICML.Google Scholar"",""Aleksandar Bojchevski and Stephan Günnemann. 2019. Certifiable Robustness to Graph Perturbations. In NeurIPS. 8317--8328.Google Scholar"",""Aleksandar Bojchevski and Stephan Günnemann. 2020. Efficient Robustness Certificates for Discrete Data: Sparsity-Aware Randomized Smoothing for Graphs, Images and More. In ICML.Google Scholar"",""Hanjun Dai, Hui Li, Tian Tian, Xin Huang, Lin Wang, Jun Zhu, and Le Song. 2018. Adversarial Attack on Graph Structured Data. In ICML.Google Scholar"",""Negin Entezari, Saba A. Al-Sayouri, Amirali Darvishzadeh, and Evangelos E. Papalexakis. 2020. All You Need Is Low (Rank): Defending Against Adversarial Attacks on Graphs. In WSDM. ACM, 169--177.Google Scholar"",""Ian Goodfellow, Jonathon Shlens, and Christian Szegedy. 2014. Explaining and Harnessing Adversarial Examples. arXiv 1412.6572 (12 2014).Google Scholar"",""Thomas N Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In ICLR.Google Scholar"",""Andrew Kachites McCallum, Kamal Nigam, Jason Rennie, and Kristie Seymore. 2000. Automating the construction of internet portals with machine learning. Information Retrieval, Vol. 3, 2 (2000), 127--163.Google ScholarDigital Library"",""Andrea Qualizza, Pietro Belotti, and Franc cois Margot. 2012. Linear Programming Relaxations of Quadratically Constrained Quadratic Programs. In Mixed Integer Nonlinear Programming, Jon Lee and Sven Leyffer (Eds.). Springer New York.Google Scholar"",""Aditi Raghunathan, Jacob Steinhardt, and Percy S Liang. 2018. Semidefinite Relaxations for Certifying Robustness to Adversarial Examples. In NIPS.Google Scholar"",""Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, and Tina Eliassi-Rad. 2008. Collective classification in network data. AI magazine, Vol. 29, 3 (2008), 93.Google Scholar"",""Eric Wong and Zico Kolter. 2018. Provable Defenses against Adversarial Examples via the Convex Outer Adversarial Polytope. In ICML. 5283--5292.Google Scholar"",""Kaidi Xu, Hongge Chen, Sijia Liu, Pin-Yu Chen, Tsui-Wei Weng, Mingyi Hong, and Xue Lin. 2019. Topology Attack and Defense for Graph Neural Networks: An Optimization Perspective. In IJCAI. ijcai.org, 3961--3967.Google Scholar"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale recommender systems. In SIGKDD. 974--983.Google Scholar"",""Dingyuan Zhu, Ziwei Zhang, Peng Cui, and Wenwu Zhu. 2019. Robust graph convolutional networks against adversarial attacks. In SIGKDD. 1399--1407.Google Scholar"",""Daniel Zügner, Amir Akbarnejad, and Stephan Günnemann. 2018. Adversarial Attacks on Neural Networks for Graph Data. In SIGKDD. 2847--2856.Google Scholar"",""Daniel Zügner and Stephan Günnemann. 2019 a. Adversarial Attacks on Graph Neural Networks via Meta Learning. In ICLR.Google Scholar"",""Daniel Zügner and Stephan Günnemann. 2019 b. Certifiable Robustness and Robust Training for Graph Convolutional Networks. In SIGKDD. 246--256.Google Scholar""]"
https://doi.org/10.1145/3394486.3403218,Understanding Negative Sampling in Graph Representation Learning,"Graph representation learning has been extensively studied in recent years, in which sampling is a critical point. Prior arts usually focus on sampling positive node pairs, while the strategy for negative sampling is left insufficiently explored. To bridge the gap, we systematically analyze the role of negative sampling from the perspectives of both objective and risk, theoretically demonstrating that negative sampling is as important as positive sampling in determining the optimization objective and the resulted variance. To the best of our knowledge, we are the first to derive the theory and quantify that a nice negative sampling distribution is pn(u|v) ∝ pd(u|v)α, 0 < α < 1. With the guidance of the theory, we propose MCNS, approximating the positive distribution with self-contrast approximation and accelerating negative sampling by Metropolis-Hastings. We evaluate our method on 5 datasets that cover extensive downstream graph learning tasks, including link prediction, node classification and recommendation, on a total of 19 experimental settings. These relatively comprehensive experimental results demonstrate its robustness and superiorities.","[{""name"":""Zhen Yang"",""id"":""/profile/99659574245""},{""name"":""Ming Ding"",""id"":""/profile/99659316268""},{""name"":""Chang Zhou"",""id"":""/profile/99659371467""},{""name"":""Hongxia Yang"",""id"":""/profile/99659259298""},{""name"":""Jingren Zhou"",""id"":""/profile/99659315652""},{""name"":""Jie Tang"",""id"":""/profile/81548005696""},{""name"":""Zhen Yang"",""id"":""/profile/99659574245""},{""name"":""Ming Ding"",""id"":""/profile/99659316268""},{""name"":""Chang Zhou"",""id"":""/profile/99659371467""},{""name"":""Hongxia Yang"",""id"":""/profile/99659259298""},{""name"":""Jingren Zhou"",""id"":""/profile/99659315652""},{""name"":""Jie Tang"",""id"":""/profile/81548005696""}]","[""Yoshua Bengio and Jean-Sébastien Senécal. 2008. Adaptive importance sampling to accelerate training of a neural probabilistic language model. IEEE Transactions on Neural Networks, Vol. 19, 4 (2008), 713--722.Google ScholarDigital Library"",""Avishek Joey Bose, Huan Ling, and Yanshuai Cao. 2018. Adversarial Contrastive Estimation. (2018), 1021--1032.Google Scholar"",""Liwei Cai and William Yang Wang. 2018. KBGAN: Adversarial Learning for Knowledge Graph Embeddings. In NAACL-HLT?18. 1470--1480.Google Scholar"",""Hugo Caselles-Dupré, Florian Lesaint, and Jimena Royo-Letelier. 2018. Word2vec applied to recommendation: Hyperparameters matter. In RecSys'18. ACM, 352--356.Google Scholar"",""Jie Chen, Tengfei Ma, and Cao Xiao. 2018. FastGCN: fast learning with graph convolutional networks via importance sampling. ICLR'18 (2018).Google Scholar"",""Siddhartha Chib and Edward Greenberg. 1995. Understanding the metropolis-hastings algorithm. The american statistician, Vol. 49, 4 (1995), 327--335.Google Scholar"",""Paolo Cremonesi, Yehuda Koren, and Roberto Turrin. 2010. Performance of recommender algorithms on top-n recommendation tasks. In Proceedings of the fourth ACM conference on Recommender systems. ACM, 39--46.Google ScholarDigital Library"",""Ming Ding, Jie Tang, and Jie Zhang. 2018. Semi-supervised learning on graphs with generative adversarial nets. In CIKM'18. ACM, 913--922.Google ScholarDigital Library"",""Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin. 2008. LIBLINEAR: A library for large linear classification. Journal of machine learning research, Vol. 9, Aug (2008), 1871--1874.Google ScholarDigital Library"",""Hongchang Gao and Heng Huang. 2018. Self-Paced Network Embedding. (2018), 1406--1415.Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In KDD'16. ACM, 855--864.Google ScholarDigital Library"",""Michael U Gutmann and Aapo Hyv\""arinen. 2012. Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics. Journal of Machine Learning Research, Vol. 13, Feb (2012), 307--361.Google ScholarDigital Library"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In NIPS'17. 1024--1034.Google ScholarDigital Library"",""Henry Hsu and Peter A Lachenbruch. 2007. Paired t test. Wiley encyclopedia of clinical trials (2007), 1--3.Google Scholar"",""Yifan Hu, Yehuda Koren, and Chris Volinsky. 2008. Collaborative filtering for implicit feedback datasets. In ICDM'08. Ieee, 263--272.Google ScholarDigital Library"",""Hong Huang, Jie Tang, Sen Wu, Lu Liu, and Xiaoming Fu. 2014. Mining triadic closure patterns in social networks. In WWW'14. 499--504.Google ScholarDigital Library"",""Thomas N Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional networks. ICLR'17 (2017).Google Scholar"",""Jure Leskovec, Jon Kleinberg, and Christos Faloutsos. 2007. Graph evolution: Densification and shrinking diameters. TKDD'07, Vol. 1, 1 (2007), 2--es.Google ScholarDigital Library"",""Omer Levy and Yoav Goldberg. 2014. Neural word embedding as implicit matrix factorization. In NIPS'14. 2177--2185.Google Scholar"",""Qimai Li, Zhichao Han, and Xiao-Ming Wu. 2018. Deeper insights into graph convolutional networks for semi-supervised learning. In AAAI'18.Google Scholar"",""Greg Linden, Brent Smith, and Jeremy York. 2003. Amazon. com recommendations: Item-to-item collaborative filtering. IEEE Internet computing, Vol. 7, 1 (2003), 76--80.Google Scholar"",""Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van Den Hengel. 2015. Image-based recommendations on styles and substitutes. In SIGIR'15. ACM, 43--52.Google ScholarDigital Library"",""Nicholas Metropolis, Arianna W Rosenbluth, Marshall N Rosenbluth, Augusta H Teller, and Edward Teller. 1953. Equation of state calculations by fast computing machines. The journal of chemical physics, Vol. 21, 6 (1953), 1087--1092.Google Scholar"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In NIPS'13. 3111--3119.Google ScholarDigital Library"",""Andriy Mnih and Koray Kavukcuoglu. 2013. Learning word embeddings efficiently with noise-contrastive estimation. In NIPS'13. 2265--2273.Google Scholar"",""Rong Pan, Yunhong Zhou, Bin Cao, Nathan N Liu, Rajan Lukose, Martin Scholz, and Qiang Yang. 2008. One-class collaborative filtering. In ICDM'08. IEEE, 502--511.Google ScholarDigital Library"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In KDD'14. ACM, 701--710.Google ScholarDigital Library"",""Jiezhong Qiu, Yuxiao Dong, Hao Ma, Jian Li, Kuansan Wang, and Jie Tang. 2018. Network embedding as matrix factorization: Unifying deepwalk, line, pte, and node2vec. In WSDM'18. ACM, 459--467.Google ScholarDigital Library"",""Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian personalized ranking from implicit feedback. In UAI'09. AUAI Press, 452--461.Google ScholarDigital Library"",""Kazunari Sugiyama and Min-Yen Kan. 2010. Scholarly paper recommendation via user's recent research interests. In JCDL'10. ACM, 29--38.Google ScholarDigital Library"",""Zhiqing Sun, Zhi-Hong Deng, Jian-Yun Nie, and Jian Tang. 2019. Rotate: Knowledge graph embedding by relational rotation in complex space. arXiv preprint arXiv:1902.10197 (2019).Google Scholar"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. In WWW'15. 1067--1077.Google ScholarDigital Library"",""Cunchao Tu, Han Liu, Zhiyuan Liu, and Maosong Sun. 2017. Cane: Context-aware network embedding for relation modeling. In ACL'17. 1722--1731.Google ScholarCross Ref"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2018. Graph attention networks. ICLR'18 (2018).Google Scholar"",""Jun Wang, Lantao Yu, Weinan Zhang, Yu Gong, Yinghui Xu, Benyou Wang, Peng Zhang, and Dell Zhang. 2017b. Irgan: A minimax game for unifying generative and discriminative information retrieval models. In SIGIR'17. ACM, 515--524.Google ScholarDigital Library"",""Qinyong Wang, Hongzhi Yin, Zhiting Hu, Defu Lian, Hao Wang, and Zi Huang. 2018. Neural memory streaming recommender networks with adversarial training. In KDD'18. ACM, 2467--2475.Google ScholarDigital Library"",""Xiao Wang, Peng Cui, Jing Wang, Jian Pei, Wenwu Zhu, and Shiqiang Yang. 2017a. Community preserving network embedding. In AAAI'17.Google Scholar"",""Jason Weston, Samy Bengio, and Nicolas Usunier. 2011. Wsabie: Scaling up to large vocabulary image annotation. In IJCAI'11 .Google Scholar"",""Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2018. How powerful are graph neural networks? arXiv preprint arXiv:1810.00826 (2018).Google Scholar"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale recommender systems. In KDD'18. ACM, 974--983.Google ScholarDigital Library"",""Weinan Zhang, Tianqi Chen, Jun Wang, and Yong Yu. 2013. Optimizing Top-N Collaborative Filtering via Dynamic Negative Item Sampling. In SIGIR'13. ACM, 785--788.Google ScholarDigital Library"",""Yongqi Zhang, Quanming Yao, Yingxia Shao, and Lei Chen. 2019. NSCaching: Simple and Efficient Negative Sampling for Knowledge Graph Embedding. (2019), 614--625.Google Scholar"",""Zheng Zhang and Pierre Zweigenbaum. 2018. GNEG: Graph-Based Negative Sampling for word2vec. In ACL'18. 566--571.Google ScholarCross Ref"",""Tong Zhao, Julian McAuley, and Irwin King. 2015. Improving latent factor models via personalized feature projection for one class recommendation. In CIKM'15. ACM, 821--830.Google ScholarDigital Library"",""Chang Zhou, Yuqiong Liu, Xiaofei Liu, Zhongyi Liu, and Jun Gao. 2017. Scalable graph embedding for asymmetric proximity. In AAAI'17.Google Scholar"",""Chang Zhou, Jianxin Ma, Jianwei Zhang, Jingren Zhou, and Hongxia Yang. 2020. Contrastive Learning for Debiased Candidate Generation in Large-Scale Recommender Systems. arxiv: cs.IR/2005.12964Google Scholar""]"
https://doi.org/10.1145/3394486.3403219,Aligning Superhuman AI with Human Behavior: Chess as a Model System,"As artificial intelligence becomes increasingly intelligent---in some cases, achieving superhuman performance---there is growing potential for humans to learn from and collaborate with algorithms. However, the ways in which AI systems approach problems are often different from the ways people do, and thus may be uninterpretable and hard to learn from. A crucial step in bridging this gap between human and artificial intelligence is modeling the granular actions that constitute human behavior, rather than simply matching aggregate human performance. We pursue this goal in a model system with a long history in artificial intelligence: chess. The aggregate performance of a chess player unfolds as they make decisions over the course of a game. The hundreds of millions of games played online by players at every skill level form a rich source of data in which these decisions, and their exact context, are recorded in minute detail. Applying existing chess engines to this data, including an open-source implementation of AlphaZero, we find that they do not predict human moves well. We develop and introduce Maia, a customized version of AlphaZero trained on human chess games, that predicts human moves at a much higher accuracy than existing engines, and can achieve maximum accuracy when predicting decisions made by players at a specific skill level in a tuneable way. For a dual task of predicting whether a human will make a large mistake on the next move, we develop a deep neural network that significantly outperforms competitive baselines. Taken together, our results suggest that there is substantial promise in designing artificial intelligence systems with human collaboration in mind by first accurately modeling granular human decision-making.","[{""name"":""Reid McIlroy-Young"",""id"":""/profile/99659304858""},{""name"":""Siddhartha Sen"",""id"":""/profile/99659152804""},{""name"":""Jon Kleinberg"",""id"":""/profile/81100288264""},{""name"":""Ashton Anderson"",""id"":""/profile/81466643014""},{""name"":""Reid McIlroy-Young"",""id"":""/profile/99659304858""},{""name"":""Siddhartha Sen"",""id"":""/profile/99659152804""},{""name"":""Jon Kleinberg"",""id"":""/profile/81100288264""},{""name"":""Ashton Anderson"",""id"":""/profile/81466643014""}]","[""Ashton Anderson, Jon Kleinberg, and Sendhil Mullainathan. 2017. Assessing human error against a benchmark of perfection. ACM Transactions on Knowledge Discovery from Data (TKDD) , Vol. 11, 4 (2017), 45.Google Scholar"",""John R Anderson, C Franklin Boyle, and Brian J Reiser. 1985. Intelligent tutoring systems. Science , Vol. 228, 4698 (1985), 456--462.Google Scholar"",""Tamal Biswas and Kenneth W Regan. 2015. Measuring Level-K Reasoning, Satisficing, and Human Error in Game-Play Data. In 2015 IEEE 14th International Conference on Machine Learning and Applications . IEEE, Miami, FL, 941--947.Google ScholarCross Ref"",""Neil Charness. 1992. The impact of chess research on cognitive science. Psychological research , Vol. 54, 1 (1992), 4--9.Google Scholar"",""Finale Doshi-Velez and Been Kim. 2017. A Roadmap for a Rigorous Science of Interpretability . Technical Report 1702.08608. arxiv.org.Google Scholar"",""Andre Esteva, Brett Kuprel, Roberto A Novoa, Justin Ko, Susan M Swetter, Helen M Blau, and Sebastian Thrun. 2017. Dermatologist-level classification of skin cancer with deep neural networks. Nature , Vol. 542, 7639 (2017), 115--118.Google Scholar"",""Eric Horvitz. 1999. Principles of Mixed-Initiative User Interfaces. In Proceeding of the CHI '99 Conference on Human Factors in Computing Systems, Marian G. Williams and Mark W. Altom (Eds.). ACM, Pittsburgh Pennsylvania, 159--166.Google ScholarDigital Library"",""Garry Kasparov. 2018. Chess, a Drosophila of reasoning. Science (2018).Google Scholar"",""Barry Kirwan. 1993. Human reliability assessment .Wiley, London, England.Google Scholar"",""Jon Kleinberg, Himabindu Lakkaraju, Jure Leskovec, Jens Ludwig, and Sendhil Mullainathan. 2018. Human decisions and machine predictions. The quarterly journal of economics , Vol. 133, 1 (2018), 237--293.Google Scholar"",""Zachary C. Lipton. 2018. The mythos of model interpretability. CACM (2018).Google Scholar"",""John McCarthy. 1990. Chess as the Drosophila of AI. In Computers, chess, and cognition . Springer, New York, NY, 227--237.Google Scholar"",""Gavriel Salvendy. 2012. Handbook of human factors and ergonomics .Wiley, NJ.Google Scholar"",""David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, et almbox. 2018. A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. Science (2018).Google Scholar"",""David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, et almbox. 2017. Mastering the game of go without human knowledge. Nature (2017).Google Scholar"",""Bradly C. Stadie, Pieter Abbeel, and Ilya Sutskever. 2017. Third-Person Imitation Learning . Technical Report 1703.0173. arxiv.org.Google Scholar"",""Wikipedia. 2020. Top Chess Engine Championship. en.wikipedia.org/wiki/Top_Chess_Engine_Championship#Tournament_results_(TCEC) . Accessed: 20-02-09.Google Scholar"",""Jiaming Zeng, Berk Ustun, and Cynthia Rudin. 2017. Interpretable classification models for recidivism prediction. J. Royal Stat Society: Series A , Vol. 180 (2017).Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403220,Heidegger: Interpretable Temporal Causal Discovery,"Temporal causal discovery aims to find cause-effect relationships between time-series. However, none of the existing techniques is able to identify the causal profile, the temporal pattern that the causal variable needs to follow in order to trigger the most significant change in the outcome. Toward a new horizon, this study introduces the novel problem of Causal Profile Discovery, which is crucial for many applications such as adverse drug reaction and cyber-attack detection. This work correspondingly proposes Heidegger to discover causal profiles, comprised of a flexible randomized block design for hypothesis evaluation and an efficient profile search via on-the-fly graph construction and entropy-based pruning. Heidegger's performance is demonstrated/evaluated extensively on both synthetic and real-world data. The experimental results show the proposed method is robust to noise and flexible at detecting complex patterns.","[{""name"":""Mehrdad Mansouri"",""id"":""/profile/99659573133""},{""name"":""Ali Arab"",""id"":""/profile/99659573195""},{""name"":""Zahra Zohrevand"",""id"":""/profile/81496686769""},{""name"":""Martin Ester"",""id"":""/profile/81100382875""},{""name"":""Mehrdad Mansouri"",""id"":""/profile/99659573133""},{""name"":""Ali Arab"",""id"":""/profile/99659573195""},{""name"":""Zahra Zohrevand"",""id"":""/profile/81496686769""},{""name"":""Martin Ester"",""id"":""/profile/81100382875""}]","[""Ahmed Abbas, Xin-Bing Kong, Zhi Liu, Bing-Yi Jing, and Xin Gao. 2013. Automatic peak selection by a Benjamini-Hochberg-based algorithm. PloS one, Vol. 8, 1 (2013).Google Scholar"",""Constantin F Aliferis, Alexander Statnikov, Ioannis Tsamardinos, Subramani Mani, and Xenofon D Koutsoukos. 2010. Local causal and markov blanket induction for causal discovery and feature selection for classification part i: Algorithms and empirical evaluation. Journal of Machine Learning Research, Vol. 11, Jan (2010), 171--234.Google ScholarDigital Library"",""Barak Ariel and David P Farrington. 2010. Randomized block designs. In Handbook of quantitative criminology. Springer, 437--454.Google Scholar"",""Andrew Arnold, Yan Liu, and Naoki Abe. 2007. Temporal causal modeling with graphical granger methods. In Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 66--75.Google ScholarDigital Library"",""Eyal Bairey, Eric D Kelsic, and Roy Kishony. 2016. High-order species interactions shape ecosystem diversity. Nature communications, Vol. 7 (2016), 12285.Google Scholar"",""Yoav Benjamini and Yosef Hochberg. 1995. Controlling the false discovery rate: a practical and powerful approach to multiple testing. Journal of the Royal statistical society: series B (Methodological), Vol. 57, 1 (1995), 289--300.Google ScholarCross Ref"",""Hans-Peter Blossfeld and Götz Rohwer. 1997. Causal inference, time and observation plans in the social sciences. Quality and quantity, Vol. 31, 4 (1997), 361--384.Google Scholar"",""Sezen Cekic, Didier Grandjean, and Olivier Renaud. 2018. Time, frequency, and time-varying Granger-causality measures in neuroscience. Statistics in medicine, Vol. 37, 11 (2018), 1910--1931.Google Scholar"",""Kunjin Chen, Caowei Huang, and Jinliang He. 2016. Fault detection, classification and location for transmission lines and distribution systems: a review on the methods. High voltage, Vol. 1, 1 (2016), 25--33.Google Scholar"",""Diego Colombo, Marloes H Maathuis, Markus Kalisch, and Thomas S Richardson. 2012. Learning high-dimensional directed acyclic graphs with latent and selection variables. The Annals of Statistics (2012), 294--321.Google Scholar"",""Doris Entner and Patrik O Hoyer. 2010. On causal discovery from time series data using FCI. Probabilistic graphical models (2010), 121--128.Google Scholar"",""Edmund A Gehan. 1965. A generalized Wilcoxon test for comparing arbitrarily singly-censored samples. Biometrika, Vol. 52, 1--2 (1965), 203--224.Google ScholarCross Ref"",""Clark Glymour, Kun Zhang, and Peter Spirtes. 2019. Review of Causal Discovery Methods Based on Graphical Models. Frontiers in Genetics, Vol. 10 (2019).Google ScholarCross Ref"",""Mingming Gong, Kun Zhang, Bernhard Schoelkopf, Dacheng Tao, and Philipp Geiger. 2015. Discovering temporal causal relations from subsampled data. In International Conference on Machine Learning. 1898--1906.Google Scholar"",""Clive WJ Granger. 1969. Investigating causal relations by econometric models and cross-spectral methods. Econometrica: Journal of the Econometric Society (1969), 424--438.Google Scholar"",""Miguel Henry and George Judge. 2019. Permutation Entropy and Information Recovery in Nonlinear Dynamic Economic Time Series. Econometrics, Vol. 7, 1 (2019), 10.Google ScholarCross Ref"",""Meng Hu and Hualou Liang. 2014. A copula approach to assessing Granger causality. NeuroImage, Vol. 100 (2014), 125--134.Google ScholarCross Ref"",""Aapo Hyv\""arinen, Kun Zhang, Shohei Shimizu, and Patrik O Hoyer. 2010. Estimation of a structural vector autoregression model using non-gaussianity. Journal of Machine Learning Research, Vol. 11, May (2010), 1709--1731.Google Scholar"",""Ronald Kessler and David F Greenberg. 1981. Linear panel models. New York: Academic (1981).Google Scholar"",""Samantha Kleinberg. 2015. Why: A guide to finding and using causes . \""O'Reilly Media, Inc.\"".Google Scholar"",""Yan Liu, Jayant R Kalagnanam, and Oivind Johnsen. 2009. Learning dynamic temporal graphs for oil-production equipment monitoring system. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 1225--1234.Google ScholarDigital Library"",""Yan Liu, Alexandru Niculescu-Mizil, Aurelie Lozano, and Yong Lu. 2011. Temporal graphical models for cross-species gene regulatory network discovery. Journal of bioinformatics and computational biology, Vol. 9, 02 (2011), 231--250.Google ScholarCross Ref"",""Christos Louizos, Uri Shalit, Joris M Mooij, David Sontag, Richard Zemel, and Max Welling. 2017. Causal effect inference with deep latent-variable models. In Advances in Neural Information Processing Systems. 6446--6456.Google Scholar"",""Daniel Malinsky and David Danks. 2018. Causal discovery algorithms: A practical guide. Philosophy Compass, Vol. 13, 1 (2018), e12470.Google ScholarCross Ref"",""Mehrdad Mansouri, Bowei Yuan, Colin JD Ross, Bruce C Carleton, and Martin Ester. 2018. HUME: large-scale detection of causal genetic factors of adverse drug reactions. Bioinformatics, Vol. 34, 24 (2018), 4274--4283.Google ScholarCross Ref"",""Abul MM Masih and Rumi Masih. 1996. Energy consumption, real income and temporal causality: results from a multi-country study based on cointegration and error-correction modelling techniques. Energy economics, Vol. 18, 3 (1996), 165--183.Google Scholar"",""Lawrence S Mayer. 1986. On cross-lagged panel models with serially correlated errors. Journal of Business \u0026 Economic Statistics, Vol. 4, 3 (1986), 347--357.Google Scholar"",""MF McGranaghan, RC Dugan, and WL Sponsler. 1981. Digital simulation of distribution system frequency-response characteristics. IEEE Transactions on Power Apparatus and Systems 3 (1981), 1362--1369.Google ScholarCross Ref"",""Marie C McGraw and Elizabeth A Barnes. [n.d.]. Memory matters: a case for Granger causality in climate variability studies. Journal of Climate ( [n.,d.]).Google Scholar"",""Jovana Mitrovic, Dino Sejdinovic, and Yee Whye Teh. 2018. Causal inference via kernel deviance measures. In Advances in Neural Information Processing Systems. 6986--6994.Google Scholar"",""Dan Mønster, Riccardo Fusaroli, Kristian Tylén, Andreas Roepstorff, and Jacob F Sherson. 2017. Causal inference from noisy time-series data-Testing the Convergent Cross-Mapping algorithm in the presence of noise and external influence. Future Generation Computer Systems, Vol. 73 (2017), 52--62.Google ScholarCross Ref"",""Volker Nannen. 2010. A short introduction to model selection, Kolmogorov complexity and Minimum Description Length (MDL). arXiv preprint arXiv:1005.2364 (2010).Google Scholar"",""Meike Nauta, Doina Bucur, and Christin Seifert. 2019. Causal discovery with attention-based convolutional neural networks. Machine Learning and Knowledge Extraction, Vol. 1, 1 (2019), 312--340.Google ScholarCross Ref"",""Bo Ning, Subhashis Ghosal, Jewell Thomas, et al. 2019. Bayesian method for causal inference in spatially-correlated multivariate time series. Bayesian Analysis, Vol. 14, 1 (2019), 1--28.Google ScholarCross Ref"",""Sam Norton, Fiona E Matthews, Deborah E Barnes, Kristine Yaffe, and Carol Brayne. 2014. Potential for primary prevention of Alzheimer's disease: an analysis of population-based data. The Lancet Neurology, Vol. 13, 8 (2014), 788--794.Google ScholarCross Ref"",""World Health Organization et al. 2019. Risk reduction of cognitive decline and dementia: WHO guidelines. In Risk reduction of cognitive decline and dementia: WHO guidelines. 401--401.Google Scholar"",""Jakob Runge, Peer Nowack, Marlene Kretschmer, Seth Flaxman, and Dino Sejdinovic. 2017. Detecting causal associations in large nonlinear time series datasets. arXiv preprint arXiv:1702.07007 (2017).Google Scholar"",""James P Selig and Todd D Little. 2012. Autoregressive and cross-lagged panel analysis for longitudinal data. (2012).Google Scholar"",""William R Shadish, Thomas D Cook, and Donald T Campbell. [n.d.]. Experimental and quasi-experimental designs for generalized causal inference. ( [n.,d.]).Google Scholar"",""Shohei Shimizu, Patrik O Hoyer, Aapo Hyv\""arinen, and Antti Kerminen. 2006. A linear non-Gaussian acyclic model for causal discovery. Journal of Machine Learning Research, Vol. 7, Oct (2006), 2003--2030.Google ScholarDigital Library"",""Du Sizhen, Song Guojie, Han Lei, and Hong Haikun. 2018. Temporal Causal Inference with Time Lag. Neural Computing, Vol. 30 (2018), 271--291.Google ScholarDigital Library"",""Peter Spirtes, Clark N Glymour, Richard Scheines, David Heckerman, Christopher Meek, Gregory Cooper, and Thomas Richardson. 2000. Causation, prediction, and search .MIT press.Google Scholar"",""Peter Spirtes and Kun Zhang. 2016. Causal discovery and inference: concepts and recent methodological advances. In Applied informatics, Vol. 3. SpringerOpen, 3.Google Scholar"",""Andrew Steptoe, Elizabeth Breeze, James Banks, and James Nazroo. 2013. Cohort profile: the English longitudinal study of ageing. International journal of epidemiology, Vol. 42, 6 (2013), 1640--1648.Google Scholar"",""Gilbert Sybille. [n.d.]. Use of Surge Arresters in Transmission System. https://www.mathworks.com/help/physmod/sps/examples/use-of-surge-arresters-in-transmission-system.html accessed: 11-November-2019.Google Scholar"",""Gilbert Sybille and Hoang Le-Huy. 2000. Digital simulation of power systems and power electronics using the MATLAB/Simulink Power System Blockset. In 2000 IEEE Power Engineering Society Winter Meeting. Conference Proceedings (Cat. No. 00CH37077), Vol. 4. IEEE, 2973--2981.Google ScholarCross Ref"",""CF Jeff Wu and Michael S Hamada. 2011. Experiments: planning, analysis, and optimization. Vol. 552. John Wiley \u0026 Sons.Google Scholar"",""Mattia Zorzi and Alessandro Chiuso. 2017. Sparse plus low rank network identification: A nonparametric approach. Automatica, Vol. 76 (2017), 355--366.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403221,Interpretable Deep Graph Generation with Node-edge Co-disentanglement,"Disentangled representation learning has recently attracted a significant amount of attention, particularly in the field of image representation learning. However, learning the disentangled representations behind a graph remains largely unexplored, especially for the attributed graph with both node and edge features. Disentanglement learning for graph generation has substantial new challenges including 1) the lack of graph deconvolution operations to jointly decode node and edge attributes; and 2) the difficulty in enforcing the disentanglement among latent factors that respectively influence: i) only nodes, ii) only edges, and iii) joint patterns between them. To address these challenges, we propose a new disentanglement enhancement framework for deep generative models for attributed graphs. In particular, a novel variational objective is proposed to disentangle the above three types of latent factors, with novel architecture for node and edge deconvolutions. Qualitative and quantitative experiments on both synthetic and real-world datasets demonstrate the effectiveness of the proposed model and its extensions.","[{""name"":""Xiaojie Guo"",""id"":""/profile/99659322728""},{""name"":""Liang Zhao"",""id"":""/profile/82658652657""},{""name"":""Zhao Qin"",""id"":""/profile/99659575136""},{""name"":""Lingfei Wu"",""id"":""/profile/99659061651""},{""name"":""Amarda Shehu"",""id"":""/profile/81336493044""},{""name"":""Yanfang Ye"",""id"":""/profile/99658737605""},{""name"":""Xiaojie Guo"",""id"":""/profile/99659322728""},{""name"":""Liang Zhao"",""id"":""/profile/82658652657""},{""name"":""Zhao Qin"",""id"":""/profile/99659575136""},{""name"":""Lingfei Wu"",""id"":""/profile/99659061651""},{""name"":""Amarda Shehu"",""id"":""/profile/81336493044""},{""name"":""Yanfang Ye"",""id"":""/profile/99658737605""}]","[""Romany NN Abskharon, Gabriele Giachin, and et al. 2014. Probing the N-terminal β-sheet conversion in the crystal structure of the human prion protein bound to a nanobody. Journal of the American Chemical Society, Vol. 136, 3 (2014), 937--944.Google ScholarCross Ref"",""Alexander A Alemi, Ian Fischer, Joshua V Dillon, and Kevin Murphy. 2017. Deep variational information bottleneck. ICLR (2017).Google Scholar"",""Yunsheng Bai, Hao Ding, Yang Qiao, Agustin Marinovic, Ken Gu, Ting Chen, Yizhou Sun, and Wei Wang. 2019. Unsupervised inductive graph-level representation learning via graph-graph proximity. In IJCAI. 1988--1994.Google Scholar"",""Yoshua Bengio, Aaron Courville, and Pascal Vincent. 2013. Representation learning: A review and new perspectives. IEEE transactions on pattern analysis and machine intelligence, Vol. 35, 8 (2013), 1798--1828.Google Scholar"",""Aleksandar Bojchevski, Oleksandr Shchur, Daniel Zügner, and Stephan Günnemann. 2018. NetGAN: Generating Graphs via Random Walks. In ICML. 609--618.Google Scholar"",""Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. 2013. Spectral networks and locally connected networks on graphs. ICLR (2013).Google Scholar"",""Tian Qi Chen, Xuechen Li, Roger B Grosse, and David K Duvenaud. 2018. Isolating sources of disentanglement in variational autoencoders. In NeurIPS. 2610--2620.Google Scholar"",""Yu Chen, Lingfei Wu, and Mohammed J Zaki. 2020 a. Graphflow: Exploiting conversation flow with graph neural networks for conversational machine comprehension. IJCAI (2020).Google Scholar"",""Yu Chen, Lingfei Wu, and Mohammed J Zaki. 2020 b. Reinforcement learning based graph-to-sequence model for natural question generation. ICLR (2020).Google Scholar"",""Hanjun Dai, Yingtao Tian, Bo Dai, Steven Skiena, and Le Song. 2018. Syntax-directed variational autoencoder for structured data. ICLR (2018).Google Scholar"",""Finale Doshi-Velez and Been Kim. 2017. Towards a rigorous science of interpretable machine learning. (2017).Google Scholar"",""Cian Eastwood and Christopher KI Williams. 2018. A framework for the quantitative evaluation of disentangled representations. (2018).Google Scholar"",""Paul ErdHo s and Alfréd Rényi. 1960. On the evolution of random graphs. Publ. Math. Inst. Hung. Acad. Sci, Vol. 5, 1 (1960), 17--60.Google Scholar"",""Babak Esmaeili, Hao Wu, Sarthak Jain, and et al. 2019. Structured Disentangled Representations. In AISTATS. 2525--2534.Google Scholar"",""Yuyang Gao, Lingfei Wu, Houman Homayoun, and Liang Zhao. 2019. Dyngraph2seq: Dynamic-graph-to-sequence interpretable learning for health stage prediction in online health forums. ICDM (2019).Google Scholar"",""Ian Goodfellow, Jean Pouget-Abadie, and et al. 2014. Generative adversarial nets. In NeurIPS. 2672--2680.Google Scholar"",""Marco Gori, Gabriele Monfardini, and Franco Scarselli. 2005. A new model for learning in graph domains. In IJCNN, Vol. 2. IEEE, 729--734.Google ScholarCross Ref"",""Aditya Grover, Aaron Zweig, and Stefano Ermon. 2019. Graphite: Iterative Generative Modeling of Graphs. In ICML. 2434--2444.Google Scholar"",""Xiaojie Guo, Lingfei Wu, and Liang Zhao. 2018. Deep graph translation. arXiv preprint arXiv:1805.09980 (2018).Google Scholar"",""Xiaojie Guo, Liang Zhao, and et al. 2019. Deep Multi-attributed Graph Translation with Node-Edge Co-evolution. In ICDM.Google Scholar"",""Mikael Henaff, Joan Bruna, and Yann LeCun. 2015. Deep convolutional networks on graph-structured data. (2015).Google Scholar"",""Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. 2017. beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework. ICLR, Vol. 2, 5 (2017), 6.Google Scholar"",""Hyunjik Kim and Andriy Mnih. 2018. Disentangling by factorising. ICML (2018).Google Scholar"",""Diederik P Kingma and Max Welling. 2013. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 (2013).Google Scholar"",""Thomas N Kipf and Max Welling. 2016a. Semi-supervised classification with graph convolutional networks. ICLR (2016).Google Scholar"",""Thomas N Kipf and Max Welling. 2016b. Variational graph auto-encoders. (2016).Google Scholar"",""Abhishek Kumar, Prasanna Sattigeri, and Avinash Balakrishnan. 2018. Variational inference of disentangled latent concepts from unlabeled observations. ICLR (2018).Google Scholar"",""Matt J Kusner, Brooks Paige, and José Miguel Hernández-Lobato. 2017. Grammar variational autoencoder. In ICML. JMLR. org, 1945--1954.Google Scholar"",""Brenden M Lake, Tomer D Ullman, Joshua B Tenenbaum, and Samuel J Gershman. 2017. Building machines that learn and think like people. Behavioral and brain sciences, Vol. 40 (2017).Google Scholar"",""Alexander LeClair, Sakib Haque, Linfgei Wu, and Collin McMillan. 2020. Improved code summarization via a graph neural network. MSR (2020).Google Scholar"",""Qingzhe Li, Amir Alipour-Fanid, Martin Slawski, Yanfang Ye, Lingfei Wu, Kai Zeng, and Liang Zhao. 2019. Large-scale Cost-aware Classification Using Feature Computational Dependency Graph. IEEE Transactions on Knowledge and Data Engineering (2019).Google Scholar"",""Yujia Li, Oriol Vinyals, Chris Dyer, Razvan Pascanu, and Peter Battaglia. 2018. Learning deep generative models of graphs. (2018).Google Scholar"",""Yanbei Liu, Xiao Wang, Shu Wu, and Zhitao Xiao. 2019. Independence Promoted Graph Disentangled Networks. (2019).Google Scholar"",""Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Raetsch, Sylvain Gelly, Bernhard Schölkopf, and Olivier Bachem. 2019. Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations. In ICML. 4114--4124.Google Scholar"",""Romain Lopez, Jeffrey Regier, Michael I Jordan, and Nir Yosef. 2018. Information constraints on auto-encoding variational bayes. In NeurIPS. 6114--6125.Google Scholar"",""Jianxin Ma, Chang Zhou, Peng Cui, Hongxia Yang, and Wenwu Zhu. 2019. Learning disentangled representations for recommendation. In NeurIPS. 5712--5723.Google Scholar"",""Alireza Makhzani and Brendan J Frey. 2017. Pixelgan autoencoders. In NeurIPS. 1975--1985.Google Scholar"",""Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. 2014. Stochastic backpropagation and approximate inference in deep generative models. In ICML-Volume 32. II--1278.Google Scholar"",""Karl Ridgeway and Michael C Mozer. 2018. Learning deep disentangled embeddings with the f-statistic loss. In NeurIPS. 185--194.Google Scholar"",""Bidisha Samanta, Abir De, Niloy Ganguly, and Manuel Gomez-Rodriguez. 2018. Designing random graph models using variational autoencoders with applications to chemical design. (2018).Google Scholar"",""Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. 2008. The graph neural network model. IEEE Transactions on Neural Networks, Vol. 20, 1 (2008), 61--80.Google ScholarDigital Library"",""Kai Shen, Lingfei Wu, Fangli Xu, Siliang Tang, Jun Xiao, and Yueting Zhuang. 2020. Hierarchical Attention Based Spatial-Temporal Graph-to-Sequence Learning for Grounded Video Description. IJCAI (2020).Google Scholar"",""Martin Simonovsky and Nikos Komodakis. 2018. Graphvae: Towards generation of small graphs using variational autoencoders. In ICANN. Springer, 412--422.Google Scholar"",""Niklas Stoehr, Marc Brockschmidt, and et al. 2019. Disentangling Interpretable Generative Parameters of Random and Real-World Graphs. (2019).Google Scholar"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph attention networks. (2017).Google Scholar"",""Satosi Watanabe. 1960. Information theoretical analysis of multivariate correlation. IBM Journal of research and development, Vol. 4, 1 (1960), 66--82.Google Scholar"",""Duncan J Watts and Steven H Strogatz. 1998. Collective dynamics of ?small-world'networks. nature, Vol. 393, 6684 (1998), 440.Google Scholar"",""Jiaxuan You, Rex Ying, and et al. 2018. GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models. In ICML. 5708--5717.Google Scholar"",""Shengjia Zhao, Jiaming Song, and Stefano Ermon. 2019. Infovae: Information maximizing variational autoencoders. AAAI (2019).Google Scholar""]"
https://doi.org/10.1145/3394486.3403222,Minimizing Localized Ratio Cut Objectives in Hypergraphs,"Hypergraphs are a useful abstraction for modeling multiway relationships in data, and hypergraph clustering is the task of detecting groups of closely related nodes in such data.Graph clustering has been studied extensively, and there are numerous methods for detecting small, localized clusters without having to explore an entire input graph. However, there are only a few specialized approaches for localized clustering in hypergraphs. Here we present a framework for local hypergraph clustering based on minimizing localized ratio cut objectives. Our framework takes an input set of reference nodes in a hypergraph and solves a sequence of hypergraph minimum s-t cut problems in order to identify a nearby well-connected cluster of nodes that overlaps substantially with the input set.Our methods extend graph-based techniques but are significantly more general and have new output quality guarantees. First, our methods can minimize new generalized notions of hypergraph cuts, which depend on specific configurations of nodes within each hyperedge, rather than just on the number of cut hyperedges. Second, our framework has several attractive theoretical properties in terms of output cluster quality. Most importantly, our algorithm is strongly-local, meaning that its runtime depends only on the size of the input set, and does not need to explore the entire hypergraph to find good local clusters. We use our methodology to effectively identify clusters in hypergraphs of real-world data with millions of nodes, millions of hyperedges, and large average hyperedge size with runtimes ranging between a few seconds and a few minutes.","[{""name"":""Nate Veldt"",""id"":""/profile/99659125447""},{""name"":""Austin R. Benson"",""id"":""/profile/99658632368""},{""name"":""Jon Kleinberg"",""id"":""/profile/81100288264""},{""name"":""Nate Veldt"",""id"":""/profile/99659125447""},{""name"":""Austin R. Benson"",""id"":""/profile/99658632368""},{""name"":""Jon Kleinberg"",""id"":""/profile/81100288264""}]","[""Sameer Agarwal, Kristin Branson, and Serge Belongie. 2006. Higher Order Learning with Graphs. In ICML.Google Scholar"",""Sameer Agarwal, Jongwoo Lim, Lihi Zelnik-Manor, Pietro Perona, David Kriegman, and Serge Belongie. 2005. Beyond Pairwise Clustering. In CVPR.Google Scholar"",""Reid Andersen, Fan Chung, and Kevin Lang. 2006. Local Graph Partitioning using PageRank Vectors. In FOCS.Google Scholar"",""Reid Andersen and Kevin J. Lang. 2008. An Algorithm for Improving Graph Partitions (SODA '08). Society for Industrial and Applied Mathematics, Philadelphia, PA, USA, 651--660. http://dl.acm.org/citation.cfm?id=1347082.1347154Google Scholar"",""Austin R Benson, Rediet Abebe, Michael T Schaub, Ali Jadbabaie, and Jon Kleinberg. 2018. Simplicial closure and higher-order link prediction. PNAS (2018).Google Scholar"",""Austin R. Benson, David F. Gleich, and Jure Leskovec. 2016. Higher-order organization of complex networks. Science (2016).Google Scholar"",""Avrim Blum and Shuchi Chawla. 2001. Learning from Labeled and Unlabeled Data Using Graph Mincuts. In Proceedings of the Eighteenth International Conference on Machine Learning (ICML '01). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 19--26.Google ScholarDigital Library"",""T. H. Hubert Chan and Zhibin Liang. 2018. Generalizing the Hypergraph Laplacian via a Diffusion Process with Mediators. In COCOON.Google Scholar"",""T.-H. Hubert Chan, Anand Louis, Zhihao Gavin Tang, and Chenzi Zhang. 2018. Spectral Properties of Hypergraph Laplacian and Approximation Algorithms. JACM (2018).Google Scholar"",""Uthsav Chitra and Benjamin J. Raphael. 2019. Random Walks on Hypergraphs with Edge-Dependent Vertex Weights. In ICML.Google Scholar"",""Fan R. K. Chung. 1997. Spectral Graph Theory .American Math. Society.Google Scholar"",""Alina Ene, Huy Nguyen, and László A. Végh. 2017. Decomposable Submodular Function Minimization: Discrete and Continuous. In NeurIPS.Google Scholar"",""Santo Fortunato and Darko Hric. 2016. Community detection in networks: A user guide. Physics Reports (2016).Google Scholar"",""K. Fountoulakis, M. Liu, D. F. Gleich, and M. W. Mahoney. 2020. Flow-based Algorithms for Improving Clusters: A Unifying Framework, Software, and Performance. arxiv: cs.LG/2004.09608Google Scholar"",""M. Grötschel, L. Lovász, and A. Schrijver. 1981. The ellipsoid method and its consequences in combinatorial optimization. Combinatorica (1981).Google Scholar"",""Scott W. Hadley. 1995. Approximation techniques for hypergraph partitioning problems. Discrete Applied Mathematics (1995).Google Scholar"",""Edmund Ihler, Dorothea Wagner, and Frank Wagner. 1993. Modeling hypergraphs by graphs with the same mincut properties. Inform. Process. Lett. (1993).Google Scholar"",""Jianbo Shi and J. Malik. 2000. Normalized cuts and image segmentation. TPAMI (2000).Google Scholar"",""Vladimir Kolmogorov. 2012. Minimizing a Sum of Submodular Functions. Discrete Appl. Math. (2012).Google Scholar"",""Kevin Lang and Satish Rao. 2004. A Flow-Based Method for Improving the Expansion or Conductance of Graph Cuts. In IPCO.Google Scholar"",""E. L. Lawler. 1973. Cutsets and partitions of hypergraphs. Networks (1973).Google Scholar"",""Jianbo Li, Jingrui He, and Yada Zhu. 2018. E-tail product return prediction via hypergraph-based local graph cut. In KDD. 519--527.Google Scholar"",""Pan Li and Olgica Milenkovic. 2017. Inhomogeneous Hypergraph Clustering with Applications. In NeurIPS.Google Scholar"",""Pan Li and Olgica Milenkovic. 2018a. Revisiting Decomposable Submodular Function Minimization with Incidence Relations. In NeurIPS.Google Scholar"",""Pan Li and Olgica Milenkovic. 2018b. Submodular Hypergraphs: p-Laplacians, Cheeger Inequalities and Spectral Clustering. In ICML.Google Scholar"",""Jianmo Ni, Jiacheng Li, and Julian McAuley. 2019. Justifying Recommendations using Distantly-Labeled Reviews and Fine-Grained Aspects. In EMNLP-IJCNLP.Google Scholar"",""Lorenzo Orecchia and Zeyuan Allen Zhu. 2014. Flow-based Algorithms for Local Graph Clustering. In SODA.Google Scholar"",""James B. Orlin. 2009. A faster strongly polynomial time algorithm for submodular function minimization. Mathematical Programming (2009).Google Scholar"",""James B. Orlin. 2013. Max Flows in $O(nm)$ Time, or Better. In STOC.Google Scholar"",""Satu Elisa Schaeffer. 2007. Graph clustering. Computer Science Review, Vol. 1, 1 (2007), 27 -- 64. https://doi.org/10.1016/j.cosrev.2007.05.001Google ScholarDigital Library"",""Alexander Schrijver. 2000. A Combinatorial Algorithm Minimizing Submodular Functions in Strongly Polynomial Time. J. Comb. Theory Ser. B (2000).Google Scholar"",""Peter Stobbe and Andreas Krause. 2010. Efficient Minimization of Decomposable Submodular Functions. In NeurIPS.Google Scholar"",""Nate Veldt, Austin R. Benson, and Jon Kleinberg. 2020. Hypergraph Cuts with General Splitting Functions. arxiv: cs.DS/2001.02817Google Scholar"",""Nate Veldt, David Gleich, and Michael Mahoney. 2016. A Simple and Strongly-Local Flow-Based Method for Cut Improvement. In ICML.Google Scholar"",""Nate Veldt, Christine Klymko, and David F. Gleich. 2019. Flow-Based Local Graph Clustering with Better Seed Set Inclusion. In SDM.Google Scholar"",""Dorothea Wagner and Frank Wagner. 1993. Between min cut and graph bisection. In MFCS.Google Scholar"",""Naganand Yadati, Madhav Nimishakavi, Prateek Yadav, Vikram Nitin, Anand Louis, and Partha Talukdar. 2019. HyperGCN: A New Method For Training Graph Convolutional Networks on Hypergraphs. In NeurIPS.Google Scholar"",""Hao Yin, Austin R. Benson, Jure Leskovec, and David F. Gleich. 2017. Local Higher-Order Graph Clustering. In KDD.Google Scholar"",""Dengyong Zhou, Jiayuan Huang, and Bernhard Schölkopf. 2006. Learning with Hypergraphs: Clustering, Classification, and Embedding. In NeurIPS.Google Scholar"",""J. Y. Zien, M. D. F. Schlag, and P. K. Chan. 1999. Multilevel spectral hypergraph partitioning with arbitrary vertex sizes. IEEE TCAD (1999).Google Scholar""]"
https://doi.org/10.1145/3394486.3403223,RECIPTOR: An Effective Pretrained Model for Recipe Representation Learning,"Recipe representation plays an important role in food computing for perception, recognition, recommendation and other applications. Learning pretrained recipe embeddings is a challenging task, as there is a lack of high quality annotated food datasets. In this paper, we provide a joint approach for learning effective pretrained recipe embeddings using both the ingredients and cooking instructions. We present RECIPTOR, a novel set transformer-based joint model to learn recipe representations, that preserves permutation-invariance for the ingredient set and uses a novel knowledge graph (KG) derived triplet sampling approach to optimize the learned embeddings so that related recipes are closer in the latent semantic space. The embeddings are further jointly optimized by combining similarity among cooking instructions with a KG based triplet loss. We experimentally show that RECIPTOR's recipe embeddings outperform state-of-the-art baselines on two newly designed downstream classification tasks by a wide margin.","[{""name"":""Diya Li"",""id"":""/profile/99659573943""},{""name"":""Mohammed J. Zaki"",""id"":""/profile/81548027493""},{""name"":""Diya Li"",""id"":""/profile/99659573943""},{""name"":""Mohammed J. Zaki"",""id"":""/profile/81548027493""}]","[""Yong-Yeol Ahn, Sebastian E Ahnert, James P Bagrow, and Albert-László Barabási. 2011. Flavor network and the principles of food pairing. Scientific Reports, Vol. 1 (2011), 196.Google ScholarCross Ref"",""Amir Bakarov. 2018. A survey of word embeddings evaluation methods. arXiv preprint arXiv:1801.09536 (2018).Google Scholar"",""Fernando Batista, Joana Paulo Pardal, Paula Vaz Nuno Mamede, and Ricardo Ribeiro. 2006. Ontology construction: cooking domain. Artificial Intelligence: Methodology, Systems, and Applications, Vol. 41, 1 (2006), 30.Google Scholar"",""Micael Carvalho, Rémi Cadène, David Picard, Laure Soulier, Nicolas Thome, and Matthieu Cord. 2018. Cross-modal retrieval in the cooking context: Learning semantic text-image embeddings. In ACM SIGIR Conference.Google ScholarDigital Library"",""Gal Chechik, Varun Sharma, Uri Shalit, and Samy Bengio. 2010. Large scale online learning of image similarity through ranking. Journal of Machine Learning Research, Vol. 11, Mar (2010), 1109--1135.Google ScholarDigital Library"",""Jing-Jing Chen, Chong-Wah Ngo, Fu-Li Feng, and Tat-Seng Chua. 2018. Deep understanding of cooking procedure for cross-modal recipe retrieval. In ACM International conference on Multimedia.Google ScholarDigital Library"",""George Dahl, Tara Sainath, and Geoffrey Hinton. 2013. Improving deep neural networks for LVCSR using rectified linear units and dropout. In IEEE international conference on acoustics, speech and signal processing.Google ScholarCross Ref"",""Damion M Dooley, Emma J Griffiths, Gurinder S Gosal, Pier L Buttigieg, Robert Hoehndorf, Matthew C Lange, Lynn M Schriml, Fiona SL Brinkman, and William WL Hsiao. 2018. FoodOn: a harmonized food ontology to increase global food traceability, quality control and data integration. npj Science of Food, Vol. 2, 1 (2018), 1--10.Google Scholar"",""Matthias Fontanellaz, Stergios Christodoulidis, and Stavroula Mougiakakou. 2019. Self-Attention and Ingredient-Attention Based Model for Recipe Retrieval from Image Queries. In 5th Int'l Workshop on Multimedia Assisted Dietary Management.Google Scholar"",""Steven Haussmann, Oshani Seneviratne, Yu Chen, Yarden Ne'eman, James Codella, Ching-Hua Chen, Deborah L McGuinness, and Mohammed J Zaki. 2019. FoodKG: A Semantics-Driven Knowledge Graph for Food Recommendation. In International Semantic Web Conference. Springer, 146--162.Google Scholar"",""Luis Herranz, Weiqing Min, and Shuqiang Jiang. 2018. Food recognition and recipe analysis: integrating visual content, context and external knowledge. arXiv preprint arXiv:1801.07239 (2018).Google Scholar"",""Yoshiyuki Kawano and Keiji Yanai. 2014. Foodcam-256: a large-scale real-time mobile food recognition system employing high-dimensional features and compression of classifier weights. In ACM international conference on Multimedia.Google ScholarDigital Library"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).Google Scholar"",""Juho Lee, Yoonho Lee, Jungtaek Kim, Adam R Kosiorek, Seungjin Choi, and Yee Whye Teh. 2018. Set transformer: A framework for attention-based permutation-invariant neural networks. arXiv preprint arXiv:1810.00825 (2018).Google Scholar"",""Ilya Loshchilov and Frank Hutter. 2017. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101 (2017).Google Scholar"",""Javier Marin, Aritro Biswas, Ferda Ofli, Nicholas Hynes, Amaia Salvador, Yusuf Aytar, Ingmar Weber, and Antonio Torralba. 2019. Recipe1M+: A Dataset for Learning Cross-Modal Embeddings for Cooking Recipes and Food Images. IEEE Trans. Pattern Anal. Mach. Intell. (2019).Google Scholar"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems. 3111--3119.Google Scholar"",""Weiqing Min, Bing-Kun Bao, Shuhuan Mei, Yaohui Zhu, Yong Rui, and Shuqiang Jiang. 2017a. You are what you eat: Exploring rich recipe information for cross-region food analysis. IEEE Transactions on Multimedia, Vol. 20, 4 (2017), 950--964.Google ScholarDigital Library"",""Weiqing Min, Shuqiang Jiang, Linhu Liu, Yong Rui, and Ramesh Jain. 2019. A survey on food computing. ACM Computing Surveys (CSUR), Vol. 52, 5 (2019), 1--36.Google ScholarDigital Library"",""Weiqing Min, Shuqiang Jiang, Jitao Sang, Huayang Wang, Xinda Liu, and Luis Herranz. 2016. Being a supercook: Joint food attributes and multimodal content modeling for recipe retrieval and exploration. IEEE Transactions on Multimedia, Vol. 19, 5 (2016), 1100--1113.Google ScholarDigital Library"",""Weiqing Min, Shuqiang Jiang, Shuhui Wang, Jitao Sang, and Shuhuan Mei. 2017b. A delicious recipe analysis framework for exploring multi-modal recipes with various attributes. In ACM international conference on Multimedia.Google ScholarDigital Library"",""Ole G Mouritsen, Rachel Edwards-Stuart, Yong-Yeol Ahn, and Sebastian E Ahnert. 2017. Data-driven methods for the study of food perception, preparation, consumption, and culture. Frontiers in ICT, Vol. 4 (2017), 15.Google ScholarCross Ref"",""Paritosh Pandey, Akella Deepthi, Bappaditya Mandal, and Niladri B Puhan. 2017. FoodNet: Recognizing foods using ensemble of deep networks. IEEE Signal Processing Letters, Vol. 24, 12 (2017), 1758--1762.Google ScholarCross Ref"",""Markus Rokicki, Christoph Trattner, and Eelco Herder. 2018. The impact of recipe features, social cues and demographics on estimating the healthiness of online recipes. In AAAI Conference on Web and Social Media.Google Scholar"",""Sina Sajadmanesh, Sina Jafarzadeh, Seyed Ali Ossia, Hamid R Rabiee, Hamed Haddadi, Yelena Mejova, Mirco Musolesi, Emiliano De Cristofaro, and Gianluca Stringhini. 2017. Kissing cuisines: Exploring worldwide culinary habits on the web. In International conference on world wide web companion.Google ScholarDigital Library"",""Amaia Salvador, Nicholas Hynes, Yusuf Aytar, Javier Marin, Ferda Ofli, Ingmar Weber, and Antonio Torralba. 2017. Learning Cross-modal Embeddings for Cooking Recipes and Food Images. In IEEE CVPR Conference.Google Scholar"",""Tobias Schnabel, Igor Labutov, David Mimno, and Thorsten Joachims. 2015. Evaluation methods for unsupervised word embeddings. In EMNLP Conference.Google ScholarCross Ref"",""Florian Schroff, Dmitry Kalenichenko, and James Philbin. 2015. Facenet: A unified embedding for face recognition and clustering. In IEEE CVPR Conference.Google ScholarCross Ref"",""Chun-Yuen Teng, Yu-Ru Lin, and Lada A Adamic. 2012. Recipe recommendation using ingredient networks. In Annual ACM Web Science Conference.Google ScholarDigital Library"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In NIPS.Google Scholar"",""Hao Wang, Doyen Sahoo, Chenghao Liu, Ee-peng Lim, and Steven CH Hoi. 2019. Learning cross-modal embeddings with adversarial networks for cooking recipes and food images. In IEEE CVPR Conference.Google ScholarCross Ref"",""Jiang Wang, Yang Song, Thomas Leung, Chuck Rosenberg, Jingbin Wang, James Philbin, Bo Chen, and Ying Wu. 2014. Learning fine-grained image similarity with deep ranking. In IEEE CVPR Conference.Google ScholarDigital Library"",""Semih Yagcioglu, Aykut Erdem, Erkut Erdem, and Nazli Ikizler-Cinbis. 2018. RecipeQA: A challenge dataset for multimodal comprehension of cooking recipes. arXiv preprint arXiv:1809.00812 (2018).Google Scholar"",""Longqi Yang, Cheng-Kang Hsieh, Hongjian Yang, John P Pollak, Nicola Dell, Serge Belongie, Curtis Cole, and Deborah Estrin. 2017. Yum-me: a personalized nutrient-based meal recommender system. ACM Transactions on Information Systems (TOIS), Vol. 36, 1 (2017), 1--31.Google ScholarDigital Library"",""Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Russ R Salakhutdinov, and Alexander J Smola. 2017. Deep sets. In NIPS.Google Scholar""]"
https://doi.org/10.1145/3394486.3403224,Hyperbolic Distance Matrices,"Hyperbolic space is a natural setting for mining and visualizing data with hierarchical structure. In order to compute a hyperbolic embedding from comparison or similarity information, one has to solve a hyperbolic distance geometry problem. In this paper, we propose a unified framework to compute hyperbolic embeddings from an arbitrary mix of noisy metric and non-metric data. Our algorithms are based on semidefinite programming and the notion of a hyperbolic distance matrix, in many ways parallel to its famous Euclidean counterpart. A central ingredient we put forward is a semidefinite characterization of the hyperbolic Gramian---a matrix of Lorentzian inner products. This characterization allows us to formulate a semidefinite relaxation to efficiently compute hyperbolic embeddings in two stages: first, we complete and denoise the observed hyperbolic distance matrix; second, we propose a spectral factorization method to estimate the embedded points from the hyperbolic distance matrix. We show through numerical experiments how the flexibility to mix metric and non-metric constraints allows us to efficiently compute embeddings from arbitrary data.","[{""name"":""Puoya Tabaghi"",""id"":""/profile/99659574916""},{""name"":""Ivan Dokmanić"",""id"":""/profile/99659308915""},{""name"":""Puoya Tabaghi"",""id"":""/profile/99659574916""},{""name"":""Ivan Dokmanić"",""id"":""/profile/99659308915""}]","[""Sameer Agarwal, Josh Wills, Lawrence Cayton, Gert Lanckriet, David Kriegman, and Serge Belongie. 2007. Generalized non-metric multidimensional scaling. In Artificial Intelligence and Statistics. 11--18.Google Scholar"",""Leman Akoglu, Mary McGlohon, and Christos Faloutsos. 2010. Oddball: Spotting anomalies in weighted graphs. In Pacific-Asia Conference on Knowledge Discovery and Data Mining. Springer, 410--421.Google ScholarDigital Library"",""Abdo Y Alfakih, Amir Khandani, and Henry Wolkowicz. 1999. Solving Euclidean distance matrix completion problems via semidefinite programming. Computational Optimization and Applications, Vol. 12, 1--3 (1999), 13--30.Google ScholarDigital Library"",""Michael Ashburner, Catherine A Ball, Judith A Blake, David Botstein, Heather Butler, J Michael Cherry, Allan P Davis, Kara Dolinski, Selina S Dwight, Janan T Eppig, et al. 2000. Gene ontology: tool for the unification of biology. Nature Genetics, Vol. 25, 1 (2000), 25.Google ScholarCross Ref"",""Dena Asta and Cosma Rohilla Shalizi. 2014. Geometric network comparison. arXiv preprint arXiv:1411.1350 (2014).Google Scholar"",""Riccardo Benedetti and Carlo Petronio. 2012. Lectures on hyperbolic geometry .Springer Science \u0026 Business Media.Google Scholar"",""Marián Boguná, Fragkiskos Papadopoulos, and Dmitri Krioukov. 2010. Sustaining the Internet with hyperbolic mapping. Nature Communications, Vol. 1 (2010), 62.Google ScholarCross Ref"",""Carlo Vittorio Cannistraci, Gregorio Alanis-Lobato, and Timothy Ravasi. 2013. From link-prediction in brain connectomes and protein interactomes to the local-community-paradigm in complex networks. Scientific Reports, Vol. 3 (2013), 1613.Google ScholarCross Ref"",""James W Cannon, William J Floyd, Richard Kenyon, Walter R Parry, et al. 1997. Hyperbolic geometry. Flavors of Geometry, Vol. 31 (1997), 59--115.Google Scholar"",""Benjamin Paul Chamberlain, Stephen R Hardwick, David R Wardrope, Fabon Dzogang, Fabio Daolio, and Saúl Vargas. 2019. Scalable hyperbolic recommender systems. arXiv preprint arXiv:1902.08648 (2019).Google Scholar"",""Kenny Chowdhary and Tamara G Kolda. 2018. An improved hyperbolic embedding algorithm. Journal of Complex Networks, Vol. 6, 3 (2018), 321--341.Google ScholarCross Ref"",""Andrej Cvetkovski and Mark Crovella. 2009. Hyperbolic embedding and routing for dynamic graphs. In IEEE International Conference on Computer Communications. IEEE, 1647--1655.Google ScholarCross Ref"",""Christopher De Sa, Albert Gu, Christopher Ré, and Frederic Sala. 2018. Representation tradeoffs for hyperbolic embeddings. Proceedings of Machine Learning Research, Vol. 80 (2018), 4460.Google Scholar"",""Bhuwan Dhingra, Christopher J Shallue, Mohammad Norouzi, Andrew M Dai, and George E Dahl. 2018. Embedding text in hyperbolic spaces. arXiv preprint arXiv:1806.04313 (2018).Google Scholar"",""Steven Diamond and Stephen Boyd. 2016. CVXPY: A Python-embedded modeling language for convex optimization. The Journal of Machine Learning Research, Vol. 17, 1 (2016), 2909--2913.Google ScholarDigital Library"",""Ivan Dokmani?, Reza Parhizkar, Juri Ranieri, and Martin Vetterli. 2015. Euclidean distance matrices: Essential theory, algorithms, and applications. IEEE Signal Processing Magazine, Vol. 32, 6 (2015), 12--30.Google ScholarCross Ref"",""Maryam Fazel. 2002. Matrix rank minimization with applications. (2002).Google Scholar"",""Maryam Fazel, Haitham Hindi, and Stephen P Boyd. 2003. Log-det heuristic for matrix rank minimization with applications to Hankel and Euclidean distance matrices. In Proceedings of the 2003 American Control Conference, 2003., Vol. 3. IEEE, 2156--2162.Google ScholarCross Ref"",""Massimo Fornasier, Holger Rauhut, and Rachel Ward. 2011. Low-rank matrix recovery via iteratively reweighted least squares minimization. SIAM Journal on Optimization, Vol. 21, 4 (2011), 1614--1640.Google ScholarDigital Library"",""Octavian-Eugen Ganea, Gary Bécigneul, and Thomas Hofmann. 2018. Hyperbolic entailment cones for learning hierarchical embeddings. arXiv preprint arXiv:1804.01882 (2018).Google Scholar"",""Jessica L Gilbert, Matthew J Guthart, Salvador A Gezan, Melissa Pisaroglo de Carvalho, Michael L Schwieterman, Thomas A Colquhoun, Linda M Bartoshuk, Charles A Sims, David G Clark, and James W Olmstead. 2015. Identifying breeding priorities for blueberry flavor using biochemical, sensory, and genotype by environment analyses. PLoS One, Vol. 10, 9 (2015), e0138494.Google ScholarCross Ref"",""Chad Giusti, Eva Pastalkova, Carina Curto, and Vladimir Itskov. 2015. Clique topology reveals intrinsic geometric structure in neural correlations. Proceedings of the National Academy of Sciences, Vol. 112, 44 (2015), 13455--13460.Google ScholarCross Ref"",""Israel Gohberg, Peter Lancaster, and Leiba Rodman. 1983. Matrices and indefinite scalar products. (1983).Google Scholar"",""Roger A Horn and Charles R Johnson. 2012. Matrix analysis .Cambridge University Press.Google Scholar"",""Pratik Jawanpuria, Mayank Meghwanshi, and Bamdev Mishra. 2019. Low-rank approximations of hyperbolic embeddings. arXiv preprint arXiv:1903.07307 (2019).Google Scholar"",""Martin Keller-Ressel and Stephanie Nargang. 2020. Hydra: a method for strain-minimizing hyperbolic embedding of network-and distance-based data. Journal of Complex Networks, Vol. 8, 1 (2020), cnaa002.Google ScholarCross Ref"",""Robert Kleinberg. 2007. Geographic routing using hyperbolic space. In 26th IEEE International Conference on Computer Communications. IEEE, 1902--1909.Google ScholarDigital Library"",""Dmitri Krioukov, Fragkiskos Papadopoulos, Maksim Kitsak, Amin Vahdat, and Marián Boguná. 2010. Hyperbolic geometry of complex networks. Physical Review E, Vol. 82, 3 (2010), 036106.Google ScholarCross Ref"",""Joseph B Kruskal and Myron Wish. 1978. Multidimensional scaling. Number 11. Sage.Google Scholar"",""John Lamping and Ramana Rao. 1994. Laying out and visualizing large trees using a hyperbolic space. In Proceedings of the 7th annual ACM symposium on User interface software and technology. ACM, 13--14.Google ScholarDigital Library"",""Matt Le, Stephen Roller, Laetitia Papaxanthos, Douwe Kiela, and Maximilian Nickel. 2019. Inferring concept hierarchies from text corpora via hyperbolic embeddings. arXiv preprint arXiv:1902.00913 (2019).Google Scholar"",""Leo Liberti, Carlile Lavor, Nelson Maculan, and Antonio Mucherino. 2014. Euclidean distance geometry and applications. SIAM Rev., Vol. 56, 1 (2014), 3--69.Google ScholarDigital Library"",""Nathan Linial, Eran London, and Yuri Rabinovich. 1995. The geometry of graphs and some of its algorithmic applications. Combinatorica, Vol. 15, 2 (1995), 215--245.Google ScholarCross Ref"",""Ke Ma, Qianqian Xu, and Xiaochun Cao. 2019. Robust ordinal embedding from contaminated relative comparisons. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 7908--7915.Google ScholarCross Ref"",""Anirudha Majumdar, Georgina Hall, and Amir Ali Ahmadi. 2019. Recent scalability improvements for semidefinite programming with applications in machine Learning, control, and robotics. Annual Review of Control, Robotics, and Autonomous Systems, Vol. 3 (2019).Google Scholar"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems. 3111--3119.Google Scholar"",""George A Miller. 1998. WordNet: An electronic lexical database .MIT press.Google Scholar"",""Bamdev Mishra, Gilles Meyer, Francis Bach, and Rodolphe Sepulchre. 2013. Low-rank optimization with trace norm penalty. SIAM Journal on Optimization, Vol. 23, 4 (2013), 2124--2149.Google ScholarCross Ref"",""John W Moon et al. 1968. On the maximum degree in a random tree. The Michigan Mathematical Journal, Vol. 15, 4 (1968), 429--432.Google ScholarCross Ref"",""Maximillian Nickel and Douwe Kiela. 2017. Poincaré embeddings for learning hierarchical representations. In Advances in neural information processing systems. 6338--6347.Google Scholar"",""Maximilian Nickel and Douwe Kiela. 2018. Learning continuous hierarchies in the lorentz model of hyperbolic geometry. arXiv preprint arXiv:1806.03417 (2018).Google Scholar"",""Carl Olsson, Anders Eriksson, and Richard Hartley. 2010. Outlier removal using duality. In 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. IEEE, 1450--1457.Google ScholarCross Ref"",""Jeffrey Pennington, Richard Socher, and Christopher Manning. 2014. Glove: Global vectors for word representation. In Proceedings of the 2014 conference on Empirical Methods in Natural Language Processing (EMNLP). 1532--1543.Google ScholarCross Ref"",""Stephen Roller, Douwe Kiela, and Maximilian Nickel. 2018. Hearst patterns revisited: Automatic hypernym detection from large text corpora. arXiv preprint arXiv:1806.03191 (2018).Google Scholar"",""Rik Sarkar. 2011. Low distortion delaunay embedding of trees in hyperbolic plane. In International Symposium on Graph Drawing. Springer, 355--366.Google Scholar"",""Yongduek Seo, Hyunjung Lee, and Sang Wook Lee. 2009. Outlier removal by convex optimization for l-infinity approaches. In Pacific-Rim Symposium on Image and Video Technology. Springer, 203--214.Google ScholarDigital Library"",""Yuval Shavitt and Tomer Tankel. 2008. Hyperbolic embedding of internet graph for distance estimation and overlay construction. IEEE/ACM Transactions on Networking, Vol. 16, 1 (2008), 25--36.Google ScholarDigital Library"",""Puoya Tabaghi, Ivan Dokmani?, and Martin Vetterli. 2019. Kinetic Euclidean distance matrices. IEEE Transactions on Signal Processing, Vol. 68 (2019), 452--465.Google ScholarDigital Library"",""Omer Tamuz, Ce Liu, Serge Belongie, Ohad Shamir, and Adam Tauman Kalai. 2011. Adaptively learning the crowd kernel. arXiv preprint arXiv:1105.1033 (2011).Google Scholar"",""Laurens Van Der Maaten and Kilian Weinberger. 2012. Stochastic triplet embedding. In 2012 IEEE International Workshop on Machine Learning for Signal Processing. IEEE, 1--6.Google ScholarCross Ref"",""Lieven Vandenberghe and Stephen Boyd. 1996. Semidefinite programming. SIAM Rev., Vol. 38, 1 (1996), 49--95.Google ScholarDigital Library"",""Ivan Vendrov, Ryan Kiros, Sanja Fidler, and Raquel Urtasun. 2015. Order-embeddings of images and language. arXiv preprint arXiv:1511.06361 (2015).Google Scholar"",""Kevin Verbeek and Subhash Suri. 2014. Metric embedding, hyperbolic space, and social networks. In Proceedings of the thirtieth annual symposium on Computational Geometry. ACM, 501.Google ScholarDigital Library"",""Tran Dang Quang Vinh, Yi Tay, Shuai Zhang, Gao Cong, and Xiao-Li Li. 2018. Hyperbolic recommender systems. arXiv preprint arXiv:1809.01703 (2018).Google Scholar"",""Richard C Wilson, Edwin R Hancock, El.zbieta Pekalska, and Robert PW Duin. 2014. Spherical and hyperbolic embeddings of data. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 36, 11 (2014), 2255--2269.Google ScholarCross Ref"",""Huan Xu, Constantine Caramanis, and Sujay Sanghavi. 2010. Robust PCA via outlier pursuit. In Advances in Neural Information Processing Systems. 2496--2504.Google Scholar"",""Jin Yu, Anders Eriksson, Tat-Jun Chin, and David Suter. 2014. An adversarial optimization approach to efficient outlier removal. Journal of Mathematical Imaging and Vision, Vol. 48, 3 (2014), 451--466.Google ScholarDigital Library"",""Wenchao Yu, Wei Cheng, Charu C Aggarwal, Kai Zhang, Haifeng Chen, and Wei Wang. 2018. Netwalk: A flexible deep embedding approach for anomaly detection in dynamic networks. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 2672--2681.Google ScholarDigital Library"",""Alp Yurtsever, Joel A Tropp, Olivier Fercoq, Madeleine Udell, and Volkan Cevher. 2019. Scalable semidefinite programming. arXiv preprint arXiv:1912.02949 (2019).Google Scholar"",""Alp Yurtsever, Madeleine Udell, Joel A Tropp, and Volkan Cevher. 2017. Sketchy decisions: Convex low-rank matrix optimization with optimal storage. arXiv preprint arXiv:1702.06838 (2017).Google Scholar"",""Yuansheng Zhou, Brian H Smith, and Tatyana O Sharpee. 2018. Hyperbolic geometry of the olfactory space. Science Advances, Vol. 4, 8 (2018), eaaq1458.Google Scholar""]"
https://doi.org/10.1145/3394486.3403225,RayS: A Ray Searching Method for Hard-label Adversarial Attack,"Deep neural networks are vulnerable to adversarial attacks. Among different attack settings, the most challenging yet the most practical one is the hard-label setting where the attacker only has access to the hard-label output (prediction label) of the target model. Previous attempts are neither effective enough in terms of attack success rate nor efficient enough in terms of query complexity under the widely used $L_\infty$ norm threat model. In this paper, we present the Ray Searching attack (RayS), which greatly improves the hard-label attack effectiveness as well as efficiency. Unlike previous works, we reformulate the continuous problem of finding the closest decision boundary into a discrete problem that does not require any zeroth-order gradient estimation. In the meantime, all unnecessary searches are eliminated via a fast check step. This significantly reduces the number of queries needed for our hard-label attack. Moreover, interestingly, we found that the proposed RayS attack can also be used as a sanity check for possible ""falsely robust"" models. On several recently proposed defenses that claim to achieve the state-of-the-art robust accuracy, our attack method demonstrates that the current white-box/black-box attacks could still give a false sense of security and the robust accuracy drop between the most popular PGD attack and RayS attack could be as large as 28%. We believe that our proposed RayS attack could help identify falsely robust models that beat most white-box/black-box attacks.","[{""name"":""Jinghui Chen"",""id"":""/profile/99659573480""},{""name"":""Quanquan Gu"",""id"":""/profile/81436598990""},{""name"":""Jinghui Chen"",""id"":""/profile/99659573480""},{""name"":""Quanquan Gu"",""id"":""/profile/81436598990""}]","[""Abdullah Al-Dujaili and Una-May O'Reilly. 2020. Sign Bits Are All You Need for Black-Box Attacks. In International Conference on Learning Representations.Google Scholar"",""Maksym Andriushchenko, Francesco Croce, Nicolas Flammarion, and Matthias Hein. 2019. Square Attack: a query-efficient black-box adversarial attack via random search. arXiv preprint arXiv:1912.00049 (2019).Google Scholar"",""Anish Athalye, Nicholas Carlini, and David Wagner. 2018. Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples. In International Conference on Machine Learning.Google Scholar"",""Wieland Brendel, Jonas Rauber, and Matthias Bethge. 2018. Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models. In International Conference on Learning Representations.Google Scholar"",""Nicholas Carlini and David Wagner. 2017. Towards evaluating the robustness of neural networks. In 2017 IEEE Symposium on Security and Privacy (SP). IEEE, 39--57.Google ScholarCross Ref"",""Jianbo Chen, Michael I Jordan, and Martin J Wainwright. 2019. Hopskipjumpattack: A query-efficient decision-based attack. arXiv preprint arXiv:1904.02144, Vol. 3 (2019).Google Scholar"",""Jinghui Chen, Dongruo Zhou, Jinfeng Yi, and Quanquan Gu. 2020. A Frank-Wolfe framework for efficient and effective adversarial attacks. AAAI (2020).Google Scholar"",""Pin-Yu Chen, Huan Zhang, Yash Sharma, Jinfeng Yi, and Cho-Jui Hsieh. 2017. Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models. In Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security. ACM, 15--26.Google ScholarDigital Library"",""Minhao Cheng, Thong Le, Pin-Yu Chen, Huan Zhang, JinFeng Yi, and Cho-Jui Hsieh. 2019. Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach. In International Conference on Learning Representations.Google Scholar"",""Minhao Cheng, Simranjit Singh, Patrick H. Chen, Pin-Yu Chen, Sijia Liu, and Cho-Jui Hsieh. 2020. Sign-OPT: A Query-Efficient Hard-label Adversarial Attack. In International Conference on Learning Representations.Google Scholar"",""Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. Imagenet: A large-scale hierarchical image database. In Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on. Ieee, 248--255.Google ScholarCross Ref"",""Guneet S Dhillon, Kamyar Azizzadenesheli, Zachary C Lipton, Jeremy Bernstein, Jean Kossaifi, Aran Khanna, and Anima Anandkumar. 2018. Stochastic activation pruning for robust adversarial defense. International Conference on Learning Representations (2018).Google Scholar"",""Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2015. Explaining and harnessing adversarial examples. International Conference on Learning Representations (2015).Google Scholar"",""Chuan Guo, Mayank Rana, Moustapha Cisse, and Laurens Van Der Maaten. 2018. Countering adversarial images using input transformations. International Conference on Learning Representations (2018).Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016a. Deep residual learning for image recognition. In CVPR. 770--778.Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016b. Identity mappings in deep residual networks. In European Conference on Computer Vision. Springer, 630--645.Google ScholarCross Ref"",""Geoffrey Hinton, Li Deng, Dong Yu, George Dahl, Abdel-rahman Mohamed, Navdeep Jaitly, Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Brian Kingsbury, et al. 2012. Deep neural networks for acoustic modeling in speech recognition. IEEE Signal processing magazine, Vol. 29 (2012).Google Scholar"",""Weiwei Hu and Ying Tan. 2017. Generating adversarial malware examples for black-box attacks based on GAN. arXiv preprint arXiv:1702.05983 (2017).Google Scholar"",""Andrew Ilyas, Logan Engstrom, Anish Athalye, Jessy Lin, Anish Athalye, Logan Engstrom, Andrew Ilyas, and Kevin Kwok. 2018. Black-box Adversarial Attacks with Limited Queries and Information. In Proceedings of the 35th International Conference on Machine Learning.Google Scholar"",""Andrew Ilyas, Logan Engstrom, and Aleksander Madry. 2019. Prior convictions: Black-box adversarial attacks with bandits and priors. International Conference on Learning Representations (2019).Google Scholar"",""Jungeum Kim and Xiao Wang. 2020. Sensible adversarial learning. https://openreview.net/forum?id=rJlf_RVKwrGoogle Scholar"",""Alex Krizhevsky, Geoffrey Hinton, et al. 2009. Learning multiple layers of features from tiny images. (2009).Google Scholar"",""Alexey Kurakin, Ian Goodfellow, and Samy Bengio. 2016. Adversarial examples in the physical world. arXiv preprint arXiv:1607.02533 (2016).Google Scholar"",""Yann LeCun, Corinna Cortes, and CJ Burges. 2010. MNIST handwritten digit database. (2010).Google Scholar"",""Yandong Li, Lijun Li, Liqiang Wang, Tong Zhang, and Boqing Gong. 2019. NATTACK: Learning the Distributions of Adversarial Examples for an Improved Black-Box Attack on Deep Neural Networks. In International Conference on Machine Learning. 3866--3876.Google Scholar"",""Xingjun Ma, Bo Li, Yisen Wang, Sarah M Erfani, Sudanthi Wijewickrema, Grant Schoenebeck, Dawn Song, Michael E Houle, and James Bailey. 2018. Characterizing adversarial subspaces using local intrinsic dimensionality. International Conference on Learning Representations (2018).Google Scholar"",""Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. 2018. Towards deep learning models resistant to adversarial attacks. International Conference on Learning Representations (2018).Google Scholar"",""Seungyong Moon, Gaon An, and Hyun Oh Song. 2019. Parsimonious Black-Box Adversarial Attacks via Efficient Combinatorial Optimization. In International Conference on Machine Learning. 4636--4645.Google Scholar"",""Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard. 2016. Deepfool: a simple and accurate method to fool deep neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2574--2582.Google ScholarCross Ref"",""Nicolas Papernot, Patrick McDaniel, and Ian Goodfellow. 2016a. Transferability in machine learning: from phenomena to black-box attacks using adversarial samples. arXiv preprint arXiv:1605.07277 (2016).Google Scholar"",""Nicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z Berkay Celik, and Ananthram Swami. 2017. Practical black-box attacks against machine learning. In Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security. ACM, 506--519.Google ScholarDigital Library"",""Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z Berkay Celik, and Ananthram Swami. 2016b. The limitations of deep learning in adversarial settings. In Security and Privacy (EuroS\u0026P), 2016 IEEE European Symposium on. IEEE, 372--387.Google Scholar"",""Nicolas Papernot, Patrick McDaniel, Xi Wu, Somesh Jha, and Ananthram Swami. 2016c. Distillation as a defense to adversarial perturbations against deep neural networks. In 2016 IEEE Symposium on Security and Privacy (SP). IEEE, 582--597.Google ScholarCross Ref"",""Pouya Samangouei, Maya Kabkab, and Rama Chellappa. 2018. Defense-gan: Protecting classifiers against adversarial attacks using generative models. International Conference on Learning Representations (2018).Google Scholar"",""Yang Song, Taesup Kim, Sebastian Nowozin, Stefano Ermon, and Nate Kushman. 2018. Pixeldefend: Leveraging generative models to understand and defend against adversarial examples. International Conference on Learning Representations (2018).Google Scholar"",""Ilya Sutskever, Geoffrey E Hinton, and A Krizhevsky. 2012. Imagenet classification with deep convolutional neural networks. Advances in neural information processing systems (2012), 1097--1105.Google Scholar"",""Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. 2016. Rethinking the inception architecture for computer vision. In Proceedings of the IEEE conference on computer vision and pattern recognition. 2818--2826.Google ScholarCross Ref"",""Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. 2013. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199 (2013).Google Scholar"",""Jonathan Uesato, Brendan O'Donoghue, Pushmeet Kohli, and Aaron Oord. 2018. Adversarial Risk and the Dangers of Evaluating Against Weak Attacks. In International Conference on Machine Learning. 5025--5034.Google Scholar"",""Yisen Wang, Xingjun Ma, James Bailey, Jinfeng Yi, Bowen Zhou, and Quanquan Gu. 2019. On the Convergence and Robustness of Adversarial Training. In International Conference on Machine Learning. 6586--6595.Google Scholar"",""Yisen Wang, Difan Zou, Jinfeng Yi, James Bailey, Xingjun Ma, and Quanquan Gu. 2020. Improving Adversarial Robustness Requires Revisiting Misclassified Examples. In International Conference on Learning Representations.Google Scholar"",""Cihang Xie, Jianyu Wang, Zhishuai Zhang, Zhou Ren, and Alan Yuille. 2018. Mitigating adversarial effects through randomization. International Conference on Learning Representations (2018).Google Scholar"",""Sergey Zagoruyko and Nikos Komodakis. 2016. Wide residual networks. arXiv preprint arXiv:1605.07146 (2016).Google Scholar"",""Haichao Zhang and Jianyu Wang. 2019. Defense against adversarial attacks using feature scattering-based adversarial training. In Advances in Neural Information Processing Systems. 1829--1839.Google Scholar"",""Haichao Zhang and Wei Xu. 2020. Adversarial Interpolation Training: A Simple Approach for Improving Model Robustness. https://openreview.net/forum?id=Syejj0NYvrGoogle Scholar"",""Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El Ghaoui, and Michael Jordan. 2019. Theoretically Principled Trade-off between Robustness and Accuracy. In International Conference on Machine Learning. 7472--7482.Google Scholar""]"
https://doi.org/10.1145/3394486.3403226,On Sampled Metrics for Item Recommendation,"The task of item recommendation requires ranking a large catalogue of items given a context. Item recommendation algorithms are evaluated using ranking metrics that depend on the positions of relevant items. To speed up the computation of metrics, recent work often uses sampled metrics where only a smaller set of random items and the relevant items are ranked. This paper investigates sampled metrics in more detail and shows that they are inconsistent with their exact version, in the sense that they do not persist relative statements, e.g., recommender A is better than B, not even in expectation. Moreover, the smaller the sampling size, the less difference there is between metrics, and for very small sampling size, all metrics collapse to the AUC metric. We show that it is possible to improve the quality of the sampled metrics by applying a correction, obtained by minimizing different criteria such as bias or mean squared error. We conclude with an empirical evaluation of the naive sampled metrics and their corrected variants. To summarize, our work suggests that sampling should be avoided for metric calculation, however if an experimental study needs to sample, the proposed corrections can improve the quality of the estimate.","[{""name"":""Walid Krichene"",""id"":""/profile/99658757507""},{""name"":""Steffen Rendle"",""id"":""/profile/81321497327""},{""name"":""Walid Krichene"",""id"":""/profile/99658757507""},{""name"":""Steffen Rendle"",""id"":""/profile/81321497327""}]","[""Fabio Aiolli. 2013. Efficient Top-n Recommendation for Very Large Scale Binary Rated Datasets. In Proceedings of the 7th ACM Conference on Recommender Systems (Hong Kong, China) (RecSys '13). Association for Computing Machinery, New York, NY, USA, 273--280. https://doi.org/10.1145/2507157.2507189Google ScholarDigital Library"",""R.E. Barlow, D.J. Bartholomew, J. M. Bremner, and Brunk H. D. 1972. Statistical Inference Under Order Restrictions: The Theory and Application of Isotonic Regression .J. Wiley.Google Scholar"",""Immanuel Bayer, Xiangnan He, Bhargav Kanagal, and Steffen Rendle. 2017. A Generic Coordinate Descent Framework for Learning from Implicit Feedback. In Proceedings of the 26th International Conference on World Wide Web (Perth, Australia) (WWW '17). 1341--1350. https://doi.org/10.1145/3038912.3052694Google ScholarDigital Library"",""Yoshua Bengio and Jean-Sé bastien Senecal. 2003. Quick Training of Probabilistic Neural Nets by Importance Sampling. In Proceedings of the Ninth International Workshop on Artificial Intelligence and Statistics, AISTATS 2003, Key West, Florida, USA, January 3--6, 2003.Google Scholar"",""Yoshua Bengio and Jean-Sé bastien Senecal. 2008. Adaptive Importance Sampling to Accelerate Training of a Neural Probabilistic Language Model. IEEE Trans. Neural Networks, Vol. 19, 4 (2008), 713--722.Google ScholarDigital Library"",""Guy Blanc and Steffen Rendle. 2018. Adaptive Sampled Softmax with Kernel Based Sampling. In Proceedings of the 35th International Conference on Machine Learning (Proceedings of Machine Learning Research, Vol. 80), Jennifer Dy and Andreas Krause (Eds.). PMLR, Stockholmsmässan, Stockholm Sweden, 590--599.Google Scholar"",""Travis Ebesu, Bin Shen, and Yi Fang. 2018. Collaborative Memory Network for Recommendation Systems. In The 41st International ACM SIGIR Conference on Research \u0026 Development in Information Retrieval (Ann Arbor, MI, USA) (SIGIR '18). ACM, New York, NY, USA, 515--524. https://doi.org/10.1145/3209978.3209991Google Scholar"",""F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Trans. Interact. Intell. Syst., Vol. 5, 4, Article 19 (Dec. 2015), 19 pages. https://doi.org/10.1145/2827872Google Scholar"",""Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural Collaborative Filtering. In Proceedings of the 26th International Conference on World Wide Web (Perth, Australia) (WWW '17). International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, Switzerland, 173--182. https://doi.org/10.1145/3038912.3052569Google Scholar"",""Binbin Hu, Chuan Shi, Wayne Xin Zhao, and Philip S. Yu. 2018. Leveraging Meta-path Based Context for Top- N Recommendation with A Neural Co-Attention Model. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining (London, United Kingdom) (KDD '18). ACM, New York, NY, USA, 1531--1540. https://doi.org/10.1145/3219819.3219965Google Scholar"",""Yifan Hu, Yehuda Koren, and Chris Volinsky. 2008. Collaborative Filtering for Implicit Feedback Datasets. In Proceedings of the 2008 Eighth IEEE International Conference on Data Mining (ICDM '08). 263--272.Google ScholarDigital Library"",""Walid Krichene, Nicolas Mayoraz, Steffen Rendle, Li Zhang, Xinyang Yi, Lichan Hong, Ed Chi, and John Anderson. 2019. Efficient Training on Very Large Corpora via Gramian Estimation. In International Conference on Learning Representations.Google Scholar"",""Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient Estimation of Word Representations in Vector Space. CoRR, Vol. abs/1301.3781 (2013).Google Scholar"",""Badrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. 2001. Item-Based Collaborative Filtering Recommendation Algorithms. In Proceedings of the 10th International Conference on World Wide Web (Hong Kong, Hong Kong) (WWW '01). Association for Computing Machinery, New York, NY, USA, 285--295. https://doi.org/10.1145/371920.372071Google ScholarDigital Library"",""Xiang Wang, Dingxian Wang, Canran Xu, Xiangnan He, Yixin Cao, and Tat-Seng Chua. 2019. Explainable Reasoning over Knowledge Graphs for Recommendation. In Proceedings of the 33rd AAAI Conference on Artificial Intelligence (AAAI) (AAAI '19). 5329--5336.Google ScholarCross Ref"",""Longqi Yang, Eugene Bagdasaryan, Joshua Gruenstein, Cheng-Kang Hsieh, and Deborah Estrin. 2018a. OpenRec: A Modular Framework for Extensible and Adaptable Recommendation Algorithms. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining (Marina Del Rey, CA, USA) (WSDM '18). ACM, New York, NY, USA, 664--672. https://doi.org/10.1145/3159652.3159681Google ScholarDigital Library"",""Longqi Yang, Yin Cui, Yuan Xuan, Chenyang Wang, Serge Belongie, and Deborah Estrin. 2018b. Unbiased Offline Recommender Evaluation for Missing-not-at-random Implicit Feedback. In Proceedings of the 12th ACM Conference on Recommender Systems (Vancouver, British Columbia, Canada) (RecSys '18). ACM, New York, NY, USA, 279--287. https://doi.org/10.1145/3240323.3240355Google ScholarDigital Library"",""Hsiang-Fu Yu, Mikhail Bilenko, and Chih-Jen Lin. 2017. Selection of Negative Samples for One-class Matrix Factorization. In Proceedings of the 2017 SIAM International Conference on Data Mining. 363--371.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403227,ALO-NMF: Accelerated Locality-Optimized Non-negative Matrix Factorization,"Non-negative Matrix Factorization (NMF) is a key kernel for unsupervised dimension reduction used in a wide range of applications, including graph mining, recommender systems and natural language processing. Due to the compute-intensive nature of applications that must perform repeated NMF, several parallel implementations have been developed. However, existing parallel NMF algorithms have not addressed data locality optimizations, which are critical for high performance since data movement costs greatly exceed the cost of arithmetic/logic operations on current computer systems. In this paper, we present a novel optimization method for parallel NMF algorithm based on the HALS (Hierarchical Alternating Least Squares) scheme that incorporates algorithmic transformations to enhance data locality. Efficient realizations of the algorithm on multi-core CPUs and GPUs are developed, demonstrating a new Accelerated Locality-Optimized NMF (ALO-NMF) that obtains up to 2.29x lower data movement cost and up to 4.45x speedup over existing state-of-the-art parallel NMF algorithms.","[{""name"":""Gordon E. Moon"",""id"":""/profile/99659573673""},{""name"":""J. Austin Ellis"",""id"":""/profile/99659574080""},{""name"":""Aravind Sukumaran-Rajam"",""id"":""/profile/83058721557""},{""name"":""Srinivasan Parthasarathy"",""id"":""/profile/81100375834""},{""name"":""P. Sadayappan"",""id"":""/profile/81453642049""},{""name"":""Gordon E. Moon"",""id"":""/profile/99659573673""},{""name"":""J. Austin Ellis"",""id"":""/profile/99659574080""},{""name"":""Aravind Sukumaran-Rajam"",""id"":""/profile/83058721557""},{""name"":""Srinivasan Parthasarathy"",""id"":""/profile/81100375834""},{""name"":""P. Sadayappan"",""id"":""/profile/81453642049""}]","[""Mehdi Hosseinzadeh Aghdam, Morteza Analoui, and Peyman Kabiri. 2015. A Novel Non-negative Matrix Factorization Method for Recommender Systems. Applied Mathematics \u0026 Information Sciences, Vol. 9, 5 (2015), 2721.Google Scholar"",""Eric Battenberg and David Wessel. 2009. Accelerating Non-Negative Matrix Factorization for Audio Source Separation on Multi-Core and Many-Core Architectures.. In ISMIR. 501--506.Google Scholar"",""Andrzej Cichocki and Anh-Huy Phan. 2009. Fast Local Algorithms for Large Scale Nonnegative Matrix and Tensor Factorizations. IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences, Vol. 92, 3 (2009), 708--721.Google ScholarCross Ref"",""Andrzej Cichocki, Rafal Zdunek, and Shun-ichi Amari. 2007. Hierarchical ALS Algorithms for Nonnegative Matrix and 3D Tensor Factorization. In International Conference on Independent Component Analysis and Signal Separation. Springer, 169--176.Google ScholarDigital Library"",""Chao Dong, Huijie Zhao, and Wei Wang. 2010. Parallel Nonnegative Matrix Factorization Algorithm on the Distributed Memory Platform. International Journal of Parallel Programming, Vol. 38, 2 (2010), 117--137.Google ScholarCross Ref"",""H. Carter Edwards, Christian R. Trott, and Daniel Sunderland. 2014. Kokkos: Enabling manycore performance portability through polymorphic memory access patterns. J. Parallel and Distrib. Comput., Vol. 74, 12 (2014), 3202 -- 3216. https://doi.org/10.1016/j.jpdc.2014.07.003 Domain-Specific Languages and High-Level Frameworks for High-Performance Computing.Google ScholarDigital Library"",""James P Fairbanks, Ramakrishnan Kannan, Haesun Park, and David A Bader. 2015. Behavioral Clusters in Dynamic Graphs. Parallel Comput., Vol. 47 (2015), 38--50.Google ScholarDigital Library"",""Nicolas Gillis. 2014. The Why and How of Nonnegative Matrix Factorization. Regularization, Optimization, Kernels, and Support Vector Machines, Vol. 12, 257 (2014).Google Scholar"",""Edward F Gonzalez and Yin Zhang. 2005. Accelerating the Lee-Seung Algorithm for Nonnegative Matrix Factorization. Technical Report.Google Scholar"",""Saket Gurukar, Priyesh Vijayan, Aakash Srinivasan, Goonmeet Bajaj, Chen Cai, Moniba Keymanesh, Saravana Kumar, Pranav Maneriker, Anasua Mitra, Vedang Patel, Balaraman Ravindran, and Srinivasan Parthasarathy. 2019. Network Representation Learning: Consolidation and renewed bearing. arXiv preprint arXiv:1905.00987 (2019).Google Scholar"",""Antonio Hernando, Jesús Bobadilla, and Fernando Ortega. 2016. A Non Negative Matrix Factorization for Collaborative Filtering Recommender Systems based on a Bayesian Probabilistic Model. Knowledge-Based Systems, Vol. 97 (2016), 188--202.Google ScholarDigital Library"",""Ramakrishnan Kannan, Grey Ballard, and Haesun Park. 2016. A High-Performance Parallel Algorithm for Nonnegative Matrix Factorization. ACM SIGPLAN Notices, Vol. 51, 8 (2016), 1--11.Google ScholarDigital Library"",""Hyunsoo Kim and Haesun Park. 2008. Nonnegative Matrix Factorization based on Alternating Nonnegativity Constrained Least Squares and Active Set Method. SIAM J. Matrix Anal. Appl., Vol. 30, 2 (2008), 713--730.Google ScholarDigital Library"",""Jingu Kim and Haesun Park. 2011. Fast Nonnegative Matrix Factorization: An active-set-like method and comparisons. SIAM Journal on Scientific Computing, Vol. 33, 6 (2011), 3261--3281.Google ScholarDigital Library"",""Sven Koitka and Christoph M Friedrich. 2016. nmfgpu4R: GPU-accelerated computation of the non-negative matrix factorization (NMF) using CUDA capable hardware. The R Journal, Vol. 8, 2 (2016), 382--392.Google ScholarCross Ref"",""Daniel D Lee and H Sebastian Seung. 2001. Algorithms for Non-negative Matrix Factorization. In Advances in Neural Information Processing Systems. 556--562.Google Scholar"",""Ruiqi Liao, Yifan Zhang, Jihong Guan, and Shuigeng Zhou. 2014. CloudNMF: A MapReduce implementation of nonnegative matrix factorization for large-scale biological datasets. Genomics, Proteomics \u0026 Bioinformatics, Vol. 12, 1 (2014), 48--51.Google ScholarCross Ref"",""Chih-Jen Lin. 2007. Projected Gradient Methods for Nonnegative Matrix Factorization. Neural Computation, Vol. 19, 10 (2007), 2756--2779.Google ScholarDigital Library"",""Chao Liu, Hung-chih Yang, Jinliang Fan, Li-Wei He, and Yi-Min Wang. 2010. Distributed Nonnegative Matrix Factorization for Web-Scale Dyadic Data Analysis on MapReduce. In Proceedings of the 19th International Conference on World Wide Web. ACM, 681--690.Google ScholarDigital Library"",""Noel Lopes and Bernardete Ribeiro. 2010. Non-negative Matrix Factorization Implementation using Graphic Processing Units. In International Conference on Intelligent Data Engineering and Automated Learning. Springer, 275--283.Google ScholarCross Ref"",""Edgardo Mej'ia-Roa, Daniel Tabas-Madrid, Javier Setoain, Carlos Garc'ia, Francisco Tirado, and Alberto Pascual-Montano. 2015. NMF-mGPU: Non-negative matrix factorization on multi-GPU systems. BMC Bioinformatics, Vol. 16, 1 (2015), 43.Google ScholarCross Ref"",""Anasua Mitra, Priyesh Vijayan, Srinivasan Parthasarathy, and Balaraman Ravindran. 2020. A Unified Non-Negative Matrix Factorization Framework for Semi Supervised Learning on Graphs. In Proceedings of the 2020 SIAM International Conference on Data Mining, SDM 2020, Carlotta Demeniconi and Nitesh V. Chawla (Eds.). 487--495.Google ScholarCross Ref"",""Jiezhong Qiu, Yuxiao Dong, Hao Ma, Jian Li, Kuansan Wang, and Jie Tang. 2018. Network Embedding as Matrix Factorization: Unifying deepwalk, line, pte, and node2vec. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. 459--467.Google ScholarDigital Library"",""Stefan A Robila and Lukasz G Maciak. 2006. A Parallel Unmixing Algorithm for Hyperspectral Images. In Intelligent Robots and Computer Vision XXIV: Algorithms, Techniques, and Active Vision, Vol. 6384. International Society for Optics and Photonics, 63840F.Google Scholar"",""Tian Shi, Kyeongpil Kang, Jaegul Choo, and Chandan K Reddy. 2018. Short-Text Topic Modeling via Non-negative Matrix Factorization Enriched with Local Word-Context Correlations. In Proceedings of the 2018 World Wide Web Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 1105--1114.Google ScholarDigital Library"",""Tyler Michael Smith et al. 2018. Theory and Practice of Classical Matrix-Matrix Multiplication for Hierarchical Memory Architectures. Ph.D. Dissertation.Google Scholar"",""Sangho Suh, Jaegul Choo, Joonseok Lee, and Chandan K Reddy. 2017. Local Topic Discovery via Boosted Ensemble of Nonnegative Matrix Factorization. In Proceedings of the 26th International Joint Conference on Artificial Intelligence. AAAI Press, 4944--4948.Google ScholarCross Ref"",""Xiao Wang, Peng Cui, Jing Wang, Jian Pei, Wenwu Zhu, and Shiqiang Yang. 2017. Community Preserving Network Embedding. In Thirty-first AAAI Conference on Artificial Intelligence.Google Scholar""]"
https://doi.org/10.1145/3394486.3403228,Multi-Source Deep Domain Adaptation with Weak Supervision for Time-Series Sensor Data,"Domain adaptation (DA) offers a valuable means to reuse data and models for new problem domains. However, robust techniques have not yet been considered for time series data with varying amounts of data availability. In this paper, we make three main contributions to fill this gap. First, we propose a novel Convolutional deep Domain Adaptation model for Time Series data (CoDATS) that significantly improves accuracy and training time over state-of-the-art DA strategies on real-world sensor data benchmarks. By utilizing data from multiple source domains, we increase the usefulness of CoDATS to further improve accuracy over prior single-source methods, particularly on complex time series datasets that have high variability between domains. Second, we propose a novel Domain Adaptation with Weak Supervision (DA-WS) method by utilizing weak supervision in the form of target-domain label distributions, which may be easier to collect than additional data labels. Third, we perform comprehensive experiments on diverse real-world datasets to evaluate the effectiveness of our domain adaptation and weak supervision methods. Results show that CoDATS for single-source DA significantly improves over the state-of-the-art methods, and we achieve additional improvements in accuracy using data from multiple source domains and weakly supervised signals.","[{""name"":""Garrett Wilson"",""id"":""/profile/99659487748""},{""name"":""Janardhan Rao Doppa"",""id"":""/profile/81470652738""},{""name"":""Diane J. Cook"",""id"":""/profile/81100111814""},{""name"":""Garrett Wilson"",""id"":""/profile/99659487748""},{""name"":""Janardhan Rao Doppa"",""id"":""/profile/81470652738""},{""name"":""Diane J. Cook"",""id"":""/profile/81100111814""}]","[""D. Anguita, A. Ghio, L. Oneto, X. Parra, and J. L. Reyes-Ortiz. 2013. A public domain dataset for human activity recognition using smartphones. In ESANN.Google Scholar"",""S. Bai, J. Z. Kolter, et al. 2018. An empirical evaluation of generic convolutional and recurrent networks for sequence modeling. arXiv:1803.01271(2018).Google Scholar"",""S. Ben-David et al.2010. A theory of learning from different domains. Machine Learning 79, 1 (2010), 151--175.Google ScholarDigital Library"",""K. Bousmalis et al. 2017. Unsupervised Pixel-Level Domain Adaptation With Generative Adversarial Networks. In CVPR.Google Scholar"",""C. Chen, Y. Miao, C. X. Lu, and Xie. 2019. Motion Transformer: Transferring Neural Inertial Tracking between Domains. In AAAI. 8009--8016.Google Scholar"",""H. I. Fawaz, G. Forestier, J. Weber, L. Idoumghar, and P. Muller. 2018. Transfer learning for time series classification. In IEEE Big Data. 1367--1376.Google Scholar"",""H. I. Fawaz, G. Forestier, J. Weber, L. Idoumghar, and P. Muller. 2019. Deep learning for time series classification: a review. DMKD 33, 4 (2019), 917--963.Google ScholarDigital Library"",""H. I. Fawaz, B. Lucas, G. Forestier, C. Pelletier, et al.2019. Inception Time: Finding AlexNet for Time Series Classification. arXiv:1909.04939(2019).Google Scholar"",""G. French et al. 2018. Self-ensembling for visual domain adaptation. In ICLR.Google Scholar"",""J. Froehlich et al.2007. MyExperience: A System for in Situ Tracing and Capturing of User Feedback on Mobile Phones. In MobiSys. 57--70.Google Scholar"",""K. Ganchev, J. Gillenwater, B. Taskar, et al.2010. Posterior regularization for structured latent variable models. JMLR 11, Jul (2010), 2001--2049.Google ScholarDigital Library"",""Y. Ganin et al.2016. Domain-Adversarial Training of Neural Networks. JMLR 17, 59 (2016), 1--35.Google ScholarDigital Library"",""K. Greff et al. 2017. LSTM: A Search Space Odyssey.IEEE Tr. Neur. Net. Learn. Sys. 28, 10 (2017), 2222--2232.Google ScholarCross Ref"",""J. Hoffman et al.2018. CyCADA: Cycle-Consistent Adversarial Domain Adaptation. In ICML, Vol. 80. 1994--2003.Google Scholar"",""S. Hong, J. Oh, H. Lee, and B. Han. 2016. Learning Transferrable Knowledge for Semantic Segmentation With Deep Convolutional Neural Network. In CVPR.Google Scholar"",""W. Hong, Z. Wang, M. Yang, and J. Yuan. 2018. Conditional Generative Adversarial Network for Structured Domain Adaptation. In CVPR.Google Scholar"",""E. Hosseini-Asl, Y. Zhou, C. Xiong, and R. Socher. 2019. Augmented Cyclic Adversarial Learning for Low Resource Domain Adaptation. In ICLR.Google Scholar"",""N. Hu, G. Englebienne, Z. Lou, et al.2017. Learning to Recognize Human Activities Using Soft Labels.IEEE Trans. Pat. Anal. Mach. Intell. 39, 10 (2017), 1973--1984.Google ScholarCross Ref"",""F. Huang and A. Yates. 2012. Biased Representation Learning for Domain Adaptation. In EMNLP-CoNLL. 1313--1323.Google Scholar"",""W. Jiang, C. Miao, F. Ma, S. Yao, Y. Wang, Y. Yuan, et al.2018. Towards environment independent device free human activity recognition. In MobiCom. 289--304.Google Scholar"",""R. Jozefowicz, W. Zaremba, and I. Sutskever. 2015. An empirical exploration of recurrent network architectures. In ICML. 2342--2350.Google Scholar"",""G. Kang, L. Jiang, Y. Yang, and A. G. Hauptmann. 2019. Contrastive Adaptation Network for Unsupervised Domain Adaptation. arXiv:1901.00976(2019).Google Scholar"",""A. Kumar et al.2018. Co-regularized Alignment for Unsupervised Domain Adaptation. In NeurIPS 31. 9345--9356.Google Scholar"",""J. R. Kwapisz, G. M. Weiss, and S. A. Moore. 2011. Activity Recognition Using Cell Phone Accelerometers. SIGKDD Explor. Newsl.12, 2 (2011), 74--82.Google ScholarDigital Library"",""Y. Li, N. Wang, J. Shi, X. Hou, and J. Liu. 2018. Adaptive Batch Normalization for practical domain adaptation.Pattern Recognition 80 (2018), 109 -- 117.Google Scholar"",""J. Liu, L. Zhong, and J. Wickramasuriya. 2009. uWave: Accelerometer-based personalized gesture recognition and its applications. In PerCom. 657 -- 675.Google Scholar"",""G. Melis, C. Dyer, and P. Blunsom. 2017. On the state of the art of evaluation in neural language models.arXiv:1707.05589(2017).Google Scholar"",""J. Miller and M. Hardt. 2018. Stable recurrent models. arXiv:1805.10369(2018).Google Scholar"",""B. D. Minor, J. R. Doppa, et al.2017. Learning Activity Predictors from Sensor Data:Algorithms, Evaluation, and Applications. IEEE TKDE 29, 12 (2017), 2744--2757.Google Scholar"",""R. Pascanu, T. Mikolov, and Y. Bengio. 2013. On the difficulty of training recurrent neural networks. In ICML. 1310--1318.Google Scholar"",""D. Pathak, P. Krahenbuhl, and T. Darrell. 2015. Constrained Convolutional Neural Networks for Weakly Supervised Segmentation. In ICCV.Google Scholar"",""S. Purushotham, W. Carvalho, T. Nilanon, and Y. Liu. 2017. Variational adversarial deep domain adaptation for health care time series analysis. In ICLR.Google Scholar"",""S. Sankaranarayanan, Y. Balaji, C. D. Castillo, and R. Chellappa. 2018. Generate to Adapt: Aligning Domains Using Generative Adversarial Networks. In CVPR.Google Scholar"",""R. Shu, H. Bui, H. Narui, and S. Ermon. 2018. A DIRT-T Approach to Unsupervised Domain Adaptation. In ICLR.Google Scholar"",""A. Stisen et al.2015. Smart Devices Are Different: Assessing and Mitigating Mobile Sensing Heterogeneities for Activity Recognition. In SenSys. 127--140.Google Scholar"",""S. Sun, H. Shi, and Y. Wu. 2015. A survey of multi-source domain adaptation. Information Fusion24 (2015), 84 -- 92.Google Scholar"",""M. Tonutti, E. Ruffaldi, A. Cattaneo, et al.2019. Robust and subject-independent driving manoeuvre anticipation through Domain-Adversarial Recurrent Neural Networks. Robotics and Autonomous Systems115 (2019), 162 -- 173.Google Scholar"",""V. Vercruyssen, W. Meert, and J. Davis. 2017. Transfer learning for time series anomaly detection. In CEUR Workshop Proceedings, Vol. 1924. 27--37.Google Scholar"",""Z. Wang, W. Yan, and T. Oates. 2017. Time series classification from scratch with deep neural networks: A strong baseline. In IJCNN. 1578--1585.Google Scholar"",""G. Wilson and D. J. Cook. 2019. A Survey of Unsupervised Deep Domain Adaptation. arXiv: 1812.02849(2019).Google Scholar"",""Q. Xie, Z. Dai, Y. Du, E. Hovy, and G. Neubig. 2017. Controllable In variance through Adversarial Feature Learning. In NeurIPS 30. 585--596.Google Scholar"",""H. Zhao, S. Zhang, G. Wu, J. M. F. Moura, J. P. Costeira, and G. J. Gordon. 2018. Adversarial Multiple Source Domain Adaptation. In NeurIPS 31. 8559--8570.Google Scholar"",""M. Zhao et al.2017. Learning Sleep Stages from Radio Signals: A Conditional Adversarial Architecture. In ICML, Vol. 70. 4100--4109.Google Scholar""]"
https://doi.org/10.1145/3394486.3403229,Counterfactual Evaluation of Slate Recommendations with Sequential Reward Interactions,"Users of music streaming, video streaming, news recommendation, and e-commerce services often engage with content in a sequential manner. Providing and evaluating good sequences of recommendations is therefore a central problem for these services. Prior reweighting-based counterfactual evaluation methods either suffer from high variance or make strong independence assumptions about rewards. We propose a new counterfactual estimator that allows for sequential interactions in the rewards with lower variance in an asymptotically unbiased manner. Our method uses graphical assumptions about the causal relationships of the slate to reweight the rewards in the logging policy in a way that approximates the expected sum of rewards under the target policy. Extensive experiments in simulation and on a live recommender system show that our approach outperforms existing methods in terms of bias and data efficiency for the sequential track recommendations problem.","[{""name"":""James McInerney"",""id"":""/profile/81548025298""},{""name"":""Brian Brost"",""id"":""/profile/99659369051""},{""name"":""Praveen Chandar"",""id"":""/profile/81447604033""},{""name"":""Rishabh Mehrotra"",""id"":""/profile/99658716949""},{""name"":""Benjamin Carterette"",""id"":""/profile/81100270582""},{""name"":""James McInerney"",""id"":""/profile/81548025298""},{""name"":""Brian Brost"",""id"":""/profile/99659369051""},{""name"":""Praveen Chandar"",""id"":""/profile/81447604033""},{""name"":""Rishabh Mehrotra"",""id"":""/profile/99658716949""},{""name"":""Benjamin Carterette"",""id"":""/profile/81100270582""}]","[""J. Achiam, D. Held, A. Tamar, and P. Abbeel. Constrained policy optimization. In Proceedings of the ICML, pages 22--31, 2017.Google Scholar"",""A. F. Bibaut, I. Malenica, N. Vlassis, and M. J. van der Laan. More efficient off-policy evaluation through regularized targeted learning. In Proceedings of the ICML, pages 654--663, 2019.Google Scholar"",""P. Chandar and B. Carterette. Estimating clickthrough bias in the cascade model. In Proceedings of CIKM, CIKM '18, pages 1587--1590, 2018.Google ScholarDigital Library"",""M. Chen, A. Beutel, P. Covington, S. Jain, F. Belletti, and E. H. Chi. Top-K off-policy correction for a REINFORCE recommender system. In Proceedings of WSDM, pages 456--464, 2019.Google ScholarDigital Library"",""M. Dud'ik, J. Langford, and L. Li. Doubly robust policy evaluation and learning. In Proceedings of the ICML, pages 1097--1104, 2011.Google Scholar"",""A. Gilotte, C. Calauzènes, T. Nedelec, A. Abraham, and S. Dollé. Offline A/B testing for recommender systems. In Proceedings of WSDM, pages 198--206, 2018.Google ScholarDigital Library"",""C. A. Gomez-Uribe and N. Hunt. The Netflix recommender system: Algorithms, business value, and innovation. ACM Transactions on Management Information Systems (TMIS), 6(4):13, 2016.Google Scholar"",""L. Guo, H. Yin, Q. Wang, T. Chen, A. Zhou, and N. Quoc Viet Hung. Streaming session-based recommendation. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining, KDD '19, pages 1569--1577, New York, NY, USA, 2019. ACM.Google ScholarDigital Library"",""G. W. Imbens and D. B. Rubin. Causal inference in statistics, social, and biomedical sciences. Cambridge University Press, 2015.Google ScholarDigital Library"",""R. Jagerman, I. Markov, and M. de Rijke. When people change their mind: Off-policy evaluation in non-stationary recommendation environments. In Proceedings of WSDM, pages 447--455, 2019.Google ScholarDigital Library"",""L. Kish. Survey sampling. John Wiley and Sons, 1965.Google Scholar"",""R. Kohavi, A. Deng, B. Frasca, T. Walker, Y. Xu, and N. Pohlmann. Online controlled experiments at large scale. In Proceedings of ACM SIGKDD, pages 1168--1176, 2013.Google ScholarDigital Library"",""L. Li, W. Chu, J. Langford, and R. E. Schapire. A contextual-bandit approach to personalized news article recommendation. In Proceedings of WWW, pages 661--670, 2010.Google ScholarDigital Library"",""S. Li, Y. Abbasi-Yadkori, B. Kveton, S. Muthukrishnan, V. Vinay, and Z. Wen. Offline evaluation of ranking policies with click models. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining, pages 1685--1694, 2018.Google ScholarDigital Library"",""D. Liang, L. Charlin, J. McInerney, and D. M. Blei. Modeling user exposure in recommendation. In Proceedings of WWW, pages 951--961, 2016.Google ScholarDigital Library"",""M. Ludewig and D. Jannach. Evaluation of session-based recommendation algorithms. CoRR, abs/1803.09587, 2018.Google Scholar"",""B. M. Marlin and R. S. Zemel. Collaborative prediction and ranking with non-random missing data. In Proceedings of RecSys, RecSys '09, pages 5--12, 2009.Google ScholarDigital Library"",""T. Nedelec, N. L. Roux, and V. Perchet. A comparative study of counterfactual estimators. arXiv preprint arXiv:1704.00773, 2017.Google Scholar"",""J. Pearl. Causality. Cambridge university press, 2009.Google Scholar"",""M. Sanderson. Test collection based evaluation of information retrieval systems. Foundations and Trends in Information Retrieval, 4(4):247--375, 2010.Google ScholarCross Ref"",""T. Schnabel, A. Swaminathan, A. Singh, N. Chandak, and T. Joachims. Recommendations as treatments: Debiasing learning and evaluation. In Proceedings of the ICML, pages 1670--1679, 2016.Google Scholar"",""H. Steck. Evaluation of recommendations: Rating-prediction and ranking. In Proceedings of RecSys'13, pages 213--220, 2013.Google ScholarDigital Library"",""Y. Su, L. Wang, M. Santacatterina, and T. Joachims. CAB: Continuous adaptive blending for policy evaluation and learning. In International Conference on Machine Learning, pages 6005--6014, 2019.Google Scholar"",""A. Swaminathan and T. Joachims. The self-normalized estimator for counterfactual learning. In Advances in Neural Information Processing Systems (NeurIPS), pages 3231--3239, 2015.Google Scholar"",""A. Swaminathan, A. Krishnamurthy, A. Agarwal, M. Dudik, J. Langford, D. Jose, and I. Zitouni. Off-policy evaluation for slate recommendation. In Advances in Neural Information Processing Systems (NeurIPS), pages 3632--3642, 2017.Google Scholar"",""J. Tang and K. Wang. Personalized top-N sequential recommendation via convolutional sequence embedding. In Proceedings of WSDM, WSDM '18, pages 565--573, 2018.Google ScholarDigital Library"",""P. Thomas and E. Brunskill. Data-efficient off-policy policy evaluation for reinforcement learning. In Proceedings of the ICML, pages 2139--2148, 2016.Google Scholar"",""F. Yuan, A. Karatzoglou, I. Arapakis, J. M. Jose, and X. He. A simple convolutional generative network for next item recommendation. In Proceedings of WSDM, WSDM '19, pages 582--590, 2019.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403230,TAdaNet: Task-Adaptive Network for Graph-Enriched Meta-Learning,"Annotated data samples in real-world applications are often limited. Meta-learning, which utilizes prior knowledge learned from related tasks and generalizes to new tasks of limited supervised experience, is an effective approach for few-shot learning. However, standard meta-learning with globally shared knowledge cannot handle the task heterogeneity problem well, i.e., tasks lie in different distributions. Recent advances have explored several ways to trigger task-dependent initial parameters or metrics, in order to customize task-specific information. These approaches learn task contextual information from data, but ignore external domain knowledge that can help in the learning process. In this paper, we propose a task-adaptive network (TAdaNet) that makes use of a domain-knowledge graph to enrich data representations and provide task-specific customization. Specifically, we learn a task embedding that characterizes task relationships and tailors task-specific parameters, resulting in a task-adaptive metric space for classification. Experimental results on a few-shot image classification problem show the effectiveness of the proposed method. We also apply it on a real-world disease classification problem, and show promising results for clinical decision support.","[{""name"":""Qiuling Suo"",""id"":""/profile/99659574394""},{""name"":""Jingyuan Chou"",""id"":""/profile/99659573862""},{""name"":""Weida Zhong"",""id"":""/profile/99659574373""},{""name"":""Aidong Zhang"",""id"":""/profile/99659573207""},{""name"":""Qiuling Suo"",""id"":""/profile/99659574394""},{""name"":""Jingyuan Chou"",""id"":""/profile/99659573862""},{""name"":""Weida Zhong"",""id"":""/profile/99659574373""},{""name"":""Aidong Zhang"",""id"":""/profile/99659573207""}]","[""Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W Hoffman, David Pfau, Tom Schaul, Brendan Shillingford, and Nando De Freitas. 2016. Learning to learn by gradient descent by gradient descent. In Advances in neural information processing systems. 3981--3989.Google Scholar"",""Wei-Yu Chen, Yen-Cheng Liu, Zsolt Kira, Yu-Chiang Frank Wang, and Jia-Bin Huang. 2019. A Closer Look at Few-shot Classification. In ICLR.Google Scholar"",""Yu Cheng, Fei Wang, Ping Zhang, and Jianying Hu. 2016. Risk prediction with electronic health records: A deep learning approach. In Proceedings of the 2016 SIAM International Conference on Data Mining. SIAM, 432--440.Google ScholarCross Ref"",""Edward Choi, Mohammad Taha Bahadori, Le Song, Walter F Stewart, and Jimeng Sun. 2017. GRAM: graph-based attention model for healthcare representation learning. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 787--795.Google ScholarDigital Library"",""Zhengxiao Du, Xiaowei Wang, Hongxia Yang, Jingren Zhou, and Jie Tang. 2019. Sequential Scenario-Specific Meta Learner for Online Recommendation. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 2895--2904.Google ScholarDigital Library"",""Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017. Model-agnostic meta-learning for fast adaptation of deep networks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 1126--1135.Google ScholarDigital Library"",""Victor Garcia and Joan Bruna. 2018. Few-shot learning with graph neural networks. In ICLR.Google Scholar"",""Erin Grant, Chelsea Finn, Sergey Levine, Trevor Darrell, and Thomas Griffiths. 2018. Recasting gradient-based meta-learning as hierarchical bayes. arXiv preprint arXiv:1801.08930 (2018).Google Scholar"",""Jiatao Gu, Yong Wang, Yun Chen, Kyunghyun Cho, and Victor OK Li. 2018. Meta-learning for low-resource neural machine translation. In EMNLP.Google Scholar"",""Hrayr Harutyunyan, Hrant Khachatrian, David C Kale, Greg Ver Steeg, and Aram Galstyan. 2017. Multitask learning and benchmarking with clinical time series data. arXiv preprint arXiv:1703.07771 (2017).Google Scholar"",""Bingyi Kang, Zhuang Liu, Xin Wang, Fisher Yu, Jiashi Feng, and Trevor Darrell. 2019. Few-shot object detection via feature reweighting. In Proceedings of the IEEE International Conference on Computer Vision. 8420--8429.Google ScholarCross Ref"",""Hoyeop Lee, Jinbae Im, Seongwon Jang, Hyunsouk Cho, and Sehee Chung. 2019. MeLU: Meta-Learned User Preference Estimator for Cold-Start Recommendation. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1073--1082.Google ScholarDigital Library"",""Yoonho Lee and Seungjin Choi. 2018. Gradient-based meta-learning with learned layerwise metric and subspace. In ICML.Google Scholar"",""Huaiyu Li, Weiming Dong, Xing Mei, Chongyang Ma, Feiyue huang, and Baogang Hu. 2019. LGM-Net: Learning to Generate Matching Networks for Few-Shot Learning. In ICML.Google Scholar"",""Zhenguo Li, Fengwei Zhou, Fei Chen, and Hang Li. 2017. Meta-SGD: Learning to learn quickly for few-shot learning. arXiv preprint arXiv:1707.09835 (2017).Google Scholar"",""Lu Liu, Tianyi Zhou, Guodong Long, Jing Jiang, Lina Yao, and Chengqi Zhang. 2019 c. Prototype propagation networks (PPN) for weakly-supervised few-shot learning on category graph. In IJCAI.Google Scholar"",""Lu Liu, Tianyi Zhou, Guodong Long, Jing Jiang, and Chengqi Zhang. 2019 b. Learning to propagate for graph meta-learning. In Advances in Neural Information Processing Systems. 1037--1048.Google Scholar"",""Yanbin Liu, Juho Lee, Minseop Park, Saehoon Kim, Eunho Yang, Sung Ju Hwang, and Yi Yang. 2019 a. Learning to propagate labels: Transductive propagation network for few-shot learning. In ICLR.Google Scholar"",""Fenglong Ma, Jing Gao, Qiuling Suo, Quanzeng You, Jing Zhou, and Aidong Zhang. 2018a. Risk prediction on electronic health records with prior medical knowledge. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1910--1919.Google ScholarDigital Library"",""Fenglong Ma, Quanzeng You, Houping Xiao, Radha Chitta, Jing Zhou, and Jing Gao. 2018b. Kame: Knowledge-based attention model for diagnosis prediction in healthcare. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management. 743--752.Google ScholarDigital Library"",""Laurens van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE. Journal of machine learning research, Vol. 9, Nov (2008), 2579--2605.Google Scholar"",""Nikhil Mishra, Mostafa Rohaninejad, Xi Chen, and Pieter Abbeel. 2018. A simple neural attentive meta-learner. In ICLR.Google Scholar"",""Tsendsuren Munkhdalai, Xingdi Yuan, Soroush Mehri, and Adam Trischler. 2018. Rapid adaptation with conditionally shifted neurons. In ICML.Google Scholar"",""Boris Oreshkin, Pau Rodr'iguez López, and Alexandre Lacoste. 2018. Tadam: Task dependent adaptive metric for improved few-shot learning. In Advances in Neural Information Processing Systems. 721--731.Google Scholar"",""Sachin Ravi and Hugo Larochelle. 2017. Optimization as a model for few-shot learning. In ICLR.Google Scholar"",""Mengye Ren, Eleni Triantafillou, Sachin Ravi, Jake Snell, Kevin Swersky, Joshua B Tenenbaum, Hugo Larochelle, and Richard S Zemel. 2018. Meta-learning for semi-supervised few-shot classification. In ICLR.Google Scholar"",""Andrei A Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals, Razvan Pascanu, Simon Osindero, and Raia Hadsell. 2019. Meta-learning with latent embedding optimization. In ICLR.Google Scholar"",""Jake Snell, Kevin Swersky, and Richard Zemel. 2017. Prototypical networks for few-shot learning. In Advances in Neural Information Processing Systems. 4077--4087.Google Scholar"",""Flood Sung, Yongxin Yang, Li Zhang, Tao Xiang, Philip HS Torr, and Timothy M Hospedales. 2018. Learning to compare: Relation network for few-shot learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 1199--1208.Google ScholarCross Ref"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2018. Graph attention networks. In ICLR.Google Scholar"",""Oriol Vinyals, Charles Blundell, Timothy Lillicrap, and Daan Wierstra. 2016. Matching networks for one shot learning. In Advances in neural information processing systems. 3630--3638.Google Scholar"",""Risto Vuorio, Shao-Hua Sun, Hexiang Hu, and Joseph J Lim. 2019. Multimodal Model-Agnostic Meta-Learning via Task-Aware Modulation. In Advances in Neural Information Processing Systems. 1--12.Google Scholar"",""Duo Wang, Yu Cheng, Mo Yu, Xiaoxiao Guo, and Tao Zhang. 2019. A Hybrid Approach with Optimization and Metric-based Meta-Learner for Few-Shot Learning. NeuroComputing (2019).Google Scholar"",""Lu Wang, Wei Zhang, Xiaofeng He, and Hongyuan Zha. 2018. Supervised reinforcement learning with recurrent neural network for dynamic treatment recommendation. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 2447--2456.Google ScholarDigital Library"",""Huaxiu Yao, Yiding Liu, Ying Wei, Xianfeng Tang, and Zhenhui Li. 2019 a. Learning from multiple cities: A meta-learning approach for spatial-temporal prediction. In The World Wide Web Conference. 2181--2191.Google ScholarDigital Library"",""Huaxiu Yao, Ying Wei, Junzhou Huang, and Zhenhui Li. 2019 b. Hierarchically Structured Meta-learning. In ICML.Google Scholar"",""Huaxiu Yao, Xian Wu, Ruirui Li, Zhiqiang Tao, Yaliang Li, Bolin Ding, and Zhenhui Li. 2020. Automated Relational Meta-learning. In ICLR.Google Scholar"",""Huaxiu Yao, Chuxu Zhang, Ying Wei, Meng Jiang, Suhang Wang, Junzhou Huang, Nitesh V Chawla, and Zhenhui Li. 2019 c. Graph Few-shot Learning via Knowledge Transfer. arXiv preprint arXiv:1910.03053 (2019).Google Scholar"",""Sung Whan Yoon, Jun Seo, and Jaekyun Moon. 2019. TapNet: Neural Network Augmented with Task-Adaptive Projection for Few-Shot Learning. In ICML.Google Scholar"",""Xi Sheryl Zhang, Fengyi Tang, Hiroko H Dodge, Jiayu Zhou, and Fei Wang. 2019. Metapred: Meta-learning for clinical risk prediction with limited patient electronic health records. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 2487--2495.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403231,Unsupervised Paraphrasing via Deep Reinforcement Learning,"Paraphrasing is expressing the meaning of an input sentence in different wording while maintaining fluency (i.e., grammatical and syntactical correctness). Most existing work on paraphrasing use supervised models that are limited to specific domains (e.g., image captions). Such models can neither be straightforwardly transferred to other domains nor generalize well, and creating labeled training data for new domains is expensive and laborious. The need for paraphrasing across different domains and the scarcity of labeled training data in many such domains call for exploring unsupervised paraphrase generation methods. We propose Progressive Unsupervised Paraphrasing (PUP): a novel unsupervised paraphrase generation method based on deep reinforcement learning (DRL). PUP uses a variational autoencoder (trained using a non-parallel corpus) to generate a seed paraphrase that warm-starts the DRL model. Then, PUP progressively tunes the seed paraphrase guided by our novel reward function which combines semantic adequacy, language fluency, and expression diversity measures to quantify the quality of the generated paraphrases in each iteration without needing parallel sentences. Our extensive experimental evaluation shows that PUP outperforms unsupervised state-of-the-art paraphrasing techniques in terms of both automatic metrics and user studies on four real datasets. We also show that PUP outperforms domain-adapted supervised algorithms on several datasets. Our evaluation also shows that PUP achieves a great trade-off between semantic similarity and diversity of expression.","[{""name"":""A. B. Siddique"",""id"":""/profile/99659310607""},{""name"":""Samet Oymak"",""id"":""/profile/99659047341""},{""name"":""Vagelis Hristidis"",""id"":""/profile/81337490216""},{""name"":""A. B. Siddique"",""id"":""/profile/99659310607""},{""name"":""Samet Oymak"",""id"":""/profile/99659047341""},{""name"":""Vagelis Hristidis"",""id"":""/profile/81337490216""}]","[""Satanjeev Banerjee and Alon Lavie. 2005. METEOR: An automatic metric for MT evaluation with improved correlation with human judgments. In Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization. 65--72.Google Scholar"",""Regina Barzilay and Lillian Lee. 2003. Learning to paraphrase: an unsupervised approach using multiple-sequence alignment. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology-Volume 1. Association for Computational Linguistics, 16--23.Google Scholar"",""Yoshua Bengio. 2008. Neural net language models. Scholarpedia, Vol. 3, 1 (2008), 3881.Google ScholarCross Ref"",""Samuel R Bowman, Luke Vilnis, Oriol Vinyals, Andrew M Dai, Rafal Jozefowicz, and Samy Bengio. 2015. Generating sentences from a continuous space. arXiv preprint arXiv:1511.06349 (2015).Google Scholar"",""Daniel Cer, Mona Diab, Eneko Agirre, Inigo Lopez-Gazpio, and Lucia Specia. 2017. Semeval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation. arXiv preprint arXiv:1708.00055 (2017).Google Scholar"",""Daniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua, Nicole Limtiaco, Rhomni St John, Noah Constant, Mario Guajardo-Cespedes, Steve Yuan, Chris Tar, et al. 2018. Universal sentence encoder. arXiv preprint arXiv:1803.11175 (2018).Google Scholar"",""David L Chen and William B Dolan. 2011. Collecting highly parallel data for paraphrase evaluation. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1. Association for Computational Linguistics, 190--200.Google ScholarDigital Library"",""Hal Daumé, John Langford, and Daniel Marcu. 2009. Search-based structured prediction. Machine learning, Vol. 75, 3 (2009), 297--325.Google Scholar"",""Peter Dayan and Yael Niv. 2008. Reinforcement learning: the good, the bad and the ugly. Current opinion in neurobiology, Vol. 18, 2 (2008), 185--196.Google Scholar"",""Bill Dolan, Chris Quirk, and Chris Brockett. 2004. Unsupervised Construction of Large Paraphrase Corpora: Exploiting Massively Parallel News Sources. In Proceedings of the 20th International Conference on Computational Linguistics (Geneva, Switzerland) (COLING '04). Association for Computational Linguistics, Stroudsburg, PA, USA, Article 350. https://doi.org/10.3115/1220355.1220406Google ScholarDigital Library"",""William B Dolan and Chris Brockett. 2005. Automatically constructing a corpus of sentential paraphrases. In Proceedings of the Third International Workshop on Paraphrasing (IWP2005) .Google Scholar"",""Michael Ellsworth and Adam Janin. 2007. Mutaphrase: Paraphrasing with framenet. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing. Association for Computational Linguistics, 143--150.Google ScholarCross Ref"",""Anthony Fader, Luke Zettlemoyer, and Oren Etzioni. 2013. Paraphrase-driven learning for open question answering. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 1608--1618.Google Scholar"",""Ankush Gupta, Arvind Agarwal, Prawaan Singh, and Piyush Rai. 2018. A deep generative framework for paraphrase generation. In Thirty-Second AAAI Conference on Artificial Intelligence .Google Scholar"",""Kenneth Heafield. 2011. KenLM: Faster and smaller language model queries. In Proceedings of the sixth workshop on statistical machine translation. Association for Computational Linguistics, 187--197.Google Scholar"",""Sepp Hochreiter and Jürgen Schmidhuber. 1997. LSTM can solve hard long time lag problems. In Advances in neural information processing systems. 473--479.Google Scholar"",""Eduard H Hovy, Chin-Yew Lin, Liang Zhou, and Junichi Fukumoto. 2006. Automated Summarization Evaluation with Basic Elements.. In LREC, Vol. 6. Citeseer, 899--902.Google Scholar"",""Diederik P Kingma and Max Welling. 2013. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 (2013).Google Scholar"",""Emily Kissner. 2006. Summarizing, paraphrasing and retelling. Portsmouth, NH: Heinernann (2006).Google Scholar"",""Kevin Knight and Daniel Marcu. 2000. Statistics-based summarization-step one: Sentence compression. AAAI/IAAI, Vol. 2000 (2000), 703--710.Google ScholarDigital Library"",""Wuwei Lan, Siyu Qiu, Hua He, and Wei Xu. 2017. A continuously growing dataset of sentential paraphrases. arXiv preprint arXiv:1708.00391 (2017).Google Scholar"",""Zichao Li, Xin Jiang, Lifeng Shang, and Hang Li. 2017. Paraphrase generation with deep reinforcement learning. arXiv preprint arXiv:1711.00279 (2017).Google Scholar"",""Zichao Li, Xin Jiang, Lifeng Shang, and Qun Liu. 2019. Decomposable neural paraphrase generation. arXiv preprint arXiv:1906.09741 (2019).Google Scholar"",""Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C Lawrence Zitnick. 2014. Microsoft coco: Common objects in context. In European conference on computer vision. Springer, 740--755.Google ScholarCross Ref"",""Xianggen Liu, Lili Mou, Fandong Meng, Hao Zhou, Jie Zhou, and Sen Song. 2019. Unsupervised Paraphrasing by Simulated Annealing. arXiv preprint arXiv:1909.03588 (2019).Google Scholar"",""Nitin Madnani and Bonnie J Dorr. 2010. Generating phrasal and sentential paraphrases: A survey of data-driven methods. Computational Linguistics, Vol. 36, 3 (2010), 341--387.Google ScholarDigital Library"",""Kathleen R McKeown. 1983. Paraphrasing questions using given and new information. Computational Linguistics, Vol. 9, 1 (1983), 1--10.Google ScholarDigital Library"",""Donald Metzler, Eduard Hovy, and Chunliang Zhang. 2011. An empirical evaluation of data-driven paraphrase generation techniques. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2. Association for Computational Linguistics, 546--551.Google ScholarDigital Library"",""Ning Miao, Hao Zhou, Lili Mou, Rui Yan, and Lei Li. 2019. Cgmh: Constrained sentence generation by metropolis-hastings sampling. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 6834--6842.Google ScholarCross Ref"",""Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin Riedmiller. 2013. Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602 (2013).Google Scholar"",""Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting on association for computational linguistics. Association for Computational Linguistics, 311--318.Google Scholar"",""Ellie Pavlick, Travis Wolfe, Pushpendre Rastogi, Chris Callison-Burch, Mark Dredze, and Benjamin Van Durme. 2015. FramenetGoogle Scholar"","": Fast paraphrastic tripling of framenet. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers). 408--413.Google Scholar"",""Aaditya Prakash, Sadid A Hasan, Kathy Lee, Vivek Datla, Ashequl Qadir, Joey Liu, and Oladimeji Farri. 2016. Neural paraphrase generation with stacked residual LSTM networks. arXiv preprint arXiv:1610.03098 (2016).Google Scholar"",""Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. 2014. Stochastic backpropagation and approximate inference in deep generative models. arXiv preprint arXiv:1401.4082 (2014).Google Scholar"",""Stéphane Ross, Geoffrey Gordon, and Drew Bagnell. 2011. A reduction of imitation learning and structured prediction to no-regret online learning. In Proceedings of the fourteenth international conference on artificial intelligence and statistics. 627--635.Google Scholar"",""Abigail See, Peter J Liu, and Christopher D Manning. 2017. Get to the point: Summarization with pointer-generator networks. arXiv preprint arXiv:1704.04368 (2017).Google Scholar"",""Pararth Shah, Dilek Hakkani-Tür, Gokhan Tür, Abhinav Rastogi, Ankur Bapna, Neha Nayak, and Larry Heck. 2018. Building a conversational agent overnight with dialogue self-play. arXiv preprint arXiv:1801.04871 (2018).Google Scholar"",""David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, et al. 2017. Mastering the game of go without human knowledge. Nature, Vol. 550, 7676 (2017), 354.Google Scholar"",""Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. 2006. A study of translation edit rate with targeted human annotation. In Proceedings of association for machine translation in the Americas, Vol. 200.Google Scholar"",""Hong Sun and Ming Zhou. 2012. Joint learning of a dual SMT system for paraphrase generation. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers-Volume 2. Association for Computational Linguistics, 38--42.Google ScholarDigital Library"",""Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Sequence to sequence learning with neural networks. In Advances in neural information processing systems. 3104--3112.Google Scholar"",""Richard S Sutton, Andrew G Barto, et al. 1998. Introduction to reinforcement learning. Vol. 135. MIT press Cambridge.Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998--6008.Google Scholar"",""Alex Warstadt, Amanpreet Singh, and Samuel R Bowman. 2019. Neural network acceptability judgments. Transactions of the Association for Computational Linguistics, Vol. 7 (2019), 625--641.Google ScholarCross Ref"",""Ronald J Williams. 1992. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning, Vol. 8, 3--4 (1992), 229--256.Google Scholar"",""Sam Wiseman and Alexander M Rush. 2016. Sequence-to-sequence learning as beam-search optimization. arXiv preprint arXiv:1606.02960 (2016).Google Scholar"",""Shiqi Zhao, Xiang Lan, Ting Liu, and Sheng Li. 2009. Application-driven statistical paraphrase generation. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2. Association for Computational Linguistics, 834--842.Google ScholarDigital Library"",""Shiqi Zhao and Haifeng Wang. 2010. Paraphrases and applications. In Coling 2010: Paraphrases and Applications--Tutorial notes. 1--87.Google Scholar"",""Shiqi Zhao, Haifeng Wang, Xiang Lan, and Ting Liu. 2010. Leveraging multiple MT engines for paraphrase generation. In Proceedings of the 23rd International Conference on Computational Linguistics. Association for Computational Linguistics, 1326--1334.Google Scholar""]"
https://doi.org/10.1145/3394486.3403232,CICLAD: A Fast and Memory-efficient Closed Itemset Miner for Streams,"Mining association rules from data streams is a challenging task due to the (typically) limited resources available vs. the large size of the result. Frequent closed itemsets (FCI) enable an efficient first step, yet current FCI stream miners are not optimal on resource consumption, e.g. they store a large number of extra itemsets at an additional cost. In a search for a better storage-efficiency trade-off, we designed Ciclad, an intersection-based sliding-window FCI miner. Leveraging in-depth insights into FCI evolution, it combines minimal storage with quick access. Experimental results indicate Ciclad's memory imprint is much lower and its performances globally better than competitor methods.","[{""name"":""Tomas Martin"",""id"":""/profile/99659176062""},{""name"":""Guy Francoeur"",""id"":""/profile/99659574767""},{""name"":""Petko Valtchev"",""id"":""/profile/81100262189""},{""name"":""Tomas Martin"",""id"":""/profile/99659176062""},{""name"":""Guy Francoeur"",""id"":""/profile/99659574767""},{""name"":""Petko Valtchev"",""id"":""/profile/81100262189""}]","[""C. Borgelt et al. Finding closed frequent item sets by intersecting transactions. In 14th EDBT, pages 367--376. ACM, 2011.Google ScholarDigital Library"",""T. Calders et al. A Survey on Condensed Representations for Frequent Sets. In Constraint-Based Mining and Inductive Databases, volume 3848 of LNCS, pages 64--80. Springer, 2004.Google Scholar"",""J. Chen and S. Li. GC-tree: a fast online algorithm for mining frequent closed itemsets. In 11th PAKDD, pages 457--468. Springer, 2007.Google ScholarCross Ref"",""Y. Chi et al. Moment: Maintaining closed frequent itemsets over a stream sliding window. In 4th IEEE ICDM, pages 59--66. IEEE, 2004.Google Scholar"",""B. Ganter and R. Wille. Formal concept analysis: mathematical foundations. Springer, 1999.Google ScholarDigital Library"",""C. Gao and J. Wang. Efficient itemset generator discovery over a stream sliding window. In 18th ACM CIKM, pages 355--364, 2009.Google ScholarDigital Library"",""R. Godin et al. Incremental Concept Formation Algorithms Based on Galois (Concept) Lattices. Computational Intelligence, 11(2):246--267, 1995.Google ScholarCross Ref"",""D. Gunopulos et al. Data mining, hypergraph transversals, and machine learning (extended abstract). In 16th ACM SIGACT-SIGMOD-SIGART PODS, pages 209--216. ACM, 1997.Google ScholarDigital Library"",""S. Hamadi et al. Compiling packet forwarding rules for switch pipelined architecture. In The 35th IEEE INFOCOM 2016. IEEE, April 2016.Google ScholarCross Ref"",""D. Huang et al. Rare pattern mining on data streams. In Intl. Conf. DaWaK, pages 303--314. Springer, 2012.Google ScholarDigital Library"",""N. Jiang and L. Gruenwald. CFI-Stream: mining closed frequent itemsets in data streams. In 12th ACM SIGKDD, pages 592--597. ACM, 2006.Google ScholarDigital Library"",""N. Jiang and L. Gruenwald. Research issues in data stream association rule mining. ACM Sigmod Record, 35(1):14--19, 2006.Google ScholarDigital Library"",""R. Karim et al. Mining maximal frequent patterns in transactional databases and dynamic data streams: A spark-based approach. Information Sciences, 432:278--300, 2018.Google ScholarCross Ref"",""M. Kryszkiewicz. Concise Representations of Association Rules. In ESF Exploratory WS on Pattern Detection and Discovery, pages 92--109, 2002.Google ScholarDigital Library"",""H.-F. Li et al. A new algorithm for maintaining closed frequent itemsets in data streams by incremental updates. In ICDM Workshops 2006, pages 672--676. IEEE, 2006.Google ScholarDigital Library"",""H.-F. Li and S.-Y. Lee. Mining frequent itemsets over data streams using efficient window sliding techniques. Expert systems with applications, 36(2):1466--1477, 2009.Google Scholar"",""C. Lucchese et al. DCI Closed: A Fast and Memory Efficient Algorithm to Mine Frequent Closed Itemsets. In FIMI, 2004.Google Scholar"",""K. Nehme et al. On Computing the Minimal Generator Family for Concept Lattices and Icebergs. In 3rd Intl. Conf. on Formal Concept Analysis, pages 192--207, Lens (FR), 2005. Springer.Google Scholar"",""E. M. Norris. An algorithm for computing the maximal rectangles in a binary relation. Revue Roumaine de Maths Pures et Appliquées, 23(2):243--250, 1978.Google Scholar"",""J. L. Pfaltz. Incremental Transformation of Lattices: A Key to Effective Knowledge Discovery. In Proc. of the 1st ICGT, pages 351--362, 2002.Google ScholarCross Ref"",""M. Rashid et al. Mining associated sensor patterns for data stream of wireless sensor networks. In 8th ACM WS on Performance monitoring and measurement of heterogeneous wireless and wired networks, pages 91--98. ACM, 2013.Google Scholar"",""L. Szathmary et al. Constructing Iceberg Lattices from Frequent Closures Using Generators. In 11th Intl. Conf. on Discovery Science, pages 136--147, Budapest (HU), 2008. Springer.Google ScholarDigital Library"",""L. Szathmary et al. Generating rare association rules using the minimal rare itemsets family. Intl. J-l of Software and Informatics, 4(3), 2010.Google Scholar"",""P. Valtchev et al. Generating Frequent Itemsets Incrementally: Two Novel Approaches Based On Galois Lattice Theory. Journal of Experimental \u0026 Theoretical Artificial Intelligence, 14(2--3):115--142, 2002.Google ScholarCross Ref"",""P. Valtchev et al. A framework for incremental generation of closed itemsets. Discrete Appl. Math., 156:924--949, March 2008.Google ScholarDigital Library"",""Y. Yamamoto et al. Parasol: a hybrid approximation approach for scalable frequent itemset mining in streaming data. Journal of Intelligent Information Systems, 55:119--147, 2019.Google ScholarCross Ref"",""S. Yen et al. A fast algorithm for mining frequent closed itemsets over stream sliding window. In IEEE Intl. Conf. on Fuzzy Systems, pages 996--1002. IEEE, 2011.Google ScholarCross Ref"",""M. Zaki et al. New Algorithms for Fast Discovery of Association Rules. In 3rd Intl. Conf. KDD, pages 283--286, 1997.Google Scholar"",""M. Zaki and C-J Hsiao. Efficient algorithms for mining closed itemsets and their lattice structure. IEEE Transactions on Knowledge and Data Engineering, 17(4):462--478, 2005.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403233,Graph Attention Networks over Edge Content-Based Channels,"Edges play a crucial role in passing information on a graph, especially when they carry textual content reflecting semantics behind how nodes are linked and interacting with each other. In this paper, we propose a channel-aware attention mechanism enabled by edge text content when aggregating information from neighboring nodes; and we realize this mechanism in a graph autoencoder framework. Edge text content is encoded as low-dimensional mixtures of latent topics, which serve as semantic channels for topic-level information passing on edges. We embed nodes and topics in the same latent space to capture their mutual dependency when decoding the structural and textual information on graph. We evaluated the proposed model on Yelp user-item bipartite graph and StackOverflow user-user interaction graph. The proposed model outperformed a set of baselines on link prediction and content prediction tasks. Qualitative evaluations also demonstrated the descriptive power of the learnt node embeddings, showing its potential as an interpretable representation of graphs.","[{""name"":""Lu Lin"",""id"":""/profile/99659346604""},{""name"":""Hongning Wang"",""id"":""/profile/81466648782""},{""name"":""Lu Lin"",""id"":""/profile/99659346604""},{""name"":""Hongning Wang"",""id"":""/profile/81466648782""}]","[""Sami Abu-El-Haija, Bryan Perozzi, Rami Al-Rfou, and Alexander A Alemi. 2018. Watch your step: Learning node embeddings via graph attention. In NeurIPS. 9180--9190.Google Scholar"",""Charu C Aggarwal, Haixun Wang, et al. 2010. Managing and mining graph data. Vol. 40. Springer.Google Scholar"",""Rianne van den Berg, Thomas N Kipf, and Max Welling. 2017. Graph convolutional matrix completion. arXiv preprint arXiv:1706.02263 (2017).Google Scholar"",""Smriti Bhagat, Graham Cormode, and S Muthukrishnan. 2011. Node classification in social networks. In Social network data analytics. Springer, 115--148.Google Scholar"",""DavidMBlei, AndrewY Ng, and Michael I Jordan. 2003. Latent dirichlet allocation. Journal of machine Learning research 3, Jan (2003), 993--1022.Google ScholarDigital Library"",""Joan Bruna,Wojciech Zaremba, Arthur Szlam, and Yann LeCun. 2013. Spectral networks and locally connected networks on graphs. arXiv preprint arXiv:1312.6203 (2013).Google Scholar"",""Hongyun Cai, Vincent W Zheng, and Kevin Chen-Chuan Chang. 2018. A comprehensive survey of graph embedding: Problems, techniques, and applications. TKDE 30, 9 (2018), 1616--1637.Google ScholarCross Ref"",""Yukuo Cen, Xu Zou, Jianwei Zhang, Hongxia Yang, Jingren Zhou, and Jie Tang. 2019. Representation learning for attributed multiplex heterogeneous network. In SIGKDD. 1358--1368.Google Scholar"",""Pengfei Chen, Weiwen Liu, Chang-Yu Hsieh, Guangyong Chen, and Shengyu Zhang. 2019. Utilizing edge features in graph neural networks via variational information maximization. arXiv preprint arXiv:1906.05488 (2019).Google Scholar"",""Robert B Cialdini and Noah J Goldstein. 2004. Social influence: Compliance and conformity. Annu. Rev. Psychol. 55 (2004), 591--621.Google ScholarCross Ref"",""Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolutional neural networks on graphs with fast localized spectral filtering. In NeurIPS. 3844--3852.Google Scholar"",""Frederik Diehl. 2019. Edge Contraction Pooling for Graph Neural Networks. arXiv preprint arXiv:1905.10990 (2019).Google Scholar"",""Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. 2017. Neural message passing for quantum chemistry. In ICML. JMLR. org, 1263--1272.Google Scholar"",""Liyu Gong and Qiang Cheng. 2019. Exploiting Edge Features for Graph Neural Networks. In CVPR. 9211--9219.Google Scholar"",""Lin Gong, Lu Lin, Weihao Song, and Hongning Wang. 2020. JNET: Learning User Representations via Joint Network Embedding and Topic Embedding. In WSDM. 205--213.Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In SIGKDD. 855--864.Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In NeurIPS. 1024--1034.Google Scholar"",""Diederik P Kingma and Max Welling. 2013. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 (2013).Google Scholar"",""Diederik P Kingma, Max Welling, et al. 2019. An introduction to variational autoencoders. Foundations and Trends® in Machine Learning 12, 4 (2019), 307--392.Google Scholar"",""Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).Google Scholar"",""Lu Lin, Lin Gong, and Hongning Wang. 2019. Learning Personalized Topical Compositions with Item Response Theory. In WSDM. 609--617.Google Scholar"",""Miller McPherson, Lynn Smith-Lovin, and James M Cook. 2001. Birds of a feather: Homophily in social networks. Annual review of sociology 27, 1 (2001), 415--444.Google Scholar"",""Ashwin Paranjape, Austin R Benson, and Jure Leskovec. 2017. Motifs in temporal networks. In WSDM. 601--610.Google Scholar"",""Heiko Paulheim. 2017. Knowledge graph refinement: A survey of approaches and evaluation methods. Semantic web 8, 3 (2017), 489--508.Google Scholar"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In SIGKDD. 701--710.Google ScholarDigital Library"",""Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den Berg, Ivan Titov, and Max Welling. 2018. Modeling relational data with graph convolutional networks. In ESWC. Springer, 593--607.Google Scholar"",""Akash Srivastava and Charles Sutton. 2017. Autoencoding variational inference for topic models. arXiv preprint arXiv:1703.01488 (2017).Google Scholar"",""Ben Taskar, Ming-Fai Wong, Pieter Abbeel, and Daphne Koller. 2004. Link prediction in relational data. In NeurIPS. 659--666.Google Scholar"",""Cunchao Tu, Han Liu, Zhiyuan Liu, and Maosong Sun. 2017. Cane: Context-aware network embedding for relation modeling. In ACL. 1722--1731.Google Scholar"",""Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph attention networks. arXiv preprint arXiv:1710.10903 (2017).Google Scholar"",""Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. 2014. Knowledge graph embedding by translating on hyperplanes. In AAAI.Google Scholar"",""Carl Yang, Jieyu Zhang, Haonan Wang, Sha Li, Myungwan Kim, Matt Walker, Yiou Xiao, and Jiawei Han. 2020. Relation Learning on Social Networks with Multi-Modal Graph Edge Variational Autoencoders. In WSDM. 699--707.Google Scholar"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale recommender systems. In SIGKDD. 974--983.Google Scholar"",""Hongming Zhang, Liwei Qiu, Lingling Yi, and Yangqiu Song. 2018. Scalable Multiplex Network Embedding. In IJCAI, Vol. 18. 3082--3088.Google Scholar""]"
https://doi.org/10.1145/3394486.3403234,Multimodal Learning with Incomplete Modalities by Knowledge Distillation,"Multimodal learning aims at utilizing information from a variety of data modalities to improve the generalization performance. One common approach is to seek the common information that is shared among different modalities for learning, whereas we can also fuse the supplementary information to leverage modality-specific information. Though the supplementary information is often desired, most existing multimodal approaches can only learn from samples with complete modalities, which wastes a considerable amount of data collected. Otherwise, model-based imputation needs to be used to complete the missing values and yet may introduce undesired noise, especially when the sample size is limited. In this paper, we proposed a framework based on knowledge distillation, utilizing the supplementary information from all modalities, and avoiding imputation and noise associated with it. Specifically, we first train models on each modality independently using all the available data. Then the trained models are used as teachers to teach the student model, which is trained with the samples having complete modalities. We demonstrate the effectiveness of the proposed method in extensive empirical studies on both synthetic datasets and real-world datasets.","[{""name"":""Qi Wang"",""id"":""/profile/99659193535""},{""name"":""Liang Zhan"",""id"":""/profile/99659192991""},{""name"":""Paul Thompson"",""id"":""/profile/81405594226""},{""name"":""Jiayu Zhou"",""id"":""/profile/99659456851""},{""name"":""Qi Wang"",""id"":""/profile/99659193535""},{""name"":""Liang Zhan"",""id"":""/profile/99659192991""},{""name"":""Paul Thompson"",""id"":""/profile/81405594226""},{""name"":""Jiayu Zhou"",""id"":""/profile/99659456851""}]","[""Galen Andrew, Raman Arora, Jeff Bilmes, and Karen Livescu. 2013. Deep canonical correlation analysis. In International Conference on Machine Learning. 1247--1255.Google ScholarDigital Library"",""Lei Cai, Zhengyang Wang, Hongyang Gao, Dinggang Shen, and Shuiwang Ji. 2018. Deep adversarial learning for multi-modality missing data completion. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 1158--1166.Google ScholarDigital Library"",""Rahul S Desikan, Florent Ségonne, Bruce Fischl, Brian T Quinn, Bradford C Dickerson, Deborah Blacker, Randy L Buckner, Anders M Dale, R Paul Maguire, Bradley T Hyman, et al. 2006. An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest. Neuroimage, Vol. 31, 3 (2006), 968--980.Google ScholarCross Ref"",""Craig K Enders. 2010. Applied missing data analysis. Guilford press.Google Scholar"",""Jean A Frazier, Sufen Chiu, Janis L Breeze, Nikos Makris, Nicholas Lange, David N Kennedy, Martha R Herbert, Eileen K Bent, Vamsi K Koneru, Megan E Dieterich, et al. 2005. Structural brain magnetic resonance imaging of limbic and thalamic volumes in pediatric bipolar disorder. American Journal of Psychiatry, Vol. 162, 7 (2005), 1256--1265.Google ScholarCross Ref"",""Hatice Gunes and Massimo Piccardi. 2005. Affect recognition from face and body: early fusion vs. late fusion. In 2005 IEEE international conference on systems, man and cybernetics, Vol. 4. IEEE, 3437--3443.Google ScholarCross Ref"",""Leticia Gutiérrez-Galve, Manja Lehmann, Nicola Z Hobbs, Matthew J Clarkson, Gerard R Ridgway, Sebastian Crutch, Sebastien Ourselin, Jonathan M Schott, Nick C Fox, and Josephine Barnes. 2009. Patterns of cortical thickness according to APOE genotype in Alzheimer's disease. Dementia and geriatric cognitive disorders, Vol. 28, 5 (2009), 461--470.Google Scholar"",""Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531 (2015).Google Scholar"",""K Juottonen, MP Laakso, R Insausti, M Lehtovirta, A Pitk\""anen, K Partanen, and H Soininen. 1998. Volumes of the entorhinal and perirhinal cortices in Alzheimer's disease. Neurobiology of aging, Vol. 19, 1 (1998), 15--22.Google Scholar"",""Sham M Kakade and Dean P Foster. 2007. Multi-view regression via canonical correlation analysis. In International Conference on Computational Learning Theory. Springer, 82--96.Google ScholarCross Ref"",""Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems. 1097--1105.Google Scholar"",""Weifeng Liu and Dacheng Tao. 2013. Multiview hessian regularization for image annotation. IEEE Transactions on Image Processing, Vol. 22, 7 (2013), 2676--2687.Google ScholarCross Ref"",""Rahil Mehrizi, Xi Peng, Zhiqiang Tang, Xu Xu, Dimitris Metaxas, and Kang Li. 2018. Toward marker-free 3D pose estimation in lifting: A deep multi-view solution. In 2018 13th IEEE International Conference on Automatic Face \u0026 Gesture Recognition (FG 2018). IEEE, 485--491.Google ScholarCross Ref"",""Nicolai Meinshausen and Peter Bühlmann. 2010. Stability selection. Journal of the Royal Statistical Society: Series B (Statistical Methodology), Vol. 72, 4 (2010), 417--473.Google ScholarCross Ref"",""Yongsheng Pan, Mingxia Liu, Chunfeng Lian, Tao Zhou, Yong Xia, and Dinggang Shen. 2018. Synthesizing missing PET from MRI with cycle-consistent generative adversarial networks for Alzheimer's disease diagnosis. In International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 455--463.Google ScholarCross Ref"",""Geoffrey JM Parker, Hamied A Haroon, and Claudia AM Wheeler-Kingshott. 2003. A framework for a streamline-based probabilistic index of connectivity (PICo) using a structural interpretation of MRI diffusion measurements. Journal of Magnetic Resonance Imaging: An Official Journal of the International Society for Magnetic Resonance in Medicine, Vol. 18, 2 (2003), 242--254.Google ScholarCross Ref"",""Hai Pham, Paul Pu Liang, Thomas Manzini, Louis-Philippe Morency, and Barnabás Póczos. 2019. Found in translation: Learning robust joint representations by cyclic translations between modalities. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 6892--6899.Google ScholarCross Ref"",""Snehashis Roy, John A Butman, Daniel S Reich, Peter A Calabresi, and Dzung L Pham. 2018. Multiple sclerosis lesion segmentation from brain MRI via fully convolutional neural networks. arXiv preprint arXiv:1803.09172 (2018).Google Scholar"",""Alexander G Schwing and Raquel Urtasun. 2015. Fully connected deep structured networks. arXiv preprint arXiv:1503.02351 (2015).Google Scholar"",""Weixiang Shao, Xiaoxiao Shi, and S Yu Philip. 2013. Clustering on multiple incomplete datasets via collective kernel learning. In 2013 IEEE 13th International Conference on Data Mining. IEEE, 1181--1186.Google ScholarCross Ref"",""Cees GM Snoek, Marcel Worring, and Arnold WM Smeulders. 2005. Early versus late fusion in semantic video analysis. In Proceedings of the 13th annual ACM international conference on Multimedia. 399--402.Google ScholarDigital Library"",""Yang Song, Ali Mamdouh Elkahky, and Xiaodong He. 2016. Multi-rate deep learning for temporal recommendation. In Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval. ACM, 909--912.Google ScholarDigital Library"",""Qiuling Suo, Weida Zhong, Fenglong Ma, Ye Yuan, Jing Gao, and Aidong Zhang. 2019. Metric learning on healthcare data with incomplete modalities. In Proceedings of the 28th International Joint Conference on Artificial Intelligence. AAAI Press, 3534--3540.Google ScholarCross Ref"",""Qiaoyu Tan, Guoxian Yu, Carlotta Domeniconi, Jun Wang, and Zili Zhang. 2018. Incomplete multi-view weak-label learning.. In IJCAI. 2703--2709.Google Scholar"",""Luan Tran, Xiaoming Liu, Jiayu Zhou, and Rong Jin. 2017. Missing modalities imputation via cascaded residual autoencoder. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 1405--1414.Google ScholarCross Ref"",""Grigorios Tzortzis and Aristidis Likas. 2012. Kernel-based weighted multi-view clustering. In 2012 IEEE 12th international conference on data mining. IEEE, 675--684.Google ScholarDigital Library"",""Manik Varma and Bodla Rakesh Babu. 2009. More generality in efficient multiple kernel learning. In Proceedings of the 26th Annual International Conference on Machine Learning. ACM, 1065--1072.Google ScholarDigital Library"",""Qianqian Wang, Zhengming Ding, Zhiqiang Tao, Quanxue Gao, and Yun Fu. 2018a. Partial multi-view clustering via consistent GAN. In 2018 IEEE International Conference on Data Mining (ICDM). IEEE, 1290--1295.Google ScholarCross Ref"",""Qi Wang, Lei Guo, Paul M Thompson, Clifford R Jack Jr, Hiroko Dodge, Liang Zhan, Jiayu Zhou, Alzheimer's Disease Neuroimaging Initiative, et al. 2018b. The added value of diffusion-weighted MRI-derived structural connectome in evaluating mild cognitive impairment: A multi-cohort validation. Journal of Alzheimer's Disease, Vol. 64, 1 (2018), 149--169.Google ScholarCross Ref"",""Qi Wang, Mengying Sun, Liang Zhan, Paul Thompson, Shuiwang Ji, and Jiayu Zhou. 2017. Multi-Modality Disease Modeling via Collective Deep Matrix Factorization. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 1155--1164.Google ScholarDigital Library"",""Qi Wang, Liang Zhan, Paul M Thompson, Hiroko H Dodge, and Jiayu Zhou. 2016. Discriminative fusion of multiple brain networks for early mild cognitive impairment detection. In 2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI). IEEE, 568--572.Google ScholarCross Ref"",""Weiran Wang, Raman Arora, Karen Livescu, and Jeff Bilmes. 2015. On deep multi-view representation learning. In International Conference on Machine Learning. 1083--1092.Google ScholarDigital Library"",""Jennifer Williams, Steven Kleinegesse, Ramona Comanescu, and Oana Radu. 2018. Recognizing emotions in video using multimodal dnn feature fusion. In Proceedings of Grand Challenge and Workshop on Human Multimodal Language (Challenge-HML). 11--19.Google ScholarCross Ref"",""Chang Xu, Dacheng Tao, and Chao Xu. 2013. A survey on multi-view learning. arXiv preprint arXiv:1304.5634 (2013).Google Scholar"",""Qiyue Yin, Shu Wu, and Liang Wang. 2015. Incomplete multi-view clustering via subspace learning. In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management. ACM, 383--392.Google ScholarDigital Library"",""Qiyue Yin, Shu Wu, and Liang Wang. 2017. Unified subspace learning for incomplete and unlabeled multi-view data. Pattern Recognition, Vol. 67 (2017), 313--327.Google ScholarDigital Library"",""Hsiang-Fu Yu, Cho-Jui Hsieh, Si Si, and Inderjit Dhillon. 2012. Scalable coordinate descent approaches to parallel matrix factorization for recommender systems. In Data Mining (ICDM), 2012 IEEE 12th International Conference on. IEEE, 765--774.Google ScholarDigital Library"",""Lei Yuan, Yalin Wang, Paul M Thompson, Vaibhav A Narayan, and Jieping Ye. 2012. Multi-source learning for joint analysis of incomplete multi-modality neuroimaging data. In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. 1149--1157.Google ScholarDigital Library"",""Ying Zhang, Tao Xiang, Timothy M Hospedales, and Huchuan Lu. 2018. Deep mutual learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 4320--4328.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403235,Estimating the Percolation Centrality of Large Networks through Pseudo-dimension Theory,"In this work we investigate the problem of estimating the percolation centrality of every vertex in a graph. This centrality measure quantifies the importance of each vertex in a graph going through a contagious process. It is an open problem whether the percolation centrality can be computed in O(n3-c) time, for any constant c>0. In this paper we present a ~O(m) randomized approximation algorithm for the percolation centrality for every vertex of G, generalizing techniques developed by Riondato, Upfal and Kornaropoulos. The estimation obtained by the algorithm is within ε of the exact value with probability 1- δ, for fixed constants 0 < ε,δ < 1. In fact, we show in our experimental analysis that in the case of real-world complex networks, the output produced by our algorithm is significantly closer to the exact values than its guarantee in terms of theoretical worst case analysis.","[{""name"":""Alane M. de Lima"",""id"":""/profile/99659574131""},{""name"":""Murilo V. G. da Silva"",""id"":""/profile/81549031056""},{""name"":""André L. Vignatti"",""id"":""/profile/81440623399""},{""name"":""Alane M. de Lima"",""id"":""/profile/99659574131""},{""name"":""Murilo V. G. da Silva"",""id"":""/profile/81549031056""},{""name"":""André L. Vignatti"",""id"":""/profile/81440623399""}]","[""A. Abboud and V. Williams. 2014. Popular Conjectures Imply Strong Lower Bounds for Dynamic Problems. In 2014 IEEE 55th Annual Symposium on Foundations of Computer Science. 434--443. https://doi.org/10.1109/FOCS.2014.53Google Scholar"",""A. Abboud, V. Williams, and H. Yu. 2018. Matching Triangles and Basing Hardness on an Extremely Popular Conjecture. SIAM J. Comput. 47, 3 (2018), 1098--1122. https://doi.org/10.1137/15M1050987 arXiv: https://doi.org/10.1137/15M1050987Google ScholarCross Ref"",""D. Aingworth, C. Chekuri, and R. Motwani. 1996. Fast Estimation of Diameter and Shortest Paths (Without Matrix Multiplication). In Proceedings of the Seventh Annual ACM-SIAM Symposium on Discrete Algorithms (SODA '96). 547--553.Google Scholar"",""M. Anthony and P. L. Bartlett. 2009.Neural Network Learning: Theoretical Foundations(1st ed.). Cambridge University Press, New York, NY, USA.Google Scholar"",""Albert-László Barabási and Réka Albert. 1999. Emergence of Scaling in Random Networks. Science 286, 5439 (1999), 509--512.Google Scholar"",""S. R. Broadbent and J. M. Hammersley. 1957. Percolation processes: I. Crystals and mazes. Math. Proc. of the Cambridge Philosophical Society 53, 3 (1957), 629--641.Google ScholarCross Ref"",""Aric A. Hagberg, Daniel A. Schult, and Pieter J. Swart. 2008. Exploring network structure, dynamics, and function using Network X. In Proceedings of the 7th Python in Science Conference (SciPy2008). Pasadena, CA USA, 11--15.Google Scholar"",""Jure Leskovec and Andrej Krevl. 2014. SNAP Datasets: Stanford Large Network Dataset Collection. http://snap.stanford.edu/data.Google Scholar"",""Yi Li, Philip M. Long, and Aravind Srinivasan. 2001. Improved Bounds on the Sample Complexity of Learning. J. Comput. System Sci. 62, 3 (2001), 516 -- 527. https://doi.org/10.1006/jcss.2000.1741Google ScholarDigital Library"",""M. Löffler and J. M. Phillips. 2009. Shape Fitting on Point Sets with Probability Distributions. In Algorithms - ESA 2009, 17th Annual European Symposium, Copenhagen, Denmark, September 7--9, 2009. Proceedings. Springer Berlin Heidelberg,313--324.Google Scholar"",""M. Mitzenmacher and E. Upfal. 2017. Probability and Computing: Randomization and Probabilistic Techniques in Algorithms and Data Analysis(2nd ed.). Cambridge University Press.Google Scholar"",""M. Mohri, A. Rostamizadeh, and A. Talwalkar. 2012. Foundations of Machine Learning. The MIT Press.Google Scholar"",""M. Piraveenan, M. Prokopenko, and L. Hossain. 2013. Percolation Centrality: Quantifying Graph-Theoretic Impact of Nodes during Percolation in Networks. PLOS ONE8, 1 (2013), 1--14.Google Scholar"",""M. Riondato and E. M. Kornaropoulos. 2016. Fast approximation of betweenness centrality through sampling. Data Mining and Knowledge Discovery 30, 2 (2016),438--475.Google ScholarDigital Library"",""M. Riondato and E. Upfal. 2018. ABRA: Approximating Betweenness Centrality in Static and Dynamic Graphs with Rademacher Averages. ACM Trans. Knowl. Discov. Data12, 5, Article 61 (July 2018), 38 pages.Google ScholarDigital Library"",""R. Seidel. 1995. On the All-Pairs-Shortest-Path Problem in Unweighted Undirected Graphs. J. Comput. System Sci.51, 3 (1995), 400 -- 403.Google ScholarDigital Library"",""S. Shalev-Shwartz and S. Ben-David. 2014. Understanding Machine Learning: From Theory to Algorithms. Cambridge University Press.Google Scholar"",""M. D. Vose. 1991. A linear algorithm for generating random numbers with a given distribution. IEEE Transactions on software engineering 17, 9 (1991), 972--975.Google ScholarDigital Library"",""R. Williams. 2018. Faster All-Pairs Shortest Paths via Circuit Complexity. SIAM J. Comput. 47, 5 (2018), 1965--1985. https://doi.org/10.1137/15M1024524arXiv: https://doi.org/10.1137/15M1024524Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403236,TinyGNN: Learning Efficient Graph Neural Networks,"Recently, Graph Neural Networks (GNNs) arouse a lot of research interest and achieve great success in dealing with graph-based data. The basic idea of GNNs is to aggregate neighbor information iteratively. After k iterations, a k-layer GNN can capture nodes' k-hop local structure. In this way, a deeper GNN can access much more neighbor information leading to better performance. However, when a GNN goes deeper, the exponential expansion of neighborhoods incurs expensive computations in batched training and inference. This takes the deeper GNN away from many applications, e.g., real-time systems. In this paper, we try to learn a small GNN (called TinyGNN), which can achieve high performance and infer the node representation in a short time. However, since a small GNN cannot explore as much local structure as a deeper GNN does, there exists a neighbor information gap between the deeper GNN and the small GNN. To address this problem, we leverage peer node information to model the local structure explicitly and adopt a neighbor distillation strategy to learn local structure knowledge from a deeper GNN implicitly. Extensive experimental results demonstrate that TinyGNN is empirically effective and achieves similar or even better performance compared with the deeper GNNs. Meanwhile, TinyGNN gains a 7.73x--126.59x speed-up on inference over all data sets.","[{""name"":""Bencheng Yan"",""id"":""/profile/99659574167""},{""name"":""Chaokun Wang"",""id"":""/profile/81384599346""},{""name"":""Gaoyang Guo"",""id"":""/profile/99659143474""},{""name"":""Yunkai Lou"",""id"":""/profile/99659573450""},{""name"":""Bencheng Yan"",""id"":""/profile/99659574167""},{""name"":""Chaokun Wang"",""id"":""/profile/81384599346""},{""name"":""Gaoyang Guo"",""id"":""/profile/99659143474""},{""name"":""Yunkai Lou"",""id"":""/profile/99659573450""}]","[""Aleksandar Bojchevski, Johannes Klicpera, Bryan Perozzi, Martin Blais, Amol Kapoor, Michal Lukasik, and Stephan Günnemann. 2019. Is pagerank all you need for scalable graph neural networks?. In ACM KDD, MLG Workshop.Google Scholar"",""Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. 2014. Spectral networks and locally connected networks on graphs. In ICLR.Google Scholar"",""Yukuo Cen, Xu Zou, Jianwei Zhang, Hongxia Yang, Jingren Zhou, and Jie Tang. 2019. Representation Learning for Attributed Multiplex Heterogeneous Network. In KDD. 1358--1368.Google Scholar"",""Jie Chen, Tengfei Ma, and Cao Xiao. 2018. Fastgcn: fast learning with graph convolutional networks via importance sampling. In ICLR.Google Scholar"",""Michael Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolutional neural networks on graphs with fast localized spectral filtering. In NIPS. 3844--3852.Google Scholar"",""Arthur Gretton, Dino Sejdinovic, Heiko Strathmann, Sivaraman Balakrishnan, Massimiliano Pontil, Kenji Fukumizu, and Bharath K Sriperumbudur. 2012. Optimal kernel choice for large-scale two-sample tests. In NIPS. 1205--1213.Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In KDD. ACM, 855--864.Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In NIPS. 1024--1034.Google Scholar"",""Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015. Distilling the knowledge in a neural network. In arXiv preprint arXiv:1503.02531.Google Scholar"",""Wenbing Huang, Tong Zhang, Yu Rong, and Junzhou Huang. 2018. Adaptive sampling towards fast graph representation learning. In NIPS. 4558--4567.Google Scholar"",""Zehao Huang and Naiyan Wang. 2017. Like what you like: Knowledge distill via neuron selectivity transfer. In arXiv preprint arXiv:1707.01219.Google Scholar"",""Thomas N Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional networks. In ICLR.Google Scholar"",""Feng Li, Zhenrui Chen, Pengjie Wang, Yi Ren, Di Zhang, and Xiaoyu Zhu. 2019. Graph Intention Network for Click-through Rate Prediction in Sponsored Search. In SIGIR. 961--964.Google Scholar"",""Qimai Li, Zhichao Han, and Xiao-Ming Wu. 2018. Deeper insights into graph convolutional networks for semi-supervised learning. In AAAI. 3538--3545.Google Scholar"",""Mingsheng Long, Yue Cao, Jianmin Wang, and Michael I Jordan. 2015. Learning transferable features with deep adaptation networks. In ICML. 97--105.Google Scholar"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In KDD. ACM, 701--710.Google ScholarDigital Library"",""Leonardo FR Ribeiro, Pedro HP Saverese, and Daniel R Figueiredo. 2017. struc2vec: Learning node representations from structural identity. In KDD. ACM, 385--394.Google Scholar"",""Adriana Romero, Nicolas Ballas, Samira Ebrahimi Kahou, Antoine Chassang, Carlo Gatta, and Yoshua Bengio. 2015. Fitnets: Hints for thin deep nets. In ICLR.Google Scholar"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. In WWW. 1067--1077.Google ScholarDigital Library"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In NIPS. 5998--6008.Google Scholar"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. 2018. Graph Attention Networks. In ICLR.Google Scholar"",""Changping Wang, Chaokun Wang, Zheng Wang, Xiaojun Ye, and Philip S Yu. 2020 a. Edge2vec: Edge-based Social Network Embedding. In TKDD. ACM.Google Scholar"",""Zheng Wang, Xiaojun Ye, Chaokun Wang, Jian Cui, and Philip Yu. 2020 b. Network Embedding with Completely-imbalanced Labels. In IEEE Transactions on Knowledge and Data Engineering.Google Scholar"",""Keyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi, and Stefanie Jegelka. 2018. Representation Learning on Graphs with Jumping Knowledge Networks. In ICML. 5449--5458.Google Scholar"",""Bencheng Yan and Chaokun Wang. 2020. GraphAE: Adaptive Embedding across Graphs. In ICDE. IEEE, 1958--1961.Google ScholarCross Ref"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale recommender systems. In KDD. 974--983.Google Scholar"",""Yizhou Zhang, Yun Xiong, Xiangnan Kong, Shanshan Li, Jinhong Mi, and Yangyong Zhu. 2018. Deep Collective Classification in Heterogeneous Information Networks. In WWW. 399--408.Google Scholar""]"
https://doi.org/10.1145/3394486.3403237,GPT-GNN: Generative Pre-Training of Graph Neural Networks,"Graph neural networks (GNNs) have been demonstrated to be powerful in modeling graph-structured data. However, training GNNs requires abundant task-specific labeled data, which is often arduously expensive to obtain. One effective way to reduce the labeling effort is to pre-train an expressive GNN model on unlabelled data with self-supervision and then transfer the learned model to downstream tasks with only a few labels. In this paper, we present the GPT-GNN framework to initialize GNNs by generative pre-training. GPT-GNN introduces a self-supervised attributed graph generation task to pre-train a GNN so that it can capture the structural and semantic properties of the graph. We factorize the likelihood of graph generation into two components: 1) attribute generation and 2) edge generation. By modeling both components, GPT-GNN captures the inherent dependency between node attributes and graph structure during the generative process. Comprehensive experiments on the billion-scale open academic graph and Amazon recommendation data demonstrate that GPT-GNN significantly outperforms state-of-the-art GNN models without pre-training by up to 9.1% across various downstream tasks?","[{""name"":""Ziniu Hu"",""id"":""/profile/99659171147""},{""name"":""Yuxiao Dong"",""id"":""/profile/81556305356""},{""name"":""Kuansan Wang"",""id"":""/profile/81451595141""},{""name"":""Kai-Wei Chang"",""id"":""/profile/99659574556""},{""name"":""Yizhou Sun"",""id"":""/profile/81548005095""},{""name"":""Ziniu Hu"",""id"":""/profile/99659171147""},{""name"":""Yuxiao Dong"",""id"":""/profile/81556305356""},{""name"":""Kuansan Wang"",""id"":""/profile/81451595141""},{""name"":""Kai-Wei Chang"",""id"":""/profile/99659574556""},{""name"":""Yizhou Sun"",""id"":""/profile/81548005095""}]","[""Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. 2013. Spectral networks and locally connected networks on graphs. arXiv:1312.6203 (2013).Google Scholar"",""Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey E. Hinton. 2020. A Simple Framework for Contrastive Learning of Visual Representations. arxiv:2002.05709 (2020).Google Scholar"",""Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. Imagenet: A large-scale hierarchical image database. (2009).Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In NAACL 2019 .Google Scholar"",""Jeff Donahue, Yangqing Jia, Oriol Vinyals, Judy Hoffman, Ning Zhang, Eric Tzeng, and Trevor Darrell. 2014. Decaf: A deep convolutional activation feature for generic visual recognition. In ICML 2014 .Google Scholar"",""Yuxiao Dong, Nitesh V Chawla, and Ananthram Swami. 2017. metapath2vec: Scalable Representation Learning for Heterogeneous Networks. In KDD 2017.Google ScholarDigital Library"",""Yuxiao Dong, Ziniu Hu, Kuansan Wang, Yizhou Sun, and Jie Tang. 2020. Heterogeneous Network Representation Learning. In IJCAI .Google Scholar"",""Matthias Fey and Jan Eric Lenssen. 2019. Fast Graph Representation Learning with PyTorch Geometric. ICLR Workshop (2019).Google Scholar"",""Justin Gilmer, Samuel S. Schoenholz, Patrick F. Riley, Oriol Vinyals, and George E. Dahl. 2017. Neural Message Passing for Quantum Chemistry. In ICML 2017 .Google Scholar"",""Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra Malik. 2014. Rich feature hierarchies for accurate object detection and semantic segmentation. In CVPR 2014 .Google ScholarDigital Library"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In KDD 2016 .Google ScholarDigital Library"",""William L. Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive Representation Learning on Large Graphs. In NeurIPS 2017 .Google Scholar"",""Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. 2019. Momentum contrast for unsupervised visual representation learning. arXiv:1911.05722 (2019).Google Scholar"",""Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay S. Pande, and Jure Leskovec. 2020 b. Strategies for Pre-training Graph Neural Networks. In ICLR 2020 .Google Scholar"",""Ziniu Hu, Yuxiao Dong, Kuansan Wang, and Yizhou Sun. 2020 a. Heterogeneous Graph Transformer. In WWW 2020 .Google Scholar"",""Thomas N. Kipf and Max Welling. 2016. Variational Graph Auto-Encoders. arXiv:1611.07308 (2016).Google Scholar"",""Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In ICLR 2017 .Google Scholar"",""Renjie Liao, Yujia Li, Yang Song, Shenlong Wang, William L. Hamilton, David Duvenaud, Raquel Urtasun, and Richard S. Zemel. 2019. Efficient Graph Generation with Graph Recurrent Attention Networks. In NeurIPS 2019 .Google Scholar"",""Tie-Yan Liu. 2011. Learning to Rank for Information Retrieval .Springer.Google Scholar"",""Ilya Loshchilov and Frank Hutter. 2017. SGDR: Stochastic Gradient Descent with Warm Restarts. In ICLR 2017 .Google Scholar"",""Ilya Loshchilov and Frank Hutter. 2019. Decoupled Weight Decay Regularization. In ICLR 2019 .Google Scholar"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In NIPS 2013 .Google Scholar"",""Jianmo Ni, Jiacheng Li, and Julian J. McAuley. 2019. Justifying Recommendations using Distantly-Labeled Reviews and Fine-Grained Aspects. In EMNLP 2019 .Google Scholar"",""Deepak Pathak, Philipp Kr\""a henbü hl, Jeff Donahue, Trevor Darrell, and Alexei A. Efros. 2016. Context Encoders: Feature Learning by Inpainting. In CVPR 2016 .Google Scholar"",""Jeffrey Pennington, Richard Socher, and Christopher Manning. 2014. Glove: Global vectors for word representation. In EMNLP 2014 .Google ScholarCross Ref"",""Jiezhong Qiu, Yuxiao Dong, Hao Ma, Jian Li, Kuansan Wang, and Jie Tang. 2018. Network embedding as matrix factorization: Unifying deepwalk, line, pte, and node2vec. In WSDM '18 . 459--467.Google ScholarDigital Library"",""Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language Models are Unsupervised Multitask Learners. (2019).Google Scholar"",""Michael Sejr Schlichtkrull, Thomas N. Kipf, Peter Bloem, Rianne van den Berg, Ivan Titov, and Max Welling. 2018. Modeling Relational Data with Graph Convolutional Networks. In ESWC 2018 .Google Scholar"",""Fan-Yun Sun, Jordan Hoffmann, Vikas Verma, and Jian Tang. 2020. InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization. In ICLR 2020 .Google Scholar"",""Yizhou Sun and Jiawei Han. 2012. Mining Heterogeneous Information Networks: Principles and Methodologies .Morgan \u0026 Claypool Publishers.Google Scholar"",""Yizhou Sun, Jiawei Han, Xifeng Yan, Philip S. Yu, and Tianyi Wu. 2011. Pathsim: Meta path-based top-k similarity search in heterogeneous information networks. In VLDB 2011 .Google ScholarDigital Library"",""Yizhou Sun, Brandon Norick, Jiawei Han, Xifeng Yan, Philip S. Yu, and Xiao Yu. 2012. Integrating meta-path selection with user-guided object clustering in heterogeneous information networks. In KDD 2012 .Google ScholarDigital Library"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. In WWW 2015 .Google ScholarDigital Library"",""Jie Tang, Jing Zhang, Limin Yao, Juanzi Li, Li Zhang, and Zhong Su. 2008. Arnetminer: extraction and mining of academic social networks. In KDD 2008 .Google ScholarDigital Library"",""A\""a ron van den Oord, Yazhe Li, and Oriol Vinyals. 2018. Representation Learning with Contrastive Predictive Coding. arXiv:1807.03748 (2018).Google Scholar"",""Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò , and Yoshua Bengio. 2018. Graph Attention Networks. In ICLR 2018 .Google Scholar"",""Petar Velickovic, William Fedus, William L. Hamilton, Pietro Liò, Yoshua Bengio, and R. Devon Hjelm. 2019. Deep Graph Infomax. In ICLR 2019 .Google Scholar"",""Kuansan Wang, Zhihong Shen, Chiyuan Huang, Chieh-Han Wu , Yuxiao Dong, and Anshul Kanakia. 2020. Microsoft Academic Graph: When experts are not enough. Quantitative Science Studies , Vol. 1, 1 (2020), 396--413.Google ScholarCross Ref"",""Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, and Philip S. Yu. 2019. Heterogeneous Graph Attention Network. In WWW 2019 .Google Scholar"",""Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, and Jamie Brew. 2019. Transformers: State-of-the-art Natural Language Processing. arxiv: cs.CL/1910.03771Google Scholar"",""Zhilin Yang, Zihang Dai, Yiming Yang, Jaime G. Carbonell, Ruslan Salakhutdinov, and Quoc V. Le. 2019. XLNet: Generalized Autoregressive Pretraining for Language Understanding. In NeurIPS 2019 .Google Scholar"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L. Hamilton, and Jure Leskovec. 2018. Graph Convolutional Neural Networks for Web-Scale Recommender Systems. In KDD 2018 .Google Scholar"",""Jiaxuan You, Rex Ying, Xiang Ren, William L. Hamilton, and Jure Leskovec. 2018. GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models. In ICML 2018 .Google Scholar"",""Fanjin Zhang, Xiao Liu, Jie Tang, Yuxiao Dong, Peiran Yao, Jie Zhang, Xiaotao Gu, Yan Wang, Bin Shao, Rui Li, and Kuansan Wang. 2019. OAG: Toward Linking Large-scale Heterogeneous Entity Graphs. In KDD 2019 .Google ScholarDigital Library"",""Difan Zou, Ziniu Hu, Yewen Wang, Song Jiang, Yizhou Sun, and Quanquan Gu. 2019. Layer-Dependent Importance Sampling for Training Deep and Large Graph Convolutional Networks. In NeurIPS 2019 .Google Scholar""]"
https://doi.org/10.1145/3394486.3403238,Parameterized Correlation Clustering in Hypergraphs and Bipartite Graphs,"Motivated by applications in community detection and dense subgraph discovery, we consider new clustering objectives in hypergraphs and bipartite graphs. These objectives are parameterized by one or more resolution parameters in order to enable diverse knowledge discovery in complex data.For both hypergraph and bipartite objectives, we identify relevant parameter regimes that are equivalent to existing objectives and share their (polynomial-time) approximation algorithms. We first show that our parameterized hypergraph correlation clustering objective is related to higher-order notions of normalized cut and modularity in hypergraphs. It is further amenable to approximation algorithms via hyperedge expansion techniques.Our parameterized bipartite correlation clustering objective generalizes standard unweighted bipartite correlation clustering, as well as the bicluster deletion problem. For a certain choice of parameters it is also related to our hypergraph objective. Although in general it is NP-hard, we highlight a parameter regime for the bipartite objective where the problem reduces to the bipartite matching problem and thus can be solved in polynomial time. For other parameter settings, we present several approximation algorithms using linear program rounding techniques. These results allow us to introduce the first constant-factor approximation for bicluster deletion, the task of removing a minimum number of edges to partition a bipartite graph into disjoint bi-cliques.In several experimental results, we highlight the flexibility of our framework and the diversity of results that can be obtained in different parameter settings. This includes clustering bipartite graphs across a range of parameters, detecting motif-rich clusters in an email network and a food web, and forming clusters of retail products in a product review hypergraph, that are highly correlated with known product categories.","[{""name"":""Nate Veldt"",""id"":""/profile/99659125447""},{""name"":""Anthony Wirth"",""id"":""/profile/81100261305""},{""name"":""David F. Gleich"",""id"":""/profile/81367596421""},{""name"":""Nate Veldt"",""id"":""/profile/99659125447""},{""name"":""Anthony Wirth"",""id"":""/profile/81100261305""},{""name"":""David F. Gleich"",""id"":""/profile/81367596421""}]","[""Sameer Agarwal, Jongwoo Lim, Lihi Zelnik-Manor, Pietro Perona, David Kriegman, and Serge Belongie. 2005. Beyond Pairwise Clustering (CVPR '05).Google Scholar"",""Nir. Ailon, Noa. Avigdor-Elgrabli, Edo. Liberty, and Anke. van Zuylen. 2012. Improved Approximation Algorithms for Bipartite Correlation Clustering. SIAM J. Comput., Vol. 41, 5 (2012), 1110--1121.Google ScholarCross Ref"",""Nir Ailon, Moses Charikar, and Alantha Newman. 2008. Aggregating inconsistent information: ranking and clustering. Journal of the ACM (JACM), Vol. 55, 5 (2008), 23.Google ScholarDigital Library"",""Ilya Amburg, Nate Veldt, and Austin R Benson. Clustering in graphs and hypergraphs with categorical edge labels (WWW '20).Google Scholar"",""Noga Amit. 2004. The bicluster graph editing problem. Master's thesis. Tel Aviv University.Google Scholar"",""A Arenas, A Ferná ndez, S Fortunato, and S Gó mez. 2008b. Motif-based communities in complex networks. Journal of Physics A: Mathematical and Theoretical, Vol. 41, 22 (2008).Google ScholarCross Ref"",""A Arenas, A Ferná ndez, and S Gó mez. 2008a. Analysis of the structure of complex networks at different resolution levels. New Journal of Physics, Vol. 10, 5 (2008).Google ScholarCross Ref"",""M. Asteris, A. Kyrillidis, D. Papailiopoulos, and A. Dimakis. Bipartite correlation clustering: Maximizing agreements (AISTATS '16).Google Scholar"",""Nikhil Bansal, Avrim Blum, and Shuchi Chawla. 2004. Correlation Clustering. Machine Learning, Vol. 56 (2004), 89--113.Google ScholarDigital Library"",""Austin R. Benson, David F. Gleich, and Jure Leskovec. 2016. Higher-order organization of complex networks. Science, Vol. 353, 6295 (2016), 163--166.Google Scholar"",""Vincent D Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefebvre. 2008. Fast unfolding of communities in large networks. Journal of Statistical Mechanics: Theory and Experiment, Vol. 2008, 10 (2008), P10008.Google ScholarCross Ref"",""Justin Brickell, Inderjit S. Dhillon, Suvrit Sra, and Joel A. Tropp. 2008. The Metric Nearness Problem. SIAM J. Matrix Anal. Appl., Vol. 30, 1 (2008), 375--396.Google ScholarDigital Library"",""Ü mit V. cC atalyü rek and Cevdet Aykanat. 1999. Hypergraph-Partitioning Based Decomposition for Parallel Sparse-Matrix Vector Multiplication. IEEE Transactions on Parallel and Distributed Systems, Vol. 10, 7 (1999), 673--693.Google ScholarDigital Library"",""Moses Charikar, Venkatesan Guruswami, and Anthony Wirth. 2005. Clustering with qualitative information. J. Comput. System Sci., Vol. 71, 3 (2005), 360 -- 383. Learning Theory 2003.Google ScholarDigital Library"",""Shuchi Chawla, Konstantin Makarychev, Tselil Schramm, and Grigory Yaroslavtsev. 2015. Near optimal LP rounding algorithm for correlation clustering on complete and complete k-partite graphs (STOC '15). ACM.Google Scholar"",""J.-C. Delvenne, S. N. Yaliraki, and M. Barahona. 2010. Stability of graph communities across time scales. Proceedings of the National Academy of Sciences, Vol. 107, 29 (2010), 12755--12760.Google ScholarCross Ref"",""Erik D. Demaine, Dotan Emanuel, Amos Fiat, and Nicole Immorlica. 2006. Correlation clustering in general weighted graphs. Theoretical Computer Science, Vol. 361, 2 (2006), 172 -- 187. Approximation and Online Algorithms.Google ScholarDigital Library"",""Inderjit S. Dhillon, Yuqiang Guan, and Brian Kulis. 2007. Weighted Graph Cuts without Eigenvectors A Multilevel Approach. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 29, 11 (2007), 1944--1957.Google ScholarDigital Library"",""Santo Fortunato and Marc Barthélemy. 2007. Resolution limit in community detection. Proceedings of the National Academy of Sciences, Vol. 104, 1 (2007), 36--41.Google ScholarCross Ref"",""Takuro Fukunaga. 2018. LP-Based Pivoting Algorithm for Higher-Order Correlation Clustering. In Computing and Combinatorics .Google Scholar"",""David F. Gleich, Nate Veldt, and Anthony Wirth. 2018. Correlation Clustering Generalized (ISAAC 2018).Google Scholar"",""J. Gong and Sung Kyu Lim. 1998. Multiway partitioning with pairwise movement (ICAD '98).Google Scholar"",""S. W. Hadley, B. L. Mark, and A. Vannelli. 1992. An efficient eigenvector approach for finding netlist partitions. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, Vol. 11, 7 (1992).Google ScholarDigital Library"",""Matthias Hein, Simon Setzer, Leonardo Jost, and Syama Sundar Rangapuram. 2013. The Total Variation on Hypergraphs - Learning on Hypergraphs Revisited (NIPS'13).Google Scholar"",""Edmund Ihler, Dorothea Wagner, and Frank Wagner. 1993. Modeling Hypergraphs by Graphs with the Same Mincut Properties. Inf. Process. Lett., Vol. 45, 4 (1993).Google Scholar"",""Lucas G. S. Jeub, Marya Bazzi, Inderjit S. Jutla, and Peter J. Mucha. 2011--2017. A generalized Louvain method for community detection implemented in MATLAB. (2011--2017). http://netwiki.amath.unc.edu/GenLouvainGoogle Scholar"",""Bogumił Kami'nski, Valérie Poulin, Paweł Prałat, Przemysław Szufel, and Francc ois Théberge. 2019. Clustering via hypergraph modularity. PloS one, Vol. 14, 11 (2019).Google Scholar"",""George Karypis and Vipin Kumar. 1998. A Fast and High Quality Multilevel Scheme for Partitioning Irregular Graphs. SIAM J. Sci. Comput., Vol. 20, 1 (1998), 359--392.Google ScholarDigital Library"",""George Karypis and Vipin Kumar. 1999. Multilevel K-way Hypergraph Partitioning (DAC '99). ACM, 343--348.Google Scholar"",""Sungwoong Kim, Sebastian Nowozin, Pushmeet Kohli, and Chang D. Yoo. 2011. Higher-Order Correlation Clustering for Image Segmentation (NIPS '11).Google Scholar"",""Christine Klymko, David F. Gleich, and Tamara G. Kolda. 2014. Using Triangles to Improve Community Detection in Directed Networks. In The Second ASE International Conference on Big Data Science and Computing, BigDataScience .Google Scholar"",""Tarun Kumar, Sankaran Vaidyanathan, Harini Ananthapadmanabhan, Srinivasan Parthasarathy, and Balaraman Ravindran. 2020. A New Measure of Modularity in Hypergraphs: Theoretical Insights and Implications for Effective Clustering. In Complex Networks and Their Applications VIII. Springer International Publishing.Google Scholar"",""Jure Leskovec, Jon Kleinberg, and Christos Faloutsos. 2007. Graph evolution: Densification and shrinking diameters. ACM Transactions on Knowledge Discovery from Data (TKDD), Vol. 1, 1 (2007), 2.Google Scholar"",""Pan Li, H. Dau, Gregory J. Puleo, and Olgica Milenkovic. 2017. Motif clustering and overlapping clustering for social network analysis (INFOCOM '17). 1--9.Google Scholar"",""Pan Li and Olgica Milenkovic. 2017. Inhomogeneous Hypergraph Clustering with Applications (NIPS '17). 2308--2318.Google Scholar"",""Pan Li and Olgica Milenkovic. 2018. Submodular Hypergraphs: p-Laplacians, Cheeger Inequalities and Spectral Clustering (ICML '18). 3020--3029.Google Scholar"",""Pan Li, Gregory. J. Puleo, and Olgica. Milenkovic. 2019. Motif and Hypergraph Correlation Clustering. IEEE Transactions on Information Theory (2019), 1--1.Google Scholar"",""Tom Michoel and Bruno Nachtergaele. 2012. Alignment and integration of complex networks by hypergraph-based spectral clustering. Physical Review E, Vol. 86 (2012), 056111. Issue 5.Google ScholarCross Ref"",""Mark EJ Newman and Michelle Girvan. 2004. Finding and evaluating community structure in networks. Physical review E, Vol. 69, 026113 (2004).Google Scholar"",""Jianmo Ni, Jiacheng Li, and Julian McAuley. 2019. Justifying Recommendations using Distantly-Labeled Reviews and Fine-Grained Aspects (EMNLP-IJCNLP '19). 188--197.Google Scholar"",""Leto Peel, Daniel B. Larremore, and Aaron Clauset. 2017. The ground truth about metadata and community detection in networks. Science Advances, Vol. 3, 5 (2017).Google Scholar"",""Gregory. J. Puleo and Olgica. Milenkovic. 2018. Correlation Clustering and Biclustering With Locally Bounded Errors. IEEE Transactions on Information Theory, Vol. 64, 6 (June 2018), 4105--4119.Google ScholarCross Ref"",""Jörg Reichardt and Stefan Bornholdt. 2004. Detecting Fuzzy Community Structures in Complex Networks with a Potts Model. Phys. Rev. Lett., Vol. 93 (2004), 218701.Google ScholarCross Ref"",""Cameron Ruggles, Nate Veldt, and David F. Gleich. A Parallel Projection Method for Metric Constrained Optimization (SIAM CSC '20).Google Scholar"",""Satu Elisa Schaeffer. 2007. Graph clustering. Computer Science Review (2007).Google Scholar"",""Ron Shamir, Roded Sharan, and Dekel Tsur. 2004. Cluster graph modification problems. Discrete Applied Mathematics, Vol. 144 (2004), 173--182.Google ScholarDigital Library"",""Jianbo Shi and J. Malik. 2000. Normalized cuts and image segmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 22, 8 (2000), 888--905.Google ScholarDigital Library"",""Rishi Sonthalia and Anna C. Gilbert. 2020. Project and Forget: Solving Large-Scale Metric Constrained Problems. (2020). arxiv: cs.LG/2005.03853Google Scholar"",""Ze Tian, TaeHyun Hwang, and Rui Kuang. 2009. A hypergraph-based learning algorithm for classifying gene expression and arrayCGH data with prior knowledge. Bioinformatics, Vol. 25, 21 (2009), 2831--2838.Google ScholarDigital Library"",""V. A. Traag, P. Van Dooren, and Y. Nesterov. 2011. Narrow scope for resolution-limit-free community detection. Phys. Rev. E, Vol. 84 (Jul 2011), 016114. Issue 1.Google ScholarCross Ref"",""Charalampos E. Tsourakakis, Jakub Pachocki, and Michael Mitzenmacher. 2017. Scalable Motif-aware Graph Clustering (WWW '17). 1451--1460.Google Scholar"",""Anke van Zuylen and David P. Williamson. 2009. Deterministic Pivoting Algorithms for Constrained Ranking and Clustering Problems. Mathematics of Operations Research, Vol. 34, 3 (2009), 594--620.Google ScholarDigital Library"",""Nate Veldt, Austin R. Benson, and Jon Kleinberg. 2020. Hypergraph Cuts with General Splitting Functions. (2020). arxiv: cs.DS/2001.02817Google Scholar"",""Nate Veldt, David F. Gleich, and Anthony Wirth. 2018. A Correlation Clustering Framework for Community Detection (WWW '18). 439--448.Google Scholar"",""Nate Veldt, David F. Gleich, and Anthony Wirth. 2019 a. Learning Resolution Parameters for Graph Clustering (WWW '19).Google Scholar"",""Nate Veldt, David F. Gleich, Anthony Wirth, and James Saunderson. 2019 b. Metric-Constrained Optimization for Graph Clustering Algorithms. SIAM Journal on Mathematics of Data Science, Vol. 1, 2 (2019), 333--355.Google ScholarCross Ref"",""Nate Veldt, Anthony Wirth, and David F. Gleich. 2020. Parameterized Correlation Clustering in Hypergraphs and Bipartite Graphs. (2020). arxiv: cs.DS/2002.09460Google Scholar"",""Hao Yin, Austin R. Benson, and Jure Leskovec. 2018. Higher-order clustering in networks. Phys. Rev. E, Vol. 97 (2018), 052306. Issue 5.Google ScholarCross Ref"",""Hao Yin, Austin R Benson, Jure Leskovec, and David F Gleich. 2017. Local higher-order graph clustering (KDD '17). 555--564.Google Scholar"",""Dengyong Zhou, Jiayuan Huang, and Bernhard Schölkopf. 2006. Learning with Hypergraphs: Clustering, Classification, and Embedding (NIPS '06).Google Scholar"",""J. Y. Zien, M. D. F. Schlag, and P. K. Chan. 1999. Multilevel spectral hypergraph partitioning with arbitrary vertex sizes. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, Vol. 18, 9 (1999), 1389--1399.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403239,Prioritized Restreaming Algorithms for Balanced Graph Partitioning,"Balanced graph partitioning is a critical step for many large-scale distributed computations with relational data. As graph datasets have grown in size and density, a range of highly-scalable balanced partitioning algorithms have appeared to meet varied demands across different domains. As the starting point for the present work, we observe that two recently introduced families of iterative partitioners---those based on restreaming and those based on balanced label propagation (including Facebook's Social Hash Partitioner)---can be viewed through a common modular framework of design decisions. With the help of this modular perspective, we find that a key combination of design decisions leads to a novel family of algorithms with notably better empirical performance than any existing highly-scalable algorithm on a broad range of real-world graphs. The resulting prioritized restreaming algorithms employ a constraint management strategy based on multiplicative weights, borrowed from the restreaming literature, while adopting notions of priority from balanced label propagation to optimize the ordering of the streaming process. Our experimental results consider a range of stream orders, where a dynamic ordering based on what we call ambivalence is broadly the most performative in terms of the cut quality of the resulting balanced partitions, with a static ordering based on degree being nearly as good.","[{""name"":""Amel Awadelkarim"",""id"":""/profile/99659573127""},{""name"":""Johan Ugander"",""id"":""/profile/81548562356""},{""name"":""Amel Awadelkarim"",""id"":""/profile/99659573127""},{""name"":""Johan Ugander"",""id"":""/profile/81548562356""}]","[""K. Andreev and H. Racke. 2006. Balanced Graph Partitioning. Theory of Computing Systems, Vol. 39, 6 (2006), 929 -- 939.Google ScholarDigital Library"",""M. Armbruster, M. Fügenschuh, C. Helmberg, and A. Martin. 2008. A Comparative Study of Linear and Semidefinite Branch-and-Cut Methods for Solving the Minimum Graph Bisection Problem. In IPCO. 112--124.Google Scholar"",""Kevin Aydin, MohammadHossein Bateni, and Vahab Mirrokni. 2019. Distributed balanced partitioning via linear embedding. Algorithms, Vol. 12, 8 (2019), 162.Google ScholarCross Ref"",""MohammadHossein Bateni, Soheil Behnezhad, Mahsa Derakhshan, MohammadTaghi Hajiaghayi, Raimondas Kiveris, Silvio Lattanzi, and Vahab Mirrokni. 2017. Affinity clustering: Hierarchical clustering at scale. In NIPS. 6864--6874.Google Scholar"",""L. Brunetta, M. Conforti, and G. Rinaldi. 1997. A branch-and-cut algorithm for the equicut problem. Mathematical Programming, Vol. 78, 2 (1997), 243--263.Google ScholarDigital Library"",""A. Bulucc, H. Meyerhenke, I. Safro, P. Sanders, and C. Schulz. 2013. Recent Advances in Graph Partitioning. (2013). arxiv: 1311.3144Google Scholar"",""U. V. Catalyurek and C. Aykanat. 1999. Hypergraph-partitioning-based decomposition for parallel sparse-matrix vector multiplication. IEEE Transactions on Parallel and Distributed Systems, Vol. 10, 7 (July 1999), 673--693.Google ScholarDigital Library"",""C. Chevalier and I. Safro. 2009. Comparison of Coarsening Schemes for Multilevel Graph Partitioning. In Learning and Intelligent Optimization. 191--205.Google Scholar"",""Q. Duong, S. Goel, J. Hofman, and S. Vassilvitskii. 2013. Sharding Social Networks. In WSDM. New York, NY, USA, 223--232.Google Scholar"",""C. M. Fiduccia and R. M. Mattheyses. 1982. A Linear-Time Heuristic for Improving Network Partitions. In 19th Design Automation Conference. 175--181.Google Scholar"",""J. E Gonzalez, Y. Low, H. Gu, D. Bickson, and C. Guestrin. 2012. Powergraph: Distributed graph-parallel computation on natural graphs. In USENIX OSDI.Google Scholar"",""I. Kabiljo, B. Karrer, M. Pundir, S. Pupyrev, and A. Shalita. 2017. Social hash partitioner: a scalable distributed hypergraph partitioner. VLDB, Vol. 10, 11 (2017).Google Scholar"",""George Karypis and Vipin Kumar. 1998 a. A fast and high quality multilevel scheme for partitioning irregular graphs. SIAM J. Sci. Comput., Vol. 20, 1 (1998), 359--392.Google ScholarCross Ref"",""G. Karypis and V. Kumar. 1998 b. Multilevel k-way Partitioning Scheme for Irregular Graphs. J. Parallel and Distrib. Comput., Vol. 48, 1 (1998), 96 -- 129.Google ScholarDigital Library"",""B. W. Kernighan and S. Lin. 1970. An efficient heuristic procedure for partitioning graphs. The Bell System Technical Journal, Vol. 49, 2 (Feb 1970), 291--307.Google ScholarCross Ref"",""D. Lasalle and G. Karypis. 2013. Multi-threaded Graph Partitioning. In 2013 IEEE 27th International Symposium on Parallel and Distributed Processing. 225--236.Google Scholar"",""Jure Leskovec and Eric Horvitz. 2008. Planetary-Scale Views on an Instant-Messaging Network. In WWW. 915--924.Google Scholar"",""Jure Leskovec and Andrej Krevl. 2014. SNAP Datasets: Stanford Large Network Dataset Collection. http://snap.stanford.edu/data.Google Scholar"",""Jure Leskovec, Kevin J Lang, Anirban Dasgupta, and Michael W Mahoney. 2009. Community structure in large networks: Natural cluster sizes and the absence of large well-defined clusters. Internet Mathematics, Vol. 6, 1 (2009), 29--123.Google ScholarCross Ref"",""G. Malewicz, M. H. Austern, A. J.C Bik, J. C. Dehnert, I. Horn, N. Leiser, and G. Czajkowski. 2010. Pregel: A System for Large-Scale Graph Processing. In SIGMOD.Google ScholarDigital Library"",""C. Martella, D. Logothetis, A. Loukas, and G. Siganos. 2017. Spinner: Scalable Graph Partitioning in the Cloud. In ICDE. 1083--1094.Google Scholar"",""H. Meyerhenke, B. Monien, and S. Schamberger. 2006. Accelerating shape optimizing load balancing for parallel FEM simulations by algebraic multigrid. In IPDPS, Vol. 2006. 10 pp.Google Scholar"",""H. Meyerhenke, B. Monien, and S. Schamberger. 2009. Graph partitioning and disturbed diffusion. Parallel Comput., Vol. 35, 10 (2009), 544 -- 569.Google ScholarDigital Library"",""J. Nishimura and J. Ugander. 2013. Restreaming Graph Partitioning: Simple Versatile Algorithms for Advanced Balancing. In KDD. 1106--1114.Google Scholar"",""V. Osipov and P. Sanders. 2010. n-Level Graph Partitioning. CoRR (2010). arxiv: 1004.4024Google Scholar"",""Anil Pacaci and M. Tamer Özsu. 2019. Experimental Analysis of Streaming Algorithms for Graph Partitioning. In SIGMOD. 1375--1392.Google Scholar"",""F. Pellegrini. 2007. A Parallelisable Multi-level Banded Diffusion Scheme for Computing Balanced Partitions with Smooth Boundaries. In Euro-Par 2007 Parallel Processing. 195--204.Google Scholar"",""U. Raghavan, R. Albert, and S. Kumara. 2007. Near linear time algorithm to detect community structures in large-scale networks. Physical Review E (2007), 11.Google Scholar"",""Erzsébet Regan and Albert-Laszlo Barabasi. 2003. Hierarchical Organization in Complex Networks. Physical Review E, Vol. 67 (03 2003), 026112.Google Scholar"",""Peter Sanders and Christian Schulz. 2011. Engineering multilevel graph partitioning algorithms. In European Symposium on Algorithms. Springer, 469--480.Google ScholarCross Ref"",""Mohamed Sarwat, Sameh Elnikety, Yuxiong He, and Gabriel Kliot. 2012. Horton: Online Query Execution Engine for Large Distributed Graphs. In ICDE.Google Scholar"",""Venu Satuluri, Srinivasan Parthasarathy, and Yiye Ruan. 2011. Local Graph Sparsification for Scalable Clustering. In SIGMOD. 721--732.Google Scholar"",""M. Saveski, J. Pouget-Abadie, G. Saint-Jacques, W. Duan, S. Ghosh, Y. Xu, and E. Airoldi. 2017. Detecting network effects: Randomizing over randomized experiments. In KDD. 1027--1035.Google Scholar"",""A. Shalita, B. Karrer, I. Kabiljo, A. Sharma, A. Presta, A. Adcock, H. Kllapi, and M. Stumm. 2016. Social Hash: An Assignment Framework for Optimizing Distributed Systems Operations on Social Networks. In USENIX NSDI. 455--468.Google Scholar"",""Bin Shao, Haixun Wang, and Yatao Li. 2013. Trinity: A Distributed Graph Engine on a Memory Cloud. In SIGMOD.Google Scholar"",""Isabelle Stanton. 2014. Streaming balanced graph partitioning algorithms for random graphs. In SODA. 1287--1301.Google Scholar"",""Isabelle Stanton and Gabriel Kliot. 2012. Streaming Graph Partitioning for Large Distributed Graphs. In KDD. 1222--1230.Google Scholar"",""C. E. Tsourakakis, C. Skantsidis, B. Radunovic, and M. Vojnovic. 2014. FENNEL: Streaming Graph Partitioning for Massive Scale Graphs. In WSDM.Google ScholarDigital Library"",""J. Ugander and L. Backstrom. 2013. Balanced Label Propagation for Partitioning Massive Graphs. In WSDM. 507--516.Google Scholar"",""J. Ugander, B. Karrer, L. Backstrom, and J. Kleinberg. 2013. Graph cluster randomization: Network exposure to multiple universes. In KDD. 329--337.Google Scholar"",""J. Ugander, B. Karrer, L. Backstrom, and C. Marlow. 2011. The Anatomy of the Facebook Social Graph. (2011). arxiv: 1111.4503Google Scholar"",""S. Vigna. 2015. A weighted correlation index for rankings with ties. In WWW.Google Scholar"",""E. Voorhees. 2002. Evaluation by Highly Relevant Documents. In SIGIR Forum.Google Scholar"",""Duncan J. Watts and Steven H. Strogatz. 1998. Collective dynamics of 'small-world' networks. Nature, Vol. 393, 6684 (1998), 440--442.Google Scholar"",""Xiaojin Zhu and Zoubin Ghahramani. 2002. Learning from Labeled and Unlabeled Data with Label Propagation. Technical Report. Carnegie Mellon University CALD.Google Scholar""]"
https://doi.org/10.1145/3394486.3403240,A Non-Iterative Quantile Change Detection Method in Mixture Model with Heavy-Tailed Components,"Estimating parameters of mixture model has wide applications ranging from classification problems to estimating of complex distributions. Most of the current literature on estimating the parameters of the mixture densities are based on iterative Expectation Maximization (EM) type algorithms which require the use of either taking expectations over the latent label variables or generating samples from the conditional distribution of such latent labels using the Bayes rule. Moreover, when the number of components is unknown, the problem becomes computationally more demanding due to well-known label switching issues [28]. In this paper, we propose a robust and quick approach based on change-point methods to determine the number of mixture components that works for almost any location-scale families even when the components are heavy tailed (e.g., Cauchy). We present several numerical illustrations by comparing our method with some of popular methods available in the literature using simulated data and real case studies. The proposed method is shown be as much as 500 times faster than some of the competing methods and are also shown to be more accurate in estimating the mixture distributions by goodness-of-fit tests.","[{""name"":""Yuantong Li"",""id"":""/profile/99659575274""},{""name"":""Qi Ma"",""id"":""/profile/99659573517""},{""name"":""Sujit K. Ghosh"",""id"":""/profile/81490665017""},{""name"":""Yuantong Li"",""id"":""/profile/99659575274""},{""name"":""Qi Ma"",""id"":""/profile/99659573517""},{""name"":""Sujit K. Ghosh"",""id"":""/profile/81490665017""}]","[""Murray Aitkin, Duy Vu, and Brian Francis. 2015. A new Bayesian approach for determining the number of components in a finite mixture. Metron, Vol. 73, 2 (2015), 155--176.Google ScholarCross Ref"",""Hirotugu Akaike. 1987. Factor analysis and AIC. In Selected papers of hirotugu akaike. Springer, 371--386.Google Scholar"",""Felipe M Aparicio and Javier Estrada. 2001. Empirical distributions of stock returns: European securities markets, 1990--95. The European Journal of Finance, Vol. 7, 1 (2001), 1--21.Google ScholarCross Ref"",""Tatiana Benaglia, Didier Chauveau, and David R Hunter. 2009. An EM-like algorithm for semi-and nonparametric estimation in multivariate mixtures. Journal of Computational and Graphical Statistics, Vol. 18, 2 (2009), 505--526.Google ScholarCross Ref"",""Tatiana Benaglia, Didier Chauveau, and David R Hunter. 2011. Bandwidth selection in an EM-like algorithm for nonparametric multivariate mixtures. In Nonparametric Statistics And Mixture Models: A Festschrift in Honor of Thomas P Hettmansperger. World Scientific, 15--27.Google Scholar"",""Kenneth P Burnham and David R Anderson. 2004. Multimodel inference: understanding AIC and BIC in model selection. Sociological methods \u0026 research, Vol. 33, 2 (2004), 261--304.Google Scholar"",""Bradley P Carlin and Siddhartha Chib. 1995. Bayesian model choice via Markov chain Monte Carlo methods. Journal of the Royal Statistical Society: Series B (Methodological), Vol. 57, 3 (1995), 473--484.Google ScholarCross Ref"",""Arthur P Dempster, Nan M Laird, and Donald B Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. Journal of the royal statistical society. Series B (methodological) (1977), 1--38.Google Scholar"",""Mathias Drton and Martyn Plummer. 2017. A Bayesian information criterion for singular models. Journal of the Royal Statistical Society: Series B (Statistical Methodology), Vol. 79, 2 (2017), 323--380.Google ScholarCross Ref"",""Nader Ebrahimi and Sujit K Ghosh. 2001. Bayesian and frequentist methods in change-point problems. Handbook of statistics, Vol. 20 (2001), 777--787.Google Scholar"",""Paul Fearnhead. 2005. Direct simulation for discrete mixture distributions. Statistics and Computing, Vol. 15, 2 (2005), 125--133.Google ScholarDigital Library"",""DAS Fraser. 1963. On sufficiency and the exponential family. Journal of the Royal Statistical Society: Series B (Methodological), Vol. 25, 1 (1963), 115--123.Google ScholarCross Ref"",""Stuart Geman and Donald Geman. 1984. Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. IEEE Transactions on pattern analysis and machine intelligence 6 (1984), 721--741.Google ScholarDigital Library"",""John Geweke. 2007. Interpretation and inference in mixture models: Simple MCMC works. Computational Statistics \u0026 Data Analysis, Vol. 51, 7 (2007), 3529--3550.Google ScholarDigital Library"",""Sanford J Grossman and Robert J Shiller. 1980. The determinants of the variability of stock market prices.Google Scholar"",""Ling Hu. 2006. Dependence patterns across financial markets: a mixed copula approach. Applied financial economics, Vol. 16, 10 (2006), 717--729.Google Scholar"",""JD Humphrey and KR Rajagopal. 2002. A constrained mixture model for growth and remodeling of soft tissues. Mathematical models and methods in applied sciences, Vol. 12, 03 (2002), 407--430.Google Scholar"",""Rebecca Killick, Paul Fearnhead, and Idris A Eckley. 2012. Optimal detection of changepoints with a linear computational cost. J. Amer. Statist. Assoc., Vol. 107, 500 (2012), 1590--1598.Google ScholarCross Ref"",""Tze-San Lee. 2010. Change-point problems: bibliography and review. Journal of Statistical Theory and Practice, Vol. 4, 4 (2010), 643--662.Google ScholarCross Ref"",""Jiayi Ma, Junjun Jiang, Chengyin Liu, and Yansheng Li. 2017. Feature guided Gaussian mixture model with semi-supervised EM and local geometric constraint for retinal image registration. Information Sciences, Vol. 417 (2017), 128--142.Google ScholarDigital Library"",""Andrew McCallum. 1999. Multi-label text classification with a mixture model trained by EM. In AAAI workshop on Text Learning. 1--7.Google Scholar"",""Bengt Muthén and Kerby Shedden. 1999. Finite mixture modeling with mixture outcomes using the EM algorithm. Biometrics, Vol. 55, 2 (1999), 463--469.Google ScholarCross Ref"",""Kazem Nasserinejad, Joost van Rosmalen, Wim de Kort, and Emmanuel Lesaffre. 2017. Comparison of criteria for choosing the number of classes in Bayesian finite mixture models. PloS one, Vol. 12, 1 (2017), e0168838.Google ScholarCross Ref"",""Peter Neal and Theodore Kypraios. 2015. Exact Bayesian inference via data augmentation. Statistics and Computing, Vol. 25, 2 (2015), 333--347.Google ScholarDigital Library"",""Ewa Nowakowska, Jacek Koronacki, and Stan Lipovetsky. 2014. Tractable measure of component overlap for gaussian mixture models. arXiv preprint arXiv:1407.7172 (2014).Google Scholar"",""Ewan S Page. 1954. Continuous inspection schemes. Biometrika, Vol. 41, 1/2 (1954), 100--115.Google ScholarCross Ref"",""Byung-Jung Park, Dominique Lord, and Chungwon Lee. 2014. Finite mixture modeling for vehicle crash data with application to hotspot identification. Accident Analysis \u0026 Prevention, Vol. 71 (2014), 319--326.Google ScholarCross Ref"",""Sylvia Richardson and Peter J Green. 1997. On Bayesian analysis of mixtures with an unknown number of components (with discussion). Journal of the Royal Statistical Society: series B (statistical methodology), Vol. 59, 4 (1997), 731--792.Google ScholarCross Ref"",""Kathryn Roeder. 1994. A graphical technique for determining the number of components in a mixture of normals. J. Amer. Statist. Assoc., Vol. 89, 426 (1994), 487--495.Google ScholarCross Ref"",""Judith Rousseau and Kerrie Mengersen. 2011. Asymptotic behaviour of the posterior distribution in overfitted mixture models. Journal of the Royal Statistical Society: Series B (Statistical Methodology), Vol. 73, 5 (2011), 689--710.Google ScholarCross Ref"",""Jianfeng Si, Arjun Mukherjee, Bing Liu, Qing Li, Huayi Li, and Xiaotie Deng. 2013. Exploiting topic based twitter sentiment for stock prediction. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). 24--29.Google Scholar"",""Chao Wang, Mohammed A Quddus, and Stephen G Ison. 2011. Predicting accident frequency at their severity levels and its application in site ranking using a two-stage mixed multivariate model. Accident Analysis \u0026 Prevention, Vol. 43, 6 (2011), 1979--1990.Google ScholarCross Ref"",""Tingting Wang, Yi-Ping Phoebe Chen, Phil J Bowman, Michael E Goddard, and Ben J Hayes. 2016. A hybrid expectation maximisation and MCMC sampling algorithm to implement Bayesian mixture model based genomic prediction and QTL mapping. BMC genomics, Vol. 17, 1 (2016), 744.Google Scholar"",""Eric J Ward. 2008. A review and comparison of four commonly used Bayesian and maximum likelihood model selection tools. Ecological Modelling, Vol. 211, 1--2 (2008), 1--10.Google ScholarCross Ref"",""CS Wong, WS Chan, and PL Kam. 2009. A Student t-mixture autoregressive model with applications to heavy-tailed financial data. Biometrika, Vol. 96, 3 (2009), 751--760.Google ScholarCross Ref"",""Dong Yin, Jia Pan, Peng Chen, and Rong Zhang. 2008. Medical image categorization based on gaussian mixture model. In 2008 International Conference on BioMedical Engineering and Informatics, Vol. 2. IEEE, 128--131.Google ScholarDigital Library"",""Ming-Heng Zhang and Qian-Sheng Cheng. 2004. Determine the number of components in a mixture model by the extended KS test. Pattern recognition letters, Vol. 25, 2 (2004), 211--216.Google Scholar""]"
https://doi.org/10.1145/3394486.3403241,AdvMind: Inferring Adversary Intent of Black-Box Attacks,"Deep neural networks (DNNs) are inherently susceptible to adversarial attacks even under black-box settings, in which the adversary only has query access to the target models. In practice, while it may be possible to effectively detect such attacks (e.g., observing massive similar but non-identical queries), it is often challenging to exactly infer the adversary intent (e.g., the target class of the adversarial example the adversary attempts to craft) especially during early stages of the attacks, which is crucial for performing effective deterrence and remediation of the threats in many scenarios.In this paper, we present AdvMind, a new class of estimation models that infer the adversary intent of black-box adversarial attacks in a robust and prompt manner. Specifically, to achieve robust detection, AdvMind accounts for the adversary adaptiveness such that her attempt to conceal the target will significantly increase the attack cost (e.g., in terms of the number of queries); to achieve prompt detection, AdvMind proactively synthesizes plausible query results to solicit subsequent queries from the adversary that maximally expose her intent. Through extensive empirical evaluation on benchmark datasets and state-of-the-art black-box attacks, we demonstrate that on average AdvMind detects the adversary intent with over 75% accuracy after observing less than 3 query batches and meanwhile increases the cost of adaptive attacks by over 60%. We further discuss the possible synergy between AdvMind and other defense methods against black-box adversarial attacks, pointing to several promising research directions.","[{""name"":""Ren Pang"",""id"":""/profile/99659573235""},{""name"":""Xinyang Zhang"",""id"":""/profile/99659574740""},{""name"":""Shouling Ji"",""id"":""/profile/81488646438""},{""name"":""Xiapu Luo"",""id"":""/profile/81300038101""},{""name"":""Ting Wang"",""id"":""/profile/99659564620""},{""name"":""Ren Pang"",""id"":""/profile/99659573235""},{""name"":""Xinyang Zhang"",""id"":""/profile/99659574740""},{""name"":""Shouling Ji"",""id"":""/profile/81488646438""},{""name"":""Xiapu Luo"",""id"":""/profile/81300038101""},{""name"":""Ting Wang"",""id"":""/profile/99659564620""}]","[""Anish Athalye, Nicholas Carlini, and David Wagner. 2018. Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples. In Proceedings of IEEE Conference on Machine Learning (ICML).Google Scholar"",""Jeremy Bernstein, Yu-Xiang Wang, Kamyar Azizzadenesheli, and Animashree Anandkumar. 2018. signSGD: Compressed Optimisation for Non-Convex Problems. In Proceedings of IEEE Conference on Machine Learning (ICML).Google Scholar"",""Battista Biggio, Giorgio Fumera, Fabio Roli, and Luca Didaci. 2012. Poisoning Adaptive Biometric Systems. In Proceedings of Joint IAPR International Workshop on Structural, Syntactic, and Statistical Pattern Recognition (SSPR\u0026SPR).Google ScholarDigital Library"",""Qiong Cao, Li Shen, Weidi Xie, Omkar M Parkhi, and Andrew Zisserman. 2018. Vggface2: A dataset for recognising faces across pose and age. In 13th IEEE International Conference on Automatic Face \u0026 Gesture Recognition.Google ScholarCross Ref"",""Nicholas Carlini and David A. Wagner. 2017. Towards Evaluating the Robustness of Neural Networks. In Proceedings of IEEE Symposium on Security and Privacy (S\u0026P).Google Scholar"",""Pin-Yu Chen, Huan Zhang, Yash Sharma, Jinfeng Yi, and Cho-Jui Hsieh. 2017. Zoo: Zeroth Order Optimization based Black-Box Attacks to Deep Neural Networks without Training Substitute Models. In Proceedings of ACM Workshop on Artificial Intelligence and Security (AISec).Google ScholarDigital Library"",""Steven Chen, Nicholas Carlini, and David Wagner. 2019. Stateful Detection of Black-Box Adversarial Attacks. ArXiv e-prints (2019).Google Scholar"",""Nilesh Dalvi, Pedro Domingos, Mausam, Sumit Sanghai, and Deepak Verma. 2004. Adversarial Classification. In Proceedings of ACM International Conference on Knowledge Discovery and Data Mining (KDD).Google Scholar"",""J. Deng, W. Dong, R. Socher, L. Li, Kai Li, and Li Fei-Fei. 2009. ImageNet: A Large-scale Hierarchical Image Database. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR).Google ScholarCross Ref"",""Andre Esteva, Brett Kuprel, Roberto A. Novoa, Justin Ko, Susan M. Swetter, Helen M. Blau, and Sebastian Thrun. 2017. Dermatologist-level classification of skin cancer with deep neural networks. Nature, Vol. 542, 7639 (2017), 115--118.Google Scholar"",""Ian Goodfellow, Jonathon Shlens, and Christian Szegedy. 2015. Explaining and Harnessing Adversarial Examples. In Proceedings of International Conference on Learning Representations (ICLR).Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep Residual Learning for Image Recognition. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR).Google ScholarCross Ref"",""Peter J. Huber. 1964. Robust Estimation of a Location Parameter. Ann. Math. Statist., Vol. 35, 1 (1964), 73--101.Google ScholarCross Ref"",""Andrew Ilyas, Logan Engstrom, Anish Athalye, and Jessy Lin. 2018. Black-box Adversarial Attacks with Limited Queries and Information. In Proceedings of IEEE Conference on Machine Learning (ICML).Google Scholar"",""Alex Krizhevsky and Geoffrey Hinton. 2009. Learning Multiple Layers of Features from Tiny Images. Technical report, University of Toronto (2009).Google Scholar"",""Yann Lecun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep learning. Nature, Vol. 521, 7553 (2015), 436--444.Google Scholar"",""Bin Liang, Miaoqiang Su, Wei You, Wenchang Shi, and Gang Yang. 2016. Cracking Classifiers for Evasion: A Case Study on the Google's Phishing Pages Filter. In Proceedings of International Conference on World Wide Web (WWW).Google ScholarDigital Library"",""X. Ling, S. Ji, J. Zou, J. Wang, C. Wu, B. Li, and T. Wang. 2019. DEEPSEC: A Uniform Platform for Security Analysis of Deep Learning Model. In Proceedings of IEEE Symposium on Security and Privacy (S\u0026P).Google Scholar"",""Sijia Liu, Pin-Yu Chen, Xiangyi Chen, and Mingyi Hong. 2019. signSGD via Zeroth-Order Oracle. In Proceedings of International Conference on Learning Representations (ICLR).Google Scholar"",""Yanpei Liu, Xinyun Chen, Chang Liu, and Dawn Song. 2016. Delving into Transferable Adversarial Examples and Black-Box Attacks. ArXiv e-prints (2016).Google Scholar"",""Xingjun Ma, Bo Li, Yisen Wang, Sarah M. Erfani, Sudanthi Wijewickrema, Grant Schoenebeck, Dawn Song, Michael E. Houle, and James Bailey. 2018. Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality. In Proceedings of International Conference on Learning Representations (ICLR).Google Scholar"",""Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. 2018. Towards Deep Learning Models Resistant to Adversarial Attacks. In Proceedings of International Conference on Learning Representations (ICLR).Google Scholar"",""S. Moosavi-Dezfooli, A. Fawzi, O. Fawzi, and P. Frossard. 2017. Universal Adversarial Perturbations. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR).Google Scholar"",""Nina Narodytska and Shiva Prasad Kasiviswanathan. 2017. Simple Black-Box Adversarial Perturbations for Deep Networks. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR).Google Scholar"",""Nicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z Berkay Celik, and Ananthram Swami. 2017. Practical Black-Box Attacks Against Machine Learning. In Proceedings of ACM Symposium on Information, Computer and Communications Security (AsiaCCS).Google ScholarDigital Library"",""Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. SQuAD: 100,000+ Questions for Machine Comprehension of Text. In Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP).Google ScholarCross Ref"",""Pang Ren, Zhang Xinyang, Ji Shouling, Luo Xiapu, and Wang Ting. 2020. AdvMind: Inferring Adversary Intent of Black-Box Attacks. ArXiv e-prints (2020).Google Scholar"",""Orbis Research. 2019. Healthcare Fraud Detection Market to grow at 24.59% CAGR by 2024. https://www.globenewswire.com/.Google Scholar"",""Peter J. Rousseeuw and Sabine Verboven. 2002. Robust estimation in very small samples. Computational Statistics \u0026 Data Analysis, Vol. 40, 4 (2002), 741--758.Google ScholarDigital Library"",""David Silver, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George van den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, Sander Dieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya Sutskever, Timothy Lillicrap, Madeleine Leach, Koray Kavukcuoglu, Thore Graepel, and Demis Hassabis. 2016. Mastering the Game of Go with Deep Neural Networks and Tree Search. Nature 7587 (2016), 484--489.Google ScholarCross Ref"",""Karen Simonyan and Andrew Zisserman. 2014. Very Deep Convolutional Networks for Large-Scale Image Recognition. In Proceedings of International Conference on Learning Representations (ICLR).Google Scholar"",""Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. 2014. Intriguing Properties of Neural Networks. In Proceedings of International Conference on Learning Representations (ICLR).Google Scholar"",""F. Tramèr, A. Kurakin, N. Papernot, I. Goodfellow, D. Boneh, and P. McDaniel. 2018. Ensemble Adversarial Training: Attacks and Defenses. In Proceedings of International Conference on Learning Representations (ICLR).Google Scholar"",""Florian Tramèr, Fan Zhang, Ari Juels, Michael K. Reiter, and Thomas Ristenpart. 2016. Stealing Machine Learning Models via Prediction APIs. In Proceedings of USENIX Security Symposium (SEC).Google Scholar"",""Daan Wierstra, Tom Schaul, Tobias Glasmachers, Yi Sun, Jan Peters, and Jürgen Schmidhuber. 2014. Natural Evolution Strategies. J. Mach. Learn. Res., Vol. 15, 1 (2014), 949--980.Google ScholarDigital Library"",""Haishan Ye, Zhichao Huang, Cong Fang, Chris Junchi Li, and Tong Zhang. 2018. Hessian-Aware Zeroth-Order Optimization for Black-Box Adversarial Attack. ArXiv e-prints (2018).Google Scholar""]"
https://doi.org/10.1145/3394486.3403242,Hierarchical Topic Mining via Joint Spherical Tree and Text Embedding,"Mining a set of meaningful topics organized into a hierarchy is intuitively appealing since topic correlations are ubiquitous in massive text corpora. To account for potential hierarchical topic structures, hierarchical topic models generalize flat topic models by incorporating latent topic hierarchies into their generative modeling process. However, due to their purely unsupervised nature, the learned topic hierarchy often deviates from users' particular needs or interests. To guide the hierarchical topic discovery process with minimal user supervision, we propose a new task, Hierarchical Topic Mining, which takes a category tree described by category names only, and aims to mine a set of representative terms for each category from a text corpus to help a user comprehend his/her interested topics. We develop a novel joint tree and text embedding method along with a principled optimization procedure that allows simultaneous modeling of the category tree structure and the corpus generative process in the spherical space for effective category-representative term discovery. Our comprehensive experiments show that our model, named JoSH, mines a high-quality set of hierarchical topics with high efficiency and benefits weakly-supervised hierarchical text classification tasks.","[{""name"":""Yu Meng"",""id"":""/profile/99659316366""},{""name"":""Yunyi Zhang"",""id"":""/profile/99659575102""},{""name"":""Jiaxin Huang"",""id"":""/profile/99659536420""},{""name"":""Yu Zhang"",""id"":""/profile/99659259686""},{""name"":""Chao Zhang"",""id"":""/profile/99659455279""},{""name"":""Jiawei Han"",""id"":""/profile/81548005096""},{""name"":""Yu Meng"",""id"":""/profile/99659316366""},{""name"":""Yunyi Zhang"",""id"":""/profile/99659575102""},{""name"":""Jiaxin Huang"",""id"":""/profile/99659536420""},{""name"":""Yu Zhang"",""id"":""/profile/99659259686""},{""name"":""Chao Zhang"",""id"":""/profile/99659455279""},{""name"":""Jiawei Han"",""id"":""/profile/81548005096""}]","[""Enrique Alfonseca, Katja Filippova, Jean-Yves Delort, and Guillermo Garrido. 2012. Pattern Learning for Relation Extraction with a Hierarchical Topic Model. In ACL.Google Scholar"",""David Andrzejewski and Xiaojin Zhu. 2009. Latent Dirichlet Allocation with Topic-in-Set Knowledge. In HLT-NAACL.Google Scholar"",""Kayhan Batmanghelich, Ardavan Saeedi, Karthik Narasimhan, and Sam Gershman. 2016. Nonparametric spherical topic modeling with word embeddings. In ACL. 537.Google Scholar"",""David M. Blei, Thomas L. Griffiths, Michael I. Jordan, and Joshua B. Tenenbaum. 2003 a. Hierarchical Topic Models and the Nested Chinese Restaurant Process. In NIPS.Google Scholar"",""David M Blei and Jon D Mcauliffe. 2008. Supervised topic models. In NIPS. 121--128.Google Scholar"",""David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003 b. Latent Dirichlet Allocation. In NIPS.Google Scholar"",""Adji B. Dieng, Francisco J. R. Ruiz, and David M. Blei. 2019. Topic Modeling in Embedding Spaces. ArXiv, Vol. abs/1907.04907 (2019).Google Scholar"",""Ryan J. Gallagher, Kyle Reing, David C. Kale, and Greg Ver Steeg. 2017. Anchored Correlation Explanation: Topic Modeling with Minimal Domain Knowledge. TACL (2017).Google Scholar"",""Octavian-Eugen Ganea, Gary Bécigneul, and Thomas Hofmann. 2018. Hyperbolic Entailment Cones for Learning Hierarchical Embeddings. In ICML.Google Scholar"",""Justin Grimmer. 2010. A Bayesian hierarchical topic model for political texts: Measuring expressed agendas in Senate press releases. Political Analysis, Vol. 18, 1 (2010), 1--35.Google ScholarCross Ref"",""Thomas Hofmann. 1999. Probabilistic Latent Semantic Indexing. In SIGIR.Google Scholar"",""Jiaxin Huang, Yiqing Xie, Yu Meng, Jiaming Shen, Yunyi Zhang, and Jiawei Han. 2020 a. Guiding Corpus-based Set Expansion by Auxiliary Sets Generation and Co-Expansion. In WWW.Google Scholar"",""Jiaxin Huang, Yiqing Xie, Yu Meng, Yunyi Zhang, and Jiawei Han. 2020 b. CoRel: Seed-Guided Topical Taxonomy Construction by Concept Learning and Relation Transferring. In KDD.Google Scholar"",""Jagadeesh Jagarlamudi, Hal Daumé, and Raghavendra Udupa. 2012. Incorporating Lexical Priors into Topic Models. In EACL.Google Scholar"",""Saurabh S Kataria, Krishnan S Kumar, Rajeev R Rastogi, Prithviraj Sen, and Srinivasan H Sengamedu. 2011. Entity disambiguation with hierarchical topic models. In KDD.Google Scholar"",""Sachin Kumar and Yulia Tsvetkov. 2019. Von Mises-Fisher Loss for Training Sequence to Sequence Models with Continuous Outputs. In ICLR.Google Scholar"",""Quoc V. Le and Tomas Mikolov. 2014. Distributed Representations of Sentences and Documents. In ICML.Google Scholar"",""Omer Levy and Yoav Goldberg. 2014. Linguistic Regularities in Sparse and Explicit Word Representations. In CoNLL.Google Scholar"",""Wei Li and Andrew McCallum. 2006. Pachinko allocation: DAG-structured mixture models of topic correlations. In ICML. 577--584.Google Scholar"",""Yang Liu, Zhiyuan Liu, Tat-Seng Chua, and Maosong Sun. 2015. Topical Word Embeddings. In AAAI.Google Scholar"",""Laurens van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE. Journal of machine learning research, Vol. 9, Nov (2008), 2579--2605.Google Scholar"",""Xianling Mao, Zhaoyan Ming, Tat-Seng Chua, Si Kan Li, Hongfei Yan, and Xiaoming Li. 2012. SSHLDA: A Semi-Supervised Hierarchical Topic Model. In EMNLP-CoNLL.Google Scholar"",""Yu Meng, Jiaxin Huang, Guangyuan Wang, Zihan Wang, Chao Zhang, and Jiawei Han. 2020 a. Unsupervised Word Embedding Learning by Incorporating Local and Global Contexts. Frontiers in Big Data (2020).Google Scholar"",""Yu Meng, Jiaxin Huang, Guangyuan Wang, Zihan Wang, Chao Zhang, Yu Zhang, and Jiawei Han. 2020 b. Discriminative Topic Mining via Category-Name Guided Text Embedding. In WWW.Google Scholar"",""Yu Meng, Jiaxin Huang, Guangyuan Wang, Chao Zhang, Honglei Zhuang, Lance Kaplan, and Jiawei Han. 2019 a. Spherical Text Embedding. In NeurIPS.Google Scholar"",""Yu Meng, Jiaming Shen, Chao Zhang, and Jiawei Han. 2018. Weakly-Supervised Neural Text Classification. In CIKM.Google Scholar"",""Yu Meng, Jiaming Shen, Chao Zhang, and Jiawei Han. 2019 b. Weakly-Supervised Hierarchical Text Classification. In AAAI.Google Scholar"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S. Corrado, and Jeffrey Dean. 2013. Distributed Representations of Words and Phrases and their Compositionality. In NIPS.Google Scholar"",""David M. Mimno, Wei Li, and Andrew McCallum. 2007. Mixtures of hierarchical topics with Pachinko allocation. In ICML '07.Google ScholarDigital Library"",""Maximilian Nickel and Douwe Kiela. 2017. Poincaré Embeddings for Learning Hierarchical Representations. In NIPS.Google Scholar"",""Maximilian Nickel and Douwe Kiela. 2018. Learning Continuous Hierarchies in the Lorentz Model of Hyperbolic Geometry. In ICML.Google Scholar"",""Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. Glove: Global Vectors for Word Representation. In EMNLP.Google Scholar"",""Adler J. Perotte, Frank D. Wood, Noémie Elhadad, and Nicholas Bartlett. 2011. Hierarchically Supervised Latent Dirichlet Allocation. In NIPS.Google Scholar"",""Evan Sandhaus. 2008. The New York Times Annotated Corpus.Google Scholar"",""Jingbo Shang, Jialu Liu, Meng Jiang, Xiang Ren, Clare R. Voss, and Jiawei Han. 2018. Automated Phrase Mining from Massive Text Corpora. IEEE Transactions on Knowledge and Data Engineering, Vol. 30 (2018), 1825--1837.Google ScholarCross Ref"",""Alexandru Tifrea, Gary Bécigneul, and Octavian-Eugen Ganea. 2019. Poincaré Glove: Hyperbolic Word Embeddings. In ICLR.Google Scholar"",""Yu Zhang, Frank F Xu, Sha Li, Yu Meng, Xuan Wang, Qi Li, and Jiawei Han. 2019. HiGitClass: Keyword-Driven Hierarchical Classification of GitHub Repositories. In ICDM.Google Scholar""]"
https://doi.org/10.1145/3394486.3403243,Combinatorial Black-Box Optimization with Expert Advice,"We consider the problem of black-box function optimization over the Boolean hypercube. Despite the vast literature on black-box function optimization over continuous domains, not much attention has been paid to learning models for optimization over combinatorial domains until recently. However, the computational complexity of the recently devised algorithms are prohibitive even for moderate numbers of variables; drawing one sample using the existing algorithms is more expensive than a function evaluation for many black-box functions of interest. To address this problem, we propose a computationally efficient model learning algorithm based on multilinear polynomials and exponential weight updates. In the proposed algorithm, we alternate between simulated annealing with respect to the current polynomial representation and updating the weights using monomial experts' advice. Numerical experiments on various datasets in both unconstrained and sum-constrained Boolean optimization indicate the competitive performance of the proposed algorithm, while improving the computational time up to several orders of magnitude compared to state-of-the-art algorithms in the literature.","[{""name"":""Hamid Dadkhahi"",""id"":""/profile/99659193055""},{""name"":""Karthikeyan Shanmugam"",""id"":""/profile/81554811456""},{""name"":""Jesus Rios"",""id"":""/profile/99659574858""},{""name"":""Payel Das"",""id"":""/profile/87258723357""},{""name"":""Samuel C. Hoffman"",""id"":""/profile/99659495762""},{""name"":""Troy David Loeffler"",""id"":""/profile/99659573220""},{""name"":""Subramanian Sankaranarayanan"",""id"":""/profile/99659573314""},{""name"":""Hamid Dadkhahi"",""id"":""/profile/99659193055""},{""name"":""Karthikeyan Shanmugam"",""id"":""/profile/81554811456""},{""name"":""Jesus Rios"",""id"":""/profile/99659574858""},{""name"":""Payel Das"",""id"":""/profile/87258723357""},{""name"":""Samuel C. Hoffman"",""id"":""/profile/99659495762""},{""name"":""Troy David Loeffler"",""id"":""/profile/99659573220""},{""name"":""Subramanian Sankaranarayanan"",""id"":""/profile/99659573314""}]","[""Sanjeev Arora, Elad Hazan, and Satyen Kale. 2012. The multiplicative weights update method: a meta-algorithm and applications. Theory of Computing, Vol. 8, 1 (2012), 121--164.Google ScholarCross Ref"",""Peter Auer. 2002. Using confidence bounds for exploitation-exploration trade-offs. Journal of Machine Learning Research, Vol. 3, Nov (2002), 397--422.Google ScholarDigital Library"",""Jordan Bell and Brett Stevens. 2009. A survey of known results and research areas for n-queens. Discrete Mathematics, Vol. 309, 1 (2009), 1--31.Google ScholarDigital Library"",""James Bergstra and Yoshua Bengio. 2012. Random Search for Hyper-Parameter Optimization. J. Mach. Learn. Res., Vol. 13 (2012), 281--305.Google ScholarDigital Library"",""James S Bergstra, Rémi Bardenet, Yoshua Bengio, and Balázs Kégl. 2011. Algorithms for hyper-parameter optimization. In Advances in neural information processing systems. 2546--2554.Google Scholar"",""Nicolò Cesa-Bianchi and Gábor Lugosi. 2006. Prediction, learning, and games. Cambridge University Press.Google Scholar"",""Josip Djolonga, Andreas Krause, and Volkan Cevher. 2013. High-dimensional gaussian process bandits. In Advances in Neural Information Processing Systems. 1025--1033.Google Scholar"",""Sébastien Gerchinovitz and Jia Yuan Yu. 2011. Adaptive and Optimal Online Linear Regression on l1-Balls. In Algorithmic Learning Theory. Springer Berlin Heidelberg, 99--113.Google Scholar"",""M. Hardt and G. N. Rothblum. 2010. A Multiplicative Weights Mechanism for Privacy-Preserving Data Analysis. In 2010 IEEE 51st Annual Symposium on Foundations of Computer Science. 61--70.Google Scholar"",""Ali Hebbal, Loic Brevault, Mathieu Balesdent, El-Ghazali Talbi, and Nouredine Melab. 2019. Bayesian optimization using deep Gaussian processes. arXiv preprint arXiv:1905.03350 (2019).Google Scholar"",""Abdollah Homaifar, Joseph Turner, and Samia Ali. 1992. The n-queens problem and genetic algorithms. In Proceedings IEEE Southeastcon'92. IEEE, 262--267.Google ScholarCross Ref"",""Xiaohui Hu, Russell C Eberhart, and Yuhui Shi. 2003. Swarm intelligence for permutation optimization: a case study of n-queens problem. In Proceedings of the 2003 IEEE Swarm Intelligence Symposium. SIS'03. IEEE, 243--246.Google Scholar"",""Donald R Jones, Matthias Schonlau, and William J Welch. 1998. Efficient global optimization of expensive black-box functions. Journal of Global optimization, Vol. 13, 4 (1998), 455--492.Google ScholarDigital Library"",""Kirthevasan Kandasamy, Gautam Dasarathy, Jeff Schneider, and Barnabás Póczos. 2017. Multi-fidelity bayesian optimisation with continuous approximations. In International Conference on Machine Learning. 1799--1808.Google Scholar"",""S. Kirkpatrick, C. D. Gelatt, and M. P. Vecchi. 1983. Optimization by Simulated Annealing. Science, Vol. 220, 4598 (1983), 671--680.Google Scholar"",""Jyrki Kivinen and Manfred K. Warmuth. 1997. Exponentiated Gradient versus Gradient Descent for Linear Predictors. Information and Computation, Vol. 132, 1 (1997), 1 -- 63.Google ScholarDigital Library"",""Lisha Li, Kevin Jamieson, Giulia DeSalvo, Afshin Rostamizadeh, and Ameet Talwalkar. 2017. Hyperband: A novel bandit-based approach to hyperparameter optimization. The Journal of Machine Learning Research, Vol. 18, 1 (2017), 6765--6816.Google ScholarDigital Library"",""Jonas Movc kus. 1975. On Bayesian methods for seeking the extremum. In Optimization techniques IFIP technical conference. Springer, 400--404.Google Scholar"",""Jonas Mockus. 1994. Application of Bayesian approach to numerical methods of global and stochastic optimization. Journal of Global Optimization, Vol. 4, 4 (1994), 347--365.Google ScholarCross Ref"",""Soham Mukherjee, Santanu Datta, Pramit Brata Chanda, and Pratik Pathak. 2015. Comparative Study of Different Algorithms to Solve N-Queens Problem. International Journal of Foundations of Computer Science and Technology, Vol. 5, 2 (2015), 15--27.Google ScholarCross Ref"",""Ryan O'Donnell. 2014. Analysis of Boolean Functions. Cambridge University Press.Google Scholar"",""Changyong Oh, Jakub Tomczak, Efstratios Gavves, and Max Welling. 2019. Combinatorial Bayesian Optimization using the Graph Cartesian Product. In Advances in Neural Information Processing Systems 32. 2910--2920.Google Scholar"",""Alireza Ostadhossein, Ali Rahnamoun, Yuanxi Wang, Peng Zhao, Sulin Zhang, Vincent H Crespi, and Adri CT van Duin. 2017. ReaxFF reactive force-field study of molybdenum disulfide (MoS2). The journal of physical chemistry letters, Vol. 8, 3 (2017), 631--640.Google Scholar"",""Tarak K. Patra, Fu Zhang, Daniel S. Schulman, Henry Chan, Mathew J. Cherukara, Mauricio Terrones, Saptarshi Das, Badri Narayanan, and Subramanian K. R. S. Sankaranarayanan. 2018. Defect Dynamics in 2-D MoS2 Probed by Using Machine Learning, Atomistic Simulations, and High-Resolution Microscopy. ACS Nano, Vol. 12, 8 (2018), 8006--8016.Google ScholarCross Ref"",""Steve Plimpton. 1995. Fast Parallel Algorithms for Short-Range Molecular Dynamics. J. Comput. Phys., Vol. 117, 1 (1995), 1--19.Google ScholarDigital Library"",""Matthias Poloczek Ricardo Baptista. 2018. Bayesian Optimization of Combinatorial Structures. In International Conference on International Conference on Machine Learning (ICML).Google Scholar"",""Christian Sch\""afer. 2013. Particle Algorithms for Optimization on Binary Spaces. ACM Transactions on Modeling and Computer Simulation (TOMACS), Vol. 23, 1 (2013).Google Scholar"",""Rajat Sen, Kirthevasan Kandasamy, and Sanjay Shakkottai. 2018. Multi-fidelity black-box optimization with hierarchical partitions. In International conference on machine learning. 4538--4547.Google Scholar"",""B. Shahriari, K. Swersky, Z. Wang, R. P. Adams, and N. de Freitas. 2016. Taking the Human Out of the Loop: A Review of Bayesian Optimization. Proc. IEEE (2016).Google ScholarCross Ref"",""William M. Spears. 1993. Simulated Annealing for Hard Satisfiability Problems. In DIMACS Workshop: Cliques, Coloring, and Satisfiability. 533--557.Google Scholar"",""Niranjan Srinivas, Andreas Krause, Sham Kakade, and Matthias Seeger. 2010. Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design. In Proceedings of the 27th International Conference on International Conference on Machine Learning (ICML'10). 1015--1022.Google ScholarDigital Library"",""Yoichi Takenaka, Nobuo Funabiki, and Teruo Higashino. 2000. A proposal of neuron filter: A constraint resolution scheme of neural networks for combinatorial optimization problems. IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences, Vol. 83, 9 (2000), 1815--1823.Google Scholar"",""William R Thompson. 1933. On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. Biometrika, Vol. 25, 3/4 (1933), 285--294.Google ScholarCross Ref"",""Dirk van der Hoeven, Tim van Erven, and Wojciech Kotłowski. 2018. The Many Faces of Exponential Weights in Online Learning. In Proceedings of the 31st Conference On Learning Theory, Vol. 75. 2067--2092.Google Scholar"",""V Vovk. 1998. A Game of Prediction with Expert Advice. J. Comput. Syst. Sci., Vol. 56, 2 (1998), 153--173.Google ScholarDigital Library"",""Ziyu Wang, Masrour Zoghi, Frank Hutter, David Matheson, and Nando De Freitas. 2013. Bayesian optimization in high dimensions via random embeddings. In Twenty-Third International Joint Conference on Artificial Intelligence.Google ScholarDigital Library"",""David P Williamson and David B Shmoys. 2011. The design of approximation algorithms .Cambridge university press.Google Scholar"",""Laurence A Wolsey and George L Nemhauser. 1999. Integer and combinatorial optimization. Vol. 55. John Wiley \u0026 Sons.Google Scholar"",""Y. Xu Y. Hu, J. Hu and F. Wang. 2010. Contamination control in food supply chain. In Proceedings of the 2010 Winter Simulation Conference.Google Scholar"",""Robert E. Schapire Yoav Freund. 1997. A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting. J. Comput. System Sci. (1997).Google Scholar""]"
https://doi.org/10.1145/3394486.3403244,CoRel: Seed-Guided Topical Taxonomy Construction by Concept Learning and Relation Transferring,"Taxonomy is not only a fundamental form of knowledge representation, but also crucial to vast knowledge-rich applications, such as question answering and web search. Most existing taxonomy construction methods extract hypernym-hyponym entity pairs to organize a ""universal"" taxonomy. However, these generic taxonomies cannot satisfy user's specific interest in certain areas and relations. Moreover, the nature of instance taxonomy treats each node as a single word, which has low semantic coverage for people to fully understand. In this paper, we propose a method for seed-guided topical taxonomy construction, which takes a corpus and a seed taxonomy described by concept names as input, and constructs a more complete taxonomy based on user's interest, wherein each node is represented by a cluster of coherent terms. Our framework, CoRel, has two modules to fulfill this goal. A relation transferring module learns and transfers the user's interested relation along multiple paths to expand the seed taxonomy structure in width and depth. A concept learning module enriches the semantics of each concept node by jointly embedding the taxonomy and text. Comprehensive experiments conducted on real-world datasets show that CoRel generates high-quality topical taxonomies and outperforms all the baselines significantly.","[{""name"":""Jiaxin Huang"",""id"":""/profile/99659536420""},{""name"":""Yiqing Xie"",""id"":""/profile/99659536239""},{""name"":""Yu Meng"",""id"":""/profile/99659316366""},{""name"":""Yunyi Zhang"",""id"":""/profile/99659575102""},{""name"":""Jiawei Han"",""id"":""/profile/81548005096""},{""name"":""Jiaxin Huang"",""id"":""/profile/99659536420""},{""name"":""Yiqing Xie"",""id"":""/profile/99659536239""},{""name"":""Yu Meng"",""id"":""/profile/99659316366""},{""name"":""Yunyi Zhang"",""id"":""/profile/99659575102""},{""name"":""Jiawei Han"",""id"":""/profile/81548005096""}]","[""David M. Blei, Thomas L. Griffiths, Michael I. Jordan, and Joshua B. Tenenbaum. 2003. Hierarchical Topic Models and the Nested Chinese Restaurant Process. In NIPS.Google Scholar"",""Haw-Shiuan Chang, ZiYun Wang, Luke Vilnis, and Andrew McCallum. 2017. Distributional Inclusion Vector Embedding for Unsupervised Hypernymy Detection. In NAACL-HLT.Google Scholar"",""Philipp Cimiano, Andreas Hotho, and Steffen Staab. 2004. Comparing Conceptual, Divise and Agglomerative Clustering for Learning Taxonomies from Text. In ECAI.Google Scholar"",""Sarthak Dash, Md. Faisal Mahbub Chowdhury, Alfio Massimiliano Gliozzo, Nandana Mihindukulasooriya, and Nicolas R. Fauceglia. 2019. Hypernym Detection Using Strict Partial Order Networks.Google Scholar"",""Barry de Ville. 2001. Introduction to Data Mining.Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In NAACL-HLT.Google Scholar"",""Brendan J. Frey and Delbert Dueck. 2007. Clustering by passing messages between data points. Science, Vol. 315 5814 (2007), 972--6.Google ScholarCross Ref"",""Ruiji Fu, Jiang Guo, Bing Qin, Wanxiang Che, Haifeng Wang, and Ting Liu. 2014. Learning Semantic Hierarchies via Word Embeddings. In ACL.Google Scholar"",""Tianyu Gao, Xu Han, Zhiyuan Liu, and Maosong Sun. 2019. Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification. In AAAI.Google Scholar"",""Xu Han, Hao Zhu, Pengfei Yu, Ziyun Wang, Yuan Yao, Zhiyuan Liu, and Maosong Sun. 2018. FewRel: A Large-Scale Supervised Few-shot Relation Classification Dataset with State-of-the-Art Evaluation. In EMNLP.Google Scholar"",""Marti A. Hearst. 1992. Automatic Acquisition of Hyponyms from Large Text Corpora. In COLING.Google Scholar"",""Jiaxin Huang, Yi qing Xie, Yu Meng, Jiaming Shen, Yunyi Zhang, and Jiawei Han. 2020. Guiding Corpus-based Set Expansion by Auxiliary Sets Generation and Co-Expansion. Proceedings of The Web Conference 2020 (2020).Google ScholarDigital Library"",""Yuval Kluger, Ronen Basri, Joseph T. Chang, and Mark B Gerstein. 2003. Spectral biclustering of microarray data: coclustering genes and conditions. Genome research, Vol. 13 4 (2003), 703--16.Google Scholar"",""Zornitsa Kozareva and Eduard H. Hovy. 2010. A Semi-Supervised Method to Learn and Construct Taxonomies Using the Web. In EMNLP.Google Scholar"",""Matt Le, Stephen Roller, Laetitia Papaxanthos, Douwe Kiela, and Maximilian Nickel. 2019. Inferring Concept Hierarchies from Text Corpora via Hyperbolic Embeddings. In ACL.Google Scholar"",""Xueqing Liu, Yangqiu Song, Shixia Liu, and Haixun Wang. 2012. Automatic taxonomy construction from keywords. In KDD.Google Scholar"",""Yu Meng, Jiaxin Huang, Guangyuan Wang, Zihan Wang, Chao Zhang, Yu Zhang, and Jiawei Han. 2020. Discriminative Topic Mining via Category-Name Guided Text Embedding. In WWW.Google Scholar"",""Yu Meng, Jiaxin Huang, Guangyuan Wang, Chao Zhang, Honglei Zhuang, Lance M. Kaplan, and Jiawei Han. 2019. Spherical Text Embedding. In NIPS.Google Scholar"",""Yu Meng, Yunyi Zhang, Jiaxin Huang, Yu Zhang, Chao Zhang, and Jiawei Han. 2020. Hierarchical Topic Mining via Joint Spherical Tree and Text Embedding. In KDD.Google Scholar"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S. Corrado, and Jeffrey Dean. 2013. Distributed Representations of Words and Phrases and their Compositionality. In NIPS.Google Scholar"",""David M. Mimno, Wei Li, and Andrew McCallum. 2007. Mixtures of hierarchical topics with Pachinko allocation. In ICML '07.Google ScholarDigital Library"",""Ndapandula Nakashole, Gerhard Weikum, and Fabian M. Suchanek. 2012. PATTY: A Taxonomy of Relational Patterns with Semantic Types. In EMNLP-CoNLL.Google Scholar"",""Roberto Navigli and Paola Velardi. 2010. Learning Word-Class Lattices for Definition and Hypernym Extraction. In ACL.Google Scholar"",""Roberto Navigli, Paola Velardi, and Stefano Faralli. 2011. A Graph-Based Algorithm for Inducing Lexical Taxonomies from Scratch. In IJCAI.Google Scholar"",""Maximilian Nickel and Douwe Kiela. 2017. Poincaré Embeddings for Learning Hierarchical Representations. In NIPS.Google Scholar"",""Meng Qu, Xiang Ren, Yu Lin Zhang, and Jiawei Han. 2017. Weakly-supervised Relation Extraction by Pattern-enhanced Embedding Learning. In WWW.Google Scholar"",""Xin Rong, Zhe Chen, Qiaozhu Mei, and Eytan Adar. 2016. EgoSet: Exploiting Word Ego-networks and User-generated Ontology for Multifaceted Set Expansion. In WSDM.Google Scholar"",""Jingbo Shang, Jialu Liu, Meng Jiang, Xiang Ren, Clare R. Voss, and Jiawei Han. 2017. Automated Phrase Mining from Massive Text Corpora. IEEE Transactions on Knowledge and Data Engineering, Vol. 30 (2017), 1825--1837.Google ScholarCross Ref"",""Jiaming Shen, Zeqiu Wu, Dongming Lei, Jingbo Shang, Xiang Ren, and Jiawei Han. 2017. SetExpan: Corpus-Based Set Expansion via Context Feature Selection and Rank Ensemble. In ECML/PKDD.Google Scholar"",""Jiaming Shen, Zeqiu Wu, Dongming Lei, Chao Zhang, Xiang Ren, Michelle T. Vanni, Brian M. Sadler, and Jiawei Han. 2018. HiExpan: Task-Guided Taxonomy Construction by Hierarchical Tree Expansion. ArXiv, Vol. abs/1910.08194 (2018).Google Scholar"",""Vered Shwartz, Yoav Goldberg, and Ido Dagan. 2016. Improving Hypernymy Detection with an Integrated Path-based and Distributional Method. ArXiv, Vol. abs/1603.06076 (2016).Google Scholar"",""Rion Snow, Dan Jurafsky, and Andrew Y. Ng. 2004. Learning Syntactic Patterns for Automatic Hypernym Discovery. In NIPS.Google Scholar"",""Livio Baldini Soares, Nicholas FitzGerald, Jeffrey Ling, and Tom Kwiatkowski. 2019. Matching the Blanks: Distributional Similarity for Relation Learning. In ACL.Google Scholar"",""Paola Velardi, Stefano Faralli, and Roberto Navigli. 2013. OntoLearn Reloaded: A Graph-Based Algorithm for Taxonomy Induction. Computational Linguistics, Vol. 39 (2013), 665--707.Google ScholarCross Ref"",""Ivan Vendrov, Ryan Kiros, Sanja Fidler, and Raquel Urtasun. 2015. Order-Embeddings of Images and Language. CoRR, Vol. abs/1511.06361 (2015).Google Scholar"",""Chi Wang, Marina Danilevsky, Nihit Desai, Yinan Zhang, Phuong Nguyen, Thrivikrama Taula, and Jiawei Han. 2013. A phrase mining framework for recursive construction of a topical hierarchy. In KDD '13.Google ScholarDigital Library"",""Julie Weeds, David J. Weir, and Diana McCarthy. 2004. Characterising Measures of Lexical Distributional Similarity. In COLING.Google Scholar"",""Grace Hui Yang and James P. Callan. 2009. A Metric-based Framework for Automatic Taxonomy Induction. In ACL/IJCNLP.Google Scholar"",""Shuo Yang, Lei Zou, Zhongyuan Wang, Jun Yan, and Ji-Rong Wen. 2017. Efficiently Answering Technical Questions - A Knowledge Graph Approach. In AAAI.Google Scholar"",""Chao Zhang, Fangbo Tao, Xiusi Chen, Jiaming Shen, Meng Jiang, Brian M. Sadler, Michelle Vanni, and Jiawei Han. 2018. TaxoGen: Unsupervised Topic Taxonomy Construction by Adaptive Term Embedding and Clustering. In KDD '18.Google ScholarDigital Library"",""Yuchen Zhang, Amr Ahmed, Vanja Josifovski, and Alexander J. Smola. 2014. Taxonomy discovery for personalized recommendation. In WSDM '14.Google Scholar"",""Maayan Zhitomirsky-Geffet and Ido Dagan. 2005. The Distributional Inclusion Hypotheses and Lexical Entailment. In ACL.Google Scholar""]"
https://doi.org/10.1145/3394486.3403245,Treatment Policy Learning in Multiobjective Settings with Fully Observed Outcomes,"In several medical decision-making problems, such as antibiotic prescription, laboratory testing can provide precise indications for how a patient will respond to different treatment options. This enables us to ""fully observe"" all potential treatment outcomes, but while present in historical data, these results are infeasible to produce in real-time at the point of the initial treatment decision. Moreover, treatment policies in these settings often need to trade off between multiple competing objectives, such as effectiveness of treatment and harmful side effects. We present, compare, and evaluate three approaches for learning individualized treatment policies in this setting: First, we consider two indirect approaches, which use predictive models of treatment response to construct policies optimal for different trade-offs between objectives. Second, we consider a direct approach that constructs such a set of policies without intermediate models of outcomes. Using a medical dataset of Urinary Tract Infection (UTI) patients, we show that all approaches learn policies that achieve strictly better performance on all outcomes than clinicians, while also trading off between different objectives. We demonstrate additional benefits of the direct approach, including flexibly incorporating other goals such as deferral to physicians on simple cases.","[{""name"":""Soorajnath Boominathan"",""id"":""/profile/99659573717""},{""name"":""Michael Oberst"",""id"":""/profile/99659574924""},{""name"":""Helen Zhou"",""id"":""/profile/99659573171""},{""name"":""Sanjat Kanjilal"",""id"":""/profile/99659574261""},{""name"":""David Sontag"",""id"":""/profile/81448593391""},{""name"":""Soorajnath Boominathan"",""id"":""/profile/99659573717""},{""name"":""Michael Oberst"",""id"":""/profile/99659574924""},{""name"":""Helen Zhou"",""id"":""/profile/99659573171""},{""name"":""Sanjat Kanjilal"",""id"":""/profile/99659574261""},{""name"":""David Sontag"",""id"":""/profile/81448593391""}]","[""Gagan Bansal, Besmira Nushi, Ece Kamar, Eric Horvitz, and Daniel S Weld. 2020. Optimizing AI for Teamwork. arXiv preprint arXiv:2004.13102 (2020).Google Scholar"",""Leon Barrett and Srini Narayanan. 2008. Learning all optimal policies with multiple criteria. Proceedings of the 25th International Conference on Machine Learning (2008), 41--47. https://doi.org/10.1145/1390156.1390162Google ScholarDigital Library"",""Y.-S. Chen S.-H. Lee Y.-S. Chen S.-C. Chen S.-C. Chang C.-C. Lee, M.-T. G. Lee. 2015. Risk of Aortic Dissection and Aortic Aneurysm in Patients Taking Oral Fluoroquinolone. JAMA Internal Medicine, Vol. 175 (2015).Google ScholarCross Ref"",""Minmin Chen, Ramki Gummadi, Chris Harris, and Dale Schuurmans. 2019. Surrogate Objectives for Batch Policy Optimization in One-step Decision Making. Neural Information Processing Systems (NeurIPS) (2019).Google Scholar"",""K. E. Dingle, X. Didelot, and T.P. Quan. 2016. Effects of control interventions on Clostridium difficile infection in England: an observational study. Lancet Infectious Diseases, Vol. 17 (2016), 411 -- 421.Google ScholarCross Ref"",""Charles Elkan. 2001. The foundations of cost-sensitive learning. IJCAI International Joint Conference on Artificial Intelligence (2001), 973--978.Google Scholar"",""D J Farrell, I Morrissey, D De Rubeis, M Robbins, and D Felmingham. 2003. A UK multicentre study of the antimicrobial susceptibility of bacterial pathogens causing urinary tract infection. The Journal of infection, Vol. 46, 2 (Feb 2003), 94--100.Google ScholarCross Ref"",""Robin Henderson, Phil Ansell, and Deyadeen Alshibani. 2010. Regret-regression for optimal dynamic treatment regimes. Biometrics, Vol. 66, 4 (Dec 2010), 1192--201. https://doi.org/10.1111/j.1541-0420.2009.01368.xGoogle ScholarCross Ref"",""Miguel Hernan and Jamie Robbins. 2020. Causal Inference. Chapman \u0026 Hall/CRC, Boca Raton.Google Scholar"",""Xinyang Huang, Yair Goldberg, and Jin Xu. 2019. Multicategory individualized treatment regime using outcome weighted learning. Biometrics August 2018 (2019), 1216--1227. https://doi.org/10.1111/biom.13084Google Scholar"",""Guido W Imbens and Donald B Rubin. 2015. Causal Inference for Statistics, Social, and Biomedical Sciences. Cambridge University Press.Google Scholar"",""Sarah Kabbani, Adam Hersh, Daniel Shapiro, Katherine Fleming-Dutra, Andrew Pavia, and Lauri Hicks. 2018. Opportunities to Improve Fluoroquinolone Prescribing in the United States for Adult Ambulatory Care Visits. Clinical Infectious Diseases, Vol. 67, 1 (2018), 134--136.Google ScholarCross Ref"",""Daniel J. Lizotte, Michael Bowling, and Susan A. Murphy. 2012. Linear fitted-Q iteration with multiple reward functions. Journal of Machine Learning Research, Vol. 13, 1 (2012), 3253--3295.Google ScholarDigital Library"",""David Madras, Toniann Pitassi, and Richard Zemel. 2018. Predict responsibly: Increasing fairness by learning to defer. (2018).Google Scholar"",""Qian Min and S.A. Murphy. 2011. Performance Guarantees for Individualized Treatment Rules. The Annals of Statistics, Vol. 39 (2011), 1180--1210.Google ScholarCross Ref"",""Hussein Mozannar and David Sontag. 2020. Consistent Estimators for Learning to Defer to an Expert. arXiv preprint arXiv:2006.01862 (2020).Google Scholar"",""Inbal Nahum-Shani, Min Qian, Daniel Almirall, William E Pelham, Beth Gnagy, Gregory A Fabiano, James G Waxmonsky, Jihnhee Yu, and Susan A Murphy. 2012. Q-learning: a data analysis method for constructing adaptive interventions. Psychological methods, Vol. 17, 4 (Dec 2012), 478--94. https://doi.org/10.1037/a0029373Google Scholar"",""Karen C Nanji, Diane L Seger, Sarah P Slight, Mary G Amato, Patrick E Beeler, Qoua L Her, Olivia Dalleur, Tewodros Eguale, Adrian Wong, Elizabeth R Silvers, et al. 2018. Medication-related clinical decision support alert overrides in inpatients. Journal of the American Medical Informatics Association, Vol. 25, 5 (2018), 476--481.Google ScholarCross Ref"",""Sriraam Natarajan and Prasad Tadepalli. 2005. Dynamic preferences in multi-criteria reinforcement learning. Proceedings of the 22nd International Conference on Machine Learning (2005), 601--608. https://doi.org/10.1145/1102351.1102427Google ScholarDigital Library"",""Mathupanee Oonsivilai, Yin Mo, Nantasit Luangasanatip, Yoel Lubell, Thyl Miliya, Pisey Tan, Lorn Loeuk, Paul Turner, and Ben Cooper. 2018. Using machine learning to guide targeted and locally-tailored empiric antibiotic prescribing in a children's hospital in Cambodia. Wellcome Open Research, Vol. 3 (2018).Google ScholarCross Ref"",""Diederik M. Roijers, Peter Vamplew, Shimon Whiteson, and Richard Dazeley. 2013. A survey of multi-objective sequential decision-making. Journal of Artificial Intelligence Research, Vol. 48 (2013), 67--113. https://doi.org/10.1613/jair.3987 arxiv: 1402.0590Google ScholarDigital Library"",""Philip Schulte, Anastasios Tsiatis, Eric Laber, and Marie Davidian. 2014. Q- and A-learning Methods for Estimating Optimal Treatment Regimes. Statist. Sci., Vol. 29, 4 (2014), 640--661.Google ScholarCross Ref"",""Walter E Stamm and S Ragnar Norrby. 2001. Urinary tract infections: disease panorama and challenges. Journal of infectious diseases, Vol. 183, Supplement 1 (2001), S1--S4.Google ScholarCross Ref"",""TJ Stewart. 1992. A critical survey on the status of multiple criteria decision making theory and practice. Omega, Vol. 20, 5--6 (1992), 569--586. https://doi.org/10.1016/0305-0483(92)90003-PGoogle ScholarCross Ref"",""Adith Swaminathan and Thorsten Joachims. 2015. Batch Learning from Logged Bandit Feedback through Counterfactual Risk Minimization. Journal of Machine Learning Research, Vol. 16, 52 (2015), 1731--1755.Google ScholarDigital Library"",""Ambuj Tewari and Peter L. Bartlett. 2007. On the consistency of multiclass classification methods. Journal of Machine Learning Research, Vol. 8 (2007), 1007--1025. https://doi.org/10.1007/11503415_10Google ScholarDigital Library"",""C. Vira and Y. Y. Haimes. 1983. Multiobjective Decision Making: Theory and Methodology. North-Holland.Google Scholar"",""C. F. Wang and X. J. Shi. 2019. Generation and application of patient-derived xenograft models in pancreatic cancer research. Chin. Med. J., Vol. 132, 22 (Nov 2019), 2729--2736.Google ScholarCross Ref"",""Bryan Wilder, Eric Horvitz, and Ece Kamar. 2020. Learning to Complement Humans. arXiv preprint arXiv:2005.00582 (2020).Google Scholar"",""Runzhe Yang, Xingyuan Sun, and Karthik Narasimhan. 2019. A Generalized Algorithm for Multi-Objective Reinforcement Learning and Policy Adaptation. In Advances in Neural Information Processing Systems 32, H Wallach, H Larochelle, A Beygelzimer, F dAlché Buc, E Fox, and R Garnett (Eds.). Curran Associates, Inc., 14610--14621.Google Scholar"",""Idan Yelin, Olga Snitser, Gal Novich, Rachel Katz, Ofir Tal, Miriam Parizade, Gabriel Chodick, Gideon Koren, Varda Shalev, and Roy Kishony. 2019. Personal clinical history predicts antibiotic resistance of urinary tract infections. Nature Medicine, Vol. 25, July (2019). https://doi.org/10.1038/s41591-019-0503--6Google ScholarCross Ref"",""M. Zeleny and J. L. Cochrane. 1982. Multiple Criteria Decision Making. McGraw-Hill, New York, NY, USA.Google Scholar"",""Tong Zhang. 2004. Statistical analysis of some multi-category large margin classification methods. Journal of Machine Learning Research, Vol. 5 (2004), 1225--1251.Google ScholarDigital Library"",""Yingqi Zhao, Donglin Zeng, A. John Rush, and Michael R. Kosorok. 2012. Estimating Individualized Treatment Rules Using Outcome Weighted Learning. J. Amer. Statist. Assoc., Vol. 107 (2012), 1106--1118. Issue 499.Google ScholarCross Ref"",""Ying-qi Zhao, Eric B Laber, and Bruce E Sands. 2019. Efficient augmentation and relaxation learning for individualized treatment rules using observational data. Journal of Machine Learning Research, Vol. 20 (2019), 1--23.Google Scholar"",""Hui Zou, Ji Zhu, and Trevor Hastie. 2008. New multicategory boosting algorithms based on multicategory fisher-consistent losses. Annals of Applied Statistics, Vol. 2, 4 (2008), 1290--1306. https://doi.org/10.1214/08-AOAS198Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403246,List-wise Fairness Criterion for Point Processes,"Many types of event sequence data exhibit triggering and clustering properties in space and time. Point processes are widely used in modeling such event data with applications such as predictive policing and disaster event forecasting. Although current algorithms can achieve significant event prediction accuracy, the historic data or the self-excitation property can introduce biased prediction. For example, hotspots ranked by event hazard rates can make the visibility of a disadvantaged group (e.g., racial minorities or the communities of lower social economic status) more apparent. Existing methods have explored ways to achieve parity between the groups by penalizing the objective function with several group fairness metrics. However, these metrics fail to measure the fairness on every prefix of the ranking. In this paper, we propose a novel list-wise fairness criterion for point processes, which can efficiently evaluate the ranking fairness in event prediction. We also present a strict definition of the unfairness consistency property of a fairness metric and prove that our list-wise fairness criterion satisfies this property. Experiments on several real-world spatial-temporal sequence datasets demonstrate the effectiveness of our list-wise fairness criterion.","[{""name"":""Jin Shang"",""id"":""/profile/99659575146""},{""name"":""Mingxuan Sun"",""id"":""/profile/99659219440""},{""name"":""Nina S.N. Lam"",""id"":""/profile/99659574516""},{""name"":""Jin Shang"",""id"":""/profile/99659575146""},{""name"":""Mingxuan Sun"",""id"":""/profile/99659219440""},{""name"":""Nina S.N. Lam"",""id"":""/profile/99659574516""}]","[""Richard Berk, Hoda Heidari, Shahin Jabbari, Matthew Joseph, Michael Kearns, Jamie Morgenstern, Seth Neel, and Aaron Roth. 2017. A convex framework for fair regression. arXiv preprint arXiv:1706.02409 (2017).Google Scholar"",""Wim Bernasco, Shane D Johnson, and Stijn Ruiter. 2015. Learning where to offend: Effects of past on future burglary locations. Applied Geography, Vol. 60 (2015), 120--129.Google ScholarCross Ref"",""Alex Beutel, Jilin Chen, Tulsee Doshi, Hai Qian, Li Wei, Yi Wu, Lukasz Heldt, Zhe Zhao, Lichan Hong, Ed H Chi, et al. 2019. Fairness in recommendation ranking through pairwise comparisons. In Proc. of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD). 2212--2220.Google ScholarDigital Library"",""Toon Calders, Faisal Kamiran, and Mykola Pechenizkiy. 2009. Building classifiers with independency constraints. In Proc. of the IEEE International Conference on Data Mining Workshops. 13--18.Google ScholarDigital Library"",""Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. 2012. Fairness through awareness. In Proc. of the 3rd Innovations in Theoretical Computer Science Conference. 214--226.Google ScholarDigital Library"",""Michael Feldman, Sorelle A Friedler, John Moeller, Carlos Scheidegger, and Suresh Venkatasubramanian. 2015. Certifying and removing disparate impact. In Proc. of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD). 259--268.Google ScholarDigital Library"",""Eric W Fox, Martin B Short, Frederic P Schoenberg, Kathryn D Coronges, and Andrea L Bertozzi. 2016. Modeling e-mail networks and inferring leadership using self-exciting point processes. J. Amer. Statist. Assoc., Vol. 111, 514 (2016), 564--584.Google ScholarCross Ref"",""Andrew M Freed. 2005. Earthquake triggering by static, dynamic, and postseismic stress transfer. Annu. Rev. Earth Planet. Sci., Vol. 33 (2005), 335--367.Google ScholarCross Ref"",""Moritz Hardt, Eric Price, and Nati Srebro. 2016. Equality of opportunity in supervised learning. In Proc. of the Annual Conference on Neural Information Processing Systems (NeurIPS). 3315--3323.Google Scholar"",""Zubin Jelveh and Michael Luca. 2014. Towards diagnosing accuracy loss in discrimination-aware classification: An application to predictive policing. Fairness, Accountability and Transparency in Machine Learning, Vol. 26, 1 (2014), 137--141.Google Scholar"",""Toshihiro Kamishima, Shotaro Akaho, and Jun Sakuma. 2011. Fairness-aware learning through regularization approach. In Proc. of the IEEE 11th International Conference on Data Mining Workshops. 643--650.Google ScholarDigital Library"",""Juhi Kulshrestha, Motahhare Eslami, Johnnatan Messias, Muhammad Bilal Zafar, Saptarshi Ghosh, Krishna P Gummadi, and Karrie Karahalios. 2017. Quantifying search bias: Investigating sources of bias for political searches in social media. In Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing. 417--432.Google ScholarDigital Library"",""Jeffrey C Lagarias, James A Reeds, Margaret H Wright, and Paul E Wright. 1998. Convergence properties of the Nelder--Mead simplex method in low dimensions. SIAM Journal on optimization, Vol. 9, 1 (1998), 112--147.Google Scholar"",""Scott Linderman and Ryan Adams. 2014. Discovering latent network structure in point process data. In Proc. of the International Conference on Machine Learning (ICML). 1413--1421.Google Scholar"",""Christos Louizos, Kevin Swersky, Yujia Li, Max Welling, and Richard Zemel. 2015. The variational fair autoencoder. arXiv preprint arXiv:1511.00830 (2015).Google Scholar"",""George Mohler, Jeremy Carter, and Rajeev Raje. 2018a. Improving social harm indices with a modulated Hawkes process. International Journal of Forecasting, Vol. 34, 3 (2018), 431--439.Google ScholarCross Ref"",""George Mohler, Michael D Porter, Jeremy Carter, and Gary LaFree. 2018b. Learning to rank spatio-temporal event hotspots. In Proceedings of the 7th international workshop on urban computing .Google Scholar"",""George Mohler, Rajeev Raje, Jeremy Carter, Matthew Valasik, and Jeffrey Brantingham. 2018c. A penalized likelihood method for balancing accuracy and fairness in predictive policing. In Proc. of the IEEE International Conference on Systems, Man, and Cybernetics (SMC). 2454--2459.Google ScholarCross Ref"",""Tao Qin, Tie-Yan Liu, and Hang Li. 2010. A general approximation framework for direct optimization of information retrieval measures. Information retrieval, Vol. 13, 4 (2010), 375--397.Google Scholar"",""Nikhil Rao, Hsiang-Fu Yu, Pradeep K Ravikumar, and Inderjit S Dhillon. 2015. Collaborative filtering with graph information: Consistency and scalable methods. In Proc. of the Annual Conference on Neural Information Processing Systems (NeurIPS). 2107--2115.Google Scholar"",""Chris Russell, Matt J Kusner, Joshua Loftus, and Ricardo Silva. 2017. When worlds collide: Integrating different counterfactual assumptions in fairness. In Proc. of the Annual Conference on Neural Information Processing Systems (NeurIPS). 6414--6423.Google Scholar"",""Jin Shang and Mingxuan Sun. 2018. Local Low-Rank Hawkes Processes for Temporal User-Item Interactions. In Proc. of the IEEE International Conference on Data Mining (ICDM). 427--436.Google ScholarCross Ref"",""Jin Shang and Mingxuan Sun. 2019. Geometric Hawkes Processes with Graph Convolutional Recurrent Neural Networks. In Proc. of the AAAI Conference on Artificial Intelligence, Vol. 33. 4878--4885.Google ScholarCross Ref"",""Ashudeep Singh and Thorsten Joachims. 2018. Fairness of exposure in rankings. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 2219--2228.Google ScholarDigital Library"",""Daniel A Spielman and Shang-Hua Teng. 2004. Smoothed analysis of algorithms: Why the simplex algorithm usually takes polynomial time. Journal of the ACM (JACM), Vol. 51, 3 (2004), 385--463.Google ScholarDigital Library"",""Yining Wang, Liwei Wang, Yuanzhi Li, Di He, and Tie-Yan Liu. 2013. A theoretical analysis of NDCG type ranking measures. In Proc. of the Conference on Learning Theory (COLT). 25--54.Google Scholar"",""Maximilian J Werner, Agnès Helmstetter, David D Jackson, and Yan Y Kagan. 2011. High-resolution long-term and short-term earthquake forecasts for California. Bulletin of the Seismological Society of America, Vol. 101, 4 (2011), 1630--1648.Google ScholarCross Ref"",""Ke Yang and Julia Stoyanovich. 2017. Measuring fairness in ranked outputs. In Proceedings of the 29th International Conference on Scientific and Statistical Database Management. 1--6.Google ScholarDigital Library"",""Sirui Yao and Bert Huang. 2017. Beyond parity: Fairness objectives for collaborative filtering. In Proc. of the Annual Conference on Neural Information Processing Systems (NeurIPS). 2921--2930.Google Scholar"",""Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rodriguez, and Krishna P Gummadi. 2017. Fairness beyond disparate treatment \u0026 disparate impact: Learning classification without disparate mistreatment. In Proc. of the International World Wide Web Conference (WWW). 1171--1180.Google ScholarDigital Library"",""Meike Zehlike, Francesco Bonchi, Carlos Castillo, Sara Hajian, Mohamed Megahed, and Ricardo Baeza-Yates. 2017. Fa* ir: A fair top-k ranking algorithm. In Proc. of the ACM International Conference on Information and Knowledge Management (CIKM). 1569--1578.Google ScholarDigital Library"",""Richard Zemel, Yu Wu, Kevin Swersky, Toniann Pitassi, and Cynthia Dwork. 2013. Learning Fair Representations. In Proc. of the International Conference on Machine Learning (ICML) (Atlanta, GA, USA). 325--333.Google Scholar"",""Lei Zou, NSN Lam, Shayan Shams, Heng Cai, Michelle A Meyer, Seungwon Yang, Kisung Lee, Seung-Jong Park, and Margaret A Reams. 2018. Social and geographical disparities in Twitter use during Hurricane Harvey. International Journal of Digital Earth (2018), 1--19.Google Scholar""]"
https://doi.org/10.1145/3394486.3403247,Neural Subgraph Isomorphism Counting,"In this paper, we study a new graph learning problem: learning to count subgraph isomorphisms. Different from other traditional graph learning problems such as node classification and link prediction, subgraph isomorphism counting is NP-complete and requires more global inference to oversee the whole graph. To make it scalable for large-scale graphs and patterns, we propose a learning framework that augments different representation learning architectures and iteratively attends pattern and target data graphs to memorize intermediate states of subgraph isomorphism searching for global counting. We develop both small graphs (<= 1,024 subgraph isomorphisms in each) and large graphs (<= 4,096 subgraph isomorphisms in each) sets to evaluate different representation and interaction modules. A mutagenic compound dataset, MUTAG, is also used to evaluate neural models and demonstrate the success of transfer learning. While the learning based approach is inexact, we are able to generalize to count large patterns and data graphs in linear time compared to the exponential time of the original NP-complete problem. Experimental results show that learning based subgraph isomorphism counting can speed up the traditional algorithm, VF2, 10-1,000 times with acceptable errors. Domain adaptation based on fine-tuning also shows the usefulness of our approach in real-world applications.","[{""name"":""Xin Liu"",""id"":""/profile/99659370216""},{""name"":""Haojie Pan"",""id"":""/profile/99659368604""},{""name"":""Mutian He"",""id"":""/profile/99659573640""},{""name"":""Yangqiu Song"",""id"":""/profile/81317500799""},{""name"":""Xin Jiang"",""id"":""/profile/81438594913""},{""name"":""Lifeng Shang"",""id"":""/profile/99659001423""},{""name"":""Xin Liu"",""id"":""/profile/99659370216""},{""name"":""Haojie Pan"",""id"":""/profile/99659368604""},{""name"":""Mutian He"",""id"":""/profile/99659573640""},{""name"":""Yangqiu Song"",""id"":""/profile/81317500799""},{""name"":""Xin Jiang"",""id"":""/profile/81438594913""},{""name"":""Lifeng Shang"",""id"":""/profile/99659001423""}]","[""Noga Alon, Phuong Dao, Iman Hajirasouliha, Fereydoun Hormozdiari, and Süleyman Cenk Sahinalp. 2008. Biomolecular network motif counting and discovery by color coding. In ISMB. 241--249.Google Scholar"",""Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural Machine Translation by Jointly Learning to Align and Translate. In ICLR.Google Scholar"",""Peter W. Battaglia, Jessica B. Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vin'i cius Flores Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, cC aglar Gü lcc ehre, H. Francis Song, Andrew J. Ballard, Justin Gilmer, George E. Dahl, Ashish Vaswani, Kelsey R. Allen, Charles Nash, Victoria Langston, Chris Dyer, Nicolas Heess, Daan Wierstra, Pushmeet Kohli, Matthew Botvinick, Oriol Vinyals, Yujia Li, and Razvan Pascanu. 2018. Relational inductive biases, deep learning, and graph networks. CoRR, Vol. abs/1806.01261 (2018).Google Scholar"",""Yoshua Bengio, Jé rô me Louradour, Ronan Collobert, and Jason Weston. 2009. Curriculum learning. In ICML. 41--48.Google Scholar"",""Vincenzo Carletti, Pasquale Foggia, Alessia Saggese, and Mario Vento. 2018. Challenging the Time Complexity of Exact Subgraph Isomorphism for Huge and Dense Graphs with VF3. PAMI, Vol. 40, 4 (2018), 804--818.Google ScholarCross Ref"",""Zhengdao Chen, Soledad Villar, Lei Chen, and Joan Bruna. 2019. On the equivalence between graph isomorphism testing and function approximation with GNNs. In NeurIPS. 15868--15876.Google Scholar"",""Kyunghyun Cho, Bart van Merrienboer, cC aglar Gü lcc ehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation. In EMNLP. 1724--1734.Google Scholar"",""Luigi P. Cordella, Pasquale Foggia, Carlo Sansone, and Mario Vento. 2004. A (Sub)Graph Isomorphism Algorithm for Matching Large Graphs. PAMI, Vol. 26, 10 (2004), 1367--1372.Google ScholarDigital Library"",""Zihang Dai, Zhilin Yang, Yiming Yang, Jaime G. Carbonell, Quoc Viet Le, and Ruslan Salakhutdinov. 2019. Transformer-XL: Attentive Language Models beyond a Fixed-Length Context. In ACL. 2978--2988.Google Scholar"",""Talya Eden, Amit Levi, Dana Ron, and C. Seshadhri. 2017. Approximately Counting Triangles in Sublinear Time. SIAM J. Comput., Vol. 46, 5 (2017), 1603--1646.Google ScholarCross Ref"",""Changjun Fan, Li Zeng, Yuhui Ding, Muhao Chen, Yizhou Sun, and Zhong Liu. 2019. Learning to Identify High Betweenness Centrality Nodes from Scratch: A Novel Graph Neural Network Approach. In CIKM. 559--568.Google Scholar"",""Wenfei Fan, Jianzhong Li, Shuai Ma, Nan Tang, Yinghui Wu, and Yunpeng Wu. 2010. Graph Pattern Matching: From Intractable to Polynomial Time. VLDB, Vol. 3, 1 (2010), 264--275.Google ScholarDigital Library"",""Yuan Fang, Wenqing Lin, Vincent Wenchen Zheng, Min Wu, Kevin Chen-Chuan Chang, and Xiaoli Li. 2016. Semantic proximity search on graphs with metagraph-based learning. In ICDE. 277--288.Google Scholar"",""Michele Gori, Gabriele Monfardini, and Franco Scarselli. 2005. A new model for learning in graph domains. IJCNN, Vol. 2 (2005), 729--734.Google Scholar"",""Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka Grabska-Barwinska, Sergio Gomez Colmenarejo, Edward Grefenstette, Tiago Ramalho, John Agapiou, Adrià Puigdomè nech Badia, Karl Moritz Hermann, Yori Zwols, Georg Ostrovski, Adam Cain, Helen King, Christopher Summerfield, Phil Blunsom, Koray Kavukcuoglu, and Demis Hassabis. 2016. Hybrid computing using a neural network with dynamic external memory. Nature, Vol. 538, 7626 (2016), 471--476.Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable Feature Learning for Networks. In SIGKDD. 855--864.Google Scholar"",""William L. Hamilton, Rex Ying, and Jure Leskovec. 2017a. Representation Learning on Graphs: Methods and Applications. IEEE Data Eng. Bull., Vol. 40, 3 (2017), 52--74.Google Scholar"",""William L. Hamilton, Zhitao Ying, and Jure Leskovec. 2017b. Inductive Representation Learning on Large Graphs. In NeurIPS. 1024--1034.Google Scholar"",""Wook-Shin Han, Jinsoo Lee, and Jeong-Hoon Lee. 2013. Turbo(_iso ): towards ultrafast and robust subgraph isomorphism search in large graph databases. In SIGMOD. 337--348.Google Scholar"",""Huahai He and Ambuj K. Singh. 2008. Graphs-at-a-time: query language and access methods for graph databases. In SIGMOD. 405--418.Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep Residual Learning for Image Recognition. In CVPR. 770--778.Google Scholar"",""Sepp Hochreiter and Jü rgen Schmidhuber. 1997. Long Short-Term Memory. Neural Computation, Vol. 9, 8 (1997), 1735--1780.Google ScholarDigital Library"",""Minghao Hu, Yuxing Peng, Zhen Huang, Xipeng Qiu, Furu Wei, and Ming Zhou. 2018. Reinforced Mnemonic Reader for Machine Reading Comprehension. In IJCAI. 4099--4106.Google Scholar"",""Jun Huan, Wei Wang, and Jan F. Prins. 2003. Efficient Mining of Frequent Subgraphs in the Presence of Isomorphism. In ICDM. 549--552.Google Scholar"",""Zhipeng Huang, Yudian Zheng, Reynold Cheng, Yizhou Sun, Nikos Mamoulis, and Xiang Li. 2016. Meta Structure: Computing Relevance in Large Heterogeneous Information Networks. In SIGKDD. 1595--1604.Google ScholarDigital Library"",""He Jiang, Yangqiu Song, Chenguang Wang, Ming Zhang, and Yizhou Sun. 2017. Semi-supervised Learning over Heterogeneous Information Networks by Ensemble of Meta-graph Guided Random Walks. In IJCAI. 1944--1950.Google Scholar"",""Yoon Kim. 2014. Convolutional Neural Networks for Sentence Classification. In EMNLP. 1746--1751.Google Scholar"",""Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In ICLR.Google Scholar"",""Ankit Kumar, Ozan Irsoy, Peter Ondruska, Mohit Iyyer, James Bradbury, Ishaan Gulrajani, Victor Zhong, Romain Paulus, and Richard Socher. 2016. Ask Me Anything: Dynamic Memory Networks for Natural Language Processing. In ICML. 1378--1387.Google Scholar"",""Michihiro Kuramochi and George Karypis. 2004. GREW-A Scalable Frequent Subgraph Discovery Algorithm. In ICDM. 439--442.Google Scholar"",""Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard S. Zemel. 2016. Gated Graph Sequence Neural Networks. In ICLR.Google Scholar"",""Ilya Loshchilov and Frank Hutter. 2019. Decoupled Weight Decay Regularization. In ICLR.Google Scholar"",""Shuai Ma, Yang Cao, Wenfei Fan, Jinpeng Huai, and Tianyu Wo. 2014. Strong simulation: Capturing topology in graph pattern matching. TODS, Vol. 39, 1 (2014), 4:1--4:46.Google ScholarDigital Library"",""Ron Milo, Shai Shen-Orr, Shalev Itzkovitz, Nadav Kashtan, Dmitri Chklovskii, and Uri Alon. 2002. Network motifs: simple building blocks of complex networks. Science, Vol. 298, 5594 (2002), 824--827.Google Scholar"",""Mathias Niepert, Mohamed Ahmed, and Konstantin Kutzkov. 2016. Learning Convolutional Neural Networks for Graphs. In ICML. 2014--2023.Google Scholar"",""Sinno Jialin Pan and Qiang Yang. 2010. A Survey on Transfer Learning. TKDE, Vol. 22, 10 (2010), 1345--1359.Google ScholarDigital Library"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. DeepWalk: online learning of social representations. In SIGKDD. 701--710.Google Scholar"",""Natasa Przulj, Derek G. Corneil, and Igor Jurisica. 2006. Efficient estimation of graphlet frequency distributions in protein-protein interaction networks. Bioinformatics, Vol. 22, 8 (2006), 974--980.Google ScholarDigital Library"",""Franco Scarselli, Sweah Liang Yong, Marco Gori, Markus Hagenbuchner, Ah Chung Tsoi, and Marco Maggini. 2005. Graph Neural Networks for Ranking Web Pages. In WI. 666--672.Google Scholar"",""Michael Sejr Schlichtkrull, Thomas N. Kipf, Peter Bloem, Rianne van den Berg, Ivan Titov, and Max Welling. 2018. Modeling Relational Data with Graph Convolutional Networks. In ESWC. 593--607.Google Scholar"",""Nino Shervashidze, Pascal Schweitzer, Erik Jan van Leeuwen, Kurt Mehlhorn, and Karsten M. Borgwardt. 2011. Weisfeiler-Lehman Graph Kernels. J. Mach. Learn. Res., Vol. 12 (2011), 2539--2561.Google ScholarDigital Library"",""Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. 2015. End-To-End Memory Networks. In NeurIPS. 2440--2448.Google Scholar"",""Zhao Sun, Hongzhi Wang, Haixun Wang, Bin Shao, and Jianzhong Li. 2012. Efficient Subgraph Matching on Billion Node Graphs. PVLDB, Vol. 5, 9 (2012), 788--799.Google ScholarDigital Library"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. LINE: Large-scale Information Network Embedding. In WWW. 1067--1077.Google ScholarDigital Library"",""Carlos H. C. Teixeira, Leornado Cotta, Bruno Ribeiro, and Wagner Meira Jr. 2018. Graph Pattern Mining and Learning through User-Defined Relations. In ICDM. 1266--1271.Google Scholar"",""Matteo Togninalli, M. Elisabetta Ghisu, Felipe Llinares-Ló pez, Bastian Rieck, and Karsten M. Borgwardt. 2019. Wasserstein Weisfeiler-Lehman Graph Kernels. In NeurIPS. 6436--6446.Google Scholar"",""Charalampos E. Tsourakakis. 2008. Fast Counting of Triangles in Large Real Networks without Counting: Algorithms and Laws. In ICDM. 608--617.Google Scholar"",""Julian R. Ullmann. 1976. An Algorithm for Subgraph Isomorphism. J. ACM, Vol. 23, 1 (1976), 31--42.Google ScholarDigital Library"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In NeurIPS. 5998--6008.Google Scholar"",""Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. 2018. Graph Attention Networks. In ICLR.Google Scholar"",""S. V. N. Vishwanathan, Nicol N. Schraudolph, Risi Kondor, and Karsten M. Borgwardt. 2010. Graph Kernels. J. Mach. Learn. Res., Vol. 11 (2010), 1201--1242.Google ScholarDigital Library"",""Pinghui Wang, John C. S. Lui, Bruno F. Ribeiro, Don Towsley, Junzhou Zhao, and Xiaohong Guan. 2014. Efficiently Estimating Motif Statistics of Large Networks. TKDD, Vol. 9, 2 (2014), 8:1--8:27.Google ScholarDigital Library"",""Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2019. How Powerful are Graph Neural Networks?. In ICLR.Google Scholar"",""Keyulu Xu, Jingling Li, Mozhi Zhang, Simon S. Du, Ken-ichi Kawarabayashi, and Stefanie Jegelka. 2020. What Can Neural Networks Reason About?. In ICLR.Google Scholar"",""Xifeng Yan and Jiawei Han. 2002. gSpan: Graph-Based Substructure Pattern Mining. In ICDM. 721--724.Google Scholar"",""Xifeng Yan, Philip S. Yu, and Jiawei Han. 2004. Graph Indexing: A Frequent Structure-based Approach. In SIGMOD. 335--346.Google ScholarDigital Library"",""Pinar Yanardag and S. V. N. Vishwanathan. 2015. Deep Graph Kernels. In SIGKDD. 1365--1374.Google Scholar"",""Jiaxuan You, Rex Ying, Xiang Ren, William L. Hamilton, and Jure Leskovec. 2018. GraphRNN: Generating Realistic Graphs with Deep Auto-regressive Models. In ICML. 5694--5703.Google Scholar"",""Huan Zhao, Quanming Yao, Jianda Li, Yangqiu Song, and Dik Lun Lee. 2017. Meta-Graph Based Recommendation Fusion over Heterogeneous Information Networks. In SIGKDD. 635--644.Google Scholar""]"
https://doi.org/10.1145/3394486.3403248,Hypergraph Clustering Based on PageRank,"A hypergraph is a useful combinatorial object to model ternary or higher-order relations among entities. Clustering hypergraphs is a fundamental task in network analysis. In this study, we develop two clustering algorithms based on personalized PageRank on hypergraphs. The first one is local in the sense that its goal is to find a tightly connected vertex set with a bounded volume including a specified vertex. The second one is global in the sense that its goal is to find a tightly connected vertex set. For both algorithms, we discuss theoretical guarantees on the conductance of the output vertex set. Also, we experimentally demonstrate that our clustering algorithms outperform existing methods in terms of both the solution quality and running time. To the best of our knowledge, ours are the first practical algorithms for hypergraphs with theoretical guarantees on the conductance of the output set.","[{""name"":""Yuuki Takai"",""id"":""/profile/99659573191""},{""name"":""Atsushi Miyauchi"",""id"":""/profile/99658635316""},{""name"":""Masahiro Ikeda"",""id"":""/profile/99659574701""},{""name"":""Yuichi Yoshida"",""id"":""/profile/99659574217""},{""name"":""Yuuki Takai"",""id"":""/profile/99659573191""},{""name"":""Atsushi Miyauchi"",""id"":""/profile/99658635316""},{""name"":""Masahiro Ikeda"",""id"":""/profile/99659574701""},{""name"":""Yuichi Yoshida"",""id"":""/profile/99659574217""}]","[""Sameer Agarwal, Kristin Branson, and Serge Belongie. 2006. Higher order learning with graphs. In ICML. 17--24.Google Scholar"",""Sameer Agarwal, Jongwoo Lim, Lihi Zelnik-Manor, Pietro Perona, David Kriegman, and Serge Belongie. 2005. Beyond pairwise clustering. In CVPR. 838--845.Google Scholar"",""Noga Alon. 1986. Eigenvalues and expanders. Combinatorica, Vol. 6, 2 (1986), 83--96.Google ScholarDigital Library"",""Noga Alon and V. D. Milman. 1985. $łambda_1$, Isoperimetric inequalities for graphs, and superconcentrators. Journal of Combinatorial Theory, Series B, Vol. 38, 1 (1985), 73--88.Google ScholarCross Ref"",""Reid Andersen, Fan Chung, and Kevin Lang. 2007. Using PageRank to locally partition a graph. Internet Mathematics, Vol. 4, 1 (2007), 35--64.Google ScholarCross Ref"",""Reid Andersen and Yuval Peres. 2009. Finding sparse cuts locally using evolving sets. STOC. 235--244.Google Scholar"",""Marianna Bolla. 1993. Spectra, Euclidean representations and clusterings of hypergraphs. Discrete Mathematics, Vol. 117 (1993), 19--39.Google ScholarDigital Library"",""T-H Hubert Chan, Anand Louis, Zhihao Gavin Tang, and Chenzi Zhang. 2018. Spectral properties of hypergraph Laplacian and approximation algorithms. J. ACM, Vol. 65, 3 (2018), 15--48.Google Scholar"",""I Chien, Chung-Yi Lin, and I-Hsiang Wang. 2018. Community detection in hypergraphs: Optimal statistical limit and efficient algorithms. In AISTATS. 871--879.Google Scholar"",""Fan Chung. 2007. The heat kernel as the pagerank of a graph. Proceedings of the National Academy of Sciences of the United States of America, Vol. 104, 50 (2007), 19735--19740.Google ScholarCross Ref"",""Pedro F. Felzenszwalb and Daniel P. Huttenlocher. 2004. Efficient graph-based image segmentation. International Journal of Computer Vision, Vol. 59, 2 (2004), 167--181.Google ScholarDigital Library"",""Santo Fortunato. 2010. Community detection in graphs. Physics Reports, Vol. 486, 3--5 (2010), 75--174.Google ScholarCross Ref"",""Kaito Fujii, Tasuku Soma, and Yuichi Yoshida. 2018. Polynomial-time algorithms for submodular Laplacian systems. arXiv preprint, arXiv:1803.10923 (2018).Google Scholar"",""Shayan Oveis Gharan and Luca Trevisan. 2012. Approximating the expansion profile and almost optimal local graph clustering. In FOCS. 187--196.Google Scholar"",""Debarghya Ghoshdastidar and Ambedkar Dukkipati. 2014. Consistency of spectral partitioning of uniform hypergraphs under planted partition model. In NIPS. 397--405.Google Scholar"",""Masahiro Ikeda, Atsushi Miyauchi, Yuuki Takai, and Yuichi Yoshida. 2018. Finding Cheeger cuts in hypergraphs via heat equation. arXiv preprint arXiv:1809.04396 (2018).Google Scholar"",""Glen Jeh and Jennifer Widom. 2003. Scaling personalized web search. In WWW. 271--279.Google Scholar"",""Kyle Kloster and David F. Gleich. 2014. Heat kernel based community detection. In KDD. 1386--1395.Google Scholar"",""Tsz C. Kwok, Lap C. Lau, and Yin T. Lee. 2017. Improved Cheeger's inequality and analysis of local graph partitioning using vertex expansion and expansion profile. SIAM J. Comput., Vol. 46, 3 (2017), 890--910.Google ScholarCross Ref"",""Marius Leordeanu and Cristian Sminchisescu. 2012. Efficient hypergraph clustering. In AISTATS. 676--684.Google Scholar"",""Pan Li, Niao He, and Olgica Milenkovic. 2018. Quadratic decomposable submodular function minimization. In NeurIPS. 1054--1064.Google Scholar"",""Hairong Liu, Longin J. Latecki, and Shuicheng Yan. 2010. Robust clustering as ensembles of affinity relations. In NIPS. 1414--1422.Google Scholar"",""Juan Peypouquet and Sylvain Sorin. 2010. Evolution Equations for Maximal Monotone Operators: Asymptotic Analysis in Continuous and Discrete Time. Journal of Convex Analysis, Vol. 17, 3\u00264 (2010), 1113--1163.Google Scholar"",""J. A. Rodri'guez. 2002. On the Laplacian eigenvalues and metric parameters of hypergraphs. Linear and Multilinear Algebra, Vol. 50, 1 (2002), 1--14.Google ScholarCross Ref"",""Samuel Rota Bulo and Marcello Pelillo. 2013. A game-theoretic approach to hypergraph clustering. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 35, 6 (2013), 1312--1327.Google ScholarDigital Library"",""Daniel A. Spielman and Shang-Hua Teng. 2013. A local clustering algorithm for massive graphs and its application to nearly linear time graph partitioning. SIAM J. Comput., Vol. 42, 1 (2013), 1--26.Google ScholarCross Ref"",""Yuuki Takai, Atsushi Miyauchi, Masahiro Ikeda, and Yuichi Yoshida. 2020. Hypergraph Clustering Based on PageRank. (2020). arxiv: cs.DS/2006.08302Google Scholar"",""Yuichi Yoshida. 2016. Nonlinear Laplacian for digraphs and its applications to network analysis. In WSDM. 483--492.Google Scholar"",""Yuichi Yoshida. 2019. Cheeger inequalities for submodular transformations. In SODA. 2582--2601.Google Scholar"",""Dengyong Zhou, Jiayuan Huang, and Bernhard Schölkopf. 2005. Beyond pairwise classification and clustering using hypergraphs. Max Plank Institute for Biological Cybernetics, Tübingen, Germany (2005).Google Scholar"",""Dengyong Zhou, Jiayuan Huang, and Bernhard Schölkopf. 2007. Learning with hypergraphs: Clustering, classification, and embedding. In NIPS. 1601--1608.Google Scholar"",""Jason Y. Zien, Martin D. F. Schlag, and Pak K. Chan. 1999. Multilevel spectral hypergraph partitioning with arbitrary vertex sizes. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 18, 9 (1999), 1389--1399.Google Scholar""]"
https://doi.org/10.1145/3394486.3403249,DeepSinger: Singing Voice Synthesis with Data Mined From the Web,"In this paper, we develop DeepSinger, a multi-lingual multi-singer singing voice synthesis (SVS) system, which is built from scratch using singing training data mined from music websites. The pipeline of DeepSinger consists of several steps, including data crawling, singing and accompaniment separation, lyrics-to-singing alignment, data filtration, and singing modeling. Specifically, we design a lyrics-to-singing alignment model to automatically extract the duration of each phoneme in lyrics starting from coarse-grained sentence level to fine-grained phoneme level, and further design a multi-lingual multi-singer singing model based on a feed-forward Transformer to directly generate linear-spectrograms from lyrics, and synthesize voices using Griffn-Lim. DeepSinger has several advantages over previous SVS systems: 1) to the best of our knowledge, it is the first SVS system that directly mines training data from music websites, 2) the lyrics-to-singing alignment model further avoids any human efforts for alignment labeling and greatly reduces labeling cost, 3) the singing model based on a feed-forward Transformer is simple and efficient, by removing the complicated acoustic feature modeling in parametric synthesis and leveraging a reference encoder to capture the timbre of a singer from noisy singing data, and 4) it can synthesize singing voices in multiple languages and multiple singers. We evaluate DeepSinger on our mined singing dataset that consists of about 92 hours data from 89 singers on three languages (Chinese, Cantonese and English). The results demonstrate that with the singing data purely mined from the Web, DeepSinger can synthesize high-quality singing voices in terms of both pitch accuracy and voice naturalness. Our audio samples are shown in https://speechresearch.github.io/deepsinger/.","[{""name"":""Yi Ren"",""id"":""/profile/99659574292""},{""name"":""Xu Tan"",""id"":""/profile/99659364242""},{""name"":""Tao Qin"",""id"":""/profile/81100549718""},{""name"":""Jian Luan"",""id"":""/profile/99659574103""},{""name"":""Zhou Zhao"",""id"":""/profile/99658748124""},{""name"":""Tie-Yan Liu"",""id"":""/profile/81350580267""},{""name"":""Yi Ren"",""id"":""/profile/99659574292""},{""name"":""Xu Tan"",""id"":""/profile/99659364242""},{""name"":""Tao Qin"",""id"":""/profile/81100549718""},{""name"":""Jian Luan"",""id"":""/profile/99659574103""},{""name"":""Zhou Zhao"",""id"":""/profile/99658748124""},{""name"":""Tie-Yan Liu"",""id"":""/profile/81350580267""}]","[""Merlijn Blaauw and Jordi Bonada. 2017. A neural parametric singing synthesizer modeling timbre and expression from natural songs. Applied Sciences, Vol. 7, 12 (2017), 1313.Google ScholarCross Ref"",""Paul Boersma et al. 2002. Praat, a system for doing phonetics by computer. Glot international, Vol. 5 (2002).Google Scholar"",""Jamie Callan, Mark Hoy, Changkuk Yoo, and Le Zhao. 2009. Clueweb09 data set.Google Scholar"",""Zhe Cao, Tao Qin, Tie-Yan Liu, Ming-Feng Tsai, and Hang Li. 2007. Learning to rank: from pairwise approach to listwise approach. In Proceedings of the 24th international conference on Machine learning. 129--136.Google ScholarDigital Library"",""Pritish Chandna, Merlijn Blaauw, Jordi Bonada, and Emilia Gomez. 2019. WGANSing: A Multi-Voice Singing Voice Synthesizer Based on the Wasserstein-GAN. arXiv preprint arXiv:1903.10729 (2019).Google Scholar"",""Yu-Ren Chien, Hsin-Min Wang, Shyh-Kang Jeng, Yu-Ren Chien, Hsin-Min Wang, and Shyh-Kang Jeng. 2016. Alignment of lyrics with accompanied singing audio based on acoustic-phonetic vowel likelihood modeling. TASLP, Vol. 24, 11 (2016), 1998--2008.Google Scholar"",""Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, and Ilya Sutskever. 2020. Jukebox: A generative model for music. arXiv preprint arXiv:2005.00341 (2020).Google Scholar"",""Zhiyong Zhang Dong Wang, Xuewei Zhang. 2015. THCHS-30 : A Free Chinese Speech Corpus. http://arxiv.org/abs/1512.01882Google Scholar"",""Georgi Dzhambazov et al. 2017. Knowledge-based probabilistic modeling for tracking lyrics in music audio signals. Ph.D. Dissertation. Universitat Pompeu Fabra.Google Scholar"",""Hiromasa Fujihara, Masataka Goto, Jun Ogata, and Hiroshi G Okuno. 2011. LyricSynchronizer: Automatic synchronization system between musical audio signals and lyrics. IJSTSP, Vol. 5, 6 (2011), 1252--1261.Google ScholarCross Ref"",""Daniel Griffin and Jae Lim. 1984. Signal estimation from modified short-time Fourier transform. ICASSP, Vol. 32, 2 (1984), 236--243.Google ScholarCross Ref"",""Chitralekha Gupta, Rong Tong, Haizhou Li, and Ye Wang. 2018. Semi-supervised Lyrics and Solo-singing Alignment.. In ISMIR. 600--607.Google Scholar"",""Chitralekha Gupta, Emre Yilmaz, and Haizhou Li. 2019. Acoustic Modeling for Automatic Lyrics-to-Audio Alignment. arXiv preprint arXiv:1906.10369 (2019).Google Scholar"",""Romain Hennequin, Anis Khlif, Felix Voituret, and Manuel Moussalam. 2019. Spleeter: A fast and state-of-the art music source separation tool with pre-trained models. In Proc. International Society for Music Information Retrieval Conference .Google Scholar"",""Yukiya Hono, Kei Hashimoto, Keiichiro Oura, Yoshihiko Nankaku, and Keiichi Tokuda. 2019. Singing Voice Synthesis Based on Generative Adversarial Networks. In ICASSP 2019. IEEE, 6955--6959.Google Scholar"",""Andrew J Hunt and Alan W Black. 1996. Unit selection in a concatenative speech synthesis system using a large speech database. In ICASSP 1996, Vol. 1. IEEE, 373--376.Google ScholarDigital Library"",""Herbert Jaeger. 2002. Tutorial on training recurrent neural networks, covering BPPT, RTRL, EKF and the\"" echo state network\"" approach. Vol. 5. GMD-Forschungszentrum Informationstechnik Bonn.Google Scholar"",""Nal Kalchbrenner, Erich Elsen, Karen Simonyan, Seb Noury, Norman Casagrande, Edward Lockhart, Florian Stimberg, Aaron van den Oord, Sander Dieleman, and Koray Kavukcuoglu. 2018. Efficient neural audio synthesis. arXiv preprint arXiv:1802.08435 (2018).Google Scholar"",""Juntae Kim, Heejin Choi, Jinuk Park, Sangjin Kim, Jongjin Kim, and Minsoo Hahn. 2018. Korean Singing Voice Synthesis System based on an LSTM Recurrent Neural Network. In INTERSPEECH 2018. ISCA.Google ScholarCross Ref"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Juheon Lee, Hyeong-Seok Choi, Chang-Bin Jeon, Junghyun Koo, and Kyogu Lee. 2019. Adversarially Trained End-to-end Korean Singing Voice Synthesis System. arXiv preprint arXiv:1908.01919 (2019).Google Scholar"",""Hao Li, Yongguo Kang, and Zhenyu Wang. 2018. EMPHASIS: An emotional phoneme-based acoustic model for speech synthesis system. arXiv preprint arXiv:1806.09276 (2018).Google Scholar"",""Wen Li, Limin Wang, Wei Li, Eirikur Agustsson, and Luc Van Gool. 2017. Webvision database: Visual learning and understanding from web data. arXiv preprint arXiv:1708.02862 (2017).Google Scholar"",""Peiling Lu, Jie Wu, Jian Luan, Xu Tan, and Li Zhou. 2020. XiaoiceSing: A High-Quality and Integrated Singing Voice Synthesis System. arXiv preprint arXiv:2006.06261 (2020).Google Scholar"",""Michael McAuliffe, Michaela Socolof, Sarah Mihuc, Michael Wagner, and Morgan Sonderegger. 2017. Montreal Forced Aligner: Trainable Text-Speech Alignment Using Kaldi. In Interspeech. 498--502.Google Scholar"",""Annamaria Mesaros and Tuomas Virtanen. 2008. Automatic alignment of music audio and lyrics. In Proceedings of the 11th Int. Conference on Digital Audio Effects (DAFx-08) .Google Scholar"",""Kazuhiro Nakamura, Kei Hashimoto, Keiichiro Oura, Yoshihiko Nankaku, and Keiichi Tokuda. 2019. Singing voice synthesis based on convolutional neural networks. arXiv preprint arXiv:1904.06868 (2019).Google Scholar"",""Thi Hao Nguyen. 2018. A Study on Correlates of Acoustic Features to Emotional Singing Voice Synthesis. (2018).Google Scholar"",""Masanari Nishimura, Kei Hashimoto, Keiichiro Oura, Yoshihiko Nankaku, and Keiichi Tokuda. 2016. Singing Voice Synthesis Based on Deep Neural Networks.. In Interspeech. 2478--2482.Google Scholar"",""Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. 2016. Wavenet: A generative model for raw audio. arXiv preprint arXiv:1609.03499 (2016).Google Scholar"",""Wei Ping, Kainan Peng, and Jitong Chen. 2019. ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech. In ICLR .Google Scholar"",""Tao Qin, Tie-Yan Liu, Jun Xu, and Hang Li. 2010. LETOR: A benchmark collection for research on learning to rank for information retrieval. Information Retrieval, Vol. 13, 4 (2010), 346--374.Google ScholarDigital Library"",""Yi Ren, Chenxu Hu, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, and Tie-Yan Liu. 2020. FastSpeech 2: Fast and High-Quality End-to-End Text-to-Speech. arXiv preprint arXiv:2006.04558 (2020).Google Scholar"",""Yi Ren, Yangjun Ruan, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, and Tie-Yan Liu. 2019. Fastspeech: Fast, robust and controllable text to speech. In Advances in Neural Information Processing Systems. 3171--3180.Google Scholar"",""Bidisha Sharma, Chitralekha Gupta, Haizhou Li, and Ye Wang. 2019. Automatic Lyrics-to-audio Alignment on Polyphonic Music Using Singing-adapted Acoustic Models. In ICASSP 2019. IEEE, 396--400.Google Scholar"",""Jonathan Shen, Ruoming Pang, Ron J Weiss, Mike Schuster, Navdeep Jaitly, Zongheng Yang, Zhifeng Chen, Yu Zhang, Yuxuan Wang, Rj Skerrv-Ryan, et al. 2018. Natural tts synthesis by conditioning wavenet on mel spectrogram predictions. In ICASSP 2018. IEEE, 4779--4783.Google ScholarCross Ref"",""Hideyuki Tachibana, Katsuya Uenoyama, and Shunsuke Aihara. 2018. Efficiently trainable text-to-speech system based on deep convolutional networks with guided attention. In ICASSP 2018. IEEE, 4784--4788.Google ScholarCross Ref"",""Marti Umbert, Jordi Bonada, Masataka Goto, Tomoyasu Nakano, and Johan Sundberg. 2015. Expression control in singing voice synthesis: Features, approaches, evaluation, and challenges. IEEE Signal Processing Magazine, Vol. 32, 6 (2015), 55--73.Google ScholarCross Ref"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems. 5998--6008.Google Scholar"",""Zhizheng Wu, Oliver Watts, and Simon King. 2016. Merlin: An Open Source Neural Network Speech Synthesis System.. In SSW. 202--207.Google Scholar"",""Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, and Quoc V Le. 2019. Xlnet: Generalized autoregressive pretraining for language understanding. In Advances in neural information processing systems. 5754--5764.Google Scholar"",""Yuan-Hao Yi, Yang Ai, Zhen-Hua Ling, and Li-Rong Dai. 2019. Singing Voice Synthesis Using Deep Autoregressive Neural Networks for Acoustic Modeling. (2019).Google Scholar"",""Heiga Zen, Viet Dang, Rob Clark, Yu Zhang, Ron J Weiss, Ye Jia, Zhifeng Chen, and Yonghui Wu. 2019. LibriTTS: A corpus derived from librispeech for text-to-speech. arXiv preprint arXiv:1904.02882 (2019).Google Scholar"",""Liqiang Zhang, Chengzhu Yu, Heng Lu, Chao Weng, Yusong Wu, Xiang Xie, Zijin Li, and Dong Yu. 2019. Learning Singing From Speech. arXiv preprint arXiv:1912.10128 (2019).Google Scholar""]"
https://doi.org/10.1145/3394486.3403250,Scaling Choice Models of Relational Social Data,"Many prediction problems on social networks, from recommendations to anomaly detection, can be approached by modeling network data as a sequence of relational events and then leveraging the resulting model for prediction. Conditional logit models of discrete choice are a natural approach to modeling relational events as ""choices'' in a framework that envelops and extends many long-studied models of network formation. The conditional logit model is simplistic, but it is particularly attractive because it allows for efficient consistent likelihood maximization via negative sampling, something that isn't true for mixed logit and many other richer models. The value of negative sampling is particularly pronounced because choice sets in relational data are often enormous. Given the importance of negative sampling, in this work we introduce a model simplification technique for mixed logit models that we call ""de-mixing'', whereby standard mixture models of network formation---particularly models that mix local and global link formation---are reformulated to operate their modes over disjoint choice sets. This reformulation reduces mixed logit models to conditional logit models, opening the door to negative sampling while also circumventing other standard challenges with maximizing mixture model likelihoods. To further improve scalability, we also study importance sampling for more efficiently selecting negative samples, finding that it can greatly speed up inference in both standard and de-mixed models. Together, these steps make it possible to much more realistically model network formation in very large graphs. We illustrate the relative gains of our improvements on synthetic datasets with known ground truth as well as a large-scale dataset of public transactions on the Venmo platform.","[{""name"":""Jan Overgoor"",""id"":""/profile/81479660431""},{""name"":""George Pakapol Supaniratisai"",""id"":""/profile/99659574306""},{""name"":""Johan Ugander"",""id"":""/profile/81548562356""},{""name"":""Jan Overgoor"",""id"":""/profile/81479660431""},{""name"":""George Pakapol Supaniratisai"",""id"":""/profile/99659574306""},{""name"":""Johan Ugander"",""id"":""/profile/81548562356""}]","[""Rakesh Agrawal, Tomasz Imieli'nski, and Arun Swami. 1993. Mining association rules between sets of items in large databases. In ICMD . ACM, 207--216.Google Scholar"",""Alan Agresti. 2003. Categorical data analysis . Vol. 482. John Wiley \u0026 Sons.Google Scholar"",""Leman Akoglu, Hanghang Tong, and Danai Koutra. 2015. Graph based anomaly detection and description: a survey. Data mining and knowledge discovery, Vol. 29, 3.Google Scholar"",""Réka Albert and Albert-László Barabási. 1999. Emergence of scaling in random networks. Science, Vol. 286, 5439, 509--512.Google Scholar"",""Lars Backstrom and Jure Leskovec. 2011. Supervised random walks: predicting and recommending links in social networks. In WSDM. ACM, 635--644.Google Scholar"",""Moshe E Ben-Akiva, Steven R Lerman, and Steven R Lerman. 1985. Discrete choice analysis: theory and application to travel demand. Vol. 9. MIT press.Google Scholar"",""Austin R Benson, Rediet Abebe, Michael T Schaub, Ali Jadbabaie, and Jon Kleinberg. 2018a. Simplicial closure and higher-order link prediction. PNAS, Vol. 115, 48.Google ScholarCross Ref"",""Austin R Benson, Ravi Kumar, and Andrew Tomkins. 2018b. A Discrete Choice Model for Subset Selection. In WSDM. ACM, 37--45.Google Scholar"",""Elizabeth E Bruch and Robert D Mare. 2012. Methodological issues in the analysis of residential preferences, residential mobility, and neighborhood change. Sociological methodology , Vol. 42, 1, 103--154.Google Scholar"",""Carter T Butts. 2008. A Relational Event Framework for Social Action . Sociological Methodology , Vol. 38, 1, 155--200.Google ScholarCross Ref"",""Shuo Chen and Thorsten Joachims. 2016. Predicting matchups and preferences in context. In KDD. ACM, 775--784.Google Scholar"",""Sergio Currarini, Matthew O Jackson, and Paolo Pin. 2010. Identifying the roles of race-based choice and chance in high school friendship network formation. PNAS , Vol. 107, 11, 4857--4861.Google ScholarCross Ref"",""Amir Ghasemian, Homa Hosseinmardi, Aram Galstyan, Edoardo M Airoldi, and Aaron Clauset. 2019. Stacking Models for Nearly Optimal Link Prediction in Complex Networks. arXiv preprint arXiv:1909.07578 .Google Scholar"",""C Angelo Guevara and Moshe E Ben-Akiva. 2013. Sampling of alternatives in Logit Mixture models . Transportation Research Part B , Vol. 58, C, 185--198.Google ScholarCross Ref"",""Petter Holme and Jari Saram\""aki. 2012. Temporal networks. Physics Reports , Vol. 519.Google ScholarCross Ref"",""Matthew O Jackson and Brian W Rogers. 2007. Meeting Strangers and Friends of Friends: How Random Are Social Networks? AER , Vol. 97, 3, 890--915.Google Scholar"",""Benjamin F Jarvis. 2018. Estimating Multinomial Logit Models with Samples of Alternatives. Sociological Methodology , Vol. 49, 1, 341--348.Google ScholarCross Ref"",""Emily M Jin, Michelle Girvan, and Mark EJ Newman. 2001. Structure of growing social networks. Physical Review E , Vol. 64, 4, 046132.Google ScholarCross Ref"",""Jon M Kleinberg, Ravi Kumar, Prabhakar Raghavan, Sridhar Rajagopalan, and Andrew S Tomkins. 1999. The web as a graph: measurements, models, and methods. In ICCC. Springer, 1--17.Google Scholar"",""Gueorgi Kossinets and Duncan J Watts. 2006. Empirical analysis of an evolving social network. Science , Vol. 311, 5757, 88--90.Google Scholar"",""Ravi Kumar, Prabhakar Raghavan, Sridhar Rajagopalan, D Sivakumar, Andrew Tomkins, and Eli Upfal. 2000. Stochastic models for the web graph. In Proceedings of the 42st Annual Symposium on Foundations of Computer Science. IEEE, 57--65.Google ScholarCross Ref"",""B Langholz and Ørnulf Borgan. 1995. Counter-matching: a stratified nested case-control sampling method . Biometrika , Vol. 82, 1, 69--79.Google ScholarCross Ref"",""Jürgen Lerner and Alessandro Lomi. 2020. Reliability of relational event model estimates under sampling: how to fit a relational event model to 360 million dyadic events . Network Science , Vol. 8, 1, 97--135.Google ScholarCross Ref"",""Jure Leskovec, Lars Backstrom, Ravi Kumar, and Andrew Tomkins. 2008. Microscopic evolution of social networks. In KDD. ACM, 462--470.Google Scholar"",""Jure Leskovec and Eric Horvitz. 2008. Planetary-scale views on a large instant-messaging network. In WWW. ACM, 915--924.Google Scholar"",""David Liben-Nowell and Jon Kleinberg. 2007. The link-prediction problem for social networks. Journal of the American society for information science and technology , Vol. 58, 7, 1019--1031.Google ScholarDigital Library"",""R Duncan Luce. 1959. Individual Choice Behavior; a Theoretical Analysis .New York, Wiley.Google Scholar"",""C F Manski and Daniel McFadden. 1981. Alternative estimators and sample designs for discrete choice analysis . In Structural Analysis of Discrete Data and Econometric Applications. 2--50.Google Scholar"",""Daniel McFadden. 1977. Modelling the Choice of Residential Location . Cowles Foundation Discussion Papers 477. Yale University.Google Scholar"",""Miller McPherson, Lynn Smith-Lovin, and James M Cook. 2001. Birds of a feather: Homophily in social networks . Annual Review of Sociology , Vol. 32, 1, 19--28.Google Scholar"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In NeurIPS . Curran Associates, 3111--3119.Google Scholar"",""S Nerella and C Bhat. 2004. Numerical analysis of effect of sampling of alternatives in discrete choice models . J of Transportation Research , Vol. 1894, 1, 11--19.Google Scholar"",""Yurii Nesterov. 2013. Introductory lectures on convex optimization: A basic course. Vol. 87. Springer Science \u0026 Business Media.Google Scholar"",""Caleb C Noble and Diane J Cook. 2003. Graph-based anomaly detection. In KDD. ACM, 631--636.Google Scholar"",""Jan Overgoor, Austin Benson, and Johan Ugander. 2019. Choosing to grow a graph: Modeling network formation as discrete choice. In WWW . ACM, 1409--1420.Google Scholar"",""Art B. Owen. 2013. Monte Carlo theory, methods and examples .Google Scholar"",""Anatol Rapoport. 1953. Spread of information through a population with socio-structural bias: I. Assumption of transitivity. The bulletin of mathematical biophysics , Vol. 15, 4, 523--533.Google Scholar"",""Garry Robins, Pip Pattison, Yuval Kalish, and Dean Lusher. 2007. An introduction to exponential random graph (p*) models for social networks. Social networks , Vol. 29, 2, 173--191.Google Scholar"",""Arjun Seshadri, Alex Peysakhovich, and Johan Ugander. 2019. Discovering Context Effects from Raw Choice Data. In ICML. PMLR, 5660--5669.Google Scholar"",""Tom AB Snijders, Gerhard G Van de Bunt, and Christian EG Steglich. 2010. Introduction to stochastic actor-based models for network dynamics. Social networks , Vol. 32, 1, 44--60.Google Scholar"",""Christoph Stadtfeld and Per Block. 2017. Interactions, Actors, and Time: Dynamic Network Actor Models for Relational Events . Sociological Science , Vol. 4, 318--352.Google ScholarCross Ref"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. In WWW. ACM, 1067--1077.Google ScholarDigital Library"",""Louis L Thurstone. 1927. A law of comparative judgment. Psychological review , Vol. 34, 4, 273--286.Google Scholar"",""Kenneth E Train. 2009. Discrete choice methods with simulation .CUP.Google Scholar"",""John W Tukey. 1960. A survey of sampling from contaminated distributions. Contributions to probability and statistics, 448--485.Google Scholar"",""Johan Ugander and Lars Backstrom. 2013. Balanced label propagation for partitioning massive graphs. In WSDM. ACM, 507--516.Google Scholar"",""Roger H von Haefen and Adam Domanski. 2018. Estimation and welfare analysis from mixed logit models with large choice sets . Journal of Environmental Economics and Management , Vol. 90, 101--118.Google ScholarCross Ref"",""Duy Vu, Philippa Pattison, and Garry Robins. 2015. Relational event models for social learning in MOOCs . Social Networks , Vol. 43, 121--135.Google ScholarCross Ref"",""Duncan J Watts. 2003. Small worlds: the dynamics of networks between order and randomness .Princeton university press.Google Scholar"",""Xinyi Zhang, Shiliang Tang, Yun Zhao, Gang Wang, Haitao Zheng, and Ben Y Zhao. 2017. Cold hard E-cash: Friends and vendors in the Venmo digital payments system. In ICWSM . ACM, 387--396.Google Scholar""]"
https://doi.org/10.1145/3394486.3403251,Deep Exogenous and Endogenous Influence Combination for Social Chatter Intensity Prediction,"Modeling user engagement dynamics on social media has compelling applications in market trend analysis, user-persona detection, and political discourse mining. Most existing approaches depend heavily on knowledge of the underlying user network. However, a large number of discussions happen on platforms that either lack any reliable social network (news portal, blogs, Buzzfeed) or reveal only partially the inter-user ties (Reddit, Stackoverflow). Many approaches require observing a discussion for some considerable period before they can make useful predictions. In real-time streaming scenarios, observations incur costs. Lastly, most models do not capture complex interactions between exogenous events (such as news articles published externally) and in-network effects (such as follow-up discussions on Reddit) to determine engagement levels. To address the three limitations noted above, we propose a novel framework, ChatterNet, which, to our knowledge, is the first that can model and predict user engagement without considering the underlying user network. Given streams of timestamped news articles and discussions, the task is to observe the streams for a short period leading up to a time horizon, then predict chatter: the volume of discussions through a specified period after the horizon. ChatterNet processes text from news and discussions using a novel time-evolving recurrent network architecture that captures both temporal properties within news and discussions, as well as influence of news on discussions. We report on extensive experiments using a two-month-long discussion corpus of Reddit, and a contemporaneous corpus of online news articles from the Common Crawl. ChatterNet shows considerable improvements beyond recent state-of-the-art models of engagement prediction. Detailed studies controlling observation and prediction windows, over 43 different subreddits, yield further useful insights.","[{""name"":""Subhabrata Dutta"",""id"":""/profile/99659477864""},{""name"":""Sarah Masud"",""id"":""/profile/99659574176""},{""name"":""Soumen Chakrabarti"",""id"":""/profile/81100424876""},{""name"":""Tanmoy Chakraborty"",""id"":""/profile/86158668557""},{""name"":""Subhabrata Dutta"",""id"":""/profile/99659477864""},{""name"":""Sarah Masud"",""id"":""/profile/99659574176""},{""name"":""Soumen Chakrabarti"",""id"":""/profile/81100424876""},{""name"":""Tanmoy Chakraborty"",""id"":""/profile/86158668557""}]","[""Sitaram Asur and Bernardo A Huberman. 2010. Predicting the future with social media. In ICWSM. 492--499.Google Scholar"",""Reema Aswani, SP Ghrera, Arpan Kumar Kar, and Satish Chandra. 2017. Identifying buzz in social media: a hybrid approach using artificial bee colony and k-nearest neighbors for outlier detection. SNAM, Vol. 7, 1 (2017), 38.Google Scholar"",""Erik Cambria, Soujanya Poria, Devamanyu Hazarika, and Kenneth Kwok. 2018. SenticNet 5: Discovering conceptual primitives for sentiment analysis by means of context embeddings. In AAAI. 1795--1802.Google Scholar"",""Justin Cheng, Lada Adamic, P Alex Dow, Jon Michael Kleinberg, and Jure Leskovec. 2014. Can cascades be predicted?. In WWW Conference. ACM, 925--936.Google ScholarDigital Library"",""Abir De, Sourangshu Bhattacharya, and Niloy Ganguly. 2018. Demarcating endogenous and exogenous opinion diffusion process on social networks. In WWW Conference. 549--558.Google ScholarDigital Library"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In NAACL-HLT. 4171--4186.Google Scholar"",""Subhabrata Dutta, Dipankar Das, and Tanmoy Chakraborty. 2019. Modeling Engagement Dynamics of Online Discussions using Relativistic Gravitational Theory. In ICDM. IEEE, 180--189.Google Scholar"",""Mats Ekström and Adam Shehata. 2018. Social media, porous boundaries, and the development of online political engagement among young citizens. New Media \u0026 Society, Vol. 20, 2 (2018), 740--759.Google ScholarCross Ref"",""Marco Guerini, Carlo Strapparava, and Gozde Ozbal. 2011. Exploring text virality in social networks. In ICWSM. 1--10.Google Scholar"",""Felix Hamborg, Norman Meuschke, Corinna Breitinger, and Bela Gipp. 2017. news-please: A Generic News Crawler and Extractor. In ICIS, Maria Gaede, Violeta Trkulja, and Vivien Petra (Eds.). 218--223.Google Scholar"",""Lala Hu. 2018. Luxury brand communication on social media: A qualitative study of the Chinese market. In 2018 Global Marketing Conference at Tokyo. 160--161.Google ScholarCross Ref"",""Henry Jenkins, Sangita Shresthova, Liana Gamber-Thompson, Neta Kligler-Vilenchik, and Arely Zimmerman. 2018. By any media necessary: The new youth activism. Vol. 3. NYU Press.Google Scholar"",""Nal Kalchbrenner, Edward Grefenstette, and Phil Blunsom. 2014. A convolutional neural network for modelling sentences. arXiv preprint arXiv:1404.2188 (2014).Google Scholar"",""M Laeeq Khan. 2017. Social media engagement: What motivates user participation and consumption on YouTube? Computers in Human Behavior, Vol. 66 (2017), 236--247.Google ScholarDigital Library"",""Yoon Kim. 2014. Convolutional neural networks for sentence classification. arXiv preprint arXiv:1408.5882 (2014).Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Ryota Kobayashi and Renaud Lambiotte. 2016. TiDeH: Time-dependent Hawkes process for predicting retweet dynamics. In Tenth International AAAI Conference on Web and Social Media .Google Scholar"",""Andrey Kupavskii, Liudmila Ostroumova, Alexey Umnov, Svyatoslav Usachev, Pavel Serdyukov, Gleb Gusev, and Andrey Kustarev. 2012. Prediction of retweet cascade size over time. In CIKM. 2335--2338.Google Scholar"",""Lian Fen Lee, Amy P Hutton, and Susan Shu. 2015. The role of social media in the capital market: Evidence from consumer product recalls. Journal of Accounting Research, Vol. 53, 2 (2015), 367--404.Google ScholarCross Ref"",""Cheng Li, Jiaqi Ma, Xiaoxiao Guo, and Qiaozhu Mei. 2017. DeepCas: An End-to-end Predictor of Information Cascades. In Proceedings of the 26th International Conference on World Wide Web, WWW 2017, Perth, Australia, April 3--7, 2017, Rick Barrett, Rick Cummings, Eugene Agichtein, and Evgeniy Gabrilovich (Eds.). ACM, 577--586. https://doi.org/10.1145/3038912.3052643Google ScholarDigital Library"",""Ryosuke Nishi, Taro Takaguchi, Keigo Oka, Takanori Maehara, Masashi Toyoda, Ken-ichi Kawarabayashi, and Naoki Masuda. 2016. Reply trees in twitter: data analysis and branching process models. SNAM, Vol. 6, 1 (2016), 1--13.Google Scholar"",""Sinya Peng, Vincent S Tseng, Che-Wei Liang, and Man-Kwan Shan. 2018. Emerging Product Topics Prediction in Social Media without Social Structure Information. In WWW Conference (Companion). 1661--1668.Google ScholarDigital Library"",""Benjamin Shulman, Amit Sharma, and Dan Cosley. 2016. Predictability of popularity: Gaps between prediction and understanding. In Web and Social Media. AAAI, 348--357.Google Scholar"",""Ke Wang, Mohit Bansal, and Jan-Michael Frahm. 2018. Retweet wars: Tweet popularity prediction via dynamic multimodal regression. In WACV. 1842--1851.Google Scholar"",""Lilian Weng, Alessandro Flammini, Alessandro Vespignani, and Fillipo Menczer. 2012. Competition among memes in a world with limited attention. Sci. Rep., Vol. 2 (2012), 335.Google ScholarCross Ref"",""Sheng Yu and Subhash Kak. 2012. A Survey of Prediction Using Social Media. arxiv: 1203.1647Google Scholar"",""Qingyuan Zhao, Murat A Erdogdu, Hera Y He, Anand Rajaraman, and Jure Leskovec. 2015. SEISMIC: A self-exciting point process model for predicting tweet popularity. In KDD Conference. 1513--1522.Google ScholarDigital Library"",""Zhou Zhao, Lingtao Meng, Jun Xiao, Min Yang, Fei Wu, Deng Cai, Xiaofei He, and Yueting Zhuang. 2018. Attentional Image Retweet Modeling via Multi-Faceted Ranking Network Learning.. In IJCAI. 3184--3190.Google Scholar""]"
https://doi.org/10.1145/3394486.3403252,Geography-Aware Sequential Location Recommendation,"Sequential location recommendation plays an important role in many applications such as mobility prediction, route planning and location-based advertisements. In spite of evolving from tensor factorization to RNN-based neural networks, existing methods did not make effective use of geographical information and suffered from the sparsity issue. To this end, we propose a Geography-aware sequential recommender based on the Self-Attention Network (GeoSAN for short) for location recommendation. On the one hand, we propose a new loss function based on importance sampling for optimization, to address the sparsity issue by emphasizing the use of informative negative samples. On the other hand, to make better use of geographical information, GeoSAN represents the hierarchical gridding of each GPS point with a self-attention based geography encoder. Moreover, we put forward geography-aware negative samplers to promote the informativeness of negative samples. We evaluate the proposed algorithm with three real-world LBSN datasets, and show that GeoSAN outperforms the state-of-the-art sequential location recommenders by 34.9%. The experimental results further verify significant effectiveness of the new loss function, geography encoder, and geography-aware negative samplers.","[{""name"":""Defu Lian"",""id"":""/profile/81490653988""},{""name"":""Yongji Wu"",""id"":""/profile/99659573361""},{""name"":""Yong Ge"",""id"":""/profile/81496674732""},{""name"":""Xing Xie"",""id"":""/profile/81385598345""},{""name"":""Enhong Chen"",""id"":""/profile/81323488612""},{""name"":""Defu Lian"",""id"":""/profile/81490653988""},{""name"":""Yongji Wu"",""id"":""/profile/99659573361""},{""name"":""Yong Ge"",""id"":""/profile/81496674732""},{""name"":""Xing Xie"",""id"":""/profile/81385598345""},{""name"":""Enhong Chen"",""id"":""/profile/81323488612""}]","[""Christopher M. Bishop. 2006. Pattern Recognition and Machine Learning (Information Science and Statistics). Springer-Verlag New York, Inc.Google Scholar"",""Chen Cheng, Haiqin Yang, Irwin King, and Michael R Lyu. 2012. Fused matrix factorization with geographical and social influence in location-based social networks. In Proceedings of AAAI'12. 17--23.Google Scholar"",""Chen Cheng, Haiqin Yang, Michael R Lyu, and Irwin King. 2013. Where you like to go next: successive point-of-interest recommendation. In Proceedings of IJCAI'13. AAAI Press, 2605--2611.Google ScholarDigital Library"",""E. Cho, S.A. Myers, and J. Leskovec. 2011. Friendship and mobility: user movement in location-based social networks. In Proceedings of KDD'11. 1082--1090.Google Scholar"",""Qiang Cui, Yuyuan Tang, Shu Wu, and Liang Wang. 2019. Distance2Pre: Personalized Spatial Preference for Next Point-of-Interest Prediction. In Proceedings of PAKDD'19. Springer, 289--301.Google ScholarCross Ref"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).Google Scholar"",""Shanshan Feng, Gao Cong, Bo An, and Yeow Meng Chee. 2017. Poi2vec: Geographical latent representation for predicting future visitors. In Proceedings of AAAI'17.Google Scholar"",""Shanshan Feng, Xutao Li, Yifeng Zeng, Gao Cong, Yeow Meng Chee, and Quan Yuan. 2015. Personalized ranking metric embedding for next new POI recommendation. In Proceedings of IJCAI'15. AAAI Press, 2069--2075.Google Scholar"",""M.C. Gonzalez, C.A. Hidalgo, and A.L. Barabasi. 2008. Understanding individual human mobility patterns. Nature, Vol. 453, 7196 (2008), 779--782.Google Scholar"",""Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2015. Session-based recommendations with recurrent neural networks. In International Conference on Learning Representations (ICLR).Google Scholar"",""Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recommendation. In Proceedings of ICDM'18. IEEE, 197--206.Google ScholarCross Ref"",""Jiacheng Li, Yujie Wang, and Julian McAuley. 2020. Time Interval Aware Self-Attention for Sequential Recommendation. In Proceedings of WSDM'20. 322--330.Google ScholarDigital Library"",""Ranzhen Li, Yanyan Shen, and Yanmin Zhu. 2018. Next point-of-interest recommendation with temporal and multi-level context attention. In Proceedings of ICDM'18. IEEE, 1110--1115.Google ScholarCross Ref"",""Defu Lian, Yong Ge, Fuzheng Zhang, Nicholas Jing Yuan, Xing Xie, Tao Zhou, and Yong Rui. 2018a. Scalable Content-Aware Collaborative Filtering for Location Recommendation. IEEE Transactions on Knowledge and Data Engineering (2018). https://doi.org/10.1109/TKDE.2018.2789445Google Scholar"",""Defu Lian, Qi Liu, and Enhong Chen. 2020. Personalized Ranking with Importance Sampling. In Proceedings of The Web Conference 2020. 1093--1103.Google ScholarDigital Library"",""Defu Lian, Cong Zhao, Xing Xie, Guangzhong Sun, Enhong Chen, and Yong Rui. 2014a. GeoMF: joint geographical modeling and matrix factorization for point-of-interest recommendation. In Proceedings of KDD'14. ACM, 831--840.Google ScholarDigital Library"",""Defu Lian, Kai Zheng, Yong Ge, Longbing Cao, Enhong Chen, and Xing Xie. 2018b. GeoMF+ Scalable Location Recommendation via Joint Geographical Modeling and Matrix Factorization. ACM Transactions on Information Systems (TOIS), Vol. 36, 3 (2018), 1--29.Google ScholarDigital Library"",""Defu Lian, Vincent Wenchen Zheng, and Xing Xie. 2013. Collaborative Filtering Meets Next Check-in Location Prediction. In Proceedings of WWW'13 Companion. ACM, 231--232.Google ScholarDigital Library"",""Defu Lian, Yin Zhu, Xing Xie, and Enhong Chen. 2014b. Analyzing Location Predictability on Location-Based Social Networks. In Proceedings of PAKDD'14.Google ScholarCross Ref"",""Jianxun Lian, Xiaohuan Zhou, Fuzheng Zhang, Zhongxia Chen, Xing Xie, and Guangzhong Sun. 2018c. xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems. In Proceedings of KDD'18. ACM, 1754--1763.Google ScholarDigital Library"",""Bin Liu, Yanjie Fu, Zijun Yao, and Hui Xiong. 2013. Learning geographical preferences for point-of-interest recommendation. In Proceedings of KDD'13. ACM, 1043--1051.Google ScholarDigital Library"",""Qiang Liu, Shu Wu, Liang Wang, and Tieniu Tan. 2016. Predicting the next location: a recurrent model with spatial and temporal contexts. In Proceedings of AAAI'16. AAAI Press, 194--200.Google Scholar"",""Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781 (2013).Google Scholar"",""Massimo Quadrana, Paolo Cremonesi, and Dietmar Jannach. 2018. Sequence-aware recommender systems. ACM Computing Surveys (CSUR), Vol. 51, 4 (2018), 1--36.Google ScholarDigital Library"",""S. Rendle, C. Freudenthaler, Z. Gantner, and L. Schmidt-Thieme. 2009. BPR: Bayesian personalized ranking from implicit feedback. In Proceedings of UAI'09. AUAI Press, 452--461.Google ScholarDigital Library"",""S. Rendle, C. Freudenthaler, and L. Schmidt-Thieme. 2010. Factorizing personalized markov chains for next-basket recommendation. In Proceedings of WWW'10. ACM, 811--820.Google Scholar"",""C. Song, T. Koren, P. Wang, and A.L. Barabási. 2010a. Modelling the scaling properties of human mobility. Nature Physics, Vol. 6, 10 (2010), 818--823.Google ScholarCross Ref"",""C. Song, Z. Qu, N. Blumm, and A.L. Barabási. 2010b. Limits of predictability in human mobility. Science, Vol. 327, 5968 (2010), 1018--1021.Google Scholar"",""Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer. In Proceedings of CIKM'19. 1441--1450.Google ScholarDigital Library"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998--6008.Google Scholar"",""Shoujin Wang, Longbing Cao, and Yan Wang. 2019. A survey on session-based recommender systems. arXiv preprint arXiv:1902.04864 (2019).Google Scholar"",""Markus Weimer, Alexandros Karatzoglou, Quoc Viet Le, and Alex Smola. 2007. Maximum margin matrix factorization for collaborative ranking. Proceedings of NIPS'07 (2007), 1--8.Google ScholarDigital Library"",""Yongji Wu, Defu Lian, Shuowei Jin, and Enhong Chen. 2019. Graph convolutional networks on user mobility heterogeneous graphs for social relationship inference. In Proceedings of IJCAI'19. AAAI Press, 3898--3904.Google ScholarCross Ref"",""Cheng Yang, Maosong Sun, Wayne Xin Zhao, Zhiyuan Liu, and Edward Y Chang. 2017. A neural network approach to jointly modeling social networks and mobile trajectories. ACM Transactions on Information Systems (TOIS), Vol. 35, 4 (2017), 36.Google ScholarDigital Library"",""Dingqi Yang, Bingqing Qu, Jie Yang, and Philippe Cudre-Mauroux. 2019. Revisiting user mobility and social relationships in lbsns: A hypergraph embedding approach. In The World Wide Web Conference. 2147--2157.Google ScholarDigital Library"",""Mao Ye, Peifeng Yin, Wang-Chien Lee, and Dik-Lun Lee. 2011. Exploiting geographical influence for collaborative point-of-interest recommendation. In Proceedings of SIGIR'11. ACM, 325--334.Google ScholarDigital Library"",""Jia-Dong Zhang and Chi-Yin Chow. 2013. iGSLR: Personalized Geo-Social Location Recommendation-A Kernel Density Estimation Approach. In Proceedings of GIS'13.Google ScholarDigital Library"",""Jia-Dong Zhang, Chi-Yin Chow, and Yanhua Li. 2014. iGeoRec: A personalized and efficient geographical location recommendation framework. IEEE Transactions on Services Computing, Vol. 8, 5 (2014), 701--714.Google ScholarCross Ref"",""Shuai Zhang, Yi Tay, Lina Yao, and Aixin Sun. 2018. Next item recommendation with self-attention. arXiv preprint arXiv:1808.06414 (2018).Google Scholar"",""Pengpeng Zhao, Haifeng Zhu, Yanchi Liu, Jiajie Xu, Zhixu Li, Fuzhen Zhuang, Victor S Sheng, and Xiaofang Zhou. 2019. Where to go next: a spatio-temporal gated network for next poi recommendation. In Proceedings of AAAI'19, Vol. 33. 5877--5884.Google ScholarCross Ref"",""Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through rate prediction. In Proceedings of KDD'18. ACM, 1059--1068.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403253,Dual Channel Hypergraph Collaborative Filtering,"Collaborative filtering (CF) is one of the most popular and important recommendation methodologies in the heart of numerous recommender systems today. Although widely adopted, existing CF-based methods, ranging from matrix factorization to the emerging graph-based methods, suffer inferior performance especially when the data for training are very limited. In this paper, we first pinpoint the root causes of such deficiency and observe two main disadvantages that stem from the inherent designs of existing CF-based methods, i.e., 1) inflexible modeling of users and items and 2) insufficient modeling of high-order correlations among the subjects. Under such circumstances, we propose a dual channel hypergraph collaborative filtering (DHCF) framework to tackle the above issues. First, a dual channel learning strategy, which holistically leverages the divide-and-conquer strategy, is introduced to learn the representation of users and items so that these two types of data can be elegantly interconnected while still maintaining their specific properties. Second, the hypergraph structure is employed for modeling users and items with explicit hybrid high-order correlations. The jump hypergraph convolution (JHConv) method is proposed to support the explicit and efficient embedding propagation of high-order correlations. Comprehensive experiments on two public benchmarks and two new real-world datasets demonstrate that DHCF can achieve significant and consistent improvements against other state-of-the-art methods.","[{""name"":""Shuyi Ji"",""id"":""/profile/99659574088""},{""name"":""Yifan Feng"",""id"":""/profile/99659317353""},{""name"":""Rongrong Ji"",""id"":""/profile/81321493059""},{""name"":""Xibin Zhao"",""id"":""/profile/81472645216""},{""name"":""Wanwan Tang"",""id"":""/profile/99659574414""},{""name"":""Yue Gao"",""id"":""/profile/81361595457""},{""name"":""Shuyi Ji"",""id"":""/profile/99659574088""},{""name"":""Yifan Feng"",""id"":""/profile/99659317353""},{""name"":""Rongrong Ji"",""id"":""/profile/81321493059""},{""name"":""Xibin Zhao"",""id"":""/profile/81472645216""},{""name"":""Wanwan Tang"",""id"":""/profile/99659574414""},{""name"":""Yue Gao"",""id"":""/profile/81361595457""}]","[""Austin R Benson, David F Gleich, and Jure Leskovec. 2016. Higher-order organization of complex networks. Science, Vol. 353, 6295 (2016), 163--166.Google Scholar"",""Rianne van den Berg, Thomas N Kipf, and Max Welling. 2018. Graph Convolutional Matrix Completion. In Proc. of the 24th ACM International Conference on Knowledge Discovery and Data mining (SIGKDD).Google Scholar"",""Yifan Feng, Haoxuan You, Zizhao Zhang, et al. 2019. Hypergraph neural networks. In Proc. of the 33rd Conference on Artificial Intelligence (AAAI). 3558--3565.Google ScholarCross Ref"",""Xavier Glorot and Yoshua Bengio. 2010. Understanding the Difficulty of Training Deep Feedforward Neural Networks. In Proc. of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS). 249--256.Google Scholar"",""Marco Gori, Augusto Pucci, V Roma, et al. 2007. Itemrank: A Random-walk Based Scoring Algorithm for Recommender Engines. In Proc. of the 20th International Joint Conference on Artifical Intelligence (IJCAI). 2766--2771.Google Scholar"",""Mihajlo Grbovic and Haibin Cheng. 2018. Real-time Personalization using Embeddings for Search Ranking at Airbnb. In Proc. of the 24th ACM International Conference on Knowledge Discovery and Data mining (SIGKDD). 311--320.Google ScholarDigital Library"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive Representation Learning on Large Graphs. In Proc. of the 31st Advances in Neural Information Processing Systems (NeurIPS). 1024--1034.Google Scholar"",""F Maxwell Harper and Joseph A Konstan. 2015. The Movielens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems, Vol. 5, 4 (2015), 1--19.Google ScholarDigital Library"",""Xiangnan He, Ming Gao, Min-Yen Kan, et al. 2016. Birank: Towards Ranking on Bipartite Graphs. IEEE Transactions on Knowledge and Data Engineering, Vol. 29, 1 (2016), 57--71.Google ScholarDigital Library"",""Xiangnan He, Lizi Liao, Hanwang Zhang, et al. 2017. Neural Collaborative Filtering. In Proc. of International Conference on World Wide Web. 173--182.Google ScholarDigital Library"",""Glen Jeh and Jennifer Widom. 2002. SimRank: a Measure of Structural-context Similarity. In Proc. of the 8th ACM International Conference on Knowledge Discovery and Data mining (SIGKDD). 538--543.Google ScholarDigital Library"",""Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In Proc. of International Conference on Learning Representations (ICLR).Google Scholar"",""Yehuda Koren. 2008. Factorization meets the neighborhood: a multifaceted collaborative filtering model. In Proc. of the 14th ACM International Conference on Knowledge Discovery and Data mining (SIGKDD). 426--434.Google ScholarDigital Library"",""Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix Factorization Techniques for Recommender Systems. Computer, Vol. 42, 8 (2009), 30--37.Google ScholarDigital Library"",""C-H Lee, Y-H Kim, and P-K Rhee. 2001. Web Personalization Expert with Combining Collaborative Filtering and Association Rule Mining Technique. Expert Systems with Applications, Vol. 21, 3 (2001), 131--137.Google ScholarCross Ref"",""H Brendan McMahan, Gary Holt, David Sculley, Michael Young, Dietmar Ebner, Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, et al. 2013. Ad click prediction: a view from the trenches. In Proceedings of the 19th ACM international conference on Knowledge discovery and data mining (SIGKDD). 1222--1230.Google ScholarDigital Library"",""Arkadiusz Paterek. 2007. Improving regularized singular value decomposition for collaborative filtering. In Proc. of the ACM SIGKDD cup and workshop, Vol. 2007. 5--8.Google Scholar"",""Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, et al. 2009. BPR: Bayesian Personalized Ranking from Implicit Feedback. In Proc. of the 25th Conference on Uncertainty in Artificial Intelligence (UAI).Google Scholar"",""Steffen Rendle, Zeno Gantner, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2011. Fast context-aware recommendations with factorization machines. In Proc. of the 34th International ACM Conference on Research and Development in Information Retrieval (SIGIR). 635--644.Google ScholarDigital Library"",""Badrul Sarwar, George Karypis, Joseph Konstan, et al. 2001. Item-based Collaborative Filtering Recommendation Algorithms. In Proc. of the 10th international conference on World Wide Web. 285--295.Google ScholarDigital Library"",""Nino Shervashidze, Pascal Schweitzer, Erik Jan van Leeuwen, et al. 2011. Weisfeiler-lehman Graph Kernels. Journal of Machine Learning Research, Vol. 12 (2011), 2539--2561.Google ScholarDigital Library"",""Xiaoyuan Su and Taghi M Khoshgoftaar. 2009. A Survey of Collaborative Filtering Techniques. Advances in Artificial Intelligence (2009).Google Scholar"",""Lyle H Ungar and Dean P Foster. 1998. Clustering Methods for Collaborative Filtering. In AAAI Workshop on Recommendation Systems. 114--129.Google Scholar"",""Hao Wang, Binyi Chen, and Wu-Jun Li. 2013. Collaborative Topic Regression with Social Regularization for Tag Recommendation. In Proc. of the 23rd International Joint Conference on Artificial Intelligence (IJCAI).Google Scholar"",""Xiang Wang, Xiangnan He, Meng Wang, et al. 2019. Neural Graph Collaborative Filtering. In Proc. of the 42nd International ACM Conference on Research and Development in Information Retrieval (SIGIR). 165--174.Google ScholarDigital Library"",""Jheng-Hong Yang, Chih-Ming Chen, Chuan-Ju Wang, et al. 2018. HOP-rec: High-order Proximity for Implicit Recommendation. In Proc. of the 12th ACM Conference on Recommender Systems (RecSys). 140--144.Google ScholarDigital Library"",""Xiwang Yang, Yang Guo, and Yong Liu. 2012. Bayesian-inference-based Recommendation in Online Social Networks. IEEE Transactions on Parallel and Distributed Systems, Vol. 24, 4 (2012), 642--651.Google ScholarDigital Library"",""Rex Ying, Ruining He, Kaifeng Chen, et al. 2018. Graph Convolutional Neural Networks for Web-scale Recommender Systems. In Proc. of the 24th ACM International Conference on Knowledge Discovery and Data mining (SIGKDD). 974--983.Google ScholarDigital Library"",""Zhi-Dan Zhao and Ming-Sheng Shang. 2010. User-based Collaborative-filtering Recommendation Algorithms on Hadoop. In Proc. of the third International Conference on Knowledge Discovery and Data mining (SIGKDD). IEEE, 478--481.Google Scholar""]"
https://doi.org/10.1145/3394486.3403254,A Framework for Recommending Accurate and Diverse Items Using Bayesian Graph Convolutional Neural Networks,"Personalized recommender systems are playing an increasingly important role for online consumption platforms. Because of the multitude of relationships existing in recommender systems, Graph Neural Networks (GNNs) based approaches have been proposed to better characterize the various relationships between a user and items while modeling a user's preferences. Previous graph-based recommendation approaches process the observed user-item interaction graph as a ground-truth depiction of the relationships between users and items. However, especially in the implicit recommendation setting, all the unobserved user-item interactions are usually assumed to be negative samples. There are missing links that represent a user's future actions. In addition, there may be spurious or misleading positive interactions. To alleviate the above issue, in this work, we take a first step to introduce a principled way to model the uncertainty in the user-item interaction graph using the Bayesian Graph Convolutional Neural Network framework. We discuss how inference can be performed under our framework and provide a concrete formulation using the Bayesian Probabilistic Ranking training loss. We demonstrate the effectiveness of our proposed framework on four benchmark recommendation datasets. The proposed method outperforms state-of-the-art graph-based recommendation models. Furthermore, we conducted an offline evaluation on one industrial large-scale dataset. It shows that our proposed method outperforms the baselines, with the potential gain being more significant for cold-start users. This illustrates the potential practical benefit in real-world recommender systems.","[{""name"":""Jianing Sun"",""id"":""/profile/99659566374""},{""name"":""Wei Guo"",""id"":""/profile/99659450898""},{""name"":""Dengcheng Zhang"",""id"":""/profile/99659574320""},{""name"":""Yingxue Zhang"",""id"":""/profile/99659567130""},{""name"":""Florence Regol"",""id"":""/profile/99659573260""},{""name"":""Yaochen Hu"",""id"":""/profile/99659573328""},{""name"":""Huifeng Guo"",""id"":""/profile/99659154282""},{""name"":""Ruiming Tang"",""id"":""/profile/81488661679""},{""name"":""Han Yuan"",""id"":""/profile/99659575034""},{""name"":""Xiuqiang He"",""id"":""/profile/81331494271""},{""name"":""Mark Coates"",""id"":""/profile/81100363584""},{""name"":""Jianing Sun"",""id"":""/profile/99659566374""},{""name"":""Wei Guo"",""id"":""/profile/99659450898""},{""name"":""Dengcheng Zhang"",""id"":""/profile/99659574320""},{""name"":""Yingxue Zhang"",""id"":""/profile/99659567130""},{""name"":""Florence Regol"",""id"":""/profile/99659573260""},{""name"":""Yaochen Hu"",""id"":""/profile/99659573328""},{""name"":""Huifeng Guo"",""id"":""/profile/99659154282""},{""name"":""Ruiming Tang"",""id"":""/profile/81488661679""},{""name"":""Han Yuan"",""id"":""/profile/99659575034""},{""name"":""Xiuqiang He"",""id"":""/profile/81331494271""},{""name"":""Mark Coates"",""id"":""/profile/81100363584""}]","[""Gediminas Adomavicius and YoungOk Kwon. 2012. Improving Aggregate Recommendation Diversity Using Ranking-Based Techniques. IEEE Transactions on Knowledge and Data Engineering (2012).Google Scholar"",""Massimo Caccia, Lucas Caccia, William Fedus, Hugo Larochelle, Joelle Pineau, and Laurent Charlin. 2020. Language GANs Falling Short. In Proc. Int. Conf. Learning Representations (ICLR) .Google Scholar"",""Yukuo Cen, Xu Zou, Jianwei Zhang, Hongxia Yang, Jingren Zhou, and Jie Tang. 2019. Representation Learning for Attributed Multiplex Heterogeneous Network. In Proc. ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining .Google ScholarDigital Library"",""Michelle Keim Condli, David D Lewis, David Madigan, and Christian Posse. 1999. Bayesian mixed-E ects models for recommender systems. In Int. ACM SIGIR Conf. on Research and Development in Information Retrieval .Google Scholar"",""Michaë l Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering. In Proc. Adv. Neural Information Processing Systems .Google Scholar"",""Shaohua Fan, Junxiong Zhu, Xiaotian Han, Chuan Shi, Linmei Hu, Biyu Ma, and Yongliang Li. 2019 c. Metapath-guided Heterogeneous Graph Neural Network for Intent Recommendation. In Proc. Int. Joint Conf. Artificial Intelligence .Google ScholarDigital Library"",""Wenqi Fan, Yao Ma, Qing Li, Yuan He, Eric Zhao, Jiliang Tang, and Dawei Yin. 2019 a. Graph Neural Networks for Social Recommendation. In Proc. Int. Conf. World Wide Web .Google ScholarDigital Library"",""Wenqi Fan, Yao Ma, Dawei Yin, Jianping Wang, Jiliang Tang, and Qing Li. 2019 b. Deep social collaborative filtering. In Proc. ACM Conf. Recommender Systems .Google ScholarDigital Library"",""Marco Gori and Augusto Pucci. 2007. ItemRank: A Random-Walk Based Scoring Algorithm for Recommender Engines. In Proc. Int. Joint Conf. Artificial Intell.Google Scholar"",""Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: A Factorization-Machine based Neural Network for CTR Prediction. In Proc. Int. Joint Conf. Artificial Intelligence .Google ScholarCross Ref"",""William L. Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive Representation Learning on Large Graphs. In Proc. Adv. Neural Inf. Proc. Systems .Google Scholar"",""Ruining He and Julian McAuley. 2016. Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering. In Proc. Int. Conf. World Wide Web .Google ScholarDigital Library"",""Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural Collaborative Filtering. In Proc. Int. Conf. World Wide Web .Google ScholarDigital Library"",""Antonio Hernando, Jesús Bobadilla, and Fernando Ortega. 2016. A non negative matrix factorization for collaborative filtering recommender systems based on a Bayesian probabilistic model. Knowledge-Based Systems (2016).Google Scholar"",""Thomas Hofmann. 2004. Latent semantic models for collaborative filtering. ACM Trans. Information System (2004).Google Scholar"",""Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In Proc. Int. Conf. Learning Representations .Google Scholar"",""Yehuda Koren. 2008. Factorization meets the neighborhood: a multifaceted collaborative filtering model. In Proc. ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining .Google ScholarDigital Library"",""Yehuda Koren, Robert M. Bell, and Chris Volinsky. 2009. Matrix Factorization Techniques for Recommender Systems. IEEE Computer (2009).Google Scholar"",""Feng Li, Zhenrui Chen, Pengjie Wang, Yi Ren, Di Zhang, and Xiaoyu Zhu. 2019. Graph Intention Network for Click-through Rate Prediction in Sponsored Search. In Proc. ACM Int. Conf. Research and Development in Information Retrieval .Google ScholarDigital Library"",""Wenzhe Li, Sungjin Ahn, and Max Welling. 2016. Scalable MCMC for mixed membership stochastic blockmodels. In Proc. Artificial Intelligence and Statistics .Google Scholar"",""Ramon Lopes, Renato Assuncc ao, and Rodrygo LT Santos. 2016. Efficient Bayesian methods for graph-based recommendation. In Proc. ACM Conf. Recommender Systems .Google ScholarDigital Library"",""Sean M McNee, John Riedl, and Joseph A Konstan. 2006. Being accurate is not enough: how accuracy metrics have hurt recommender systems. In CHI'06 extended abstracts on Human factors in computing systems .Google ScholarDigital Library"",""Soumyasundar Pal, Saber Malekmohammadi, Florence Regol, Yingxue Zhang, Yishi Xu, and Mark Coates. 2020. Non-Parametric Graph Learning for Bayesian Graph Neural Networks. Proc. Conf. Uncertainty in Artificial Intelligence (2020).Google Scholar"",""Soumyasundar Pal, Florence Regol, and Mark Coates. 2019. Bayesian Graph Convolutional Neural Networks using Node Copying. Proc. Learning and Reasoning with Graph-Structured Representations Workshop (ICML) (2019).Google Scholar"",""Steffen Rendle. 2010. Factorization Machines. In Proc. IEEE Int. Conf. Data Mining .Google Scholar"",""Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian Personalized Ranking from Implicit Feedback. In Proc. Conf. Uncertainty in Artificial Intelligence .Google Scholar"",""Thiago Silveira, Min Zhang, Xiao Lin, Yiqun Liu, and Shaoping Ma. 2019. How good your recommender system is? A survey on evaluations in recommendation. Int. Journal of Machine Learning and Cybernetics (2019).Google Scholar"",""Weiping Song, Zhiping Xiao, Yifan Wang, Laurent Charlin, Ming Zhang, and Jian Tang. 2019. Session-based Social Recommendation via Dynamic Graph Attention Networks. In Proc. ACM Int. Conf. Web Search and Data Mining .Google ScholarDigital Library"",""Jianing Sun, Yingxue Zhang, Chen Ma, Mark Coates, Huifeng Guo, Ruiming Tang, and Xiuqiang He. 2019. Multi-Graph Convolution Collaborative Filtering. In IEEE Int. Conf. on Data Mining .Google Scholar"",""Louis C. Tiao, Pantelis Elinas, Harrison Nguyen, and Edwin V. Bonilla. 2019. Variational Spectral Graph Convolutional Networks. (2019).Google Scholar"",""Rianne van den Berg, Thomas N Kipf, and Max Welling. 2018. Graph Convolutional Matrix Completion. In Proc. ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (Deep Learning Day) .Google Scholar"",""Saúl Vargas and Pablo Castells. 2011. Rank and relevance in novelty and diversity metrics for recommender systems. In Proc. ACM Conf. Recommender Systems .Google ScholarDigital Library"",""Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò , and Yoshua Bengio. 2018. Graph Attention Networks. In Proc. Int. Conf. Learning Representations .Google Scholar"",""Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019. Neural Graph Collaborative Filtering. In Proc. ACM Int. Conf. Research and Development in Information Retrieval .Google ScholarDigital Library"",""Le Wu, Peijie Sun, Yanjie Fu, Richang Hong, Xiting Wang, and Meng Wang. 2019 a. A neural influence diffusion model for social recommendation. In Int. ACM SIGIR Conf. on Research and Development in Information Retrieval .Google ScholarDigital Library"",""Qitian Wu, Hengrui Zhang, Xiaofeng Gao, Peng He, Paul Weng, Han Gao, and Guihai Chen. 2019 b. Dual Graph Attention Networks for Deep Latent Representation of Multifaceted Social Effects in Recommender Systems. In Proc. Int. Conf. World Wide Web .Google ScholarDigital Library"",""Jheng-Hong Yang, Chih-Ming Chen, Chuan-Ju Wang, and Ming-Feng Tsai. 2018. HOP-rec: high-order proximity for implicit recommendation. In Proc ACM Conf. Recommender Systems .Google ScholarDigital Library"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L. Hamilton, and Jure Leskovec. 2018. Graph Convolutional Neural Networks for Web-Scale Recommender Systems. In Proc. ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining .Google ScholarDigital Library"",""Yingxue Zhang, Soumyasundar Pal, Mark Coates, and Deniz Ü stebay. 2019. Bayesian graph convolutional neural networks for semi-supervised classification. In Proc. AAAI Int. Conf. Artificial Intelligence .Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403255,Learning Based Distributed Tracking,"Inspired by the great success of machine learning in the past decade, people have been thinking about the possibility of improving the theoretical results by exploring data distribution. In this paper, we revisit a fundamental problem called Distributed Tracking (DT) under an assumption that the data follows a certain (known or unknown) distribution, and propose a number Data-dependent algorithms with improved theoretical bounds. Informally, in the DT problem, there is a coordinator and k players, where the coordinator holds a threshold N and each player has a counter. At each time stamp, at most one counter can be increased by one. The job of the coordinator is to capture the exact moment when the sum of all these k counters reaches N. The goal is to minimise the communication cost. While our first type of algorithms assume the concrete data distribution is known in advance, our second type of algorithms can learn the distribution on the fly. Both of the algorithms achieve a communication cost bounded by O(k log log N) with high probability, improving the state-of-the-art data-independent bound O(k log N/k). We further propose a number of implementation optimisation heuristics to improve both efficiency and robustness of the algorithms. Finally, we conduct extensive experiments on three real datasets and four synthetic datasets. The experimental results show that the communication cost of our algorithms is as least as $20%$ of that of the state-of-the-art algorithms.","[{""name"":""Hao WU"",""id"":""/profile/99659572985""},{""name"":""Junhao Gan"",""id"":""/profile/99659573947""},{""name"":""Rui Zhang"",""id"":""/profile/81435596120""},{""name"":""Hao WU"",""id"":""/profile/99659572985""},{""name"":""Junhao Gan"",""id"":""/profile/99659573947""},{""name"":""Rui Zhang"",""id"":""/profile/81435596120""}]","[""Anders Aamand, Piotr Indyk, and Ali Vakilian. 2019. (Learned) Frequency Estimation Algorithms under Zipfian Distribution. CoRR, Vol. abs/1908.05198 (2019). arxiv: 1908.05198Google Scholar"",""Jean-Yves Audibert, Ré mi Munos, and Csaba Szepesvá ri. 2009. Exploration-exploitation tradeoff using variance estimates in multi-armed bandits. Theor. Comput. Sci., Vol. 410, 19 (2009), 1876--1902.Google ScholarDigital Library"",""Irwan Bello, Hieu Pham, Quoc V. Le, Mohammad Norouzi, and Samy Bengio. 2017. Neural Combinatorial Optimization with Reinforcement Learning. In 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24--26, 2017, Workshop Track Proceedings.Google Scholar"",""Fan R. K. Chung and Lincoln Lu. 2006. Survey: Concentration Inequalities and Martingale Inequalities: A Survey. Internet Mathematics, Vol. 3, 1 (2006), 79--127.Google ScholarCross Ref"",""Graham Cormode. 2013. The continuous distributed monitoring model. SIGMOD Record, Vol. 42, 1 (2013), 5--14.Google ScholarDigital Library"",""Graham Cormode, Minos N. Garofalakis, S. Muthukrishnan, and Rajeev Rastogi. 2005. Holistic Aggregates in a Networked World: Distributed Tracking of Approximate Quantiles. In Proceedings of the ACM SIGMOD International Conference on Management of Data, Baltimore, Maryland, USA, June 14--16, 2005. 25--36.Google ScholarDigital Library"",""Graham Cormode, S. Muthukrishnan, and Ke Yi. 2011. Algorithms for distributed functional monitoring. ACM Trans. Algorithms, Vol. 7, 2 (2011), 21:1--21:20.Google ScholarDigital Library"",""Nikos Giatrakos, Antonios Deligiannakis, Minos N. Garofalakis, Izchak Sharfman, and Assaf Schuster. 2012. Prediction-based geometric monitoring over distributed data streams. In Proceedings of the International Conference on Management of Data, SIGMOD, Scottsdale, AZ, USA, May 20--24, 2012. 265--276.Google ScholarDigital Library"",""Chen-Yu Hsu, Piotr Indyk, Dina Katabi, and Ali Vakilian. 2019. Learning-Based Frequency Estimation Algorithms. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6--9, 2019.Google Scholar"",""Zengfeng Huang, Ke Yi, and Qin Zhang. 2019. Randomized Algorithms for Tracking Distributed Count, Frequencies, and Ranks. Algorithmica, Vol. 81, 6 (2019), 2222--2243.Google ScholarDigital Library"",""Ram Keralapura, Graham Cormode, and Jeyashankher Ramamirtham. 2006. Communication-efficient distributed monitoring of thresholded counts. In Proceedings of the ACM SIGMOD International Conference on Management of Data, Chicago, Illinois, USA, June 27--29, 2006. 289--300.Google ScholarDigital Library"",""Elias B. Khalil, Hanjun Dai, Yuyu Zhang, Bistra Dilkina, and Le Song. 2017. Learning Combinatorial Optimization Algorithms over Graphs. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, 4--9 December 2017, Long Beach, CA, USA. 6348--6358.Google Scholar"",""David Kotz, Tristan Henderson, Ilya Abyzov, and Jihwang Yeo. 2009. CRAWDAD dataset dartmouth/campus (v. 2009-09-09).Google Scholar"",""Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018. The Case for Learned Index Structures. In Proceedings of the 2018 International Conference on Management of Data, SIGMOD 2018. 489--504.Google ScholarDigital Library"",""Michael Mitzenmacher. 2018. A Model for Learned Bloom Filters and Optimizing by Sandwiching. In Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, 3--8 December 2018, Montré al, Canada. 462--471.Google Scholar"",""Miao Qiao, Junhao Gan, and Yufei Tao. 2016. Range Thresholding on Streams. In Proceedings of the 2016 International Conference on Management of Data, SIGMOD Conference 2016, San Francisco, CA, USA, June 26 - July 01, 2016. 571--582.Google ScholarDigital Library"",""Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. 2015. Pointer Networks. In Annual Conference on Neural Information Processing Systems (NeuIPS), December 7--12, 2015, Montreal, Quebec, Canada. 2692--2700.Google Scholar""]"
https://doi.org/10.1145/3394486.3403256,Tight Sensitivity Bounds For Smaller Coresets,"An ε-coreset to the dimensionality reduction problem for a (possibly very large) matrix A ∈ Rn x d is a small scaled subset of its n rows that approximates their sum of squared distances to every affine k-dimensional subspace of Rd, up to a factor of 1±ε. Such a coreset is useful for boosting the running time of computing a low-rank approximation (k-SVD/k-PCA) while using small memory. Coresets are also useful for handling streaming, dynamic and distributed data in parallel. With high probability, non-uniform sampling based on the so called leverage score or sensitivity of each row in A yields a coreset. The size of the (sampled) coreset is then near-linear in the total sum of these sensitivity bounds. We provide algorithms that compute provably tight bounds for the sensitivity of each input row. It is based on two ingredients: (i) iterative algorithm that computes the exact sensitivity of each row up to arbitrary small precision for (non-affine) k-subspaces, and (ii) a general reduction for computing a coreset for affine subspaces, given a coreset for (non-affine) subspaces in Rd. Experimental results on real-world datasets, including the English Wikipedia documents-term matrix, show that our bounds provide significantly smaller and data-dependent coresets also in practice. Full open source code is also provided.","[{""name"":""Alaa Maalouf"",""id"":""/profile/99659575057""},{""name"":""Adiel Statman"",""id"":""/profile/99659573230""},{""name"":""Dan Feldman"",""id"":""/profile/81322493481""},{""name"":""Alaa Maalouf"",""id"":""/profile/99659575057""},{""name"":""Adiel Statman"",""id"":""/profile/99659573230""},{""name"":""Dan Feldman"",""id"":""/profile/81322493481""}]","[""2012. https://gist.github.com/h3xx/1976236.Google Scholar"",""2019. https://dumps.wikimedia.org/enwiki/latest/.Google Scholar"",""Homayun Afrabandpey, Tomi Peltola, and Samuel Kaski. 2016. Regression Analysis in Small-n-Large-p Using Interactive Prior Elicitation of Pairwise Similarities. In FILM 2016, NIPS Workshop on Future of Interactive Learning Machines.Google Scholar"",""Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, and Jorge Luis Reyes-Ortiz. 2013. A public domain dataset for human activity recognition using smartphones.. In Esann.Google Scholar"",""Artem Barger and Dan Feldman. 2015. k-Means for Streaming and Distributed Big Sparse Data. CoRR, Vol. abs/1511.08990 (2015). arxiv: 1511.08990 http://arxiv.org/abs/1511.08990Google Scholar"",""Christian Bauckhage. 2015. NumPy/SciPy Recipes for Data Science: Ordinary Least Squares Optimization. researchgate. net, Mar (2015).Google Scholar"",""Vladimir Braverman, Dan Feldman, and Harry Lang. 2016. New Frameworks for Offline and Streaming Coreset Constructions. CoRR, Vol. abs/1612.00889 (2016). arxiv: 1612.00889 http://arxiv.org/abs/1612.00889Google Scholar"",""Michael B Cohen, Sam Elder, Cameron Musco, Christopher Musco, and Madalina Persu. 2015a. Dimensionality reduction for k-means clustering and low rank approximation. In Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing. ACM, 163--172.Google ScholarDigital Library"",""Michael B Cohen, Yin Tat Lee, Cameron Musco, Christopher Musco, Richard Peng, and Aaron Sidford. 2015b. Uniform sampling for matrix approximation. In Proceedings of the 2015 Conference on Innovations in Theoretical Computer Science. 181--190.Google ScholarDigital Library"",""Michael B Cohen, Cameron Musco, and Christopher Musco. 2017. Input sparsity time low-rank approximation via ridge leverage score sampling. In Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms. SIAM, 1758--1777.Google ScholarCross Ref"",""John B Copas. 1983. Regression, prediction and shrinkage. Journal of the Royal Statistical Society: Series B (Methodological), Vol. 45, 3 (1983), 311--335.Google ScholarCross Ref"",""Chris Ding and Xiaofeng He. 2004. K-means clustering via principal component analysis. In Proceedings of the twenty-first international conference on Machine learning. 29.Google ScholarDigital Library"",""Petros Drineas, Malik Magdon-Ismail, Michael W Mahoney, and David P Woodruff. 2012. Fast approximation of matrix coherence and statistical leverage. Journal of Machine Learning Research, Vol. 13, Dec (2012), 3475--3506.Google ScholarDigital Library"",""Petros Drineas, Michael W Mahoney, and Shan Muthukrishnan. 2008. Relative-error CUR matrix decompositions. SIAM J. Matrix Anal. Appl., Vol. 30, 2 (2008), 844--881.Google ScholarDigital Library"",""Dan Feldman. 2020. Core-sets: An updated survey. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, Vol. 10, 1 (2020), e1335.Google ScholarCross Ref"",""Dan Feldman, Morteza Monemizadeh, Christian Sohler, and David P Woodruff. 2010. Coresets and sketches for high dimensional subspace approximation problems. In Proceedings of the twenty-first annual ACM-SIAM symposium on Discrete Algorithms. Society for Industrial and Applied Mathematics, 630--649.Google ScholarDigital Library"",""Dan Feldman, Melanie Schmidt, and Christian Sohler. 2013. Turning big data into tiny data: Constant-size coresets for k-means, pca and projective clustering. In Proceedings of the twenty-fourth annual ACM-SIAM symposium on Discrete algorithms. Society for Industrial and Applied Mathematics, 1434--1453.Google ScholarDigital Library"",""Dan Feldman, Melanie Schmidt, and Christian Sohler. 2018. Turning Big data into tiny data: Constant-size coresets for k-means, PCA and projective clustering. CoRR, Vol. abs/1807.04518 (2018). arxiv: 1807.04518 http://arxiv.org/abs/1807.04518Google Scholar"",""Dan Feldman and Leonard J. Schulman. 2012. Data Reduction for Weighted and Outlier-resistant Clustering. In Proceedings of the Twenty-third Annual ACM-SIAM Symposium on Discrete Algorithms (Kyoto, Japan) (SODA '12). Society for Industrial and Applied Mathematics, Philadelphia, PA, USA, 1343--1354. http://dl.acm.org/citation.cfm?id=2095116.2095222Google Scholar"",""D. Feldman and T. Tassa. 2015. More constraints, smaller coresets: Constrained matrix approximation of sparse big data. In KDD. ACM, 249--258.Google Scholar"",""Dan Feldman, Mikhail Volkov, and Daniela Rus. 2016. Dimensionality reduction of massive sparse datasets using coresets. In Advances in Neural Information Processing Systems. 2766--2774.Google Scholar"",""Alan Frieze, Ravi Kannan, and Santosh Vempala. 2004. Fast Monte-Carlo algorithms for finding low-rank approximations. Journal of the ACM (JACM), Vol. 51, 6 (2004), 1025--1041.Google ScholarDigital Library"",""Neil Gallagher, Kyle R Ulrich, Austin Talbot, Kafui Dzirasa, Lawrence Carin, and David E Carlson. 2017. Cross-spectral factor analysis. In Advances in Neural Information Processing Systems. 6842--6852.Google Scholar"",""Mina Ghashami, Edo Liberty, and Jeff M Phillips. 2016a. Efficient frequent directions algorithm for sparse matrices. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 845--854.Google ScholarDigital Library"",""Mina Ghashami, Edo Liberty, Jeff M Phillips, and David P Woodruff. 2016b. Frequent directions: Simple and deterministic matrix sketching. SIAM J. Comput., Vol. 45, 5 (2016), 1762--1792.Google ScholarCross Ref"",""Gene H Golub and Christian Reinsch. 1971. Singular value decomposition and least squares solutions. In Linear Algebra. Springer, 134--151.Google Scholar"",""Gene H Golub and Charles F Van Loan. 2012. Matrix computations. Vol. 3. JHU press.Google Scholar"",""Sariel Har-Peled. 2004. No, coreset, no cry. In International Conference on Foundations of Software Technology and Theoretical Computer Science. Springer, 324--335.Google ScholarDigital Library"",""Arthur E Hoerl and Robert W Kennard. 1970. Ridge regression: Biased estimation for nonorthogonal problems. Technometrics, Vol. 12, 1 (1970), 55--67.Google ScholarCross Ref"",""William B Johnson and Joram Lindenstrauss. 1984. Extensions of Lipschitz mappings into a Hilbert space. Contemporary mathematics, Vol. 26, 189--206 (1984), 1.Google Scholar"",""Ian Jolliffe. 2011. Principal component analysis .Springer.Google Scholar"",""Eric Jones, Travis Oliphant, Pearu Peterson, et al. 2001--. SciPy: Open source scientific tools for Python. http://www.scipy.org/ [Online; accessed \u003ctoday\u003e].Google Scholar"",""Byung Kang, Woosang Lim, and Kyomin Jung. 2011. Scalable kernel K-means via centroid approximation. In Proc. NIPS.Google Scholar"",""Michael Langberg and Leonard J Schulman. 2010. Universal $varepsilon$-approximators for integrals. In Proceedings of the twenty-first annual ACM-SIAM symposium on Discrete Algorithms. SIAM, 598--607.Google ScholarDigital Library"",""Valero Laparra, Jesús Malo, and Gustau Camps-Valls. 2015. Dimensionality reduction via regression in hyperspectral imagery. IEEE Journal of Selected Topics in Signal Processing, Vol. 9, 6 (2015), 1026--1036.Google ScholarCross Ref"",""Yingyu Liang, Maria-Florina Balcan, and Vandana Kanchanapally. 2013. Distributed PCA and k-means clustering. In The Big Learning Workshop at NIPS, Vol. 2013. Citeseer.Google Scholar"",""Alaa Maalouf, Ibrahim Jubran, and Dan Feldman. 2019 a. Fast and Accurate Least-Mean-Squares Solvers. In Advances in Neural Information Processing Systems.Google Scholar"",""Alaa Maalouf, Ibrahim Jubran, Murad Tukan, and Dan Feldman. 2020. Faster PAC Learning and Smaller Coresets via Smoothed Analysis. arXiv e-prints, Article arXiv:2006.05441 (2020).Google Scholar"",""Alaa Maalouf, Adiel Statman, and Dan Feldman. 2019 b. Tight Sensitivity Bounds For Smaller Coresets. arXiv preprint arXiv:1907.01433 (2019).Google Scholar"",""Alaa Maalouf, Adiel Statman, and Dan Feldman. 2020. Open source code for all the algorithms presented in this paper. hrefhttps://github.com/adielstatman/Tight_sen_projLink for open-source code.Google Scholar"",""Thanh T Ngo, Mohammed Bellalij, and Yousef Saad. 2012. The trace ratio optimization problem. SIAM review, Vol. 54, 3 (2012), 545--569.Google Scholar"",""Travis E Oliphant. 2006. A guide to NumPy. Vol. 1. Trelgol Publishing USA.Google Scholar"",""Dimitris Papailiopoulos, Anastasios Kyrillidis, and Christos Boutsidis. 2014. Provable deterministic leverage score sampling. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. 997--1006.Google ScholarDigital Library"",""Karl Pearson. 1900. X. On the criterion that a given system of deviations from the probable in the case of a correlated system of variables is such that it can be reasonably supposed to have arisen from random sampling. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, Vol. 50, 302 (1900), 157--175.Google ScholarCross Ref"",""Xi Peng, Zhang Yi, and Huajin Tang. 2015. Robust subspace clustering via thresholding ridge regression. In Twenty-Ninth AAAI Conference on Artificial Intelligence.Google ScholarDigital Library"",""Jeff M Phillips. 2016. Coresets and sketches. arXiv preprint arXiv:1601.00617 (2016).Google Scholar"",""Aldo Porco, Andreas Kaltenbrunner, and Vicencc Gómez. 2015. Low-rank approximations for predicting voting behaviour. In Workshop on Networks in the Social and Information Sciences, NIPS.Google Scholar"",""S Rasoul Safavian and David Landgrebe. 1991. A survey of decision tree classifier methodology. IEEE transactions on systems, man, and cybernetics, Vol. 21, 3 (1991), 660--674.Google Scholar"",""Tamas Sarlos. 2006. Improved approximation algorithms for large matrices via random projections. In 2006 47th Annual IEEE Symposium on Foundations of Computer Science (FOCS'06). IEEE, 143--152.Google ScholarDigital Library"",""George AF Seber and Alan J Lee. 2012. Linear regression analysis. Vol. 329. John Wiley \u0026 Sons.Google Scholar"",""Robert Tibshirani. 1996. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society: Series B (Methodological), Vol. 58, 1 (1996), 267--288.Google ScholarCross Ref"",""Nicolas Tremblay, Simon Barthelmé, and Pierre-Olivier Amblard. 2018. Determinantal point processes for coresets. arXiv preprint arXiv:1803.08700 (2018).Google Scholar"",""Kasturi Varadarajan and Xin Xiao. 2012a. A near-linear algorithm for projective clustering integer points. In Proceedings of the twenty-third annual ACM-SIAM symposium on Discrete Algorithms. SIAM, 1329--1342.Google ScholarCross Ref"",""Kasturi R. Varadarajan and Xin Xiao. 2012b. On the Sensitivity of Shape Fitting Problems. CoRR, Vol. abs/1209.4893 (2012). arxiv: 1209.4893 http://arxiv.org/abs/1209.4893Google Scholar"",""Jiyan Yang, Yin-Lam Chow, Christopher Ré, and Michael W Mahoney. 2017. Weighted SGD for $ell_p$ regression with randomized preconditioning. The Journal of Machine Learning Research, Vol. 18, 1 (2017), 7811--7853.Google ScholarDigital Library"",""Lei-Hong Zhang, Li-Zhi Liao, and Michael K Ng. 2010. Fast algorithms for the generalized Foley--Sammon discriminant analysis. SIAM J. Matrix Anal. Appl., Vol. 31, 4 (2010), 1584--1605.Google ScholarDigital Library"",""Yilin Zhang and Karl Rohe. 2018. Understanding Regularized Spectral Clustering via Graph Conductance. In Advances in Neural Information Processing Systems. 10631--10640.Google Scholar"",""Hui Zou and Trevor Hastie. 2005. Regularization and variable selection via the elastic net. Journal of the royal statistical society: series B (statistical methodology), Vol. 67, 2 (2005), 301--320.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403257,GHashing: Semantic Graph Hashing for Approximate Similarity Search in Graph Databases,"Graph similarity search aims to find the most similar graphs to a query in a graph database in terms of a given proximity measure, say Graph Edit Distance (GED). It is a widely studied yet still challenging problem. Most of the studies are based on the pruning-verification framework, which first prunes non-promising graphs and then conducts verification on the small candidate set. Existing methods are capable of managing databases with thousands or tens of thousands of graphs, but fail to scale to even larger database, due to their exact pruning strategy. Inspired by the recent success of deep-learning-based semantic hashing in image and document retrieval, we propose a novel graph neural network (GNN) based semantic hashing, i.e. GHashing, for approximate pruning. We first train a GNN with ground-truth GED results so that it learns to generate embeddings and hash codes that preserve GED between graphs. Then a hash index is built to enable graph lookup in constant time. To answer a query, we use the hash codes and the continuous embeddings as two-level pruning to retrieve the most promising candidates, which are sent to the exact solver for final verification. Due to the approximate pruning strategy leveraged by our graph hashing technique, our approach achieves significantly faster query time compared to state-of-the-art methods while maintaining a high recall. Experiments show that our approach is on average 20x faster than the only baseline that works on million-scale databases, which demonstrates GHashing successfully provides a new direction in addressing graph search problem for large-scale graph databases.","[{""name"":""Zongyue Qin"",""id"":""/profile/99659575137""},{""name"":""Yunsheng Bai"",""id"":""/profile/99659347342""},{""name"":""Yizhou Sun"",""id"":""/profile/81548005095""},{""name"":""Zongyue Qin"",""id"":""/profile/99659575137""},{""name"":""Yunsheng Bai"",""id"":""/profile/99659347342""},{""name"":""Yizhou Sun"",""id"":""/profile/81548005095""}]","[""Yunsheng Bai, Hao Ding, Song Bian, Ting Chen, Yizhou Sun, and Wei Wang. 2019 a. SimGNN: A Neural Network Approach to Fast Graph Similarity Computation. In WSDM.Google Scholar"",""Yunsheng Bai, Hao Ding, Ken Gu, Yizhou Sun, and Wei Wang. 2020. Learning-based Efficient Graph Similarity Computation via Multi-Scale Convolutional Set Matching. AAAI (2020).Google Scholar"",""Yunsheng Bai, Hao Ding, Yang Qiao, Agustin Marinovic, Ken Gu, Ting Chen, Yizhou Sun, and Wei Wang. 2019 b. Unsupervised Inductive Graph-Level Representation Learning via Graph-Graph Proximity. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019, Macao, China, August 10--16, 2019. 1988--1994. https://doi.org/10.24963/ijcai.2019/275Google ScholarCross Ref"",""Albert-Laszlo Barabasi and Reka Albert. 1999. Albert, R.: Emergence of Scaling in Random Networks. Science 286, 509--512. Science (New York, N.Y.), Vol. 286 (11 1999), 509--12. https://doi.org/10.1126/science.286.5439.509Google Scholar"",""Horst Bunke. 1983. What is the distance between graphs. Bulletin of the EATCS, Vol. 20 (1983), 35--39.Google Scholar"",""Horst Bunke and Kim Shearer. 1998. A graph distance metric based on the maximal common subgraph. Pattern recognition letters, Vol. 19, 3--4 (1998), 255--259.Google Scholar"",""Guangyong Chen, Pengfei Chen, Chang-Yu Hsieh, Chee-Kong Lee, Benben Liao, Renjie Liao, Weiwen Liu, Jiezhong Qiu, Qiming Sun, Jie Tang, Richard Zemel, and Shengyu Zhang. 2019 a. Alchemy: A Quantum Chemistry Dataset for Benchmarking AI Models. arXiv preprint arXiv:1906.09427 (2019).Google Scholar"",""Xiaoyang Chen, Hongwei Huo, Jun Huan, and Jeffrey Scott Vitter. 2019 b. An efficient algorithm for graph edit distance computation. Knowledge-Based Systems, Vol. 163 (2019), 762--775.Google ScholarCross Ref"",""Pàl Erdös and A. Rényi. 1959. On random graphs I. Publ. Math. Debrecen, Vol. 6 (01 1959), 290--297.Google Scholar"",""Justin Gilmer, Samuel S. Schoenholz, Patrick F. Riley, Oriol Vinyals, and George E. Dahl. 2017. Neural Message Passing for Quantum Chemistry. In Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6--11 August 2017. 1263--1272. http://proceedings.mlr.press/v70/gilmer17a.htmlGoogle Scholar"",""Jongik Kim, Dong-Hoon Choi, and Chen Li. 2019. Inves: Incremental Partitioning-Based Verification for Graph Similarity Search. In EDBT.Google Scholar"",""Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24--26, 2017, Conference Track Proceedings. https://openreview.net/forum?id=SJU4ayYglGoogle Scholar"",""H. Lai, Y. Pan, Ye Liu, and S. Yan. 2015. Simultaneous feature learning and hash coding with deep neural networks. In 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE Computer Society, Los Alamitos, CA, USA, 3270--3278. https://doi.org/10.1109/CVPR.2015.7298947Google Scholar"",""Yujia Li, Chengcun Gu, Thomas Dullien, Oriol Vinyals, and Pushmeet Kohli. 2019. Graph Matching Networks for Learning the Similarity of Graph Structured Objects. In ICML.Google Scholar"",""Zijian Li, Xun Jian, Xiang Lian, and Lei Chen. 2017. An Efficient Probabilistic Approach for Graph Similarity Search. 2018 IEEE 34th International Conference on Data Engineering (ICDE) (2017), 533--544.Google Scholar"",""Yongjiang Liang and Peixiang Zhao. 2017. Similarity Search in Graph Databases: A Multi-Layered Indexing Approach. In 33rd IEEE International Conference on Data Engineering, ICDE 2017, San Diego, CA, USA, April 19--22, 2017. 783--794. https://doi.org/10.1109/ICDE.2017.129Google Scholar"",""Haomiao Liu, Ruiping Wang, Shiguang Shan, and Xilin Chen. 2019. Deep Supervised Hashing for Fast Image Retrieval. International Journal of Computer Vision (03 2019). https://doi.org/10.1007/s11263-019-01174--4Google Scholar"",""Kaspar Riesen and Horst Bunke. 2009. Approximate graph edit distance computation by means of bipartite graph matching. Image and Vision Computing, Vol. 27 (06 2009), 950--959. https://doi.org/10.1016/j.imavis.2008.04.004Google ScholarDigital Library"",""Kaspar Riesen, Stefan Fankhauser, and Horst Bunke. 2007. Speeding Up Graph Edit Distance Computation with a Bipartite Heuristic. In Mining and Learning with Graphs, MLG 2007, Firence, Italy, August 1--3, 2007, Proceedings.Google Scholar"",""Kaspar Riesen, Miquel Ferrer, and Horst Bunke. 2015. Approximate Graph Edit Distance in Quadratic Time. IEEE/ACM Transactions on Computational Biology and Bioinformatics, Vol. PP (09 2015), 1--1. https://doi.org/10.1109/TCBB.2015.2478463Google Scholar"",""Esko Ukkonen. 1992. Approximate string-matching with Q-grams and maximal matches. Theoretical Computer Science, Vol. 92 (01 1992), 191--211. https://doi.org/10.1016/0304--3975(92)90143--4Google Scholar"",""Guangtao Wang, Baoezeng Wang, Xiaochun Yang, and Lei Yu. 2012b. Efficiently Indexing Large Sparse Graphs for Similarity Search. IEEE Trans. Knowl. Data Eng., Vol. 24 (03 2012), 440--451. https://doi.org/10.1109/TKDE.2010.28Google ScholarDigital Library"",""Jun Wang, Wei Liu, Sanjiv Kumar, and Shih-Fu Chang. 2016. Learning to Hash for Indexing Big Data - A Survey. Proc. IEEE, Vol. 104, 1 (2016), 34--57. https://doi.org/10.1109/JPROC.2015.2487976Google ScholarCross Ref"",""Xiaoli Wang, Xiaofeng Ding, Anthony Tung, Shanshan Ying, and Hai Jin. 2012a. An Efficient Graph Indexing Method. Proceedings - International Conference on Data Engineering (04 2012). https://doi.org/10.1109/ICDE.2012.28Google ScholarDigital Library"",""Ye Zhang, Md. Mustafizur Rahman, Alex Braylan, Brandon Dang, Heng-Lu Chang, Henna Kim, Quinten McNamara, Aaron Angert, Edward Banner, Vivek Khetan, Tyler McDonnell, An Thanh Nguyen, Dan Xu, Byron C. Wallace, and Matthew Lease. 2016. Neural Information Retrieval: A Literature Review. CoRR, Vol. abs/1611.06792 (2016). arxiv: 1611.06792 http://arxiv.org/abs/1611.06792Google Scholar"",""Xiang Zhao, Chuan Xiao, Xuemin Lin, Qing Liu, and Wenjie Zhang. 2013a. A partition-based approach to structure similarity search. Proceedings of the VLDB Endowment, Vol. 7 (11 2013), 169--180. https://doi.org/10.14778/2732232.2732236Google ScholarDigital Library"",""Xiang Zhao, Chuan Xiao, Xuemin Lin, Wei Wang, and Yoshiharu Ishikawa. 2013b. Efficient processing of graph similarity queries with edit distance constraints. The VLDB Journal, Vol. 22 (12 2013). https://doi.org/10.1007/s00778-013-0306--1Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403258,Interactive Path Reasoning on Graph for Conversational Recommendation,"Traditional recommendation systems estimate user preference on items from past interaction history, thus suffering from the limitations of obtaining fine-grained and dynamic user preference. Conversational recommendation system (CRS) brings revolutions to those limitations by enabling the system to directly ask users about their preferred attributes on items. However, existing CRS methods do not make full use of such advantage --- they only use the attribute feedback in rather implicit ways such as updating the latent user representation. In this paper, we propose Conversational Path Reasoning (CPR), a generic framework that models conversational recommendation as an interactive path reasoning problem on a graph. It walks through the attribute vertices by following user feedback, utilizing the user preferred attributes in an explicit way. By leveraging on the graph structure, CPR is able to prune off many irrelevant candidate attributes, leading to a better chance of hitting user-preferred attributes. To demonstrate how CPR works, we propose a simple yet effective instantiation named SCPR (Simple CPR). We perform empirical studies on the multi-round conversational recommendation scenario, the most realistic CRS setting so far that considers multiple rounds of asking attributes and recommending items. Through extensive experiments on two datasets Yelp and LastFM, we validate the effectiveness of our SCPR, which significantly outperforms the state-of-the-art CRS methods EAR and CRM. In particular, we find that the more attributes there are, the more advantages our method can achieve.","[{""name"":""Wenqiang Lei"",""id"":""/profile/99659231861""},{""name"":""Gangyi Zhang"",""id"":""/profile/99659574555""},{""name"":""Xiangnan He"",""id"":""/profile/87658767957""},{""name"":""Yisong Miao"",""id"":""/profile/99659495958""},{""name"":""Xiang Wang"",""id"":""/profile/99659076634""},{""name"":""Liang Chen"",""id"":""/profile/99659003038""},{""name"":""Tat-Seng Chua"",""id"":""/profile/81100547902""},{""name"":""Wenqiang Lei"",""id"":""/profile/99659231861""},{""name"":""Gangyi Zhang"",""id"":""/profile/99659574555""},{""name"":""Xiangnan He"",""id"":""/profile/87658767957""},{""name"":""Yisong Miao"",""id"":""/profile/99659495958""},{""name"":""Xiang Wang"",""id"":""/profile/99659076634""},{""name"":""Liang Chen"",""id"":""/profile/99659003038""},{""name"":""Tat-Seng Chua"",""id"":""/profile/81100547902""}]","[""Keping Bi, Qingyao Ai, Yongfeng Zhang, and W Bruce Croft. 2019. Conversational product search based on negative feedback. In CIKM. 359--368.Google Scholar"",""Senthilkumar Chandramohan, Matthieu Geist, Fabrice Lefevre, and Olivier Pietquin. 2011. User simulation in dialogue systems using inverse reinforcement learning. In Interspeech 2011. 1025--1028.Google Scholar"",""Olivier Chapelle and Lihong Li. 2011. An empirical evaluation of thompson sampling. In NeurIPS. 2249--2257.Google Scholar"",""Haokun Chen, Xinyi Dai, Han Cai,Weinan Zhang, XuejianWang, Ruiming Tang, Yuzhou Zhang, and Yong Yu. 2019. Large-scale interactive recommendation with tree-structured policy gradient. In AAAI, Vol. 33. 3312--3320.Google ScholarCross Ref"",""Qibin Chen, Junyang Lin, Yichang Zhang, Ming Ding, Yukuo Cen, Hongxia Yang, and Jie Tang. 2019. Towards Knowledge-Based Recommender Dialog System. In EMNLP-IJCNLP. 1803--1813.Google Scholar"",""Konstantina Christakopoulou, Alex Beutel, Rui Li, Sagar Jain, and Ed H Chi. 2018. Q\u0026R: A Two-Stage Approach toward Interactive Recommendation. In SIGKDD. 139--148.Google Scholar"",""Konstantina Christakopoulou, Filip Radlinski, and Katja Hofmann. 2016. Towards conversational recommender systems. In SIGKDD. 815--824.Google Scholar"",""Sudeep Gandhe and David Traum. 2008. An evaluation understudy for dialogue coherence models. In Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue. 172--181.Google ScholarDigital Library"",""Xiangnan He and Tat-Seng Chua. 2017. Neural factorization machines for sparse predictive analytics. In SIGIR. 355--364.Google Scholar"",""Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural Collaborative Filtering. In WWW. 173--182.Google Scholar"",""Xiangnan He, Hanwang Zhang, Min-Yen Kan, and Tat-Seng Chua. 2016. Fast matrix factorization for online recommendation with implicit feedback. In SIGIR. 549--558.Google Scholar"",""Xisen Jin, Wenqiang Lei, Zhaochun Ren, Hongshen Chen, Shangsong Liang, Yihong Zhao, and Dawei Yin. 2018. Explicit State Tracking with Semi-Supervision for Neural Dialogue Generation. In CIKM. 1403--1412.Google Scholar"",""Wenqiang Lei, Xiangnan He, Yisong Miao, Qingyun Wu, Richang Hong, Min- Yen Kan, and Tat-Seng Chua. 2020. Estimation--Action--Reflection: Towards Deep Interaction Between Conversational and Recommender Systems. In WSDM. 304--312.Google Scholar"",""Wenqiang Lei, Xisen Jin, Min-Yen Kan, Zhaochun Ren, Xiangnan He, and Dawei Yin. 2018. Sequicity: Simplifying Task-oriented Dialogue Systems with Single Sequence-to-Sequence Architectures. In ACL. 1437--1447.Google Scholar"",""Raymond Li, Samira Ebrahimi Kahou, Hannes Schulz, Vincent Michalski, Laurent Charlin, and Chris Pal. 2018. Towards Deep Conversational Recommendations. In NeurIPS. 9748--9758.Google Scholar"",""Shijun Li, Wenqiang Lei, Qingyun Wu, Xiangnan He, Peng Jiang, and Tat-Seng Chua. 2020. Seamlessly Unifying Attributes and Items: Conversational Recommendation for Cold-Start Users. arXiv preprint arXiv:2005.12979 (2020).Google Scholar"",""Lizi Liao, Yunshan Ma, Xiangnan He, Richang Hong, and Tat-Seng Chua. 2018. Knowledge-aware Multimodal Dialogue Systems. In ACM MM. 801--809.Google Scholar"",""Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness, Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg Ostrovski, et al. 2015. Human-level control through deep reinforcement learning. Nature 518, 7540 (2015), 529--533.Google Scholar"",""Bilih Priyogi. 2019. Preference Elicitation Strategy for Conversational Recommender System. In WSDM. 824--825.Google Scholar"",""Steffen Rendle. 2010. Factorization machines. In ICDM. 995--1000.Google Scholar"",""Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Factorizing personalized markov chains for next-basket recommendation. In WWW. 811--820.Google Scholar"",""Nicola Sardella, Claudio Biancalana, Alessandro Micarelli, and Giuseppe Sansonetti. 2019. An Approach to Conversational Recommendation of Restaurants. In ICHCI. 123--130.Google Scholar"",""Weiping Song, Zhiping Xiao, YifanWang, Laurent Charlin, Ming Zhang, and Jian Tang. 2019. Session-based social recommendation via dynamic graph attention networks. In WSDM. 555--563.Google Scholar"",""Yueming Sun and Yi Zhang. 2018. Conversational Recommender System. In SIGIR. 235--244.Google Scholar"",""Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019. Neural Graph Collaborative Filtering. In SIGIR. 165--174.Google Scholar"",""XiangWang, DingxianWang, Canran Xu, Xiangnan He, Yixin Cao, and Tat-Seng Chua. 2019. Explainable reasoning over knowledge graphs for recommendation. In AAAI, Vol. 33. 5329--5336.Google ScholarCross Ref"",""Ji Wu, Miao Li, and Chin-Hui Lee. 2015. A probabilistic framework for representing dialog systems and entropy-based dialog management through dynamic stochastic state evolution. TASLP 23, 11 (2015), 2026--2035.Google Scholar"",""Qingyun Wu, Naveen Iyer, and Hongning Wang. 2018. Learning Contextual Bandits in a Non-stationary Environment. In SIGIR. 495--504.Google Scholar"",""Yikun Xian, Zuohui Fu, S Muthukrishnan, Gerard De Melo, and Yongfeng Zhang. 2019. Reinforcement knowledge graph reasoning for explainable recommendation. In SIGIR. 285--294.Google Scholar"",""Jheng-Hong Yang, Chih-Ming Chen, Chuan-Ju Wang, and Ming-Feng Tsai. 2018. HOP-rec: high-order proximity for implicit recommendation. In RecSys. 140--144.Google Scholar"",""Tong Yu, Yilin Shen, and Hongxia Jin. 2019. An Visual Dialog Augmented Interactive Recommender System. In SIGKDD. 157--165.Google Scholar"",""Ruiyi Zhang, Tong Yu, Yilin Shen, Hongxia Jin, and Changyou Chen. 2019. Text- Based Interactive Recommendation via Constraint-Augmented Reinforcement Learning. In NIPS. 15188--15198.Google Scholar"",""Xiaoying Zhang, Hong Xie, Hang Li, and John Lui. 2020. Conversational Contextual Bandit: Algorithm and Application. In WWW.Google Scholar"",""Yongfeng Zhang, Xu Chen, Qingyao Ai, Liu Yang, and W Bruce Croft. 2018. Towards conversational search and recommendation: System ask, user respond. In CIKM. 177--186.Google Scholar"",""Lei Zheng, Chun-Ta Lu, Fei Jiang, Jiawei Zhang, and Philip S. Yu. 2018. Spectral Collaborative Filtering. In RecSys. 311--319.Google Scholar"",""Ke Zhou, Shuang-Hong Yang, and Hongyuan Zha. 2011. Functional matrix factorizations for cold-start recommendation. In SIGIR. 315--324.Google Scholar""]"
https://doi.org/10.1145/3394486.3403259,Algorithmic Aspects of Temporal Betweenness,"The betweenness centrality of a graph vertex measures how often this vertex is visited on shortest paths between other vertices of the graph. In the analysis of many real-world graphs or networks, betweenness centrality of a vertex is used as an indicator for its relative importance in the network. In recent years, a growing number of real-world networks is modeled as temporal graphs instead of conventional (static) graphs. In a temporal graph, we have a fixed set of vertices and there is a finite discrete set of time steps and every edge might be present only at some time steps. While shortest paths are straightforward to define in static graphs, temporal paths can be considered ""optimal"" with respect to many different criteria, including length, arrival time, and overall travel time (shortest, foremost, and fastest paths). This leads to different concepts of temporal betweenness centrality, posing new challenges on the algorithmic side. We provide a systematic study of temporal betweenness variants based on various concepts of optimal temporal paths both on a theoretical and empirical level.","[{""name"":""Sebastian Buß"",""id"":""/profile/99659574943""},{""name"":""Hendrik Molter"",""id"":""/profile/81551772756""},{""name"":""Rolf Niedermeier"",""id"":""/profile/81100191636""},{""name"":""Maciej Rymar"",""id"":""/profile/99659575122""},{""name"":""Sebastian Buß"",""id"":""/profile/99659574943""},{""name"":""Hendrik Molter"",""id"":""/profile/81551772756""},{""name"":""Rolf Niedermeier"",""id"":""/profile/81100191636""},{""name"":""Maciej Rymar"",""id"":""/profile/99659575122""}]","[""Ahmad Alsayed and Desmond J Higham. 2015. Betweenness in time dependent networks. Chaos, Solitons \u0026 Fractals, Vol. 72 (2015), 35--48.Google ScholarCross Ref"",""Ulrik Brandes. 2001. A Faster Algorithm for Betweenness Centrality. Journal of Mathematical Sociology, Vol. 25, 2 (2001), 163--177.Google ScholarCross Ref"",""Binh-Minh Bui-Xuan, Afonso Ferreira, and Aubin Jarry. 2003. Computing shortest, fastest, and foremost journeys in dynamic networks. International Journal of Foundations of Computer Science, Vol. 14, 02 (2003), 267--285.Google ScholarCross Ref"",""Sebastian Buß, Hendrik Molter, Rolf Niedermeier, and Maciej Rymar. 2020. Algorithmic Aspects of Temporal Betweenness. CoRR, Vol. abs/2006.08668 (2020). http://arxiv.org/abs/2006.08668Google Scholar"",""Arnaud Casteigts, Anne-Sophie Himmel, Hendrik Molter, and Philipp Zschoche. 2019. The Computational Complexity of Finding Temporal Paths under Waiting Time Constraints. CoRR, Vol. abs/1909.06437 (2019). http://arxiv.org/abs/1909.06437Google Scholar"",""Elizabeth M. Daly and Mads Haahr. 2007. Social Network Analysis for Routing in Disconnected Delay-tolerant MANETs. In Proceedings of the 8th ACM International Symposium on Mobile Ad Hoc Networking and Computing. ACM, 32--40.Google Scholar"",""Julie Fournet and Alain Barrat. 2014. Contact patterns among high school students. PlOS ONE, Vol. 9, 9 (2014).Google ScholarCross Ref"",""Linton C. Freeman. 1977. A Set of Measures of Centrality Based on Betweenness. Sociometry, Vol. 40, 1 (1977), 35--41.Google ScholarCross Ref"",""Valerio Gemmetto, Alain Barrat, and Ciro Cattuto. 2014. Mitigation of infectious disease at school: targeted class closure vs school closure. BMC Infectious Diseases, Vol. 14, 1 (2014), 695.Google ScholarCross Ref"",""Robert Goerke. 2011. Email Network of KIT Informatics. http://i11www.iti.uni-karlsruhe.de/en/projects/spp1307/emaildata.Google Scholar"",""Habiba, Chayant Tantipathananandh, and Tanya Y Berger-Wolf. 2007. Betweenness centrality measure in dynamic networks. Technical Report 19. Department of Computer Science, University of Illinois at Chicago, Chicago. DIMACS Technical Report.Google Scholar"",""Anne-Sophie Himmel, Matthias Bentert, André Nichterlein, and Rolf Niedermeier. 2019. Efficient Computation of Optimal Temporal Walks under Waiting-Time Constraints. In Proceedings of the 8th International Conference on Complex Networks and their Applications (SCI), Vol. 882. Springer, 494--506.Google Scholar"",""Petter Holme. 2015. Modern temporal network theory: a colloquium. The European Physical Journal B, Vol. 88, 9 (2015), 234.Google ScholarCross Ref"",""Petter Holme and Jari Saramaki (eds.). 2013. Temporal Networks .Springer.Google Scholar"",""Petter Holme and Jari Saram\""aki (eds.). 2019. Temporal Network Theory .Springer.Google Scholar"",""Lorenzo Isella, Juliette Stehlé, Alain Barrat, Ciro Cattuto, Jean-Francc ois Pinton, and Wouter Van den Broeck. 2011. What's in a crowd? Analysis of face-to-face behavioral networks. Journal of Theoretical Biology, Vol. 271, 1 (2011), 166--180.Google ScholarCross Ref"",""Hyoungshick Kim and Ross Anderson. 2012. Temporal node centrality in complex networks. Physical Review E, Vol. 85, 2 (2012), 026107.Google ScholarCross Ref"",""William R Knight. 1966. A computer method for calculating Kendall's tau with ungrouped data. J. Amer. Statist. Assoc., Vol. 61, 314 (1966), 436--439.Google ScholarCross Ref"",""Matthieu Latapy, Tiphaine Viard, and Clémence Magnien. 2018. Stream graphs and link streams for the modeling of interactions over time. Social Network Analysis and Mining, Vol. 8, 1 (2018), 61.Google ScholarCross Ref"",""Loet Leydesdorff. 2007. Betweenness centrality as an indicator of the interdisciplinarity of scientific journals. Journal of the American Society for Information Science and Technology, Vol. 58, 9 (2007), 1303--1319.Google ScholarDigital Library"",""Othon Michail. 2016. An introduction to temporal graphs: An algorithmic perspective. Internet Mathematics, Vol. 12, 4 (2016), 239--280.Google ScholarCross Ref"",""Vincenzo Nicosia, John Tang, Cecilia Mascolo, Mirco Musolesi, Giovanni Russo, and Vito Latora. 2013. Graph metrics for temporal networks. In Temporal Networks. Springer, 15--40.Google Scholar"",""Tore Opsahl and Pietro Panzarasa. 2009. Clustering in weighted networks. Social Networks, Vol. 31, 2 (2009), 155--163.Google ScholarCross Ref"",""Amir Afrasiabi Rad, Paola Flocchini, and Joanne Gaudet. 2017. Computation and analysis of temporal betweenness in a knowledge mobilization network. Computational Social Networks, Vol. 4, 1 (2017), 5.Google ScholarCross Ref"",""Özgür cS imcs ek and Andrew G Barto. 2009. Skill Characterization Based on Betweenness. In Proceedings of Advances in Neural Information Processing Systems 21. Curran Associates, Inc., 1497--1504.Google Scholar"",""Juliette Stehlé, Nicolas Voirin, Alain Barrat, Ciro Cattuto, Lorenzo Isella, Jean-Francc ois Pinton, Marco Quaggiotto, Wouter Van den Broeck, Corinne Régis, Bruno Lina, et al. 2011. High-resolution measurements of face-to-face contact patterns in a primary school. PlOS ONE, Vol. 6, 8 (2011).Google ScholarCross Ref"",""John Tang, Cecilia Mascolo, Mirco Musolesi, and Vito Latora. [n.d.]. Exploiting temporal complex network metrics in mobile malware containment. In Proceedings of the 2011 IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks (2011). 1--9.Google ScholarDigital Library"",""John Tang, Mirco Musolesi, Cecilia Mascolo, and Vito Latora. 2009. Temporal distance metrics for social network analysis. In Proceedings of the 2nd ACM Workshop on Online Social Networks. ACM, 31--36.Google ScholarDigital Library"",""John Tang, Mirco Musolesi, Cecilia Mascolo, Vito Latora, and Vincenzo Nicosia. 2010. Analysing Information Flows and Key Mediators Through Temporal Centrality Metrics. In Proceedings of the 3rd ACM Workshop on Social Network Systems. ACM, 3:1--3:6.Google ScholarDigital Library"",""Leslie G Valiant. 1979. The complexity of enumeration and reliability problems. SIAM J. Comput., Vol. 8, 3 (1979), 410--421.Google ScholarCross Ref"",""Martijn P van den Heuvel, René CW Mandl, Cornelis J Stam, René S Kahn, and Hilleke E Hulshoff Pol. 2010. Aberrant frontal and temporal complex network structure in schizophrenia: a graph theoretical analysis. Journal of Neuroscience, Vol. 30, 47 (2010), 15915--15926.Google ScholarCross Ref"",""Philippe Vanhems, Alain Barrat, Ciro Cattuto, Jean-Francc ois Pinton, Nagham Khanafer, Corinne Régis, Byeul-a Kim, Brigitte Comte, and Nicolas Voirin. 2013. Estimating potential infection transmission routes in hospital wards using wearable proximity sensors. PlOS ONE, Vol. 8, 9 (2013).Google Scholar"",""Huanhuan Wu, James Cheng, Yiping Ke, Silu Huang, Yuzhen Huang, and Hejun Wu. 2016. Efficient algorithms for temporal path computation. IEEE Transactions on Knowledge and Data Engineering, Vol. 28, 11 (2016), 2927--2942.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403260,Non-Linear Mining of Social Activities in Tensor Streams,"Given a large time-evolving event series such as Google web-search logs, which are collected according to various aspects, i.e., timestamps, locations and keywords, how accurately can we forecast their future activities? How can we reveal significant patterns that allow us to long-term forecast from such complex tensor streams? In this paper, we propose a streaming method, namely, CubeCast, that is designed to capture basic trends and seasonality in tensor streams and extract temporal and multi-dimensional relationships between such dynamics. Our proposed method has the following properties: (a) it is effective: it finds both trends and seasonality and summarizes their dynamics into simultaneous non-linear latent space. (b) it is automatic: it automatically recognizes and models such structural patterns without any parameter tuning or prior information. (c) it is scalable: it incrementally and adaptively detects shifting points of patterns for a semi-infinite collection of tensor streams. Extensive experiments that we conducted on real datasets demonstrate that our algorithm can effectively and efficiently find meaningful patterns for generating future values, and outperforms the state-of-the-art algorithms for time series forecasting in terms of forecasting accuracy and computational time.","[{""name"":""Koki Kawabata"",""id"":""/profile/99659478166""},{""name"":""Yasuko Matsubara"",""id"":""/profile/81365594947""},{""name"":""Takato Honda"",""id"":""/profile/99659039699""},{""name"":""Yasushi Sakurai"",""id"":""/profile/81452606482""},{""name"":""Koki Kawabata"",""id"":""/profile/99659478166""},{""name"":""Yasuko Matsubara"",""id"":""/profile/81365594947""},{""name"":""Takato Honda"",""id"":""/profile/99659039699""},{""name"":""Yasushi Sakurai"",""id"":""/profile/81452606482""}]","[""2018. Recurrent Neural Networks for Multivariate Time Series with Missing Values. Scientific Reports 8, 1 (2018), 6085.Google ScholarCross Ref"",""Roel Bertens, Jilles Vreeken, and Arno Siebes. 2016. Keeping it short and simple: Summarising complex event sequences with multivariate patterns. In KDD. 735--744.Google Scholar"",""Yongjie Cai, Hanghang Tong, Wei Fan, Ping Ji, and Qing He. 2015. Facets: Fast Comprehensive Mining of Coevolving High-order Time Series. In KDD. 79--88.Google ScholarDigital Library"",""Deepayan Chakrabarti, Spiros Papadimitriou, Dharmendra S. Modha, and Christos Faloutsos. 2004. Fully automatic cross-associations. In KDD. 79--88.Google Scholar"",""James Durbin and Siem Jan Koopman. 2012. Time Series Analysis by State Space Methods 2 ed.). Oxford University Press.Google Scholar"",""Jayavardhana Gubbi, Rajkumar Buyya, Slaven Marusic, and Marimuthu Palaniswami. 2013. Internet of Things (IoT): A Vision, Architectural Elements, and Future Directions. Future Gener. Comput. Syst., Vol. 29, 7 (2013), 1645--1660.Google ScholarDigital Library"",""David Hallac, Sagar Vare, Stephen Boyd, and Jure Leskovec. 2017. Toeplitz Inverse Covariance-Based Clustering of Multivariate Time Series Data. In KDD. 215--223.Google Scholar"",""Geoffrey Hinton, Li Deng, Dong Yu, George E Dahl, Abdel rahman Mohamed, Navdeep Jaitly, Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Tara N Sainath, et al. 2012. Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. IEEE Signal Processing Magazine, Vol. 29, 6 (2012), 82--97.Google ScholarCross Ref"",""Bryan Hooi, Shenghua Liu, Asim Smailagic, and Christos Faloutsos. 2017. BeatLex: Summarizing and Forecasting Time Series with Patterns. In ECML PKDD. Springer, 3--19.Google Scholar"",""Emre Kiciman and Matthew Richardson. 2015. Towards Decision Support and Goal Achievement: Identifying Action-Outcome Relationships From Social Media. In KDD. 547--556.Google Scholar"",""Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Optimization. CoRR, Vol. abs/1412.6980 (2015).Google Scholar"",""Tamara G. Kolda and Brett W. Bader. 2009. Tensor Decompositions and Applications. SIAM Rev., Vol. 51, 3 (September 2009), 455--500.Google ScholarDigital Library"",""Jae-Gil Lee, Jiawei Han, and Kyu-Young Whang. 2007. Trajectory clustering: a partition-and-group framework. In SIGMOD. 593--604.Google Scholar"",""Lei Li, James McCann, Nancy S. Pollard, and Christos Faloutsos. 2009. DynaMMo: mining and summarization of coevolving sequences with missing values. In KDD. 507--516.Google Scholar"",""Yasuko Matsubara and Yasushi Sakurai. 2016. Regime Shifts in Streams: Real-time Forecasting of Co-evolving Time Sequences. In KDD. 1045--1054.Google Scholar"",""Yasuko Matsubara and Yasushi Sakurai. 2019. Dynamic Modeling and Forecasting of Time-Evolving Data Streams. In KDD. 458--468.Google Scholar"",""Yasuko Matsubara, Yasushi Sakurai, and Christos Faloutsos. 2014. AutoPlait: Automatic Mining of Co-evolving Time Sequences. In SIGMOD.Google Scholar"",""Yasuko Matsubara, Yasushi Sakurai, and Christos Faloutsos. 2016. Non-Linear Mining of Competing Local Activities. In WWW.Google Scholar"",""Yasuko Matsubara, Yasushi Sakurai, Christos Faloutsos, Tomoharu Iwata, and Masatoshi Yoshikawa. 2012. Fast mining and forecasting of complex time-stamped events. In KDD. 271--279.Google Scholar"",""Gianmarco De Francisci Morales, Albert Bifet, Latifur Khan, Joao Gama, and Wei Fan. 2016. IoT Big Data Stream Mining. In KDD, Tutorial. 2119--2120.Google Scholar"",""Jorge J. Moré. 1978. The Levenberg-Marquardt algorithm: Implementation and theory. In Numerical Analysis. 105--116.Google Scholar"",""Yao Qin, Dongjin Song, Haifeng Cheng, Wei Cheng, Guofei Jiang, and Garrison W. Cottrell. 2017. A Dual-stage Attention-based Recurrent Neural Network for Time Series Prediction. In IJCAI. AAAI Press, 2627--2633.Google Scholar"",""Jorma Rissanen. 1978. Modeling by shortest data description. Automatia, Vol. 14 (1978), 465--471.Google ScholarDigital Library"",""Mark Rogers, Lei Li, and Stuart J Russell. 2013. Multilinear Dynamical Systems for Tensor Time Series. In NIPS. 2634--2642.Google Scholar"",""Yasushi Sakurai, Yasuko Matsubara, and Christos Faloutsos. 2015. Mining and Forecasting of Big Time-series Data. In SIGMOD, Tutorial. 919--922.Google Scholar"",""Yasushi Sakurai, Yasuko Matsubara, and Christos Faloutsos. 2016. Mining Big Time-series Data on the Web. In WWW, Tutorial. 1029--1032.Google Scholar"",""Hyun Ah Song, Bryan Hooi, Marko Jereminov, Amritanshu Pandey, Lawrence T. Pileggi, and Christos Faloutsos. 2017a. PowerCast: Mining and Forecasting Power Grid Sequences. In ECML/PKDD.Google Scholar"",""Qingquan Song, Xiao Huang, Hancheng Ge, James Caverlee, and Xia Hu. 2017b. Multi-Aspect Streaming Tensor Completion. In KDD. 435--443.Google Scholar"",""Jimeng Sun, Dacheng Tao, and Christos Faloutsos. 2006. Beyond Streams and Graphs: Dynamic Tensor Analysis. In KDD. 374--383.Google Scholar"",""Tsubasa Takahashi, Bryan Hooi, and Christos Faloutsos. 2017. AutoCyclone: Automatic Mining of Cyclic Online Activities with Robust Tensor Factorization. In WWW. 213--221.Google Scholar"",""Nikolaj Tatti and Jilles Vreeken. 2012. The long and the short of it: summarising event sequences with serial episodes. In KDD. 462--470.Google Scholar"",""Peng Wang, Haixun Wang, and Wei Wang. 2011. Finding semantics in time series. In SIGMOD. 385--396.Google Scholar"",""Junchen Ye, Leilei Sun, Bowen Du, Yanjie Fu, Xinran Tong, and Hui Xiong. 2019. Co-Prediction of Multiple Transportation Demands Based on Deep Spatio-Temporal Neural Network. In SIGKDD. 305--313.Google Scholar"",""Shuo Zhou, Nguyen Xuan Vinh, James Bailey, Yunzhe Jia, and Ian Davidson. 2016. Accelerating Online CP Decompositions for Higher Order Tensors. In KDD. 1375--1384.Google Scholar""]"
https://doi.org/10.1145/3394486.3403261,DeepLine: AutoML Tool for Pipelines Generation using Deep Reinforcement Learning and Hierarchical Actions Filtering,"Automatic Machine Learning (AutoML) is an area of research aimed at automating Machine Learning (ML) activities that currently require the involvement of human experts. One of the most challenging tasks in this field is the automatic generation of end-to-end ML pipelines: combining multiple types of ML algorithms into a single architecture used for analysis of previously-unseen data. This task has two challenging aspects: the first is the need to explore a large search space of algorithms and pipeline architectures. The second challenge is the computational cost of training and evaluating multiple pipelines. In this study we present DeepLine, a reinforcement learning-based approach for automatic pipeline generation. Our proposed approach utilizes an efficient representation of the search space together with a novel method for operating in environments with large and dynamic action spaces. By leveraging past knowledge gained from previously-analyzed datasets, our approach only needs to generate and evaluate few dozens of pipelines to reach comparable or better performance than current state-of-the-art AutoML systems that evaluate hundreds and even thousands of pipelines in their optimization process. Evaluation on 56 classification datasets demonstrates the merits of our approach.","[{""name"":""Yuval Heffetz"",""id"":""/profile/99659574728""},{""name"":""Roman Vainshtein"",""id"":""/profile/99659317294""},{""name"":""Gilad Katz"",""id"":""/profile/81456620496""},{""name"":""Lior Rokach"",""id"":""/profile/81331503121""},{""name"":""Yuval Heffetz"",""id"":""/profile/99659574728""},{""name"":""Roman Vainshtein"",""id"":""/profile/99659317294""},{""name"":""Gilad Katz"",""id"":""/profile/81456620496""},{""name"":""Lior Rokach"",""id"":""/profile/81331503121""}]","[""Thomas Anthony, Zheng Tian, and David Barber. 2017. Thinking fast and slow with deep learning and tree search. In Advances in Neural Information Processing Systems. 5360--5370.Google Scholar"",""Irwan Bello, Barret Zoph, Vijay Vasudevan, and Quoc V Le. 2017. Neural optimizer search with reinforcement learning. In Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR.org, 459--468.Google ScholarDigital Library"",""Yash Chandak, Georgios Theocharous, James Kostas, Scott Jordan, and Philip S Thomas. 2019. Learning action representations for reinforcement learning. arXiv preprint arXiv:1902.00183 (2019).Google Scholar"",""Tianqi Chen and Carlos Guestrin. 2016. Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining. ACM, 785--794.Google ScholarDigital Library"",""Iddo Drori, Yamuna Krishnamurthy, Raoni Lourenco, Remi Rampin, Kyunghyun Cho, Claudio Silva, and Juliana Freire. 2019. Automatic Machine Learning by Pipeline Synthesis using Model-Based Reinforcement Learning and a Grammar. arXiv preprint arXiv:1905.10345 (2019).Google Scholar"",""Iddo Drori, Yamuna Krishnamurthy, Remi Rampin, Raoni de Paula Lourenco, Jorge Piazentin Ono, Kyunghyun Cho, Claudio Silva, and Juliana Freire. 2018. AlphaD3M: Machine learning pipeline synthesis. In AutoML Workshop at ICML .Google Scholar"",""Gabriel Dulac-Arnold, Richard Evans, Hado van Hasselt, Peter Sunehag, Timothy Lillicrap, Jonathan Hunt, Timothy Mann, Theophane Weber, Thomas Degris, and Ben Coppin. 2015. Deep reinforcement learning in large discrete action spaces. arXiv preprint arXiv:1512.07679 (2015).Google Scholar"",""Matthias Feurer, Aaron Klein, Katharina Eggensperger, Jost Springenberg, Manuel Blum, and Frank Hutter. 2015. Efficient and robust automated machine learning. In Advances in Neural Information Processing Systems. 2962--2970.Google Scholar"",""Pierre Geurts, Damien Ernst, and Louis Wehenkel. 2006. Extremely randomized trees. Machine learning, Vol. 63, 1 (2006), 3--42.Google Scholar"",""John A Hartigan and Manchek A Wong. 1979. Algorithm AS 136: A k-means clustering algorithm. Journal of the Royal Statistical Society. Series C (Applied Statistics), Vol. 28, 1 (1979), 100--108.Google ScholarDigital Library"",""Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In Proceedings of the 26th international conference on world wide web. International World Wide Web Conferences Steering Committee, 173--182.Google ScholarDigital Library"",""Ashley Hill, Antonin Raffin, Maximilian Ernestus, Adam Gleave, Anssi Kanervisto, Rene Traore, Prafulla Dhariwal, Christopher Hesse, Oleg Klimov, Alex Nichol, Matthias Plappert, Alec Radford, John Schulman, Szymon Sidor, and Yuhuai Wu. 2018. Stable Baselines. https://github.com/hill-a/stable-baselines .Google Scholar"",""Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural computation, Vol. 9, 8 (1997), 1735--1780.Google Scholar"",""Frank Hutter, Holger H Hoos, and Kevin Leyton-Brown. 2011. Sequential model-based optimization for general algorithm configuration. In International Conference on Learning and Intelligent Optimization. Springer, 507--523.Google ScholarDigital Library"",""Gilad Katz, Eui Chul Richard Shin, and Dawn Song. 2016. Explorekit: Automatic feature generation and selection. In 2016 IEEE 16th International Conference on Data Mining (ICDM). IEEE, 979--984.Google ScholarCross Ref"",""Andy Liaw, Matthew Wiener, et al. 2002. Classification and regression by randomForest. R news, Vol. 2, 3 (2002), 18--22.Google Scholar"",""Mitar Milutinovic, Atilim Günecs Baydin, Robert Zinkov, William Harvey, Dawn Song, Frank Wood, and Wade Shen. 2017. End-to-end training of differentiable pipelines across machine learning frameworks. https://openreview.net (2017).Google Scholar"",""Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. 2016. Asynchronous methods for deep reinforcement learning. In International conference on machine learning. 1928--1937.Google ScholarDigital Library"",""Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness, Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg Ostrovski, et al. 2015. Human-level control through deep reinforcement learning. Nature, Vol. 518, 7540 (2015), 529.Google Scholar"",""Randal S Olson and Jason H Moore. 2016. TPOT: A tree-based pipeline optimization tool for automating machine learning. In Workshop on Automatic Machine Learning. 66--74.Google Scholar"",""Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. 2011. Scikit-learn: Machine learning in Python. Journal of machine learning research, Vol. 12, Oct (2011), 2825--2830.Google ScholarDigital Library"",""Herilalaina Rakotoarison, Marc Schoenauer, and Michèle Sebag. 2019. Automated Machine Learning with Monte-Carlo Tree Search (Extended Version). arXiv preprint arXiv:1906.00170 (2019).Google Scholar"",""Tom Schaul, John Quan, Ioannis Antonoglou, and David Silver. 2015. Prioritized experience replay. arXiv preprint arXiv:1511.05952 (2015).Google Scholar"",""John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp Moritz. 2015. Trust region policy optimization. In International Conference on Machine Learning. 1889--1897.Google ScholarDigital Library"",""David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, et al. 2017. Mastering chess and shogi by self-play with a general reinforcement learning algorithm. arXiv preprint arXiv:1712.01815 (2017).Google Scholar"",""Chris Thornton, Frank Hutter, Holger H Hoos, and Kevin Leyton-Brown. 2013. Auto-WEKA: Combined selection and hyperparameter optimization of classification algorithms. In Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 847--855.Google ScholarDigital Library"",""Hado Van Hasselt, Arthur Guez, and David Silver. 2016. Deep reinforcement learning with double q-learning. In Thirtieth AAAI conference on artificial intelligence .Google ScholarDigital Library"",""Ziyu Wang, Tom Schaul, Matteo Hessel, Hado Van Hasselt, Marc Lanctot, and Nando De Freitas. 2015. Dueling network architectures for deep reinforcement learning. arXiv preprint arXiv:1511.06581 (2015).Google Scholar"",""Tom Zahavy, Matan Haroush, Nadav Merlis, Daniel J Mankowitz, and Shie Mannor. 2018. Learn what not to learn: Action elimination with deep reinforcement learning. In Advances in Neural Information Processing Systems. 3562--3573.Google Scholar""]"
https://doi.org/10.1145/3394486.3403262,On Sampling Top-K Recommendation Evaluation,"Recently, Rendle has warned that the use of sampling-based top-k metrics might not suffice. This throws a number of recent studies on deep learning-based recommendation algorithms, and classic non-deep-learning algorithms using such a metric, into jeopardy. In this work, we thoroughly investigate the relationship between the sampling and global top-K Hit-Ratio (HR, or Recall), originally proposed by Koren[2] and extensively used by others. By formulating the problem of aligning sampling top-k ([email protected]$) and global top-K ([email protected]) Hit-Ratios through a mapping function f, so that [email protected]~ [email protected](k), we demonstrate both theoretically and experimentally that the sampling top-k Hit-Ratio provides an accurate approximation of its global (exact) counterpart, and can consistently predict the correct winners (the same as indicate by their corresponding global Hit-Ratios).","[{""name"":""Dong Li"",""id"":""/profile/99659573944""},{""name"":""Ruoming Jin"",""id"":""/profile/81100054574""},{""name"":""Jing Gao"",""id"":""/profile/99659573110""},{""name"":""Zhi Liu"",""id"":""/profile/99659573431""},{""name"":""Dong Li"",""id"":""/profile/99659573944""},{""name"":""Ruoming Jin"",""id"":""/profile/81100054574""},{""name"":""Jing Gao"",""id"":""/profile/99659573110""},{""name"":""Zhi Liu"",""id"":""/profile/99659573431""}]","[""Immanuel Bayer, X. He, B. Kanagal, and S. Rendle. 2017. A Generic Coordinate Descent Framework for Learning from Implicit Feedback. In WWW'17.Google Scholar"",""Paolo Cremonesi, Yehuda Koren, and Roberto Turrin. 2010. Performance of Recommender Algorithms on Top-n Recommendation Tasks. In RecSys'10.Google Scholar"",""Maurizio Ferrari Dacrema, P. Cremonesi, and D. Jannach. 2019. Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches. In RecSys'19.Google Scholar"",""Mukund Deshpande and George Karypis. 2004. Item-Based Top-N Recommendation Algorithms. ACM Trans. Inf. Syst. (2004).Google Scholar"",""Travis Ebesu, Bin Shen, and Yi Fang. 2018. Collaborative Memory Network for Recommendation Systems. In SIGIR'18.Google Scholar"",""Ali Mamdouh Elkahky, Y. Song, and X. He. 2015. A Multi-View Deep Learning Approach for Cross Domain User Modeling in Recommendation Systems. In WWW'15.Google Scholar"",""Xiangnan He, L. Liao, H. Zhang, L. Nie, X. Hu, and T. Chua. 2017. Neural Collaborative Filtering. In WWW'17.Google Scholar"",""Binbin Hu, C. Shi, W. X. Zhao, and P. S. Yu. 2018. Leveraging Meta-Path Based Context for Top- N Recommendation with A Neural Co-Attention Model. In KDD'18.Google Scholar"",""Y. Hu, Y. Koren, and C. Volinsky. 2008. Collaborative filtering for implicit feedback datasets. In ICDM'08.Google Scholar"",""Yehuda Koren. 2008. Factorization Meets the Neighborhood: A Multifaceted Collaborative Filtering Model. In KDD'08.Google ScholarDigital Library"",""Walid Krichene, N. Mayoraz, S. Rendle, L. Zhang, X. Yi, L. Hong, Ed H. Chi, and J. R. Anderson. 2019. Efficient Training on Very Large Corpora via Gramian Estimation. In ICLR'2019.Google Scholar"",""Wentian Li, Pedro Miramontes, and Cocho Germinal. 2010. Fitting Ranked Linguistic Data with Two-Parameter Functions. (2010).Google Scholar"",""Dawen Liang, R. G. Krishnan, M. D. Hoffman, and T. Jebara. 2018. Variational Autoencoders for Collaborative Filtering. In WWW'18.Google Scholar"",""K. Deergha Rao. 2018. Signals and Systems .Springer International Publishing.Google Scholar"",""Steffen Rendle. 2019. Evaluation Metrics for Item Recommendation under Sampling. arxiv: 1912.02263Google Scholar"",""Steffen Rendle, Li Zhang, and Yehuda Koren. 2019. On the Difficulty of Evaluating Baselines: A Study on Recommender Systems. (2019).Google Scholar"",""Harald Steck. 2019. Embarrassingly Shallow Autoencoders for Sparse Data. WWW'19 (2019).Google Scholar"",""Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019 a. Neural Graph Collaborative Filtering. SIGIR'19 (2019).Google Scholar"",""Xiang Wang, D. Wang, C. Xu, X. He, Y. Cao, and T. Chua. 2019 b. Explainable Reasoning over Knowledge Graphs for Recommendation. In The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI2019.Google Scholar"",""Longqi Yang, Eugene Bagdasaryan, Joshua Gruenstein, Cheng-Kang Hsieh, and Deborah Estrin. 2018a. OpenRec: A Modular Framework for Extensible and Adaptable Recommendation Algorithms. In WSDM'18.Google ScholarDigital Library"",""Longqi Yang, Y. Cui, Y. Xuan, C. Wang, S. J. Belongie, and D. Estrin. 2018b. Unbiased Offline Recommender Evaluation for Missing-Not-at-Random Implicit Feedback. In RecSys'18.Google Scholar"",""Shuai Zhang, Lina Yao, Aixin Sun, and Yi Tay. 2019. Deep Learning Based Recommender System: A Survey and New Perspectives. ACM Comput. Surv. (2019).Google Scholar""]"
https://doi.org/10.1145/3394486.3403263,Algorithmic Decision Making with Conditional Fairness,"Nowadays fairness issues have raised great concerns in decision-making systems. Various fairness notions have been proposed to measure the degree to which an algorithm is unfair. In practice, there frequently exist a certain set of variables we term as fair variables, which are pre-decision covariates such as users' choices. The effects of fair variables are irrelevant in assessing the fairness of the decision support algorithm. We thus define conditional fairness as a more sound fairness metric by conditioning on the fairness variables. Given different prior knowledge of fair variables, we demonstrate that traditional fairness notations, such as demographic parity and equalized odds, are special cases of our conditional fairness notations. Moreover, we propose a Derivable Conditional Fairness Regularizer (DCFR), which can be integrated into any decision-making model, to track the trade-off between precision and fairness of algorithmic decision making. Specifically, an adversarial representation based conditional independence loss is proposed in our DCFR to measure the degree of unfairness. With extensive experiments on three real-world datasets, we demonstrate the advantages of our conditional fairness notation and DCFR.","[{""name"":""Renzhe Xu"",""id"":""/profile/99659453659""},{""name"":""Peng Cui"",""id"":""/profile/81413596063""},{""name"":""Kun Kuang"",""id"":""/profile/99659192894""},{""name"":""Bo Li"",""id"":""/profile/99659193449""},{""name"":""Linjun Zhou"",""id"":""/profile/99659574378""},{""name"":""Zheyan Shen"",""id"":""/profile/99659317832""},{""name"":""Wei Cui"",""id"":""/profile/99659573190""},{""name"":""Renzhe Xu"",""id"":""/profile/99659453659""},{""name"":""Peng Cui"",""id"":""/profile/81413596063""},{""name"":""Kun Kuang"",""id"":""/profile/99659192894""},{""name"":""Bo Li"",""id"":""/profile/99659193449""},{""name"":""Linjun Zhou"",""id"":""/profile/99659574378""},{""name"":""Zheyan Shen"",""id"":""/profile/99659317832""},{""name"":""Wei Cui"",""id"":""/profile/99659573190""}]","[""Tameem Adel, Isabel Valera, Zoubin Ghahramani, and Adrian Weller. 2019. One-network adversarial fairness. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 2412--2420.Google Scholar"",""Alekh Agarwal, Alina Beygelzimer, Miroslav Dudik, John Langford, and Hanna Wallach. 2018. A Reductions Approach to Fair Classification. In International Conference on Machine Learning. 60--69.Google Scholar"",""Alex Beutel, Jilin Chen, Zhe Zhao, and Ed H Chi. 2017. Data decisions and theoretical implications when adversarially learning fair representations. arXiv preprint arXiv:1707.00075 (2017).Google Scholar"",""Peter J Bickel, Eugene A Hammel, and J William O'Connell. 1975. Sex bias in graduate admissions: Data from Berkeley. Science, Vol. 187, 4175 (1975), 398--404.Google Scholar"",""Minnesota Population Center. 2019. Integrated public use microdata series: Version 7.2 [dataset]. Minneapolis, MN: IPUMS (2019).Google Scholar"",""Silvia Chiappa. 2019. Path-specific counterfactual fairness. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 7801--7808.Google Scholar"",""Sam Corbett-Davies, Emma Pierson, Avi Feller, Sharad Goel, and Aziz Huq. 2017. Algorithmic decision making and the cost of fairness. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 797--806.Google Scholar"",""JJ Daudin. 1980. Partial association measures and an application to qualitative regression. Biometrika, Vol. 67, 3 (1980), 581--590.Google Scholar"",""Dheeru Dua and Casey Graff. 2017. UCI Machine Learning Repository. http://archive.ics.uci.edu/mlGoogle Scholar"",""Sanghamitra Dutta, Praveen Venkatesh, Piotr Mardziel, Anupam Datta, and Pulkit Grover. 2020. An Information-Theoretic Quantification of Discrimination with Exempt Features.. In AAAI. 3825--3833.Google Scholar"",""Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. 2012. Fairness through awareness. In Proceedings of the 3rd innovations in theoretical computer science conference. 214--226.Google Scholar"",""Harrison Edwards and Amos Storkey. 2015. Censoring representations with an adversary. arXiv preprint arXiv:1511.05897 (2015).Google Scholar"",""Michael Feldman, Sorelle A Friedler, John Moeller, Carlos Scheidegger, and Suresh Venkatasubramanian. 2015. Certifying and removing disparate impact. In proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining. 259--268.Google Scholar"",""Kenji Fukumizu, Arthur Gretton, Xiaohai Sun, and Bernhard Schölkopf. 2008. Kernel measures of conditional dependence. In Advances in neural information processing systems. 489--496.Google Scholar"",""Moritz Hardt, Eric Price, and Nati Srebro. 2016. Equality of opportunity in supervised learning. In Advances in neural information processing systems. 3315--3323.Google Scholar"",""Tatsunori Hashimoto, Megha Srivastava, Hongseok Namkoong, and Percy Liang. 2018. Fairness Without Demographics in Repeated Loss Minimization. In International Conference on Machine Learning. 1929--1938.Google Scholar"",""Faisal Kamiran and Toon Calders. 2012. Data preprocessing techniques for classification without discrimination. Knowledge and Information Systems, Vol. 33, 1 (2012), 1--33.Google Scholar"",""Faisal Kamiran, Indr.e vZ liobait.e, and Toon Calders. 2013. Quantifying explainable discrimination and removing illegal discrimination in automated decision making. Knowledge and information systems, Vol. 35, 3 (2013), 613--644.Google Scholar"",""Niki Kilbertus, Mateo Rojas Carulla, Giambattista Parascandolo, Moritz Hardt, Dominik Janzing, and Bernhard Schölkopf. 2017. Avoiding discrimination through causal reasoning. In Advances in Neural Information Processing Systems. 656--666.Google Scholar"",""Jon Kleinberg, Sendhil Mullainathan, and Manish Raghavan. 2016. Inherent trade-offs in the fair determination of risk scores. arXiv preprint arXiv:1609.05807 (2016).Google Scholar"",""Matt J Kusner, Joshua Loftus, Chris Russell, and Ricardo Silva. 2017. Counterfactual fairness. In Advances in Neural Information Processing Systems. 4066--4076.Google Scholar"",""Jeff Larson, Surya Mattu, Lauren Kirchner, and Julia Angwin. 2016. How we analyzed the COMPAS recidivism algorithm. ProPublica (5 2016), Vol. 9 (2016).Google Scholar"",""David Madras, Elliot Creager, Toniann Pitassi, and Richard Zemel. 2018. Learning Adversarially Fair and Transferable Representations. In International Conference on Machine Learning. 3384--3393.Google Scholar"",""Amitabha Mukerjee, Rita Biswas, Kalyanmoy Deb, and Amrit P Mathur. 2002. Multi--objective evolutionary algorithms for the risk--return trade-off in bank loan management. International Transactions in operational research, Vol. 9, 5 (2002), 583--597.Google Scholar"",""Razieh Nabi and Ilya Shpitser. 2018. Fair inference on outcomes. In Thirty-Second AAAI Conference on Artificial Intelligence.Google Scholar"",""Judea Pearl. 2009. Causality .Cambridge university press.Google Scholar"",""Joseph D Ramsey. 2014. A scalable conditional independence test for nonlinear, non-gaussian data. arXiv preprint arXiv:1401.5031 (2014).Google Scholar"",""Lauren A Rivera. 2012. Hiring as cultural matching: The case of elite professional service firms. American sociological review, Vol. 77, 6 (2012), 999--1022.Google Scholar"",""Chris Russell, Matt J Kusner, Joshua Loftus, and Ricardo Silva. 2017. When worlds collide: integrating different counterfactual assumptions in fairness. In Advances in Neural Information Processing Systems. 6414--6423.Google Scholar"",""Dino Sejdinovic, Bharath Sriperumbudur, Arthur Gretton, and Kenji Fukumizu. 2013. Equivalence of distance-based and RKHS-based statistics in hypothesis testing. The Annals of Statistics (2013), 2263--2291.Google Scholar"",""Peter Spirtes, Clark N Glymour, Richard Scheines, and David Heckerman. 2000. Causation, prediction, and search .MIT press.Google Scholar"",""Eric V Strobl, Kun Zhang, and Shyam Visweswaran. 2019. Approximate kernel-based conditional independence tests for fast non-parametric causal discovery. Journal of Causal Inference, Vol. 7, 1 (2019).Google Scholar"",""Hao Wang, Berk Ustun, and Flavio Calmon. 2019. Repairing without Retraining: Avoiding Disparate Impact with Counterfactual Distributions. In International Conference on Machine Learning. 6618--6627.Google Scholar"",""Yongkai Wu, Lu Zhang, Xintao Wu, and Hanghang Tong. 2019. PC-Fairness: A Unified Framework for Measuring Causality-based Fairness. In Advances in Neural Information Processing Systems. 3399--3409.Google Scholar"",""Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rodriguez, and Krishna P Gummadi. 2017. Fairness beyond disparate treatment \u0026 disparate impact: Learning classification without disparate mistreatment. In Proceedings of the 26th international conference on world wide web. 1171--1180.Google Scholar"",""Rich Zemel, Yu Wu, Kevin Swersky, Toni Pitassi, and Cynthia Dwork. 2013. Learning fair representations. In International Conference on Machine Learning. 325--333.Google Scholar"",""Brian Hu Zhang, Blake Lemoine, and Margaret Mitchell. 2018. Mitigating unwanted biases with adversarial learning. In Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society. 335--340.Google Scholar"",""Kun Zhang, Jonas Peters, Dominik Janzing, and Bernhard Schölkopf. 2012. Kernel-based conditional independence test and application in causal discovery. arXiv preprint arXiv:1202.3775 (2012).Google Scholar"",""Han Zhao, Amanda Coston, Tameem Adel, and Geoffrey J. Gordon. 2020. Conditional Learning of Fair Representations. In International Conference on Learning Representations.Google Scholar""]"
https://doi.org/10.1145/3394486.3403264,Semi-supervised Collaborative Filtering by Text-enhanced Domain Adaptation,"Data sparsity is an inherent challenge in the recommender systems, where most of the data is collected from the implicit feedbacks of users. This causes two difficulties in designing effective algorithms: first, the majority of users only have a few interactions with the system and there is no enough data for learning; second, there are no negative samples in the implicit feedbacks and it is a common practice to perform negative sampling to generate negative samples. However, this leads to a consequence that many potential positive samples are mislabeled as negative ones and data sparsity would exacerbate the mislabeling problem.To solve these difficulties, we regard the problem of recommendation on sparse implicit feedbacks as a semi-supervised learning task, and explore domain adaption to solve it. We transfer the knowledge learned from dense data to sparse data and we focus on the most challenging case - there is no user or item overlap.In this extreme case, aligning embeddings of two datasets directly is rather sub-optimal since the two latent spaces encode very different information. As such, we adopt domain-invariant textual features as the anchor points to align the latent spaces. To align the embeddings, we extract the textual features for each user and item and feed them into a domain classifier with the embeddings of users and items. The embeddings are trained to puzzle the classifier and textual features are fixed as anchor points. By domain adaptation, the distribution pattern in the source domain is transferred to the target domain. As the target part can be supervised by domain adaptation, we abandon negative sampling in target dataset to avoid label noise.We adopt three pairs of real-world datasets to validate the effectiveness of our transfer strategy. Results show that our models outperform existing models significantly.","[{""name"":""Wenhui Yu"",""id"":""/profile/99659217376""},{""name"":""Xiao Lin"",""id"":""/profile/99659370614""},{""name"":""Junfeng Ge"",""id"":""/profile/99659462640""},{""name"":""Wenwu Ou"",""id"":""/profile/99659154653""},{""name"":""Zheng Qin"",""id"":""/profile/81310499840""},{""name"":""Wenhui Yu"",""id"":""/profile/99659217376""},{""name"":""Xiao Lin"",""id"":""/profile/99659370614""},{""name"":""Junfeng Ge"",""id"":""/profile/99659462640""},{""name"":""Wenwu Ou"",""id"":""/profile/99659154653""},{""name"":""Zheng Qin"",""id"":""/profile/81310499840""}]","[""Zhangjie Cao, Mingsheng Long, Jianmin Wang, and Michael I. Jordan. 2018. Partial Transfer Learning With Selective Adversarial Networks. In CVPR. 2724--2732.Google Scholar"",""Chong Chen, Min Zhang, Yiqun Liu, and Shaoping Ma. 2018. Neural Attentional Rating Regression with Review-level Explanations. In WWW. 1583--1592.Google Scholar"",""Xu Chen, Yongfeng Zhang, Qingyao Ai, Hongteng Xu, Junchi Yan, and Zheng Qin. 2017. Personalized Key Frame Recommendation. In SIGIR. 315--324.Google Scholar"",""Yaroslav Ganin and Victor Lempitsky. 2015. Unsupervised Domain Adaptation by Back propagation. In ICML. 1180--1189.Google Scholar"",""Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, François Laviolette, Mario Marchand, and Victor Lempitsky. 2016. Domain-Adversarial Training of Neural Networks. The Journal of Machine Learning Research(2016), 2096--2030.Google Scholar"",""Zeno Gantner, Lucas Drumond, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2011. Bayesian personalized ranking for non-uniformly sampled items. In KDDCup.Google Scholar"",""David Goldberg. 1992. Using collaborative filtering to weave an information tapestry. Communications of the Acm(1992), 61--70.Google Scholar"",""Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural Collaborative Filtering. In WWW. 173--182.Google Scholar"",""Guangneng Hu, Yu Zhang, and Qiang Yang. 2018. CoNet: Collaborative Cross Networks for Cross-Domain Recommendation. In CIKM. 667--676.Google Scholar"",""Guangneng Hu, Yu Zhang, and Qiang Yang. 2019. Transfer Meets Hybrid: A Synthetic Approach for Cross-Domain Collaborative Filtering with Text. In WWW. 2822--2829.Google Scholar"",""Heishiro Kanagawa, Hayato Kobayashi, Nobuyuki Shimizu, Yukihiro Tagami, and Taiji Suzuki. 2018. Cross-domain Recommendation via Deep Domain Adaptation. CoRR(2018).Google Scholar"",""Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Optimization. In ICLR.Google Scholar"",""Yehuda Koren. 2009. The bellkor solution to the netflix grand prize. Netflix prize documentation(2009), 1--10.Google Scholar"",""Bin Li, Qiang Yang, and Xiangyang Xue. 2009. Can Movies and Books Collaborate?: Cross-domain Collaborative Filtering for Sparsity Reduction. In IJCAI. 2052--2057.Google Scholar"",""Mingsheng Long, Yue Cao, Jianmin Wang, and Michael I. Jordan. 2015. Learning Transferable Features with Deep Adaptation Networks. In ICML. 97--105.Google Scholar"",""Zhongqi Lu, Weike Pan, Evan Wei Xiang, Qiang Yang, Lili Zhao, and Erheng Zhong. 2013. Selective Transfer Learning for Cross Domain Recommendation. In SDM. 641--649.Google Scholar"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Distributed Representations of Words and Phrases and Their Compositionality. In NIPS. 3111--3119.Google Scholar"",""Weike Pan and Li Chen. 2013. GBPR: group preference based Bayesian personalized ranking for one-class collaborative filtering. In IJCAI. 2691--2697.Google Scholar"",""Weike Pan, Evan Wei Xiang, Nathan Nan Liu, and Qiang Yang. 2010. Transfer Learning in Collaborative Filtering for Sparsity Reduction. In AAAI.Google Scholar"",""S. Rendle. 2010. Factorization Machines. In ICDM. 995--1000.Google Scholar"",""Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian personalized ranking from implicit feedback. In UAI. 452--461.Google ScholarDigital Library"",""Badrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. 2001. Item-based Collaborative Filtering Recommendation Algorithms. In WWW. 285--295.Google Scholar"",""Cheng Wang, Mathias Niepert, and Hui Li. 2019. RecSys-DAN: Discriminative Adversarial Networks for Cross-Domain Recommender Systems. CoRR(2019).Google Scholar"",""Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019. Neural Graph Collaborative Filtering. In SIGIR.Google Scholar"",""Wenhui Yu and Zheng Qin. 2019. Spectrum-enhanced Pairwise Learning to Rank. In WWW. 2247--2257.Google Scholar"",""Wenhui Yu and Zheng Qin. 2020. Graph Convolutional Network for Recommendation with Low-pass Collaborative Filters. In ICML.Google Scholar"",""Wenhui Yu and Zheng Qin. 2020. Sampler Design for Implicit Feedback Data by Noisy-label Robust Learning. In SIGIR.Google Scholar"",""Wenhui Yu, Huidi Zhang, Xiangnan He, Xu Chen, Li Xiong, and Zheng Qin. 2018. Aesthetic-based Clothing Recommendation. In WWW. 649--658.Google Scholar"",""Feng Yuan, Lina Yao, and Boualem Benatallah. 2019. DARec: Deep Domain Adaptation for Cross-Domain Recommendation via Transferring Rating Patterns. In IJCAI. 4227--4233.Google Scholar"",""Lei Zheng, Vahid Noroozi, and Philip S. Yu. 2017. Joint Deep Modeling of Users and Items Using Reviews for Recommendation. In WSDM. 425--434.Google Scholar""]"
https://doi.org/10.1145/3394486.3403265,Rich Information is Affordable: A Systematic Performance Analysis of Second-order Optimization Using K-FAC,"Rich information matrices from first and second-order derivatives have many potential applications in both theoretical and practical problems in deep learning. However, computing these information matrices is extremely expensive and this enormous cost is currently limiting its application to important problems regarding generalization, hyperparameter tuning, and optimization of deep neural networks. One of the most challenging use cases of information matrices is their use as a preconditioner for the optimizers, since the information matrices need to be updated every step. In this work, we conduct a step-by-step performance analysis when computing the Fisher information matrix during training of ResNet-50 on ImageNet, and show that the overhead can be reduced to the same amount as the cost of performing a single SGD step. We also show that the resulting Fisher preconditioned optimizer can converge in 1/3 the number of epochs compared to SGD, while achieving the same Top-1 validation accuracy. This is the first work to achieve such accuracy with K-FAC while reducing the training time to match that of SGD.","[{""name"":""Yuichiro Ueno"",""id"":""/profile/99659450807""},{""name"":""Kazuki Osawa"",""id"":""/profile/99659451049""},{""name"":""Yohei Tsuji"",""id"":""/profile/99659451115""},{""name"":""Akira Naruse"",""id"":""/profile/99659321971""},{""name"":""Rio Yokota"",""id"":""/profile/81447599968""},{""name"":""Yuichiro Ueno"",""id"":""/profile/99659450807""},{""name"":""Kazuki Osawa"",""id"":""/profile/99659451049""},{""name"":""Yohei Tsuji"",""id"":""/profile/99659451115""},{""name"":""Akira Naruse"",""id"":""/profile/99659321971""},{""name"":""Rio Yokota"",""id"":""/profile/81447599968""}]","[""Takuya Akiba, Shuji Suzuki, and Keisuke Fukuda. 2017. Extremely Large Minibatch SGD: Training ResNet-50 on ImageNet in 15 Minutes. arXiv:1711.04325 [cs] (Nov. 2017). http://arxiv.org/abs/1711.04325Google Scholar"",""Shun-ichi Amari. 1998. Natural Gradient Works Efficiently in Learning. Neural Computation, Vol. 10, 2 (Feb. 1998), 251--276. https://doi.org/10.1162/089976698300017746Google ScholarDigital Library"",""Aleksandar Botev, Hippolyt Ritter, and David Barber. 2017. Practical Gauss-Newton optimisation for deep learning. In Proceedings of the 34th International Conference on Machine Learning - Volume 70 (ICML'17). JMLR.org, Sydney, NSW, Australia, 557--565.Google Scholar"",""Felix Dangel, Frederik Kunstner, and Philipp Hennig. 2019. BackPACK: Packing more into backprop. arXiv:1912.10985 [cs, stat] (Dec. 2019). http://arxiv.org/abs/1912.10985Google Scholar"",""Priya Goyal, Piotr Dollár, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He. 2017. Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour. arXiv:1706.02677 [cs] (June 2017). http://arxiv.org/abs/1706.02677Google Scholar"",""Roger Grosse and James Martens. 2016. A Kronecker-factored approximate Fisher matrix for convolution layers. arXiv:1602.01407 [cs, stat] (May 2016). http://arxiv.org/abs/1602.01407Google Scholar"",""K. He, X. Zhang, S. Ren, and J. Sun. 2016. Deep Residual Learning for Image Recognition. In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 770--778. https://doi.org/10.1109/CVPR.2016.90Google Scholar"",""Tong He, Zhi Zhang, Hang Zhang, Zhongyue Zhang, Junyuan Xie, and Mu Li. 2018. Bag of Tricks for Image Classification with Convolutional Neural Networks. arXiv:1812.01187 [cs] (Dec. 2018). http://arxiv.org/abs/1812.01187Google Scholar"",""Tsuyoshi Ichimura, Kohei Fujita, Takuma Yamaguchi, Akira Naruse, Jack C. Wells, Thomas C. Schulthess, Tjerk P. Straatsma, Christopher J. Zimmer, Maxime Martinasso, Kengo Nakajima, Muneo Hori, and Lalith Maddegedara. 2018. A fast scalable implicit solver for nonlinear time-evolution earthquake city problem on low-ordered unstructured finite elements with artificial intelligence and transprecision computing. In Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis (SC '18). IEEE Press, Dallas, Texas, 1--11.Google ScholarDigital Library"",""Xianyan Jia, Shutao Song, Wei He, Yangzihao Wang, Haidong Rong, Feihu Zhou, Liqiang Xie, Zhenyu Guo, Yuanzhou Yang, Liwei Yu, Tiegang Chen, Guangxiao Hu, Shaohuai Shi, and Xiaowen Chu. 2018. Highly Scalable Deep Learning Training System with Mixed-Precision: Training ImageNet in Four Minutes. arXiv:1807.11205 [cs, stat] (July 2018). http://arxiv.org/abs/1807.11205Google Scholar"",""Wonkyung Jung, Daejin Jung, and Byeongho Kim, Sunjung Lee, Wonjong Rhee, and Jung Ho Ahn. 2018. Restructuring Batch Normalization to Accelerate CNN Training. arXiv:1807.01702 [cs] (July 2018). http://arxiv.org/abs/1807.01702Google Scholar"",""James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, and Raia Hadsell. 2017. Overcoming catastrophic forgetting in neural networks. arXiv:1612.00796 [cs, stat] (Jan. 2017). http://arxiv.org/abs/1612.00796Google Scholar"",""Frederik Kunstner, Lukas Balles, and Philipp Hennig. 2019. Limitations of the Empirical Fisher Approximation for Natural Gradient Descent. arXiv:1905.12558 [cs, stat] (Dec. 2019). http://arxiv.org/abs/1905.12558Google Scholar"",""James Martens and Roger Grosse. 2015. Optimizing Neural Networks with Kronecker-factored Approximate Curvature. arXiv:1503.05671 [cs, stat] (March 2015). http://arxiv.org/abs/1503.05671Google Scholar"",""Sam McCandlish, Jared Kaplan, Dario Amodei, and OpenAI Dota Team. 2018. An Empirical Model of Large-Batch Training. arXiv:1812.06162 [cs, stat] (Dec. 2018). http://arxiv.org/abs/1812.06162Google Scholar"",""Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen, David Garcia, Boris Ginsburg, Michael Houston, Oleksii Kuchaiev, Ganesh Venkatesh, and Hao Wu. 2018. Mixed Precision Training. arXiv:1710.03740 [cs, stat] (Feb. 2018). http://arxiv.org/abs/1710.03740Google Scholar"",""Hiroaki Mikami, Hisahiro Suganuma, Pongsakorn U-chupala, Yoshiki Tanaka, and Yuichi Kageyama. 2018. ImageNet/ResNet-50 Training in 224 Seconds. (Nov. 2018). https://arxiv.org/abs/1811.05233Google Scholar"",""Kazuki Osawa, Yohei Tsuji, Yuichiro Ueno, Akira Naruse, Chuan-Sheng Foo, and Rio Yokota. 2020. Scalable and Practical Natural Gradient for Large-Scale Deep Learning. arXiv:2002.06015 [cs, stat] (Feb. 2020). http://arxiv.org/abs/2002.06015Google Scholar"",""Kazuki Osawa, Yohei Tsuji, Yuichiro Ueno, Akira Naruse, Rio Yokota, and Satoshi Matsuoka. 2019. Large-Scale Distributed Second-Order Optimization Using Kronecker-Factored Approximate Curvature for Deep Convolutional Neural Networks. In 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 12351--12359. https://doi.org/10.1109/CVPR.2019.01264Google Scholar"",""Pitch Patarasuk and Xin Yuan. 2009. Bandwidth Optimal All-reduce Algorithms for Clusters of Workstations. J. Parallel and Distrib. Comput., Vol. 69, 2 (Feb. 2009), 117--124. https://doi.org/10.1016/j.jpdc.2008.09.002Google ScholarDigital Library"",""Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. 2015. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision, Vol. 115, 3 (Dec. 2015), 211--252. https://doi.org/10.1007/s11263-015-0816-yGoogle ScholarDigital Library"",""Valentin Thomas, Fabian Pedregosa, Bart van Merriënboer, Pierre-Antoine Mangazol, Yoshua Bengio, and Nicolas Le Roux. 2019. Information matrices and generalization. arXiv:1906.07774 [cs, stat] (June 2019). http://arxiv.org/abs/1906.07774Google Scholar"",""Yohei Tsuji, Kazuki Osawa, Yuichiro Ueno, Akira Naruse, Rio Yokota, and Satoshi Matsuoka. 2019. Performance Optimizations and Analysis of Distributed Deep Learning with Approximated Second-Order Optimization Method. In Proceedings of the 48th International Conference on Parallel Processing: Workshops (ICPP 2019). Association for Computing Machinery, Kyoto, Japan, 1--8. https://doi.org/10.1145/3339186.3339202Google ScholarDigital Library"",""Yuichiro Ueno and Rio Yokota. 2019. Exhaustive Study of Hierarchical AllReduce Patterns for Large Messages Between GPUs. In 2019 19th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID). 430--439. https://doi.org/10.1109/CCGRID.2019.00057Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention Is All You Need. arXiv:1706.03762 [cs] (June 2017). http://arxiv.org/abs/1706.03762Google Scholar"",""Chaoqi Wang, Roger Grosse, Sanja Fidler, and Guodong Zhang. 2019. EigenDamage: Structured Pruning in the Kronecker-Factored Eigenbasis. arXiv:1905.05934 [cs, stat] (May 2019). http://arxiv.org/abs/1905.05934Google Scholar"",""Masafumi Yamazaki, Akihiko Kasagi, Akihiro Tabuchi, Takumi Honda, Masahiro Miwa, Naoto Fukumoto, Tsuguchika Tabaru, Atsushi Ike, and Kohta Nakashima. 2019. Yet Another Accelerated SGD: ResNet-50 Training on ImageNet in 74.7 seconds. arXiv:1903.12650 [cs, stat] (March 2019). http://arxiv.org/abs/1903.12650Google Scholar"",""Chris Ying, Sameer Kumar, Dehao Chen, Tao Wang, and Youlong Cheng. 2018. Image Classification at Supercomputer Scale. arXiv:1811.06992 [cs, stat] (Nov. 2018). http://arxiv.org/abs/1811.06992Google Scholar"",""Yang You, Zhao Zhang, Cho-Jui Hsieh, James Demmel, and Kurt Keutzer. 2018. ImageNet Training in Minutes. In Proceedings of the 47th International Conference on Parallel Processing (ICPP 2018). ACM, New York, NY, USA, 1:1--1:10. https://doi.org/10.1145/3225058.3225069Google ScholarDigital Library"",""Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, and David Lopez-Paz. 2018. mixup: Beyond Empirical Risk Minimization. arXiv:1710.09412 [cs, stat] (April 2018). http://arxiv.org/abs/1710.09412Google Scholar""]"
https://doi.org/10.1145/3394486.3403266,Voronoi Graph Traversal in High Dimensions with Applications to Topological Data Analysis and Piecewise Linear Interpolation,"Voronoi diagrams and their dual, the Delaunay complex, are two fundamental geometric concepts that lie at the foundation of many machine learning algorithms and play a role in particular in classical piecewise linear interpolation and regression methods. More recently, they are also crucial for the construction of a common class of simplicial complexes such as Alpha and Delaunay-\vC ech complexes in topological data analysis. We propose a randomized approximation approach that mitigates the prohibitive cost of exact computation of Voronoi diagrams in high dimensions for machine learning applications. In experiments with data in up to 50 dimensions, we show that this allows us to significantly extend the use of Voronoi-based simplicial complexes in Topological Data Analysis (TDA) to higher dimensions. We confirm prior TDA results on image patches that previously had to rely on sub-sampled data with increased resolution and demonstrate the scalability of our approach by performing a TDA analysis on synthetic data as well as on filters of a ResNet neural network architecture. Secondly, we propose an application of our approach to piecewise linear interpolation of high dimensional data that avoids explicit complete computation of an associated Delaunay triangulation.","[{""name"":""Vladislav Polianskii"",""id"":""/profile/99659574200""},{""name"":""Florian T. Pokorny"",""id"":""/profile/87259044357""},{""name"":""Vladislav Polianskii"",""id"":""/profile/99659574200""},{""name"":""Florian T. Pokorny"",""id"":""/profile/87259044357""}]","[""Sunil Arya, Theocharis Malamatos, and David M Mount. 2002. Space-efficient approximate Voronoi diagrams. In Proceedings of the thiry-fourth annual ACM symposium on Theory of computing. 721--730.Google ScholarDigital Library"",""Sunil Arya, David M Mount, Nathan S Netanyahu, Ruth Silverman, and Angela Y Wu. 1998. An optimal algorithm for approximate nearest neighbor searching fixed dimensions. Journal of the ACM (JACM), Vol. 45, 6 (1998), 891--923.Google ScholarDigital Library"",""Franz Aurenhammer, Rolf Klein, and Der-Tsai Lee. 2013. Voronoi diagrams and Delaunay triangulations .World Scientific Publishing Company.Google Scholar"",""C Bradford Barber, David P Dobkin, and Hannu Huhdanpaa. 1996. The quickhull algorithm for convex hulls. ACM Transactions on Mathematical Software (TOMS), Vol. 22, 4 (1996), 469--483.Google ScholarDigital Library"",""Ulrich Bauer and Herbert Edelsbrunner. 2017. The Morse theory of vC ech and Delaunay complexes. Trans. Amer. Math. Soc., Vol. 369, 5 (2017), 3741--3762.Google ScholarCross Ref"",""Ulrich Bauer, Michael Kerber, Jan Reininghaus, and Hubert Wagner. 2017. Phat--persistent homology algorithms toolbox. Journal of symbolic computation, Vol. 78 (2017), 76--90.Google ScholarDigital Library"",""Prosenjit Bose and Luc Devroye. 2007. On the stabbing number of a random Delaunay triangulation. Computational Geometry, Vol. 36, 2 (2007), 89--105.Google ScholarDigital Library"",""Gunnar Carlsson, Tigran Ishkhanov, Vin De Silva, and Afra Zomorodian. 2008. On the local behavior of spaces of natural images. International journal of computer vision, Vol. 76, 1 (2008), 1--12.Google Scholar"",""ZJ Cendes, D Shenton, and H Shahnasser. 1983. Magnetic field computation using Delaunay triangulation and complementary finite element methods. IEEE Transactions on Magnetics, Vol. 19, 6 (1983), 2551--2554.Google ScholarCross Ref"",""Sanjoy Dasgupta and Anupam Gupta. 1999. An elementary proof of the Johnson-Lindenstrauss lemma. International Computer Science Institute, Technical Report, Vol. 22, 1 (1999), 1--5.Google Scholar"",""Vin De Silva and Gunnar E Carlsson. 2004. Topological estimation using witness complexes. SPBG, Vol. 4 (2004), 157--166.Google ScholarDigital Library"",""Olivier Devillers and Ross Hemsley. 2016. The worst visibility walk in a random Delaunay triangulation is O(√n). (2016).Google Scholar"",""Olivier Devillers, Sylvain Pion, and Monique Teillaud. 2001. Walking in a triangulation. In Proceedings of the seventeenth annual symposium on Computational geometry. 106--114.Google ScholarDigital Library"",""Rex A Dwyer. 1993. The expected number of k-faces of a Voronoi diagram. Computers \u0026 Mathematics with Applications, Vol. 26, 5 (1993), 13--19.Google ScholarCross Ref"",""Herbert Edelsbrunner. 1990. An acyclicity theorem for cell complexes in d dimension. Combinatorica, Vol. 10, 3 (1990), 251--260.Google ScholarCross Ref"",""Herbert Edelsbrunner and John Harer. 2010. Computational topology: an introduction .American Mathematical Soc.Google Scholar"",""Brittany Terese Fasy, Jisu Kim, Fabrizio Lecci, and Clément Maria. 2014. Introduction to the R package TDA. arXiv preprint arXiv:1411.1830 (2014).Google Scholar"",""Rickard Brüel Gabrielsson and Gunnar Carlsson. 2018. Exposition and interpretation of the topology of neural networks. arXiv preprint arXiv:1810.03234 (2018).Google Scholar"",""David Gillman. 1998. A Chernoff bound for random walks on expander graphs. SIAM J. Comput., Vol. 27, 4 (1998), 1203--1220.Google ScholarDigital Library"",""Francc ois Godi. 2020. Bottleneck distance. In GUDHI User and Reference Manual 3.1.1 ed.). GUDHI Editorial Board. https://gudhi.inria.fr/doc/3.1.1/group__bottleneck__distance.htmlGoogle Scholar"",""Gaël Guennebaud, Benoît Jacob, et al. 2010. Eigen v3. http://eigen.tuxfamily.org.Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition. 770--778.Google ScholarCross Ref"",""Shlomo Hoory, Nathan Linial, and Avi Wigderson. 2006. Expander graphs and their applications. Bull. Amer. Math. Soc., Vol. 43, 4 (2006), 439--561.Google ScholarCross Ref"",""Alex Krizhevsky, Geoffrey Hinton, et al. 2009. Learning multiple layers of features from tiny images. (2009).Google Scholar"",""Ann B Lee, Kim S Pedersen, and David Mumford. 2003. The nonlinear statistics of high-contrast patches in natural images. International Journal of Computer Vision, Vol. 54, 1--3 (2003), 83--103.Google ScholarDigital Library"",""László Lovász et al. [n.d.]. Random walks on graphs: A survey. ( [n.,d.]).Google Scholar"",""Atsuyuki Okabe, Barry Boots, Kokichi Sugihara, and Sung Nok Chiu. 2009. Spatial tessellations: concepts and applications of Voronoi diagrams. Vol. 501. John Wiley \u0026 Sons.Google Scholar"",""Vladislav Polianskii and Florian T Pokorny. 2019. Voronoi Boundary Classification: A High-Dimensional Geometric Approach via Weighted Monte Carlo Integration. In International Conference on Machine Learning. 5162--5170.Google Scholar"",""Donald R Sheehy. 2013. Linear-size approximations to the Vietoris--Rips filtration. Discrete \u0026 Computational Geometry, Vol. 49, 4 (2013), 778--796.Google ScholarDigital Library"",""Donald R Sheehy. 2014. The persistent homology of distance functions under random projection. In Proceedings of the thirtieth annual symposium on Computational geometry. 328--334.Google ScholarDigital Library"",""Jonathan Richard Shewchuk. 2004. Stabbing delaunay tetrahedralizations. Discrete \u0026 Computational Geometry, Vol. 32, 3 (2004), 339--343.Google ScholarDigital Library"",""Gurjeet Singh, Facundo Mémoli, and Gunnar E Carlsson. 2007. Topological methods for the analysis of high dimensional data sets and 3d object recognition.. In SPBG. 91--100.Google Scholar"",""Andrew Tausz, Mikael Vejdemo-Johansson, and Henry Adams. 2014. JavaPlex: A research software package for persistent (co)homology. In Proceedings of ICMS 2014 (Lecture Notes in Computer Science 8592), Han Hong and Chee Yap (Eds.). 129--136. Software available at http://appliedtopology.github.io/javaplex/.Google Scholar"",""J Hans Van Hateren and Arjen van der Schaaf. 1998. Independent component filters of natural images compared with simple cells in primary visual cortex. Proceedings of the Royal Society of London. Series B: Biological Sciences, Vol. 265, 1394 (1998), 359--366.Google Scholar"",""Shayne Waldron. 1998. The error in linear interpolation at the vertices of a simplex. SIAM J. Numer. Anal., Vol. 35, 3 (1998), 1191--1200.Google ScholarDigital Library"",""Emo Welzl. 1991. Smallest enclosing disks (balls and ellipsoids). In New results and new trends in computer science. Springer, 359--370.Google Scholar""]"
https://doi.org/10.1145/3394486.3403267,MCRapper: Monte-Carlo Rademacher Averages for Poset Families and Approximate Pattern Mining,"We present MCRapper, an algorithm for efficient computation of Monte-Carlo Empirical Rademacher Averages (MCERA) for families of functions exhibiting poset (e.g., lattice) structure, such as those that arise in many pattern mining tasks. The MCERA allows us to compute upper bounds to the maximum deviation of sample means from their expectations, thus it can be used to find both statistically-significant functions (i.e., patterns) when the available data is seen as a sample from an unknown distribution, and approximations of collections of high-expectation functions (e.g., frequent patterns) when the available data is a small sample from a large dataset. This feature is a strong improvement over previously proposed solutions that could only achieve one of the two. MCRapper uses upper bounds to the discrepancy of the functions to efficiently explore and prune the search space, a technique borrowed from pattern mining itself. To show the practical use of MCRapper, we employ it to develop an algorithm TFP-R for the task of True Frequent Pattern (TFP) mining. TFP-R gives guarantees on the probability of including any false positives (precision) and exhibits higher statistical power (recall) than existing methods offering the same guarantees. We evaluate MCRapper and TFP-R and show that they outperform the state-of-the-art for their respective tasks.","[{""name"":""Leonardo Pellegrina"",""id"":""/profile/99659287647""},{""name"":""Cyrus Cousins"",""id"":""/profile/99659267145""},{""name"":""Fabio Vandin"",""id"":""/profile/81436602702""},{""name"":""Matteo Riondato"",""id"":""/profile/81467665989""},{""name"":""Leonardo Pellegrina"",""id"":""/profile/99659287647""},{""name"":""Cyrus Cousins"",""id"":""/profile/99659267145""},{""name"":""Fabio Vandin"",""id"":""/profile/81436602702""},{""name"":""Matteo Riondato"",""id"":""/profile/81467665989""}]","[""R. Agrawal and R. Srikant. Mining sequential patterns. ICDE'95, 1995.Google ScholarDigital Library"",""R. Agrawal, T. Imielinski, and A. Swami. Mining association rules between sets of items in large databases. SIGMOD Rec., 22: 207--216, 1993.Google ScholarDigital Library"",""N. K. Ahmed, J. Neville, R. A. Rossi, and Duffield N. Efficient graphlet counting for large networks. ICDM'15, 2015.Google ScholarDigital Library"",""P. L. Bartlett and S. Mendelson. Rademacher and Gaussian complexities: Risk bounds and structural results. J. Mach. Learn. Res., 3: 463--482, 2002.Google ScholarDigital Library"",""S. D. Bay and M. J. Pazzani. Detecting group differences: Mining contrast sets. Data Min. Knowl. Disc., 5 (3): 213--246, 2001.Google ScholarDigital Library"",""M. Boley, C. Lucchese, D. Paurat, and T. Gartner. Direct local pattern sampling by efficient two-step random procedures. KDD'11, 2011.Google ScholarDigital Library"",""V. T. Chakaravarthy, V. Pandit, and Y. Sabharwal. Analysis of sampling techniques for association rule mining. ICDT'09, 2009Google ScholarDigital Library"",""L. De Stefani and E. Upfal. A Rademacher Complexity Based Method for Controlling Power andConfidence Level in Adaptive Statistical Analysis. DSAA'19, 2019Google Scholar"",""V. Dzyuba, M. van Leeuwen, and L. De Raedt. Flexible constrained sampling with guarantees for pattern mining. Data Min. Knowl. Disc., 31 (5): 1266--1293, 2017.Google ScholarDigital Library"",""P. Fournier-Viger, J. Chun-Wei Lin, T. Truong-Chi, and R. Nkambou. A survey of high utility itemset mining. In High-Utility Pattern Mining. Springer, 2019.Google ScholarCross Ref"",""W. Hamalainen and G. I. Webb. A tutorial on statistically sound pattern discovery. Data Min. Knowl. Disc., 33(2): 325--377,2019.Google ScholarDigital Library"",""A. Kirsch, M. Mitzenmacher, A. Pietracaprina, G. Pucci, E. Upfal, and F. Vandin. An efficient rigorous approach for identifying statistically significant frequent itemsets. J. ACM, 59 (3): 1--22, 2012.Google ScholarDigital Library"",""W. Klösgen. Problems for knowledge discovery in databases and their treatment in the Statistics Interpreter Explora. Intl. J. of Intell. Sys., 7: 649--673, 1992.Google ScholarCross Ref"",""V. Koltchinskii and D. Panchenko. Rademacher processes and bounding the risk of function learning. In High dimensional probability II, 443--457. Springer, 2000.Google Scholar"",""L. Pellegrina, C. Cousins, F. Vandin, M. Riondato. titlefirstpart titlesecondpart. Extended version. arxivlink .Google Scholar"",""L. Pellegrina and F. Vandin. Efficient mining of the most significant patterns with permutation testing. Data Min. Knowl. Disc., 34(4), 1201--1234, 2020.Google ScholarCross Ref"",""L. Pellegrina, M. Riondato, and F. Vandin. SPuManTE: Significant pattern mining with unconditional testing. KDD'19, 2019.Google ScholarDigital Library"",""M. Riondato and E. Upfal. Efficient discovery of association rules and frequent itemsets through sampling with tight performance guarantees. ACM Trans. Knowl. Disc. from Data, 8 (4): 20, 2014.Google Scholar"",""M. Riondato and E. Upfal. Mining frequent itemsets through progressive sampling with Rademacher averages. KDD'15, 2015.Google ScholarDigital Library"",""M. Riondato and F. Vandin. Finding the true frequent itemsets. SDM'14, 2014.Google ScholarCross Ref"",""M. Riondato and F. Vandin. MiSoSouP: Mining interesting subgroups with sampling and pseudodimension. KDD'18, 2018.Google ScholarDigital Library"",""D. Santoro, A. Tonon, F. Vandin. Mining Sequential Patterns with VC-Dimension and Rademacher Complexity. Algorithms, 13(5), 123, 2020.Google ScholarCross Ref"",""S. Servan-Schreiber, M. Riondato, and E. Zgraggen. ProSecCo: Progressive sequence mining with convergence guarantees. ICDM'18, 2018.Google ScholarCross Ref"",""S. Shalev-Shwartz and S. Ben-David. Understanding Machine Learning: From Theory to Algorithms. Cambridge University Press, 2014.Google ScholarDigital Library"",""M. Sugiyama, F. Llinares-López, N. Kasenburg, and K. M. Borgwardt. Significant subgraph mining with multiple testing correction. SDM'15, 2015.Google ScholarCross Ref"",""A. Terada, M. Okada-Hatakeyama, K. Tsuda, and J. Sese. Statistical significance of combinatorial regulations. Proc. Nat. Acad. of Sci., 110 (32): 12996--13001, 2013.Google ScholarCross Ref"",""H. Toivonen. Sampling large databases for association rules. VLDB'96, 1996.Google ScholarDigital Library"",""A. Tonon and F. Vandin. Permutation strategies for mining significant sequential patterns. ICDM'19, 2019.Google ScholarCross Ref"",""Vladimir N. Vapnik. Statistical learning theory. Wiley, 1998.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403268,REA: Robust Cross-lingual Entity Alignment Between Knowledge Graphs,"Cross-lingual entity alignment aims at associating semantically similar entities in knowledge graphs with different languages. It has been an essential research problem for knowledge integration and knowledge graph connection, and been studied with supervised or semi-supervised machine learning methods with the assumption of clean labeled data. However, labels from human annotations often include errors, which can largely affect the alignment results. We thus aim to formulate and explore the robust entity alignment problem, which is non-trivial, due to the deficiency of noisy labels. Our proposed method named REA (Robust Entity Alignment) consists of two components: noise detection and noise-aware entity alignment. The noise detection is designed by following the adversarial training principle. The noise-aware entity alignment is devised by leveraging graph neural network based knowledge graph encoder as the core. In order to mutually boost the performance of the two components, we propose a unified reinforced training strategy to combine them. To evaluate our REA method, we conduct extensive experiments on several real-world datasets. The experimental results demonstrate the effectiveness of our proposed method and also show that our model consistently outperforms the state-of-the-art methods with significant improvement on alignment accuracy in the noise-involved scenario.","[{""name"":""Shichao Pei"",""id"":""/profile/99659369031""},{""name"":""Lu Yu"",""id"":""/profile/99659259809""},{""name"":""Guoxian Yu"",""id"":""/profile/81477641184""},{""name"":""Xiangliang Zhang"",""id"":""/profile/81436599318""},{""name"":""Shichao Pei"",""id"":""/profile/99659369031""},{""name"":""Lu Yu"",""id"":""/profile/99659259809""},{""name"":""Guoxian Yu"",""id"":""/profile/81477641184""},{""name"":""Xiangliang Zhang"",""id"":""/profile/81436599318""}]","[""Leman Akoglu and Christos Faloutsos. 2013. Anomaly, event, and fraud detection in large network datasets. In WSDM. 773--774.Google Scholar"",""Leman Akoglu, Mary McGlohon, and Christos Faloutsos. 2010. Oddball: Spotting anomalies in weighted graphs. In PAKDD. 410--421.Google Scholar"",""Leman Akoglu, Hanghang Tong, and Danai Koutra. 2015. Graph based anomaly detection and description: a survey. DAMI, Vol. 29, 3 (2015), 626--688.Google Scholar"",""Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko. 2013. Translating embeddings for modeling multi-relational data. In NeurIPS. 2787--2795.Google Scholar"",""Yixin Cao, Zhiyuan Liu, Chengjiang Li, Juanzi Li, and Tat-Seng Chua. 2019. Multi-Channel Graph Neural Network for Entity Alignment. In ACL. 1452--1461.Google Scholar"",""Muhao Chen, Yingtao Tian, Kai-Wei Chang, Steven Skiena, and Carlo Zaniolo. 2018. Co-training Embeddings of Knowledge Graphs and Entity Descriptions for Cross-lingual Entity Alignment. In IJCAI. 3998--4004.Google Scholar"",""Muhao Chen, Yingtao Tian, Mohan Yang, and Carlo Zaniolo. 2016. Multilingual knowledge graph embeddings for cross-lingual knowledge alignment. arXiv preprint arXiv:1611.03954 (2016).Google Scholar"",""Quanyu Dai, Qiang Li, Jian Tang, and Dan Wang. 2018. Adversarial network embedding. In AAAI. 2167--2174.Google Scholar"",""Kaize Ding, Jundong Li, and Huan Liu. 2019. Interactive anomaly detection on attributed networks. In WSDM. 357--365.Google Scholar"",""Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial nets. In NeurIPS. 2672--2680.Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In NIPS. 1024--1034.Google Scholar"",""Binbin Hu, Yuan Fang, and Chuan Shi. 2019. Adversarial Learning on Heterogeneous Information Networks. In KDD. 120--129.Google Scholar"",""Wei Hu, Jianfeng Chen, and Yuzhong Qu. 2011. A self-training approach for resolving object coreference on the semantic web. In Web Conf. 87--96.Google ScholarDigital Library"",""Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).Google Scholar"",""Simon Lacoste-Julien, Konstantina Palla, Alex Davies, Gjergji Kasneci, Thore Graepel, and Zoubin Ghahramani. 2013. Sigma: Simple greedy matching for aligning large knowledge bases. In KDD. 572--580.Google Scholar"",""Kuang-Huei Lee, Xiaodong He, Lei Zhang, and Linjun Yang. 2018. Cleannet: Transfer learning for scalable image classifier training with label noise. In CVPR. 5447--5456.Google Scholar"",""Jens Lehmann, Robert Isele, Max Jakob, Anja Jentzsch, Dimitris Kontokostas, Pablo N Mendes, Sebastian Hellmann, Mohamed Morsey, Patrick Van Kleef, Sören Auer, et al. 2015. DBpedia--a large-scale, multilingual knowledge base extracted from Wikipedia. Semantic Web, Vol. 6, 2 (2015), 167--195.Google ScholarCross Ref"",""Chengjiang Li, Yixin Cao, Lei Hou, Jiaxin Shi, Juanzi Li, and Tat-Seng Chua. 2019 a. Semi-supervised Entity Alignment via Joint Knowledge Embedding Model and Cross-graph Model. In EMNLP-IJCNLP. 2723--2732.Google Scholar"",""Junnan Li, Yongkang Wong, Qi Zhao, and Mohan S Kankanhalli. 2019 c. Learning to learn from noisy labeled data. In CVPR. 5051--5059.Google Scholar"",""Yuening Li, Xiao Huang, Jundong Li, Mengnan Du, and Na Zou. 2019 b. SpecAE: Spectral AutoEncoder for Anomaly Detection in Attributed Networks. In CIKM. 2233--2236.Google Scholar"",""Yan Li and Jieping Ye. 2018. Learning adversarial networks for semi-supervised text classification via policy gradient. In KDD. 1715--1723.Google Scholar"",""Andrew L Maas, Awni Y Hannun, and Andrew Y Ng. 2013. Rectifier nonlinearities improve neural network acoustic models. In Proc. icml, Vol. 30. 3.Google Scholar"",""Farzaneh Mahdisoltani, Joanna Biega, and Fabian M Suchanek. 2013. Yago3: A knowledge base from multilingual wikipedias. In CIDR. 1--11.Google Scholar"",""Xin Mao, Wenting Wang, Huimin Xu, Man Lan, and Yuanbin Wu. 2020. MRAEA: An Efficient and Robust Entity Alignment Approach for Cross-lingual Knowledge Graph. In WSDM. 420--428.Google ScholarDigital Library"",""Thanh Nguyen, Viviane Moreira, Huong Nguyen, Hoa Nguyen, and Juliana Freire. 2011. Multilingual schema matching for Wikipedia infoboxes. Proc. VLDB Endowment, Vol. 5, 2 (2011), 133--144.Google ScholarDigital Library"",""Shichao Pei, Lu Yu, Robert Hoehndorf, and Xiangliang Zhang. 2019 b. Semi-supervised entity alignment via knowledge graph embedding with awareness of degree difference. In Web Conf. 3130--3136.Google ScholarDigital Library"",""Shichao Pei, Lu Yu, and Xiangliang Zhang. 2019 a. Improving cross-lingual entity alignment via optimal transport. In IJCAI. 3231--3237.Google Scholar"",""Yingchun Shan, Chenyang Bu, Xiaojian Liu, Shengwei Ji, and Lei Li. 2018. Confidence-aware negative sampling method for noisy knowledge graph embedding. In ICBK. 33--40.Google Scholar"",""Xiaofei Shi and Yanghua Xiao. 2019. Modeling Multi-mapping Relations for Precise Cross-lingual Entity Alignment. In EMNLP-IJCNLP. 813--822.Google Scholar"",""Fabian M Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. Yago: a core of semantic knowledge. In Web Conf. 697--706.Google ScholarDigital Library"",""Zequn Sun, Wei Hu, and Chengkai Li. 2017. Cross-lingual entity alignment via joint attribute-preserving embedding. In ISWC. 628--644.Google Scholar"",""Zequn Sun, Wei Hu, Qingheng Zhang, and Yuzhong Qu. 2018. Bootstrapping Entity Alignment with Knowledge Graph Embedding.. In IJCAI. 4396--4402.Google Scholar"",""Richard S Sutton, David A McAllester, Satinder P Singh, and Yishay Mansour. 2000. Policy gradient methods for reinforcement learning with function approximation. In NeurIPS. 1057--1063.Google Scholar"",""Bayu Distiawan Trisedya, Jianzhong Qi, and Rui Zhang. 2019. Entity alignment between knowledge graphs using attribute embeddings. In AAAI. 297--304.Google Scholar"",""Denny Vrandevc ić and Markus Krötzsch. 2014. Wikidata: a free collaborative knowledgebase. Comm. of the ACM, Vol. 57, 10 (2014), 78--85.Google ScholarDigital Library"",""Hongwei Wang, Jia Wang, Jialin Wang, Miao Zhao, Weinan Zhang, Fuzheng Zhang, Xing Xie, and Minyi Guo. 2018b. Graphgan: Graph representation learning with generative adversarial nets. In AAAI. 2508--2515.Google Scholar"",""Jun Wang, Lantao Yu, Weinan Zhang, Yu Gong, Yinghui Xu, Benyou Wang, Peng Zhang, and Dell Zhang. 2017. Irgan: A minimax game for unifying generative and discriminative information retrieval models. In SIGIR. 515--524.Google ScholarDigital Library"",""Zhichun Wang, Qingsong Lv, Xiaohan Lan, and Yu Zhang. 2018a. Cross-lingual Knowledge Graph Alignment via Graph Convolutional Networks.. In EMNLP. 349--357.Google Scholar"",""Ronald J Williams. 1992. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine Learning, Vol. 8, 3--4 (1992), 229--256.Google ScholarDigital Library"",""Yuting Wu, Xiao Liu, Yansong Feng, Zheng Wang, Rui Yan, and Dongyan Zhao. 2019 b. Relation-aware entity alignment for heterogeneous knowledge graphs. In IJCAI. 5278--5284.Google Scholar"",""Yuting Wu, Xiao Liu, Yansong Feng, Zheng Wang, and Dongyan Zhao. 2019 a. Jointly Learning Entity and Relation Representations for Entity Alignment. In EMNLP-IJCNLP. 240--249.Google Scholar"",""Ruobing Xie, Zhiyuan Liu, Fen Lin, and Leyu Lin. [n.d.]. Does william shakespeare really write hamlet? knowledge representation learning with confidence. In AAAI. 4954--4961.Google Scholar"",""Kun Xu, Liwei Wang, Mo Yu, Yansong Feng, Yan Song, Zhiguo Wang, and Dong Yu. 2019. Cross-lingual Knowledge Graph Alignment via Graph Matching Neural Network. In ACL. 3156--3161.Google Scholar"",""Yang Yang, Yizhou Sun, Jie Tang, Bo Ma, and Juanzi Li. 2015. Entity matching across heterogeneous sources. In KDD. 1395--1404.Google Scholar"",""Rui Ye, Xin Li, Yujie Fang, Hongyu Zang, and Mingzhong Wang. 2019. A vectorized relational graph convolutional network for multi-relational network alignment. In IJCAI. 4135--4141.Google Scholar"",""Minji Yoon, Bryan Hooi, Kijung Shin, and Christos Faloutsos. 2019. Fast and accurate anomaly detection in dynamic graphs with a two-pronged approach. In KDD. 647--657.Google Scholar"",""Wenchao Yu, Wei Cheng, Charu C Aggarwal, Kai Zhang, Haifeng Chen, and Wei Wang. 2018a. Netwalk: A flexible deep embedding approach for anomaly detection in dynamic networks. In KDD. 2672--2681.Google ScholarDigital Library"",""Wenchao Yu, Cheng Zheng, Wei Cheng, Charu C Aggarwal, Dongjin Song, Bo Zong, Haifeng Chen, and Wei Wang. 2018b. Learning deep network representations with adversarially regularized autoencoders. In KDD. 2663--2671.Google Scholar"",""Qingheng Zhang, Zequn Sun, Wei Hu, Muhao Chen, Lingbing Guo, and Yuzhong Qu. 2019. Multi-view knowledge graph embedding for entity alignment. In IJCAI. 5429--5435.Google Scholar"",""Hao Zhu, Ruobing Xie, Zhiyuan Liu, and Maosong Sun. 2017. Iterative entity alignment via joint knowledge embeddings. In IJCAI. 4258--4264.Google Scholar"",""Qiannan Zhu, Xiaofei Zhou, Jia Wu, Jianlong Tan, and Li Guo. 2019. Neighborhood-aware attentional representation for multilingual knowledge graphs. In IJCAI. 10--16.Google Scholar""]"
https://doi.org/10.1145/3394486.3403269,Stable Learning via Differentiated Variable Decorrelation,"Recently, as the applications of artificial intelligence gradually seeping into some risk-sensitive areas such as justice, healthcare and autonomous driving, an upsurge of research interest on model stability and robustness has arisen in the field of machine learning. Rather than purely fitting the observed training data, stable learning tries to learn a model with uniformly good performance under non-stationary and agnostic testing data. The key challenge of stable learning in practice is that we do not have any knowledge about the true model and test data distribution as a priori. Under such condition, we cannot expect a faithful estimation of model parameters and its stability over wild changing environments. Previous methods resort to a reweighting scheme to remove the correlations between all the variables through a set of new sample weights. However, we argue that such aggressive decorrelation between all the variables may cause the over-reduced sample size, which leads to the variance inflation and possible underperformance. In this paper, we incorporate the unlabled data from multiple environments into the variable decorrelation framework and propose a Differentiated Variable Decorrelation (DVD) algorithm based on the clustering of variables. Specifically, the variables are clustered according to the stability of their correlations and the variable decorrelation module learns a set of sample weights to remove the correlations merely between the variables of different clusters. Empirical studies on both synthetic and real world datasets clearly demonstrate the efficacy of our DVD algorithm on improving the model parameter estimation and the prediction stability over changing distributions.","[{""name"":""Zheyan Shen"",""id"":""/profile/99659317832""},{""name"":""Peng Cui"",""id"":""/profile/81413596063""},{""name"":""Jiashuo Liu"",""id"":""/profile/99659573654""},{""name"":""Tong Zhang"",""id"":""/profile/99659287232""},{""name"":""Bo Li"",""id"":""/profile/99659193449""},{""name"":""Zhitang Chen"",""id"":""/profile/81501673641""},{""name"":""Zheyan Shen"",""id"":""/profile/99659317832""},{""name"":""Peng Cui"",""id"":""/profile/81413596063""},{""name"":""Jiashuo Liu"",""id"":""/profile/99659573654""},{""name"":""Tong Zhang"",""id"":""/profile/99659287232""},{""name"":""Bo Li"",""id"":""/profile/99659193449""},{""name"":""Zhitang Chen"",""id"":""/profile/81501673641""}]","[""Aylin Alin. 2010. Multicollinearity. Wiley Interdisciplinary Reviews Computational Statistics, Vol. 2, 3 (2010), 370--374.Google ScholarCross Ref"",""Susan Athey, Guido W Imbens, and Stefan Wager. 2018. Approximate residual balancing: debiased inference of average treatment effects in high dimensions. Journal of the Royal Statistical Society: Series B (Statistical Methodology), Vol. 80, 4 (2018), 597--623.Google ScholarCross Ref"",""Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan. 2010. A theory of learning from different domains. Machine learning, Vol. 79, 1--2 (2010), 151--175.Google Scholar"",""Richard A Berk, Hoda Heidari, Shahin Jabbari, Michael Kearns, and Aaron Roth. 2018. Fairness in Criminal Justice Risk Assessments: The State of the Art. Sociological Methods \u0026 Research (2018), 004912411878253.Google Scholar"",""Steffen Bickel, Michael Brückner, and Tobias Scheffer. 2009. Discriminative learning under covariate shift. Journal of Machine Learning Research, Vol. 10, Sep (2009), 2137--2155.Google ScholarDigital Library"",""Peter Bühlmann. 2018. Invariance, causality and robustness. arXiv preprint arXiv:1812.08233 (2018).Google Scholar"",""Sibao Chen, Chris HQ Ding, Bin Luo, and Ying Xie. 2013. Uncorrelated Lasso.. In AAAI .Google Scholar"",""Miroslav Dud'ik, Steven J Phillips, and Robert E Schapire. 2006. Correcting sample selection bias in maximum entropy density estimation. In Advances in neural information processing systems. 323--330.Google Scholar"",""Donald E Farrar and Robert R Glauber. 1967. Multicollinearity in regression analysis: the problem revisited. The Review of Economic and Statistics (1967), 92--107.Google Scholar"",""Basura Fernando, Amaury Habrard, Marc Sebban, and Tinne Tuytelaars. 2013. Unsupervised visual domain adaptation using subspace alignment. In Proceedings of the IEEE international conference on computer vision. 2960--2967.Google ScholarDigital Library"",""Yaroslav Ganin and Victor Lempitsky. 2014. Unsupervised domain adaptation by backpropagation. arXiv preprint arXiv:1409.7495 (2014).Google Scholar"",""Jiayuan Huang, Arthur Gretton, Karsten Borgwardt, Bernhard Schölkopf, and Alex J Smola. 2007. Correcting sample selection bias by unlabeled data. In Advances in neural information processing systems. 601--608.Google Scholar"",""Brody Huval, T Wang, Sameep Tandon, Jeff Kiske, Will Song, Joel Pazhayampallil, Mykhaylo Andriluka, Pranav Rajpurkar, Toki Migimatsu, Royce Chengyue, et al. 2015. An Empirical Evaluation of Deep Learning on Highway Driving. arXiv: Robotics (2015).Google Scholar"",""Kun Kuang, Peng Cui, Susan Athey, Ruoxuan Xiong, and Bo Li. 2018. Stable prediction across unknown environments. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1617--1626.Google ScholarDigital Library"",""Kun Kuang, Peng Cui, Bo Li, Meng Jiang, and Shiqiang Yang. 2017. Estimating treatment effect in the wild via differentiated confounder balancing. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 265--274.Google ScholarDigital Library"",""Kun Kuang, Ruoxuan Xiong, Peng Cui, Susan Athey, and Bo Li. 2020. Stable Prediction with Model Misspecification and Agnostic Distribution Shift. arXiv preprint arXiv:2001.11713 (2020).Google Scholar"",""Matja Kukar. 2003. Transductive reliability estimation for medical diagnosis. Artificial Intelligence in Medicine, Vol. 29, 1 (2003), 81--106.Google ScholarDigital Library"",""Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M Hospedales. 2017. Deeper, broader and artier domain generalization. In Proceedings of the IEEE international conference on computer vision. 5542--5550.Google ScholarCross Ref"",""Mingsheng Long, Yue Cao, Jianmin Wang, and Michael I Jordan. 2015. Learning transferable features with deep adaptation networks. arXiv preprint arXiv:1502.02791 (2015).Google Scholar"",""James MacQueen et al. 1967. Some methods for classification and analysis of multivariate observations. In Proceedings of the fifth Berkeley symposium on mathematical statistics and probability, Vol. 1. Oakland, CA, USA, 281--297.Google Scholar"",""Luca Martino, V'ictor Elvira, and Francisco Louzada. 2017. Effective sample size for importance sampling based on discrepancy measures. Signal Processing, Vol. 131 (2017), 386--401.Google ScholarDigital Library"",""Krikamol Muandet, David Balduzzi, and Bernhard Schölkopf. 2013. Domain generalization via invariant feature representation. In International Conference on Machine Learning. 10--18.Google Scholar"",""Sinno Jialin Pan, Qiang Yang, et al. 2010. A survey on transfer learning. IEEE Transactions on knowledge and data engineering, Vol. 22, 10 (2010), 1345--1359.Google ScholarDigital Library"",""Jonas Peters, Peter Bühlmann, and Nicolai Meinshausen. 2016. Causal inference by using invariant prediction: identification and confidence intervals. Journal of the Royal Statistical Society: Series B (Statistical Methodology), Vol. 78, 5 (2016), 947--1012.Google ScholarCross Ref"",""Mateo Rojas-Carulla, Bernhard Schölkopf, Richard Turner, and Jonas Peters. 2018. Invariant models for causal transfer learning. The Journal of Machine Learning Research, Vol. 19, 1 (2018), 1309--1342.Google ScholarDigital Library"",""Cynthia Rudin and Berk Ustun. 2018. Optimized Scoring Systems: Toward Trust in Machine Learning for Healthcare and Criminal Justice. Interfaces, Vol. 48, 5 (2018), 449--466.Google ScholarDigital Library"",""Zheyan Shen, Peng Cui, Tong Zhang, and Kun Kuang. 2019. Stable Learning via Sample Reweighting. arXiv preprint arXiv:1911.12580 (2019).Google Scholar"",""Hidetoshi Shimodaira. 2000. Improving predictive inference under covariate shift by weighting the log-likelihood function. Journal of statistical planning and inference, Vol. 90, 2 (2000), 227--244.Google ScholarCross Ref"",""Masaaki Takada, Taiji Suzuki, and Hironori Fujisawa. 2018. Independently Interpretable Lasso: A New Regularizer for Sparse Regression with Uncorrelated Variables. In International Conference on Artificial Intelligence and Statistics. 454--463.Google Scholar"",""Robert Tibshirani. 1996. Regression Shrinkage and Selection via the Lasso. Journal of the Royal Statistical Society, Vol. 58, 1 (1996), 267--288.Google Scholar"",""Hui Zou and Trevor Hastie. 2005. Regularization and variable selection via the elastic net. Journal of the Royal Statistical Society: Series B (Statistical Methodology), Vol. 67, 2 (2005), 301--320.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403270,Learning Stable Graphs from Multiple Environments with Selection Bias,"Nowadays graph has become a general and powerful representation to describe the rich relationships among different kinds of entities via the underlying patterns encoded in its structure. The knowledge (more generally) accumulated in graph is expected to be able to cross populations from one to another and the past to future. However the data collection process of graph generation is full of known or unknown sample selection biases, leading to spurious correlations among entities, especially in the non-stationary and heterogeneous environments. In this paper, we target the problem of learning stable graphs from multiple environments with selection bias. We purpose a Stable Graph Learning (SGL) framework to learn a graph that can capture general relational patterns which are irrelevant with the selection bias in an unsupervised way. Extensive experimental results from both simulation and real data demonstrate that our method could significantly benefit the generalization capacity of graph structure.","[{""name"":""Yue He"",""id"":""/profile/99659575206""},{""name"":""Peng Cui"",""id"":""/profile/81413596063""},{""name"":""Jianxin Ma"",""id"":""/profile/99659286785""},{""name"":""Hao Zou"",""id"":""/profile/99659572915""},{""name"":""Xiaowei Wang"",""id"":""/profile/99659455689""},{""name"":""Hongxia Yang"",""id"":""/profile/99659259298""},{""name"":""Philip S. Yu"",""id"":""/profile/81556177556""},{""name"":""Yue He"",""id"":""/profile/99659575206""},{""name"":""Peng Cui"",""id"":""/profile/81413596063""},{""name"":""Jianxin Ma"",""id"":""/profile/99659286785""},{""name"":""Hao Zou"",""id"":""/profile/99659572915""},{""name"":""Xiaowei Wang"",""id"":""/profile/99659455689""},{""name"":""Hongxia Yang"",""id"":""/profile/99659259298""},{""name"":""Philip S. Yu"",""id"":""/profile/81556177556""}]","[""Lada A Adamic and Eytan Adar. 2003. Friends and neighbors on the web. Social networks, Vol. 25, 3 (2003), 211--230.Google Scholar"",""James Atwood and Don Towsley. [n.d.]. Diffusion-Convolutional Neural Networks. ( [n.,d.]).Google Scholar"",""Aleksandar Bojchevski, Oleksandr Shchur, Daniel Zügner, and Stephan Günnemann. 2018. Netgan: Generating graphs via random walks. arXiv preprint arXiv:1803.00816 (2018).Google Scholar"",""Peter Bühlmann, Jonas Peters, Jan Ernest, et al. 2014. CAM: Causal additive models, high-dimensional order search and penalized regression. The Annals of Statistics, Vol. 42, 6 (2014), 2526--2556.Google ScholarCross Ref"",""Jie Chen, Tengfei Ma, and Cao Xiao. 2018a. Fastgcn: fast learning with graph convolutional networks via importance sampling. arXiv preprint arXiv:1801.10247 (2018).Google Scholar"",""Jianfei Chen, Jun Zhu, and Le Song. 2018b. Stochastic Training of Graph Convolutional Networks with Variance Reduction. In International Conference on Machine Learning. 942--950.Google Scholar"",""Nicola De Cao and Thomas Kipf. [n.d.]. MolGAN: An implicit generative model for small molecular graphs. ( [n.,d.]).Google Scholar"",""Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolutional neural networks on graphs with fast localized spectral filtering. In Advances in neural information processing systems. 3844--3852.Google Scholar"",""Zhengxiao Du, Xiaowei Wang, Hongxia Yang, Jingren Zhou, and Jie Tang. 2019. Sequential Scenario-Specific Meta Learner for Online Recommendation. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 2895--2904.Google ScholarDigital Library"",""Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial nets. In Advances in neural information processing systems. 2672--2680.Google Scholar"",""Abhishek Gupta, Coline Devin, YuXuan Liu, Pieter Abbeel, and Sergey Levine. 2017. Learning invariant feature spaces to transfer skills with reinforcement learning. arXiv preprint arXiv:1703.02949 (2017).Google Scholar"",""Kilol Gupta, Mukund Yelahanka Raghuprasad, and Pankhuri Kumar. [n.d.]. A Hybrid Variational Autoencoder for Collaborative Filtering. ( [n.,d.]).Google Scholar"",""Hinton and G. E. [n.d.]. Reducing the Dimensionality of Data with Neural Networks. Science, Vol. 313, 5786 ( [n.,d.]), 504--507.Google Scholar"",""Bo Jiang, Ziyan Zhang, Doudou Lin, Jin Tang, and Bin Luo. 2019. Semi-supervised learning with graph learning-convolutional networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 11313--11320.Google ScholarCross Ref"",""Diederik P Kingma and Max Welling. 2013. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 (2013).Google Scholar"",""Thomas N Kipf and Max Welling. 2016. Semi-Supervised Classification with Graph Convolutional Networks. (2016).Google Scholar"",""Kun Kuang, Peng Cui, Susan Athey, Ruoxuan Xiong, and Bo Li. 2018. Stable prediction across unknown environments. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1617--1626.Google ScholarDigital Library"",""Kun Kuang, Peng Cui, Bo Li, Meng Jiang, and Shiqiang Yang. 2017. Estimating treatment effect in the wild via differentiated confounder balancing. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 265--274.Google ScholarDigital Library"",""Ankit Kumar, Ozan Irsoy, Peter Ondruska, Mohit Iyyer, James Bradbury, Ishaan Gulrajani, Victor Zhong, Romain Paulus, and Richard Socher. 2016. Ask me anything: Dynamic memory networks for natural language processing. In International conference on machine learning. 1378--1387.Google ScholarDigital Library"",""Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. 1998. Gradient-based learning applied to document recognition. Proc. IEEE, Vol. 86, 11 (1998), 2278--2324.Google ScholarCross Ref"",""Jianxin Ma, Peng Cui, Kun Kuang, Xin Wang, and Wenwu Zhu. 2019. Disentangled graph convolutional networks. In International Conference on Machine Learning. 4212--4221.Google Scholar"",""Tengfei Ma, Jie Chen, and Cao Xiao. 2018. Constrained generation of semantically valid graphs via regularizing variational autoencoders. In Advances in Neural Information Processing Systems. 7113--7124.Google Scholar"",""Yutaka Matsuo and Mitsuru Ishizuka. 2004. Keyword extraction from a single document using word co-occurrence statistical information. International Journal on Artificial Intelligence Tools, Vol. 13, 01 (2004), 157--169.Google ScholarCross Ref"",""Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. 2017. Automatic differentiation in PyTorch. In NIPS-W .Google Scholar"",""Zheyan Shen, Peng Cui, Kun Kuang, Bo Li, and Peixuan Chen. 2018. Causally regularized learning with agnostic data selection bias. In Proceedings of the 26th ACM international conference on Multimedia. 411--419.Google ScholarDigital Library"",""Zheyan Shen, Peng Cui, Tong Zhang, and Kun Kuang. 2019. Stable Learning via Sample Reweighting.Google Scholar"",""Shohei Shimizu, Patrik O Hoyer, Aapo Hyvärinen, and Antti Kerminen. 2006. A linear non-Gaussian acyclic model for causal discovery. Journal of Machine Learning Research 7, Oct (2006), 2003?2030.Google Scholar"",""Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2019. Graph Attention Networks. In International Conference on Learning Representations.Google Scholar"",""Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, and Philip S Yu. 2019. Heterogeneous graph attention network. In The World Wide Web Conference. 2022?2032.Google ScholarDigital Library"",""Jiaxuan You, Rex Ying, Xiang Ren, William L Hamilton, and Jure Leskovec. 2018. Graphrnn: Generating realistic graphs with deep auto-regressive models. arXiv preprint arXiv:1802.08773(2018).Google Scholar"",""Kun Zhang and Aapo Hyvarinen. 2012. On the identifiability of the post-nonlinear causal model. arXiv preprint arXiv:1205.2599(2012).Google Scholar"",""Xun Zheng, Bryon Aragam, Pradeep K Ravikumar, and Eric P Xing. 2018. DAGs with NO TEARS: Continuous optimization for structure learning. In Advances in Neural Information Processing Systems. 9472?9483.Google Scholar"",""Dingyuan Zhu, Peng Cui, Daixin Wang, and Wenwu Zhu. 2018. Deep variational network embedding in wasserstein space. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 2827-2836.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403271,Fast RobustSTL: Efficient and Robust Seasonal-Trend Decomposition for Time Series with Complex Patterns,"Many real-world time series data exhibit complex patterns with trend, seasonality, outlier and noise. Robustly and accurately decomposing these components would greatly facilitate time series tasks including anomaly detection, forecasting and classification. RobustSTL is an effective seasonal-trend decomposition for time series data with complicated patterns. However, it cannot handle multiple seasonal components properly. Also it suffers from its high computational complexity, which limits its usage in practice. In this paper, we extend RobustSTL to handle multiple seasonality. To speed up the computation, we propose a special generalized ADMM algorithm to perform the decomposition efficiently. We rigorously prove that the proposed algorithm converges approximately as standard ADMM while reducing the complexity from O(N2) to O(N log N) for each iteration. We empirically study our proposed algorithm with other state-of-the-art seasonal-trend decomposition methods, including MSTL, STR, TBATS, on both synthetic and real-world datasets with single and multiple seasonality. The experimental results demonstrate the superior performance of our decomposition algorithm in terms of both effectiveness and efficiency.","[{""name"":""Qingsong Wen"",""id"":""/profile/99659574450""},{""name"":""Zhe Zhang"",""id"":""/profile/99659574883""},{""name"":""Yan Li"",""id"":""/profile/99659350734""},{""name"":""Liang Sun"",""id"":""/profile/99659455171""},{""name"":""Qingsong Wen"",""id"":""/profile/99659574450""},{""name"":""Zhe Zhang"",""id"":""/profile/99659574883""},{""name"":""Yan Li"",""id"":""/profile/99659350734""},{""name"":""Liang Sun"",""id"":""/profile/99659455171""}]","[""Herman Blinchikoff and Helen Krause. 2001. Filtering in the time and frequency domains .Noble Pub, Atlanta, GA.Google Scholar"",""George EP Box, Gwilym M Jenkins, Gregory C Reinsel, and Greta M Ljung. 2015. Time series analysis: forecasting and control .John Wiley \u0026 Sons.Google Scholar"",""Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, Jonathan Eckstein, et al. 2011. Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trends in Machine learning, Vol. 3, 1 (2011), 1--122.Google Scholar"",""Antonin Chambolle and Thomas Pock. 2011. A first-order primal-dual algorithm for convex problems with applications to imaging. Journal of mathematical imaging and vision, Vol. 40, 1 (2011), 120--145.Google ScholarDigital Library"",""Robert B Cleveland, William S Cleveland, Jean E McRae, and Irma Terpenning. 1990. STL: A Seasonal-Trend Decomposition Procedure Based on Loess. Journal of Official Statistics, Vol. 6, 1 (1990), 3--73.Google Scholar"",""Alysha M De Livera, Rob J Hyndman, and Ralph D Snyder. 2011. Forecasting Time Series with Complex Seasonal Patterns using Exponential Smoothing. J. Amer. Statist. Assoc., Vol. 106, 496 (2011), 1513--1527.Google ScholarCross Ref"",""Wei Deng, Ming-Jun Lai, Zhimin Peng, and Wotao Yin. 2017. Parallel multi-block ADMM with O (1/k) convergence. Journal of Scientific Computing, Vol. 71, 2 (2017), 712--736.Google ScholarDigital Library"",""Wei Deng and Wotao Yin. 2016. On the global and linear convergence of the generalized alternating direction method of multipliers. Journal of Scientific Computing, Vol. 66, 3 (2016), 889--916.Google ScholarDigital Library"",""Alexander Dokumentov, Rob J Hyndman, et al. 2015. STR: A Seasonal-Trend Decomposition Procedure Based on Regression. Technical Report. Monash University, Department of Econometrics and Business Statistics.Google Scholar"",""Jingkun Gao, Xiaomin Song, Qingsong Wen, Pichao Wang, Liang Sun, and Huan Xu. 2020. RobustTAD: Robust Time Series Anomaly Detection via Decomposition and Convolutional Neural Networks. arXiv preprint arXiv:2002.09535 (2020).Google Scholar"",""Robert M. Gray. 2006. Toeplitz and Circulant Matrices: A Review. Foundations and Trends® in Communications and Information Theory, Vol. 2, 3 (2006), 155--239.Google Scholar"",""Lan Guanghui. 2019. Lectures on Optimization Methods for Machine Learning .Google Scholar"",""David Hallac, Sagar Vare, Stephen Boyd, and Jure Leskovec. 2017. Toeplitz inverse covariance-based clustering of multivariate time series data. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 215--223.Google ScholarDigital Library"",""Jordan Hochenbaum, Owen S. Vallis, and Arun Kejariwal. 2017. Automatic Anomaly Detection in the Cloud Via Statistical Learning. (2017). arxiv: 1704.07706Google Scholar"",""Rob J Hyndman, George Athanasopoulos, Christoph Bergmeir, Gabriel Caceres, Leanne Chhay, Mitchell O'Hara-Wild, Fotios Petropoulos, Slava Razbash, Earo Wang, and Farah Yasmeen. 2018. Package `forecast'. [Online] https://cran. r-project. org/web/packages/forecast/forecast. pdf (2018).Google Scholar"",""Seung-Jean Kim, Kwangmoo Koh, Stephen Boyd, and Dimitry Gorinevsky. 2009. $ell_1$ Trend Filtering. SIAM Rev., Vol. 51, 2 (2009), 339--360.Google ScholarDigital Library"",""Nikolay Laptev, Saeed Amizadeh, and Ian Flint. 2015. Generic and scalable framework for automated time-series anomaly detection. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 1939--1947.Google ScholarDigital Library"",""Sylvain Paris, Pierre Kornprobst, and Jack Tumblin. 2009. Bilateral Filtering .Now Publishers Inc., Hanover, MA.Google Scholar"",""Marina Theodosiou. 2011. Forecasting monthly and quarterly time series using STL decomposition. International Journal of Forecasting, Vol. 27, 4 (2011), 1178--1195.Google ScholarCross Ref"",""JL Thompson. 2014. An Empirical Evaluation of Denoising Techniques for Streaming Data. Technical Report. Report LLNL-TR-659435. Lawrence Livermore National Laboratory, Livermore, Calif.Google Scholar"",""Michail Vlachos, Philip Yu, and Vittorio Castelli. 2005. On periodicity detection and structural periodic similarity. In Proceedings of the 2005 SIAM international conference on data mining. SIAM, 449--460.Google ScholarCross Ref"",""Jingyuan Wang, Ze Wang, Jianfeng Li, and Junjie Wu. 2018. Multilevel wavelet decomposition network for interpretable time series analysis. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 2437--2446.Google ScholarDigital Library"",""Qingsong Wen, Jingkun Gao, Xiaomin Song, Liang Sun, and Jian Tan. 2019 a. RobustTrend: A Huber Loss with a Combined First and Second Order Difference Regularization for Time Series Trend Filtering. In Proceedings of the 28th International Joint Conference on Artificial Intelligence (IJCAI '19). 3856--3862.Google ScholarCross Ref"",""Qingsong Wen, Jingkun Gao, Xiaomin Song, Liang Sun, Huan Xu, and Shenghuo Zhu. 2019 b. RobustSTL: A Robust Seasonal-Trend Decomposition Algorithm for Long Time Series. In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI '19), Vol. 33. 5409--5416.Google ScholarCross Ref"",""Qingsong Wen, Kai He, Liang Sun, Yingying Zhang, Min Ke, and Huan Xu. 2020. RobustPeriod: Time-Frequency Mining for Robust Multiple Periodicities Detection. arXiv preprint arXiv:3056069 (2020).Google Scholar"",""Bo Wu, Tao Mei, Wen-Huang Cheng, and Yongdong Zhang. 2016. Unfolding Temporal Dynamics: Predicting Social Media Popularity Using Multi-scale Temporal Decomposition (AAAI '16). AAAI Press, 272--278. http://dl.acm.org/citation.cfm?id=3015812.3015852Google Scholar"",""Dazhi Yang, Vishal Sharma, Zhen Ye, Lihong Idris Lim, Lu Zhao, and Aloysius W Aryaputera. 2015. Forecasting of global horizontal irradiance by exponential smoothing, using decompositions. Energy, Vol. 81 (2015), 111--119.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403272,CurvaNet: Geometric Deep Learning based on Directional Curvature for 3D Shape Analysis,"Over the last decade, deep learning research has achieved tremendous success in computer vision and natural language processing. The current widely successful deep learning models are largely based on convolution and pooling operations on a Euclidean plane with a regular grid (e.g., image and video data) and thus cannot be directly applied to the non-Euclidean surface. Geometric deep learning aims to fill the gap by generalizing deep learning models from a 2D Euclidean plane to a 3D geometric surface. The problem has important applications in human-computer interaction, biochemistry, and mechanical engineering, but is uniquely challenging due to the lack of a regular grid framework and the difficulties in learning geometric features on a non-Euclidean manifold. Existing works focus on generalizing deep learning models from 2D image to graphs (e.g., graph neural networks) or 3D mesh surfaces but without fully learning geometric features from a differential geometry perspective. In contrast, this paper proposes a novel geometric deep learning model called CurvaNet that integrates differential geometry with graph neural networks. The key idea is to learn direction sensitive 3D shape features through directional curvature filters. We design a U-Net like architecture with downsampling and upsampling paths based on mesh pooling and unpooling operations. Evaluation on real-world datasets shows that the proposed model outperforms several baseline methods in classification accuracy.","[{""name"":""Wenchong He"",""id"":""/profile/99659573900""},{""name"":""Zhe Jiang"",""id"":""/profile/99659232895""},{""name"":""Chengming Zhang"",""id"":""/profile/99659502746""},{""name"":""Arpan Man Sainju"",""id"":""/profile/99659164830""},{""name"":""Wenchong He"",""id"":""/profile/99659573900""},{""name"":""Zhe Jiang"",""id"":""/profile/99659232895""},{""name"":""Chengming Zhang"",""id"":""/profile/99659502746""},{""name"":""Arpan Man Sainju"",""id"":""/profile/99659164830""}]","[""Alexander Agathos, Ioannis Pratikakis, Stavros Perantonis, Nikolaos Sapidis, and Philip Azariadis. 2007. 3D mesh segmentation methodologies for CAD applications. Computer-Aided Design and Applications, Vol. 4, 6 (2007), 827--841.Google ScholarCross Ref"",""Eman Ahmed, Alexandre Saint, Abd El Rahman Shabayek, Kseniya Cherenkova, Rig Das, Gleb Gusev, Djamila Aouada, and Bjorn Ottersten. 2018. A survey on Deep Learning Advances on Different 3D Data Representations. arXiv preprint arXiv:1808.01462 (2018).Google Scholar"",""James Atwood and Don Towsley. 2016. Diffusion-convolutional neural networks. In Advances in neural information processing systems. 1993--2001.Google Scholar"",""Davide Boscaini, Jonathan Masci, Emanuele Rodolà, and Michael Bronstein. 2016a. Learning shape correspondence with anisotropic convolutional neural networks. In Advances in Neural Information Processing Systems. 3189--3197.Google Scholar"",""Davide Boscaini, Jonathan Masci, Emanuele Rodolà, Michael M Bronstein, and Daniel Cremers. 2016b. Anisotropic diffusion descriptors. In Computer Graphics Forum, Vol. 35. Wiley Online Library, 431--441.Google Scholar"",""Michael M Bronstein, Joan Bruna, Yann LeCun, Arthur Szlam, and Pierre Vandergheynst. 2017. Geometric deep learning: going beyond euclidean data. IEEE Signal Processing Magazine, Vol. 34, 4 (2017), 18--42.Google ScholarCross Ref"",""Xiaobai Chen, Aleksey Golovinskiy, and Thomas Funkhouser. 2009. A benchmark for 3D mesh segmentation. Acm transactions on graphics (tog), Vol. 28, 3 (2009), 1--12.Google Scholar"",""Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, and Cho-Jui Hsieh. 2019. Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 257--266.Google ScholarDigital Library"",""Yan Cui, Sebastian Schuon, Derek Chan, Sebastian Thrun, and Christian Theobalt. 2010. 3D shape scanning with a time-of-flight camera. In 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. IEEE, 1173--1180.Google ScholarCross Ref"",""William HE Day and Herbert Edelsbrunner. 1984. Efficient algorithms for agglomerative hierarchical clustering methods. Journal of classification, Vol. 1, 1 (1984), 7--24.Google ScholarCross Ref"",""Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolutional neural networks on graphs with fast localized spectral filtering. In Advances in neural information processing systems. 3844--3852.Google Scholar"",""Inderjit S Dhillon, Yuqiang Guan, and Brian Kulis. 2007. Weighted graph cuts without eigenvectors a multilevel approach. IEEE transactions on pattern analysis and machine intelligence, Vol. 29, 11 (2007), 1944--1957.Google Scholar"",""Felix Endres, Jürgen Hess, Jürgen Sturm, Daniel Cremers, and Wolfram Burgard. 2013. 3-D mapping with an RGB-D camera. IEEE transactions on robotics, Vol. 30, 1 (2013), 177--187.Google Scholar"",""Yi Fang, Jin Xie, Guoxian Dai, Meng Wang, Fan Zhu, Tiantian Xu, and Edward Wong. 2015. 3d deep shape descriptor. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2319--2328.Google ScholarCross Ref"",""Yutong Feng, Yifan Feng, Haoxuan You, Xibin Zhao, and Yue Gao. 2019. MeshNet: mesh neural network for 3D shape representation. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 8279--8286.Google ScholarCross Ref"",""Matthias Fey, Jan Eric Lenssen, Frank Weichert, and Heinrich Mü ller. 2018. SplineCNN: Fast geometric deep learning with continuous B-spline kernels. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 869--877.Google ScholarCross Ref"",""P Gainza, F Sverrisson, F Monti, E Rodolà, D Boscaini, MM Bronstein, and BE Correia. 2020. Deciphering interaction fingerprints from protein molecular surfaces using geometric deep learning. Nature Methods, Vol. 17, 2 (2020), 184--192.Google Scholar"",""Hongyang Gao and Shuiwang Ji. 2019. Graph U-Nets. arXiv preprint arXiv:1905.05178 (2019).Google Scholar"",""Hongyang Gao, Zhengyang Wang, and Shuiwang Ji. 2018. Large-scale learnable graph convolutional networks. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1416--1424.Google ScholarDigital Library"",""Michael Garland and Paul S Heckbert. 1997. Surface simplification using quadric error metrics. In Proceedings of the 24th annual conference on Computer graphics and interactive techniques. 209--216.Google ScholarDigital Library"",""Kan Guo, Dongqing Zou, and Xiaowu Chen. 2015. 3d mesh labeling via deep convolutional neural networks. ACM Transactions on Graphics (TOG), Vol. 35, 1 (2015), 1--12.Google ScholarDigital Library"",""Rana Hanocka, Amir Hertz, Noa Fish, Raja Giryes, Shachar Fleishman, and Daniel Cohen-Or. 2019. MeshCNN: a network with an edge. ACM Transactions on Graphics (TOG), Vol. 38, 4 (2019), 90.Google ScholarDigital Library"",""Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).Google Scholar"",""Sebastian Koch, Albert Matveev, Zhongshi Jiang, Francis Williams, Alexey Artemov, Evgeny Burnaev, Marc Alexa, Denis Zorin, and Daniele Panozzo. 2019. ABC: A big CAD model dataset for geometric deep learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 9601--9611.Google ScholarCross Ref"",""Yao Ma, Suhang Wang, Charu C Aggarwal, and Jiliang Tang. 2019. Graph convolutional networks with eigenpooling. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 723--731.Google ScholarDigital Library"",""Jean-Luc Mari, Sophie Viseur, Sylvain Bouley, Martin-Pierre Schmidt, Jennifer Muscato, Florian Beguet, Sarah Bali, and Laurent Jorda. 2018. Robust detection of circular shapes on 3D meshes based on discrete curvatures-Application to impact craters recognition.Google Scholar"",""Jonathan Masci, Davide Boscaini, Michael Bronstein, and Pierre Vandergheynst. 2015. Geodesic convolutional neural networks on riemannian manifolds. In Proceedings of the IEEE international conference on computer vision workshops. 37--45.Google ScholarDigital Library"",""Takashi Matsuyama, Xiaojun Wu, Takeshi Takai, and Shohei Nobuhara. 2004. Real-time 3D shape reconstruction, dynamic 3D mesh deformation, and high fidelity visualization for 3D video. Computer Vision and Image Understanding, Vol. 96, 3 (2004), 393--434.Google ScholarDigital Library"",""Federico Monti, Davide Boscaini, Jonathan Masci, Emanuele Rodola, Jan Svoboda, and Michael M Bronstein. 2017. Geometric deep learning on graphs and manifolds using mixture model cnns. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 5115--5124.Google ScholarCross Ref"",""Vladimir I Pavlovic, Rajeev Sharma, and Thomas S. Huang. 1997. Visual interpretation of hand gestures for human-computer interaction: A review. IEEE Transactions on pattern analysis and machine intelligence, Vol. 19, 7 (1997), 677--695.Google ScholarDigital Library"",""CMPPC Rocchini, Paulo Cignoni, Claudio Montani, Paolo Pingi, and Roberto Scopigno. 2001. A low cost 3D scanner based on structured light. In Computer Graphics Forum, Vol. 20. Wiley Online Library, 299--308.Google Scholar"",""Olaf Ronneberger, Philipp Fischer, and Thomas Brox. 2015. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computer-assisted intervention. Springer, 234--241.Google ScholarCross Ref"",""Reihaneh Rostami, Fereshteh S Bashiri, Behrouz Rostami, and Zeyun Yu. 2019. A Survey on Data-Driven 3D Shape Descriptors. In Computer Graphics Forum, Vol. 38. Wiley Online Library, 356--393.Google Scholar"",""Gérard Subsol, Bertrand Mafart, Alain Silvestre, Marie-Antoinette de Lumley, and H Delingette. 2002. 3d image processing for the study of the evolution of the shape of the human skull: presentation of the tools and preliminary results. Three-Dimensional Imaging in Paleoanthropology and Prehistoric Archaeology, Vol. 1049 (2002), 37--45.Google Scholar"",""Hiromi T Tanaka, Masaki Ikeda, and Hisako Chiaki. 1998. Curvature-based face surface recognition using spherical correlation. principal directions for curved object recognition. In Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition. IEEE, 372--377.Google ScholarCross Ref"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph attention networks. arXiv preprint arXiv:1710.10903 (2017).Google Scholar"",""Nitika Verma, Edmond Boyer, and Jakob Verbeek. 2018. Feastnet: Feature-steered graph convolutions for 3d shape analysis. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2598--2606.Google ScholarCross Ref"",""Peng-Shuai Wang, Chun-Yu Sun, Yang Liu, and Xin Tong. 2018. Adaptive O-CNN: A patch-based deep representation of 3D shapes. ACM Transactions on Graphics (TOG), Vol. 37, 6 (2018), 1--11.Google ScholarDigital Library"",""Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and Philip S Yu. 2019. A comprehensive survey on graph neural networks. arXiv preprint arXiv:1901.00596 (2019).Google Scholar"",""Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, and Jure Leskovec. 2018. Hierarchical graph representation learning with differentiable pooling. In Advances in Neural Information Processing Systems. 4800--4810.Google Scholar"",""Ziwei Zhang, Peng Cui, and Wenwu Zhu. 2018. Deep learning on graphs: A survey. arXiv preprint arXiv:1812.04202 (2018).Google Scholar"",""Jie Zhou, Ganqu Cui, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li, and Maosong Sun. 2018. Graph neural networks: A review of methods and applications. arXiv preprint arXiv:1812.08434 (2018).Google Scholar""]"
https://doi.org/10.1145/3394486.3403273,Attentional Multi-graph Convolutional Network for Regional Economy Prediction with Open Migration Data,"We study the problem of predicting regional economy of U.S. counties with open migration data collected from U.S. Internal Revenue Service (IRS) records. To capture the complicated correlations between them, we design a novel Attentional Multi-graph Convolutional Network (AMCN), which models the migration behavior as a multi-graph with different types of edges denoting the migration flows collected from heterogeneous sources of different years and different demographics. AMCN extracts high quality feature from the migration multi-graph by first applying customized aggregator functions on the induced subgraphs, and then fusing the aggregated features with a higher-order attentional aggregator function. In addition, we address the data sparsity problem with an important neighbor discovery algorithm that can automatically supplement important neighbors that are absent in the empirical data. Experiment results show our AMCN model significantly outperforms all baselines in terms of reducing the relative mean square error by 43.8% against the classic regression model and by 12.7% against the state-of-the-art deep learning baselines. In-depth model analysis shows our proposed AMCN model reveals insightful correlations between regional economy and migration data.","[{""name"":""Fengli Xu"",""id"":""/profile/99658756914""},{""name"":""Yong Li"",""id"":""/profile/81453640533""},{""name"":""Shusheng Xu"",""id"":""/profile/99659573485""},{""name"":""Fengli Xu"",""id"":""/profile/99658756914""},{""name"":""Yong Li"",""id"":""/profile/81453640533""},{""name"":""Shusheng Xu"",""id"":""/profile/99659573485""}]","[""Brinley Thomas. Migration and economic growth: a study of Great Britain and the Atlantic economy, volume 12. CUP Archive, 1973.Google Scholar"",""Oded Stark and David E Bloom. The new economics of labor migration. The American Economic review, 75(2):173--178, 1985.Google Scholar"",""Adrian J Bailey. Worlds in motion: Understanding international migration at the end of the millennium, 2001.Google Scholar"",""Hendrik Van den Berg and Örn B Bodvarsson. The Economics of Immigration: Theory and Policy. Springer, 2009.Google Scholar"",""Doug Saunders. Arrival city: How the largest migration in history is reshaping our world. Vintage, 2011.Google Scholar"",""David Card, Christian Dustmann, and Ian Preston. Immigration, wages, and compositional amenities. Journal of the European Economic Association, 10(1):78--119, 2012.Google ScholarCross Ref"",""Claire L Adida and Desha M Girod. Do migrants improve their hometowns? remittances and access to public services in Mexico, 1995--2000. Comparative Political Studies, 44(1):3--27, 2011.Google ScholarCross Ref"",""Mette Foged and Giovanni Peri. Immigrants' effect on native workers: New analysis on longitudinal data. American Economic Journal: Applied Economics, 8(2):1--34, 2016.Google ScholarCross Ref"",""Sari Pekkala Kerr and William R Kerr. Economic impacts of immigration: A survey. Technical report, National Bureau of Economic Research, 2011.Google Scholar"",""Joao Pedro Azevedo, Judy S Yang, and Osman Kaan Inan. What are the impacts of Syrian refugees on host community welfare in Turkey? a subnational poverty analysis. The World Bank, 2016.Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs. In Advances in Neural Information Processing Systems, pages 1024--1034, 2017.Google Scholar"",""Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907, 2016.Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural information processing systems, pages 5998--6008, 2017.Google Scholar"",""Benjamin Elsner. Emigration and wages: The eu enlargement experiment. Journal of International Economics, 91(1):154--163, 2013.Google ScholarCross Ref"",""Jennifer Hunt and Marjolaine Gauthier-Loiselle. How much does immigration boost innovation? American Economic Journal: Macroeconomics, 2(2):31--56, 2010.Google ScholarCross Ref"",""Zhihan Fang, Fan Zhang, Ling Yin, and Desheng Zhang. Multicell: Urban population modeling based on multiple cellphone networks. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 2(3):106, 2018.Google Scholar"",""Fengli Xu, Pengyu Zhang, and Yong Li. Context-aware real-time population estimation for metropolis. In Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing, pages 1064--1075. ACM, 2016.Google ScholarDigital Library"",""Farbod Faghihi and Petteri Nurmi. An empirical study on the regularity of route mobility. In Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct, pages 1418--1425. ACM, 2016.Google ScholarDigital Library"",""Shenggong Ji, Yu Zheng, and Tianrui Li. Urban sensing based on human mobility. In Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing, pages 1040--1051. ACM, 2016.Google ScholarDigital Library"",""Aku Visuri, Kennedy Opoku Asare, Elina Kuosmanen, Yuuki Nishiyama, Denzil Ferreira, Zhanna Sarsenbayeva, Jorge Goncalves, Niels van Berkel, Greg Wadley, Vassilis Kostakos, et al. Ubiquitous mobile sensing: Behaviour, mood, and environment. In Proceedings of the 2018 ACM International Joint Conference and 2018 International Symposium on Pervasive and Ubiquitous Computing and Wearable Computers, pages 1140--1143. ACM, 2018.Google ScholarDigital Library"",""Luca Canzian and Mirco Musolesi. Trajectories of depression: Unobtrusive monitoring of depressive states by means of smartphone mobility traces analysis. In Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing, UbiComp '15, pages 1293--1304. ACM, 2015.Google ScholarDigital Library"",""Fei Yi, Zhiwen Yu, Qin Lv, and Bin Guo. Toward estimating user-social event distance: mobility, content, and social relationship. In Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct, pages 233--236. ACM, 2016.Google ScholarDigital Library"",""Yanwei Yu, Hongjian Wang, and Zhenhui Li. Inferring mobility relationship via graph embedding. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 2(3):147, 2018.Google Scholar"",""Donghan Yu, Yong Li, Fengli Xu, Pengyu Zhang, and Vassilis Kostakos. Smartphone app usage prediction using points of interest. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 1(4):174, 2018.Google Scholar"",""Tong Xia, Yue Yu, Fengli Xu, Funing Sun, Diansheng Guo, Depeng Jin, and Yong Li. Understanding urban dynamics via state-sharing hidden markov model. In The World Wide Web Conference, pages 3363--3369. ACM, 2019.Google ScholarDigital Library"",""Stefan Foell, Gerd Kortuem, Reza Rawassizadeh, Santi Phithakkitnukoon, Marco Veloso, and Carlos Bento. Mining temporal patterns of transport behaviour for predicting future transport usage. In Proceedings of the 2013 ACM conference on Pervasive and ubiquitous computing, pages 1239--1248. ACM, 2013.Google ScholarDigital Library"",""Yang Yang, Zongtao Liu, Chenhao Tan, Fei Wu, Yueting Zhuang, and Yafeng Li. To stay or to leave: Churn prediction for urban migrants in the initial period. In Proceedings of the 2018 World Wide Web Conference, pages 967--976. International World Wide Web Conferences Steering Committee, 2018.Google ScholarDigital Library"",""Yang Yang, Chenhao Tan, Zongtao Liu, Fei Wu, and Yueting Zhuang. Urban dreams of migrants: A case study of migrant integration in shanghai. In Thirty-Second AAAI Conference on Artificial Intelligence, 2018.Google Scholar"",""Jinyin Chen, Xuanheng Xu, Yangyang Wu, and Haibin Zheng. Gc-lstm: Graph convolution embedded lstm for dynamic link prediction. arXiv preprint arXiv:1812.04206, 2018.Google Scholar"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. Graph attention networks. arXiv preprint arXiv:1710.10903, 2017.Google Scholar"",""Binbing Liao, Jingqing Zhang, Chao Wu, Douglas McIlwraith, Tong Chen, Shengwen Yang, Yike Guo, and Fei Wu. Deep sequence learning with auxiliary information for traffic prediction. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining, pages 537--546. ACM, 2018.Google ScholarDigital Library"",""Jiezhong Qiu, Jian Tang, Hao Ma, Yuxiao Dong, Kuansan Wang, and Jie Tang. Deepinf: Social influence prediction with deep learning. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining, pages 2110--2119. ACM, 2018.Google ScholarDigital Library"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. Graph convolutional neural networks for web-scale recommender systems. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining, pages 974--983. ACM, 2018.Google ScholarDigital Library"",""Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, and Philip S Yu. Heterogeneous graph attention network. In The World Wide Web Conference, WWW '19, pages 2022--2032, New York, NY, USA, 2019. ACM.Google ScholarDigital Library"",""Yizhou Sun, Jiawei Han, Xifeng Yan, Philip S Yu, and Tianyi Wu. Pathsim: Meta path-based top-k similarity search in heterogeneous information networks. Proceedings of the VLDB Endowment, 4(11):992--1003, 2011.Google ScholarDigital Library"",""Matt W Gardner and SR Dorling. Artificial neural networks (the multilayer perceptron)-a review of applications in the atmospheric sciences. Atmospheric environment, 32(14--15):2627--2636, 1998.Google Scholar"",""Bing Xu, Naiyan Wang, Tianqi Chen, and Mu Li. Empirical evaluation of rectified activations in convolutional network. arXiv preprint arXiv:1505.00853, 2015.Google Scholar"",""Roland Memisevic, Christopher Zach, Marc Pollefeys, and Geoffrey E Hinton. Gated softmax classification. In Advances in neural information processing systems, pages 1603--1611, 2010.Google Scholar"",""George Kingsley Zipf. The p 1 p 2/d hypothesis: on the intercity movement of persons. American sociological review, 11(6):677--686, 1946.Google Scholar"",""Marc Barthelemy. Spatial networks. Phys. Rep., 499:1--101, 2010.Google ScholarCross Ref"",""Woo-Sung Jung, Fengzhong Wang, and H Eugene Stanley. Gravity model in the korean highway. EPL (Europhysics Letters), 81(4):48005, 2008.Google Scholar"",""Harris Drucker, Christopher JC Burges, Linda Kaufman, Alex J Smola, and Vladimir Vapnik. Support vector regression machines. In Advances in neural information processing systems, pages 155--161, 1997.Google ScholarDigital Library"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 701--710. ACM, 2014.Google ScholarDigital Library"",""Aditya Grover and Jure Leskovec. node2vec: Scalable feature learning for networks. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining, pages 855--864. ACM, 2016.Google ScholarDigital Library"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. Line: Large-scale information network embedding. In Proceedings of the 24th international conference on world wide web, pages 1067--1077. International World Wide Web Conferences Steering Committee, 2015.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403274,Octet: Online Catalog Taxonomy Enrichment with Self-Supervision,"Taxonomies have found wide applications in various domains, especially online for item categorization, browsing, and search. Despite the prevalent use of online catalog taxonomies, most of them in practice are maintained by humans, which is labor-intensive and difficult to scale. While taxonomy construction from scratch is considerably studied in the literature, how to effectively enrich existing incomplete taxonomies remains an open yet important research question. Taxonomy enrichment not only requires the robustness to deal with emerging terms but also the consistency between existing taxonomy structure and new term attachment. In this paper, we present a self-supervised end-to-end framework, Octet, for Online Catalog Taxonomy EnrichmenT. Octet leverages heterogeneous information unique to online catalog taxonomies such as user queries, items, and their relations to the taxonomy nodes while requiring no other supervision than the existing taxonomies. We propose to distantly train a sequence labeling model for term extraction and employ graph neural networks (GNNs) to capture the taxonomy structure as well as the query-item-taxonomy interactions for term attachment. Extensive experiments in different online domains demonstrate the superiority of Octet over state-of-the-art methods via both automatic and human evaluations. Notably, Octet enriches an online catalog taxonomy in production to 2 times larger in the open-world evaluation.","[{""name"":""Yuning Mao"",""id"":""/profile/99659574589""},{""name"":""Tong Zhao"",""id"":""/profile/99659452891""},{""name"":""Andrey Kan"",""id"":""/profile/81548396856""},{""name"":""Chenwei Zhang"",""id"":""/profile/99659574421""},{""name"":""Xin Luna Dong"",""id"":""/profile/99659531494""},{""name"":""Christos Faloutsos"",""id"":""/profile/81100373169""},{""name"":""Jiawei Han"",""id"":""/profile/81548005096""},{""name"":""Yuning Mao"",""id"":""/profile/99659574589""},{""name"":""Tong Zhao"",""id"":""/profile/99659452891""},{""name"":""Andrey Kan"",""id"":""/profile/81548396856""},{""name"":""Chenwei Zhang"",""id"":""/profile/99659574421""},{""name"":""Xin Luna Dong"",""id"":""/profile/99659531494""},{""name"":""Christos Faloutsos"",""id"":""/profile/81100373169""},{""name"":""Jiawei Han"",""id"":""/profile/81548005096""}]","[""Mohit Bansal, David Burkett, Gerard De Melo, and Dan Klein. 2014. Structured Learning for Taxonomy Induction with Belief Propagation.. In ACL.Google Scholar"",""Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. Enriching Word Vectors with Subword Information. TACL (2017).Google Scholar"",""Georgeta Bordea, Els Lefever, and Paul Buitelaar. 2016. Semeval-2016 task 13: Taxonomy extraction evaluation (texeval-2). In SemEval-2016. ACL.Google Scholar"",""Haw-Shiuan Chang, ZiYun Wang, Luke Vilnis, and Andrew McCallum. 2017. Unsupervised Hypernym Detection by Distributional Inclusion Vector Embedding. arXiv preprint arXiv:1710.00880 (2017).Google Scholar"",""Thomas Demeester, Tim Rocktäschel, and Sebastian Riedel. 2016. Lifted Rule Injection for Relation Embeddings. In EMNLP.Google Scholar"",""Ruiji Fu, Jiang Guo, Bing Qin, Wanxiang Che, Haifeng Wang, and Ting Liu. 2014. Learning semantic hierarchies via word embeddings. In ACL.Google Scholar"",""Amit Gupta, Rémi Lebret, Hamza Harkous, and Karl Aberer. 2017. Taxonomy Induction using Hypernym Subsequences. In CIKM. ACM, 1329--1338.Google Scholar"",""Marti A Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In ACL.Google Scholar"",""Jin Huang, Zhaochun Ren, Wayne Xin Zhao, Gaole He, Ji-Rong Wen, and Daxiang Dong. 2019. Taxonomy-aware multi-hop reasoning networks for sequential recommendation. In WSDM. ACM, 573--581.Google Scholar"",""David Jurgens and Mohammad Taher Pilehvar. 2015. Reserating the awesometastic: An automatic extension of the WordNet taxonomy for novel terms. In NAACL.Google Scholar"",""David Jurgens and Mohammad Taher Pilehvar. 2016. Semeval-2016 task 14: Semantic taxonomy enrichment. In SemEval-2016.Google Scholar"",""Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).Google Scholar"",""Zornitsa Kozareva and Eduard Hovy. 2010. A semi-supervised method to learn and construct taxonomies using the web. In EMNLP. ACL, 1110--1118.Google Scholar"",""Dekang Lin et almbox. 1998. An information-theoretic definition of similarity.. In Icml, Vol. 98. Citeseer, 296--304.Google Scholar"",""Bang Liu, Weidong Guo, Di Niu, Chaoyue Wang, Shunnan Xu, Jinghong Lin, Kunfeng Lai, and Yu Xu. 2019. A User-Centered Concept Mining System for Query and Document Understanding at Tencent. In KDD.Google Scholar"",""Jialu Liu, Jingbo Shang, Chi Wang, Xiang Ren, and Jiawei Han. 2015. Mining quality phrases from massive text corpora. In SIGMOD. ACM, 1729--1744.Google Scholar"",""Yuning Mao, Xiang Ren, Jiaming Shen, Xiaotao Gu, and Jiawei Han. 2018. End-to-End Reinforcement Learning for Automatic Taxonomy Induction. In ACL.Google Scholar"",""Yuning Mao, Jingjing Tian, Jiawei Han, and Xiang Ren. 2019. Hierarchical Text Classification with Reinforced Label Assignment. In EMNLP.Google Scholar"",""Ndapandula Nakashole, Gerhard Weikum, and Fabian Suchanek. 2012. PATTY: a taxonomy of relational patterns with semantic types. In EMNLP. 1135--1145.Google Scholar"",""Rrubaa Panchendrarajan and Aravindh Amaresan. 2018. Bidirectional LSTM-CRF for Named Entity Recognition. In ACL.Google Scholar"",""Alexander Panchenko, Stefano Faralli, Eugen Ruppert, Steffen Remus, Hubert Naets, Cedrick Fairon, Simone Paolo Ponzetto, and Chris Biemann. 2016. TAXI at SemEval-2016 Task 13: a Taxonomy Induction Method based on Lexico-Syntactic Patterns, Substrings and Focused Crawling. In SemEval. San Diego, CA, USA.Google Scholar"",""Xiang Ren, Ahmed El-Kishky, Chi Wang, Fangbo Tao, Clare R Voss, and Jiawei Han. 2015. Clustype: Effective entity recognition and typing by relation phrase-based clustering. In KDD. ACM, 995--1004.Google ScholarDigital Library"",""Laura Rimell. 2014. Distributional lexical entailment by topic coherence. In EACL.Google Scholar"",""Michael Schlichtkrull and Héctor Martínez Alonso. 2016. Msejrku at semeval-2016 task 14: Taxonomy enrichment by evidence ranking. In SemEval-2016.Google Scholar"",""Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den Berg, Ivan Titov, and Max Welling. 2018. Modeling relational data with graph convolutional networks. In European Semantic Web Conference. Springer, 593--607.Google ScholarCross Ref"",""Jingbo Shang, Jialu Liu, Meng Jiang, Xiang Ren, Clare R Voss, and Jiawei Han. 2018. Automated phrase mining from massive text corpora. TKDE (2018).Google Scholar"",""Jiaming Shen, Zhihong Shen, Chenyan Xiong, Chi Wang, Kuansan Wang, and Jiawei Han. 2020. TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced Graph Neural Network. In WWW. 486--497.Google Scholar"",""Jiaming Shen, Zeqiu Wu, Dongming Lei, Chao Zhang, Xiang Ren, Michelle T Vanni, Brian M Sadler, and Jiawei Han. 2018. HiExpan: Task-guided taxonomy construction by hierarchical tree expansion. In KDD. ACM, 2180--2189.Google Scholar"",""Wei Shen, Jianyong Wang, Ping Luo, and Min Wang. 2012. A graph-based approach for ontology population with named entities. In CIKM. ACM, 345--354.Google Scholar"",""Vered Shwartz, Yoav Goldberg, and Ido Dagan. 2016. Improving Hypernymy Detection with an Integrated Path-based and Distributional Method. In ACL.Google Scholar"",""Rion Snow, Daniel Jurafsky, and Andrew Y Ng. 2005. Learning syntactic patterns for automatic hypernym discovery. In NIPS. 1297--1304.Google Scholar"",""Luu A Tuan, Yi Tay, Siu C Hui, and See K Ng. 2016. Learning Term Embeddings for Taxonomic Relation Identification Using Dynamic Weighting Neural Network. In EMNLP.Google Scholar"",""Jingjing Wang, Changsung Kang, Yi Chang, and Jiawei Han. 2014. A hierarchical dirichlet model for taxonomy expansion for search engines. In WWW. 961--970.Google Scholar"",""Julie Weeds, David Weir, and Diana McCarthy. 2004. Characterising measures of lexical distributional similarity. In COLING.Google Scholar"",""Shuo Yang, Lei Zou, Zhongyuan Wang, Jun Yan, and Ji-Rong Wen. 2017. Efficiently Answering Technical Questions - A Knowledge Graph Approach. In AAAI.Google Scholar"",""Zheng Yu, Haixun Wang, Xuemin Lin, and Min Wang. 2015. Learning Term Embeddings for Hypernymy Identification.. In IJCAI. 1390--1397.Google Scholar"",""Chao Zhang, Fangbo Tao, Xiusi Chen, Jiaming Shen, Meng Jiang, Brian Sadler, Michelle Vanni, and Jiawei Han. 2018. Taxogen: Unsupervised topic taxonomy construction by adaptive term embedding and clustering. In KDD.Google ScholarDigital Library"",""Hao Zhang, Zhiting Hu, Yuntian Deng, Mrinmaya Sachan, Zhicheng Yan, and Eric Xing. 2016. Learning Concept Taxonomies from Multi-modal Data. In ACL.Google Scholar"",""Guineng Zheng, Subhabrata Mukherjee, Xin Luna Dong, and Feifei Li. 2018. Opentag: Open attribute value extraction from product profiles. In KDD.Google Scholar""]"
https://doi.org/10.1145/3394486.3403275,TIMME: Twitter Ideology-detection via Multi-task Multi-relational Embedding,"We aim at solving the problem of predicting people's ideology, or political tendency. We estimate it by using Twitter data, and formalize it as a classification problem. Ideology-detection has long been a challenging yet important problem. Certain groups, such as the policy makers, rely on it to make wise decisions. Back in the old days when labor-intensive survey-studies were needed to collect public opinions, analyzing ordinary citizens' political tendencies was uneasy. The rise of social medias, such as Twitter, has enabled us to gather ordinary citizen's data easily. However, the incompleteness of the labels and the features in social network datasets is tricky, not to mention the enormous data size and the heterogeneousity. The data differ dramatically from many commonly-used datasets, thus brings unique challenges. In our work, first we built our own datasets from Twitter. Next, we proposed TIMME, a multi-task multi-relational embedding model, that works efficiently on sparsely-labeled heterogeneous real-world dataset. It could also handle the incompleteness of the input features. Experimental results showed that TIMME is overall better than the state-of-the-art models for ideology detection on Twitter. Our findings include: links can lead to good classification outcomes without text; conservative voice is under-represented on Twitter; follow is the most important relation to predict ideology; retweet and mention enhance a higher chance of like, etc. Last but not least, TIMME could be extended to other datasets and tasks in theory.","[{""name"":""Zhiping Xiao"",""id"":""/profile/99659243516""},{""name"":""Weiping Song"",""id"":""/profile/99659346665""},{""name"":""Haoyan Xu"",""id"":""/profile/99659574906""},{""name"":""Zhicheng Ren"",""id"":""/profile/99659573819""},{""name"":""Yizhou Sun"",""id"":""/profile/81548005095""},{""name"":""Zhiping Xiao"",""id"":""/profile/99659243516""},{""name"":""Weiping Song"",""id"":""/profile/99659346665""},{""name"":""Haoyan Xu"",""id"":""/profile/99659574906""},{""name"":""Zhicheng Ren"",""id"":""/profile/99659573819""},{""name"":""Yizhou Sun"",""id"":""/profile/81548005095""}]","[""Christopher H Achen. 1975. Mass political attitudes and the survey response. American Political Science Review, Vol. 69, 4 (1975), 1218--1231.Google ScholarCross Ref"",""Ramy Baly, Georgi Karadzhov, Abdelrhman Saleh, James Glass, and Preslav Nakov. 2019. Multi-task ordinal regression for jointly predicting the trustworthiness and the leading political ideology of news media. arXiv preprint arXiv:1904.00542 (2019).Google Scholar"",""Yukuo Cen, Xu Zou, Jianwei Zhang, Hongxia Yang, Jingren Zhou, and Jie Tang. 2019. Representation learning for attributed multiplex heterogeneous network. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1358--1368.Google ScholarDigital Library"",""Jie Chen, Tengfei Ma, and Cao Xiao. 2018. Fastgcn: fast learning with graph convolutional networks via importance sampling. arXiv preprint arXiv:1801.10247 (2018).Google Scholar"",""Wei Chen, Xiao Zhang, Tengjiao Wang, Bishan Yang, and Yi Li. 2017. Opinion-aware Knowledge Graph for Political Ideology Detection.. In IJCAI. 3647--3653.Google Scholar"",""Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, and Cho-Jui Hsieh. 2019. Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 257--266.Google ScholarDigital Library"",""Joshua Clinton, Simon Jackman, and Douglas Rivers. 2004. The statistical analysis of roll call data. American Political Science Review, Vol. 98, 2 (2004), 355--370.Google ScholarCross Ref"",""Michael D Conover, Bruno Goncc alves, Jacob Ratkiewicz, Alessandro Flammini, and Filippo Menczer. 2011a. Predicting the political alignment of twitter users. In 2011 IEEE third international conference on privacy, security, risk and trust and 2011 IEEE third international conference on social computing. IEEE, 192--199.Google Scholar"",""Michael D Conover, Jacob Ratkiewicz, Matthew Francisco, Bruno Goncc alves, Filippo Menczer, and Alessandro Flammini. 2011b. Political polarization on twitter. In Fifth international AAAI conference on weblogs and social media.Google Scholar"",""Aron Culotta, Nirmal Ravi Kumar, and Jennifer Cutler. 2015. Predicting the Demographics of Twitter Users from Website Traffic Data.. In AAAI, Vol. 15. Austin, TX, 72--8.Google Scholar"",""Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolutional neural networks on graphs with fast localized spectral filtering. In Advances in neural information processing systems. 3844--3852.Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. 855--864.Google ScholarDigital Library"",""Yupeng Gu, Ting Chen, Yizhou Sun, and Bingyu Wang. 2016. Ideology detection for twitter users with heterogeneous types of links. arXiv preprint arXiv:1612.08207 (2016).Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In Advances in neural information processing systems. 1024--1034.Google Scholar"",""Mohit Iyyer, Peter Enns, Jordan Boyd-Graber, and Philip Resnik. 2014. Political ideology detection using recursive neural networks. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 1113--1122.Google ScholarCross Ref"",""Kristen Johnson and Dan Goldwasser. 2016. Identifying stance by analyzing political discourse on twitter. In Proceedings of the First Workshop on NLP and Computational Social Science. 66--75.Google ScholarCross Ref"",""Sandeepa Kannangara. 2018. Mining twitter for fine-grained political opinion polarity classification, ideology detection and sarcasm detection. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. 751--752.Google ScholarDigital Library"",""Alex Kendall, Yarin Gal, and Roberto Cipolla. 2018. Multi-task learning using uncertainty to weigh losses for scene geometry and semantics. In Proceedings of the IEEE conference on computer vision and pattern recognition. 7482--7491.Google Scholar"",""Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).Google Scholar"",""Theresa Kuhn and Aaron Kamm. 2019. The national boundaries of solidarity: a survey experiment on solidarity with unemployed people in the European Union. European Political Science Review, Vol. 11, 2 (2019), 179--195.Google ScholarCross Ref"",""Qimai Li, Zhichao Han, and Xiao-Ming Wu. 2018. Deeper insights into graph convolutional networks for semi-supervised learning. In Thirty-Second AAAI Conference on Artificial Intelligence.Google Scholar"",""Ziqi Liu, Chaochao Chen, Xinxing Yang, Jun Zhou, Xiaolong Li, and Le Song. 2018. Heterogeneous graph neural networks for malicious account detection. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management. 2077--2085.Google ScholarDigital Library"",""Sergio Martini and Mariano Torcal. 2019. Trust across political conflicts: Evidence from a survey experiment in divided societies. Party Politics, Vol. 25, 2 (2019), 126--139.Google ScholarCross Ref"",""Viet-An Nguyen, Jordan Boyd-Graber, Philip Resnik, and Kristina Miler. 2015. Tea party in the house: A hierarchical ideal point topic model and its application to republican legislators in the 112th congress. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 1438--1448.Google ScholarCross Ref"",""Chang Sup Park. 2013. Does Twitter motivate involvement in politics? Tweeting, opinion leadership, and political engagement. Computers in Human Behavior, Vol. 29, 4 (2013), 1641--1648.Google ScholarDigital Library"",""Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove: Global vectors for word representation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP). 1532--1543.Google ScholarCross Ref"",""Gary Pollock, Tom Brock, and Mark Ellison. 2015. Populism, ideology and contradiction: mapping young people's political views. The Sociological Review, Vol. 63 (2015), 141--166.Google ScholarCross Ref"",""Keith T Poole and Howard Rosenthal. 1985. A spatial model for legislative roll call analysis. American Journal of Political Science (1985), 357--384.Google Scholar"",""Daniel Preoct iuc-Pietro, Ye Liu, Daniel Hopkins, and Lyle Ungar. 2017. Beyond binary labels: political ideology prediction of twitter users. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 729--740.Google ScholarCross Ref"",""Nils Reimers and Iryna Gurevych. 2019. Sentence-bert: Sentence embeddings using siamese bert-networks. arXiv preprint arXiv:1908.10084 (2019).Google Scholar"",""Sebastian Ruder. 2017. An overview of multi-task learning in deep neural networks. arXiv preprint arXiv:1706.05098 (2017).Google Scholar"",""Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den Berg, Ivan Titov, and Max Welling. 2018. Modeling relational data with graph convolutional networks. In European Semantic Web Conference. Springer, 593--607.Google ScholarCross Ref"",""Richard Socher, Danqi Chen, Christopher D Manning, and Andrew Ng. 2013. Reasoning with neural tensor networks for knowledge base completion. In Advances in neural information processing systems. 926--934.Google Scholar"",""Yizhou Sun and Jiawei Han. 2012. Mining heterogeneous information networks: principles and methodologies. Synthesis Lectures on Data Mining and Knowledge Discovery, Vol. 3, 2 (2012), 1--159.Google ScholarDigital Library"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. In Proceedings of the 24th international conference on world wide web. 1067--1077.Google ScholarDigital Library"",""Petar Velivc ković , Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph attention networks. arXiv preprint arXiv:1710.10903 (2017).Google Scholar"",""Prashanth Vijayaraghavan, Soroush Vosoughi, and Deb Roy. 2017. Twitter demographic classification using deep multi-modal multi-task learning. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). 478--483.Google ScholarCross Ref"",""Hongwei Wang, Fuzheng Zhang, Min Hou, Xing Xie, Minyi Guo, and Qi Liu. 2018. Shine: Signed heterogeneous information network embedding for sentiment link prediction. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. 592--600.Google ScholarDigital Library"",""Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, and Philip S Yu. 2019. Heterogeneous graph attention network. In The World Wide Web Conference. 2022--2032.Google ScholarDigital Library"",""Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2018. How powerful are graph neural networks? arXiv preprint arXiv:1810.00826 (2018).Google Scholar"",""Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. 2014. Embedding entities and relations for learning and inference in knowledge bases. arXiv preprint arXiv:1412.6575 (2014).Google Scholar"",""Seongjun Yun, Minbyul Jeong, Raehyun Kim, Jaewoo Kang, and Hyunwoo J Kim. 2019. Graph Transformer Networks. In Advances in Neural Information Processing Systems. 11960--11970.Google Scholar"",""Chuxu Zhang, Dongjin Song, Chao Huang, Ananthram Swami, and Nitesh V Chawla. 2019. Heterogeneous graph neural network. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 793--803.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403276,"Knowing your FATE: Friendship, Action and Temporal Explanations for User Engagement Prediction on Social Apps","With the rapid growth and prevalence of social network applications (Apps) in recent years, understanding user engagement has become increasingly important, to provide useful insights for future App design and development. While several promising neural modeling approaches were recently pioneered for accurate user engagement prediction, their black-box designs are unfortunately limited in model explainability. In this paper, we study a novel problem of explainable user engagement prediction for social network Apps. First, we propose a flexible definition of user engagement for various business scenarios, based on future metric expectations. Next, we design an end-to-end neural framework, FATE, which incorporates three key factors that we identify to influence user engagement, namely friendships, user actions, and temporal dynamics to achieve explainable engagement predictions. FATE is based on a tensor-based graph neural network (GNN), LSTM and a mixture attention mechanism, which allows for (a) predictive explanations based on learned weights across different feature categories, (b) reduced network complexity, and (c) improved performance in both prediction accuracy and training/inference time. We conduct extensive experiments on two large-scale datasets from Snapchat, where FATE outperforms state-of-the-art approaches by 10% error and 20% runtime reduction. We also evaluate explanations from FATE, showing strong quantitative and qualitative performance.","[{""name"":""Xianfeng Tang"",""id"":""/profile/99659343290""},{""name"":""Yozen Liu"",""id"":""/profile/99659575245""},{""name"":""Neil Shah"",""id"":""/profile/99659365166""},{""name"":""Xiaolin Shi"",""id"":""/profile/81361595824""},{""name"":""Prasenjit Mitra"",""id"":""/profile/81100106069""},{""name"":""Suhang Wang"",""id"":""/profile/99659577116""},{""name"":""Xianfeng Tang"",""id"":""/profile/99659343290""},{""name"":""Yozen Liu"",""id"":""/profile/99659575245""},{""name"":""Neil Shah"",""id"":""/profile/99659365166""},{""name"":""Xiaolin Shi"",""id"":""/profile/81361595824""},{""name"":""Prasenjit Mitra"",""id"":""/profile/81100106069""},{""name"":""Suhang Wang"",""id"":""/profile/99659577116""}]","[""Tim Althoff and Jure Leskovec. 2015. Donor retention in online crowdfunding communities: A case study of donorschoose.org. In WWW. 34--44.Google Scholar"",""Wai-Ho Au, Keith CC Chan, and Xin Yao. 2003. A novel evolutionary data mining algorithm with applications to churn prediction. TEC, Vol. 7, 6 (2003), 532--545.Google ScholarDigital Library"",""Austin R Benson, Ravi Kumar, and Andrew Tomkins. 2016. Modeling user consumption sequences. In WWW. 519--529.Google Scholar"",""Tianqi Chen and Carlos Guestrin. 2016. Xgboost: A scalable tree boosting system. In KDD. ACM, 785--794.Google ScholarDigital Library"",""Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, and Cho-Jui Hsieh. 2019. Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks. In KDD .Google ScholarDigital Library"",""Heeyoul Choi, Kyunghyun Cho, and Yoshua Bengio. 2018. Fine-grained attention mechanism for neural machine translation. Neurocomputing, Vol. 284 (2018), 171--176.Google ScholarCross Ref"",""Ali Mamdouh Elkahky, Yang Song, and Xiaodong He. 2015. A multi-view deep learning approach for cross domain user modeling in recommendation systems. In WWW.Google Scholar"",""Leilani H Gilpin, David Bau, Ben Z Yuan, Ayesha Bajwa, Michael Specter, and Lalana Kagal. 2018. Explaining explanations: An overview of interpretability of machine learning. In DSAA. IEEE, 80--89.Google Scholar"",""Tian Guo, Tao Lin, and Nino Antulov-Fantulin. 2019. Exploring Interpretable LSTM Neural Networks over Multi-Variable Data. arXiv preprint 1905.12034 (2019).Google Scholar"",""Trevor Hastie, Robert Tibshirani, and Jerome Friedman. 2009. The elements of statistical learning: data mining, inference, and prediction. Springer Science \u0026 Business Media.Google Scholar"",""Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural computation, Vol. 9, 8 (1997), 1735--1780.Google Scholar"",""Wei Jin, Yao Ma, Xiaorui Liu, Xianfeng Tang, Suhang Wang, and Jiliang Tang. 2020. Graph Structure Learning for Robust Graph Neural Networks. arXiv preprint arXiv:2005.10203 (2020).Google Scholar"",""Komal Kapoor, Mingxuan Sun, Jaideep Srivastava, and Tao Ye. 2014. A hazard based approach to user return time prediction. In KDD. ACM, 1719--1728.Google Scholar"",""Jaya Kawale, Aditya Pal, and Jaideep Srivastava. 2009. Churn prediction in MMORPGs: A social influence based approach. In ICCSE, Vol. 4. IEEE, 423--428.Google ScholarDigital Library"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Thomas N Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In ICLR.Google Scholar"",""Rohan Kumar, Mohit Kumar, Neil Shah, and Christos Faloutsos. 2018. Did We Get It Right? Predicting Query Performance in E-commerce Search. arXiv preprint arXiv:1808.00239 (2018).Google Scholar"",""Hemank Lamba and Neil Shah. 2019. Modeling Dwell Time Engagement on Visual Multimedia. In KDD. 1104--1113.Google Scholar"",""Zhiyuan Lin, Tim Althoff, and Jure Leskovec. 2018. I'll Be Back: On the Multiple Lives of Users of a Mobile Activity Tracking Application. In WWW. 1501--1511.Google Scholar"",""Yozen Liu, Xiaolin Shi, Lucas Pierce, and Xiang Ren. 2019. Characterizing and Forecasting User Engagement with In-app Action Graph: A Case Study of Snapchat. In KDD.Google Scholar"",""Caroline Lo, Dan Frankowski, and Jure Leskovec. 2016. Understanding behaviors that lead to purchasing: A case study of pinterest. In KDD. ACM, 531--540.Google Scholar"",""Yao Ma, Suhang Wang, Charu C Aggarwal, and Jiliang Tang. 2019a. Graph convolutional networks with eigenpooling. In KDD .Google Scholar"",""Yao Ma, Suhang Wang, Chara C Aggarwal, Dawei Yin, and Jiliang Tang. 2019b. Multi-dimensional graph convolutional networks. In SDM.Google Scholar"",""Panagiotis Papapetrou and George Roussos. 2014. Social context discovery from temporal app use patterns. In Ubicomp. 397--402.Google Scholar"",""Phillip E Pope, Soheil Kolouri, Mohammad Rostami, Charles E Martin, and Heiko Hoffmann. 2019. Explainability Methods for Graph Convolutional Neural Networks. In CVPR. 10772--10781.Google Scholar"",""Yao Qin, Dongjin Song, Haifeng Chen, Wei Cheng, Guofei Jiang, and Garrison Cottrell. 2017. A dual-stage attention-based recurrent neural network for time series prediction. arXiv preprint arXiv:1704.02971 (2017).Google Scholar"",""Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. Why should i trust you?: Explaining the predictions of any classifier. In KDD. ACM, 1135--1144.Google Scholar"",""Gregor PJ Schmitz, Chris Aldrich, and Francois S Gouws. 1999. ANN-DT: an algorithm for extraction of decision trees from artificial neural networks. TNN, Vol. 10, 6 (1999), 1392--1401.Google ScholarDigital Library"",""Neil Shah. 2017. Flock: Combating astroturfing on livestreaming platforms. In WWW. 1083--1091.Google ScholarDigital Library"",""Neil Shah, Hemank Lamba, Alex Beutel, and Christos Faloutsos. 2017. The many faces of link fraud. In ICDM. IEEE, 1069--1074.Google Scholar"",""Kai Shu, Limeng Cui, Suhang Wang, Dongwon Lee, and Huan Liu. 2019. defend: Explainable fake news detection. In KDD.Google Scholar"",""Mani R Subramani and Balaji Rajagopalan. 2003. Knowledge-sharing and influence in online social networks via viral marketing. CACM (2003).Google Scholar"",""Xianfeng Tang, Yandong Li, Yiwei Sun, Huaxiu Yao, Prasenjit Mitra, and Suhang Wang. 2020a. Transferring Robustness for Graph Neural Network Against Poisoning Attacks. In WSDM.Google Scholar"",""Xianfeng Tang, Huaxiu Yao, Yiwei Sun, Charu Aggarwal, Prasenjit Mitra, and Suhang Wang. 2020b. Joint Modeling of Local and Global Temporal Dynamics for Multivariate Time Series Forecasting with Missing Values. (2020).Google Scholar"",""William Trouleau, Azin Ashkan, Weicong Ding, and Brian Eriksson. 2016. Just one more: Modeling binge watching behavior. In KDD. ACM, 1215--1224.Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In NeurIPS. 5998--6008.Google Scholar"",""Yanbo Xu, Siddharth Biswal, Shriprasad R Deshpande, Kevin O. Maher, and Jimeng Sun. 2018. Raim: Recurrent attentive and intensive model of multimodal patient monitoring data. In KDD. ACM, 2565--2573.Google ScholarDigital Library"",""Carl Yang, Xiaolin Shi, Luo Jie, and Jiawei Han. 2018. I Know You'll Be Back: Interpretable New User Clustering and Churn Prediction on a Mobile Social Application. In KDD. ACM, 914--922.Google Scholar"",""Jiang Yang, Xiao Wei, Mark S Ackerman, and Lada A Adamic. 2010. Activity lifespan: An analysis of user survival patterns in online knowledge sharing communities. In ICWSM .Google Scholar"",""Huaxiu Yao, Xianfeng Tang, Hua Wei, Guanjie Zheng, and Zhenhui Li. 2019. Revisiting spatial-temporal similarity: A deep learning framework for traffic prediction. In AAAI .Google Scholar"",""Rex Ying, Dylan Bourgeois, Jiaxuan You, Marinka Zitnik, and Jure Leskovec. 2019. GNN Explainer: A Tool for Post-hoc Explanation of Graph Neural Networks. In NeurIPS .Google Scholar"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale recommender systems. In KDD . 974--983.Google Scholar"",""Jan Ruben Zilke, Eneldo Loza Menc'ia, and Frederik Janssen. 2016. DeepRED--Rule extraction from deep neural networks. In ICDS. Springer, 457--473.Google Scholar""]"
https://doi.org/10.1145/3394486.3403277,Sub-Matrix Factorization for Real-Time Vote Prediction,"We address the problem of predicting aggregate vote outcomes (e.g., national) from partial outcomes (e.g., regional) that are revealed sequentially. We combine matrix factorization techniques and generalized linear models (GLMs) to obtain a flexible, efficient, and accurate algorithm. This algorithm works in two stages: First, it learns representations of the regions from high-dimensional historical data. Second, it uses these representations to fit a GLM to the partially observed results and to predict unobserved results. We show experimentally that our algorithm is able to accurately predict the outcomes of Swiss referenda, U.S. presidential elections, and German legislative elections. We also explore the regional representations in terms of ideological and cultural patterns. Finally, we deploy an online Web platform (www.predikon.ch) to provide real-time vote predictions in Switzerland and a data visualization tool to explore voting behavior. A by-product is a dataset of sequential vote results for 330 referenda and 2196 Swiss municipalities.","[{""name"":""Alexander Immer"",""id"":""/profile/99659573274""},{""name"":""Victor Kristof"",""id"":""/profile/99659287136""},{""name"":""Matthias Grossglauser"",""id"":""/profile/81100375411""},{""name"":""Patrick Thiran"",""id"":""/profile/81100054475""},{""name"":""Alexander Immer"",""id"":""/profile/99659573274""},{""name"":""Victor Kristof"",""id"":""/profile/99659287136""},{""name"":""Matthias Grossglauser"",""id"":""/profile/81100375411""},{""name"":""Patrick Thiran"",""id"":""/profile/81100054475""}]","[""R. Bamler and S. Mandt. Dynamic word embeddings. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages 380--389, 2017.Google ScholarDigital Library"",""L. H. Bean. How to predict elections. 1948.Google Scholar"",""E. Belanger. Finding and using empirical data for vote and popularity functions in France. French Politics, 2 (2): 235--244, 2004.Google ScholarCross Ref"",""R. M. Bell and Y. Koren. Scalable collaborative filtering with jointly derived neighborhood interpolation weights. In Seventh IEEE International Conference on Data Mining (ICDM 2007), pages 43--52. IEEE, 2007.Google ScholarDigital Library"",""D. Bertsimas, C. Pawlowski, and Y. D. Zhuo. From predictive methods to missing data imputation: an optimization approach. The Journal of Machine Learning Research, 18 (1): 7133--7171, 2017.Google ScholarDigital Library"",""M. Blumenthal. The poblano model, 2008. URL https://web.archive.org/web/20090414152429/http://www.nationaljournal.com/njonline/mp_20080507_8254.php. Accessed: 2020-02-13.Google Scholar"",""S. Boyd and L. Vandenberghe. Convex optimization. Cambridge University Press, 2004.Google ScholarDigital Library"",""M. Brand. Incremental singular value decomposition of uncertain data with missing values. In European Conference on Computer Vision, pages 707--720. Springer, 2002.Google ScholarDigital Library"",""M. Brand. Fast online svd revisions for lightweight recommender systems. In Proceedings of the 2003 SIAM International Conference on Data Mining, pages 37--46. SIAM, 2003.Google ScholarCross Ref"",""M. Choy, M. Cheong, M. N. Laik, and K. P. Shung. US presidential election 2012 prediction using census corrected Twitter model. arXiv preprint arXiv:1211.0938, 2012.Google Scholar"",""P. Diaconis and R. L. Graham. Spearman's footrule as a measure of disarray. Journal of the Royal Statistical Society: Series B (Methodological), 39 (2): 262--268, 1977.Google ScholarCross Ref"",""N. Dwi Prasetyo and C. Hauff. Twitter-based election prediction in the developing world. In Proceedings of the 26th ACM Conference on Hypertext \u0026 Social Media, pages 149--158, 2015.Google ScholarDigital Library"",""C. Eckart and G. Young. The approximation of one matrix by another of lower rank. Psychometrika, 1 (3), 1936.Google Scholar"",""V. Etter, J. Herzen, M. Grossglauser, and P. Thiran. Mining democracy. In Proceedings of the second ACM Conference on Online Social Networks, 2014.Google ScholarDigital Library"",""V. Etter, M. E. Khan, M. Grossglauser, and P. Thiran. Online collaborative prediction of regional vote results. In 2016 IEEE International Conference on Data Science and Advanced Analytics (DSAA), 2016.Google ScholarCross Ref"",""F. Franch. (wisdom of the crowds) 2: 2010 uk election prediction with social media. Journal of Information Technology \u0026 Politics, 10 (1): 57--71, 2013.Google ScholarCross Ref"",""T. Hastie, R. Tibshirani, G. Sherlock, M. Eisen, P. Brown, and D. Botstein. Imputing missing data for gene expression arrays. 1999.Google Scholar"",""R. Kennedy, S. Wojcik, and D. Lazer. Improving election prediction internationally. Science, 355 (6324): 515--520, 2017.Google ScholarCross Ref"",""Y. Koren, R. Bell, and C. Volinsky. Matrix factorization techniques for recommender systems. Computer, 42 (8): 30--37, 2009.Google ScholarDigital Library"",""J. B. Kristensen, T. Albrechtsen, E. Dahl-Nielsen, M. Jensen, M. Skovrind, and T. Bornakke. Parsimonious data: How a single Facebook like predicts voting behavior in multiparty systems. PloS one, 12 (9), 2017.Google Scholar"",""M. S. Lewis-Beck. Election forecasting: Principles and practice. The British Journal of Politics and International Relations, 7 (2): 145--164, 2005.Google ScholarCross Ref"",""L. v. d. Maaten and G. Hinton. Visualizing data using t-SNE. Journal of machine learning research, 9 (Nov): 2579--2605, 2008.Google Scholar"",""MIT Election Data and Science Lab. U.S. President 1976--2016, 2017. URL https://doi.org/10.7910/DVN/42MVDX. Accessed: 2020-02-06.Google Scholar"",""K. P. Murphy. Machine learning: a probabilistic perspective. The MIT Press, 2012.Google ScholarDigital Library"",""Norwegian Centre for Research Data. German parliamentary elections, 2020. URL https://nsd.no/european_election_database/country/germany/parliamentary_elections.html. Accessed: 2020-06-16.Google Scholar"",""J. Ramteke, S. Shah, D. Godhia, and A. Shaikh. Election result prediction using Twitter sentiment analysis. In 2016 international conference on inventive computation technologies (ICICT), volume 1, pages 1--5. IEEE, 2016.Google ScholarCross Ref"",""S. E. Rigdon, S. H. Jacobson, W. K. Tam Cho, E. C. Sewell, and C. J. Rigdon. A Bayesian prediction model for the US presidential election. American Politics Research, 37 (4): 700--724, 2009.Google ScholarCross Ref"",""N. Silver. Pollster ratings v3.0, 2008. URL https://fivethirtyeight.com/features/pollster-ratings-v30/. Accessed: 2020-02--13.Google Scholar"",""The Swiss Confederation. Democracy, 2019 a. URL https://www.ch.ch/en/demokratie/. Accessed: 2020-02-04.Google Scholar"",""The Swiss Confederation. Popular vote, 2019 b . URL https://www.admin.ch/gov/en/start/documentation/votes.html. Accessed: 2020-02-04.Google Scholar"",""The Swiss Federal Statistical Office (via opendata.swiss). Real-time data on referenda on vote days, 2020. URL https://opendata.swiss/en/dataset/echtzeitdaten-am-abstimmungstag-zu-eidgenoessischen-abstimmungsvorlagen. Accessed: 2020-02-11.Google Scholar"",""O. Troyanskaya, M. Cantor, G. Sherlock, P. Brown, T. Hastie, R. Tibshirani, D. Botstein, and R. B. Altman. Missing value estimation methods for DNA microarrays. Bioinformatics, 17 (6): 520--525, 2001.Google ScholarCross Ref"",""A. Tumasjan, T. O. Sprenger, P. G. Sandner, and I. M. Welpe. Election forecasts with Twitter: How 140 characters reflect the political landscape. Social science computer review, 29 (4): 402--418, 2011.Google Scholar"",""T. Vepsäläinen, H. Li, and R. Suomi. Facebook likes and public opinion: Predicting the 2015 Finnish parliamentary elections. Government Information Quarterly, 34 (3): 524--532, 2017.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403278,Temporal-Contextual Recommendation in Real-Time,"Personalized real-time recommendation has had a profound impact on retail, media, entertainment and other industries. However, developing recommender systems for every use case is costly, time consuming and resource-intensive. To fill this gap, we present a black-box recommender system that can adapt to a diverse set of scenarios without the need for manual tuning. We build on techniques that go beyond simple matrix factorization to incorporate important new sources of information: the temporal order of events [Hidasi et al., 2015], contextual information to bootstrap cold-start users, metadata information about items [Rendle 2012] and the additional information surrounding each event. Additionally, we address two fundamental challenges when putting recommender systems in the real-world: how to efficiently train them with even millions of unique items and how to cope with changing item popularity trends [Wu et al., 2017]. We introduce a compact model, which we call hierarchical recurrent network with meta data (HRNN-meta) to address the real-time and diverse metadata needs; we further provide efficient training techniques via importance sampling that can scale to millions of items with little loss in performance. We report significant improvements on a wide range of real-world datasets and provide intuition into model capabilities with synthetic experiments. Parts of HRNN-meta have been deployed in production at scale for customers to use at Amazon Web Services and serves as the underlying recommender engine for thousands of websites.","[{""name"":""Yifei Ma"",""id"":""/profile/99659573003""},{""name"":""Balakrishnan (Murali) Narayanaswamy"",""id"":""/profile/81461658875""},{""name"":""Haibin Lin"",""id"":""/profile/99659573017""},{""name"":""Hao Ding"",""id"":""/profile/99659574375""},{""name"":""Yifei Ma"",""id"":""/profile/99659573003""},{""name"":""Balakrishnan (Murali) Narayanaswamy"",""id"":""/profile/81461658875""},{""name"":""Haibin Lin"",""id"":""/profile/99659573017""},{""name"":""Hao Ding"",""id"":""/profile/99659574375""}]","[""Léon Bottou, Jonas Peters, Joaquin Qui nonero-Candela, Denis X Charles, D Max Chickering, Elon Portugaly, Dipankar Ray, Patrice Simard, and Ed Snelson. 2013. Counterfactual reasoning and learning systems: The example of computational advertising. The Journal of Machine Learning Research, Vol. 14, 1 (2013), 3207--3260.Google ScholarDigital Library"",""Peter F Brown, Vincent J Della Pietra, Robert L Mercer, Stephen A Della Pietra, and Jennifer C Lai. 1992. An estimate of an upper bound for the entropy of English. Computational Linguistics, Vol. 18, 1 (1992), 31--40.Google ScholarDigital Library"",""Minmin Chen, Alex Beutel, Paul Covington, Sagar Jain, Francois Belletti, and Ed H Chi. 2019. Top-K Off-Policy Correction for a REINFORCE Recommender System. In Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining. ACM, 456--464.Google ScholarDigital Library"",""Kyunghyun Cho, Bart van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning Phrase Representations using RNN Encoder--Decoder for Statistical Machine Translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP).Google ScholarCross Ref"",""Tim Donkers, Benedikt Loepp, and Jürgen Ziegler. 2017. Sequential user-based recurrent neural network recommendations. In Proceedings of the Eleventh ACM Conference on Recommender Systems. ACM, 152--160.Google ScholarDigital Library"",""Ian J Goodfellow. 2014. On distinguishability criteria for estimating generative models. arXiv preprint arXiv:1412.6515 (2014).Google Scholar"",""Jiafeng Guo, Yixing Fan, Qingyao Ai, and W Bruce Croft. 2016. A deep relevance matching model for ad-hoc retrieval. In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management. ACM, 55--64.Google ScholarDigital Library"",""Michael Gutmann and Aapo Hyvärinen. 2010. Noise-contrastive estimation: A new estimation principle for unnormalized statistical models. In Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics.Google Scholar"",""F Maxwell Harper and Joseph A Konstan. 2016. The MovieLens datasets: History and context. ACM Transactions on Interactive Intelligent Systems (TIIS) (2016).Google Scholar"",""Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural Collaborative Filtering. In Proceedings of the 26th International Conference on World Wide Web. Perth Australia, 173--182.Google ScholarDigital Library"",""Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and D Tikk. 2016. Session-based recommendations with recurrent neural networks. In 4th International Conference on Learning Representations, ICLR 2016.Google Scholar"",""Sébastien Jean, Kyunghyun Cho, Roland Memisevic, and Yoshua Bengio. 2015. On Using Very Large Target Vocabulary for Neural Machine Translation. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics.Google ScholarCross Ref"",""Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. 2016. Exploring the limits of language modeling. arXiv preprint arXiv:1602.02410 (2016).Google Scholar"",""Yuchin Juan, Yong Zhuang, Wei-Sheng Chin, and Chih-Jen Lin. 2016. Field-aware Factorization Machines for CTR Prediction. In Proceedings of the 10th ACM Conference on Recommender Systems. ACM, Boston Massachusetts USA, 43--50.Google ScholarDigital Library"",""Jens Kober and Jan R Peters. 2009. Policy search for motor primitives in robotics. In Advances in neural information processing systems. 849--856.Google Scholar"",""Yehuda Koren. 2009. Collaborative filtering with temporal dynamics. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 447--456.Google ScholarDigital Library"",""Yang Li, Nan Du, and Samy Bengio. 2017. Time-dependent representation for neural event sequence prediction. arXiv preprint arXiv:1708.00065 (2017).Google Scholar"",""Yifei Ma, Yu-Xiang Wang, and Balakrishnan Narayanaswamy. 2019. Imitation-Regularized Offline Learning. In The 22nd International Conference on Artificial Intelligence and Statistics. 2956--2965.Google Scholar"",""Andriy Mnih and Ruslan R Salakhutdinov. 2008. Probabilistic matrix factorization. In Advances in neural information processing systems. 1257--1264.Google Scholar"",""Massimo Quadrana, Alexandros Karatzoglou, Balázs Hidasi, and Paolo Cremonesi. 2017. Personalizing session-based recommendations with hierarchical recurrent neural networks. In Proceedings of the Eleventh ACM Conference on Recommender Systems. ACM, 130--137.Google ScholarDigital Library"",""Steffen Rendle. 2010. Factorization machines. In Data Mining (ICDM), 2010 IEEE 10th International Conference on. IEEE, 995--1000.Google ScholarDigital Library"",""Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian personalized ranking from implicit feedback. In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence. 452--461.Google ScholarDigital Library"",""Massimiliano Ruocco, Ole Steinar Lillestøl Skrede, and Helge Langseth. 2017. Inter-session modeling for session-based recommendation. In Proceedings of the 2nd Workshop on Deep Learning for Recommender Systems. ACM, 24--31.Google ScholarDigital Library"",""Suvash Sedhain, Aditya Krishna Menon, Scott Sanner, and Lexing Xie. 2015. AutoRec: Autoencoders meet collaborative filtering. In Proceedings of the 24th International Conference on World Wide Web. ACM, 111--112.Google ScholarDigital Library"",""Guy Shani and Asela Gunawardana. 2011. Evaluating recommendation systems. In Recommender systems handbook. Springer, 257--297.Google Scholar"",""Yue Shi, Martha Larson, and Alan Hanjalic. 2014. Collaborative filtering beyond the user-item matrix: A survey of the state of the art and future challenges. ACM Computing Surveys (CSUR), Vol. 47, 1 (2014), 3.Google ScholarDigital Library"",""Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: a simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research, Vol. 15, 1 (2014), 1929--1958.Google ScholarDigital Library"",""Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Sequence to sequence learning with neural networks. In Advances in neural information processing systems.Google Scholar"",""Adith Swaminathan and Thorsten Joachims. 2015. Counterfactual risk minimization: Learning from logged bandit feedback. In International Conference on Machine Learning. 814--823.Google ScholarDigital Library"",""Alastair J Walker. 1974. New fast method for generating discrete random numbers with arbitrary frequency distributions. Electronics Letters, Vol. 10, 8 (1974), 127--128.Google ScholarCross Ref"",""Jun Wang, Lantao Yu, Weinan Zhang, Yu Gong, Yinghui Xu, Benyou Wang, Peng Zhang, and Dell Zhang. 2017c. IRGAN: A minimax game for unifying generative and discriminative information retrieval models. In Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval. ACM, 515--524.Google ScholarDigital Library"",""Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. 2017b. Deep \u0026 cross network for ad click predictions. In Proceedings of the ADKDD'17. ACM, 12.Google ScholarDigital Library"",""Yu-Xiang Wang, Alekh Agarwal, and Miroslav Dudik. 2017a. Optimal and Adaptive Off-policy Evaluation in Contextual Bandits. In International Conference on Machine Learning. 3589--3597.Google Scholar"",""Chao-Yuan Wu, Amr Ahmed, Alex Beutel, Alexander J Smola, and How Jing. 2017. Recurrent recommender networks. In Proceedings of the tenth ACM international conference on web search and data mining. ACM, 495--503.Google ScholarDigital Library"",""Yuan Zhang, Dong Wang, and Yan Zhang. 2019. Neural IR Meets Graph Embedding: A Ranking Model for Product Search. In The World Wide Web Conference. ACM, 2390--2400.Google Scholar"",""Han Zhu, Xiang Li, Pengye Zhang, Guozheng Li, Jie He, Han Li, and Kun Gai. 2018. Learning Tree-based Deep Model for Recommender Systems. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 1079--1088.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403279,OptMatch: Optimized Matchmaking via Modeling the High-Order Interactions on the Arena,"Matchmaking is a core problem for the e-sports and online games, which determines the player satisfaction and further influences the life cycle of the gaming products. Most of matchmaking systems take the form of grouping the queuing players into two opposing teams by following certain rules. The design and implementation of matchmaking systems are usually product-specific and labor-intensive.This paper proposes a two-stage data-driven matchmaking framework (namely OptMatch), which is applicable to most of gaming products and has the minimal product knowledge required. OptMatch contains an offline learning stage and an online planning stage. The offline learning stage includes (1) relationship mining modules to learn the low-dimensional representations of individuals by capturing the high-order inter-personal interactions, and (2) a neural network to incorporate the team-up effect and predict the match outcomes. The online planning stage optimizes the gross player utilities (i.e., satisfaction) during the matchmaking process, by leveraging the learned representations and predictive model.Quantitative evaluations on four real-world datasets and an online experiment on Fever Basketball game are conducted to empirically demonstrate the effectiveness of OptMatch.","[{""name"":""Linxia Gong"",""id"":""/profile/99659286675""},{""name"":""Xiaochuan Feng"",""id"":""/profile/99659574255""},{""name"":""Dezhi Ye"",""id"":""/profile/99659478925""},{""name"":""Hao Li"",""id"":""/profile/99659573473""},{""name"":""Runze Wu"",""id"":""/profile/99659454827""},{""name"":""Jianrong Tao"",""id"":""/profile/99659287469""},{""name"":""Changjie Fan"",""id"":""/profile/99659287356""},{""name"":""Peng Cui"",""id"":""/profile/81413596063""},{""name"":""Linxia Gong"",""id"":""/profile/99659286675""},{""name"":""Xiaochuan Feng"",""id"":""/profile/99659574255""},{""name"":""Dezhi Ye"",""id"":""/profile/99659478925""},{""name"":""Hao Li"",""id"":""/profile/99659573473""},{""name"":""Runze Wu"",""id"":""/profile/99659454827""},{""name"":""Jianrong Tao"",""id"":""/profile/99659287469""},{""name"":""Changjie Fan"",""id"":""/profile/99659287356""},{""name"":""Peng Cui"",""id"":""/profile/81413596063""}]","[""Ralph Allan Bradley and Milton E Terry. 1952. Rank analysis of incomplete block designs: I. The method of paired comparisons. Biometrika, Vol. 39, 3/4 (1952), 324--345.Google ScholarCross Ref"",""Shuo Chen and Thorsten Joachims. 2016a. Modeling intransitivity in matchup and comparison data. In Proceedings of the ninth acm international conference on web search and data mining. ACM, 227--236.Google ScholarDigital Library"",""Shuo Chen and Thorsten Joachims. 2016b. Predicting matchups and preferences in context. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 775--784.Google ScholarDigital Library"",""Olivier Delalleau, Emile Contal, Eric Thibodeau-Laufer, Raul Chandias Ferrari, Yoshua Bengio, and Frank Zhang. 2012. Beyond skill rating: Advanced matchmaking in ghost recon online. IEEE Transactions on Computational Intelligence and AI in Games, Vol. 4, 3 (2012), 167--177.Google ScholarCross Ref"",""Colin DeLong, Nishith Pathak, Kendrick Erickson, Eric Perrino, Kyong Shim, and Jaideep Srivastava. 2011. TeamSkill: modeling team chemistry in online multi-player games. In Pacific-Asia Conference on Knowledge Discovery and Data Mining. Springer, 519--531.Google ScholarCross Ref"",""Yuxiao Dong, Nitesh V Chawla, and Ananthram Swami. 2017. metapath2vec: Scalable representation learning for heterogeneous networks. In Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. ACM, 135--144.Google ScholarDigital Library"",""Arpad E Elo. 1978. The rating of chessplayers, past and present. Arco Pub.Google Scholar"",""Mark E Glickman. 1999. Parameter estimation in large dynamic paired comparison experiments. Journal of the Royal Statistical Society: Series C (Applied Statistics), Vol. 48, 3 (1999), 377--394.Google ScholarCross Ref"",""Xavier Glorot, Antoine Bordes, and Yoshua Bengio. 2011. Deep sparse rectifier neural networks. In Proceedings of the fourteenth international conference on artificial intelligence and statistics. 315--323.Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 855--864.Google ScholarDigital Library"",""Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: a factorization-machine based neural network for CTR prediction. arXiv preprint arXiv:1703.04247 (2017).Google Scholar"",""Ralf Herbrich, Tom Minka, and Thore Graepel. 2007. TrueSkill?: a Bayesian skill rating system. In Advances in neural information processing systems. 569--576.Google Scholar"",""Tzu-Kuo Huang, Chih-Jen Lin, and Ruby C Weng. 2008. Ranking individuals by group comparisons. Journal of Machine Learning Research, Vol. 9, Oct (2008), 2187--2216.Google Scholar"",""Junghwan Kim, Haekyu Park, Ji-Eun Lee, and U Kang. 2018. Side: Representation learning in signed directed networks. In Proceedings of the 2018 World Wide Web Conference. 509--518.Google ScholarDigital Library"",""Young Ji Kim, David Engel, Anita Williams Woolley, Jeffrey Yu-Ting Lin, Naomi McArthur, and Thomas W Malone. 2017. What makes a strong team?: Using collective intelligence to predict team performance in League of Legends. In Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing. ACM, 2316--2329.Google ScholarDigital Library"",""Yao Li, Minhao Cheng, Kevin Fujii, Fushing Hsieh, and Cho-Jui Hsieh. 2018. Learning from group comparisons: exploiting higher order interactions. In Advances in Neural Information Processing Systems. 4981--4990.Google Scholar"",""Rahul Makhijani and Johan Ugander. 2019. Parametric Models for Intransitivity in Pairwise Rankings. In The World Wide Web Conference. ACM, 3056--3062.Google Scholar"",""Joshua E Menke, C Shane Reese, and Tony R Martinez. 2007. Hierarchical models for estimating individual ratings from group competitions. In American Statistical Association. Citeseer.Google Scholar"",""Tom Minka, Ryan Cleven, and Yordan Zaykov. 2018. Trueskill 2: An improved bayesian skill rating system. Tech. Rep. (2018).Google Scholar"",""Andrew Y Ng and Michael I Jordan. 2002. On discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes. In Advances in neural information processing systems. 841--848.Google Scholar"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 701--710.Google ScholarDigital Library"",""Steffen Rendle. 2010. Factorization machines. In 2010 IEEE International Conference on Data Mining. IEEE, 995--1000.Google ScholarDigital Library"",""Leonardo FR Ribeiro, Pedro HP Saverese, and Daniel R Figueiredo. 2017. struc2vec: Learning node representations from structural identity. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 385--394.Google ScholarDigital Library"",""Ilya O Ryzhov, Awais Tariq, and Warren B Powell. 2011. May the best man win: simulation optimization for match-making in e-sports. In Proceedings of the 2011 Winter Simulation Conference (WSC). IEEE, 4234--4245.Google ScholarCross Ref"",""Anna Sapienza, Palash Goyal, and Emilio Ferrara. 2018. Deep Neural Networks for Optimal Team Composition. arXiv preprint arXiv:1805.03285 (2018).Google Scholar"",""Aleksandr Semenov, Peter Romov, Sergey Korolev, Daniil Yashkov, and Kirill Neklyudov. 2016. Performance of machine learning algorithms in predicting game outcome from drafts in Dota 2. In International Conference on Analysis of Images, Social Networks and Texts. Springer, 26--37.Google Scholar"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. In Proceedings of the 24th international conference on world wide web. International World Wide Web Conferences Steering Committee, 1067--1077.Google ScholarDigital Library"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998--6008.Google Scholar"",""Daixin Wang, Peng Cui, and Wenwu Zhu. 2016. Structural deep network embedding. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 1225--1234.Google ScholarDigital Library"",""Mason Wright and Yevgeniy Vorobeychik. 2015. Mechanism design for team formation. In Twenty-Ninth AAAI Conference on Artificial Intelligence.Google ScholarDigital Library"",""Lei Zhang, Jun Wu, Zhong-Cun Wang, and Chong-Jun Wang. 2010. A factor-based model for context-sensitive skill rating systems. In 2010 22nd IEEE International Conference on Tools with Artificial Intelligence, Vol. 2. IEEE, 249--255.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403280,PinnerSage: Multi-Modal User Embedding Framework for Recommendations at Pinterest,"Latent user representations are widely adopted in the tech industry for powering personalized recommender systems. Most prior work infers a single high dimensional embedding to represent a user, which is a good starting point but falls short in delivering a full understanding of the user's interests. In this work, we introduce PinnerSage, an end-to-end recommender system that represents each user via multi-modal embeddings and leverages this rich representation of users to provides high quality personalized recommendations. PinnerSage achieves this by clustering users' actions into conceptually coherent clusters with the help of a hierarchical clustering method (Ward) and summarizes the clusters via representative pins (Medoids) for efficiency and interpretability. PinnerSage is deployed in production at Pinterest and we outline the several design decisions that makes it run seamlessly at a very large scale. We conduct several offline and online A/B experiments to show that our method significantly outperforms single embedding methods.","[{""name"":""Aditya Pal"",""id"":""/profile/99659573511""},{""name"":""Chantat Eksombatchai"",""id"":""/profile/83458617757""},{""name"":""Yitong Zhou"",""id"":""/profile/99659573326""},{""name"":""Bo Zhao"",""id"":""/profile/99659574873""},{""name"":""Charles Rosenberg"",""id"":""/profile/99659455355""},{""name"":""Jure Leskovec"",""id"":""/profile/81367595814""},{""name"":""Aditya Pal"",""id"":""/profile/99659573511""},{""name"":""Chantat Eksombatchai"",""id"":""/profile/83458617757""},{""name"":""Yitong Zhou"",""id"":""/profile/99659573326""},{""name"":""Bo Zhao"",""id"":""/profile/99659574873""},{""name"":""Charles Rosenberg"",""id"":""/profile/99659455355""},{""name"":""Jure Leskovec"",""id"":""/profile/81367595814""}]","[""V. Athitsos, M. Potamias, P. Papapetrou, and G. Kollios. Nearest neighbor retrieval using distance-based hashing. In ICDE, 2008.Google ScholarDigital Library"",""A. Babenko and V. Lempitsky. Efficient indexing of billion-scale datasets of deep descriptors. In CVPR, 2016.Google Scholar"",""L. Baltrunas and X. Amatriain. Towards time-dependant recommendation based on implicit feedback. In Workshop on context-aware recommender systems, 2009.Google Scholar"",""O. Barkan and N. Koenigstein. ITEM2VEC: neural item embedding for collaborative filtering. In Workshop on Machine Learning for Signal Processing, 2016.Google ScholarCross Ref"",""J. G. Carbonell and J. Goldstein. The use of mmr, diversity-based reranking for reordering documents and producing summaries. In SIGIR, 1998.Google ScholarDigital Library"",""H. Cheng, L. Koc, J. Harmsen, T. Shaked, T. Chandra, H. Aradhye, G. Anderson, G. Corrado, W. Chai, M. Ispir, R. Anil, Z. Haque, L. Hong, V. Jain, X. Liu, and H. Shah. Wide \u0026 deep learning for recommender systems. In [email protected], 2016.Google Scholar"",""P. Covington, J. Adams, and E. Sargin. Deep neural networks for youtube recommendations. In RecSys, pages 191--198, 2016.Google ScholarDigital Library"",""D. Defays. An efficient algorithm for a complete link method. The Computer Journal, 20(4):364--366, 01 1977.Google ScholarCross Ref"",""C. Eksombatchai, P. Jindal, J. Z. Liu, Y. Liu, R. Sharma, C. Sugnet, M. Ulrich, and J. Leskovec. Pixie: A system for recommending 3 billion items to 200 million users in real-time. In WWW, 2018.Google Scholar"",""A. Epasto and B. Perozzi. Is a single embedding enough? learning node representations that capture multiple social contexts. In WWW, 2019.Google Scholar"",""M. Grbovic and H. Cheng. Real-time personalization using embeddings for search ranking at airbnb. In KDD, 2018.Google ScholarDigital Library"",""J. Johnson, M. Douze, and H. Jé gou. Billion-scale similarity search with gpus. CoRR, abs/1702.08734, 2017.Google Scholar"",""K. Kenthapadi, B. Le, and G. Venkataraman. Personalized job recommendation system at linkedin: Practical challenges and lessons learned. In RecSys, 2017.Google ScholarDigital Library"",""G. N. Lance and W. T. Williams. A general theory of classificatory sorting strategies 1. Hierarchical systems. Computer Journal, 9(4):373--380, Feb. 1967.Google ScholarCross Ref"",""G. Linden, B. Smith, and J. York. Amazon.com recommendations: Item-to-item collaborative filtering. IEEE Internet computing, 7(1):76--80, 2003.Google ScholarDigital Library"",""N. Liu, Q. Tan, Y. Li, H. Yang, J. Zhou, and X. Hu. Is a single vector enough?: Exploring node polysemy for network embedding. In KDD, pages 932--940, 2019.Google ScholarDigital Library"",""Y. A. Malkov and D. A. Yashunin. Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs. PAMI, 2018.Google Scholar"",""T. Mikolov, I. Sutskever, K. Chen, G. Corrado, and J. Dean. Distributed representations of words and phrases and their compositionality. In NIPS, 2013.Google ScholarDigital Library"",""S. Okura, Y. Tagami, S. Ono, and A. Tajima. Embedding-based news recommendation for millions of users. In KDD, 2017.Google ScholarDigital Library"",""B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. Item-based collaborative filtering recommendation algorithms. In WWW, page 285--295, 2001.Google Scholar"",""K. Terasawa and Y. Tanaka. Spherical lsh for approximate nearest neighbor search on unit hypersphere. In Workshop on Algorithms and Data Structures, 2007.Google ScholarDigital Library"",""D. Wang, S. Deng, X. Zhang, and G. Xu. Learning to embed music and metadata for context-aware music recommendation. World Wide Web, 21(5):1399--1423, 2018.Google ScholarDigital Library"",""J. Wang, P. Huang, H. Zhao, Z. Zhang, B. Zhao, and D. L. Lee. Billion-scale commodity embedding for e-commerce recommendation in alibaba. In KDD, 2018.Google ScholarDigital Library"",""J. J. H. Ward. Hierarchical grouping to optimize an objective function. 1963.Google Scholar"",""J. Weston, R. J. Weiss, and H. Yee. Nonlinear latent factorization by embedding multiple user interests. In RecSys, pages 65--68, 2013.Google ScholarDigital Library"",""L. Y. Wu, A. Fisch, S. Chopra, K. Adams, A. Bordes, and J. Weston. Starspace: Embed all the things! In AAAI, 2018.Google Scholar"",""R. Ying, R. He, K. Chen, P. Eksombatchai, W. L. Hamilton, and J. Leskovec. Graph convolutional neural networks for web-scale recommender systems. In KDD, 2018.Google ScholarDigital Library"",""J. You, Y. Wang, A. Pal, P. Eksombatchai, C. Rosenberg, and J. Leskovec. Hierarchical temporal convolutional networks for dynamic recommender systems. In WWW, 2019.Google Scholar"",""N. Zhang, S. Deng, Z. Sun, X. Chen, W. Zhang, and H. Chen. Attention-based capsule networks with dynamic routing for relation extraction. arXiv preprint arXiv:1812.11321, 2018.Google Scholar"",""X. Zhao, R. Louca, D. Hu, and L. Hong. Learning item-interaction embeddings for user recommendations. 2018.Google Scholar""]"
https://doi.org/10.1145/3394486.3403281,"Polestar: An Intelligent, Efficient and National-Wide Public Transportation Routing Engine","Public transportation plays a critical role in people's daily life. It has been proven that public transportation is more environmentally sustainable, efficient, and economical than any other forms of travel. However, due to the increasing expansion of transportation networks and more complex travel situations, people are having difficulties in efficiently finding the most preferred route from one place to another through public transportation systems. To this end, in this paper, we present Polestar, a data-driven engine for intelligent and efficient public transportation routing.Specifically, we first propose a novel Public Transportation Graph (PTG) to model public transportation system in terms of various travel costs, such as time or distance. Then, we introduce a general route search algorithm coupled with an efficient station binding method for efficient route candidate generation. After that, we propose a two-pass route candidate ranking module to capture user preferences under dynamic travel situations. Finally, experiments on two real-world data sets demonstrate the advantages of Polestar in terms of both efficiency and effectivenes Indeed, in early 2019, Polestar has been deployed on Baidu Maps, one of the world's largest map services. To date, Polestar is servicing over 330 cities, answers over a hundred millions of queries each day, and achieves substantial improvement of user click ratio.","[{""name"":""Hao Liu"",""id"":""/profile/99659566196""},{""name"":""Ying Li"",""id"":""/profile/99659455657""},{""name"":""Yanjie Fu"",""id"":""/profile/82658841557""},{""name"":""Huaibo Mei"",""id"":""/profile/99659574256""},{""name"":""Jingbo Zhou"",""id"":""/profile/99659520172""},{""name"":""Xu Ma"",""id"":""/profile/99659287256""},{""name"":""Hui Xiong"",""id"":""/profile/81451596433""},{""name"":""Hao Liu"",""id"":""/profile/99659566196""},{""name"":""Ying Li"",""id"":""/profile/99659455657""},{""name"":""Yanjie Fu"",""id"":""/profile/82658841557""},{""name"":""Huaibo Mei"",""id"":""/profile/99659574256""},{""name"":""Jingbo Zhou"",""id"":""/profile/99659520172""},{""name"":""Xu Ma"",""id"":""/profile/99659287256""},{""name"":""Hui Xiong"",""id"":""/profile/81451596433""}]","[""Ittai Abraham, Daniel Delling, Andrew V Goldberg, and Renato F Werneck. 2012. Hierarchical hub labelings for shortest paths. In European Symposium on Algorithms. 24--35.Google ScholarDigital Library"",""Neha Arora, James Cook, Ravi Kumar, Ivan Kuznetsov, Yechen Li, Huai-Jen Liang, Andrew Miller, Andrew Tomkins, Iveel Tsogsuren, and Yi Wang. 2019. Hard to Park?: Estimating Parking Difficulty at Scale. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 2296--2304.Google ScholarDigital Library"",""Gabriela Beir ao and JA Sarsfield Cabral. 2007. Understanding attitudes towards public transport and private car: A qualitative study. Transport policy, Vol. 14, 6 (2007), 478--489.Google Scholar"",""Tianqi Chen and Carlos Guestrin. 2016. Xgboost: A scalable tree boosting system. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 785--794.Google ScholarDigital Library"",""Zaiben Chen, Heng Tao Shen, and Xiaofang Zhou. 2011. Discovering Popular Routes from Trajectories. In Proceedings of the 27th International Conference on Data Engineering. 900--911.Google ScholarDigital Library"",""Jian Dai, Bin Yang, Chenjuan Guo, and Zhiming Ding. 2015. Personalized route recommendation using big trajectory data. In Proceedings of the 31st International Conference on Data Engineering. 543--554.Google ScholarCross Ref"",""Daniel Delling, Julian Dibbelt, Thomas Pajor, Dorothea Wagner, and Renato F Werneck. 2012. Computing and evaluating multimodal journeys. KIT, Fakultät für Informatik.Google Scholar"",""Daniel Delling, Julian Dibbelt, Thomas Pajor, and Renato F Werneck. 2015. Public transit labeling. In International Symposium on Experimental Algorithms. 273--285.Google ScholarDigital Library"",""Julian Dibbelt et almbox. 2016. Engineering Algorithms for Route Planning in Multimodal Transportation Networks. Transportation (2016).Google Scholar"",""Alexandros Efentakis. 2016. Scalable Public Transportation Queries on the Database. In EDBT. 527--538.Google Scholar"",""Jerome H Friedman. 2001. Greedy function approximation: a gradient boosting machine. Annals of statistics (2001), 1189--1232.Google Scholar"",""Stefan Funke and Sabine Storandt. 2015. Personalized route planning in road networks. In Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems. 45:1--45:10.Google ScholarDigital Library"",""Robert Geisberger, Peter Sanders, Dominik Schultes, and Daniel Delling. 2008. Contraction hierarchies: Faster and simpler hierarchical routing in road networks. In International Workshop on Experimental and Efficient Algorithms. 319--333.Google ScholarDigital Library"",""Thore Graepel, Joaquin Quinonero Candela, Thomas Borchert, and Ralf Herbrich. 2010. Web-scale bayesian click-through rate prediction for sponsored search advertising in microsoft's bing search engine. Omnipress.Google Scholar"",""Todd Litman. 2015. Evaluating public transit benefits and costs. Victoria Transport Policy Institute Victoria, BC, Canada.Google Scholar"",""Hao Liu, Ting Li, Renjun Hu, Yanjie Fu, Jingjing Gu, and Hui Xiong. 2019 a. Joint Representation Learning for Multi-Modal Transportation Recommendation. In Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence. 1036--1043.Google ScholarCross Ref"",""Hao Liu, Yongxin Tong, Panpan Zhang, Xinjiang Lu, Jianguo Duan, and Hui Xiong. 2019 b. Hydra: A Personalized and Context-Aware Multi-Modal Transportation Recommendation System. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 2314--2324.Google ScholarDigital Library"",""Gilles Louppe, Louis Wehenkel, Antonio Sutera, and Pierre Geurts. 2013. Understanding variable importances in forests of randomized trees. In Advances in neural information processing systems. 431--439.Google Scholar"",""Rolf H Möhring, Heiko Schilling, Birk Schütz, Dorothea Wagner, and Thomas Willhalm. 2007. Partitioning graphs to speedup Dijkstra's algorithm. Journal of Experimental Algorithmics (JEA), Vol. 11 (2007), 2--8.Google Scholar"",""Kevin P Murphy. 2012. Machine learning: a probabilistic perspective. MIT press.Google Scholar"",""Dimitris Sacharidis, Panagiotis Bouros, and Theodoros Chondrogiannis. 2017. Finding The Most Preferred Path. In Proceedings of the 25th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems. 5:1--5:10.Google ScholarDigital Library"",""Jingyuan Wang, Ning Wu, Wayne Xin Zhao, Fanzhang Peng, and Xin Lin. 2019. Empowering A* Search Algorithms with Neural Networks for Personalized Route Recommendation. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 539--547.Google ScholarDigital Library"",""Pengfei Wang, Yanjie Fu, Guannan Liu, Wenqing Hu, and Charu Aggarwal. 2017. Human mobility synchronization and trip purpose detection with mixture of hawkes processes. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 495--503.Google ScholarDigital Library"",""Sibo Wang, Wenqing Lin, Yi Yang, Xiaokui Xiao, and Shuigeng Zhou. 2015. Efficient route planning on public transportation networks: A labelling approach. In Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data. 967--982.Google ScholarDigital Library"",""Yining Wang, Liwei Wang, Yuanzhi Li, and Di He. 2013. A theoretical analysis of NDCG ranking measures. In COLT.Google Scholar"",""Jing Yuan, Yu Zheng, Chengyang Zhang, Wenlei Xie, Xing Xie, Guangzhong Sun, and Yan Huang. 2010T-drive: driving directions based on taxi trajectories. In Proceedings of the 18th SIGSPATIAL International conference on advances in geographic information systems. 99--108.Google ScholarDigital Library"",""Zixuan Yuan, Hao Liu, Yanchi Liu, Denghui Zhang, Fei Yi, Nengjun Zhu, and Hui Xiong. 2020. Spatio-Temporal Dual Graph Attention Network for query-POI Matching. In Proceedings of the 43nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2020, Xi'an, China, July 25-30, 2020.Google Scholar"",""Weijia Zhang, Hao Liu, Yanchi Liu, Jingbo Zhou, and Hui Xiong. 2020. Semi-Supervised Hierarchical Recurrent Graph Neural Network for City-Wide Parking Availability Prediction. In Proceedings of the Thirty-Fourth AAAI Conference on Artificial Intelligence.Google ScholarCross Ref"",""Alice Zheng and Amanda Casari. 2018. Feature Engineering for Machine Learning: Principles and Techniques for Data Scientist O'Reilly Media, Inc.Google Scholar"",""Zhaohui Zheng, Keke Chen, Gordon Sun, and Hongyuan Zha. 2007. A regression framework for learning ranking functions using relative relevance judgments. In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval. 287--294.Google ScholarDigital Library"",""Jingbo Zhou, Shan Gou, Renjun Hu, Dongxiang Zhang, Jin Xu, Airong Jiang, Ying Li, and Hui Xiong. 2019. A Collaborative Learning Framework to Tag Refinement for Points of Interest. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1752--1761.Google ScholarDigital Library"",""Jingbo Zhou, Anthony KH Tung, Wei Wu, and Wee Siong Ng. 2013. A \""semi-lazy\"" approach to probabilistic path prediction in dynamic environments. In Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining. 748--756.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403282,Context-Aware Attentive Knowledge Tracing,"Knowledge tracing (KT) refers to the problem of predicting future learner performance given their past performance in educational applications. Recent developments in KT using flexible deep neural network-based models excel at this task. However, these models often offer limited interpretability, thus making them insufficient for personalized learning, which requires using interpretable feedback and actionable recommendations to help learners achieve better learning outcomes. In this paper, we propose attentive knowledge tracing (AKT), which couples flexible attention-based neural network models with a series of novel, interpretable model components inspired by cognitive and psychometric models. AKT uses a novel monotonic attention mechanism that relates a learner's future responses to assessment questions to their past responses; attention weights are computed using exponential decay and a context-aware relative distance measure, in addition to the similarity between questions. Moreover, we use the Rasch model to regularize the concept and question embeddings; these embeddings are able to capture individual differences among questions on the same concept without using an excessive number of parameters. We conduct experiments on several real-world benchmark datasets and show that AKT outperforms existing KT methods (by up to $6%$ in AUC in some cases) on predicting future learner responses. We also conduct several case studies and show that AKT exhibits excellent interpretability and thus has potential for automated feedback and personalization in real-world educational settings.","[{""name"":""Aritra Ghosh"",""id"":""/profile/99659573606""},{""name"":""Neil Heffernan"",""id"":""/profile/81100550596""},{""name"":""Andrew S. Lan"",""id"":""/profile/99659574213""},{""name"":""Aritra Ghosh"",""id"":""/profile/99659573606""},{""name"":""Neil Heffernan"",""id"":""/profile/81100550596""},{""name"":""Andrew S. Lan"",""id"":""/profile/99659574213""}]","[""Hao Cen, Kenneth Koedinger, and Brian Junker. 2006. Learning factors analysis--A general method for cognitive model evaluation and improvement. In Proc. International Conference on Intelligent Tutoring Systems. 164--175.Google ScholarDigital Library"",""Benoît Choffin, Fabrice Popineau, Yolaine Bourda, and Jill-Jênn Vie. 2019. DAS3H: Modeling student learning and forgetting for pptimally scheduling distributed practice of skills. In Proc. International Conference on Educational Data Mining. 29--38.Google Scholar"",""Albert Corbett and John Anderson. 1994. Knowledge tracing: Modeling the acquisition of procedural knowledge. User Modeling and User-adapted Interaction, Vol. 4, 4 (Dec. 1994), 253--278.Google Scholar"",""Xavier Glorot and Yoshua Bengio. 2010. Understanding the difficulty of training deep feedforward neural networks. In Proc. International Conference on Artificial Intelligence and Statistics. 249--256.Google Scholar"",""Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. Deep Learni. MIT Press.Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In Proc. IEEE Conference on Computer Vision and Pattern Recognition. 770--778.Google ScholarCross Ref"",""Sepp Hochreiter and Jü rgen Schmidhuber. 1997. Long short-term memory. Neural Computation, Vol. 9, 8 (Nov. 1997), 1735--1780.Google ScholarDigital Library"",""MM Khajah, Y Huang, JP González-Brenes, MC Mozer, and P Brusilovsky. 2014. Integrating knowledge tracing and item response theory: A tale of two frameworks. In Proc. International Workshop on Personalization Approaches in Learning Environments, Vol. 1181. 7--15.Google Scholar"",""Mohammad Khajah, Robert Lindsey, and Michael Mozer. 2016. How deep is knowledge tracing?. In Proc. International Conference on Educational Data Mining. 94--101.Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2015. Adam: A method for stochastic optimization. In Proc. International Conference on Learning Representations.Google Scholar"",""Andrew Lan and Richard Baraniuk. 2016. A Contextual Bandits Framework for Personalized Learning Action Selection. In Proc. International Conference on Educational Data Mining. 424--429.Google Scholar"",""Andrew Lan, Tom Goldstein, Richard Baraniuk, and Christoph Studer. 2016. Dealbreaker: A nonlinear latent variable model for educational data. In Proc. International Conference on Machine Learning. 266--275.Google Scholar"",""Andrew Lan, Christoph Studer, and Richard Baraniuk. 2014. Time-varying learning and content analytics via sparse factor analysis. In Proc. ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 452--461.Google ScholarDigital Library"",""Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. 2016. Layer normalization. arXiv preprint arXiv:1607.06450 (July 2016).Google Scholar"",""Robert Lindsey, Jeffery Shroyer, Harold Pashler, and Michael Mozer. 2014. Improving students' long-term knowledge retention through personalized review. Psychological Science, Vol. 25, 3 (Jan. 2014), 639--647.Google ScholarCross Ref"",""Frederick Lord. 1980. Applications of Item Response Theory to Practical Testing Problems. Erlbaum Associates.Google Scholar"",""Michael Mozer, Denis Kazakov, and Robert Lindsey. 2017. Discrete-event continuous-time recurrent nets. arXiv preprint arXiv:1710.0411 (Oct. 2017).Google Scholar"",""Shalini Pandey and George Karypis. 2019. A self attentive model for knowledge tracing. In Proc. International Conference on Educational Data Mining. 384--389.Google Scholar"",""Zachary Pardos and Neil Heffernan. 2010. Modeling individualization in a Bayesian networks implementation of knowledge tracing. In Proc. International Conference on User Modeling, Adaptation, and Personalization. 255--266.Google ScholarDigital Library"",""Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio. 2013. On the difficulty of training recurrent neural networks. In Proc. International Conference on Machine Learning. 1310--1318.Google Scholar"",""Harold Pashler, Nicholas Cepeda, Robert Lindsey, Ed Vul, and Michael Mozer. 2009. Predicting the optimal spacing of study: A multiscale context model of memory. In Proc. Conference on Advances in Neural Information Processing Systems. 1321--1329.Google Scholar"",""Philip Pavlik Jr, Hao Cen, and Kenneth Koedinger. 2009. Performance factors analysis--A new alternative to knowledge tracing. In Proc. International Conference on Artificial Intelligence in Education. 531--538.Google Scholar"",""Chris Piech, Jonathan Bassen, Jonathan Huang, Surya Ganguli, Mehran Sahami, Leonidas J Guibas, and Jascha Sohl-Dickstein. 2015a. Deep knowledge tracing. In Proc. Conference on Advances in Neural Information Processing Systems. 505--513.Google Scholar"",""Chris Piech, Jonathan Huang, Andy Nguyen, Mike Phulsuksombati, Mehran Sahami, and Leonidas Guibas. 2015b. Learning Program Embeddings to Propagate Feedback on Student Code. In Proc. International Conference on Machine Learning. 1093--1102.Google Scholar"",""Georg Rasch. 1993. Probabilistic Models for Some Intelligence and Attainment Tests. MESA Press.Google Scholar"",""Siddharth Reddy, Igor Labutov, Siddhartha Banerjee, and Thorsten Joachims. 2016. Unbounded human learning: Optimal scheduling for spaced repetition. In Proc. ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 1815--1824.Google ScholarDigital Library"",""Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: A simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research, Vol. 15, 1 (June 2014), 1929--1958.Google ScholarDigital Library"",""Laurens Van Der Maaten. 2014. Accelerating t-SNE using tree-based algorithms. The Journal of Machine Learning Research, Vol. 15, 1 (2014), 3221--3245.Google ScholarDigital Library"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Proc. Conference on Advances in Neural Information Processing Systems. 5998--6008.Google Scholar"",""Jill-Jênn Vie and Hisashi Kashima. 2019. Knowledge tracing machines: Factorization machines for knowledge tracing. In Proc. AAAI Conference on Artificial Intelligence, Vol. 33. 750--757.Google ScholarCross Ref"",""Kevin Wilson, Yan Karklin, Bojian Han, and Chaitanya Ekanadham. 2016. Back to the basics: Bayesian extensions of IRT outperform neural networks for proficiency estimation. In Proc. International Conference on Educational Data Mining. 539--544.Google Scholar"",""Beverly Park Woolf. 2010. Building Intelligent Interactive Tutors: Student-centered Strategies for Revolutionizing E-learning. Morgan Kaufmann.Google Scholar"",""Xiaolu Xiong, Siyuan Zhao, Eric G Van Inwegen, and Joseph E Beck. 2016. Going deeper with deep knowledge tracing. International Educational Data Mining Society (2016).Google Scholar"",""Chun-Kit Yeung and Dit-Yan Yeung. 2018. Addressing two problems in deep knowledge tracing via prediction-consistent regularization. In Proc. ACM Conference on Learning at Scale. ACM, 5.Google ScholarDigital Library"",""Michael Yudelson, Kenneth Koedinger, and Geoffrey Gordon. 2013. Individualized Bayesian knowledge tracing models. In Proc. International Conference on Artificial Intelligence in Education. 171--180.Google ScholarCross Ref"",""Jiani Zhang, Xingjian Shi, Irwin King, and Dit-Yan Yeung. 2017. Dynamic key-value memory networks for knowledge tracing. In Proc. International Conference on World Wide Web. 765--774.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403283,Improving Movement Predictions of Traffic Actors in Bird's-Eye View Models using GANs and Differentiable Trajectory Rasterization,"One of the most critical pieces of the self-driving puzzle is the task of predicting future movement of surrounding traffic actors, which allows the autonomous vehicle to safely and effectively plan its future route in a complex world. Recently, a number of algorithms have been proposed to address this important problem, spurred by a growing interest of researchers from both industry and academia. Methods based on top-down scene rasterization on one side and Generative Adversarial Networks (GANs) on the other have shown to be particularly successful, obtaining state-of-the-art accuracies on the task of traffic movement prediction. In this paper we build upon these two directions and propose a raster-based conditional GAN architecture, powered by a novel differentiable rasterizer module at the input of the conditional discriminator that maps generated trajectories into the raster space in a differentiable manner. This simplifies the task for the discriminator as trajectories that are not scene-compliant are easier to discern, and allows the gradients to flow back forcing the generator to output better, more realistic trajectories. We evaluated the proposed method on a large-scale, real-world data set, showing that it outperforms state-of-the-art GAN-based baselines.","[{""name"":""Eason Wang"",""id"":""/profile/99659573444""},{""name"":""Henggang Cui"",""id"":""/profile/99659575166""},{""name"":""Sai Yalamanchi"",""id"":""/profile/99659574018""},{""name"":""Mohana Moorthy"",""id"":""/profile/99659574023""},{""name"":""Nemanja Djuric"",""id"":""/profile/99659574063""},{""name"":""Eason Wang"",""id"":""/profile/99659573444""},{""name"":""Henggang Cui"",""id"":""/profile/99659575166""},{""name"":""Sai Yalamanchi"",""id"":""/profile/99659574018""},{""name"":""Mohana Moorthy"",""id"":""/profile/99659574023""},{""name"":""Nemanja Djuric"",""id"":""/profile/99659574063""}]","[""D. Silver, A. Huang, et al., \""Mastering the game of go with deep neural networks and tree search,\"" Nature, vol. 529, no. 7587, pp. 484--489, 2016.Google ScholarCross Ref"",""D. Silver, T. Hubert, et al., \""Mastering chess and shogi by self-play with a general reinforcement learning algorithm,\"" arXiv preprint arXiv:1712.01815, 2017.Google Scholar"",""E. J. Topol, The patient will see you now: the future of medicine is in your hands. Tantor Media, 2015.Google Scholar"",""O. Vinyals, A. Toshev, S. Bengio, and D. Erhan, \""Show and tell: Lessons learned from the 2015 mscoco image captioning challenge,\"" IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 39, no. 4, pp. 652--663, 2017.Google ScholarDigital Library"",""A. Z. Broder, P. Ciccolo, et al., \""Search advertising using web relevance feedback,\"" in Proceedings of the 17th ACM Conference on Information and Knowledge Management. ACM, 2008, pp. 1013--1022.Google Scholar"",""G. Nuti, M. Mirghaemi, P. Treleaven, and C. Yingsaeree, \""Algorithmic trading,\"" Computer, vol. 44, no. 11, pp. 61--69, 2011.Google ScholarDigital Library"",""Y. N. Harari, \""Reboot for the ai revolution,\"" Nature News, vol. 550, no. 7676, p. 324, 2017.Google ScholarCross Ref"",""O. Gusikhin, N. Rychtyckyj, and D. Filev, \""Intelligent systems in the automotive industry: applications and trends,\"" Knowledge and Information Systems, vol. 12, no. 2, pp. 147--168, 2007.Google ScholarDigital Library"",""M. Hofmann, F. Neukart, and T. B\""ack, \""Artificial intelligence and data science in the automotive industry,\"" arXiv preprint arXiv:1709.01989, 2017.Google Scholar"",""D. Singh and M. Singh, \""Internet of vehicles for smart and safe driving,\"" in 2015 international conference on connected vehicles and expo (ICCVE). IEEE, 2015, pp. 328--329.Google Scholar"",""K. N. Qureshi and A. H. Abdullah, \""A survey on intelligent transportation systems,\"" Middle-East Journal of Scientific Research, vol. 15, no. 5, pp. 629--642, 2013.Google Scholar"",""A. Shaout, D. Colella, and S. Awad, \""Advanced driver assistance systems-past, present and future,\"" in 2011 Seventh International Computer Engineering Conference (ICENCO'2011). IEEE, 2011, pp. 72--82.Google Scholar"",""S. Singh, \""Critical reasons for crashes investigated in the national motor vehicle crash causation survey,\"" National Highway Traffic Safety Administration, Tech. Rep. DOT HS 812 506, March 2018.Google Scholar"",""NHTSA, \""2017 fatal motor vehicle crashes: Overview,\"" National Highway Traffic Safety Administration, Tech. Rep. DOT HS 812 603, October 2018.Google Scholar"",""D. A. Pomerleau, \""Alvinn: An autonomous land vehicle in a neural network,\"" in Advances in neural information processing systems, 1989, pp. 305--313.Google Scholar"",""----, \""Neural network perception for mobile robot guidance,\"" Carnegie-Mellon Univ Pittsburgh PA Dept. of Computer Science, Tech. Rep., 1992.Google Scholar"",""C. Urmson and W. Whittaker, \""Self-driving cars and the urban challenge,\"" IEEE Intelligent Systems, vol. 23, no. 2, pp. 66--68, 2008.Google ScholarDigital Library"",""J. Ziegler, P. Bender, M. Schreiber, et al., \""Making bertha drive: An autonomous journey on a historic route,\"" IEEE Intelligent Transportation Systems Magazine, vol. 6, pp. 8--20, 10 2015.Google ScholarCross Ref"",""C. Urmson, J. A. Bagnell, C. Baker, M. Hebert, A. Kelly, R. Rajkumar, P. E. Rybski, S. Scherer, R. Simmons, S. Singh, et al., \""Tartan racing: A multi-modal approach to the DARPA urban challenge,\"" 2007.Google Scholar"",""C. Reinholtz, D. Hong, A. Wicks, A. Bacha, C. Bauman, R. Faruque, M. Fleming, C. Terwelp, T. Alberi, D. Anderson, et al., \""Odin: Team VictorTango's entry in the DARPA urban challenge,\"" in The DARPA Urban Challenge. Springer, 2009, pp. 125--162.Google ScholarCross Ref"",""N. Djuric, V. Radosavljevic, H. Cui, T. Nguyen, F.-C. Chou, T.-H. Lin, N. Singh, and J. Schneider, \""Uncertainty-aware short-term motion prediction of traffic actors for autonomous driving,\"" arXiv preprint arXiv:1808.05819, 2018.Google Scholar"",""W. Luo, B. Yang, and R. Urtasun, \""Fast and furious: Real time end-to-end 3d detection, tracking and motion forecasting with a single convolutional net,\"" in Proceedings of the IEEE CVPR, 2018, pp. 3569--3577.Google Scholar"",""H. Cui, V. Radosavljevic, F.-C. Chou, T.-H. Lin, T. Nguyen, T.-K. Huang, J. Schneider, and N. Djuric, \""Multimodal trajectory predictions for autonomous driving using deep convolutional networks,\"" in 2019 International Conference on Robotics and Automation (ICRA). IEEE, 2019, pp. 2090--2096.Google Scholar"",""A. Gupta, J. Johnson, L. Fei-Fei, S. Savarese, and A. Alahi, \""Social gan: Socially acceptable trajectories with generative adversarial networks,\"" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp. 2255--2264.Google Scholar"",""A. Sadeghian, V. Kosaraju, A. Sadeghian, N. Hirose, H. Rezatofighi, and S. Savarese, \""Sophie: An attentive gan for predicting paths compliant to social and physical constraints,\"" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2019, pp. 1349--1358.Google Scholar"",""V. Kosaraju, A. Sadeghian, R. Martín-Martín, I. Reid, H. Rezatofighi, and S. Savarese, \""Social-bigat: Multimodal trajectory forecasting using bicycle-gan and graph attention networks,\"" in Advances in Neural Information Processing Systems, 2019, pp. 137--146.Google Scholar"",""A. Cosgun, L. Ma, et al., \""Towards full automated drive in urban environments: A demonstration in gomentum station, california,\"" in IEEE Intelligent Vehicles Symposium, 2017, pp. 1811--1818. [Online]. Available: https://doi.org/10.1109/IVS.2017.7995969Google Scholar"",""M. Bansal, A. Krizhevsky, and A. Ogale, \""Chauffeurnet: Learning to drive by imitating the best and synthesizing the worst,\"" arXiv preprint arXiv:1812.03079, 2018.Google Scholar"",""F.-C. Chou, T.-H. Lin, H. Cui, V. Radosavljevic, T. Nguyen, T.-K. Huang, M. Niedoba, J. Schneider, and N. Djuric, \""Predicting motion of vulnerable road users using high-definition maps and efficient convnets,\"" in Workshop on 'Machine Learning for Intelligent Transportation Systems' at Conference on Neural Information Processing Systems (MLITS), 2018.Google Scholar"",""Y. Chai, B. Sapp, M. Bansal, and D. Anguelov, \""Multipath: Multiple probabilistic anchor trajectory hypotheses for behavior prediction,\"" arXiv preprint arXiv:1910.05449, 2019.Google Scholar"",""J. Hong, B. Sapp, and J. Philbin, \""Rules of the road: Predicting driving behavior with a convolutional model of semantic interactions,\"" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2019, pp. 8454--8462.Google Scholar"",""S. Yalamanchi, T.-K. Huang, G. C. Haynes, and N. Djuric, \""Long-term prediction of vehicle behavior using short-term uncertainty-aware trajectories and high-definition maps,\"" in IEEE International Conference on Intelligent Transportation Systems (ITSC), 2020.Google Scholar"",""A. Jain, S. Casas, R. Liao, Y. Xiong, S. Feng, S. Segal, and R. Urtasun, \""Discrete residual flow for probabilistic pedestrian behavior prediction,\"" arXiv preprint arXiv:1910.08041, 2019.Google Scholar"",""D. Ridel, N. Deo, D. Wolf, and M. Trivedi, \""Scene compliant trajectory forecast with agent-centric spatio-temporal grids,\"" arXiv preprint arXiv:1909.07507, 2019.Google Scholar"",""M. Niedoba, H. Cui, K. Luo, D. Hegde, F.-C. Chou, and N. Djuric, \""Improving movement prediction of traffic actors using off-road loss and bias mitigation,\"" in Workshop on 'Machine Learning for Autonomous Driving' at Conference on Neural Information Processing Systems, 2019.Google Scholar"",""I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, \""Generative adversarial nets,\"" in Advances in neural information processing systems, 2014, pp. 2672--2680.Google Scholar"",""B. Dai, S. Fidler, R. Urtasun, and D. Lin, \""Towards diverse and natural image descriptions via a conditional gan,\"" in Proceedings of the IEEE International Conference on Computer Vision, 2017, pp. 2970--2979.Google Scholar"",""Y. Zhang, Z. Gan, K. Fan, Z. Chen, R. Henao, D. Shen, and L. Carin, \""Adversarial feature matching for text generation,\"" in Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 2017, pp. 4006--4015.Google Scholar"",""T. Zhao, Y. Xu, M. Monfort, W. Choi, C. Baker, Y. Zhao, Y. Wang, and Y. N. Wu, \""Multi-agent tensor fusion for contextual trajectory prediction,\"" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2019, pp. 12, 126--12,134.Google Scholar"",""H. Cui, T. Nguyen, F.-C. Chou, T.-H. Lin, J. Schneider, D. Bradley, and N. Djuric, \""Deep kinematic models for physically realistic prediction of vehicle trajectories,\"" arXiv preprint arXiv:1908.00219, 2019.Google Scholar"",""M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, and L.-C. Chen, \""Inverted residuals and linear bottlenecks: Mobile networks for classification, detection and segmentation,\"" arXiv preprint arXiv:1801.04381, 2018.Google Scholar"",""A. Radford, L. Metz, and S. Chintala, \""Unsupervised representation learning with deep convolutional generative adversarial networks,\"" arXiv preprint arXiv:1511.06434, 2015.Google Scholar"",""M. Arjovsky, S. Chintala, and L. Bottou, \""Wasserstein gan,\"" arXiv preprint arXiv:1701.07875, 2017.Google Scholar"",""I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. C. Courville, \""Improved training of wasserstein gans,\"" CoRR, vol. abs/1704.00028, 2017. [Online]. Available: http://arxiv.org/abs/1704.00028Google Scholar"",""A. Alahi, K. Goel, V. Ramanathan, A. Robicquet, L. Fei-Fei, and S. Savarese, \""Social lstm: Human trajectory prediction in crowded spaces,\"" in Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 961--971.Google Scholar"",""J. Amirian, J.-B. Hayet, and J. Pettré, \""Social ways: Learning multi-modal distributions of pedestrian trajectories with gans,\"" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, 2019, pp. 0--0.Google Scholar"",""M. Abadi, A. Agarwal, P. Barham, E. Brevdo, et al., \""TensorFlow: Large-scale machine learning on heterogeneous systems,\"" 2015. [Online]. Available: https://www.tensorflow.org/BIBentrySTDinterwordspacingGoogle Scholar"",""D. P. Kingma and J. Ba, \""Adam: A method for stochastic optimization,\"" arXiv preprint arXiv:1412.6980, 2014.Google Scholar"",""G. P. Meyer, A. Laddha, E. Kee, C. Vallespi-Gonzalez, and C. K. Wellington, \""Lasernet: An efficient probabilistic 3d object detector for autonomous driving,\"" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2019, pp. 12,677--12,686.Google Scholar"",""G. Máttyus and R. Urtasun, \""Matching adversarial networks,\"" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp. 8024--8032.Google Scholar""]"
https://doi.org/10.1145/3394486.3403284,M2GRL: A Multi-task Multi-view Graph Representation Learning Framework for Web-scale Recommender Systems,"Combining graph representation learning with multi-view data (side information) for recommendation is a trend in industry. Most existing methods can be categorized as multi-view representation fusion; they first build one graph and then integrate multi-view data into a single compact representation for each node in the graph. However, these methods are raising concerns in both engineering and algorithm aspects: 1) multi-view data are abundant and informative in industry and may exceed the capacity of one single vector, and 2) inductive bias may be introduced as multi-view data are often from different distributions. In this paper, we use a multi-view representation alignment approach to address this issue. Particularly, we propose a multi-task multi-view graph representation learning framework (M2GRL) to learn node representations from multi-view graphs for web-scale recommender systems. M2GRL constructs one graph for each single-view data, learns multiple separate representations from multiple graphs, and performs alignment to model cross-view relations. M2GRL chooses a multi-task learning paradigm to learn intra-view representations and cross-view relations jointly. Besides, M2GRL applies homoscedastic uncertainty to adaptively tune the loss weights of tasks during training. We deploy M2GRL at Taobao and train it on 57 billion examples. According to offline metrics and online A/B tests, M2GRL significantly outperforms other state-of-the-art algorithms. Further exploration on diversity recommendation in Taobao shows the effectiveness of utilizing multiple representations produced by M2GRL, which we argue is a promising direction for various industrial recommendation tasks of different focus.","[{""name"":""Menghan Wang"",""id"":""/profile/99659363556""},{""name"":""Yujie Lin"",""id"":""/profile/99659573240""},{""name"":""Guli Lin"",""id"":""/profile/99659573452""},{""name"":""Keping Yang"",""id"":""/profile/99659370695""},{""name"":""Xiao-ming Wu"",""id"":""/profile/99659573365""},{""name"":""Menghan Wang"",""id"":""/profile/99659363556""},{""name"":""Yujie Lin"",""id"":""/profile/99659573240""},{""name"":""Guli Lin"",""id"":""/profile/99659573452""},{""name"":""Keping Yang"",""id"":""/profile/99659370695""},{""name"":""Xiao-ming Wu"",""id"":""/profile/99659573365""}]","[""Amr Ahmed, Nino Shervashidze, Shravan Narayanamurthy, Vanja Josifovski, and Alexander J Smola. 2013. Distributed large-scale natural graph factorization. In WWW. ACM, 37--48.Google Scholar"",""Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep neural networks for youtube recommendations. In Recsys. ACM, 191--198.Google Scholar"",""Yuxiao Dong, Nitesh V Chawla, and Ananthram Swami. 2017. metapath2vec: Scalable representation learning for heterogeneous networks. In SIGKDD. ACM, 135--144.Google Scholar"",""Ali Mamdouh Elkahky, Yang Song, and Xiaodong He. 2015. A multi-view deep learning approach for cross domain user modeling in recommendation systems. In WWW. 278--288.Google Scholar"",""Joan Bruna Estrach, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. 2014. Spectral networks and deep locally connected networks on graphs. In ICLR .Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In SIGKDD. ACM, 855--864.Google Scholar"",""Raia Hadsell, Sumit Chopra, and Yann LeCun. 2006. Dimensionality reduction by learning an invariant mapping. In CVPR, Vol. 2. IEEE, 1735--1742.Google ScholarDigital Library"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017a. Inductive representation learning on large graphs. In NeurIPS. 1024--1034.Google Scholar"",""William L Hamilton, Rex Ying, and Jure Leskovec. 2017b. Representation learning on graphs: Methods and applications. arXiv preprint arXiv:1709.05584 (2017).Google Scholar"",""Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In WWW. 173--182.Google Scholar"",""Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2015. Session-based recommendations with recurrent neural networks. arXiv preprint arXiv:1511.06939 (2015).Google Scholar"",""Xinyang Jiang, Fei Wu, Xi Li, Zhou Zhao, Weiming Lu, Siliang Tang, and Yueting Zhuang. 2015. Deep compositional cross-modal learning to rank via local-global alignment. In ACM MM. ACM, 69--78.Google Scholar"",""Alex Kendall and Yarin Gal. 2017. What uncertainties do we need in bayesian deep learning for computer vision?. In NeurIPS . 5574--5584.Google Scholar"",""Alex Kendall, Yarin Gal, and Roberto Cipolla. 2018. Multi-task learning using uncertainty to weigh losses for scene geometry and semantics. In CVPR .Google Scholar"",""Yingming Li, Ming Yang, and Zhongfei Mark Zhang. 2018. A survey of multi-view representation learning. TKDE (2018).Google Scholar"",""Dawen Liang, Rahul G Krishnan, Matthew D Hoffman, and Tony Jebara. 2018. Variational autoencoders for collaborative filtering. In WWW. 689--698.Google Scholar"",""Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781 (2013).Google Scholar"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In SIGKDD. ACM, 701--710.Google ScholarDigital Library"",""Jiezhong Qiu, Yuxiao Dong, Hao Ma, Jian Li, Chi Wang, Kuansan Wang, and Jie Tang. 2019. Netsmf: Large-scale network embedding as sparse matrix factorization. In WWW. ACM, 1509--1520.Google Scholar"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. In WWW. 1067--1077.Google ScholarDigital Library"",""Jizhe Wang, Pipei Huang, Huan Zhao, Zhibo Zhang, Binqiang Zhao, and Dik Lun Lee. 2018b. Billion-scale commodity embedding for e-commerce recommendation in alibaba. In SIGKDD. ACM, 839--848.Google Scholar"",""Menghan Wang, Mingming Gong, Xiaolin Zheng, and Kun Zhang. 2018a. Modeling dynamic missingness of implicit feedback for recommendation. In NeurIPS . 6669--6678.Google Scholar"",""Menghan Wang, Xiaolin Zheng, Yang Yang, and Kun Zhang. 2018c. Collaborative filtering with social exposure: A modular approach to social recommendation. In AAAI .Google Scholar"",""Wei Xu, Wei Liu, Haoyuan Chi, Xiaolin Huang, and Jie Yang. 2018. Multi-task classification with sequential instances and tasks. Signal Processing: Image Communication , Vol. 64 (2018), 59--67.Google ScholarCross Ref"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale recommender systems. In SIGKDD. ACM, 974--983.Google Scholar"",""Yongfeng Zhang, Qingyao Ai, Xu Chen, and W Bruce Croft. 2017. Joint representation learning for top-n recommendation with heterogeneous information sources. In CIKM. 1449--1458.Google Scholar"",""Xiaolin Zheng, Menghan Wang, Chaochao Chen, Yan Wang, and Zhehao Cheng. 2019. EXPLORE: EXPLainable item-tag CO-REcommendation. Information Sciences , Vol. 474 (2019), 170--186.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403285,Attribute-based Propensity for Unbiased Learning in Recommender Systems: Algorithm and Case Studies,"Many modern recommender systems train their models based on a large amount of implicit user feedback data. Due to the inherent bias in this data (e.g., position bias), learning from it directly can lead to suboptimal models. Recently, unbiased learning was proposed to address such problems by leveraging counterfactual techniques like inverse propensity weighting (IPW). In these methods, propensity scores estimation is usually limited to item's display position in a single user interface (UI).In this paper, we generalize the traditional position bias model to an attribute-based propensity framework. Our methods estimate propensity scores based on offline data and allow propensity estimation across a broad range of implicit feedback scenarios, e.g., feedback beyond recommender system UI. We demonstrate this by applying this framework to three real-world large-scale recommender systems in Google Drive that serve millions of users. For each system, we conduct both offline and online evaluation. Our results show that the proposed framework is able to significantly improve upon strong production baselines across a diverse range of recommendation item types (documents, people-document pairs, and queries), UI layouts (horizontal, vertical, and grid layouts), and underlying learning algorithms (gradient boosted decision trees and neural networks), all without the need to intervene and degrade the user experience. The proposed models have been deployed in the production systems with ease since no serving infrastructure change is needed.","[{""name"":""Zhen Qin"",""id"":""/profile/99659315793""},{""name"":""Suming J. Chen"",""id"":""/profile/99659574309""},{""name"":""Donald Metzler"",""id"":""/profile/81100129957""},{""name"":""Yongwoo Noh"",""id"":""/profile/99659574532""},{""name"":""Jingzheng Qin"",""id"":""/profile/99659536430""},{""name"":""Xuanhui Wang"",""id"":""/profile/99659515466""},{""name"":""Zhen Qin"",""id"":""/profile/99659315793""},{""name"":""Suming J. Chen"",""id"":""/profile/99659574309""},{""name"":""Donald Metzler"",""id"":""/profile/81100129957""},{""name"":""Yongwoo Noh"",""id"":""/profile/99659574532""},{""name"":""Jingzheng Qin"",""id"":""/profile/99659536430""},{""name"":""Xuanhui Wang"",""id"":""/profile/99659515466""}]","[""2016. Save time with Quick Access in Drive. https://gsuiteupdates.googleblog. com/2016/09/save-time-with-quick-access-in-drive.html. Accessed: 2020-01-15.Google Scholar"",""2017. Quick Access in Google Drive now available on the web. https://gsuiteupdates.googleblog.com/2017/05/quick-access-in-google-drive-now. html. Accessed: 2020-01-15.Google Scholar"",""2018. Find shared content with new file organization in Google Drive. https: //gsuiteupdates.googleblog.com/2018/03/find-shared-content-with-new-file. html. Accessed: 2020-1-15.Google Scholar"",""2018. New intelligent search box in Google Drive. https://gsuiteupdates. googleblog.com/2018/07/intelligent-search-box-in-google-drive.html. Accessed: 2020-01-15.Google Scholar"",""Martin Abadi et almbox. 2016. TensorFlow: A system for large-scale machine learning. In OSDI. 265--283.Google Scholar"",""Aman Agarwal, Ivan Zaitsev, Xuanhui Wang, Cheng Li, Marc Najork, and Thorsten Joachims. 2019. Estimating Position Bias without Intrusive Interventions. In WSDM. 474--482.Google Scholar"",""Qingyao Ai, Keping Bi, Cheng Luo, Jiafeng Guo, and W. Bruce Croft. 2018. Unbiased Learning to Rank with Unbiased Propensity Estimation. In SIGIR. 385--394.Google Scholar"",""James Bennett, Stan Lanning, et almbox. 2007. The Netflix prize. In Proceedings of KDD cup and workshop.Google Scholar"",""Alex Beutel, Paul Covington, Sagar Jain, Can Xu, Jia Li, Vince Gatto, and Ed H. Chi. 2018. Latent Cross: Making Use of Context in Recurrent Recommender Systems. In WSDM. 46--54.Google Scholar"",""Alexey Borisov, Ilya Markov, Maarten de Rijke, and Pavel Serdyukov. 2016. A Neural Click Model for Web Search. In WWW. 531--541.Google Scholar"",""Minmin Chen, Alex Beutel, Paul Covington, Sagar Jain, Francois Belletti, and Ed H. Chi. 2019. Top-K Off-Policy Correction for a REINFORCE Recommender System. In WSDM. 456--464.Google Scholar"",""Suming J. Chen et almbox. 2020. Improving Recommendation Quality in Google Drive. In KDD.Google Scholar"",""Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et almbox. 2016. Wide \u0026 deep learning for recommender systems. In Workshop on Deep learning for Recommender Systems. 7--10.Google ScholarDigital Library"",""Aleksandr Chuklin, Ilya Markov, and Maarten de Rijke. 2015. Click Models for Web Search. Morgan \u0026 Claypool.Google Scholar"",""Andrew Collins, Dominika Tkaczyk, Akiko Aizawa, and Joeran Beel. 2018. Position bias in recommender systems for digital libraries. In International Conference on Information. Springer, 335--344.Google ScholarCross Ref"",""Zhichong Fang, A. Agarwal, and T. Joachims. 2019. Intervention Harvesting for Context-Dependent Examination-Bias Estimation. In SIGIR.Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In CVPR. 770--778.Google Scholar"",""Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In WWW. 173--182.Google Scholar"",""Katja Hofmann, Anne Schuth, Alejandro Bellogin, and Maarten De Rijke. 2014. Effects of position bias on click-based recommender evaluation. In ECIR. 624--630.Google Scholar"",""Y. Hu, Y. Koren, and C. Volinsky. 2008. Collaborative Filtering for Implicit Feedback Datasets. In ICDM. 263--272.Google Scholar"",""Ziniu Hu, Yang Wang, Qu Peng, and Hang Li. 2019. Unbiased LambdaMART: An Unbiased Pairwise Learning-to-Rank Algorithm. In WWW. 2830--2836.Google Scholar"",""Sergey Ioffe and Christian Szegedy. 2015. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167 (2015).Google Scholar"",""Thorsten Joachims, Laura Granka, Bing Pan, Helene Hembrooke, Filip Radlinski, and Geri Gay. 2007. Evaluating the accuracy of implicit feedback from clicks and query reformulations in web search. ACM Trans. Inf. Syst. (TOIS) (2007), 1--7.Google Scholar"",""Thorsten Joachims, Adith Swaminathan, and Tobias Schnabel. 2017. Unbiased Learning-to-Rank with Biased Feedback. In WSDM. 781--789.Google Scholar"",""Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix factorization techniques for recommender systems. Computer 8 (2009), 30--37.Google ScholarDigital Library"",""Lihong Li, Wei Chu, John Langford, and Robert E. Schapire. 2010. A Contextual-bandit Approach to Personalized News Article Recommendation. In WWW. 661--670.Google Scholar"",""David C. Liu, Stephanie Rogers, Raymond Shiau, Dmitry Kislyuk, Kevin C. Ma, Zhigang Zhong, Jenny Liu, and Yushi Jing. 2017. Related Pins at Pinterest: The Evolution of a Real-World Recommender System. In WWW. 583--592.Google Scholar"",""Zhen Qin, Zhongliang Li, Michael Bendersky, and Donald Metzler. 2020. Matching Cross Network for Learning to Rank in Personal Search. In WWW. 2835--2841.Google Scholar"",""Matthew Richardson, Ewa Dominowska, and Robert Ragno. 2007. Predicting Clicks: Estimating the Click-through Rate for New Ads. In WWW. 521--530.Google ScholarDigital Library"",""Tobias Schnabel, Adith Swaminathan, Ashudeep Singh, Navin Chandak, and Thorsten Joachims. 2016. Recommendations as Treatments: Debiasing Learning and Evaluation. In ICML. 1670--1679.Google Scholar"",""Jiaxi Tang and Ke Wang. 2018. Personalized top-n sequential recommendation via convolutional sequence embedding. In WSDM. 565--573.Google Scholar"",""Sandeep Tata et almbox. 2017. Quick Access: Building a Smart Experience for Google Drive. In KDD. 1643--1651.Google Scholar"",""Xuanhui Wang, Michael Bendersky, Donald Metzler, and Marc Najork. 2016. Learning to Rank with Selection Bias in Personal Search. In SIGIR. 115--124.Google Scholar"",""Xuanhui Wang, Nadav Golbandi, Michael Bendersky, Donald Metzler, and Marc Najork. 2018a. Position Bias Estimation for Unbiased Learning to Rank in Personal Search. In WSDM. 610--618.Google Scholar"",""Xuanhui Wang, Cheng Li, Nadav Golbandi, Mike Bendersky, and Marc Najork. 2018b. The LambdaLoss Framework for Ranking Metric Optimization. In CIKM. 1313--1322.Google Scholar"",""Xiaojie Wang, Rui Zhang, Yu Sun, and Jianzhong Qi. 2019. Doubly Robust Joint Learning for Recommendation on Data Missing Not at Random. In ICML. 6638--6647.Google Scholar"",""Chao-Yuan Wu, Amr Ahmed, Alex Beutel, Alexander J Smola, and How Jing. 2017a. Recurrent recommender networks. In WSDM. 495--503.Google Scholar"",""Qingyun Wu, Hongning Wang, Liangjie Hong, and Yue Shi. 2017b. Returning is believing: Optimizing long-term user engagement in recommender systems. In CIKM. 1927--1936.Google Scholar"",""Longqi Yang, Yin Cui, Yuan Xuan, Chenyang Wang, Serge Belongie, and Deborah Estrin. 2018. Unbiased Offline Recommender Evaluation for Missing-not-at-random Implicit Feedback. In RecSys. 279--287.Google Scholar"",""Xing Yi, Liangjie Hong, Erheng Zhong, Nanthan Nan Liu, and Suju Rajan. 2014. Beyond Clicks: Dwell Time for Personalization. In RecSys. 113--120.Google Scholar"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale recommender systems. In KDD. 974--983.Google Scholar"",""Shuai Zhang, Lina Yao, Aixin Sun, and Yi Tay. 2019. Deep learning based recommender system: A survey and new perspectives. ACM Computing Surveys (CSUR) (2019), 5:1--5:38.Google Scholar"",""Qian Zhao, Shuo Chang, F Maxwell Harper, and Joseph A Konstan. 2016. Gaze prediction for recommender systems. In RecSys. 131--138.Google Scholar"",""Xiangyu Zhao, Long Xia, Liang Zhang, Zhuoye Ding, Dawei Yin, and Jiliang Tang. 2018. Deep reinforcement learning for page-wise recommendations. In RecSys. 95--103.Google Scholar"",""Zhe Zhao, Lichan Hong, Li Wei, Jilin Chen, Aniruddh Nath, Shawn Andrews, Aditee Kumthekar, Maheswaran Sathiamoorthy, Xinyang Yi, and Ed Chi. 2019. Recommending what video to watch next: a multitask ranking system. In RecSys. 43--51.Google Scholar""]"
https://doi.org/10.1145/3394486.3403286,Predicting Individual Treatment Effects of Large-scale Team Competitions in a Ride-sharing Economy,"Millions of drivers worldwide have enjoyed financial benefits and work schedule flexibility through a ride-sharing economy, but meanwhile they have suffered from the lack of a sense of identity and career achievement. Equipped with social identity and contest theories, financially incentivized team competitions have been an effective instrument to increase drivers' productivity, job satisfaction, and retention, and to improve revenue over cost for ride-sharing platforms. While these competitions are overall effective, the decisive factors behind the treatment effects and how they affect the outcomes of individual drivers have been largely mysterious. In this study, we analyze data collected from more than 500 large-scale team competitions organized by a leading ride-sharing platform, building machine learning models to predict individual treatment effects. Through a careful investigation of features and predictors, we are able to reduce out-sample prediction error by more than 24%. Through interpreting the best-performing models, we discover many novel and actionable insights regarding how to optimize the design and the execution of team competitions on ride-sharing platforms. A simulated analysis demonstrates that by simply changing a few contest design options, the average treatment effect of a real competition is expected to increase by as much as 26%. Our procedure and findings shed light on how to analyze and optimize large-scale online field experiments in general.","[{""name"":""Teng Ye"",""id"":""/profile/99659131064""},{""name"":""Wei Ai"",""id"":""/profile/99658719634""},{""name"":""Lingyu Zhang"",""id"":""/profile/99659193724""},{""name"":""Ning Luo"",""id"":""/profile/99659574487""},{""name"":""Lulu Zhang"",""id"":""/profile/99659479399""},{""name"":""Jieping Ye"",""id"":""/profile/99659193247""},{""name"":""Qiaozhu Mei"",""id"":""/profile/81100214997""},{""name"":""Teng Ye"",""id"":""/profile/99659131064""},{""name"":""Wei Ai"",""id"":""/profile/99658719634""},{""name"":""Lingyu Zhang"",""id"":""/profile/99659193724""},{""name"":""Ning Luo"",""id"":""/profile/99659574487""},{""name"":""Lulu Zhang"",""id"":""/profile/99659479399""},{""name"":""Jieping Ye"",""id"":""/profile/99659193247""},{""name"":""Qiaozhu Mei"",""id"":""/profile/81100214997""}]","[""Wei Ai, Roy Chen, Yan Chen, Qiaozhu Mei, and Webb Phillips. 2016. Recommending teams promotes prosocial lending in online microfinance. Proceedings of the National Academy of Sciences, Vol. 113, 52 (2016), 14944--14948.Google ScholarCross Ref"",""Wei Ai, Yan Chen, Qiaozhu Mei, Jieping Ye, and Lingyu Zhang. 2019. Putting teams into the gig economy: A field experiment at a ride-sharing platform. (2019). University of Michigan Working Paper.Google Scholar"",""George A Akerlof and Rachel E Kranton. 2000. Economics and identity. The Quarterly Journal of Economics, Vol. 115, 3 (2000), 715--753.Google ScholarCross Ref"",""Aris Anagnostopoulos, Luca Becchetti, Carlos Castillo, Aristides Gionis, and Stefano Leonardi. 2012. Online team formation in social networks. In Proceedings of the 21st international conference on World Wide Web. ACM, 839--848.Google ScholarDigital Library"",""Joshua D Angrist and Jörn-Steffen Pischke. 2008. Mostly harmless econometrics: An empiricist's companion. Princeton University Press.Google Scholar"",""Susan Athey and Guido Imbens. 2016. Recursive partitioning for heterogeneous causal effects. Proceedings of the National Academy of Sciences, Vol. 113, 27 (2016), 7353--7360.Google ScholarCross Ref"",""Stephen P Borgatti, Ajay Mehra, Daniel J Brass, and Giuseppe Labianca. 2009. Network analysis in the social sciences. Science, Vol. 323, 5916 (2009), 892--895.Google Scholar"",""Léon Bottou, Jonas Peters, Joaquin Qui nonero-Candela, Denis X Charles, D Max Chickering, Elon Portugaly, Dipankar Ray, Patrice Simard, and Ed Snelson. 2013. Counterfactual reasoning and learning systems: The example of computational advertising. The Journal of Machine Learning Research, Vol. 14, 1 (2013), 3207--3260.Google ScholarDigital Library"",""M Keith Chen, Peter E Rossi, Judith A Chevalier, and Emily Oehlsen. 2019. The value of flexible work: Evidence from Uber drivers. Journal of Political Economy, Vol. 127, 6 (2019), 2735--2794.Google ScholarCross Ref"",""Roy Chen, Yan Chen, Yang Liu, and Qiaozhu Mei. 2017. Does team competition increase pro-social lending? Evidence from online microfinance. Games and Economic Behavior, Vol. 101 (2017), 311--333.Google ScholarCross Ref"",""Ziqiang Cheng, Yang Yang, Chenhao Tan, Denny Cheng, Alex Cheng, and Yueting Zhuang. 2019. What makes a good team? A large-scale study on the effect of team composition in Honor of Kings. In The World Wide Web Conference. 2666--2672.Google ScholarDigital Library"",""Robert B Cialdini and Melanie R Trost. 1998. Social influence: Social norms, conformity and compliance. The Handbook of Social Psychology (1998), 151--192.Google Scholar"",""Gang Fang, Izabela E Annis, Jennifer Elston-Lafata, and Samuel Cykert. 2019 a. Applying machine learning to predict real-world individual treatment effects: Insights from a virtual patient cohort. Journal of the American Medical Informatics Association, Vol. 26, 10 (2019), 977--988.Google ScholarCross Ref"",""Zhixuan Fang, Longbo Huang, and Adam Wierman. 2019 b. Prices and subsidies in the sharing economy. Performance Evaluation (2019), 102037.Google Scholar"",""Jerome H Friedman. 2002. Stochastic gradient boosting. Computational Statistics and Data Analysis, Vol. 38, 4 (2002), 367--378.Google ScholarDigital Library"",""Ruocheng Guo, Jundong Li, and Huan Liu. 2020. Learning individual causal effects from networked observational data. In Proceedings of the 13th International Conference on Web Search and Data Mining. 232--240.Google ScholarDigital Library"",""Juho Hamari, Mimmi Sjöklint, and Antti Ukkonen. 2016. The sharing economy: Why people participate in collaborative consumption. Journal of the association for information science and technology, Vol. 67, 9 (2016), 2047--2059.Google ScholarDigital Library"",""Nathan Heller. 2017. Is the gig economy working? The New Yorker (2017). https://www.newyorker.com/magazine/2017/05/15/is-the-gig-economy-workingGoogle Scholar"",""Benjamin E. Hermalin. 1997. Toward an economic theory of leadership: Leading by example. The American Economic Review, Vol. 88, 5 (1997), 1188--1206.Google Scholar"",""Arthur E Hoerl and Robert W Kennard. 1970. Ridge regression: Biased estimation for nonorthogonal problems. Technometrics, Vol. 12, 1 (1970), 55--67.Google ScholarCross Ref"",""Ron Kohavi, Alex Deng, Brian Frasca, Toby Walker, Ya Xu, and Nils Pohlmann. 2013. Online controlled experiments at large scale. In Proceedings of the 19th ACM SIGKDD. ACM, 1168--1176.Google ScholarDigital Library"",""Robert E Kraut, Susan R Fussell, Susan E Brennan, and Jane Siegel. 2002. Understanding effects of proximity on collaboration: Implications for technologies to support remote collaborative work. Distributed work (2002), 137--162.Google Scholar"",""Maggie Makar, Adith Swaminathan, and Emre Kiciman. 2019. A distillation approach to data efficient individual treatment effect estimation. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 4544--4551.Google ScholarCross Ref"",""Benny Moldovanu, Aner Sela, and Xianwen Shi. 2007. Contests for status. Journal of political Economy, Vol. 115, 2 (2007), 338--363.Google ScholarCross Ref"",""Lev Muchnik, Sinan Aral, and Sean J Taylor. 2013. Social influence bias: A randomized experiment. Science, Vol. 341, 6146 (2013), 647--651.Google Scholar"",""Alain Pinsonneault, Henri Barki, R Brent Gallupe, and Norberto Hoppen. 1999. Electronic brainstorming: The illusion of productivity. Information Systems Research, Vol. 10, 2 (1999), 110--133.Google ScholarDigital Library"",""Markus Rokicki, Sergej Zerr, and Stefan Siersdorfer. 2015. Groupsourcing: Team competition designs for crowdsourcing. In Proceedings of the 24th international conference on world wide web. 906--915.Google ScholarDigital Library"",""Charles D Scales Jr, Tannaz Moin, Arlene Fink, Sandra H Berry, Nasim Afsar-Manesh, Carol M Mangione, and B Price Kerfoot. 2016. A randomized, controlled trial of team-based competition to increase learner participation in quality-improvement education. International Journal for Quality in Health Care, Vol. 28, 2 (2016), 227--232.Google ScholarCross Ref"",""Uri Shalit, Fredrik D Johansson, and David Sontag. 2017. Estimating individual treatment effect: generalization bounds and algorithms. In Proceedings of the 34th International Conference on Machine Learning-Volume 70. 3076--3085.Google Scholar"",""VS Subrahmanian and Srijan Kumar. 2017. Predicting human behavior: The next frontiers. Science, Vol. 355, 6324 (2017), 489--489.Google Scholar"",""Adith Swaminathan and Thorsten Joachims. 2015. The self-normalized estimator for counterfactual learning. In Advances in Neural Information Processing Systems. 3231--3239.Google Scholar"",""Robert Tibshirani. 1996. Regression shrinkage and selection via the Lasso. Journal of the Royal Statistical Society. Series B (Methodological), Vol. 58, 1 (1996), 267--288.Google ScholarCross Ref"",""Milan Vojnović. 2015. Contest theory: Incentive mechanisms and ranking methods. Cambridge University Press.Google Scholar"",""Jürgen Wegge, Carla Roth, Barbara Neubach, Klaus-Helmut Schmidt, and Ruth Kanfer. 2008. Age and gender diversity as determinants of performance and health in a public organization: the role of task complexity and group size. Journal of Applied Psychology, Vol. 93, 6 (2008), 1301.Google ScholarCross Ref"",""Lingyu Zhang, Tianshu Song, Yongxin Tong, Zimu Zhou, Dan Li, Wei Ai, Lulu Zhang, Guobin Wu, Yan Liu, and Jieping Ye. 2019. Recommendation-based team formation for on-demand taxi-calling platform. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management. 59--68.Google ScholarDigital Library"",""Zhe Zhang and Beibei Li. 2017. A quasi-experimental estimate of the impact of p2p transportation platforms on urban consumer patterns. In Proceedings of the 23rd ACM SIGKDD. ACM, 1683--1692.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403287,Cellular Network Radio Propagation Modeling with Deep Convolutional Neural Networks,"Radio propagation modeling and prediction is fundamental for modern cellular network planning and optimization. Conventional radio propagation models fall into two categories. Empirical models, based on coarse statistics, are simple and computationally efficient, but are inaccurate due to oversimplification. Deterministic models, such as ray tracing based on physical laws of wave propagation, are more accurate and site specific. But they have higher computational complexity and are inflexible to utilize site information other than traditional global information system (GIS) maps.In this article we present a novel method to model radio propagation using deep convolutional neural networks and report significantly improved performance compared to conventional models. We also lay down the framework for data-driven modeling of radio propagation and enable future research to utilize rich and unconventional information of the site, e.g. satellite photos, to provide more accurate and flexible models.","[{""name"":""Xin Zhang"",""id"":""/profile/99659574745""},{""name"":""Xiujun Shu"",""id"":""/profile/99659573271""},{""name"":""Bingwen Zhang"",""id"":""/profile/99659573091""},{""name"":""Jie Ren"",""id"":""/profile/99659574761""},{""name"":""Lizhou Zhou"",""id"":""/profile/99659574379""},{""name"":""Xin Chen"",""id"":""/profile/99659574165""},{""name"":""Xin Zhang"",""id"":""/profile/99659574745""},{""name"":""Xiujun Shu"",""id"":""/profile/99659573271""},{""name"":""Bingwen Zhang"",""id"":""/profile/99659573091""},{""name"":""Jie Ren"",""id"":""/profile/99659574761""},{""name"":""Lizhou Zhou"",""id"":""/profile/99659574379""},{""name"":""Xin Chen"",""id"":""/profile/99659574165""}]","[""Alejandro Aragón-Zavala Simon R. Saunders, editor. 2000. Antennas and Propagation for Wireless Communication Systems. Wiley.Google Scholar"",""T. K. Sarkar, Zhong Ji, Kyungjung Kim, A. Medouri, and M. Salazar-Palma. 2003. A survey of various propagation models for mobile communication. IEEE Antennas and Propagation Magazine, 45, 3, 51--82.Google ScholarCross Ref"",""F. Ikegami, T. Takeuchi, and S. Yoshida. 1991. Theoretical prediction of mean field strength for urban mobile radio. IEEE Transactions on Antennas and Propagation, 39, 3, 299-- 302.Google ScholarCross Ref"",""J. Walfisch and H.L. Bertoni. 1988. A theoretical model of uhf propagation in urban environments. IEEE Transactions on Antennas and Propagation, 36, 12, 1788--1796.Google ScholarCross Ref"",""C. O. Mgbe, J. M. Mom, and G. A. Igwue. 2015. Performance evaluation of generalized regression neural network path loss prediction model in macrocellular environment. Journal of Multidisciplinary Engineering Science and Technology (JMEST), 2, 2, 204--208.Google Scholar"",""S. P. Sotiroudis, S. K. Goudos, K. Siakavara K. A. Gotsis, and J. N. Sahalos. 2013. Application of a composite differential evolution algorithm in optimal neural network design for propagation path-loss prediction in mobile communication systems. IEEE Antennas and Wireless Propagation Letters, 2, 364--367.Google ScholarCross Ref"",""S. P. Sotiroudis and K. Siakavara. 2015. Mobile radio propagation path loss prediction using artificial neural networks with optimal input information for urban environments. International Journal of Electronics and Communications (AEU), 1453--1463.Google Scholar"",""Segun I. Popoola, Emmanuel Adetiba, Aderemi A. Atayero, Nasir Faruk, and Carlos T. Calafate. 2018. Optimal model for path loss predictions using feed-forward neural networks. Cogent Engineering, 5, 1.Google ScholarCross Ref"",""Joseph M. Môm, O Callistus, Mgbe, and Gabriel A. Igwue. 2014. Application of artificial neural network for path loss prediction in urban macrocellular environment. In volume 3, 270--275.Google Scholar"",""M. Ayadi, A. Ben Zineb, and S. Tabbane. 2017. A uhf path loss model using learning machine for heterogeneous networks. IEEE Transactions on Antennas and Propagation, 65, 7, 3675-- 3683.Google ScholarCross Ref"",""Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner. 1998. Gradientbased learning applied to document recognition. Proceedings of the IEEE, 86, 11, 2278--2324. issn: 0018-9219.Google ScholarCross Ref"",""Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. 2012. Imagenet classification with deep convolutional neural networks. In Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1 (NIPS'12). Curran Associates Inc., Lake Tahoe, Nevada, 1097--1105.Google ScholarDigital Library"",""K. Simonyan and A. Zisserman. 2014. Very deep convolutional networks for large-scale image recognition. CoRR, abs/1409.1556.Google Scholar"",""Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. 2015. Going deeper with convolutions. In Computer Vision and Pattern Recognition (CVPR). http://arxiv.org/abs/1409.4842.Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016, Las Vegas, NV, USA, June 27-30, 2016, 770--778.Google ScholarCross Ref"",""J. Long, E. Shelhamer, and T. Darrell. 2015. Fully convolutional networks for semantic segmentation. In 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 3431--3440.Google Scholar"",""Bharath Hariharan, Pablo Andrés Arbeláez, Ross B. Girshick, and Jitendra Malik. 2014. Hypercolumns for object segmentation and fine-grained localization. CoRR, abs/1411.5752. arXiv: 1411.5752. http://arxiv.org/abs/1411.5752.Google Scholar"",""O. Ronneberger, P. Fischer, and T. Brox. 2015. U-net: convolutional networks for biomedical image segmentation. In Medical Image Computing and Computer-Assisted Intervention -- MICCAI. Springer, Cham, 234--241.Google Scholar"",""M. Hata. 1980. Empirical formula for propagation loss in land mobile radio services. IEEE Transactions on Vehicular Technology, 29, 3, 317--325.Google ScholarCross Ref"",""V Erceg, K.V.S. Hari, M S. Smith, D.s Baum, K P. Sheikh, C Tappenden, J M. Costa, C Bushue, A Sarajedini, R Schwartz, and D Branlund. 2001. Channel models for fixed wireless application. IEEE 802.16 Broadband Wireless Access Working Group, Tech Rep, (January 2001).Google Scholar"",""Forsk. 2019. Atoll 3.1.0 model calibration guide. https://www.forsk.com/atoll - overview. Accessed: 2019-1-21. (March 2019).Google Scholar"",""Siradel. 2019. Volcano propagation model. (March 2019). https://www.siradel.com/software/connectivity/volcanosoftware/.Google Scholar""]"
https://doi.org/10.1145/3394486.3403288,Neural Input Search for Large Scale Recommendation Models,"Recommendation problems with large numbers of discrete items, such as products, webpages, or videos, are ubiquitous in the technology industry. Deep neural networks are being increasingly used for these recommendation problems. These models use embeddings to represent discrete items as continuous vectors, and the vocabulary sizes and embedding dimensions, despite their heavy influence on the model's accuracy, are often manually selected in a heuristical manner. We present Neural Input Search (NIS), a technique for learning the optimal vocabulary sizes and embedding dimensions for categorical features. The goal is to maximize prediction accuracy subject to a constraint on the total memory used by all embeddings. Moreover, we argue that the traditional Single-size Embedding (SE), which uses the same embedding dimension for all values of a feature, suffers from inefficient usage of model capacity and training data. We propose a novel type of embedding, namely Multi-size Embedding (ME), which allows the embedding dimension to vary for different values of the feature. During training we use reinforcement learning to find the optimal vocabulary size for each feature and embedding dimension for each value of the feature. Experimentation on two public recommendation datasets shows that NIS can find significantly better models with much fewer embedding parameters. We also deployed NIS in production to a real world large scale App ranking model in our company's App store, Google Play, resulting in +1.02% App Install with 30% smaller model size.","[{""name"":""Manas R. Joglekar"",""id"":""/profile/99659574223""},{""name"":""Cong Li"",""id"":""/profile/99659574359""},{""name"":""Mei Chen"",""id"":""/profile/99659574853""},{""name"":""Taibai Xu"",""id"":""/profile/99659534928""},{""name"":""Xiaoming Wang"",""id"":""/profile/99659574979""},{""name"":""Jay K. Adams"",""id"":""/profile/99659573995""},{""name"":""Pranav Khaitan"",""id"":""/profile/81486657286""},{""name"":""Jiahui Liu"",""id"":""/profile/99659573651""},{""name"":""Quoc V. Le"",""id"":""/profile/81339511241""},{""name"":""Manas R. Joglekar"",""id"":""/profile/99659574223""},{""name"":""Cong Li"",""id"":""/profile/99659574359""},{""name"":""Mei Chen"",""id"":""/profile/99659574853""},{""name"":""Taibai Xu"",""id"":""/profile/99659534928""},{""name"":""Xiaoming Wang"",""id"":""/profile/99659574979""},{""name"":""Jay K. Adams"",""id"":""/profile/99659573995""},{""name"":""Pranav Khaitan"",""id"":""/profile/81486657286""},{""name"":""Jiahui Liu"",""id"":""/profile/99659573651""},{""name"":""Quoc V. Le"",""id"":""/profile/81339511241""}]","[""Trapit Bansal, David Belanger, and Andrew McCallum. 2016. Ask the GRU: Multi-task Learning for Deep Text Recommendations. In Proceedings of the 10th ACM Conference on Recommender Systems (Boston, Massachusetts, USA) (RecSys '16). ACM, New York, NY, USA, 107--114. https://doi.org/10.1145/2959100.2959180Google ScholarDigital Library"",""Gabriel Bender, Pieter-Jan Kindermans, Barret Zoph, Vijay Vasudevan, and Quoc Le. 2018. Understanding and Simplifying One-Shot Architecture Search. In Proceedings of the 35th International Conference on Machine Learning (Proceedings of Machine Learning Research, Vol. 80),, Jennifer Dy and Andreas Krause (Eds.). Stockholmsmässan, Stockholm Sweden, 550--559.Google Scholar"",""Andrew Brock, Theo Lim, J.M. Ritchie, and Nick Weston. 2018. SMASH: One-Shot Model Architecture Search through HyperNetworks. In International Conference on Learning Representations.Google Scholar"",""Han Cai, Jiacheng Yang, Weinan Zhang, Song Han, and Yong Yu. 2018. Path-Level Network Transformation for Efficient Architecture Search. In Proceedings of the 35th International Conference on Machine Learning (Proceedings of Machine Learning Research, Vol. 80), Jennifer Dy and Andreas Krause (Eds.). Stockholmsmässan, Stockholm Sweden, 678--687.Google Scholar"",""Han Cai, Ligeng Zhu, and Song Han. 2019. Proxyless NAS: Direct Neural Architecture Search on Target Task and Hardware. In International Conference on Learning Representations.Google Scholar"",""Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, Rohan Anil, Zakaria Haque, Lichan Hong, Vihan Jain, Xiaobing Liu, and Hemal Shah. 2016. Wide \u0026 Deep Learning for Recommender Systems. In Proceedings of the 1st Workshop on Deep Learning for Recommender Systems (Boston, MA, USA) (DLRS 2016). ACM, New York, NY, USA, 7--10. https://doi.org/10.1145/2988450.2988454Google ScholarDigital Library"",""Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep Neural Networks for YouTube Recommendations. In Proceedings of the 10th ACM Conference on Recommender Systems (Boston, Massachusetts, USA) (RecSys '16). ACM, New York, NY, USA, 191--198. https://doi.org/10.1145/2959100.2959190Google ScholarDigital Library"",""Tim Donkers, Benedikt Loepp, and Jürgen Ziegler. 2017. Sequential User-based Recurrent Neural Network Recommendations. In Proceedings of the Eleventh ACM Conference on Recommender Systems (Como, Italy) (RecSys '17). ACM, New York, NY, USA, 152--160. https://doi.org/10.1145/3109859.3109877Google ScholarDigital Library"",""Carlos A. Gomez-Uribe and Neil Hunt. 2015. The Netflix Recommender System: Algorithms, Business Value, and Innovation. ACM Trans. Manage. Inf. Syst., Vol. 6, 4, Article 13 (Dec. 2015), 19 pages. https://doi.org/10.1145/2843948Google ScholarDigital Library"",""Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In Proceedings of the 26th international conference on world wide web. 173--182.Google ScholarDigital Library"",""Binbin Hu, Chuan Shi, Wayne Xin Zhao, and Philip S Yu. 2018. Leveraging meta-path based context for top-n recommendation with a neural co-attention model. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1531--1540.Google ScholarDigital Library"",""Donghyun Kim, Chanyoung Park, Jinoh Oh, Sungyoung Lee, and Hwanjo Yu. 2016. Convolutional Matrix Factorization for Document Context-Aware Recommendation. In Proceedings of the 10th ACM Conference on Recommender Systems (Boston, Massachusetts, USA) (RecSys '16). ACM, New York, NY, USA, 233--240. https://doi.org/10.1145/2959100.2959165Google ScholarDigital Library"",""Dawen Liang, Rahul G Krishnan, Matthew D Hoffman, and Tony Jebara. 2018. Variational autoencoders for collaborative filtering. In Proceedings of the 2018 World Wide Web Conference. 689--698.Google ScholarDigital Library"",""Chenxi Liu, Barret Zoph, Maxim Neumann, Jonathon Shlens, Wei Hua, Li-Jia Li, Li Fei-Fei, Alan Yuille, Jonathan Huang, and Kevin Murphy. 2018. Progressive Neural Architecture Search. In The European Conference on Computer Vision (ECCV).Google Scholar"",""Hanxiao Liu, Karen Simonyan, and Yiming Yang. 2019. DARTS: Differentiable Architecture Search. In International Conference on Learning Representations.Google Scholar"",""Renqian Luo, Fei Tian, Tao Qin, Enhong Chen, and Tie-Yan Liu. 2018. Neural Architecture Optimization. In Advances in Neural Information Processing Systems 31, S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (Eds.). Curran Associates, Inc., 7816--7827.Google ScholarDigital Library"",""Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. 2016. Asynchronous Methods for Deep Reinforcement Learning. In Proceedings of The 33rd International Conference on Machine Learning (Proceedings of Machine Learning Research, Vol. 48),, Maria Florina Balcan and Kilian Q. Weinberger (Eds.). PMLR, New York, New York, USA, 1928--1937.Google Scholar"",""Hieu Pham, Melody Guan, Barret Zoph, Quoc Le, and Jeff Dean. 2018. Efficient Neural Architecture Search via Parameters Sharing. In Proceedings of the 35th International Conference on Machine Learning (Proceedings of Machine Learning Research, Vol. 80),, Jennifer Dy and Andreas Krause (Eds.). PMLR, Stockholmsmässan, Stockholm Sweden, 4095--4104.Google Scholar"",""Esteban Real, Alok Aggarwal, Yanping Huang, and Quoc V. Le. 2018. Regularized Evolution for Image Classifier Architecture Search. CoRR, Vol. abs/1802.01548 (2018). arxiv: 1802.01548Google Scholar"",""Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, and Quoc V. Le. 2018. MnasNet: Platform-Aware Neural Architecture Search for Mobile. CoRR, Vol. abs/1807.11626 (2018). arxiv: 1807.11626Google Scholar"",""Aaron van den Oord, Sander Dieleman, and Benjamin Schrauwen. 2013. Deep content-based music recommendation. In Advances in Neural Information Processing Systems 26, C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger (Eds.). Curran Associates, Inc., 2643--2651.Google ScholarDigital Library"",""Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019 a. Neural graph collaborative filtering. In Proceedings of the 42nd international ACM SIGIR conference on Research and development in Information Retrieval. 165--174.Google ScholarDigital Library"",""Xiang Wang, Dingxian Wang, Canran Xu, Xiangnan He, Yixin Cao, and Tat-Seng Chua. 2019 b. Explainable reasoning over knowledge graphs for recommendation. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 5329--5336.Google ScholarCross Ref"",""Xiang Wang, Dingxian Wang, Canran Xu, Xiangnan He, Yixin Cao, and Tat-Seng Chua. 2019 c. Explainable reasoning over knowledge graphs for recommendation. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 5329--5336.Google ScholarCross Ref"",""Sirui Xie, Hehui Zheng, Chunxiao Liu, and Liang Lin. 2019. SNAS: stochastic neural architecture search. In International Conference on Learning Representations.Google Scholar"",""Xin Xin, Xiangnan He, Yongfeng Zhang, Yongdong Zhang, and Joemon Jose. 2019. Relational collaborative filtering: Modeling multiple item relations for recommendation. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval. 125--134.Google ScholarDigital Library"",""Zhao Zhong, Junjie Yan, Wei Wu, Jing Shao, and Cheng-Lin Liu. 2018. Practical Block-Wise Neural Network Architecture Generation. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR).Google Scholar"",""Barret Zoph and Quoc V. Le. 2017. Neural Architecture Search with Reinforcement Learning. In International Conference on Learning Representations.Google Scholar"",""Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V. Le. 2018. Learning Transferable Architectures for Scalable Image Recognition. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR).Google Scholar""]"
https://doi.org/10.1145/3394486.3403289,Easy Perturbation EEG Algorithm for Spectral Importance (easyPEASI): A Simple Method to Identify Important Spectral Features of EEG in Deep Learning Models,"Efforts into understanding neurological differences between populations is an active area of research. Deep learning has recently shown promising results using EEG as input to distinguish recordings of subjects based on neurological activity. However, only about one quarter of these studies investigate the underlying neurophysiological implications. This work proposes and validates a method to investigate frequency bands important to EEG-driven deep learning models. Easy perturbation EEG algorithm for spectral importance (easyPEASI) is simpler than previous methods and requires only perturbations to input data. We validate easyPEASI on EEG pathology classification using the Temple University Health EEG Corpus. easyPEASI is further applied to characterize the effects of patients' medications on brain rhythms. We investigate classifications of patients taking one of two anticonvulsant medications, Dilantin (phenytoin) and Keppra (levetiracetam), and subjects taking no medications. We find that for recordings of subjects with clinically-determined normal EEG that these medications effect the Theta and Alpha band most significantly. For recordings with clinically-determined abnormal EEG these medications affected the Delta, Theta, and Alpha bands most significantly. We also find the Beta band to be affected differently by the two medications. Results found here show promise for a method of obtaining explainable artificial intelligence and interpretable models from EEG-driven deep learning through a simpler more accessible method perturbing only input data. Overall, this work provides a fast, easy, and reproducible method to automatically determine salient spectral features of neural activity that have been learned by machine learning models, such as deep learning.","[{""name"":""David O. Nahmias"",""id"":""/profile/99659573374""},{""name"":""Kimberly L. Kontson"",""id"":""/profile/99659574456""},{""name"":""David O. Nahmias"",""id"":""/profile/99659573374""},{""name"":""Kimberly L. Kontson"",""id"":""/profile/99659574456""}]","[""Bassel Abou-Khalil. 2008. Levetiracetam in the treatment of epilepsy. Neuropsychiatric disease and treatment, Vol. 4, 3 (2008), 507--523. https://doi.org/10.2147/ndt.s2937Google Scholar"",""Jean-Marc Fellous, Guillermo Sapiro, Andrew Rossi, Helen Mayberg, and Michele Ferrante. 2019. Explainable Artificial Intelligence for Neuroscience: Behavioral Neurostimulation. Frontiers in Neuroscience, Vol. 13 (2019), 1346. https://doi.org/10.3389/fnins.2019.01346Google ScholarCross Ref"",""A. Harati, S. Lopez, I. Obeid, M. Jacobson, S. Tobochnik, and J. Picone. 2014. The TUH EEG Corpus: A Big Data Resource for Automated EEG Interpretation. In Proceedings of the IEEE Signal Processing in Medicine and Biology Symposium (2014), 1--5.Google Scholar"",""O. Jensen, P. Goel, N. Kopell, M. Pohja, R. Hari, and B. Ermentrout. 2005. On the human sensorimotor-cortex beta rhythm: Sources and modeling. NeuroImage, Vol. 26, 2 (2005), 347--355. https://doi.org/10.1016/j.neuroimage.2005.02.008Google ScholarCross Ref"",""William H. Kruskal and W. Allen Wallis. 1952. Use of Ranks in One-Criterion Variance Analysis. J. Amer. Statist. Assoc., Vol. 47, 260 (1952), 583--621.Google ScholarCross Ref"",""Chi Qin Lai et almbox. 2018. Literature survey on applications of electroencephalography (EEG). AIP Conference Proceedings, Vol. 2016, 020070 (2018).Google Scholar"",""S. Lopez. 2017. Automated Identification of Abnormal EEGs. Temple University (2017).Google Scholar"",""S. López, G. Suarez, D. Jungreis, I. Obeid, and J. Picone. 2015. Automated Identification of Abnormal Adult EEGs. In IEEE Signal Processing in Medicine and Biology Symposium (SPMB). https://doi.org/10.1109/SPMB.2015.7405423Google Scholar"",""David O. Nahmias, Kimberly L. Kontson, David A. Soltysik, and F. Civillico, Eugene. 2019. Consistency of Quantitative Electroencephalography Features in a Large Clinical Data Set. Journal of Neural Engineering, Vol. 16, 066044 (2019). https://doi.org/10.1088/1741--2552/ab4af3Google ScholarCross Ref"",""F. Nasse, C. Thurau, and G. A. Fink. 2009. A review of classification algorithms for EEG-based brain-computer interfaces: a 10 year update. International Conference on Computer Analysis of Images and Patterns (2009), 83--90.Google Scholar"",""Jennifer J. Newson and Tara C. Thiagarajan. 2019. EEG Frequency Bands in Psychiatric Disorders: A Review of Resting State Studies. Frontiers in Human Neuroscience, Vol. 12 (2019), 521. https://doi.org/10.3389/fnhum.2018.00521Google ScholarCross Ref"",""F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011. Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, Vol. 12 (2011), 2825--2830.Google ScholarDigital Library"",""M. Rogawski and W Löscher. 2004. The neurobiology of antiepileptic drugs. Nature Review Neuroscience, Vol. 5 (2004), 553--564. https://doi.org/10.1038/nrn1430Google ScholarCross Ref"",""Yannick Roy et almbox. 2019. Deep learning-based electroencephalography analysis: a systematic review. Journal of Neural Engineering, Vol. 16, 051001 (2019). https://doi.org/10.1088/1741-2552/ab260c/Google Scholar"",""W. Samek, A. Binder, G. Montavon, S. Lapuschkin, and K. Müller. 2017. Evaluating the Visualization of What a Deep Neural Network Has Learned. IEEE Transactions on Neural Networks and Learning Systems, Vol. 28, 11 (Nov 2017), 2660--2673. https://doi.org/10.1109/TNNLS.2016.2599820Google ScholarCross Ref"",""R. Schirrmeister, L. Gemein, Eggensperger, F. Hutter, and T. Ball. 2017. Deep learning with convolutional neural networks for decoding and visualization of EEG pathology. The IEEE Signal Processing in Medicine and Biology Symposium (December 2017).Google Scholar"",""Donald L. Schomer and Fernando H. Lopes da Silva. 2010. Niedermeyer's Electroencephalography: Basic Principles, Clinical Applications, and Related Fields 6 ed.). Lippincott Williams \u0026 Wilkins.Google Scholar"",""J. Shen, C. Zhang, B. Jiang, J. Chen, Z. Song, J.and Liu, and W. K.. Ming. 2019. Artificial Intelligence Versus Clinicians in Disease Diagnosis: Systematic Review. JMIR medical informatics, Vol. 7(3), e10010 (2019). https://doi.org/10.2196/10010Google Scholar"",""Pierre Thodoroff, Joelle Pineau, and Andrew Lim. 2016. Learning Robust Features using Deep Learning for Automatic Seizure Detection. CoRR, Vol. abs/1608.00220 (2016). arxiv: 1608.00220 http://arxiv.org/abs/1608.00220Google Scholar"",""Michel J. A. M. van Putten, Sebastian Olbrich, and Martijn Arns. 2018. Predicting sex from brain rhythms with deep learning. Nature: Scientific Reports, Vol. 8, 3069 (2018).Google Scholar"",""Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, Stéfan J. van der Walt, Matthew Brett, Joshua Wilson, K. Jarrod Millman, Nikolay Mayorov, Andrew R. J. Nelson, Eric Jones, Robert Kern, Eric Larson, CJ Carey,.Ilhan Polat, Yu Feng, Eric W. Moore, Jake Vand erPlas, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen, E. A. Quintero, Charles R Harris, Anne M. Archibald, Antônio H. Ribeiro, Fabian Pedregosa, Paul van Mulbregt, and SciPy 1. 0 Contributors. 2019. SciPy 1.0--Fundamental Algorithms for Scientific Computing in Python. arXiv e-prints, Article arXiv:1907.10121 (Jul 2019), Xiv:1907.10121 pages.arxiv: cs.MS/1907.10121Google Scholar"",""Matthew D. Zeiler and Rob Fergus. 2014. Visualizing and Understanding Convolutional Networks. In Computer Vision -- ECCV 2014,, David Fleet, Tomas Pajdla, Bernt Schiele, and Tinne Tuytelaars (Eds.). Springer International Publishing, Cham, 818--833. https://doi.org/10.1007/978-3-319-10590-1_53Google Scholar""]"
https://doi.org/10.1145/3394486.3403290,Building Continuous Integration Services for Machine Learning,"Continuous integration (CI) has been a de facto standard for building industrial-strength software. Yet, there is little attention towards applying CI to the development of machine learning (ML) applications until the very recent effort on the theoretical side. In this paper, we take a step forward to bring the theory into practice.We develop the first CI system for ML, to the best of our knowledge, that integrates seamlessly with existing ML development tools. We present its design and implementation details.","[{""name"":""Bojan Karlaš"",""id"":""/profile/99659304361""},{""name"":""Matteo Interlandi"",""id"":""/profile/81474705142""},{""name"":""Cedric Renggli"",""id"":""/profile/99659363985""},{""name"":""Wentao Wu"",""id"":""/profile/99659165461""},{""name"":""Ce Zhang"",""id"":""/profile/99659462261""},{""name"":""Deepak Mukunthu Iyappan Babu"",""id"":""/profile/99659574089""},{""name"":""Jordan Edwards"",""id"":""/profile/99659573697""},{""name"":""Chris Lauren"",""id"":""/profile/99659574094""},{""name"":""Andy Xu"",""id"":""/profile/99659574336""},{""name"":""Markus Weimer"",""id"":""/profile/81363605401""},{""name"":""Bojan Karlaš"",""id"":""/profile/99659304361""},{""name"":""Matteo Interlandi"",""id"":""/profile/81474705142""},{""name"":""Cedric Renggli"",""id"":""/profile/99659363985""},{""name"":""Wentao Wu"",""id"":""/profile/99659165461""},{""name"":""Ce Zhang"",""id"":""/profile/99659462261""},{""name"":""Deepak Mukunthu Iyappan Babu"",""id"":""/profile/99659574089""},{""name"":""Jordan Edwards"",""id"":""/profile/99659573697""},{""name"":""Chris Lauren"",""id"":""/profile/99659574094""},{""name"":""Andy Xu"",""id"":""/profile/99659574336""},{""name"":""Markus Weimer"",""id"":""/profile/81363605401""}]","[""Amazon sage maker. https://aws.amazon.com/sagemaker/.Google Scholar"",""Aws codepipeline. https://aws.amazon.com/codepipeline/.Google Scholar"",""Azure devops services. https://azure.microsoft.com/en-us/services/devops/.Google Scholar"",""Git LFS. https://git-lfs.github.com/.Google Scholar"",""Google cloud automl. https://cloud.google.com/automl/.Google Scholar"",""Microsoft azure machine learning. https://azure.microsoft.com/en-us/services/machine-learning/.Google Scholar"",""mltest tool open-source repository on github. https://aka.ms/gsl-ml-test.Google Scholar"",""Continuous integration for machine learning. https://medium.com/@rstojnic/continuous-integration-for-machine-learning-6893aa867002, April 2018.Google Scholar"",""S. Ackermann et al. Using transfer learning to detect galaxy mergers. MNRAS, 2018.Google ScholarCross Ref"",""P. Baldi, P. Sadowski, and D. Whiteson. Searching for exotic particles in high-energy physics with deep learning. Nature communications, 5:4308, 2014.Google ScholarCross Ref"",""A. Blum and M. Hardt. The ladder: A reliable leaderboard for machine learning competitions. In ICML, pages 1006--1014, 2015.Google Scholar"",""P. M. Duvall, S. Matyas, and A. Glover. Continuous integration: improving software quality and reducing risk. Pearson Education, 2007.Google ScholarDigital Library"",""C. Dwork et al. The reusable holdout: Preserving validity in adaptive data analysis. Science, 349(6248):636--638, 2015.Google ScholarCross Ref"",""I. Girardi et al. Patient risk assessment and warning symptom detection using deep attention-based neural networks. LOUHI, 2018.Google ScholarCross Ref"",""B. Karlas, J. Liu, W. Wu, and C. Zhang. Ease.ml in action: Towards multi-tenant declarative learning services. PVLDB, 11(12):2054--2057, 2018.Google ScholarDigital Library"",""T. Kraska. Northstar: An interactive data science system. PVLDB, 11(12):2150--2164, 2018.Google ScholarDigital Library"",""A. F. Lara. Continuous integration for ml projects. https://medium.com/onfido-tech/continuous-integration-for-ml-projects-e11bc1a4d34f, October 2017.Google Scholar"",""A. F. Lara. Continuous delivery for ml models. https://medium.com/onfido-tech/continuous-delivery-for-ml-models-c1f9283aa971, July 2018.Google Scholar"",""T. Li, J. Zhong, J. Liu, W. Wu, and C. Zhang. Ease.ml: Towards multi-tenant resource sharing for machine learning workloads. PVLDB, 11(5):607--620, 2018.Google Scholar"",""C. Renggli et al. Continuous integration of machine learning models with ease.ml/ci: Towards a rigorous yet practical treatment. In SysML, 2019.Google Scholar"",""C. Renggli, F. A. Hubis, B. Karlas, K. Schawinski, W. Wu, and C. Zhang. Ease.ml/ci and ease.ml/meter in action: Towards data management for statistical generalization. PVLDB, 12(12):1962--1965, 2019.Google ScholarDigital Library"",""K. Schawinski et al. Generative adversarial networks recover features in astrophysical images of galaxies beyond the deconvolution limit. MNRAS, 2017.Google ScholarCross Ref"",""K. Schawinski et al. Exploring galaxy evolution with generative models. Astronomy \u0026 Astrophysics, 2018.Google ScholarCross Ref"",""D. Stark et al. PSFGAN: a generative adversarial network system for separating quasar point sources and host galaxy light. MNRAS, 2018.Google ScholarCross Ref"",""M. Su et al. Generative adversarial networks as a tool to recover structural information from cryo-electron microscopy data. BioRxiv, 2018.Google ScholarCross Ref"",""D. Tran. Continuous integration for data science. http://engineering.pivotal.io/post/continuous-integration-for-data-science/, February 2017.Google Scholar"",""C. Zhang, W. Wu, and T. Li. An overreaction to the broken machine learning abstraction: The ease.ml vision. In [email protected] 2017, pages 3:1--3:6, 2017.Google Scholar""]"
https://doi.org/10.1145/3394486.3403291,Learning to Cluster Documents into Workspaces Using Large Scale Activity Logs,"Google Drive is widely used for managing personal and work-related documents in the cloud. To help users organize their documents in Google Drive, we develop a new feature to allow users to create a set of working files for ongoing easy access, called workspace. A workspace is a cluster of documents, but unlike a typical document cluster, it contains documents that are not only topically coherent, but are also useful in the ongoing user tasks.To alleviate the burden of creating workspaces manually, we automatically cluster documents into suggested workspaces. We go beyond the textual similarity-based unsupervised clustering paradigm and instead directly learn from users' activity for document clustering. More specifically, we extract co-access signals (i.e., whether a user accessed two documents around the same time) to measure document relatedness. We then use a neural document similarity model that incorporates text, metadata, as well as co-access features. Since human labels are often difficult or expensive to collect, we extract weak labels based on co-access data at large scale for model training. Our offline and online experiments based on Google Drive show that (a) co-access features are very effective for document clustering; (b) our weakly supervised clustering achieves comparable or even better performance compared to the models trained with human labels; and (c) the weakly supervised method leads to better workspace suggestions that the users accept more often in the production system than baseline approaches.","[{""name"":""Weize Kong"",""id"":""/profile/99659573750""},{""name"":""Michael Bendersky"",""id"":""/profile/81363606444""},{""name"":""Marc Najork"",""id"":""/profile/81100303448""},{""name"":""Brandon Vargo"",""id"":""/profile/81501683279""},{""name"":""Mike Colagrosso"",""id"":""/profile/99659192827""},{""name"":""Weize Kong"",""id"":""/profile/99659573750""},{""name"":""Michael Bendersky"",""id"":""/profile/81363606444""},{""name"":""Marc Najork"",""id"":""/profile/81100303448""},{""name"":""Brandon Vargo"",""id"":""/profile/81501683279""},{""name"":""Mike Colagrosso"",""id"":""/profile/99659192827""}]","[""Elke Achtert, Sascha Goldhofer, Hans-Peter Kriegel, Erich Schubert, and Arthur Zimek. 2012. Evaluation of Clusterings--Metrics and Visual Support. In Proc. of ICDE. 1285--1288.Google ScholarDigital Library"",""Charu C Aggarwal, Stephen C Gates, and Philip S Yu. 1999. On the merits of building categorization systems by supervised clustering. In Proc. of KDD. 352--356.Google ScholarDigital Library"",""Charu C Aggarwal, Stephen C Gates, and Philip S Yu. 2004. On using partial supervision for text categorization. IEEE TKDE, Vol. 16, 2 (2004), 245--255.Google Scholar"",""Charu C Aggarwal and ChengXiang Zhai. 2012. A survey of text clustering algorithms. In Mining Text Data. Springer, 77--128.Google ScholarDigital Library"",""Eugene Agichtein, Eric Brill, and Susan Dumais. 2006. Improving web search ranking by incorporating user behavior information. In Proc. of SIGIR. 19--26.Google ScholarDigital Library"",""Sugato Basu, Arindam Banerjee, and Raymond Mooney. 2002. Semi-supervised clustering by seeding. In Proc. of ICML. 27--34.Google Scholar"",""Doug Beeferman and Adam Berger. 2000. Agglomerative clustering of a search engine query log. In Proc. of KDD. 407--416.Google ScholarDigital Library"",""Michael Bendersky, Xuanhui Wang, Donald Metzler, and Marc Najork. 2017. Learning from user interactions in personal search via attribute parameterization. In Proc. of WSDM. 791--799.Google ScholarDigital Library"",""David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent dirichlet allocation. Journal of Machine Learning Research, Vol. 3, Jan (2003), 993--1022.Google ScholarDigital Library"",""William W Cohen and Jacob Richman. 2002. Learning to match and cluster large high-dimensional data sets for data integration. In Proc. of KDD. 475--480.Google ScholarDigital Library"",""Zhuyun Dai, Chenyan Xiong, and Jamie Callan. 2016. Query-biased partitioning for selective search. In Proc. of CIKM. 1119--1128.Google ScholarDigital Library"",""Scott Deerwester, Susan T Dumais, George W Furnas, Thomas K Landauer, and Richard Harshman. 1990. Indexing by latent semantic analysis. Journal of the American Society for Information Science, Vol. 41, 6 (1990), 391--407.Google ScholarCross Ref"",""Thomas Finley and Thorsten Joachims. 2005. Supervised clustering with support vector machines. In Proc. of ICML. 217--224.Google ScholarDigital Library"",""Thomas Hofmann. 1999. Probabilistic latent semantic indexing. In Proc. of SIGIR. 50--57.Google ScholarDigital Library"",""Mohit Iyyer, Varun Manjunatha, Jordan Boyd-Graber, and Hal Daumé III. 2015. Deep unordered composition rivals syntactic methods for text classification. In Proc. of ACL, Vol. 1. 1681--1691.Google Scholar"",""Daxin Jiang, Jian Pei, and Hang Li. 2013. Mining search and browse logs for web search: A survey. ACM Transactions on Intelligent Systems and Technology (TIST), Vol. 4, 4 (2013), 57.Google Scholar"",""Thorsten Joachims. 2002. Optimizing search engines using clickthrough data. In Proc. of KDD. 133--142.Google ScholarDigital Library"",""Thorsten Joachims, Laura A Granka, Bing Pan, Helene Hembrooke, and Geri Gay. 2005. Accurately interpreting clickthrough data as implicit feedback. In Proc. of SIGIR. 154--161.Google ScholarDigital Library"",""Toshihiro Kamishima and Fumio Motoyoshi. 2003. Learning from cluster examples. Machine Learning, Vol. 53, 3 (2003), 199--233.Google ScholarDigital Library"",""Diane Kelly and Jaime Teevan. 2003. Implicit feedback for inferring user preference: a bibliography. SIGIR Forum, Vol. 37, 2 (2003), 18--28.Google ScholarDigital Library"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems. 3111--3119.Google Scholar"",""Vincent Ng and Claire Cardie. 2002. Improving machine learning approaches to coreference resolution. In Proc. of ACL. 104--111.Google Scholar"",""Barbara Poblete and Ricardo Baeza-Yates. 2008. Query-sets: using implicit feedback and query patterns to organize web documents. In Proc. of WWW. 41--50.Google ScholarDigital Library"",""Filip Radlinski and Thorsten Joachims. 2005. Query chains: learning to rank from implicit feedback. In Proc. of KDD. 239--248.Google ScholarDigital Library"",""Gerard Salton and Michael J McGill. 1986. Introduction to Modern Information Retrieval. McGraw-Hill, Inc.Google Scholar"",""Amit Singhal. 2012. Introducing the knowledge graph: things, not strings. https://blog.google/products/search/introducing-knowledge-graph-things-not/.Google Scholar"",""Latanya Sweeney. 2002. k-anonymity: A model for protecting privacy. Intl. Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, Vol. 10, 05 (2002), 557--570.Google ScholarDigital Library"",""C.J. van Rijsbergen. 1979. Information Retrieval. Butterworth.Google Scholar"",""Xuanhui Wang, Michael Bendersky, Donald Metzler, and Marc Najork. 2016. Learning to rank with selection bias in personal search. In Proc. of SIGIR. 115--124.Google ScholarDigital Library"",""Xuanhui Wang and ChengXiang Zhai. 2007. Learn from web search logs to organize search results. In Proc. of SIGIR. 87--94.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403292,What is that Building?: An End-to-end System for Building Recognition from Streetside Images,"The paper describes Streetside Building Search-Retrieve System (SBSRS) - a system for recognizing buildings from steetside images. SBSRS powers several distinct applications: 1) it improves map-search by enriching its streetview service with semantic information, such as location, business name, open hours, etc.; 2) it enables search by image and location - a novel form of visual image search where both visual and location signals are used to identify the most relevant result to a query image of a building.SBSRS works in an entirely unsupervised way. It has an offline component, which generates an index of building objects by scraping streetview images, segmenting and conflating them with business information. An online component can then search over the index, utilizing location information to retrieve a small set of geo-relevant results, which are then re-ranked using novel highly accurate visual descriptors. To evaluate the system, we generate a dataset of over 23K unique business buildings from four major US cities. This significantly exceeds the number of landmarks in datasets previously used by similar systems. We compare our system with a state-of-the-art baseline and show its accuracy on our new buildings dataset as well as on two popular landmark datasets.","[{""name"":""Chiqun Zhang"",""id"":""/profile/99659574425""},{""name"":""Dragomir Yankov"",""id"":""/profile/99659481155""},{""name"":""Chun-Ting Wu"",""id"":""/profile/99659573872""},{""name"":""Simon Shapiro"",""id"":""/profile/99659573744""},{""name"":""Jason Hong"",""id"":""/profile/99659574814""},{""name"":""Wei Wu"",""id"":""/profile/99659451374""},{""name"":""Chiqun Zhang"",""id"":""/profile/99659574425""},{""name"":""Dragomir Yankov"",""id"":""/profile/99659481155""},{""name"":""Chun-Ting Wu"",""id"":""/profile/99659573872""},{""name"":""Simon Shapiro"",""id"":""/profile/99659573744""},{""name"":""Jason Hong"",""id"":""/profile/99659574814""},{""name"":""Wei Wu"",""id"":""/profile/99659451374""}]","[""2019. US Building Footprints. https://github.com/Microsoft/USBuildingFootprintsGoogle Scholar"",""2020. Bing Maps REST Services. https://docs.microsoft.com/en-us/bingmaps/restservices/Google Scholar"",""Artem Babenko, Anton Slesarev, Alexandr Chigorin, and Victor Lempitsky. 2014. Neural codes for image retrieval. In European conference on computer vision. Springer, 584--599.Google ScholarCross Ref"",""Stanley M Bileschi. 2006. StreetScenes: Towards scene understanding in still images. Technical Report. MASSACHUSETTS INST OF TECH CAMBRIDGE.Google Scholar"",""Jane Bromley, Isabelle Guyon, Yann LeCun, Eduard Säckinger, and Roopak Shah. 1994. Signature verification using a \""siamese\"" time delay neural network. In Advances in neural information processing systems. 737--744.Google Scholar"",""Sumit Chopra, Raia Hadsell, Yann LeCun, et almbox. 2005. Learning a similarity metric discriminatively, with application to face verification. In CVPR (1). 539--546.Google Scholar"",""Gabriella Csurka, Christopher Dance, Lixin Fan, Jutta Willamowski, and Cédric Bray. 2004. Visual categorization with bags of keypoints. In Workshop on statistical learning in computer vision, ECCV, Vol. 1. Prague, 1--2.Google Scholar"",""Ross Girshick. 2015. Fast r-cnn. In Proceedings of the IEEE international conference on computer vision. 1440--1448.Google ScholarDigital Library"",""Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra Malik. 2014. Rich feature hierarchies for accurate object detection and semantic segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR).Google ScholarDigital Library"",""Yunchao Gong, Svetlana Lazebnik, Albert Gordo, and Florent Perronnin. 2012. Iterative quantization: A procrustean approach to learning binary codes for large-scale image retrieval. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 35, 12 (2012), 2916--2929.Google ScholarDigital Library"",""Houdong Hu, Yan Wang, Linjun Yang, Pavel Komlev, Li Huang, Xi (Stephen) Chen, Jiapei Huang, Ye Wu, Meenaz Merchant, and Arun Sacheti. 2018. Web-Scale Responsive Visual Search at Bing. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining, KDD 2018, London, UK. 359--367.Google ScholarDigital Library"",""Hervé Jégou and Andrew Zisserman. 2014. Triangulation embedding and democratic aggregation for image search. In Proceedings of the IEEE conference on computer vision and pattern recognition. 3310--3317.Google ScholarDigital Library"",""Gregory Koch, Richard Zemel, and Ruslan Salakhutdinov. 2015. Siamese neural networks for one-shot image recognition. In ICML deep learning workshop, Vol. 2.Google Scholar"",""Alina Kuznetsova, Hassan Rom, Neil Alldrin, Jasper Uijlings, Ivan Krasin, Jordi Pont-Tuset, Shahab Kamali, Stefan Popov, Matteo Malloci, Tom Duerig, and Vittorio Ferrari. 2018. The Open Images Dataset V4: Unified image classification, object detection, and visual relationship detection at scale. arXiv:1811.00982 (2018).Google Scholar"",""David G Lowe. 2004. Distinctive image features from scale-invariant keypoints. International journal of computer vision, Vol. 60, 2 (2004), 91--110.Google ScholarDigital Library"",""Krista Merry and Pete Bettinger. 2019. Smartphone GPS accuracy study in an urban environment. PloS one, Vol. 14, 7 (2019).Google Scholar"",""Hyeonwoo Noh, Andre Araujo, Jack Sim, Tobias Weyand, and Bohyung Han. 2017. Large-scale image retrieval with attentive deep local features. In Proceedings of the IEEE International Conference on Computer Vision. 3456--3465.Google ScholarCross Ref"",""Florent Perronnin and Christopher Dance. 2007. Fisher kernels on visual vocabularies for image categorization. In 2007 IEEE conference on computer vision and pattern recognition. IEEE, 1--8.Google ScholarCross Ref"",""James Philbin, Ondrej Chum, Michael Isard, Josef Sivic, and Andrew Zisserman. 2007. Object Retrieval with Large Vocabularies and Fast Spatial Matching. In IEEE Conference on Computer Vision and Pattern Recognition.Google Scholar"",""James Philbin, Ondrej Chum, Michael Isard, Josef Sivic, and Andrew Zisserman. 2008. Lost in Quantization: Improving Particular Object Retrieval in Large Scale Image Databases. In IEEE Conference on Computer Vision and Pattern Recognition.Google Scholar"",""Filip Radenoviç, Ahmet Iscen, Giorgos Tolias, Yannis Avrithis, and Ondvr ej Chum. 2018. Revisiting Oxford and Paris: Large-Scale Image Retrieval Benchmarking. In CVPR.Google Scholar"",""Filip Radenović, Giorgos Tolias, and Ondvr ej Chum. 2016. CNN image retrieval learns from BoW: Unsupervised fine-tuning with hard examples. In European conference on computer vision. Springer, 3--20.Google ScholarCross Ref"",""Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. 2015. Faster r-cnn: Towards real-time object detection with region proposal networks. In Advances in neural information processing systems. 91--99.Google Scholar"",""Jerome Revaud, Jon Almazan, Rafael Sampaio de Rezende, and Cesar Roberto de Souza. 2019. Learning with Average Precision: Training Image Retrieval with a Listwise Loss. arXiv preprint arXiv:1906.07589 (2019).Google Scholar"",""Mark Sanderson. 2010. Christopher D. Manning, Prabhakar Raghavan, Hinrich Schütze, Introduction to Information Retrieval, Cambridge University Press. 2008. ISBN-13 978-0-521-86571-5, xxi 482 pages. Natural Language Engineering, Vol. 16, 1 (2010), 100--103.Google ScholarDigital Library"",""Florian Schroff, Dmitry Kalenichenko, and James Philbin. 2015. Facenet: A unified embedding for face recognition and clustering. In Proceedings of the IEEE conference on computer vision and pattern recognition. 815--823.Google ScholarCross Ref"",""Edgar Simo-Serra, Eduard Trulls, Luis Ferraz, Iasonas Kokkinos, Pascal Fua, and Francesc Moreno-Noguer. 2015. Discriminative learning of deep convolutional feature point descriptors. In Proceedings of the IEEE International Conference on Computer Vision. 118--126.Google ScholarDigital Library"",""Eleftherios Spyromitros-Xioufis, Symeon Papadopoulos, Ioannis Yiannis Kompatsiaris, Grigorios Tsoumakas, and Ioannis Vlahavas. 2014. A comprehensive study over VLAD and product quantization in large-scale image retrieval. IEEE Transactions on Multimedia, Vol. 16, 6 (2014), 1713--1728.Google ScholarCross Ref"",""Supasorn Suwajanakorn, Carlos Herná ndez, and Steven M. Seitz. 2015. Depth from focus with your mobile phone. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2015, Boston, MA, USA, June 7-12, 2015. 3497--3506.Google ScholarCross Ref"",""Marvin Teichmann, Andre Araujo, Menglong Zhu, and Jack Sim. 2019. Detect-to-retrieve: Efficient regional aggregation for image search. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 5109--5118.Google ScholarCross Ref"",""Giorgos Tolias, Yannis Avrithis, and Hervé Jégou. 2016. Image search with selective match kernels: aggregation across single and multiple images. International Journal of Computer Vision, Vol. 116, 3 (2016), 247--261.Google ScholarDigital Library"",""Jasper RR Uijlings, Koen EA Van De Sande, Theo Gevers, and Arnold WM Smeulders. 2013. Selective search for object recognition. International journal of computer vision, Vol. 104, 2 (2013), 154--171.Google Scholar"",""Nam N Vo and James Hays. 2016. Localizing and orienting street views using overhead imagery. In European conference on computer vision. Springer, 494--509.Google ScholarCross Ref"",""Haoran Wu, Zhiyong Xu, Jianlin Zhang, Wei Yan, and Xiao Ma. 2017. Face recognition based on convolution siamese networks. In 2017 10th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI). IEEE, 1--5.Google ScholarCross Ref"",""Mu Zhu. 2004. Recall, precision and average precision. Department of Statistics and Actuarial Science, University of Waterloo, Waterloo, Vol. 2 (2004), 30.Google Scholar""]"
https://doi.org/10.1145/3394486.3403293,MultiSage: Empowering GCN with Contextualized Multi-Embeddings on Web-Scale Multipartite Networks,"Graph convolutional networks (GCNs) are a powerful class of graph neural networks. Trained in a semi-supervised end-to-end fashion, GCNs can learn to integrate node features and graph structures to generate high-quality embeddings that can be used for various downstream tasks like search and recommendation. However, existing GCNs mostly work on homogeneous graphs and consider a single embedding for each node, which do not sufficiently model the multi-facet nature and complex interaction of nodes in real-world networks. Here, we present a contextualized GCN engine by modeling the multipartite networks of target nodes and their intermediatecontext nodes that specify the contexts of their interactions. Towards the neighborhood aggregation process, we devise a contextual masking operation at the feature level and a contextual attention mechanism at the node level to achieve interaction contextualization by treating neighboring target nodes based on intermediate context nodes. Consequently, we compute multiple embeddings for target nodes that capture their diverse facets and different interactions during graph convolution, which is useful for fine-grained downstream applications. To enable efficient web-scale training, we build a parallel random walk engine to pre-sample contextualized neighbors, and a Hadoop2-based data provider pipeline to pre-join training data, dynamically reduce multi-GPU training time, and avoid high memory cost. Extensive experiments on the bipartite Pinterest graph and tripartite OAG graph corroborate the advantage of the proposed system.","[{""name"":""Carl Yang"",""id"":""/profile/99659154893""},{""name"":""Aditya Pal"",""id"":""/profile/99659573511""},{""name"":""Andrew Zhai"",""id"":""/profile/82658617457""},{""name"":""Nikil Pancha"",""id"":""/profile/99659573254""},{""name"":""Jiawei Han"",""id"":""/profile/81548005096""},{""name"":""Charles Rosenberg"",""id"":""/profile/99659455355""},{""name"":""Jure Leskovec"",""id"":""/profile/81367595814""},{""name"":""Carl Yang"",""id"":""/profile/99659154893""},{""name"":""Aditya Pal"",""id"":""/profile/99659573511""},{""name"":""Andrew Zhai"",""id"":""/profile/82658617457""},{""name"":""Nikil Pancha"",""id"":""/profile/99659573254""},{""name"":""Jiawei Han"",""id"":""/profile/81548005096""},{""name"":""Charles Rosenberg"",""id"":""/profile/99659455355""},{""name"":""Jure Leskovec"",""id"":""/profile/81367595814""}]","[""Charu C Aggarwal. 2007. Data streams: models and algorithms. Vol. 31. Springer Science \u0026 Business Media.Google Scholar"",""Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko. 2013. Translating embeddings for modeling multi-relational data. In NIPS.Google Scholar"",""Jie Chen, Tengfei Ma, and Cao Xiao. 2018. Fastgcn: fast learning with graph convolutional networks via importance sampling. In ICLR.Google Scholar"",""Michaëll Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering. In NIPS.Google Scholar"",""Alberto Garcia Duran and Mathias Niepert. 2017. Learning graph representations with embedding propagation. In NIPS.Google Scholar"",""Chantat Eksombatchai, Pranav Jindal, Jerry Zitao Liu, Yuchen Liu, Rahul Sharma, Charles Sugnet, Mark Ulrich, and Jure Leskovec. 2018. Pixie: A system for recommending 3+ billion items to 200+ million users in real-time. In WWW.Google Scholar"",""Alessandro Epasto and Bryan Perozzi. 2019. Is a Single Embedding Enough? Learning Node Representations that Capture Multiple Social Contexts. In WWW.Google Scholar"",""Shaohua Fan, Junxiong Zhu, Xiaotian Han, Chuan Shi, Linmei Hu, Biyu Ma, and Yongliang Li. 2019. Metapath-guided Heterogeneous Graph Neural Network for Intent Recommendation. In KDD.Google Scholar"",""Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. 2017. Neural message passing for quantum chemistry. In ICML.Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In NIPS.Google Scholar"",""David K Hammond, Pierre Vandergheynst, and Rémi Gribonval. 2011. Wavelets on graphs via spectral graph theory. ACHA, Vol. 30, 2 (2011), 129--150.Google ScholarCross Ref"",""Wenbing Huang, Tong Zhang, Yu Rong, and Junzhou Huang. 2018. Adaptive sampling towards fast graph representation learning. In NIPS.Google Scholar"",""Glen Jeh and Jennifer Widom. 2003. Scaling personalized web search. In WWW.Google Scholar"",""Tianwen Jiang, Tong Zhao, Bing Qin, Ting Liu, Nitesh V Chawla, and Meng Jiang. 2019. The Role of: A Novel Scientific Knowledge Graph Representation and Construction Model. In KDD.Google Scholar"",""Thomas N Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional networks. In ICLR.Google Scholar"",""Johannes Klicpera, Aleksandar Bojchevski, and Stephan Günnemann. 2019. Combining neural networks with personalized pagerank for classification on graphs. In ICLR.Google Scholar"",""John Boaz Lee, Ryan Rossi, and Xiangnan Kong. 2018. Graph classification using structural attention. In KDD.Google Scholar"",""Qimai Li, Zhichao Han, and Xiao-Ming Wu. 2018. Deeper insights into graph convolutional networks for semi-supervised learning. In AAAI.Google Scholar"",""Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu. 2015. Learning entity and relation embeddings for knowledge graph completion. In AAAI.Google Scholar"",""Hanxiao Liu, Yuexin Wu, and Yiming Yang. 2017. Analogical inference for multi-relational embeddings. In ICML.Google Scholar"",""Ninghao Liu, Qiaoyu Tan, Yuening Li, Hongxia Yang, Jingren Zhou, and Xia Hu. 2019. Is a Single Vector Enough? Exploring Node Polysemy for Network Embedding. In KDD.Google Scholar"",""Yao Ma, Suhang Wang, Charu C Aggarwal, and Jiliang Tang. 2019. Graph Convolutional Networks with EigenPooling. In KDD.Google Scholar"",""Andrew L Maas, Awni Y Hannun, and Andrew Y Ng. 2013. Rectifier nonlinearities improve neural network acoustic models. In ICML.Google Scholar"",""Maithra Raghu, Ben Poole, Jon Kleinberg, Surya Ganguli, and Jascha Sohl Dickstein. 2017. On the expressive power of deep neural networks. In ICML.Google Scholar"",""Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den Berg, Ivan Titov, and Max Welling. 2018. Modeling relational data with graph convolutional networks. In ESWC.Google Scholar"",""Arnab Sinha, Zhihong Shen, Yang Song, Hao Ma, Darrin Eide, Bo-June Hsu, and Kuansan Wang. 2015. An overview of microsoft academic service (mas) and applications. In WWW.Google Scholar"",""Jie Tang, Jing Zhang, Limin Yao, Juanzi Li, Li Zhang, and Zhong Su. 2008. Arnetminer: extraction and mining of academic social networks. In KDD.Google Scholar"",""Lei Tang and Huan Liu. 2009. Relational learning via latent social dimensions. In KDD.Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In NIPS.Google Scholar"",""Andreas Veit, Serge Belongie, and Theofanis Karaletsos. 2017. Conditional similarity networks. In CVPR.Google Scholar"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2018. Graph attention networks. In ICLR.Google Scholar"",""Saurabh Verma and Zhi-Li Zhang. 2019. Stability and Generalization of Graph Convolutional Neural Networks. In KDD.Google Scholar"",""Hao Wang, Tong Xu, Qi Liu, Defu Lian, Enhong Chen, Dongfang Du, Han Wu, and Wen Su. 2019 b. MCNE: An End-to-End Framework for Learning Multiple Conditional Network Representations of Social Network. In KDD.Google Scholar"",""Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, and Philip S Yu. 2019 a. Heterogeneous Graph Attention Network. In WWW.Google Scholar"",""Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. 2014. Knowledge graph embedding by translating on hyperplanes. In AAAI.Google Scholar"",""Duncan J Watts and Steven H Strogatz. 1998. Collective dynamics of `small-world' networks. nature, Vol. 393, 6684 (1998), 440.Google Scholar"",""Chao-Yuan Wu, R Manmatha, Alexander J Smola, and Philipp Krahenbuhl. 2017. Sampling matters in deep embedding learning. In ICCV.Google Scholar"",""Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2019. How powerful are graph neural networks?. In ICLR.Google Scholar"",""Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. 2015. Embedding entities and relations for learning in knowledge bases. In ICLR.Google Scholar"",""Carl Yang, Yichen Feng, Pan Li, Yu Shi, and Jiawei Han. 2018. Meta-graph based hin spectral embedding: Methods, analyses, and insights. In ICDM.Google Scholar"",""Carl Yang, Jieyu Zhang, and Jiawei Han. 2019 a. Neural Embedding Propagation on Heterogeneous Networks. In ICDM.Google Scholar"",""Carl Yang, Jieyu Zhang, Haonan Wang, Sha Li, Myungwan Kim, Matt Walker, Yiou Xiao, and Jiawei Han. 2020. Relation Learning on Social Networks with Multi-Modal Graph Edge Variational Autoencoders. In WSDM.Google Scholar"",""Carl Yang, Peiye Zhuang, Wenhan Shi, Alan Luu, and Pan Li. 2019 b. Conditional Structure Generation through Graph Variational Generative Adversarial Nets. In NIPS.Google Scholar"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. 2018a. Graph convolutional neural networks for web-scale recommender systems. In KDD.Google Scholar"",""Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, and Jure Leskovec. 2018b. Hierarchical graph representation learning with differentiable pooling. In NIPS.Google Scholar"",""Chuxu Zhang, Dongjin Song, Chao Huang, Ananthram Swami, and Nitesh V. Chawla. 2019. Heterogeneous Graph Neural Network. In KDD.Google Scholar"",""Jiani Zhang, Xingjian Shi, Junyuan Xie, Hao Ma, Irwin King, and Dit-Yan Yeung. 2018. Gaan: Gated attention networks for learning on large and spatiotemporal graphs. In UAI.Google Scholar"",""Jun Zhao, Zhou Zhou, Ziyu Guan, Wei Zhao, Wei Ning, Guang Qiu, and Xiaofei He. 2019. IntentGC: a Scalable Graph Convolution Framework Fusing Heterogeneous Information for Recommendation. In KDD.Google Scholar"",""Dingyuan Zhu, Ziwei Zhang, Peng Cui, and Wenwu Zhu. 2019. Robust Graph Convolutional Networks Against Adversarial Attacks. In KDD.Google Scholar""]"
https://doi.org/10.1145/3394486.3403294,HetETA: Heterogeneous Information Network Embedding for Estimating Time of Arrival,"The estimated time of arrival (ETA) is a critical task in the intelligent transportation system, which involves the spatiotemporal data. Despite a significant amount of prior efforts have been made to design efficient and accurate systems for ETA task, few of them take structural graph data into account, much less the heterogeneous information network. In this paper, we propose HetETA to leverage heterogeneous information graph in ETA task. Specifically, we translate the road map into a multi-relational network and introduce a vehicle-trajectories based network to jointly consider the traffic behavior pattern. Moreover, we employ three components to model temporal information from recent periods, daily periods and weekly periods respectively. Each component comprises temporal convolutions and graph convolutions to learn representations of the spatiotemporal heterogeneous information for ETA task. Experiments on large-scale datasets illustrate the effectiveness of the proposed HetETA beyond the state-of-the-art methods, and show the importance of representation learning of heterogeneous information networks for ETA task.","[{""name"":""Huiting Hong"",""id"":""/profile/99659575074""},{""name"":""Yucheng Lin"",""id"":""/profile/99659573238""},{""name"":""Xiaoqing Yang"",""id"":""/profile/99659575159""},{""name"":""Zang Li"",""id"":""/profile/99659574836""},{""name"":""Kung Fu"",""id"":""/profile/99659574994""},{""name"":""Zheng Wang"",""id"":""/profile/99659573267""},{""name"":""Xiaohu Qie"",""id"":""/profile/99659458860""},{""name"":""Jieping Ye"",""id"":""/profile/99659193247""},{""name"":""Huiting Hong"",""id"":""/profile/99659575074""},{""name"":""Yucheng Lin"",""id"":""/profile/99659573238""},{""name"":""Xiaoqing Yang"",""id"":""/profile/99659575159""},{""name"":""Zang Li"",""id"":""/profile/99659574836""},{""name"":""Kung Fu"",""id"":""/profile/99659574994""},{""name"":""Zheng Wang"",""id"":""/profile/99659573267""},{""name"":""Xiaohu Qie"",""id"":""/profile/99659458860""},{""name"":""Jieping Ye"",""id"":""/profile/99659193247""}]","[""George M Beal and Joe M Bohlen. 1956. The diffusion process. Technical Report.Google Scholar"",""Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. 2014. Spectral Networks and Locally Connected Networks on Graphs. In 2nd International Conference on Learning Representations.Google Scholar"",""Chao Chen, Karl Petty, Alexander Skabardonis, Pravin Varaiya, and Zhanfeng Jia. 2007. Freeway Performance Measurement System: Mining Loop Detector Data. Transportation Research Record Journal of the Transportation Research Board (2007).Google Scholar"",""Kyunghyun Cho, Bart Van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078 (2014).Google Scholar"",""Yann N Dauphin, Angela Fan, Michael Auli, and David Grangier. 2017. Language modeling with gated convolutional networks. In Proceedings of the 34th International Conference on Machine Learning. 933--941.Google ScholarDigital Library"",""Corrado De Fabritiis, Roberto Ragona, and Gaetano Valenti. 2008. Traffic estimation and prediction based on real time floating car data. In 2008 11th International IEEE Conference on Intelligent Transportation Systems. IEEE, 197--203.Google ScholarCross Ref"",""Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolutional neural networks on graphs with fast localized spectral filtering. In Advances in neural information processing systems. 3844--3852.Google Scholar"",""Jan-Willem Grotenhuis, Bart W Wiegmans, and Piet Rietveld. 2007. The desired quality of integrated multimodal travel information in public transport: Customer needs for time and effort savings. Transport Policy, Vol. 14, 1 (2007), 27--38.Google ScholarCross Ref"",""Shengnan Guo, Youfang Lin, Ning Feng, Chao Song, and Huaiyu Wan. 2019. Attention based spatial-temporal graph convolutional networks for traffic flow forecasting. In Proceedings of the AAAI Conference on Artificial Intelligence.Google ScholarCross Ref"",""Anthony Harrington and Vinny Cahill. 2004. Route profiling: putting context to work. In Proceedings of the 2004 ACM symposium on Applied computing. ACM.Google ScholarDigital Library"",""Ryan Herring, Aude Hofleitner, Saurabh Amin, T Nasr, A Khalek, Pieter Abbeel, and Alexandre Bayen. 2010. Using mobile phones to forecast arterial traffic through statistical learning. In Transportation Research Board Annual Meeting.Google Scholar"",""Aude Hofleitner and Alexandre Bayen. 2011. Optimal decomposition of travel times measured by probe vehicles using a statistical traffic flow model. In 14th International IEEE Conference on Intelligent Transportation Systems (ITSC). IEEE.Google ScholarCross Ref"",""Aude Hofleitner, Ryan Herring, Pieter Abbeel, and Alexandre Bayen. 2012. Learning the dynamics of arterial traffic from probe data using a dynamic Bayesian network. IEEE Transactions on Intelligent Transportation Systems (2012).Google Scholar"",""H. V. Jagadish, Johannes Gehrke, Alexandros Labrinidis, Yannis Papakonstantinou, Jignesh M. Patel, Raghu Ramakrishnan, and Cyrus Shahabi. 2014. Big data and its technical challenges. Communications of the Acm, Vol. 57, 7 (2014), 86--94.Google ScholarDigital Library"",""Erik Jenelius and Haris N Koutsopoulos. 2013. Travel time estimation for urban road networks using low frequency probe vehicle data. Transportation Research Part B: Methodological, Vol. 53 (2013), 64--81.Google ScholarCross Ref"",""Ishan Jindal, Tony Qin, Xuewen Chen, Matthew S. Nokleby, and Jieping Ye. 2017. A unified neural network approach for estimating travel time and distance for a taxi trip. arXiv preprint arXiv:1710.04350 (2017).Google Scholar"",""Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In ICLR, 2017.Google Scholar"",""Yaguang Li, Dingxiong Deng, Ugur Demiryurek, Cyrus Shahabi, and Siva Ravada. 2015. Towards fast and accurate solutions to vehicle routing in a large-scale and dynamic environment. In International Symposium on Spatial and Temporal Databases. Springer, 119--136.Google ScholarCross Ref"",""Yaguang Li, Kun Fu, Zheng Wang, Cyrus Shahabi, Jieping Ye, and Yan Liu. 2018a. Multi-task representation learning for travel time estimation. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 1695--1704.Google ScholarDigital Library"",""Yanying Li and Mike McDonald. 2002. Link travel time estimation using single GPS equipped probe vehicle. In Proceedings. The IEEE 5th International Conference on Intelligent Transportation Systems. IEEE, 932--937.Google Scholar"",""Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. 2018b. Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting. In International Conference on Learning Representations (ICLR '18).Google Scholar"",""Andrew L Maas, Awni Y Hannun, and Andrew Y Ng. 2013. Rectifier nonlinearities improve neural network acoustic models. In Proc. icml, Vol. 30. 3.Google Scholar"",""Santa Maiti, Arpan Pal, Arindam Pal, Tanushyam Chattopadhyay, and Arijit Mukherjee. 2014. Historical data based real time prediction of vehicle arrival time. In 17th International IEEE Conference on Intelligent Transportation Systems.Google ScholarCross Ref"",""John Miller and Moritz Hardt. 2018. When recurrent models don't need to be recurrent. arXiv preprint arXiv:1805.10369, Vol. 4 (2018).Google Scholar"",""Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. 2016. Wavenet: A generative model for raw audio. arXiv:1609.03499 (2016).Google Scholar"",""Sashank J Reddi, Satyen Kale, and Sanjiv Kumar. 2018. On the convergence of adam and beyond. In 6th International Conference on Learning Representations.Google Scholar"",""Raffi Sevlian and Ram Rajagopal. 2010. Travel time estimation using floating car data. arXiv preprint arXiv:1012.4249 (2010).Google Scholar"",""Yizhou Sun and Jiawei Han. 2012. Mining heterogeneous information networks: a structural analysis approach. SIGKDD Explorations, Vol. 14, 2 (2012), 20--28.Google ScholarDigital Library"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. 2018. Graph Attention Networks. International Conference on Learning Representations (2018).Google Scholar"",""Hongjian Wang, Xianfeng Tang, Yu-Hsuan Kuo, Daniel Kifer, and Zhenhui Li. 2019. A simple baseline for travel time estimation using large-scale trip data. ACM Transactions on Intelligent Systems and Technology (TIST), Vol. 10, 2 (2019), 19.Google ScholarDigital Library"",""Yilun Wang, Yu Zheng, and Yexiang Xue. 2014. Travel time estimation of a path using sparse trajectories. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 25--34.Google ScholarDigital Library"",""Zheng Wang, Kun Fu, and Jieping Ye. 2018. Learning to estimate the travel time. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 858--866.Google ScholarDigital Library"",""Zonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, and Chengqi Zhang. 2019. Graph WaveNet for Deep Spatial-Temporal Graph Modeling. In Proceedings of the 28th International Joint Conference on Artificial Intelligence (IJCAI).Google ScholarCross Ref"",""Bing Yu, Haoteng Yin, and Zhanxing Zhu. 2018. Spatio-temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting. In Proceedings of the 27th International Joint Conference on Artificial Intelligence.Google ScholarCross Ref"",""Nicholas Jing Yuan, Yu Zheng, Liuhang Zhang, and Xing Xie. 2012. T-finder: A recommender system for finding passengers and vacant taxis. IEEE Transactions on knowledge and data engineering, Vol. 25, 10 (2012), 2390--2403.Google ScholarDigital Library"",""Chuanpan Zheng, Xiaoliang Fan, Cheng Wang, and Jianzhong Qi. 2020. GMAN: A Graph Multi-Attention Network for Traffic Prediction. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 34.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403295,Hubble: An Industrial System for Audience Expansion in Mobile Marketing,"Recently, in order to take a preemptive opportunity in the mobile economy, the Internet companies conduct thousands of marketing campaigns every day, to promote their mobile products and services. In the mobile marketing scenario, one of the fundamental issues is the audience expansion task for marketing campaigns. Given a set of seed users, audience expansion aims to seek more users (audiences), who are similar to the seeds and will finish the business goal of the targeted campaign (ie convert). However, the problem is challenging in three aspects. First, a company will run hundreds of campaigns to serve massive users every day. The requirements of scalability and timeliness make training model for each campaign extremely resource-consuming thus impractical. Therefore, we proposed to solve the problem in a two-stage manner, in which the offline stage employs heavyweight user representation learning and the online stage performs embedding-based lightweight audience expansion. Second, conventional two-stage audience expansion systems neglect the high-order user-campaign interactions and usually generate entangled user embeddings, thus fail to achieve high-quality user representation. Third, the seeds, which are usually provided by experts or collected from users' feedbacks, could be noisy and cannot cover the entire actual audiences, thus introduce coverage bias. Unfortunately, to our best knowledge, none of the related literatures tackle this crucial issue of audience expansion.Addressing the above challenges, in this paper, we present the Hubble System, an industrial solution for audience expansion in mobile marketing scenario. Hubble system follows the hybrid online-offline architecture to satisfy the requirements of scalability and timeliness. Specifically, in the offline stage, we propose a novel adaptive and disentangled graph neural network (called AD-GNN), to adaptively explore the user-campaign graph and generate comprehensive user embedding in a disentangled manner. In the online stage, tackling the coverage bias issue, we develop a novel audience expansion model with knowledge distillation mechanism (called KD-AE), to absorb knowledge from the offline AD-GNN and alleviate the coverage bias.Finally, extensive offline experiments and online A/B testing demonstrate the superior performance of the proposed Hubble system, compared with other state-of-the-art methods.","[{""name"":""Chenyi Zhuang"",""id"":""/profile/99658764608""},{""name"":""Ziqi Liu"",""id"":""/profile/99659215987""},{""name"":""Zhiqiang Zhang"",""id"":""/profile/99659544707""},{""name"":""Yize Tan"",""id"":""/profile/99659573429""},{""name"":""Zhengwei Wu"",""id"":""/profile/99659573030""},{""name"":""Zhining Liu"",""id"":""/profile/99659573433""},{""name"":""Jianping Wei"",""id"":""/profile/99659575165""},{""name"":""Jinjie Gu"",""id"":""/profile/99659477676""},{""name"":""Guannan Zhang"",""id"":""/profile/99659574554""},{""name"":""Jun Zhou"",""id"":""/profile/99659216578""},{""name"":""Yuan Qi"",""id"":""/profile/99659192702""},{""name"":""Chenyi Zhuang"",""id"":""/profile/99658764608""},{""name"":""Ziqi Liu"",""id"":""/profile/99659215987""},{""name"":""Zhiqiang Zhang"",""id"":""/profile/99659544707""},{""name"":""Yize Tan"",""id"":""/profile/99659573429""},{""name"":""Zhengwei Wu"",""id"":""/profile/99659573030""},{""name"":""Zhining Liu"",""id"":""/profile/99659573433""},{""name"":""Jianping Wei"",""id"":""/profile/99659575165""},{""name"":""Jinjie Gu"",""id"":""/profile/99659477676""},{""name"":""Guannan Zhang"",""id"":""/profile/99659574554""},{""name"":""Jun Zhou"",""id"":""/profile/99659216578""},{""name"":""Yuan Qi"",""id"":""/profile/99659192702""}]","[""Stephanie deWet and Jiafan Ou. 2019. Finding Users Who Act Alike: Transfer Learning for Expanding Advertiser Audiences. In SIGKDD. 2251--2259.Google Scholar"",""Krzysztof J Geras, Abdel-rahman Mohamed, Rich Caruana, Gregor Urban, Shengjie Wang, Ozlem Aslan, Matthai Philipose, Matthew Richardson, and Charles Sutton. 2015. Blending lstms into cnns. arXiv preprint arXiv:1511.06433 (2015).Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable Feature Learning for Networks. In SIGKDD. 855--864.Google Scholar"",""William L. Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive Representation Learning on Large Graphs. In NIPS. 1024--1034.Google Scholar"",""Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531 (2015).Google Scholar"",""Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero, and Larry P. Heck. 2013. Learning deep structured semantic models for web search using clickthrough data. In CIKM. 2333--2338.Google Scholar"",""Yuchin Juan, Damien Lefortier, and Olivier Chapelle. 2017. Field-aware Factorization Machines in a Real-world Online Advertising System. In WWW. 680--688.Google Scholar"",""Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In ICLR.Google Scholar"",""Jinyu Li, Rui Zhao, Jui-Ting Huang, and Yifan Gong. 2014. Learning small-size DNN with output-distribution-based criteria. In ISCA. 1910--1914.Google Scholar"",""Haishan Liu, David Pardoe, Kun Liu, Manoj Thakur, Frank Cao, and Chongzhe Li. 2016. Audience Expansion for Online Social Network Advertising. In SIGKDD.Google Scholar"",""Yudan Liu, Kaikai Ge, Xu Zhang, and Leyu Lin. 2019. Real-time Attention Based Look-alike Model for Recommender System. In SIGKDD.Google Scholar"",""Ziqi Liu, Chaochao Chen, Longfei Li, Jun Zhou, Xiaolong Li, Le Song, and Yuan Qi. 2019. GeniePath: Graph Neural Networks with Adaptive Receptive Paths. In AAAI. 4424--4431.Google Scholar"",""Jianxin Ma, Peng Cui, Kun Kuang, XinWang, andWenwu Zhu. 2019. Disentangled Graph Convolutional Networks. In ICML. 4212--4221.Google Scholar"",""Qiang Ma, Eeshan Wagh, Jiayi Wen, Zhen Xia, Róbert Ormándi, and Datong Chen. 2016. Score Look-Alike Audiences. In ICDM. 647--654.Google Scholar"",""Qiang Ma, MusenWen, Zhen Xia, and Datong Chen. 2016. A Sub-linear, Massivescale Look-alike Audience Extension System. In BigMine. 51--67.Google Scholar"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. DeepWalk: online learning of social representations. In SIGKDD. 701--710.Google Scholar"",""Jianqiang Shen, Sahin Cem Geyik, and Ali Dasdan. 2015. Effective Audience Extension in Online Advertising. In SIGKDD. 2099--2108.Google Scholar"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. LINE: Large-scale Information Network Embedding. In WWW. 1067--1077.Google ScholarDigital Library"",""Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. 2018. Graph Attention Networks. In ICLR.Google Scholar"",""Ledell Yu Wu, Adam Fisch, Sumit Chopra, Keith Adams, Antoine Bordes, and Jason Weston. 2018. Starspace: Embed all the things!. In AAAI.Google Scholar"",""Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and Philip S Yu. 2019. A comprehensive survey on graph neural networks. arXiv preprint arXiv:1901.00596 (2019).Google Scholar"",""Dalong Zhang, Xin Huang, Ziqi Liu, Jun Zhou, Zhiyang Hu, Xianzheng Song, Zhibang Ge, Lin Wang, Zhiqiang Zhang, and Yuan Qi. 2020. AGL: A Scalable System for Industrial-purpose Graph Machine Learning. In VLDB.Google Scholar""]"
https://doi.org/10.1145/3394486.3403296,Scaling Graph Neural Networks with Approximate PageRank,"Graph neural networks (GNNs) have emerged as a powerful approach for solving many network mining tasks. However, learning on large graphs remains a challenge -- many recently proposed scalable GNN approaches rely on an expensive message-passing procedure to propagate information through the graph. We present the PPRGo model which utilizes an efficient approximation of information diffusion in GNNs resulting in significant speed gains while maintaining state-of-the-art prediction performance. In addition to being faster, PPRGo is inherently scalable, and can be trivially parallelized for large datasets like those found in industry settings.We demonstrate that PPRGo outperforms baselines in both distributed and single-machine training environments on a number of commonly used academic graphs. To better analyze the scalability of large-scale graph learning methods, we introduce a novel benchmark graph with 12.4 million nodes, 173 million edges, and 2.8 million node features. We show that training PPRGo from scratch and predicting labels for all nodes in this graph takes under 2 minutes on a single machine, far outpacing other baselines on the same graph. We discuss the practical application of PPRGo to solve large-scale node classification problems at Google.","[{""name"":""Aleksandar Bojchevski"",""id"":""/profile/99659193826""},{""name"":""Johannes Klicpera"",""id"":""/profile/99659574594""},{""name"":""Bryan Perozzi"",""id"":""/profile/81496689145""},{""name"":""Amol Kapoor"",""id"":""/profile/99659573521""},{""name"":""Martin Blais"",""id"":""/profile/99659574703""},{""name"":""Benedek Rózemberczki"",""id"":""/profile/99659322469""},{""name"":""Michal Lukasik"",""id"":""/profile/81502806421""},{""name"":""Stephan Günnemann"",""id"":""/profile/81447604694""},{""name"":""Aleksandar Bojchevski"",""id"":""/profile/99659193826""},{""name"":""Johannes Klicpera"",""id"":""/profile/99659574594""},{""name"":""Bryan Perozzi"",""id"":""/profile/81496689145""},{""name"":""Amol Kapoor"",""id"":""/profile/99659573521""},{""name"":""Martin Blais"",""id"":""/profile/99659574703""},{""name"":""Benedek Rózemberczki"",""id"":""/profile/99659322469""},{""name"":""Michal Lukasik"",""id"":""/profile/81502806421""},{""name"":""Stephan Günnemann"",""id"":""/profile/81447604694""}]","[""S. Abu-El-Haija, A. Kapoor, B. Perozzi, and J. Lee. 2018. N-gcn: multi-scale graph convolution for semi-supervised node classification. arXiv preprint arXiv:1802.08888.Google Scholar"",""S. Abu-El-Haija et al. 2019. MixHop: higher-order graph convolutional architectures via sparsified neighborhood mixing. ICML, 21--29.Google Scholar"",""R. Andersen, C. Borgs, J. T. Chayes, J. E. Hopcroft, V. S. Mirrokni, and S.-H. Teng. 2008. Local computation of pagerank contributions. Internet Mathematics, 5, 23--45.Google ScholarCross Ref"",""R. Andersen, F. Chung, and K. Lang. 2006. Local graph partitioning using pagerank vectors. FOCS, 475--486.Google Scholar"",""P. W. Battaglia et al. 2018. Relational inductive biases, deep learning, and graph networks. arXiv preprint arXiv:1806.01261.Google Scholar"",""A. Bojchevski and S. Günnemann. 2018. Deep gaussian embedding of graphs: unsupervised inductive learning via ranking.Google Scholar"",""P. Boldi, V. Lonati, M. Santini, and S. Vigna. 2006. Graph fibrations, graph isomorphism, and pagerank. RAIRO Theor. Informatics Appl., 40, 2, 227--253.Google ScholarCross Ref"",""J. Bruna, W. Zaremba, A. Szlam, and Y. LeCun. 2013. Spectral networks and locally connected networks on graphs. arXiv preprint arXiv:1312.6203.Google Scholar"",""E. Buchnik and E. Cohen. 2018. Bootstrapped graph diffusions: exposing the power of nonlinearity. SIGMETRICS, 8--10.Google Scholar"",""C. Chambers, A. Raniwala, F. Perry, S. Adams, R. R. Henry, R. Bradshaw, and N. Weizenbaum. 2010. Flumejava: easy, efficient data-parallel pipelines. ACM Sigplan Notices, 45, 6, 363--375.Google ScholarDigital Library"",""I. Chami, S. Abu-El-Haija, B. Perozzi, C. Ré, and K. Murphy. 2020. Machine learning on graphs: a model and comprehensive taxonomy. arXiv preprint arXiv:2005.03675.Google Scholar"",""J. Chen, J. Zhu, and L. Song. 2018. Stochastic training of graph convolutional networks with variance reduction. ICML, 941--949.Google Scholar"",""J. Chen, T. Ma, and C. Xiao. 2018. Fastgcn: fast learning with graph convolutional networks via importance sampling. arXiv preprint arXiv:1801.10247.Google Scholar"",""Z. Chen, L. Li, and J. Bruna. 2018. Supervised community detection with line graph neural networks.Google Scholar"",""W. Chiang, X. Liu, S. Si, Y. Li, S. Bengio, and C. Hsieh. 2019. Cluster-gcn: an efficient algorithm for training deep and large graph convolutional networks. KDD. ACM, 257--266.Google Scholar"",""M. Defferrard, X. Bresson, and P. Vandergheynst. 2016. Convolutional neural networks on graphs with fast localized spectral filtering. Advances in Neural Information Processing Systems, 3844--3852.Google Scholar"",""M. Fey and J. E. Lenssen. 2019. Fast graph representation learning with pytorch geometric. CoRR, abs/1903.02428. arXiv: 1903.02428.Google Scholar"",""D. Fogaras and B. Rácz. 2004. Towards scaling fully personalized pagerank. WAW.Google Scholar"",""Y. Fujiwara, M. Nakatsuji, H. Shiokawa, T. Mishima, and M. Onizuka. 2013. Fast and exact top-k algorithm for pagerank. AAAI.Google Scholar"",""H. Gao, Z. Wang, and S. Ji. 2018. Large-scale learnable graph convolutional networks. KDD, 1416--1424.Google Scholar"",""J. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, and G. E. Dahl. 2017. Neural message passing for quantum chemistry. arXiv preprint arXiv:1704.01212.Google Scholar"",""D. F. Gleich, K. Kloster, and H. Nassar. 2015. Localization in seeded pagerank. arXiv preprint arXiv:1509.00016.Google Scholar"",""M. Gori, G. Monfardini, and F. Scarselli. 2005. A new model for learning in graph domains. IJCNN, 729--734.Google Scholar"",""W. Hamilton, Z. Ying, and J. Leskovec. 2017. Inductive representation learning on large graphs. Advances in Neural Information Processing Systems, 1024--1034.Google Scholar"",""K. He, X. Zhang, S. Ren, and J. Sun. 2016. Deep Residual Learning for Image Recognition. CVPR, 770--778.Google Scholar"",""W. Huang, T. Zhang, Y. Rong, and J. Huang. 2018. Adaptive sampling towards fast graph representation learning. Advances in Neural Information Processing Systems, 4563--4572.Google Scholar"",""G. Jeh and J. Widom. 2003. Scaling personalized web search. WWW.Google Scholar"",""A. Kannan et al. 2016. Smart reply: automated response suggestion for email. KDD, 955--964.Google Scholar"",""G. Karypis and V. Kumar. 1998. A fast and high quality multilevel scheme for partitioning irregular graphs. SIAM Journal on scientific Computing, 20, 1.Google Scholar"",""D. P. Kingma and J. Ba. 2014. Adam: a method for stochastic optimization. arXiv preprint arXiv:1412.6980.Google Scholar"",""T. N. Kipf and M. Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907.Google Scholar"",""J. Klicpera, A. Bojchevski, and S. Günnemann. 2019. Predict then propagate: graph neural networks meet personalized pagerank. ICLR.Google Scholar"",""Q. Li, Z. Han, and X.-M. Wu. 2018. Deeper insights into graph convolutional networks for semi-supervised learning. arXiv preprint arXiv:1801.07606.Google Scholar"",""P. Lofgren, S. Banerjee, and A. Goel. 2016. Personalized pagerank estimation and search: a bidirectional approach. WSDM.Google Scholar"",""H. Nassar, K. Kloster, and D. F. Gleich. 2015. Strong localization in personalized pagerank vectors. International Workshop on Algorithms and Models for the Web-Graph. Springer, 190--202.Google Scholar"",""M. Niepert, M. Ahmed, and K. Kutzkov. 2016. Learning convolutional neural networks for graphs. ICML, 2014--2023.Google Scholar"",""L. Page, S. Brin, R. Motwani, and T. Winograd. 1998. The pagerank citation ranking: bringing order to the web.Google Scholar"",""B. Perozzi, M. Schueppert, J. Saalweachter, and M. Thakur. 2016. When recommendation goes wrong: anomalous link discovery in recommendation networks. KDD, 569--578.Google Scholar"",""S. Ravi. 2016. Graph-powered machine learning at google. https://ai.googleblog. com/2016/10/graph-powered-machine-learning-at-google.html. (2016).Google Scholar"",""R. Al-Rfou, D. Zelle, and B. Perozzi. 2019. Ddgk: learning graph representations for deep divergence graph kernels. WWW, 37--48.Google Scholar"",""R. Sato, M. Yamada, and H. Kashima. 2019. Constant time graph neural networks. arXiv preprint arXiv:1901.07868.Google Scholar"",""F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, and G. Monfardini. 2009. The graph neural network model. IEEE Transactions on Neural Networks, 20, 1.Google ScholarDigital Library"",""A. Sinha, Z. Shen, Y. Song, H. Ma, D. Eide, B.-J. P. Hsu, and K. Wang. 2015. An overview of microsoft academic service (mas) and applications. WWW 2015.Google Scholar"",""P. Velickovic, G. Cucurull, A. Casanova, A. Romero, P. Lio, and Y. Bengio. 2017. Graph attention networks. arXiv preprint arXiv:1710.10903, 1, 2.Google Scholar"",""S. Wang, Y. Tang, X. Xiao, Y. Yang, and Z. Li. 2016. Hubppr: effective indexing for approximate personalized pagerank. PVLDB, 10, 205--216.Google ScholarDigital Library"",""S. Wang, R. Yang, X. Xiao, Z. Wei, and Y. Yang. 2017. Fora: simple and effective approximate single-source personalized pagerank. KDD.Google Scholar"",""X. Wang, A. Shakery, and T. Tao. 2005. Dirichlet pagerank. SIGIR.Google Scholar"",""Z. Wei, X. He, X. Xiao, S. Wang, S. Shang, and J.-R. Wen. 2018. Topppr: topk personalized pagerank queries with precision guarantees on large graphs. SIGMOD.Google Scholar"",""F. Wu, T. Zhang, A. H. d. Souza Jr, C. Fifty, T. Yu, and K. Q. Weinberger. 2019. Simplifying graph convolutional networks. arXiv preprint arXiv:1902.07153.Google Scholar"",""Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, and P. S. Yu. 2019. A comprehensive survey on graph neural networks. arXiv preprint arXiv:1901.00596.Google Scholar"",""K. Xu, W. Hu, J. Leskovec, and S. Jegelka. 2018. How powerful are graph neural networks? arXiv preprint arXiv:1810.00826.Google Scholar"",""K. Xu, C. Li, Y. Tian, T. Sonobe, K.-i. Kawarabayashi, and S. Jegelka. 2018. Representation learning on graphs with jumping knowledge networks. arXiv preprint arXiv:1806.03536.Google Scholar"",""J. Yang and J. Leskovec. 2015. Defining and evaluating network communities based on ground-truth. Knowledge and Information Systems, 42, 1, 181--213.Google ScholarDigital Library"",""R. Ying, R. He, K. Chen, P. Eksombatchai, W. L. Hamilton, and J. Leskovec. 2018. Graph convolutional neural networks for web-scale recommender systems. arXiv preprint arXiv:1806.01973.Google Scholar"",""M. Zhang and Y. Chen. 2018. Link prediction based on graph neural networks. arXiv preprint arXiv:1802.09691.Google Scholar""]"
https://doi.org/10.1145/3394486.3403297,Combo-Attention Network for Baidu Video Advertising,"With the progress of communication technology and the popularity of the smart phone, videos grow to be the largest medium. Since videos can grab a customer's attention quickly and leave a big impression, video ads can gain more trust than traditional ads. Thus advertisers start to pour more resources into making creative video ads to built the connections with potential customers. Baidu, as the leading search engine company in China, receives billions of search queries per day. In this paper, we introduce a technique used in Baidu video advertising for feeding relevant video ads according to the user's query. Note that, retrieving relevant videos using the text query is a cross-modal problem. Due to the modal gap, the text-to-video search is more challenging than well exploited text-to-text search and image-to-image search. To tackle this challenge, we propose a Combo-Attention Network (CAN) and launch it in Baidu video advertising. In the proposed CAN model, we represent a video as a set of bounding boxes features and represent a sentence as a set of words features, and formulate the sentence-to-video search as a set-to-set matching problem. The proposed CAN is built upon the proposed combo-attention module, which exploits cross-modal attentions besides self attentions to effectively capture the relevance between words and bounding boxes. To testify the effectiveness of the proposed CAN offline, we built a Daily700K dataset collected from HaoKan APP. The systematic experiments on Daily700K as well as a public dataset, VATEX, demonstrate the effectiveness of our CAN. After launching the proposed CAN in Baidu's dynamic video advertising (DVA), we achieve a $5.47%$ increase in Conversion Rate (CVR) and a $11.69%$ increase in advertisement impression rate.","[{""name"":""Tan Yu"",""id"":""/profile/99659574570""},{""name"":""Yi Yang"",""id"":""/profile/99659574712""},{""name"":""Yi Li"",""id"":""/profile/99659575268""},{""name"":""Xiaodong Chen"",""id"":""/profile/99659574164""},{""name"":""Mingming Sun"",""id"":""/profile/99659242188""},{""name"":""Ping Li"",""id"":""/profile/81317488756""},{""name"":""Tan Yu"",""id"":""/profile/99659574570""},{""name"":""Yi Yang"",""id"":""/profile/99659574712""},{""name"":""Yi Li"",""id"":""/profile/99659575268""},{""name"":""Xiaodong Chen"",""id"":""/profile/99659574164""},{""name"":""Mingming Sun"",""id"":""/profile/99659242188""},{""name"":""Ping Li"",""id"":""/profile/81317488756""}]","[""Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. 2016. Layer normalization. Technical Report. arXiv:1607.06450.Google Scholar"",""Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural Machine Translation by Jointly Learning to Align and Translate. In Proceedings of the 3rd International Conference on Learning Representations (ICLR). San Diego, CA.Google Scholar"",""James Bradbury, Stephen Merity, Caiming Xiong, and Richard Socher. 2017. QuasiRecurrent Neural Networks. In Proceedings of the 5th International Conference on Learning Representations (ICLR). Toulon, France.Google Scholar"",""Andrei Broder. 2002. A taxonomy of web search. SIGIR Forum 36, 2 (2002), 3--10.Google ScholarDigital Library"",""João Carreira and Andrew Zisserman. 2017. Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset. In Proceedingts of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Honolulu, HI, 4724--4733.Google ScholarCross Ref"",""Harm de Vries, Florian Strub, Jérémie Mary, Hugo Larochelle, Olivier Pietquin, and Aaron C. Courville. 2017. Modulating early visual processing by language. In Advances in Neural Information Processing Systems (NIPS). Long Beach, CA, 6594--6604.Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT). Minneapolis, MN, 4171--4186.Google Scholar"",""Jeff Donahue, Lisa Anne Hendricks, Marcus Rohrbach, Subhashini Venugopalan, Sergio Guadarrama, Kate Saenko, and Trevor Darrell. 2017. Long-Term Recurrent Convolutional Networks for Visual Recognition and Description. IEEE Trans. Pattern Anal. Mach. Intell. 39, 4 (2017), 677--691.Google ScholarDigital Library"",""Fartash Faghri, David J. Fleet, Jamie Ryan Kiros, and Sanja Fidler. 2018. VSE++: Improving Visual-Semantic Embeddings with Hard Negatives. In Proceedings of the 2018 British Machine Vision Conference 2018 (BMVC). Newcastle, UK, 12.Google Scholar"",""Daniel C. Fain and Jan O. Pedersen. 2006. Sponsored Search: A Brief History. In SSA Workshop. Ann Arbor, Michigan.Google Scholar"",""Miao Fan, Jiacheng Guo, Shuai Zhu, Shuo Miao, Mingming Sun, and Ping Li. 2019. MOBIUS: Towards the Next Generation of Query-Ad Matching in Baidu's Sponsored Search. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining, (KDD). Anchorage, AK, 2509--2517.Google ScholarDigital Library"",""Ali Farhadi, Seyyed Mohammad Mohsen Hejrati, Mohammad Amin Sadeghi, Peter Young, Cyrus Rashtchian, Julia Hockenmaier, and David A. Forsyth. 2010. Every Picture Tells a Story: Generating Sentences from Images. In Computer Vision - ECCV 2010, Proceedings of the 11th European Conference on Computer Vision (ECCV). Heraklion, Greece, 15--29.Google Scholar"",""Andrea Frome, Gregory S. Corrado, Jonathon Shlens, Samy Bengio, Jeffrey Dean, Marc'Aurelio Ranzato, and Tomas Mikolov. 2013. DeViSE: A Deep VisualSemantic Embedding Model. In Advances in Neural Information Processing Systems (NIPS). Lake Tahoe, NV, 2121--2129.Google Scholar"",""Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. 2017. Convolutional Sequence to Sequence Learning. In Proceedings of the 34th International Conference on Machine Learning (ICML). Sydney, Australia, 1243-- 1252.Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep Residual Learning for Image Recognition. In Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Las Vegas, NV, 770--778.Google ScholarCross Ref"",""Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Koray Kavukcuoglu. 2016. Neural machine translation in linear time. Technical Report. arXiv:1610.10099.Google Scholar"",""Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David A. Shamma, Michael S. Bernstein, and Li Fei-Fei. 2017. Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations. Int. J. Comput. Vis. 123, 1 (2017), 32--73.Google ScholarDigital Library"",""Kuang-Huei Lee, Xi Chen, Gang Hua, Houdong Hu, and Xiaodong He. 2018. Stacked Cross Attention for Image-Text Matching. In Proceedings of the 15th European Conference on Computer Vision (ECCV). Munich, Germany, 212--228.Google ScholarCross Ref"",""Dingcheng Li, Xu li, Jun Wang, and Ping Li. 2020. Video Recommendation with Multi-gate Mixture of Experts Soft Actor Critic. In Proceedings of the 43th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR). Xi'an, China.Google ScholarDigital Library"",""Jiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee. 2019. ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks. In Advances in Neural Information Processing Systems (NeurIPS). Vancouver, Canada, 13--23.Google Scholar"",""Lin Ma, Zhengdong Lu, Lifeng Shang, and Hang Li. 2015. Multimodal Convolutional Neural Networks for Matching Image and Sentence. In Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV). Santiago, Chile, 2623--2631.Google ScholarDigital Library"",""Niluthpol Chowdhury Mithun, Juncheng Li, Florian Metze, and Amit K. RoyChowdhury. 2018. Learning Joint Embedding with Multimodal Cues for CrossModal Video-Text Retrieval. In Proceedings of the 2018 ACM on International Conference on Multimedia Retrieval (ICMR). Yokohama, Japan, 19--27.Google Scholar"",""Mayu Otani, Yuta Nakashima, Esa Rahtu, Janne Heikkilä, and Naokazu Yokoya. 2016. Learning Joint Representations of Videos and Sentences with Web Image Search. In Proceedings of the 10th European Conference on Computer Vision (ECCV Workshops). Amsterdam, The Netherlands, 651--667.Google ScholarCross Ref"",""Yingwei Pan, Tao Mei, Ting Yao, Houqiang Li, and Yong Rui. 2016. Jointly Modeling Embedding and Translation to Bridge Video and Language. In Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Las Vegas, NV, 4594--4602.Google ScholarCross Ref"",""Shaoqing Ren, Kaiming He, Ross B. Girshick, and Jian Sun. 2017. Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks. IEEE Trans. Pattern Anal. Mach. Intell. 39, 6 (2017), 1137--1149.Google ScholarDigital Library"",""Karen Simonyan and Andrew Zisserman. 2014. Two-Stream Convolutional Networks for Action Recognition in Videos. In Advances in Neural Information Processing Systems (NIPS). Montreal, Canada, 568--576.Google Scholar"",""Chen Sun, Austin Myers, Carl Vondrick, Kevin Murphy, and Cordelia Schmid. 2019. VideoBERT: A Joint Model for Video and Language Representation Learning. In Proceedings of the 2019 IEEE/CVF International Conference on Computer Vision (ICCV). Seoul, Korea (South), 7463--7472.Google ScholarCross Ref"",""Du Tran, Lubomir D. Bourdev, Rob Fergus, Lorenzo Torresani, and Manohar Paluri. 2015. Learning Spatiotemporal Features with 3D Convolutional Networks. In Proceedigns of the 2015 IEEE International Conference on Computer Vision (ICCV). Santiago, Chile, 4489--4497.Google ScholarDigital Library"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In Advances in Neural Information Processing Systems (NIPS). Long Beach, CA, 5998--6008.Google Scholar"",""Xiaolong Wang, Ross B. Girshick, Abhinav Gupta, and Kaiming He. 2018. NonLocal Neural Networks. In Proceedings of the 2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Salt Lake City, UT, 7794--7803.Google Scholar"",""Xiaolong Wang and Abhinav Gupta. 2018. Videos as Space-Time Region Graphs. In Proceedings of the 15th European Conference on Computer Vision (ECCV). Munich, Germany, 413--431.Google ScholarCross Ref"",""Xin Wang, Jiawei Wu, Junkun Chen, Lei Li, Yuan-Fang Wang, and William Yang Wang. 2019. VaTeX: A Large-Scale, High-Quality Multilingual Dataset for Videoand-Language Research. In Proceedings of the 2019 IEEE/CVF International Conference on Computer Vision (ICCV). Seoul, Korea (South), 4580--4590.Google ScholarCross Ref"",""Ran Xu, Caiming Xiong, Wei Chen, and Jason J. Corso. 2015. Jointly Modeling Deep Video and Compositional Text to Bridge Vision and Language in a Unified Framework. In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI). Austin, TX, 2346--2352.Google Scholar"",""Youngjae Yu, Hyungjin Ko, Jongwook Choi, and Gunhee Kim. 2017. End-toEnd Concept Word Detection for Video Captioning, Retrieval, and Question Answering. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Honolulu, HI, 3261--3269.Google ScholarCross Ref"",""Zhou Yu, Jun Yu, Yuhao Cui, Dacheng Tao, and Qi Tian. 2019. Deep Modular Co-Attention Networks for Visual Question Answering. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Long Beach, CA, 6281--6290.Google ScholarCross Ref"",""Weijie Zhao, Shulong Tan, and Ping Li. 2020. SONG: Approximate Nearest Neighbor Search on GPU. In 35th IEEE International Conference on Data Engineering (ICDE). Dallas, TX.Google Scholar"",""Weijie Zhao, Deping Xie, Ronglai Jia, Yulei Qian, Ruiquan Ding, Mingming Sun, and Ping Li. 2020. Distributed Hierarchical GPU Parameter Server for Massive Scale Deep Learning Ads Systems. In Proceedings of the 3rd Conference on Third Conference on Machine Learning and Systems (MLSys). Huston, TX.Google Scholar"",""Weijie Zhao, Jingyuan Zhang, Deping Xie, Yulei Qian, Ronglai Jia, and Ping Li. 2019. AIBox: CTR Prediction Model Training on a Single Node. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management (CIKM). Beijing, China, 319--328.Google ScholarDigital Library"",""Zhixin Zhou, Shulong Tan, Zhaozhuo Xu, and Ping Li. 2019. Möbius Transformation for Fast Inner Product Search on Graph. In Advances in Neural Information Processing Systems (NeurIPS). Vancouver, Canada, 8216--8227.Google Scholar""]"
https://doi.org/10.1145/3394486.3403298,Federated Doubly Stochastic Kernel Learning for Vertically Partitioned Data,"In a lot of real-world data mining and machine learning applications, data are provided by multiple providers and each maintains private records of different feature sets about common entities. It is challenging to train these vertically partitioned data effectively and efficiently while keeping data privacy for traditional data mining and machine learning algorithms. In this paper, we focus on nonlinear learning with kernels,and propose a federated doubly stochastic kernel learning (FDSKL) algorithm for vertically partitioned data. Specifically, we use random features to approximate the kernel mapping function and use doubly stochastic gradients to update the solutions, which are all computed federatedly without the disclosure of data. Importantly, we prove that FDSKL has a sublinear convergence rate, and can guarantee the data security under the semi-honest assumption. Extensive experimental results on a variety of benchmark datasets show that FDSKL is significantly faster than state-of-the-art federated learning methods when dealing with kernels, while retaining the similar generalization performance.","[{""name"":""Bin Gu"",""id"":""/profile/99659573743""},{""name"":""Zhiyuan Dang"",""id"":""/profile/99659574274""},{""name"":""Xiang Li"",""id"":""/profile/99658751567""},{""name"":""Heng Huang"",""id"":""/profile/99659523758""},{""name"":""Bin Gu"",""id"":""/profile/99659573743""},{""name"":""Zhiyuan Dang"",""id"":""/profile/99659574274""},{""name"":""Xiang Li"",""id"":""/profile/99658751567""},{""name"":""Heng Huang"",""id"":""/profile/99659523758""}]","[""Nadeem Badshah. 2018. Facebook to contact 87 million users affected by data breach. The Guardian) Retrieved from https://www. theguardian. com/technology/2018/apr/08/facebook-to-contact-the-87-million-users-affected-by-data-breach (2018).Google Scholar"",""Alain Berlinet and Christine Thomas-Agnan. 2011. Reproducing kernel Hilbert spaces in probability and statistics. Springer Science \u0026 Business Media.Google Scholar"",""Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, Vol. 2 (2011), 1--27. Issue 3. Software available at http://www.csie.ntu.edu.tw/~cjlin/libsvm.Google ScholarDigital Library"",""Kewei Cheng, Tao Fan, Yilun Jin, Yang Liu, Tianjian Chen, and Qiang Yang. 2019. SecureBoost: A Lossless Federated Learning Framework. arXiv preprint arXiv:1901.08755 (2019).Google Scholar"",""Bo Dai, Bo Xie, Niao He, Yingyu Liang, Anant Raj, Maria-Florina~F Balcan, and Le Song. 2014. Scalable kernel methods via doubly stochastic gradients. In Advances in Neural Information Processing Systems. 3041--3049.Google Scholar"",""Lisandro D Dalcin, Rodrigo R Paz, Pablo A Kler, and Alejandro Cosimo. 2011. Parallel distributed computing using Python. Advances in Water Resources, Vol. 34, 9 (2011), 1124--1139.Google ScholarCross Ref"",""Wenliang Du and Mikhail J Atallah. 2001. Privacy-preserving cooperative statistical analysis. In Seventeenth Annual Computer Security Applications Conference. IEEE, 102--110.Google Scholar"",""EU. 2016. REGULATION (EU) 2016/679 OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation). Available at https://eur-lex. europa. eu/legal-content/EN/TXT .Google Scholar"",""Adrià Gascón, Phillipp Schoppmann, Borja Balle, Mariana Raykova, Jack Doerner, Samee Zahur, and David Evans. 2016. Secure Linear Regression on Vertically Partitioned Datasets. IACR Cryptology ePrint Archive, Vol. 2016 (2016), 892.Google Scholar"",""Adrià Gascón, Phillipp Schoppmann, Borja Balle, Mariana Raykova, Jack Doerner, Samee Zahur, and David Evans. 2017. Privacy-preserving distributed linear regression on high-dimensional data. Proceedings on Privacy Enhancing Technologies, Vol. 2017, 4 (2017), 345--364.Google ScholarCross Ref"",""Xiang Geng, Bin Gu, Xiang Li, Wanli Shi, Guansheng Zheng, and Heng Huang. 2019. Scalable semi-supervised SVM via triply stochastic gradients. In Proceedings of the 28th International Joint Conference on Artificial Intelligence. AAAI Press, 2364--2370.Google ScholarCross Ref"",""Bin Gu, Zhouyuan Huo, and Heng Huang. 2018. Asynchronous Doubly Stochastic Group Regularized Learning. In International Conference on Artificial Intelligence and Statistics. 1791--1800.Google Scholar"",""Stephen Hardy, Wilko Henecka, Hamish Ivey-Law, Richard Nock, Giorgio Patrini, Guillaume Smith, and Brian Thorne. 2017. Private federated learning on vertically partitioned data via entity resolution and additively homomorphic encryption. arXiv preprint arXiv:1711.10677 (2017).Google Scholar"",""Alan~F Karr, Xiaodong Lin, Ashish~P Sanil, and Jerome~P Reiter. 2009. Privacy-preserving analysis of vertically partitioned data using secure matrix products. Journal of Official Statistics, Vol. 25, 1 (2009), 125.Google Scholar"",""Yang Liu, Yingting Liu, Zhijie Liu, Junbo Zhang, Chuishi Meng, and Yu Zheng. 2019. Federated Forest. arXiv preprint arXiv:1905.10053 (2019).Google Scholar"",""Richard Nock, Stephen Hardy, Wilko Henecka, Hamish Ivey-Law, Giorgio Patrini, Guillaume Smith, and Brian Thorne. 2018. Entity Resolution and Federated Learning get a Federated Resolution. arXiv preprint arXiv:1803.04035 (2018).Google Scholar"",""Ali Rahimi and Benjamin Recht. 2008. Random features for large-scale kernel machines. In Advances in neural information processing systems. 1177--1184.Google Scholar"",""Ali Rahimi and Benjamin Recht. 2009. Weighted sums of random kitchen sinks: Replacing minimization with randomization in learning. In Advances in neural information processing systems. 1313--1320.Google Scholar"",""Benjamin Recht, Christopher Re, Stephen Wright, and Feng Niu. 2011. Hogwild: A lock-free approach to parallelizing stochastic gradient descent. In Advances in neural information processing systems. 693--701.Google ScholarDigital Library"",""Walter Rudin. 1962. Fourier analysis on groups. Vol., Vol. 121967. Wiley Online Library.Google Scholar"",""Ashish~P Sanil, Alan~F Karr, Xiaodong Lin, and Jerome~P Reiter. 2004. Privacy preserving regression modelling via distributed computation. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 677--682.Google ScholarDigital Library"",""Wanli Shi, Bin Gu, Xiang Li, Xiang Geng, and Heng Huang. 2019. Quadruply stochastic gradients for large scale nonlinear semi-supervised AUC optimization. In Proceedings of the 28th International Joint Conference on Artificial Intelligence. AAAI Press, 3418--3424.Google ScholarCross Ref"",""Wanli Shi, Bin Gu, Xiang Li, and Heng Huang. 2020. Quadruply Stochastic Gradient Method for Large Scale Nonlinear Semi-Supervised Ordinal Regression AUC Optimization. In The Thirty-Fourth AAAI Conference on Artificial Intelligence, New York, NY, USA, February 7-12, 2020. AAAI Press, 5734--5741.Google Scholar"",""D. B. Skillicorn and S. M. Mcconnell. 2008. Distributed prediction from vertically partitioned data. Journal of Parallel \u0026 Distributed Computing, Vol. 68, 1 (2008), 16--36.Google ScholarDigital Library"",""Jaideep Vaidya and Chris Clifton. 2002. Privacy preserving association rule mining in vertically partitioned data. In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 639--644.Google ScholarDigital Library"",""Jaideep Vaidya and Chris Clifton. 2003. Privacy-preserving k-means clustering over vertically partitioned data. In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining. 206--215.Google ScholarDigital Library"",""Li Wan, Wee~Keong Ng, Shuguo Han, and Vincent Lee. 2007. Privacy-preservation for gradient descent methods. In Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 775--783.Google ScholarDigital Library"",""Bo Xie, Yingyu Liang, and Le Song. 2015. Scale up nonlinear component analysis with doubly stochastic gradients. In Advances in Neural Information Processing Systems. 2341--2349.Google Scholar"",""Jiyan Yang, Vikas Sindhwani, Quanfu Fan, Haim Avron, and Michael~W Mahoney. 2014. Random laplace feature maps for semigroup kernels on histograms. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 971--978.Google ScholarDigital Library"",""Hwanjo Yu, Jaideep Vaidya, and Xiaoqian Jiang. 2006. Privacy-preserving svm classification on vertically partitioned data. In Pacific-Asia Conference on Knowledge Discovery and Data Mining. Springer, 647--656.Google ScholarDigital Library"",""Gong-Duo Zhang, Shen-Yi Zhao, Hao Gao, and Wu-Jun Li. 2018. Feature-Distributed SVRG for High-Dimensional Linear Classification. arXiv preprint arXiv:1802.03604 (2018).Google Scholar"",""Haizhang Zhang, Yuesheng Xu, and Jun Zhang. 2009. Reproducing kernel Banach spaces for machine learning. Journal of Machine Learning Research, Vol. 10, Dec (2009), 2741--2775.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403299,To Tune or Not to Tune?: In Search of Optimal Configurations for Data Analytics,"This experimental study presents a number of issues that pose a challenge for practical configuration tuning and its deployment in data analytics frameworks. These issues include: 1) the assumption of a static workload or environment, ignoring the dynamic characteristics of the analytics environment (e.g., increase in input data size, changes in allocation of resources). 2) the amortization of tuning costs and how this influences what workloads can be tuned in practice in a cost-effective manner. 3) the need for a comprehensive incremental tuning solution for a diverse set of workloads. We adapt different ML techniques in order to obtain efficient incremental tuning in our problem domain, and propose Tuneful, a configuration tuning framework. We show how it is designed to overcome the above issues and illustrate its applicability by running a wide array of experiments in cloud environments provided by two different service providers.","[{""name"":""Ayat Fekry"",""id"":""/profile/99659213332""},{""name"":""Lucian Carata"",""id"":""/profile/81555775056""},{""name"":""Thomas Pasquier"",""id"":""/profile/99659573918""},{""name"":""Andrew Rice"",""id"":""/profile/81100249903""},{""name"":""Andy Hopper"",""id"":""/profile/81100172578""},{""name"":""Ayat Fekry"",""id"":""/profile/99659213332""},{""name"":""Lucian Carata"",""id"":""/profile/81555775056""},{""name"":""Thomas Pasquier"",""id"":""/profile/99659573918""},{""name"":""Andrew Rice"",""id"":""/profile/81100249903""},{""name"":""Andy Hopper"",""id"":""/profile/81100172578""}]","[""TPC-H SQL benchmark, 2014. http://www.tpc.org/tpch/.Google Scholar"",""Apache Spark: fast and general engine for large-scale data processing, 2015. https://spark.apache.org/.Google Scholar"",""Amazon EC2 instance Pricing, 2018. https://aws.amazon.com/ec2/pricing/on-demand/.Google Scholar"",""Hadoop distributed file system, 2018. https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html.Google Scholar"",""Tuneful: Experiment data repository, 2020. https://github.com/ayat-khairy/tuneful-data.git.Google Scholar"",""Tuneful: project repository, 2020. https://github.com/ayat-khairy/tuneful-code.git.Google Scholar"",""Omid Alipourfard, Hongqiang Harry Liu, Jianshu Chen, Shivaram Venkataraman, Minlan Yu, and Ming Zhang. Cherrypick: Adaptively unearthing the best cloud configurations for big data analytics. In NSDI, volume 2, pages 4--2, 2017.Google ScholarDigital Library"",""Jason Ansel, Shoaib Kamil, Kalyan Veeramachaneni, Jonathan Ragan-Kelley, Jeffrey Bosboom, Una-May O'Reilly, and Saman Amarasinghe. Opentuner: An extensible framework for program autotuning. In Parallel Architecture and Compilation Techniques (PACT), 2014 23rd International Conference on, pages 303--315. IEEE, 2014.Google Scholar"",""Emanuele Borgonovo and Elmar Plischke. Sensitivity analysis: a review of recent advances. European Journal of Operational Research, 248(3):869--887, 2016.Google ScholarCross Ref"",""Marc Peter Deisenroth, Dieter Fox, and Carl Edward Rasmussen. Gaussian processes for data-efficient learning in robotics and control. IEEE Transactions on Pattern Analysis and Machine Intelligence, 37(2):408--423, 2015.Google ScholarCross Ref"",""Songyun Duan, Vamsidhar Thummala, and Shivnath Babu. Tuning database configuration parameters with ituned. Proceedings of the VLDB Endowment, 2(1):1246--1257, 2009.Google ScholarDigital Library"",""Ayat Fekry, Lucian Carata, Thomas Pasquier, Andrew Rice, and Andy Hopper. Tuneful: An online significance-aware configuration tuner for big data analytics, 2020. https://arxiv.org/pdf/2001.08002.pdf.Google Scholar"",""Isabelle Guyon, Jason Weston, Stephen Barnhill, and Vladimir Vapnik. Gene selection for cancer classification using support vector machines. Machine learning, 46(1--3):389--422, 2002.Google Scholar"",""Shengsheng Huang, Jie Huang, Jinquan Dai, Tao Xie, and Bo Huang. The HiBench benchmark suite: Characterization of the MapReduce-based data analysis. In Data Engineering Workshops (ICDEW), 2010 IEEE 26th International Conference on, pages 41--51. IEEE, 2010.Google ScholarCross Ref"",""SPT Krishnan and Jose L Ugia Gonzalez. Google compute engine. In Building Your Next Big Thing with Google Cloud Platform, pages 53--81. Springer, 2015.Google ScholarCross Ref"",""Palden Lama and Xiaobo Zhou. Aroma: Automated resource allocation and configuration of MapReduce environment in the cloud. In Proceedings of the 9th international conference on Autonomic computing, pages 63--72. ACM, 2012.Google Scholar"",""Guangdeng Liao, Kushal Datta, and Theodore L Willke. Gunther: Search-based auto-tuning of MapReduce. In European Conference on Parallel Processing, pages 406--419. Springer, 2013.Google ScholarDigital Library"",""Andy Liaw, Matthew Wiener, et al. Classification and regression by randomforest. R news, 2(3):18--22, 2002.Google Scholar"",""Ashraf Mahgoub, Paul Wood, Sachandhan Ganesh, Subrata Mitra, Wolfgang Gerlach, Travis Harrison, Folker Meyer, Ananth Grama, Saurabh Bagchi, and Somali Chaterji. Rafiki: A middleware for parameter tuning of NoSQL datastores for dynamic metagenomics workloads. In Proceedings of the 18th ACM/IFIP/USENIX Middleware Conference, pages 28--40. ACM, 2017.Google ScholarDigital Library"",""Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P Adams, and Nando De Freitas. Taking the human out of the loop: A review of bayesian optimization. Proceedings of the IEEE, 104(1):148--175, 2015.Google ScholarCross Ref"",""Ilya M Sobol. On quasi-monte carlo integrations. Mathematics and computers in simulation, 47(2--5):103--112, 1998.Google Scholar"",""Kevin Swersky, Jasper Snoek, and Ryan P Adams. Multi-task bayesian optimization. In Advances in neural information processing systems, pages 2004--2012, 2013.Google Scholar"",""Dana Van Aken, Andrew Pavlo, Geoffrey J Gordon, and Bohan Zhang. Automatic database management system tuning through large-scale machine learning. In Proceedings of the 2017 ACM International Conference on Management of Data, pages 1009--1024. ACM, 2017.Google ScholarDigital Library"",""Guolu Wang, Jungang Xu, and Ben He. A novel method for tuning configuration parameters of Spark based on machine learning. In High Performance Computing and Communications; IEEE 14th International Conference on Smart City; IEEE 2nd International Conference on Data Science and Systems (HPCC/SmartCity/DSS), 2016 IEEE 18th International Conference on, pages 586--593. IEEE, 2016.Google Scholar"",""John A Weymark. Generalized Gini inequality indices. Mathematical Social Sciences, 1(4):409--430, 1981.Google ScholarCross Ref"",""Zhibin Yu, Zhendong Bei, and Xuehai Qian. Datasize-aware high dimensional configurations auto-tuning of in-memory cluster computing. In Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems, pages 564--577. ACM, 2018.Google ScholarDigital Library"",""Yuqing Zhu, Jianxun Liu, Mengying Guo, Yungang Bao, Wenlong Ma, Zhuoyue Liu, Kunpeng Song, and Yingchun Yang. Bestconfig: tapping the performance potential of systems via automatic configuration tuning. In Proceedings of the 2017 Symposium on Cloud Computing, pages 338--350. ACM, 2017.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403300,Reconstruction and Decomposition of High-Dimensional Landscapes via Unsupervised Learning,"Uncovering the organization of a landscape that encapsulates all states of a dynamic system is a central task in many domains, as it promises to reveal, in an unsupervised manner, a system's inner working. One domain where this task is crucial is in bioinformatics, where the energy landscape that organizes three-dimensional structures of a molecule by their energetics is a powerful construct. The landscape can be leveraged, among other things, to reveal macrostates where a molecule is biologically-active. This is a daunting task, as landscapes of complex actuated systems, such as molecules, are inherently high-dimensional. Nonetheless, our laboratories have made some progress via topological and statistical analysis of spatial data over the recent years. We have proposed what is essentially a dichotomy, methods that are more pertinent for visualization-driven discovery, and methods that are more pertinent for discovery of the biologically-active macrostates but not amenable to visualization. In this paper, we present a novel, hybrid method that combines strengths of these methods, allowing both visualization of the landscape and discovery of macrostates. We demonstrate what the method is capable of uncovering in comparison with existing methods over structure spaces sampled with conformational sampling algorithms. Though the direct evaluation in this paper is on protein energy landscapes, the proposed method is of broad interest in cross-cutting problems that necessitate characterization of fitness and optimization landscapes.","[{""name"":""Jing Lei"",""id"":""/profile/99659573535""},{""name"":""Nasrin Akhter"",""id"":""/profile/99659301970""},{""name"":""Wanli Qiao"",""id"":""/profile/99659195578""},{""name"":""Amarda Shehu"",""id"":""/profile/81336493044""},{""name"":""Jing Lei"",""id"":""/profile/99659573535""},{""name"":""Nasrin Akhter"",""id"":""/profile/99659301970""},{""name"":""Wanli Qiao"",""id"":""/profile/99659195578""},{""name"":""Amarda Shehu"",""id"":""/profile/81336493044""}]","[""N. Akhter, J. Lei, W. Qiao, and A. Shehu. 2018. Reconstructing and Decomposing Protein Energy Landscapes to Organize Structure Spaces and Reveal Biologically-active States. In IEEE Intl Conf on Bioinf and Biomed (BIBM). IEEE, Madrid, Spain. accepted.Google Scholar"",""N. Akhter and A. Shehu. 2018. From Extraction of Local Structures of Protein Energy Landscapes to Improved Decoy Selection in Template-free Protein Structure Prediction. Molecules , Vol. 23, 1 (2018), 216.Google ScholarCross Ref"",""R. Bau, D. C. Rees, D. M. Kurtz, R. A. Scott, H. Huang, M. W. W. Adams, and M. K. Eidsness. 1998. Crystal Structure of Rubredoxin from Pyrococcus Furiosus at 0.95 Angstroms Resolution, and the structures of N-terminal methionine and formylmethionine variants of Pf Rd. Contributions of N-terminal interactions to thermostability. J Biol Inorg Chem , Vol. 3 (1998), 484--493.Google ScholarCross Ref"",""H. M. Berman, K. Henrick, and H. Nakamura. 2003. Announcing the worldwide Protein Data Bank. Nat Struct Biol , Vol. 10, 12 (2003), 980--980.Google ScholarCross Ref"",""V. Biou, F. Shu, and V. Ramakrishnan. 1995. X-ray crystallography shows that translational initiation factor IF3 consists of two compact alpha/beta domains linked by an alpha-helix. EMBO J , Vol. 14, 16 (1995), 4056--4064.Google ScholarCross Ref"",""D. D. Boehr, R. Nussinov, and P. E. Wright. 2009. The role of dynamic conformational ensembles in biomolecular recognition. Nature Chem Biol , Vol. 5, 11 (2009), 789--796.Google ScholarCross Ref"",""J. D. Bryngelson, J. N. Onuchic, N. D. Socci, and P. G. Wolynes. 1995. Funnels, pathways, and the energy landscape of protein folding: a synthesis. Proteins: Struct. Funct. Genet. , Vol. 21, 3 (1995), 167--195.Google ScholarCross Ref"",""F. Cazals and T. Dreyfus. 2017. The structural bioinformatics library: modeling in biomolecular science and beyond. Bioinformatics , Vol. 33, 7 (2017), 997--1004.Google Scholar"",""R. Clausen, B. Ma, R. Nussinov, and A. Shehu. 2015. Mapping the Conformation Space of Wildtype and Mutant H-Ras with a Memetic, Cellular, and Multiscale Evolutionary Algorithm. PLoS Comput Biol , Vol. 11, 9 (2015), e1004470.Google ScholarCross Ref"",""R. Clausen and A. Shehu. 2015. A Data-driven Evolutionary Algorithm for Mapping Multi-basin Protein Energy Landscapes. J Comp Biol , Vol. 22, 9 (2015), 844--860.Google ScholarCross Ref"",""P. J. A. Cock, T. Antao, J. T. Chang, B. A. Chapman, C. J. Cox, and more. 2009. Biopython: freely available Python tools for computational molecular biology and bioinformatics. Bioinformatics , Vol. 10, 11 (2009), 1422--1423.Google ScholarDigital Library"",""S. P. Edmondson, L. Qiu, and J. W. Shriver. 1995. Solution structure of the DNA-binding protein Sac7d from the hyperthermophile Sulfolobus acidocaldarius. Biochemistry , Vol. 34, 41 (1995), 13289--13304.Google ScholarCross Ref"",""S. Gerber, P.-T. Bremer, V. Pascucci, and R. Whitaker. 2010. Visual exploration of high dimensional scalar functions. IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS , Vol. 16, 6 (2010), 1271--1280.Google ScholarDigital Library"",""L. E. Kavraki, P. Svetska, J.-C. Latombe, and M. Overmars. 1996. Probabilistic roadmaps for path planning in high-dimensional configuration spaces. IEEE Trans Robotics Automation , Vol. 12, 4 (1996), 566--580.Google ScholarCross Ref"",""A. Leaver-Fay et almbox. 2011. ROSETTA3: an object-oriented software suite for the simulation and design of macromolecules. Methods Enzymol , Vol. 487 (2011), 545--574.Google ScholarCross Ref"",""H. A. Lewis, H. Chen, C. Edo, R. J. Buckanovich, Y. Y. Yang, K. Musunuru, R. Zhong, R. B. Darnell, and S. K. Burley. 1999. Crystal structures of Nova-1 and Nova-2 K-homology RNA-binding domains. Structure , Vol. 7, 2 (1999), 191--203.Google ScholarCross Ref"",""D. G. Luenberger. 1984. Linear and Nonlinear Programming 2nd ed.). Addison-Wesley.Google Scholar"",""T. Maximova, R. Moffatt, B. Ma, R. Nussinov, and A. Shehu. 2016. Principles and Overview of Sampling Methods for Modeling Macromolecular Structure and Dynamics. PLoS Comp. Biol. , Vol. 12, 4 (2016), e1004619.Google ScholarCross Ref"",""T. Maximova, E. Plaku, and A. Shehu. 2018. Structure-guided Protein Transition Modeling with a Probabilistic Roadmap Algorithm. IEEE/ACM Trans Comput Biol and Bioinf , Vol. 15, 6 (2018), 1783--1796.Google ScholarDigital Library"",""A. D. McLachlan. 1972. A mathematical procedure for superimposing atomic coordinates of proteins. Acta Crystallogr. A. , Vol. 26, 6 (1972), 656--657.Google ScholarCross Ref"",""K. Molloy, R. Clausen, and A. Shehu. 2016. A Stochastic Roadmap Method to Model Protein Structural Transitions. Robotica , Vol. 34, 8 (2016), 1705--1733.Google ScholarCross Ref"",""K. Molloy and A. Shehu. 2016. A General, Adaptive, Roadmap-based Algorithm for Protein Motion Computation. IEEE Trans. NanoBioSci. , Vol. 2, 15 (2016), 158--165.Google ScholarCross Ref"",""R. Nussinov and P. G. Wolynes. 2014. A second molecular biology revolution? The energy landscapes of biomolecular function. Phys Chem Chem Phys , Vol. 16, 14 (2014), 6321--6322.Google ScholarCross Ref"",""K. Okazaki, N. Koga, S. Takada, J. N. Onuchic, and P. G. Wolynes. 2006. Multiple-basin energy landscapes for large-amplitude conformational motions of proteins: Structure-based molecular dynamics simulations. Proc. Natl. Acad. Sci. USA , Vol. 103, 32 (2006), 11844--11849.Google ScholarCross Ref"",""J. W. O'Neill, D. E. Kim, D. Baker, and K. Y. Zhang. 2001. Structures of the B1 domain of protein L from Peptostreptococcus magnus with a tyrosine to tryptophan substitution. Acta Crystallogr D Biol Crystallogr , Vol. 57, Pt 4 (2001), 480--487.Google ScholarCross Ref"",""R. Pandit and A. Shehu. 2016. A Principled Comparative Analysis of Dimensionality Reduction Techniques on Protein Structure Decoy Data. In Intl Conf on Bioinf and Comput Biol (Las Vegas, NV), T. Ioerger and N. Haspel (Eds.). ISCA, 43--48.Google Scholar"",""B. Pateiro-Lopez. 2008. Set estimation under convexity type restrictions . Ph.D. Dissertation. Universidad de Santiago de Compostela.Google Scholar"",""G. Rayment, I.AND Wesenberg, T. E. Meyer, M. A. Cusanovich, and H. M. Holden. 1992. Three-dimensional structure of the high-potential iron-sulfur protein isolated from the purple phototrophic bacterium Rhodocyclus tenuis determined and refined at 1.5 $Å$ resolution. J Mol Biol , Vol. 228, 2 (1992), 672--686.Google ScholarCross Ref"",""D. Reverter, C. Fernández-Catalán, R. Baumgartner, R. Pf\""ander, R. Huber, W. Bode, J. Vendrell, T. A. Holak, and F. X. Avilés. 2000. Structure of a novel leech carboxypeptidase inhibitor determined free in solution and in complex with human carboxypeptidase A2 . Nat Struct Biol , Vol. 7, 4 (2000), 322--328.Google ScholarCross Ref"",""E. Sapin, D. B. Carr, K. A. De Jong, and A. Shehu. 2016. Computing energy landscape maps and structural excursions of proteins. BMC Genomics , Vol. 17, Suppl 4 (2016), 456.Google ScholarCross Ref"",""S. Schumacher, R. T. Clubb, M. Cai, K. Mizuuchi, G. M. Clore, and A. M. Gronenborn. 1997. Solution structure of the Mu end DNA-binding ibeta subdomain of phage Mu transposase: modular DNA recognition by two tethered domains. EMBO J , Vol. 16, 24 (1997), 7532--7541.Google ScholarCross Ref"",""A. Shehu and E. Plaku. 2016. A Survey of omputational Treatments of Biomolecules by Robotics-inspired Methods Modeling Equilibrium Structure and Dynamics. J Artif Intel Res , Vol. 597 (2016), 509--572.Google ScholarCross Ref"",""S. Su, Y. G. Gao, H. Robinson, Y. C. Liaw, S. P. Edmondson, J. W. Shriver, and A. H. Wang. 2011. Crystal structures of the chromosomal proteins Sso7d/Sac7d bound to DNA containing T-G mismatched base-pairs. J Mol Biol , Vol. 303, 3 (2011), 395--403.Google ScholarCross Ref"",""M. Sunnerhagen, M. Nilges, G. Otting, and J. Carey. 1997. Solution structure of the DNA-binding domain and model for the complex of multifunctional hexameric arginine repressor with DNA . Nat Struct Biol , Vol. 4, 10 (1997), 819--826.Google ScholarCross Ref"",""D. J. Wales, M. A. Miller, and T. R. Walsh. 1998. Archetypal energy landscapes. Nature , Vol. 394, 6695 (1998), 758--760.Google Scholar"",""S. Wright. 1934. The roles of mutation, inbreeding, crossbreeding, and selection in evolution. In Intl Congress of Genetics. 356--366.Google Scholar""]"
https://doi.org/10.1145/3394486.3403301,Map Generation from Large Scale Incomplete and Inaccurate Data Labels,"Accurately and globally mapping human infrastructure is an important and challenging task with applications in routing, regulation compliance monitoring, and natural disaster response management etc.. In this paper we present progress in developing an algorithmic pipeline and distributed compute system that automates the process of map creation using high resolution aerial images. Unlike previous studies, most of which use datasets that are available only in a few cities across the world, we utilizes publicly available imagery and map data, both of which cover the contiguous United States (CONUS). We approach the technical challenge of inaccurate and incomplete training data adopting state-of-the-art convolutional neural network architectures such as the U-Net and the CycleGAN to incrementally generate maps with increasingly more accurate and more complete labels of man-made infrastructure such as roads and houses. Since scaling the mapping task to CONUS calls for parallelization, we then adopted an asynchronous distributed stochastic parallel gradient descent training scheme to distribute the computational workload onto a cluster of GPUs with nearly linear speed-up.","[{""name"":""Rui Zhang"",""id"":""/profile/99659573875""},{""name"":""Conrad Albrecht"",""id"":""/profile/99658972656""},{""name"":""Wei Zhang"",""id"":""/profile/99659138721""},{""name"":""Xiaodong Cui"",""id"":""/profile/81440594332""},{""name"":""Ulrich Finkler"",""id"":""/profile/81100161596""},{""name"":""David Kung"",""id"":""/profile/81408593178""},{""name"":""Siyuan Lu"",""id"":""/profile/99658975212""},{""name"":""Rui Zhang"",""id"":""/profile/99659573875""},{""name"":""Conrad Albrecht"",""id"":""/profile/99658972656""},{""name"":""Wei Zhang"",""id"":""/profile/99659138721""},{""name"":""Xiaodong Cui"",""id"":""/profile/81440594332""},{""name"":""Ulrich Finkler"",""id"":""/profile/81100161596""},{""name"":""David Kung"",""id"":""/profile/81408593178""},{""name"":""Siyuan Lu"",""id"":""/profile/99658975212""}]","[""[n.d.]. Open Street Map. https://www.openstreetmap.org. Accessed: 2020-02-01.Google Scholar"",""[n.d.]. SpaceNet ? Accelerating Geospatial Machine Learning. https://spacenet.ai/. Accessed: 2020-02-03.Google Scholar"",""Derrick Bonafilia, James Gill, Saikat Basu, and David Yang. 2019. Building High Resolution Maps for Humanitarian Aid and Development with Weakly-and Semi-Supervised Learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops. 1--9.Google Scholar"",""Open Geospatial Consortium. 2019. OGC GeoTIFF standard. http://docs.opengeospatial.org/is/19-008r4/19-008r4.htmlGoogle Scholar"",""Ilke Demir, Krzysztof Koperski, David Lindenbaum, Guan Pang, Jing Huang, Saikat Basu, Forest Hughes, Devis Tuia, and Ramesh Raskar. 2018. DeepGlobe 2018: A Challenge to Parse the Earth Through Satellite Images. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops.Google ScholarCross Ref"",""Adam Van Etten, Dave Lindenbaum, and Todd M. Bacastow. 2018. SpaceNet: A Remote Sensing Dataset and Challenge Series. arxiv: cs.CV/1807.01232Google Scholar"",""Raphael A. Finkel and Jon Louis Bentley. 1974. Quad trees a data structure for retrieval on composite keys. Acta informatica, Vol. 4, 1 (1974), 1--9.Google Scholar"",""Priya Goyal, Piotr Dollár, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He. 2017. Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour. arxiv: cs.CV/1706.02677Google Scholar"",""Suyog Gupta, Wei Zhang, and Fei Wang. 2016. Model Accuracy and Runtime Tradeoff in Distributed Deep Learning: A Systematic Study. 171--180. https://doi.org/10.1109/ICDM.2016.0028Google Scholar"",""IEEE. 2015. Towards a Definition of the Internet of Things (IoT). https://iot.ieee.org/definition.htmlGoogle Scholar"",""Pascal Kaiser, Jan Dirk Wegner, Aurélien Lucchi, Martin Jaggi, Thomas Hofmann, and Konrad Schindler. 2017. Learning aerial image segmentation from online maps. IEEE Transactions on Geoscience and Remote Sensing, Vol. 55, 11 (2017), 6054--6068.Google ScholarCross Ref"",""Levente J Klein, Fernando J Marianno, Conrad M Albrecht, Marcus Freitag, Siyuan Lu, Nigel Hinds, Xiaoyan Shao, Sergio Bermudez Rodriguez, and Hendrik F Hamann. 2015. PAIRS: A scalable geo-spatial data analytics platform. In 2015 IEEE International Conference on Big Data (Big Data). IEEE, 1290--1298.Google ScholarDigital Library"",""Xiangru Lian, Ce Zhang, Huan Zhang, Cho-Jui Hsieh, Wei Zhang, and Ji Liu. 2017. Can Decentralized Algorithms Outperform Centralized Algorithms? A Case Study for Decentralized Parallel Stochastic Gradient Descent. In Advances in Neural Information Processing Systems 30, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.). Curran Associates, Inc., 5330--5340. http://papers.nips.cc/paper/7117-can-decentralized-algorithms-outperform-centralized-algorithms-a-case-study-for-decentralized-parallel-stochastic-gradient-descent.pdfGoogle ScholarDigital Library"",""Xiangru Lian, Wei Zhang, Ce Zhang, and Ji Liu. 2018. Asynchronous Decentralized Parallel Stochastic Gradient Descent. In Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsm\""a ssan, Stockholm, Sweden, July 10-15, 2018. 3049--3058. http://proceedings.mlr.press/v80/lian18a.htmlGoogle Scholar"",""Siyuan Lu, Xiaoyan Shao, Marcus Freitag, Levente J Klein, Jason Renwick, Fernando J Marianno, Conrad Albrecht, and Hendrik F Hamann. 2016. IBM PAIRS curated big data service for accelerated geospatial data analytics and discovery. In 2016 IEEE International Conference on Big Data (Big Data). IEEE, 2672--2675.Google ScholarCross Ref"",""S. Lu, X. Shao, M. Freitag, L. J. Klein, J. Renwick, F. J. Marianno, C. Albrecht, and H. F. Hamann. 2016. IBM PAIRS curated big data service for accelerated geospatial data analytics and discovery. In 2016 IEEE International Conference on Big Data (Big Data). 2672--2675. https://doi.org/10.1109/BigData.2016.7840910Google ScholarCross Ref"",""Emmanuel Maggiori, Yuliya Tarabalka, Guillaume Charpiat, and Pierre Alliez. 2016. Convolutional neural networks for large-scale remote-sensing image classification. IEEE Transactions on Geoscience and Remote Sensing, Vol. 55, 2 (2016), 645--657.Google ScholarCross Ref"",""Mapnik. 2005. Mapnik. https://github.com/mapnik/mapnik/.Google Scholar"",""Microsoft. 2018. US Building Footprints. https://github.com/microsoft/USBuildingFootprints.Google Scholar"",""U.S. Department of Agriculture. 2020. National Agriculture Imagery Program. https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/Google Scholar"",""Kohei Ozaki. 2019. Winning Solution for the Spacenet Challenge: Joint Learning with OpenStreetMap. https://i.ho.lc/winning-solution-for-the-spacenet-challenge-joint-learning-with-openstreetmap.htmlGoogle Scholar"",""Olaf Ronneberger, Philipp Fischer, and Thomas Brox. 2015. U-Net: Convolutional Networks for Biomedical Image Segmentation. Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015 (2015), 234--241. https://doi.org/10.1007/978-3-319-24574-4_28Google Scholar"",""Gaurav Sharma. 2003. Digital Color Imaging Handbook. CRC Press.Google Scholar"",""Suriya Singh, Anil Batra, Guan Pang, Lorenzo Torresani, Saikat Basu, Manohar Paluri, and CV Jawahar. 2018. Self-Supervised Feature Learning for Semantic Segmentation of Overhead Imagery.. In BMVC, Vol. 1. 4.Google Scholar"",""Tobias G Tiecke, Xianming Liu, Amy Zhang, Andreas Gros, Nan Li, Gregory Yetman, Talip Kilic, Siobhan Murray, Brian Blankespoor, Espen B Prydz, et almbox. 2017. Mapping the world population one building at a time. arXiv preprint arXiv:1712.05839 (2017).Google Scholar"",""Mehul Nalin Vora. 2011. Hadoop-HBase for large-scale data. In Proceedings of 2011 International Conference on Computer Science and Network Technology, Vol. 1. IEEE, 601--605.Google ScholarCross Ref"",""Wai Yeung Yan, Ahmed Shaker, and Nagwa El-Ashmawy. 2015. Urban land cover classification using airborne LiDAR data: A review. Remote Sensing of Environment, Vol. 158 (2015), 295--310.Google ScholarCross Ref"",""Matei Zaharia, Reynold S Xin, Patrick Wendell, Tathagata Das, Michael Armbrust, Ankur Dave, Xiangrui Meng, Josh Rosen, Shivaram Venkataraman, Michael J Franklin, et almbox. 2016. Apache spark: a unified engine for big data processing. Commun. ACM, Vol. 59, 11 (2016), 56--65.Google ScholarDigital Library"",""Wei Zhang, Xiaodong Cui, Abdullah Kayi, Mingrui Liu, Ulrich Finkler, Brian Kingsbury, George Saon, Youssef Mroueh, Alper Buyuktosunoglu, Payel Das, David Kung, and Michael Picheny. 2020. Improving Efficiency in Large-Scale Decentralized Distributed Training. In ICASSP'2020.Google Scholar"",""Wei Zhang, Suyog Gupta, Xiangru Lian, and Ji Liu. 2016. Staleness-Aware Async-SGD for Distributed Deep Learning. In Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence (New York, New York, USA) (IJCAI'16). AAAI Press, 2350--2356.Google ScholarDigital Library"",""Lichen Zhou, Chuang Zhang, and Ming Wu. 2018. D-LinkNet: LinkNet With Pretrained Encoder and Dilated Convolution for High Resolution Satellite Imagery Road Extraction.. In CVPR Workshops. 182--186.Google ScholarCross Ref"",""Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. 2017. Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks. In Computer Vision (ICCV), 2017 IEEE International Conference on.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403302,Grale: Designing Networks for Graph Learning,"How can we find the right graph for semi-supervised learning? In real world applications, the choice of which edges to use for computation is the first step in any graph learning process. Interestingly, there are often many types of similarity available to choose as the edges between nodes, and the choice of edges can drastically affect the performance of downstream semi-supervised learning systems. However, despite the importance of graph design, most of the literature assumes that the graph is static.In this work, we present Grale, a scalable method we have developed to address the problem of graph design for graphs with billions of nodes. Grale operates by fusing together different measures of (potentially weak) similarity to create a graph which exhibits high task-specific homophily between its nodes. Grale is designed for running on large datasets. We have deployed Grale in more than 20 different industrial settings at Google, including datasets which have tens of billions of nodes, and hundreds of trillions of potential edges to score. By employing locality sensitive hashing techniques, we greatly reduce the number of pairs that need to be scored, allowing us to learn a task specific model and build the associated nearest neighbor graph for such datasets in hours, rather than the days or even weeks that might be required otherwise.We illustrate this through a case study where we examine the application of Grale to an abuse classification problem on YouTube with hundreds of million of items. In this application, we find that Grale detects a large number of malicious actors on top of hard-coded rules and content classifiers, increasing the total recall by 89% over those approaches alone.","[{""name"":""Jonathan Halcrow"",""id"":""/profile/99659574989""},{""name"":""Alexandru Mosoi"",""id"":""/profile/99659573005""},{""name"":""Sam Ruth"",""id"":""/profile/99659575006""},{""name"":""Bryan Perozzi"",""id"":""/profile/81496689145""},{""name"":""Jonathan Halcrow"",""id"":""/profile/99659574989""},{""name"":""Alexandru Mosoi"",""id"":""/profile/99659573005""},{""name"":""Sam Ruth"",""id"":""/profile/99659575006""},{""name"":""Bryan Perozzi"",""id"":""/profile/81496689145""}]","[""S. Abu-El-Haija et al. 2017. Learning edge representations via low-rank asymmetric projections. CIKM.Google Scholar"",""M. Al Hasan et al. 2006. Link prediction using supervised learning. SDM Workshops.Google Scholar"",""A. Blum et al. 2001. Learning from labeled and unlabeled data using graph mincuts. ICML.Google Scholar"",""J. Bromley et al. 1994. Signature verification using a \""siamese\"" time delay neural network. NIPS.Google Scholar"",""I. Chami et al. 2020. Machine learning on graphs: a model and comprehensive taxonomy. arXiv preprint arXiv:2005.03675.Google Scholar"",""H. Chen et al. 2018. A tutorial on network embeddings. arXiv preprint arXiv:1808.02590.Google Scholar"",""H. Chen et al. 2018. Enhanced network embeddings via exploiting edge labels. CIKM.Google Scholar"",""H. Chen et al. 2005. Link prediction approach to collaborative filtering. JCDL.Google Scholar"",""P. Cui et al. 2018. A survey on network embedding. TKDE.Google Scholar"",""C. A. R. de Sousa et al. 2013. Influence of graph construction on semi-supervised learning. ECML/PKDD.Google Scholar"",""C. Kanich et al. 2011. Show me the money: characterizing spam-advertised revenue. SEC.Google Scholar"",""M. Karasuyama et al. 2017. Adaptive edge weighting for graph-based learning algorithms. Mach. Learn.Google Scholar"",""D. P. Kingma et al. 2014. Semi-supervised learning with deep generative models. NIPS.Google Scholar"",""G. Koch. 2015. Siamese neural networks for one-shot image recognition. ICML Workshops.Google Scholar"",""K. Levchenko et al. 2011. Click trajectories: end-to-end analysis of the spam value chain. S\u0026P.Google Scholar"",""L. v. d. Maaten et al. 2008. Visualizing data using t-sne. JMLR.Google Scholar"",""D. McCoy et al. 2012. Pharmaleaks: understanding the business of online pharmaceutical affiliate programs. SEC.Google Scholar"",""E. Müller et al. 2009. Evaluating clustering in subspace projections of high dimensional data. VLDB.Google Scholar"",""A. Murua et al. 2008. On potts model clustering, kernel k-means and density estimation. Journal of Computational and Graphical Statistics.Google ScholarCross Ref"",""B. Perozzi et al. 2014. Deepwalk: online learning of social representations. KDD.Google Scholar"",""B. Perozzi et al. 2014. Focused clustering and outlier detection in large attributed graphs. KDD.Google Scholar"",""B. Perozzi et al. 2016. When recommendation goes wrong: anomalous link discovery in recommendation networks. KDD.Google Scholar"",""N. Ponomareva et al. 2017. Compact multi-class boosted trees. Big Data.Google Scholar"",""N. Ponomareva et al. 2017. Tf boosted trees: a scalable tensorflow based framework for gradient boosting. ECML/PKDD. Y. Altun et al., editors.Google Scholar"",""S. Ravi et al. 2016. Large scale distributed semi-supervised learning using streaming approximation. Artificial Intelligence and Statistics, 519--528.Google Scholar"",""G. T. Report. [n. d.] https://transparencyreport.google.com/youtube-policy/ removals. ().Google Scholar"",""T. Salimans et al. 2016. Improved techniques for training gans. NIPS.Google Scholar"",""D. Samosseiko. 2009. The partnerka-what is it, and why should you care. Virus Bulletin Conference.Google Scholar"",""X. Wu et al. 2018. A quest for structure: jointly learning the graph structure and semi-supervised classification. CIKM.Google Scholar"",""Z. Yang et al. 2016. Revisiting semi-supervised learning with graph embeddings. ICML.Google Scholar"",""YouTube. [n. d.] https://www.youtube.com/intl/en-GB/about/press/. ().Google Scholar"",""Y.-M. Zhang et al. 2013. Fast knn graph construction with locality sensitive hashing. ECML/PKKD.Google Scholar"",""D. Zhou et al. 2003. Learning with local and global consistency. NIPS.Google Scholar"",""X. Zhu et al. 2003. Semi-supervised learning using gaussian fields and harmonic functions. ICML.Google Scholar""]"
https://doi.org/10.1145/3394486.3403303,Automatic Validation of Textual Attribute Values in E-commerce Catalog by Learning with Limited Labeled Data,"Product catalogs are valuable resources for eCommerce website. In the catalog, a product is associated with multiple attributes whose values are short texts, such as product name, brand, functionality and flavor. Usually individual retailers self-report these key values, and thus the catalog information unavoidably contains noisy facts. It is very important to validate the correctness of these values in order to improve shopper experiences and enable more effective product recommendation. Due to the huge volume of products, an effective automatic validation approach is needed. In this paper, we propose to develop an automatic validation approach that verifies the correctness of textual attribute values for products. This can be formulated as a task as cross-checking a textual attribute value against product profile, which is a short textual description of the product on eCommerce website. Although existing deep neural network models have shown success in conducting cross-checking between two pieces of texts, their success has to be dependent upon a large set of quality labeled data, which are hard to obtain in this validation task: products span a variety of categories. Due to the category difference, annotation has to be done on all the categories, which is impossible to achieve in real practice.To address the aforementioned challenges, we propose a novel meta-learning latent variable approach, called MetaBridge, which can learn transferable knowledge from a subset of categories with limited labeled data and capture the uncertainty of never-seen categories with unlabeled data. More specifically, we make the following contributions. (1) We formalize the problem of validating the textual attribute values of products from a variety of categories as a natural language inference task in the few-shot learning setting, and propose a meta-learning latent variable model to jointly process the signals obtained from product profiles and textual attribute values. (2) We propose to integrate meta learning and latent variable in a unified model to effectively capture the uncertainty of various categories. With this model, annotation costs can be significantly reduced as we make best use of labeled data from limited categories. (3) We propose a novel objective function based on latent variable model in the few-shot learning setting, which ensures distribution consistency between unlabeled and labeled data and prevents overfitting by sampling different records from the learned distribution. Extensive experiments on real eCommerce datasets from hundreds of categories demonstrate the effectiveness of MetaBridge on textual attribute validation and its outstanding performance compared with state-of-the-art approaches.","[{""name"":""Yaqing Wang"",""id"":""/profile/99659286574""},{""name"":""Yifan Ethan Xu"",""id"":""/profile/99659461704""},{""name"":""Xian Li"",""id"":""/profile/99659462223""},{""name"":""Xin Luna Dong"",""id"":""/profile/99659531494""},{""name"":""Jing Gao"",""id"":""/profile/81314494134""},{""name"":""Yaqing Wang"",""id"":""/profile/99659286574""},{""name"":""Yifan Ethan Xu"",""id"":""/profile/99659461704""},{""name"":""Xian Li"",""id"":""/profile/99659462223""},{""name"":""Xin Luna Dong"",""id"":""/profile/99659531494""},{""name"":""Jing Gao"",""id"":""/profile/81314494134""}]","[""Trapit Bansal, Rishikesh Jha, and Andrew McCallum. 2019. Learning to Few- Shot Learn Across Diverse Natural Language Classification Tasks. arXiv preprint arXiv:1911.03863 (2019).Google Scholar"",""Yoshua Bengio, Eric Laufer, Guillaume Alain, and Jason Yosinski. 2014. Deep generative stochastic networks trainable by backprop. In International Conference on Machine Learning. 226--234.Google ScholarDigital Library"",""Yoshua Bengio, Nicholas Léonard, and Aaron Courville. 2013. Estimating or propagating gradients through stochastic neurons for conditional computation. arXiv preprint arXiv:1308.3432 (2013).Google Scholar"",""David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver, and Colin A Raffel. 2019. Mixmatch: A holistic approach to semi-supervised learning. In Advances in Neural Information Processing Systems. 5050--5060.Google Scholar"",""Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. Enriching Word Vectors with Subword Information. Transactions of the Association for Computational Linguistics 5 (2017), 135--146.Google ScholarCross Ref"",""Samuel R Bowman, Gabor Angeli, Christopher Potts, and Christopher D Manning. 2015. A large annotated corpus for learning natural language inference. arXiv preprint arXiv:1508.05326 (2015).Google Scholar"",""Andy Brown, Aaron Tuor, Brian Hutchinson, and Nicole Nichols. 2018. Recurrent neural network attention mechanisms for interpretable system log anomaly detection. In Proceedings of the First Workshop on Machine Learning for Computing Systems. 1--8.Google ScholarDigital Library"",""Raghavendra Chalapathy and Sanjay Chawla. 2019. Deep learning for anomaly detection: A survey. arXiv preprint arXiv:1901.03407 (2019).Google Scholar"",""Varun Chandola, Arindam Banerjee, and Vipin Kumar. 2009. Anomaly detection: A survey. ACM computing surveys (CSUR) 41, 3 (2009), 15.Google Scholar"",""Qian Chen, Xiaodan Zhu, Zhen-Hua Ling, Si Wei, Hui Jiang, and Diana Inkpen. 2017. Enhanced LSTM for Natural Language Inference. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 1657--1668.Google ScholarCross Ref"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). 4171--4186.Google Scholar"",""Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017. Model-agnostic metalearning for fast adaptation of deep networks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 1126--1135.Google ScholarDigital Library"",""Marta Garnelo, Jonathan Schwarz, Dan Rosenbaum, Fabio Viola, Danilo J Rezende, SM Eslami, and Yee Whye Teh. 2018. Neural processes. arXiv preprint arXiv:1807.01622 (2018).Google Scholar"",""Reza Ghaeini, Sadid A Hasan, Vivek Datla, Joey Liu, Kathy Lee, Ashequl Qadir, Yuan Ling, Aaditya Prakash, Xiaoli Fern, and Oladimeji Farri. 2018. DR-BiLSTM: Dependent Reading Bidirectional LSTM for Natural Language Inference. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers). 1460--1469.Google ScholarCross Ref"",""Yves Grandvalet and Yoshua Bengio. 2005. Semi-supervised learning by entropy minimization. In Advances in neural information processing systems. 529--536.Google Scholar"",""Wenjun Jiang, Chenglin Miao, Fenglong Ma, Shuochao Yao, Yaqing Wang, Ye Yuan, Hongfei Xue, Chen Song, Xin Ma, Dimitrios Koutsonikolas, et al. 2018. Towards environment independent device free human activity recognition. In MobiCom. ACM, 289--304.Google Scholar"",""Giannis Karamanolakis, Jun Ma, and Xin Luna Dong. 2020. TXtract: Taxonomy- Aware Knowledge Extraction for Thousands of Product Categories. arXiv preprint arXiv:2004.13852 (2020).Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Diederik P Kingma and Max Welling. 2013. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 (2013).Google Scholar"",""Dong-Hyun Lee. 2013. Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks. In Workshop on Challenges in Representation Learning, ICML, Vol. 3. 2.Google Scholar"",""Zhenguo Li, Fengwei Zhou, Fei Chen, and Hang Li. 2017. Meta-SGD: Learning to learn quickly for few-shot learning. arXiv preprint arXiv:1707.09835 (2017).Google Scholar"",""Pietro Morerio, Jacopo Cavazza, and Vittorio Murino. 2017. Minimal-entropy correlation alignment for unsupervised deep domain adaptation. arXiv preprint arXiv:1711.10288 (2017).Google Scholar"",""F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011. Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research 12 (2011), 2825--2830.Google ScholarDigital Library"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998--6008.Google Scholar"",""Ricardo Vilalta and Youssef Drissi. 2002. A perspective view and survey of meta-learning. Artificial intelligence review 18, 2 (2002), 77--95.Google Scholar"",""Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et al. 2016. Matching networks for one shot learning. In Advances in neural information processing systems. 3630--3638.Google Scholar"",""Tuan-Hung Vu, Himalaya Jain, Maxime Bucher, Matthieu Cord, and Patrick Pérez. 2019. Advent: Adversarial entropy minimization for domain adaptation in semantic segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2517--2526.Google ScholarCross Ref"",""Adina Williams, Nikita Nangia, and Samuel R Bowman. 2017. A broad-coverage challenge corpus for sentence understanding through inference. arXiv preprint arXiv:1704.05426 (2017).Google Scholar"",""Dani Yogatama, Cyprien de Masson d'Autume, Jerome Connor, Tomas Kocisky, Mike Chrzanowski, Lingpeng Kong, Angeliki Lazaridou, Wang Ling, Lei Yu, Chris Dyer, et al. 2019. Learning and evaluating general linguistic intelligence. arXiv preprint arXiv:1901.11373 (2019).Google Scholar"",""Boxue Zhang, Qi Zhao, Wenquan Feng, and Shuchang Lyu. 2018. AlphaMEX: a smarter global pooling method for convolutional neural networks. Neurocomputing 321 (2018), 36--48.Google ScholarCross Ref"",""Guineng Zheng, Subhabrata Mukherjee, Xin Luna Dong, and Feifei Li. 2018. Opentag: Open attribute value extraction from product profiles. In KDD 2018.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403304,CLARA: Confidence of Labels and Raters,"Large online services employ thousands of people to label content for applications such as video understanding, natural language processing, and content policy enforcement. While labelers typically reach their decisions by following a well-defined ""protocol'', humans may still make mistakes. A common countermeasure is to have multiple people review the same content; however, this process is often time-intensive and requires accurate aggregation of potentially noisy decisions.In this paper, we present CLARA (Confidence of Labels and Raters), a system developed and deployed at Facebook for aggregating reviewer decisions and estimating their uncertainty. We perform extensive validations and describe the deployment of CLARA for measuring the base rate of policy violations, quantifying reviewers' performance, and improving their efficiency. In our experiments, we found that CLARA (a) provides an unbiased estimator of violation rates that is robust to changes in reviewer quality, with accurate confidence intervals, (b) provides an accurate assessment of reviewers' performance, and (c) improves efficiency by reducing the number of reviews based on the review certainty, and enables the operational selection of a threshold on the cost/accuracy efficiency frontier.","[{""name"":""Viet-An Nguyen"",""id"":""/profile/99659573059""},{""name"":""Peibei Shi"",""id"":""/profile/99659574077""},{""name"":""Jagdish Ramakrishnan"",""id"":""/profile/99659264542""},{""name"":""Udi Weinsberg"",""id"":""/profile/99659575218""},{""name"":""Henry C. Lin"",""id"":""/profile/99659573019""},{""name"":""Steve Metz"",""id"":""/profile/99659574187""},{""name"":""Neil Chandra"",""id"":""/profile/99659573144""},{""name"":""Jane Jing"",""id"":""/profile/99659574111""},{""name"":""Dimitris Kalimeris"",""id"":""/profile/99659573746""},{""name"":""Viet-An Nguyen"",""id"":""/profile/99659573059""},{""name"":""Peibei Shi"",""id"":""/profile/99659574077""},{""name"":""Jagdish Ramakrishnan"",""id"":""/profile/99659264542""},{""name"":""Udi Weinsberg"",""id"":""/profile/99659575218""},{""name"":""Henry C. Lin"",""id"":""/profile/99659573019""},{""name"":""Steve Metz"",""id"":""/profile/99659574187""},{""name"":""Neil Chandra"",""id"":""/profile/99659573144""},{""name"":""Jane Jing"",""id"":""/profile/99659574111""},{""name"":""Dimitris Kalimeris"",""id"":""/profile/99659573746""}]","[""Lora Aroyo, Anca Dumitrache, Oana Inel, Zoltán Szlávik, Benjamin Timmermans, and Chris Welty. 2019. Crowdsourcing Inclusivity: Dealing with Diversity of Opinions, Perspectives and Ambiguity in Annotated Data. In WWW. 1294--1295.Google Scholar"",""Stephen H Bach, Bryan He, Alexander Ratner, and Christopher Ré. 2017. Learning the structure of generative models without labeled data. In Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org.Google ScholarDigital Library"",""Antonio Bella, Cesar Ferri, Jose Hernandez-Orallo, and Maria Jose Ramirez-Quintana. 2010. Quantification via Probability Estimators. In ICDM.Google Scholar"",""Joaquin Quiñonero Candela. 2019. Facebook and the Technical University of Munich Announce New Independent TUM Institute for Ethics in Artificial Intelligence. https://newsroom.fb.com/news/2019/01/tum-institute-for-ethics-in-ai/Google Scholar"",""Peng Cao, Yilun Xu, Yuqing Kong, and Yizhou Wang. 2019. Max-MIG: an Information Theoretic Approach for Joint Learning from Crowds. In ICLR.Google Scholar"",""Dallas Card and Noah A Smith. 2018. The Importance of Calibration for Estimating Proportions from Annotations. In NAACL-HLT, Vol. 1.Google ScholarCross Ref"",""Bob Carpenter. 2008. Multilevel Bayesian models of categorical data annotation. Unpublished manuscript, Vol. 17, 122 (2008), 45--50.Google Scholar"",""A. P. Dawid and A. M. Skene. 1979. Maximum likelihood estimation of observer error-rates using the EM algorithm. Applied Statistics 1 (1979).Google Scholar"",""B. Efron. 1979. Bootstrap Methods: Another Look at the Jackknife. The Annals of Statistics, Vol. 7, 1 (1979), 1--26.Google ScholarCross Ref"",""Facebook. 2016. Introducing FBLearner Flow: Facebook's AI backbone. https://code.fb.com/core-data/introducing-fblearner-flow-facebook-s-ai-backbone/Google Scholar"",""Paul Felt, Kevin Black, Eric Ringger, Kevin Seppi, and Robbie Haertel. 2015. Early Gains Matter: A Case for Preferring Generative over Discriminative Crowdsourcing Models. In NAACL-HLT. 882--891.Google Scholar"",""Paul Felt, Eric Ringger, and Kevin Seppi. 2016. Semantic annotation aggregation with conditional crowdsourcing models and word embeddings. In COLING.Google Scholar"",""George Forman. 2005. Counting Positives Accurately Despite Inaccurate Classification. In ECML.Google Scholar"",""George Forman. 2008. Quantifying Counts and Costs via Classification. Data Min. Knowl. Discov., Vol. 17, 2 (Oct. 2008), 164--206.Google ScholarDigital Library"",""Pablo González, Alberto Casta no, Nitesh V. Chawla, and Juan José Del Coz. 2017. A Review on Quantification Learning. ACM Comput. Surv., Vol. 50, 5 (Sept. 2017).Google ScholarDigital Library"",""Melody Y. Guan, Varun Gulshan, Andrew M. Dai, and Geoffrey E. Hinton. 2017. Who Said What: Modeling Individual Labelers Improves Classification. In AAAI.Google Scholar"",""Nguyen Quoc Viet Hung, Nguyen Thanh Tam, Lam Ngoc Tran, and Karl Aberer. 2013. An evaluation of aggregation techniques in crowdsourcing. In WISE .Google Scholar"",""Panagiotis G Ipeirotis, Foster Provost, Victor S Sheng, and Jing Wang. 2014. Repeated labeling using multiple noisy labelers. Data Mining and Knowledge Discovery, Vol. 28, 2 (2014), 402--441.Google ScholarDigital Library"",""Panagiotis G Ipeirotis, Foster Provost, and Jing Wang. 2010. Quality management on Amazon Mechanical Turk. In SIGKDD Workshop on Human Computation.Google ScholarDigital Library"",""Daniel Kahneman, Andrew M. Rosenfield, Linnea Gandhi, and Tom Blaser. 2016. Noise: How to Overcome the High, Hidden Cost of Inconsistent Decision Making. https://hbr.org/2016/10/noiseGoogle Scholar"",""David R. Karger, Sewoong Oh, and Devavrat Shah. 2011. Iterative Learning for Reliable Crowdsourcing Systems. In NeurIPS. 1953--1961.Google Scholar"",""Katherine A. Keith and Brendan O'Connor. 2018. Uncertainty-aware generative models for inferring document class prevalence. In EMNLP.Google Scholar"",""Ashish Khetan, Zachary C Lipton, and Anima Anandkumar. 2018. Learning From Noisy Singly-labeled Data. In ICLR.Google Scholar"",""Hyun-Chul Kim and Zoubin Ghahramani. 2012. Bayesian classifier combination. In Artificial Intelligence and Statistics. 619--627.Google Scholar"",""Yaliang Li, Jing Gao, Chuishi Meng, Qi Li, Lu Su, Bo Zhao, Wei Fan, and Jiawei Han. 2016. A Survey on Truth Discovery. SIGKDD, Vol. 17, 2 (2016).Google ScholarDigital Library"",""Yuan Li, Benjamin Rubinstein, and Trevor Cohn. 2019. Exploiting Worker Correlation for Label Aggregation in Crowdsourcing. In ICML. 3886--3895.Google Scholar"",""Qiang Liu, Jian Peng, and Alexander Ihler. 2012. Variational Inference for Crowdsourcing. In NeurIPS. 692--700.Google Scholar"",""Pablo G. Moreno, Antonio Artés-Rodríguez, Yee Whye Teh, and Fernando Perez-Cruz. 2015. Bayesian Nonparametric Crowdsourcing. JMLR, Vol. 16, 1 (2015).Google Scholar"",""Alejandro Moreo and Fabrizio Sebastiani. 2019. Learning to Quantify: Estimating Class Prevalence via Supervised Learning. In SIGIR.Google Scholar"",""An T. Nguyen, Byron C. Wallace, and Matthew Lease. 2016. A Correlated Worker Model for Grouped, Imbalanced and Multitask Data. In UAI. 537--546.Google Scholar"",""Curtis G. Northcutt, Lu Jiang, and Isaac L. Chuang. 2019. Confident Learning: Estimating Uncertainty in Dataset Labels. arxiv: stat.ML/1911.00068Google Scholar"",""Rebecca J Passonneau and Bob Carpenter. 2014. The benefits of a model of annotation. TACL, Vol. 2 (2014).Google ScholarCross Ref"",""Silviu Paun, Bob Carpenter, Jon Chamberlain, Dirk Hovy, Udo Kruschwitz, and Massimo Poesio. 2018. Comparing Bayesian Models of Annotation. TACL, Vol. 6 (2018), 571--585.Google ScholarCross Ref"",""Marthinus C. Plessis, Gang Niu, and Masashi Sugiyama. 2017. Class-prior Estimation for Learning from Positive and Unlabeled Data. Machine Learning (2017).Google Scholar"",""Alexander J. Ratner, Stephen H. Bach, Henry E. Ehrenberg, and Christopher Ré. 2017. Snorkel: Rapid Training Data Creation with Weak Supervision. VLDB Endowment, Vol. 11, 3 (2017), 269--282.Google ScholarDigital Library"",""Vikas C Raykar, Shipeng Yu, Linda H Zhao, Anna Jerebko, Charles Florin, Gerardo Hermosillo Valadez, Luca Bogoni, and Linda Moy. 2009. Supervised learning from multiple experts: whom to trust when everyone lies a bit. In ICML.Google Scholar"",""Vikas C. Raykar, Shipeng Yu, Linda H. Zhao, Gerardo Hermosillo Valadez, Charles Florin, Luca Bogoni, and Linda Moy. 2010. Learning From Crowds. JMLR, Vol. 11 (Aug. 2010), 1297--1322.Google Scholar"",""Marco Saerens, Patrice Latinne, and Christine Decaestecker. 2002. Adjusting the Outputs of a Classifier to New a Priori Probabilities: A Simple Procedure. Neural Computation (2002).Google Scholar"",""Victor S. Sheng, Foster Provost, and Panagiotis G. Ipeirotis. 2008. Get Another Label? Improving Data Quality and Data Mining Using Multiple, Noisy Labelers. In SIGKDD. 614--622.Google Scholar"",""Edwin Simpson, Stephen Roberts, Ioannis Psorakis, and Arfon Smith. 2013. Dynamic Bayesian Combination of Multiple Imperfect Classifiers .Springer Berlin Heidelberg, Berlin, Heidelberg, 1--35.Google Scholar"",""Padhraic Smyth, Usama M Fayyad, Michael C Burl, Pietro Perona, and Pierre Baldi. 1995. Inferring ground truth from subjective labelling of Venus images. In NeurIPS. 1085--1092.Google Scholar"",""Rion Snow, Brendan O'Connor, Daniel Jurafsky, and Andrew Ng. 2008. Cheap and Fast -- But is it Good? Evaluating Non-Expert Annotations for Natural Language Tasks. In EMNLP. 254--263.Google Scholar"",""Jennifer Wortman Vaughan. 2018. Making Better Use of the Crowd: How Crowdsourcing Can Advance Machine Learning Research. JMLR, Vol. 18 (2018), 193--1.Google Scholar"",""Matteo Venanzi, John Guiver, Gabriella Kazai, Pushmeet Kohli, and Milad Shokouhi. 2014. Community-based Bayesian Aggregation Models for Crowdsourcing. In WWW.Google Scholar"",""Peter Welinder, Steve Branson, Pietro Perona, and Serge J Belongie. 2010. The multidimensional wisdom of crowds. In NeurIPS. 2424--2432.Google Scholar"",""Jacob Whitehill, Ting-fan Wu, Jacob Bergsma, Javier R Movellan, and Paul L Ruvolo. 2009. Whose vote should count more: Optimal integration of labels from labelers of unknown expertise. In NeurIPS. 2035--2043.Google Scholar"",""Yan Yan, Rómer Rosales, Glenn Fung, Ramanathan Subramanian, and Jennifer Dy. 2014. Learning from Multiple Annotators with Varying Expertise. Mach. Learn., Vol. 95, 3 (June 2014), 291--327.Google ScholarDigital Library"",""Jing Zhang, Xindong Wu, and Victor S. Sheng. 2016b. Learning from crowdsourced labeled data: a survey. Artificial Intelligence Review, Vol. 46 (2016), 543--576.Google ScholarDigital Library"",""Yuchen Zhang, Xi Chen, Dengyong Zhou, and Michael I. Jordan. 2016a. Spectral Methods Meet EM: A Provably Optimal Algorithm for Crowdsourcing. JMLR, Vol. 17, 1 (Jan. 2016), 3537--3580.Google Scholar"",""Bo Zhao, Benjamin I. P. Rubinstein, Jim Gemmell, and Jiawei Han. 2012. A Bayesian Approach to Discovering Truth from Conflicting Sources for Data Integration. VLDB Endowment, Vol. 5, 6 (Feb. 2012), 550--561.Google Scholar"",""Yudian Zheng, Guoliang Li, Yuanbing Li, Caihua Shan, and Reynold Cheng. 2017. Truth Inference in Crowdsourcing: Is the Problem Solved? VLDB (2017).Google Scholar"",""Dengyong Zhou, Sumit Basu, Yi Mao, and John C. Platt. 2012. Learning from the Wisdom of Crowds by Minimax Entropy. In NeurIPS. 2195--2203.Google Scholar""]"
https://doi.org/10.1145/3394486.3403305,Embedding-based Retrieval in Facebook Search,"Search in social networks such as Facebook poses different challenges than in classical web search: besides the query text, it is important to take into account the searcher's context to provide relevant results. Their social graph is an integral part of this context and is a unique aspect of Facebook search. While embedding-based retrieval (EBR) has been applied in web search engines for years, Facebook search was still mainly based on a Boolean matching model. In this paper, we discuss the techniques for applying EBR to a Facebook Search system. We introduce the unified embedding framework developed to model semantic embeddings for personalized search, and the system to serve embedding-based retrieval in a typical search system based on an inverted index. We discuss various tricks and experiences on end-to-end optimization of the whole system, including ANN parameter tuning and full-stack optimization. Finally, we present our progress on two selected advanced topics about modeling. We evaluated EBR on verticals for Facebook Search with significant metrics gains observed in online A/B experiments. We believe this paper will provide useful insights and experiences to help people on developing embedding-based retrieval systems in search engines.","[{""name"":""Jui-Ting Huang"",""id"":""/profile/99659573996""},{""name"":""Ashish Sharma"",""id"":""/profile/99659574210""},{""name"":""Shuying Sun"",""id"":""/profile/99659574026""},{""name"":""Li Xia"",""id"":""/profile/99659574825""},{""name"":""David Zhang"",""id"":""/profile/99659574321""},{""name"":""Philip Pronin"",""id"":""/profile/83358710657""},{""name"":""Janani Padmanabhan"",""id"":""/profile/99659575144""},{""name"":""Giuseppe Ottaviano"",""id"":""/profile/81472654186""},{""name"":""Linjun Yang"",""id"":""/profile/81335499805""},{""name"":""Jui-Ting Huang"",""id"":""/profile/99659573996""},{""name"":""Ashish Sharma"",""id"":""/profile/99659574210""},{""name"":""Shuying Sun"",""id"":""/profile/99659574026""},{""name"":""Li Xia"",""id"":""/profile/99659574825""},{""name"":""David Zhang"",""id"":""/profile/99659574321""},{""name"":""Philip Pronin"",""id"":""/profile/83358710657""},{""name"":""Janani Padmanabhan"",""id"":""/profile/99659575144""},{""name"":""Giuseppe Ottaviano"",""id"":""/profile/81472654186""},{""name"":""Linjun Yang"",""id"":""/profile/81335499805""}]","[""Ricardo Baeza-Yates and Berthier Ribeiro-Neto. 2011. Modern Information Retrieval: The Concepts and Technology behind Search 2nd ed.). Addison-Wesley Publishing Company, USA.Google Scholar"",""Y. Bengio, A. Courville, and P. Vincent. 2013. Representation Learning: A Review and New Perspectives. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 35, 8 (Aug 2013), 1798--1828.Google ScholarDigital Library"",""Michael Curtiss, Iain Becker, Tudor Bosman, Sergey Doroshenko, Lucian Grijincu, Tom Jackson, Sandhya Kunnatur, Soren Lassen, Philip Pronin, Sriram Sankar, Guanghao Shen, Gintaras Woss, Chao Yang, and Ning Zhang. 2013. Unicorn: a system for searching the social graph. Proceedings of the VLDB Endowment, Vol. 6, 11, 1150--1161.Google ScholarDigital Library"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. CoRR, Vol. abs/1810.04805 (2018). arxiv: 1810.04805 http://arxiv.org/abs/1810.04805Google Scholar"",""Tiezheng Ge, Kaiming He, Qifa Ke, and Jian Sun. 2013. Optimized Product Quantization for Approximate Nearest Neighbor Search. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR).Google Scholar"",""Alexander Hermans, Lucas Beyer, and Bastian Leibe. 2017. In Defense of the Triplet Loss for Person Re-Identification. CoRR, Vol. abs/1703.07737 (2017). arxiv: 1703.07737 http://arxiv.org/abs/1703.07737Google Scholar"",""Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero, and Larry Heck. 2013. Learning Deep Structured Semantic Models for Web Search Using Clickthrough Data. In Proceedings of the 22nd ACM International Conference on Information and Knowledge Management (CIKM '13). Association for Computing Machinery, New York, NY, USA, 2333--2338.Google ScholarDigital Library"",""Herve Jegou, Matthijs Douze, and Cordelia Schmid. 2011. Product Quantization for Nearest Neighbor Search. IEEE Trans. Pattern Anal. Mach. Intell., Vol. 33, 1 (Jan. 2011), 117--128.Google ScholarDigital Library"",""Jeff Johnson, Matthijs Douze, and Hervé Jégou. 2017. Billion-scale similarity search with GPUs. arXiv preprint arXiv:1702.08734 (2017).Google Scholar"",""Yann LeCun, Yoshua Bengio, and Geoffrey E. Hinton. 2015. Deep learning. Nature, Vol. 521, 7553 (2015), 436--444.Google Scholar"",""Victor Lempitsky. 2012. The Inverted Multi-Index. In Proceedings of the 2012 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (CVPR '12). IEEE Computer Society, USA, 3069--3076.Google ScholarDigital Library"",""Hang Li and Jun Xu. 2014. Semantic Matching in Search. Now Publishers Inc., Hanover, MA, USA.Google Scholar"",""Bhaskar Mitra and Nick Craswell. 2018. An Introduction to Neural Information Retrieval. Foundations and Trends® in Information Retrieval, Vol. 13, 1 (December 2018), 1--126.Google ScholarCross Ref"",""Florian Schroff, Dmitry Kalenichenko, and James Philbin. 2015. FaceNet: A unified embedding for face recognition and clustering.. In CVPR. IEEE Computer Society, 815--823. http://dblp.uni-trier.de/db/conf/cvpr/cvpr2015.html#SchroffKP15Google Scholar"",""Josef Sivic and Andrew Zisserman. 2003. Video Google: A Text Retrieval Approach to Object Matching in Videos. In Proceedings of the Ninth IEEE International Conference on Computer Vision - Volume 2 (ICCV '03). IEEE Computer Society, USA, 1470.Google ScholarDigital Library"",""Hyun Oh Song, Yu Xiang, Stefanie Jegelka, and Silvio Savarese. 2015. Deep Metric Learning via Lifted Structured Feature Embedding. CoRR, Vol. abs/1511.06452 (2015). arxiv: 1511.06452 http://arxiv.org/abs/1511.06452Google Scholar"",""Chao-Yuan Wu, R. Manmatha, Alexander J. Smola, and Philipp Krähenbü hl. 2017. Sampling Matters in Deep Embedding Learning. CoRR, Vol. abs/1706.07567 (2017). arxiv: 1706.07567 http://arxiv.org/abs/1706.07567Google Scholar"",""Yuhui Yuan, Kuiyuan Yang, and Chao Zhang. 2017. Hard-Aware Deeply Cascaded Embedding. In The IEEE International Conference on Computer Vision (ICCV).Google Scholar""]"
https://doi.org/10.1145/3394486.3403306,Lumos: A Library for Diagnosing Metric Regressions in Web-Scale Applications,"Web-scale applications can ship code on a daily to weekly cadence. These applications rely on online metrics to monitor the health of new releases. Regressions in metric values need to be detected and diagnosed as early as possible to reduce the disruption to users and product owners. Regressions in metrics can surface due to a variety of reasons: genuine product regressions, changes in user population and bias due to telemetry loss (or processing) are among the common causes. Diagnosing the cause of these metric regressions is costly for engineering teams as they need to invest time in finding the root cause of the issue as soon as possible. We presentLumos, a Python library built using the principles of A/B testing to systematically diagnose metric regressions to automate such analysis.Lumos has been deployed across the component teams in Microsoft's Real-Time Communication (RTC) applications Skype and Microsoft Teams. It has enabled engineering teams to detect 100s of real changes in metrics and reject 1000s of false alarms detected by anomaly detectors. The application ofLumos has resulted in freeing up as much as $95%$ of the time allocated to metric-based investigations. In this work, we open sourceLumos and present our results from applying it to two different components within the RTC group over millions of sessions. This general library can be coupled with any production system to manage the volume of alerting efficiently.","[{""name"":""Jamie Pool"",""id"":""/profile/99659573072""},{""name"":""Ebrahim Beyrami"",""id"":""/profile/99659572939""},{""name"":""Vishak Gopal"",""id"":""/profile/99659575135""},{""name"":""Ashkan Aazami"",""id"":""/profile/99659574409""},{""name"":""Jayant Gupchup"",""id"":""/profile/81413606673""},{""name"":""Jeff Rowland"",""id"":""/profile/99659573696""},{""name"":""Binlong Li"",""id"":""/profile/99659573659""},{""name"":""Pritesh Kanani"",""id"":""/profile/99659574148""},{""name"":""Ross Cutler"",""id"":""/profile/99659316868""},{""name"":""Johannes Gehrke"",""id"":""/profile/81452607023""},{""name"":""Jamie Pool"",""id"":""/profile/99659573072""},{""name"":""Ebrahim Beyrami"",""id"":""/profile/99659572939""},{""name"":""Vishak Gopal"",""id"":""/profile/99659575135""},{""name"":""Ashkan Aazami"",""id"":""/profile/99659574409""},{""name"":""Jayant Gupchup"",""id"":""/profile/81413606673""},{""name"":""Jeff Rowland"",""id"":""/profile/99659573696""},{""name"":""Binlong Li"",""id"":""/profile/99659573659""},{""name"":""Pritesh Kanani"",""id"":""/profile/99659574148""},{""name"":""Ross Cutler"",""id"":""/profile/99659316868""},{""name"":""Johannes Gehrke"",""id"":""/profile/81452607023""}]","[""Rakesh Agrawal, Tomasz Imieliński, and Arun Swami. 1993. Mining association rules between sets of items in large databases. In Proceedings of the 1993 ACM SIGMOD international conference on Management of data. 207--216.Google ScholarDigital Library"",""Peter C Austin. 2011. An introduction to propensity score methods for reducing the effects of confounding in observational studies. Multivariate behavioral research, Vol. 46, 3 (2011), 399--424.Google Scholar"",""William G Cochran and Donald B Rubin. 1973. Controlling bias in observational studies: A review. Sankhyā: The Indian Journal of Statistics, Series A (1973), 417--446.Google Scholar"",""Thomas Crook, Brian Frasca, Ron Kohavi, and Roger Longbotham. 2009. Seven pitfalls to avoid when running controlled experiments on the web. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 1105--1114.Google ScholarDigital Library"",""Rajeev H Dehejia and Sadek Wahba. 2002. Propensity score-matching methods for nonexperimental causal studies. Review of Economics and statistics, Vol. 84, 1 (2002), 151--161.Google Scholar"",""Alex Deng, Ulf Knoblich, and Jiannan Lu. 2018. Applying the Delta method in metric analytics: A practical guide with novel ideas. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 233--242.Google ScholarDigital Library"",""Alex Deng, Ya Xu, Ron Kohavi, and Toby Walker. 2013. Improving the sensitivity of online controlled experiments by utilizing pre-experiment data. In Proceedings of the sixth ACM international conference on Web search and data mining. ACM, 123--132.Google ScholarDigital Library"",""Paul D Ellis. 2010. The essential guide to effect sizes: Statistical power, meta-analysis, and the interpretation of research results. Cambridge University Press.Google Scholar"",""Thomas Elsken, Jan Hendrik Metzen, and Frank Hutter. 2019. Neural Architecture Search: A Survey. Journal of Machine Learning Research, Vol. 20, 55 (2019), 1--21.Google Scholar"",""Hongyu Guo, Herna L Viktor, and Eric Paquet. 2010. Identifying and preventing data leakage in multi-relational classification. In 2010 IEEE International Conference on Data Mining Workshops. IEEE, 458--465.Google ScholarDigital Library"",""Jayant Gupchup, Yasaman Hosseinkashi, Martin Ellis, Sam Johnson, and Ross Cutler. 2017. Analysis of problem tokens to rank factors impacting quality in VoIP applications. In 2017 Ninth International Conference on Quality of Multimedia Experience (QoMEX). IEEE, 1--6.Google ScholarCross Ref"",""Daniel E Ho, Kosuke Imai, Gary King, and Elizabeth A Stuart. 2007. Matching as nonparametric preprocessing for reducing model dependence in parametric causal inference. Political analysis, Vol. 15, 3 (2007), 199--236.Google Scholar"",""Guido W Imbens and Donald B Rubin. 2015. Causal inference in statistics, social, and biomedical sciences. Cambridge University Press.Google Scholar"",""Haifeng Jin, Qingquan Song, and Xia Hu. 2019. Auto-keras: An efficient neural architecture search system. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 1946--1956.Google ScholarDigital Library"",""Ron Kohavi, Alex Deng, Brian Frasca, Roger Longbotham, Toby Walker, and Ya Xu. 2012. Trustworthy online controlled experiments: Five puzzling outcomes explained. In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 786--794.Google ScholarDigital Library"",""Ron Kohavi, Randal M Henne, and Dan Sommerfield. 2007. Practical guide to controlled experiments on the web: listen to your customers not to the hippo. In Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 959--967.Google ScholarDigital Library"",""Minyong R Lee and Milan Shen. 2018. Winner's Curse: Bias Estimation for Total Effects of Features in Online Controlled Experiments. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 491--499.Google ScholarDigital Library"",""Qingwei Lin, Jian-Guang Lou, Hongyu Zhang, and Dongmei Zhang. 2016. iDice: problem identification for emerging issues. In 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE). IEEE, 214--224.Google ScholarDigital Library"",""LinkedIn. 2018. Luminol. https://github.com/linkedin/luminolGoogle Scholar"",""Scott M. Lundberg, Gabriel Erion, Hugh Chen, Alex DeGrave, Jordan M. Prutkin, Bala Nair, Ronit Katz, Jonathan Himmelfarb, Nisha Bansal, and Su-In Lee. 2020. From local explanations to global understanding with explainable AI for trees. Nature Machine Intelligence, Vol. 2, 1 (2020), 2522--5839.Google ScholarCross Ref"",""Scott M Lundberg and Su-In Lee. 2017. A Unified Approach to Interpreting Model Predictions. In Advances in Neural Information Processing Systems 30, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.). Curran Associates, Inc., 4765--4774. http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdfGoogle Scholar"",""Microsoft. 2020. Lumos. https://github.com/microsoft/MS-LumosGoogle Scholar"",""Randal S Olson, Nathan Bartley, Ryan J Urbanowicz, and Jason H Moore. 2016. Evaluation of a tree-based pipeline optimization tool for automating data science. In Proceedings of the Genetic and Evolutionary Computation Conference 2016. ACM, 485--492.Google ScholarDigital Library"",""Wei Pan and Haiyan Bai. 2015. Propensity score analysis: Fundamentals and developments. Guilford Publications.Google Scholar"",""Paul Raff and Ze Jin. 2016. The difference-of-datasets framework: A statistical method to discover insight. In 2016 IEEE International Conference on Big Data (Big Data). IEEE, 1824--1831.Google ScholarCross Ref"",""Hansheng Ren, Bixiong Xu, Yujing Wang, Chao Yi, Congrui Huang, Xiaoyu Kou, Tony Xing, Mao Yang, Jie Tong, and Qi Zhang. 2019. Time-Series Anomaly Detection Service at Microsoft. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 3009--3017.Google ScholarDigital Library"",""Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. \""Why should i trust you?\"" Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. 1135--1144.Google ScholarDigital Library"",""Paul R Rosenbaum and Donald B Rubin. 1983. The central role of the propensity score in observational studies for causal effects. Biometrika, Vol. 70, 1 (1983), 41--55.Google ScholarCross Ref"",""Paul R Rosenbaum and Donald B Rubin. 1985. Constructing a control group using multivariate matched sampling methods that incorporate the propensity score. The American Statistician, Vol. 39, 1 (1985), 33--38.Google Scholar"",""Donald B Rubin. 1974. Estimating causal effects of treatments in randomized and nonrandomized studies. Journal of educational Psychology, Vol. 66, 5 (1974), 688.Google ScholarCross Ref"",""Ando Saabas. 2015. Tree Interpreter. https://github.com/andosa/treeinterpreterGoogle Scholar"",""Gabriele Tolomei, Fabrizio Silvestri, Andrew Haines, and Mounia Lalmas. 2017. Interpretable predictions of tree-based ensembles via actionable feature tweaking. In Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 465--474.Google ScholarDigital Library"",""Owen Vallis, Jordan Hochenbaum, and Arun Kejariwal. 2014. A novel technique for long-term anomaly detection in the cloud. In 6th {USENIX} Workshop on Hot Topics in Cloud Computing (HotCloud 14).Google Scholar"",""Geoffrey I Webb. 2000. Efficient search for association rules. In Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining. 99--107.Google ScholarDigital Library"",""Yuxiang Xie, Nanyu Chen, and Xiaolin Shi. 2018. False discovery rate controlled heterogeneous treatment effect detection for online controlled experiments. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 876--885.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403307,Order Fulfillment Cycle Time Estimation for On-Demand Food Delivery,"By providing customers with conveniences such as easy access to an extensive variety of restaurants, effortless food ordering and fast delivery, on-demand food delivery (OFD) platforms have achieved explosive growth in recent years. A crucial machine learning task performed at OFD platforms is prediction of the Order Fulfillment Cycle Time (OFCT), which refers to the amount of time elapsed between a customer places an order and he/she receives the meal. The accuracy of predicted OFCT is important for customer satisfaction, as it needs to be communicated to a customer before he/she places the order, and is considered as a service promise that should be fulfilled as well as possible. As a result, the estimated OFCT also heavily influences planning decisions such as dispatching and routing.In this paper, we present the OFCT prediction model that is currently deployed at Ele.me, which is one of the world's largest OFD platforms and delivers over 10 million meals in more than 200 Chinese cities every day. By dissecting the order fulfillment cycle of a meal order, we identify key factors behind OFCT, and capture them with numerous features constructed using a wide range of data sources. These features are fed into a deep neural network (DNN), which further incorporates representations of couriers, restaurants and delivery destinations to enhance prediction efficacy. Finally, a novel post-processing layer is introduced to improve convergence speed by better accounting for the distributional mismatch between the true OFCT values and those predicted by the model at initialization. Extensive offline and online experiments demonstrate the effectiveness of our approach.","[{""name"":""Lin Zhu"",""id"":""/profile/99659574756""},{""name"":""Wei Yu"",""id"":""/profile/99659574935""},{""name"":""Kairong Zhou"",""id"":""/profile/99659573189""},{""name"":""Xing Wang"",""id"":""/profile/99659574983""},{""name"":""Wenxing Feng"",""id"":""/profile/99659573401""},{""name"":""Pengyu Wang"",""id"":""/profile/99659573708""},{""name"":""Ning Chen"",""id"":""/profile/99659463252""},{""name"":""Pei Lee"",""id"":""/profile/99659573417""},{""name"":""Lin Zhu"",""id"":""/profile/99659574756""},{""name"":""Wei Yu"",""id"":""/profile/99659574935""},{""name"":""Kairong Zhou"",""id"":""/profile/99659573189""},{""name"":""Xing Wang"",""id"":""/profile/99659574983""},{""name"":""Wenxing Feng"",""id"":""/profile/99659573401""},{""name"":""Pengyu Wang"",""id"":""/profile/99659573708""},{""name"":""Ning Chen"",""id"":""/profile/99659463252""},{""name"":""Pei Lee"",""id"":""/profile/99659573417""}]","[""Roberto Baldacci, Aristide Mingozzi, and Roberto Roberti. 2012. Recent exact algorithms for solving the vehicle routing problem under capacity and time window constraints. European Journal of Operational Research, Vol. 218, 1 (2012), 1 -- 6.Google Scholar"",""James S Bergstra, Rémi Bardenet, Yoshua Bengio, and Balázs Kégl. 2011. Algorithms for hyper-parameter optimization. In NIPS. 2546--2554.Google Scholar"",""Djork-Arné Clevert, Thomas Unterthiner, and Sepp Hochreiter. 2016. Fast and accurate deep network learning by exponential linear units (elus). In ICLR.Google Scholar"",""Daxue Consulting. 2019. The food delivery market in Great China in 2019. https://daxueconsulting.com/o2o-food-delivery-market-in-china/ Retrieved September 1, 2019 fromGoogle Scholar"",""Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep neural networks for youtube recommendations. In RecSys. 191--198.Google Scholar"",""Teodor Gabriel Crainic, Nicoletta Ricciardi, and Giovanni Storchi. 2009. Models for evaluating and planning city logistics systems. Transportation Science, Vol. 43, 4 (2009), 432--454.Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In NAACL. 4171--4186.Google Scholar"",""Uber Eats. 2019. Uber Announces Results for Third Quarter 2019. https://investor.uber.com/news-events/news/press-release-details/2019/Uber-Announces-Results-for-Third-Quarter-2019/ Retrieved December 20, 2019 fromGoogle Scholar"",""Xavier Glorot and Yoshua Bengio. 2010. Understanding the difficulty of training deep feedforward neural networks. In AISTATS. 249--256.Google Scholar"",""Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: a factorization-machine based neural network for CTR prediction. In IJCAI. 1725--1731.Google Scholar"",""Malay Haldar, Mustafa Abdool, Prashant Ramanathan, Tao Xu, Shulin Yang, Huizhong Duan, Qing Zhang, Nick Barrow-Williams, Bradley C Turnbull, Brendan M Collins, et almbox. 2019. Applying deep learning to Airbnb search. In SIGKDD. 1927--1935.Google Scholar"",""Yixiao Huang, Lei Zhao, Warren B Powell, Yue Tong, and Ilya O Ryzhov. 2019. Optimal Learning for Urban Delivery Fleet Allocation. Transportation Science, Vol. 53, 3 (2019), 623--641.Google Scholar"",""Herve Jegou, Matthijs Douze, and Cordelia Schmid. 2010. Product quantization for nearest neighbor search. TPAMI, Vol. 33, 1 (2010), 117--128.Google Scholar"",""J. Johnson, M. Douze, and H. J??gou. 2020. Billion-scale similarity search with GPUs. IEEE Transactions on Big Data (2020), in press.Google Scholar"",""Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. 2017. Lightgbm: A highly efficient gradient boosting decision tree. In NIPS. 3146--3154.Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Wang-Chien Lee, Weiping Si, Ling-Jyh Chen, and Meng Chang Chen. 2012. HTTP: a new framework for bus travel time prediction based on historical trajectories. In SIGSPATIAL. 279--288.Google Scholar"",""Xiucheng Li, Gao Cong, Aixin Sun, and Yun Cheng. 2019. Learning Travel Time Distributions with Deep Generative Model. In WWW. 1017--1027.Google Scholar"",""Yaguang Li, Kun Fu, Zheng Wang, Cyrus Shahabi, Jieping Ye, and Yan Liu. 2018. Multi-task representation learning for travel time estimation. In SIGKDD. 1695--1704.Google Scholar"",""Jianxun Lian, Xiaohuan Zhou, Fuzheng Zhang, Zhongxia Chen, Xing Xie, and Guangzhong Sun. 2018. xdeepfm: Combining explicit and implicit feature interactions for recommender systems. In SIGKDD. 1754--1763.Google Scholar"",""Vitória Pureza and Gilbert Laporte. 2008. Waiting and buffering strategies for the dynamic pickup and delivery problem with time windows. INFOR, Vol. 46, 3 (2008), 165--175.Google Scholar"",""Raghav Ramesh. 2018. How DoorDash leverages AI in its world-class on-demand logistics engine. https://conferences.oreilly.com/artificial-intelligence/ai-ny-2018/public/schedule/detail/65038/ Retrieved December 15, 2019 fromGoogle Scholar"",""Matteo Salani and Maria Battarra. 2018. The opportunity cost of time window violations. EURO Journal on Transportation and Logistics, Vol. 7, 4 (2018), 343--361.Google Scholar"",""Remy Spliet and Adriana F. Gabor. 2015. The Time Window Assignment Vehicle Routing Problem. Transportation Science, Vol. 49, 4 (2015), 721--731.Google Scholar"",""Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: a simple way to prevent neural networks from overfitting. JMLR, Vol. 15, 1 (2014), 1929--1958.Google Scholar"",""Anirudh Subramanyam, Akang Wang, and Chrysanthos E Gounaris. 2018. A scenario decomposition algorithm for strategic time window assignment vehicle routing problems. Transportation Research Part B: Methodological, Vol. 117 (2018), 296--317.Google Scholar"",""Yongxin Tong, Yuxiang Zeng, Zimu Zhou, Lei Chen, Jieping Ye, and Ke Xu. 2018. A unified approach to route planning for shared mobility. VLDB, Vol. 11, 11 (2018), 1633--1646.Google Scholar"",""Marlin W. Ulmer and Barrett W. Thomas. 2019. Enough Waiting for the Cable Guy--Estimating Arrival Times for Service Vehicle Routing. Transportation Science, Vol. 53, 3 (2019), 897--916.Google Scholar"",""Anastasios D Vareias, Panagiotis P Repoussis, and Christos D Tarantilis. 2017. Assessing customer service reliability in route planning with self-imposed time windows and stochastic travel times. Transportation Science, Vol. 53, 1 (2017), 256--281.Google Scholar"",""Thibaut Vidal, Gilbert Laporte, and Piotr Matl. 2020. A concise guide to existing and emerging vehicle routing problem variants. European Journal of Operational Research, Vol. 286, 2 (2020), 401--416.Google Scholar"",""Hongjian Wang, Xianfeng Tang, Yu-Hsuan Kuo, Daniel Kifer, and Zhenhui Li. 2019. A simple baseline for travel time estimation using large-scale trip data. ACM Transactions on Intelligent Systems and Technology, Vol. 10, 2 (2019), 19.Google Scholar"",""Zi Wang. 2019. Time Predictions in Uber Eats. https://www.infoq.com/articles/uber-eats-time-predictions/ Retrieved December 15, 2019 fromGoogle Scholar"",""Zheng Wang, Kun Fu, and Jieping Ye. 2018. Learning to estimate the travel time. In SIGKDD. 858--866.Google Scholar"",""Zheng Yang, Chenshu Wu, and Yunhao Liu. 2012. Locating in Fingerprint Space: Wireless Indoor Localization with Little Human Intervention. In MobiCom. 269--280.Google Scholar"",""Huaxiu Yao, Fei Wu, Jintao Ke, Xianfeng Tang, Yitian Jia, Siyu Lu, Pinghua Gong, Jieping Ye, and Zhenhui Li. 2018. Deep multi-view spatial-temporal network for taxi demand prediction. In AAAI.Google Scholar"",""Hamed Zamani, Mostafa Dehghani, W. Bruce Croft, Erik Learned-Miller, and Jaap Kamps. 2018. From Neural Re-Ranking to Neural Ranking: Learning a Sparse Representation for Inverted Indexing. In CIKM. 497--506.Google Scholar"",""Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep Interest Network for Click-Through Rate Prediction. In SIGKDD. 1059--1068.Google Scholar"",""Lin Zhu, Yihong Chen, and Bowen He. 2019. A Domain Generalization Perspective on Listwise Context Modeling. In AAAI. 5965--5972.Google Scholar""]"
https://doi.org/10.1145/3394486.3403308,Calendar Graph Neural Networks for Modeling Time Structures in Spatiotemporal User Behaviors,"User behavior modeling is important for industrial applications such as demographic attribute prediction, content recommendation, and target advertising. Existing methods represent behavior log as a sequence of adopted items and find sequential patterns; however, concrete location and time information in the behavior log, reflecting dynamic and periodic patterns, joint with the spatial dimension, can be useful for modeling users and predicting their characteristics. In this work, we propose a novel model based on graph neural networks for learning user representations from spatiotemporal behavior data. Our model's architecture incorporates two networked structures. One is a tripartite network of items, sessions, and locations. The other is a hierarchical calendar network of hour, week, and weekday nodes. It first aggregates embeddings of location and items into session embeddings via the tripartite network, and then generates user embeddings from the session embeddings via the calendar structure. The user embeddings preserve spatial patterns and temporal patterns of a variety of periodicity (e.g., hourly, weekly, and weekday patterns). It adopts the attention mechanism to model complex interactions among the multiple patterns in user behaviors. Experiments on real datasets (i.e., clicks on news articles in a mobile app) show our approach outperforms strong baselines for predicting missing demographic attributes.","[{""name"":""Daheng Wang"",""id"":""/profile/99659287671""},{""name"":""Meng Jiang"",""id"":""/profile/81472650328""},{""name"":""Munira Syed"",""id"":""/profile/99659351326""},{""name"":""Oliver Conway"",""id"":""/profile/99659574528""},{""name"":""Vishal Juneja"",""id"":""/profile/99659573807""},{""name"":""Sriram Subramanian"",""id"":""/profile/99659575201""},{""name"":""Nitesh V. Chawla"",""id"":""/profile/81100002770""},{""name"":""Daheng Wang"",""id"":""/profile/99659287671""},{""name"":""Meng Jiang"",""id"":""/profile/81472650328""},{""name"":""Munira Syed"",""id"":""/profile/99659351326""},{""name"":""Oliver Conway"",""id"":""/profile/99659574528""},{""name"":""Vishal Juneja"",""id"":""/profile/99659573807""},{""name"":""Sriram Subramanian"",""id"":""/profile/99659575201""},{""name"":""Nitesh V. Chawla"",""id"":""/profile/81100002770""}]","[""Mohamed Aly, Andrew Hatch, Vanja Josifovski, and Vijay K Narayanan. 2012. Web-scale user modeling for targeting. In WWW. 3--12.Google Scholar"",""Ludovico Boratto, Salvatore Carta, Gianni Fenu, and Roberto Saia. 2016. Using neural word embeddings to model user behavior and detect user segments. Knowledge-based systems, Vol. 108 (2016), 5--14.Google Scholar"",""Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. 2013. Spectral networks and locally connected networks on graphs. arXiv:1312.6203 (2013).Google Scholar"",""Kyunghyun Cho, Bart Van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078 (2014).Google Scholar"",""Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016.Convolutional neural networks on graphs with fast localized spectral filtering. In NeurIPS. 3844--3852.Google Scholar"",""David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Alán Aspuru-Guzik, and Ryan P Adams. 2015. Convolutional networks on graphs for learning molecular fingerprints. In NeurIPS. 2224--2232.Google Scholar"",""Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. 2017. Neural message passing for quantum chemistry. In ICML. 1263--1272.Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In NeurIPS. 1024--1034.Google Scholar"",""Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In Proceedings of the 26th international conference on world wide web. 173--182.Google ScholarDigital Library"",""Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2015. Session-based recommendations with recurrent neural networks. arXiv:1511.06939 (2015).Google Scholar"",""Balázs Hidasi, Massimo Quadrana, Alexandros Karatzoglou, and Domonkos Tikk. 2016. Parallel recurrent neural network architectures for feature-rich session-based recommendations. In RecSys. 241--248.Google Scholar"",""Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural computation, Vol. 9, 8 (1997), 1735--1780.Google Scholar"",""Dietmar Jannach and Malte Ludewig. 2017. When recurrent neural networks meet the neighborhood for session-based recommendation. In RecSys. 306--310.Google Scholar"",""Meng Jiang, Peng Cui, Fei Wang, Xinran Xu, Wenwu Zhu, and Shiqiang Yang. 2014. Fema: flexible evolutionary multi-faceted analysis for dynamic behavioral pattern discovery. In KDD. 1186--1195.Google Scholar"",""Meng Jiang, Christos Faloutsos, and Jiawei Han. 2016. Catchtartan: Representing and summarizing dynamic multicontextual behaviors. In Proceedings of the 22nd ACM SIGKDD. 945--954.Google ScholarDigital Library"",""Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv:1609.02907 (2016).Google Scholar"",""Junhyun Lee, Inyeop Lee, and Jaewoo Kang. 2019. Self-Attention Graph Pooling. arXiv:1904.08082 (2019).Google Scholar"",""Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, and Jun Ma. 2017a. Neural attentive session-based recommendation. In CIKM. 1419--1428.Google Scholar"",""Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. 2017b. Diffusion convolutional recurrent neural network: Data-driven traffic forecasting. arXiv:1707.01926 (2017).Google Scholar"",""Dehong Ma, Sujian Li, Xiaodong Zhang, and Houfeng Wang. 2017. Interactive attention networks for aspect-level sentiment classification. In IJCAI. 4068--4074.Google Scholar"",""Laurens van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE. Journal of machine learning research, Vol. 9, Nov (2008), 2579--2605.Google Scholar"",""Franco Manessi, Alessandro Rozza, and Mario Manzo. 2017. Dynamic graph convolutional networks. arXiv:1704.06199 (2017).Google Scholar"",""Vinod Nair and Geoffrey E Hinton. 2010. Rectified linear units improve restricted boltzmann machines. In ICML. 807--814.Google Scholar"",""Mathias Niepert, Mohamed Ahmed, and Konstantin Kutzkov. 2016. Learning convolutional neural networks for graphs. In ICML. 2014--2023.Google Scholar"",""Mike Schuster and Kuldip K Paliwal. 1997. Bidirectional recurrent neural networks. IEEE Transactions on Signal Processing, Vol. 45, 11 (1997), 2673--2681.Google ScholarDigital Library"",""Youngjoo Seo, Michaël Defferrard, Pierre Vandergheynst, and Xavier Bresson. 2018. Structured sequence modeling with graph convolutional recurrent networks. In ICNIP. 362--373.Google Scholar"",""Martin Simonovsky and Nikos Komodakis. 2017. Dynamic edge-conditioned filters in convolutional neural networks on graphs. In CVPR. 3693--3702.Google Scholar"",""Yong Kiam Tan, Xinxing Xu, and Yong Liu. 2016. Improved recurrent neural networks for session-based recommendations. In Workshop on DLRS. 17--22.Google ScholarDigital Library"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph attention networks. arXiv:1710.10903 (2017).Google Scholar"",""Daheng Wang, Meng Jiang, Qingkai Zeng, Zachary Eberhart, and Nitesh V Chawla. 2018. Multi-type itemset embedding for learning behavior success. In KDD. ACM, 2397--2406.Google Scholar"",""Daheng Wang, Tianwen Jiang, Nitesh V Chawla, and Meng Jiang. 2019. TUBE: Embedding Behavior Outcomes for Predicting Success. In Proceedings of the 25th ACM SIGKDD. 1682--1690.Google ScholarDigital Library"",""Boris Weisfeiler and Andrei A Lehman. 1968. A reduction of a graph to a canonical form and an algebra arising during this reduction. Nauchno-Technicheskaya Informatsia, Vol. 2, 9 (1968), 12--16.Google Scholar"",""Chen Wu and Ming Yan. 2017. Session-aware information embedding for e-commerce product recommendation. In CIKM. 2379--2382.Google Scholar"",""Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, and Tieniu Tan. 2019. Session-based recommendation with graph neural networks. In AAAI, Vol. 33. 346--353.Google ScholarCross Ref"",""Xian Wu, Baoxu Shi, Yuxiao Dong, Chao Huang, Louis Faust, and Nitesh V Chawla. 2018. Restful: Resolution-aware forecasting of behavioral time series data. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management. 1073--1082.Google ScholarDigital Library"",""Zhang Xinyi and Lihui Chen. 2019. Capsule graph neural network. In ICLR.Google Scholar"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. 2018a. Graph convolutional neural networks for web-scale recommender systems. In KDD. 974--983.Google Scholar"",""Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, and Jure Leskovec. 2018b. Hierarchical graph representation learning with differentiable pooling. In NeurIPS. 4800--4810.Google Scholar"",""Bing Yu, Haoteng Yin, and Zhanxing Zhu. 2017. Spatio-temporal graph convolutional networks: A deep learning framework for traffic forecasting. arXiv:1709.04875 (2017).Google Scholar"",""Wenhao Yu, Mengxia Yu, Tong Zhao, and Meng Jiang. 2020. Identifying referential intention with heterogeneous contexts. In Proceedings of The Web Conference 2020. 962--972.Google Scholar"",""Muhan Zhang and Yixin Chen. 2018. Link prediction based on graph neural networks. In NeurIPS. 5165--5175.Google Scholar"",""Muhan Zhang, Zhicheng Cui, Marion Neumann, and Yixin Chen. 2018. An end-to-end deep learning architecture for graph classification. In AAAI.Google Scholar""]"
https://doi.org/10.1145/3394486.3403309,Privileged Features Distillation at Taobao Recommendations,"Features play an important role in the prediction tasks of e-commerce recommendations. To guarantee the consistency of off-line training and on-line serving, we usually utilize the same features that are both available. However, the consistency in turn neglects some discriminative features. For example, when estimating the conversion rate (CVR), i.e., the probability that a user would purchase the item if she clicked it, features like dwell time on the item detailed page are informative. However, CVR prediction should be conducted for on-line ranking before the click happens. Thus we cannot get such post-event features during serving.We define the features that are discriminative but only available during training as the privileged features. Inspired by the distillation techniques which bridge the gap between training and inference, in this work, we propose privileged features distillation (PFD). We train two models, i.e., a student model that is the same as the original one and a teacher model that additionally utilizes the privileged features. Knowledge distilled from the more accurate teacher is transferred to the student, which helps to improve its prediction accuracy. During serving, only the student part is extracted and it relies on no privileged features. We conduct experiments on two fundamental prediction tasks at Taobao recommendations, i.e., click-through rate (CTR) at coarse-grained ranking and CVR at fine-grained ranking. By distilling the interacted features that are prohibited during serving for CTR and the post-event features for CVR, we achieve significant improvements over their strong baselines. During the on-line A/B tests, the click metric is improved by +5.0% in the CTR task. And the conversion metric is improved by +2.3% in the CVR task. Besides, by addressing several issues of training PFD, we obtain comparable training speed as the baselines without any distillation.","[{""name"":""Chen Xu"",""id"":""/profile/99659573762""},{""name"":""Quan Li"",""id"":""/profile/99659574318""},{""name"":""Junfeng Ge"",""id"":""/profile/99659462640""},{""name"":""Jinyang Gao"",""id"":""/profile/81758690557""},{""name"":""Xiaoyong Yang"",""id"":""/profile/99659575163""},{""name"":""Changhua Pei"",""id"":""/profile/99659316038""},{""name"":""Fei Sun"",""id"":""/profile/81487642392""},{""name"":""Jian Wu"",""id"":""/profile/99659463051""},{""name"":""Hanxiao Sun"",""id"":""/profile/99659317092""},{""name"":""Wenwu Ou"",""id"":""/profile/99659154653""},{""name"":""Chen Xu"",""id"":""/profile/99659573762""},{""name"":""Quan Li"",""id"":""/profile/99659574318""},{""name"":""Junfeng Ge"",""id"":""/profile/99659462640""},{""name"":""Jinyang Gao"",""id"":""/profile/81758690557""},{""name"":""Xiaoyong Yang"",""id"":""/profile/99659575163""},{""name"":""Changhua Pei"",""id"":""/profile/99659316038""},{""name"":""Fei Sun"",""id"":""/profile/81487642392""},{""name"":""Jian Wu"",""id"":""/profile/99659463051""},{""name"":""Hanxiao Sun"",""id"":""/profile/99659317092""},{""name"":""Wenwu Ou"",""id"":""/profile/99659154653""}]","[""Rohan Anil, Gabriel Pereyra, Alexandre Passos, Robert Ormandi, George E Dahl, and Geoffrey E Hinton. 2018. Large scale distributed neural network training through online distillation. In ICLR.Google Scholar"",""Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. 2016. Layer normalization. arXiv:1607.06450 (2016).Google Scholar"",""Cristian Bucilu?, Rich Caruana, and Alexandru Niculescu-Mizil. 2006. Model compression. In SIGKDD. ACM, 535--541.Google Scholar"",""Xu Chen, Yongfeng Zhang, Hongteng Xu, Zheng Qin, and Hongyuan Zha. 2018. Adversarial distillation for efficient recommendation with external knowledge. ACM Transactions on Information Systems, Vol. 37, 1 (2018), 1--28.Google ScholarDigital Library"",""Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et almbox. 2016. Wide \u0026 deep learning for recommender systems. In Proceedings of the 1st workshop on deep learning for recommender systems. ACM, NY, USA, 7--10.Google ScholarDigital Library"",""Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep neural networks for youtube recommendations. In RecSys. ACM, 191--198.Google Scholar"",""George Cybenko. 1989. Approximation by superpositions of a sigmoidal function. Mathematics of Control, Signals and Systems, Vol. 2, 4 (1989), 303--314.Google ScholarCross Ref"",""Jeffrey Dean, Greg Corrado, Rajat Monga, Kai Chen, Matthieu Devin, Mark Mao, Andrew Senior, Paul Tucker, Ke Yang, Quoc V Le, et almbox. 2012. Large scale distributed deep networks. In NeurIPS. 1223--1231.Google Scholar"",""Mukund Deshpande and George Karypis. 2004. Item-based top-n recommendation algorithms. ACM Transactions on Information Systems, Vol. 22, 1 (2004), 143--177.Google ScholarDigital Library"",""John Duchi, Elad Hazan, and Yoram Singer. 2011. Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research, Vol. 12, Jul (2011), 2121--2159.Google ScholarDigital Library"",""Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: A factorization-machine based neural network for CTR prediction. In AAAI. 1725--1731.Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In CVPR. 770--778.Google Scholar"",""Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2016. Session-based recommendations with recurrent neural networks. In ICLR.Google Scholar"",""Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015. Distilling the knowledge in a neural network. arXiv:1503.02531 (2015).Google Scholar"",""Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural Computation, Vol. 9, 8 (1997), 1735--1780.Google ScholarDigital Library"",""Kurt Hornik. 1991. Approximation capabilities of multilayer feedforward networks. Neural Networks, Vol. 4, 2 (1991), 251--257.Google ScholarDigital Library"",""Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero, and Larry Heck. 2013. Learning deep structured semantic models for web search using clickthrough data. In CIKM. ACM, 2333--2338.Google Scholar"",""Sergey Ioffe and Christian Szegedy. 2015. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In ICML. 448--456.Google Scholar"",""Wang-Cheng Kang and Julian McAuley. 2018 Self-attentive sequential recommendation. In ICDM. IEEE, 197--206.Google Scholar"",""Yoon Kim and Alexander M. Rush. 2016. Sequence-Level Knowledge Distillation. In EMNLP. 1317--1327.Google Scholar"",""John Lambert, Ozan Sener, and Silvio Savarese. 2018. Deep learning under privileged information using heteroscedastic dropout. In CVPR. 8886--8895.Google Scholar"",""Jianxun Lian, Xiaohuan Zhou, Fuzheng Zhang, Zhongxia Chen, Xing Xie, and Guangzhong Sun. 2018. xDeepFM: Combining explicit and implicit feature interactions for recommender systems. In SIGKDD. ACM, NY, USA, 1754--1763.Google Scholar"",""Henry W Lin, Max Tegmark, and David Rolnick. 2017. Why does deep and cheap learning work so well? Journal of Statistical Physics, Vol. 168, 6 (2017), 1223--1247.Google ScholarCross Ref"",""Shichen Liu, Fei Xiao, Wenwu Ou, and Luo Si. 2017. Cascade ranking for operational e-commerce search. In SIGKDD. ACM, 1557--1565.Google Scholar"",""David Lopez-Paz, Léon Bottou, Bernhard Schölkopf, and Vladimir Vapnik. 2016. Unifying distillation and privileged information. In ICLR.Google Scholar"",""Andrew L Maas, Awni Y Hannun, and Andrew Y Ng. 2013. Rectifier nonlinearities improve neural network acoustic models. In ICML, Vol. 30. 3.Google Scholar"",""H Brendan McMahan, Gary Holt, David Sculley, Michael Young, Dietmar Ebner, Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, et almbox. 2013. ftrl. In SIGKDD. 1222--1230.Google Scholar"",""Asit Mishra and Debbie Marr. 2018. Apprentice: Using knowledge distillation techniques to improve low-precision network accuracy. In ICLR.Google Scholar"",""Yabo Ni, Dan Ou, Shichen Liu, Xiang Li, Wenwu Ou, Anxiang Zeng, and Luo Si. 2018. Perceive your users in depth: Learning universal user representations from multiple e-commerce tasks. In SIGKDD. ACM, 596--605.Google Scholar"",""Gabriel Pereyra, George Tucker, Jan Chorowski, Łukasz Kaiser, and Geoffrey Hinton. 2017. Regularizing neural networks by penalizing confident output distributions. arXiv:1701.06548 (2017).Google Scholar"",""Adriana Romero, Nicolas Ballas, Samira Ebrahimi Kahou, Antoine Chassang, Carlo Gatta, and Yoshua Bengio. 2015. Fitnets: Hints for thin deep nets. In ICLR.Google Scholar"",""Sebastian Ruder. 2017. An overview of multi-task learning in deep neural networks. arXiv:1706.05098 (2017).Google Scholar"",""Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. 2016. Rethinking the inception architecture for computer vision. In CVPR. 2818--2826.Google Scholar"",""Jiaxi Tang and Ke Wang. 2018. Ranking distillation: Learning compact ranking models with high performance for recommender system. In SIGKDD. ACM, 2289--2298.Google Scholar"",""Vladimir Vapnik and Rauf Izmailov. 2015. Learning using privileged information: similarity control and knowledge transfer. Journal of Machine Learning Research, Vol. 16, 2023--2049 (2015), 2.Google ScholarDigital Library"",""Vladimir Vapnik and Akshay Vashist. 2009. A new learning paradigm: Learning using privileged information. Neural Networks, Vol. 22, 5--6 (2009), 544--557.Google ScholarDigital Library"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In NeurIPS. 5998--6008.Google Scholar"",""Xiaojie Wang, Rui Zhang, Yu Sun, and Jianzhong Qi. 2018. Kdgan: Knowledge distillation with generative adversarial networks. In NeurIPS. 775--786.Google Scholar"",""Ying Zhang, Tao Xiang, Timothy M Hospedales, and Huchuan Lu. 2018. Deep mutual learning. In CVPR. 4320--4328.Google Scholar"",""Guorui Zhou, Ying Fan, Runpeng Cui, Weijie Bian, Xiaoqiang Zhu, and Kun Gai. 2018a. Rocket launching: A universal and efficient framework for training well-performing light net. In AAAI.Google Scholar"",""Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018b. Deep interest network for click-through rate prediction. In SIGKDD. ACM, 1059--1068.Google Scholar""]"
https://doi.org/10.1145/3394486.3403310,Cracking Tabular Presentation Diversity for Automatic Cross-Checking over Numerical Facts,"Tabular forms of numerical facts widely exist in the disclosure documents of vertical domains, especially the financial fields. It is also quite common that the same fact might be mentioned multiple times in different tables with diverse tabular presentation. Firm's disclosure documents are the main source of accounting information for individual investors. Its authenticity is crucial for both firms' development and investors' investment decisions. However, due to large volumes of tables, frequent updates during editing, and limited time for manual cross-checking, these facts might be inconsistent with each other even after official publishing. Such errors may bring about huge reputational risk, and even economic losses even if the mistakes are made unintentionally instead of deliberately. Hence, it creates an opportunity for Automatic Numerical Cross-Checking over Tables. This paper introduces the key module of such a system, which aims to identify whether a pair of table cells are semantically equivalent, namely referring to the same fact. We observed that due to tabular presentation diversity the facts in tabular forms are difficult to be parsed into relational tuples. Thus, we present an end-to-end solution of binary classification over each pair of table cells, which does not involve with explicit semantic parsing over tables. Also, we discuss the design of this neural model to compromise between prediction accuracy and inference time for a large number of table cell pairs, and propose some practical techniques to address the issue of extreme classification imbalance among pairs. Experiments show that our model achieves macro F1 = 0.8297 in linking semantically equivalent table cells from the IPO prospectus. Finally, an auditing tool is built to support guided cross-checking over financial documents, reducing work hours by 52% ~ 68%. This system has received wide recognition in the Chinese financial community. Nine of the top ten Chinese security brokers have adopted this system to support their business of investment banking.","[{""name"":""Hongwei Li"",""id"":""/profile/99659259834""},{""name"":""Qingping Yang"",""id"":""/profile/99659574286""},{""name"":""Yixuan Cao"",""id"":""/profile/99659259648""},{""name"":""Jiaquan Yao"",""id"":""/profile/99659259467""},{""name"":""Ping Luo"",""id"":""/profile/81100416055""},{""name"":""Hongwei Li"",""id"":""/profile/99659259834""},{""name"":""Qingping Yang"",""id"":""/profile/99659574286""},{""name"":""Yixuan Cao"",""id"":""/profile/99659259648""},{""name"":""Jiaquan Yao"",""id"":""/profile/99659259467""},{""name"":""Ping Luo"",""id"":""/profile/81100416055""}]","[""Yixuan Cao, Hongwei Li, Ping Luo, and Jiaquan Yao. 2018. Towards Automatic Numerical Cross-Checking: Extracting Formulas from Text. In WWW.Google Scholar"",""Preeti Choudhary, Kenneth J Merkley, and Katherine Schipper. 2019. Do Immaterial Error Corrections Matter? Available at SSRN 2830676 (2019).Google Scholar"",""Jing Fang, Prasenjit Mitra, Zhi Tang, and C Lee Giles. 2012. Table header detection and classification. In AAAI.Google Scholar"",""Vivian W Fang, Allen H Huang, and Wenyu Wang. 2017. Imperfect accounting and reporting bias. Journal of Accounting Research (2017).Google Scholar"",""Naeemul Hassan, Fatma Arslan, Chengkai Li, and Mark Tremayne. 2017. Toward Automated Fact-Checking: Detecting Check-worthy Factual Claims by ClaimBuster. In KDD.Google Scholar"",""Dae Hyun Kim, Enamul Hoque, Juho Kim, and Maneesh Agrawala. 2018. Facilitating document reading by linking text and tables. In UIST.Google Scholar"",""Mio Kobayashi, Ai Ishii, Chikara Hoshino, Hiroshi Miyashita, and Takuya Matsuzaki. 2017. Automated Historical Fact-Checking by Passage Retrieval, Word Statistics, and Virtual Question-Answering. In IJCNLP.Google Scholar"",""Alastair Lawrence. 2013. Individual investors and financial disclosure. Journal of Accounting and Economics (2013).Google Scholar"",""Oliver Lehmberg, Dominique Ritze, Robert Meusel, and Christian Bizer. 2016. A large public corpus of web tables containing time and context metadata. In WWW. 75--76.Google Scholar"",""Moin Nadeem, Wei Fang, Brian Xu, Mitra Mohtarami, and James R. Glass. 2019. FAKTA: An Automatic End-to-End Fact Checking System. In NAACL.Google Scholar"",""George Nagy and Sharad Seth. 2016. Table headers: An entrance to the data mine. In ICPR.Google Scholar"",""Michèle B. Nuijten, Chris H. J. Hartgerink, Marcel A. L. M. van Assen, Sacha Epskamp, and Jelte M. Wicherts. 2016. The prevalence of statistical reporting errors in psychology (1985--2013). Behavior Research Methods (2016).Google Scholar"",""Radim v Rehr uv rek and Petr Sojka. 2010. Software Framework for Topic Modelling with Large Corpora. In Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks.Google Scholar"",""Alexey O Shigarov, Viacheslav V Paramonov, Polina V Belykh, and Alexander I Bondarev. 2016. Rule-based canonicalization of arbitrary tables in spreadsheets. In ICIST.Google Scholar"",""Huan Sun, Hao Ma, Xiaodong He, Wen-tau Yih, Yu Su, and Xifeng Yan. 2016. Table cell search for question answering. In WWW.Google Scholar"",""James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. 2018. FEVER: a Large-scale Dataset for Fact Extraction and VERification. In NAACL.Google Scholar"",""Andreas Vlachos and Sebastian Riedel. 2014. Fact Checking: Task definition and dataset construction. In Workshop on Language Technologies and Computational Social Science, ACL.Google ScholarCross Ref"",""Shuo Zhang and Krisztian Balog. 2018. Ad hoc table retrieval using semantic similarity. In WWW.Google Scholar""]"
https://doi.org/10.1145/3394486.3403311,GrokNet: Unified Computer Vision Model Trunk and Embeddings For Commerce,"In this paper, we present GrokNet, a deployed image recognition system for commerce applications. GrokNet leverages a multi-task learning approach to train a single computer vision trunk. We achieve a 2.1x improvement in exact product match accuracy when compared to the previous state-of-the-art Facebook product recognition system. We achieve this by training on 7 datasets across several commerce verticals, using 80 categorical loss functions and 3 embedding losses. We share our experience of combining diverse sources with wide-ranging label semantics and image statistics, including learning from human annotations, user-generated tags, and noisy search engine interaction data. GrokNet has demonstrated gains in production applications and operates at Facebook scale.","[{""name"":""Sean Bell"",""id"":""/profile/82259068257""},{""name"":""Yiqun Liu"",""id"":""/profile/99659455799""},{""name"":""Sami Alsheikh"",""id"":""/profile/99659214083""},{""name"":""Yina Tang"",""id"":""/profile/99659453140""},{""name"":""Edward Pizzi"",""id"":""/profile/99659573849""},{""name"":""M. Henning"",""id"":""/profile/99659573920""},{""name"":""Karun Singh"",""id"":""/profile/99659572922""},{""name"":""Omkar Parkhi"",""id"":""/profile/81508705348""},{""name"":""Fedor Borisyuk"",""id"":""/profile/81508708059""},{""name"":""Sean Bell"",""id"":""/profile/82259068257""},{""name"":""Yiqun Liu"",""id"":""/profile/99659455799""},{""name"":""Sami Alsheikh"",""id"":""/profile/99659214083""},{""name"":""Yina Tang"",""id"":""/profile/99659453140""},{""name"":""Edward Pizzi"",""id"":""/profile/99659573849""},{""name"":""M. Henning"",""id"":""/profile/99659573920""},{""name"":""Karun Singh"",""id"":""/profile/99659572922""},{""name"":""Omkar Parkhi"",""id"":""/profile/81508705348""},{""name"":""Fedor Borisyuk"",""id"":""/profile/81508708059""}]","[""2016. PyTorch. http://pytorch.org/Google Scholar"",""2017. Google Lens. https://lens.google.com/Google Scholar"",""Sean Bell and Kavita Bala. 2015. Learning visual similarity for product design with convolutional neural networks. ACM Trans. Graph. (2015).Google Scholar"",""Maxim Berman, Hervé Jégou, Vedaldi Andrea, Iasonas Kokkinos, and Matthijs Douze. 2019. MultiGrain: a unified image embedding for classes and instances. arXiv e-prints (Feb 2019).Google Scholar"",""Jane Bromley, Isabelle Guyon, Yann LeCun, Eduard Säckinger, and Roopak Shah. 1993. Signature Verification Using a \""Siamese\"" Time Delay Neural Network. In NIPS.Google Scholar"",""Zhao Chen, Vijay Badrinarayanan, Chen-Yu Lee, and Andrew Rabinovich. 2018. GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks. In ICML.Google Scholar"",""Sumit Chopra, Raia Hadsell, and Yann LeCun. 2005. Learning a Similarity Metric Discriminatively, with Application to Face Verification. In CVPR.Google Scholar"",""Chuan, Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. 2017. On Calibration of Modern Neural Networks. In JMLR.Google Scholar"",""Jiankang Deng, Jia Guo, Niannan Xue, and Stefanos Zafeiriou. 2019. ArcFace: Additive Angular Margin Loss for Deep Face Recognition. In CVPR.Google Scholar"",""Piotr Dollár, Zhuowen Tu, Pietro Perona, and Serge J. Belongie. 2009. Integral Channel Features. In BMVC.Google Scholar"",""Jeffrey Dunn. 2016. Introducing FBLearner Flow: Facebook's AI backbone. https://code.fb.com/core-data/introducing-fblearner-flow-facebook-s-ai-backbone/Google Scholar"",""Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. Deep Learning. MIT Press. http://www.deeplearningbook.org.Google Scholar"",""Raia Hadsell, Sumit Chopra, and Yann LeCun. 2006. Dimensionality Reduction by Learning an Invariant Mapping. In CVPR.Google Scholar"",""Houdong Hu, Yan Wang, Linjun Yang, Pavel Komlev, Li Huang, Xi (Stephen) Chen, Jiapei Huang, Ye Wu, Meenaz Merchant, and Arun Sacheti. 2018. Web-Scale Responsive Visual Search at Bing. In KDD.Google Scholar"",""Armand Joulin, Laurens van der Maaten, Allan Jabri, and Nicolas Vasilache. 2016. Learning visual features from large weakly supervised data. In ECCV.Google Scholar"",""Alex Kendall, Yarin Gal, and Roberto Cipolla. 2017. Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics. CoRR, Vol. abs/1705.07115 (2017).Google Scholar"",""Weiyang Liu, Yandong Wen, Zhiding Yu, Ming Li, Bhiksha Raj, and Le Song. 2017. SphereFace: Deep Hypersphere Embedding for Face Recognition. In CVPR.Google Scholar"",""Wenjie Luo, Bin Yang, and Raquel Urtasun. 2018. Fast and Furious: Real Time End-to-End 3D Detection, Tracking and Motion Forecasting With a Single Convolutional Net. In CVPR.Google Scholar"",""Dhruv Mahajan, Ross B. Girshick, Vignesh Ramanathan, Kaiming He, Manohar Paluri, Yixuan Li, Ashwin Bharambe, and Laurens van der Maaten. 2018. Exploring the Limits of Weakly Supervised Pretraining. In ECCV.Google Scholar"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S. Corrado, and Jeffrey Dean. 2013. Distributed Representations of Words and Phrases and their Compositionality. In NIPS. 3111--3119.Google Scholar"",""Ishan Misra, Abhinav Shrivastava, Abhinav Gupta, and Martial Hebert. 2016. Cross-Stitch Networks for Multi-task Learning. In CVPR.Google Scholar"",""Filip Radenovic, Giorgos Tolias, and Ondrej Chum. 2019. Fine-Tuning CNN Image Retrieval with No Human Annotation. (2019).Google Scholar"",""Zhongzheng Ren and Yong Jae Lee. 2017. Cross-Domain Self-supervised Multi-task Feature Learning using Synthetic Imagery. arxiv: cs.CV/1711.09082Google Scholar"",""Alexandre Sablayrolles, Matthijs Douze, Cordelia Schmid, and Hervé Jé gou. 2019. Spreading vectors for similarity search. In ICLR.Google Scholar"",""Chen Sun, Abhinav Shrivastava, Saurabh Singh, and Abhinav Gupta. 2017. Revisiting unreasonable effectiveness of data in deep learning era. In ICCV.Google Scholar"",""Yina Tang, Fedor Borisyuk, Siddarth Malreddy, Yixuan Li, Yiqun Liu, and Sergey Kirshner. 2019. MSURU: Large Scale E-commerce Image Classification with Weakly Supervised Search Data. In KDD.Google Scholar"",""Giorgos Tolias, Ronan Sicre, and Hervé Jé gou. 2016. Particular object retrieval with integral max-pooling of CNN activations. In ICLR.Google Scholar"",""Feng Wang, Xiang Xiang, Jian Cheng, and Alan Loddon Yuille. 2017. NormFace: L(_mbox2) Hypersphere Embedding for Face Verification. In Multimedia Conference, MM.Google Scholar"",""Hao Wang, Yitong Wang, Zheng Zhou, Xing Ji, Dihong Gong, Jingchao Zhou, Zhifeng Li, and Wei Liu. 2018. CosFace: Large Margin Cosine Loss for Deep Face Recognition. In CVPR.Google Scholar"",""Chao-Yuan Wu, R. Manmatha, Alexander J. Smola, and Philipp Krahenbuhl. 2017. Sampling Matters in Deep Embedding Learning. In ICCV.Google Scholar"",""Zhirong Wu, Yuanjun Xiong, Stella Yu, and Dahua Lin. 2018. Unsupervised Feature Learning via Non-Parametric Instance-level Discrimination. CoRR (2018).Google Scholar"",""Saining Xie, Ross B. Girshick, Piotr Dollár, Zhuowen Tu, and Kaiming He. 2016. Aggregated Residual Transformations for Deep Neural Networks. CVPR (2016).Google Scholar"",""Fan Yang, Ajinkya Kale, Yury Bubnov, Leon Stein, Qiaosong Wang, M. Hadi Kiapour, and Robinson Piramuthu. 2017. Visual Search at eBay. In KDD.Google Scholar"",""Andrew Zhai, Dmitry Kislyuk, Yushi Jing, Michael Feng, Eric Tzeng, Jeff Donahue, Yue Li Du, and Trevor Darrell. 2017. Visual Discovery at Pinterest. In WWW.Google Scholar"",""Andrew Zhai and Hao-Yu Wu. 2019. Classification is a strong baseline for deep metric learning. In BMVC.Google Scholar"",""Andrew Zhai, Hao-Yu Wu, Eric Tzeng, Dong Huk Park, and Charles Rosenberg. 2019. Learning a Unified Embedding for Visual Search at Pinterest. In KDD.Google Scholar"",""Yanhao Zhang, Pan Pan, Yun Zheng, Kang Zhao, Yingya Zhang, Xiaofeng Ren, and Rong Jin. 2018. Visual Search at Alibaba. In KDD.Google Scholar""]"
https://doi.org/10.1145/3394486.3403312,Learning Instrument Invariant Characteristics for Generating High-resolution Global Coral Reef Maps,"Coral reefs are one of the most biologically complex and diverse ecosystems within the shallow marine environment. Unfortunately, these underwater ecosystems are threatened by a number of anthropogenic challenges, including ocean acidification and warming, overfishing, and the continued increase of marine debris in oceans. This requires a comprehensive assessment of the world's coastal environments, including a quantitative analysis on the health and extent of coral reefs and other associated marine species, as a vital Earth Science measurement. However, limitations in observational and technological capabilities inhibit global sustained imaging of the marine environment. Harmonizing multimodal data sets acquired using different remote sensing instruments presents additional challenges, thereby limiting the availability of good quality labeled data for analysis. In this work, we develop a deep learning model for extracting domain invariant features from multimodal remote sensing imagery and creating high-resolution global maps of coral reefs by combining various sources of imagery and limited hand-labeled data available for certain regions. This framework allows us to generate, for the first time, coral reef segmentation maps at 2-meter resolution, which is a significant improvement over the kilometer-scale state-of-the-art maps. Additionally, this framework doubles accuracy and IoU metrics over baselines that do not account for domain invariance.","[{""name"":""Ata Akbari Asanjan"",""id"":""/profile/99659573292""},{""name"":""Kamalika Das"",""id"":""/profile/99659573265""},{""name"":""Alan Li"",""id"":""/profile/99659573502""},{""name"":""Ved Chirayath"",""id"":""/profile/99659573454""},{""name"":""Juan Torres-Perez"",""id"":""/profile/99659573159""},{""name"":""Soroosh Sorooshian"",""id"":""/profile/99659573843""},{""name"":""Ata Akbari Asanjan"",""id"":""/profile/99659573292""},{""name"":""Kamalika Das"",""id"":""/profile/99659573265""},{""name"":""Alan Li"",""id"":""/profile/99659573502""},{""name"":""Ved Chirayath"",""id"":""/profile/99659573454""},{""name"":""Juan Torres-Perez"",""id"":""/profile/99659573159""},{""name"":""Soroosh Sorooshian"",""id"":""/profile/99659573843""}]","[""David Bellwood, Terence Hughes, Carl Folke, and M Nyström. 2004. Confronting the Coral Reef Crisis. Nature429 (07 2004), 827--33.Google Scholar"",""Peter Burt and Edward Adelson. 1983. The Laplacian pyramid as a compact image code. IEEE Transactions on communications 31, 4 (1983), 532--540.Google ScholarCross Ref"",""Marco Castelluccio, Giovanni Poggi, Carlo Sansone, and Luisa Verdoliva. 2015.Land Use Classification in Remote Sensing Images by Convolutional Neural Networks. CoRRabs/1508.00092 (2015).Google Scholar"",""Y. Chen, H. Jiang, C. Li, X. Jia, and P. Ghamisi. 2016. Deep Feature Extraction and classification of Hyperspectral Images Based on Convolutional Neural Networks. IEEE Transactions on Geoscience and Remote Sensing 54, 10 (Oct 2016), 6232--6251.Google Scholar"",""V. Chirayath and R. Instrella. 2016. Airborne Fluid Lensing and Machine Learning for Automated Coral Classification. AGU Fall Meeting 2016(2016).Google Scholar"",""Robert Costanza, Ralph d'Arge, Rudolf S. de Groot, Stephen Farber, Monica Grasso, Bruce Hannon, Karin E. Limburg, Shahid Naeem, Robert V. O'Neill, José M. Paruelo, Robert G. Raskin, Paul Sutton, and Marjan van den Belt. 1997. The value of the world's ecosystem services and natural capital. Nature 387(1997), 253--260.Google ScholarCross Ref"",""Emily L Denton, Soumith Chintala, Rob Fergus, et al. 2015. Deep generative image models using a laplacian pyramid of adversarial networks. In Advances in neural information processing systems. 1486--1494.Google Scholar"",""Digital Globe 2010. The Benefits of the 8 Spectral Bands of World View-2. Digital Globe.Google Scholar"",""C. Dong, C. C. Loy, K. He, and X. Tang. 2016. Image Super-Resolution Using Deep Convolutional Networks. IEEE Transactions on Pattern Analysis and Machine Intelligence 38, 2 (Feb 2016), 295--307.Google ScholarDigital Library"",""European Space Agency 2015. Sentinel-2 User Handbook. European Space Agency. Issue 1.Google Scholar"",""Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, François Laviolette, Mario Marchand, and Victor Lempitsky. 2016. Domain-adversarial training of neural networks. The Journal of Machine Learning Research 17, 1 (2016), 2096--2030.Google ScholarDigital Library"",""Sergey Ioffe and Christian Szegedy. 2015. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv: 1502.03167(2015).Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv: 1412.6980(2014).Google Scholar"",""Fredrik Moberg and Carl Folke. 1999. Ecological Goods and Services of Coral Reef Ecosystems. Ecological Economics 29 (05 1999), 215--233.Google Scholar"",""Vinod Nair and Geoffrey E Hinton. 2010. Rectified linear units improve restricted boltzmann machines. In Proceedings of the 27th international conference on machine learning (ICML-10). 807--814.Google ScholarDigital Library"",""Andy Ridgwell and Richard E. Zeebe. 2005. The role of the global carbonate cycle in the regulation and evolution of the Earth system. Earth and Planetary Science Letters 234, 3 (2005), 299--315.Google ScholarCross Ref"",""Olaf Ronneberger, Philipp Fischer, and Thomas Brox. 2015. U-net: Convolutional networks for biomedical image segmentation. In International Conference on medical image computing and computer-assisted intervention. Springer, 234--241.Google ScholarCross Ref"",""Karen Simonyan and Andrew Zisserman. 2014. Very Deep Convolutional Networks for Large-Scale Image Recognition. CoRR(2014).Google Scholar"",""Yanfei Zhong, Feng Fei, Yanfei Liu, Bei Zhao, Hongzan Jiao, and Liangpei Zhang.2017. Sat CNN: satellite image dataset classification using agile convolutional neural networks. Remote Sensing Letters 8, 2 (2017), 136--145.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403313,Causal Meta-Mediation Analysis: Inferring Dose-Response Function From Summary Statistics of Many Randomized Experiments,"It is common in the internet industry to use offline-developed algorithms to power online products that contribute to the success of a business. Offline-developed algorithms are guided by offline evaluation metrics, which are often different from online business key performance indicators (KPIs). To maximize business KPIs, it is important to pick a north star among all available offline evaluation metrics. By noting that online products can be measured by online evaluation metrics, the online counterparts of offline evaluation metrics, we decompose the problem into two parts. As the offline A/B test literature works out the first part: counterfactual estimators of offline evaluation metrics that move the same way as their online counterparts, we focus on the second part: causal effects of online evaluation metrics on business KPIs. The north star of offline evaluation metrics should be the one whose online counterpart causes the most significant lift in the business KPI. We model the online evaluation metric as a mediator and formalize its causality with the business KPI as dose-response function (DRF). Our novel approach, causal meta-mediation analysis, leverages summary statistics of many existing randomized experiments to identify, estimate, and test the mediator DRF. It is easy to implement and to scale up, and has many advantages over the literature of mediation analysis and meta-analysis. We demonstrate its effectiveness by simulation and implementation on real data.","[{""name"":""Zenan Wang"",""id"":""/profile/99659573270""},{""name"":""Xuan Yin"",""id"":""/profile/99659453088""},{""name"":""Tianbo Li"",""id"":""/profile/99659573870""},{""name"":""Liangjie Hong"",""id"":""/profile/81438595662""},{""name"":""Zenan Wang"",""id"":""/profile/99659573270""},{""name"":""Xuan Yin"",""id"":""/profile/99659453088""},{""name"":""Tianbo Li"",""id"":""/profile/99659573870""},{""name"":""Liangjie Hong"",""id"":""/profile/81438595662""}]","[""Joshua Angrist, Guido Imbens, and Donald Rubin. 1996. Identification of Causal Effects Using Instrumental Variables. J. Amer. Statist. Assoc., Vol. 91, 434 (6 1996), 444.Google Scholar"",""Joshua Angrist and Alan Krueger. 2001. Instrumental Variables and the Search for Identification: From Supply and Demand to Natural Experiments. Journal of Economic Perspectives, Vol. 15, 4 (11 2001), 69--85.Google ScholarCross Ref"",""Reuben Baron and David Kenny. 1986. The moderator-mediator variable distinction in social psychological research: Conceptual, strategic, and statistical considerations. Journal of Personality and Social Psychology, Vol. 51, 6 (1986), 1173--1182.Google ScholarCross Ref"",""Will Browne and Mike Jones. 2017. What works in e-commerce - a meta-analysis of 6700 online experiments. Qubit Digital Ltd (2017), 1--21.Google Scholar"",""Harris Cooper, Larry Hedges, and Jeffrey Valentine. 2009. The handbook of research synthesis and meta-analysis. Russell Sage Foundation.Google Scholar"",""Alexandre Gilotte, Clément Calauzè nes, Thomas Nedelec, Alexandre Abraham, and Simon Dollé. 2018. Offline A/B Testing for Recommender Systems. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining (WSDM '18). Association for Computing Machinery, New York, NY, USA, 198--206.Google ScholarDigital Library"",""Donald Green, Shang Ha, and John Bullock. 2010. Enough already about \""Black Box\"" experiments: Studying mediation is more difficult than most scholars suppose. Annals of the American Academy of Political and Social Science, Vol. 628, 1 (2010), 200--208.Google ScholarCross Ref"",""William Greene. 2011. Econometric analysis 7 ed.). Pearson Education Inc. 1232 pages.Google Scholar"",""James Heckman and Rodrigo Pinto. 2015. Econometric Mediation Analyses: Identifying the Sources of Treatment Effects from Experimentally Estimated Production Technologies with Unmeasured and Mismeasured Inputs. Econometric Reviews, Vol. 34 (2015), 6--31.Google ScholarCross Ref"",""Julian Higgins and Simon Thompson. 2002. Quantifying heterogeneity in a meta-analysis. Statistics in Medicine, Vol. 21, 11 (6 2002), 1539--1558.Google Scholar"",""Kosuke Imai, Luke Keele, Dustin Tingley, and Teppei Yamamoto. 2014. Comment on Pearl: Practical implications of theoretical results for causal mediation analysis. Psychological Methods, Vol. 19, 4 (2014), 482--487.Google ScholarCross Ref"",""Kosuke Imai, Luke Keele, and Teppei Yamamoto. 2010. Identification, Inference and Sensitivity Analysis for Causal Mediation Effects. Statist. Sci. (2010).Google Scholar"",""Guido Imbens. 2000. The Role of the Propensity Score in Estimating Dose-Response Functions. Biometrika, Vol. 87, 3 (2000), 706--710.Google ScholarCross Ref"",""Guido Imbens and Keisuke Hirano. 2004. The Propensity Score with Continuous Treatments. (2004).Google Scholar"",""David MacKinnon, Amanda Fairchild, and Matthew Fritz. 2006. Mediation Analysis. Annual Review of Psychology, Vol. 58, 1 (12 2006), 593--614.Google Scholar"",""Judea Pearl. 2001. Direct and indirect effects. In Proceedings of the seventeenth conference on uncertainty in artificial intelligence. Morgan Kaufmann Publishers Inc., 411--420.Google Scholar"",""Judea Pearl. 2014a. Interpretation and identification of causal mediation. Psychological Methods, Vol. 19, 4 (2014), 459--481.Google ScholarCross Ref"",""Judea Pearl. 2014b. Reply to Commentary by Imai, Keele, Tingley, and Yamamoto Concerning Causal Mediation Analysis. Psychological Methods, Vol. 19, 4 (2014), 488--492.Google ScholarCross Ref"",""Alexander Peysakhovich and Dean Eckles. 2018. Learning causal effects from many randomized experiments using regularized instrumental variables. In The Web Conference 2018 (WWW 2018). ACM, New York, NY.Google ScholarDigital Library"",""James Robins. 2003. Semantics of causal DAG models and the identification of direct and indirect effects. Highly Structured Stochastic Systems (1 2003), 70--82.Google Scholar"",""James Robins and Sander Greenland. 1992. Identifiability and exchangeability for direct and indirect effects. Epidemiology, Vol. 3, 2 (1992), 143--155.Google ScholarCross Ref"",""James Robins and Thomas Richardson. 2010. Alternative graphical causal models and the identification of direct effects. Causality and psychopathology: finding the determinants of disorders and their cures (2010).Google Scholar"",""Donald Rubin. 2003. Basic concepts of statistical inference for causal effects in experiments and observational studies. (2003).Google Scholar"",""Derek Rucker, Kristopher Preacher, Zakary Tormala, and Richard Petty. 2011. Mediation Analysis in Social Psychology: Current Practices and New Recommendations. Social and Personality Psychology Compass, Vol. 5, 6 (2011), 359--371.Google ScholarCross Ref"",""Dylan Small. 2012. Mediation analysis without sequential ignorability: Using baseline covariates interacted with random assignment as instrumental variables. Journal of Statistical Research, Vol. 46, 2 (2012), 91--103.Google Scholar"",""Michael Sobel. 2008. Identification of Causal Parameters in Randomized Studies With Mediating Variables. Journal of Educational and Behavioral Statistics, Vol. 33, 2 (2008), 230--251.Google ScholarCross Ref"",""Tom Stanley and Hristos Doucouliagos. 2012. Meta-regression analysis in economics and business. Routledge.Google Scholar"",""Jeffrey Wooldridge. 2010. Econometric analysis of cross section and panel data. MIT Press, Cambridge, MA. 1096 pages.Google Scholar"",""Xuan Yin and Liangjie Hong. 2019. The Identification and Estimation of Direct and Indirect Effects in A/B Tests Through Causal Mediation Analysis. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining (KDD '19). ACM, New York, NY, USA, 2989--2999.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403314,AutoFIS: Automatic Feature Interaction Selection in Factorization Models for Click-Through Rate Prediction,"Learning feature interactions is crucial for click-through rate (CTR) prediction in recommender systems. In most existing deep learning models, feature interactions are either manually designed or simply enumerated. However, enumerating all feature interactions brings large memory and computation cost. Even worse, useless interactions may introduce noise and complicate the training process. In this work, we propose a two-stage algorithm called Automatic Feature Interaction Selection (AutoFIS). AutoFIS can automatically identify important feature interactions for factorization models with computational cost just equivalent to training the target model to convergence. In the search stage, instead of searching over a discrete set of candidate feature interactions, we relax the choices to be continuous by introducing the architecture parameters. By implementing a regularized optimizer over the architecture parameters, the model can automatically identify and remove the redundant feature interactions during the training process of the model. In the re-train stage, we keep the architecture parameters serving as an attention unit to further boost the performance. Offline experiments on three large-scale datasets (two public benchmarks, one private) demonstrate that AutoFIS can significantly improve various FM based models. AutoFIS has been deployed onto the training platform of Huawei App Store recommendation service, where a 10-day online A/B test demonstrated that AutoFIS improved the DeepFM model by 20.3% and 20.1% in terms of CTR and CVR respectively.","[{""name"":""Bin Liu"",""id"":""/profile/99659565416""},{""name"":""Chenxu Zhu"",""id"":""/profile/99659573886""},{""name"":""Guilin Li"",""id"":""/profile/99659574002""},{""name"":""Weinan Zhang"",""id"":""/profile/81555923456""},{""name"":""Jincai Lai"",""id"":""/profile/99659574442""},{""name"":""Ruiming Tang"",""id"":""/profile/81488661679""},{""name"":""Xiuqiang He"",""id"":""/profile/81331494271""},{""name"":""Zhenguo Li"",""id"":""/profile/87259499257""},{""name"":""Yong Yu"",""id"":""/profile/81548005779""},{""name"":""Bin Liu"",""id"":""/profile/99659565416""},{""name"":""Chenxu Zhu"",""id"":""/profile/99659573886""},{""name"":""Guilin Li"",""id"":""/profile/99659574002""},{""name"":""Weinan Zhang"",""id"":""/profile/81555923456""},{""name"":""Jincai Lai"",""id"":""/profile/99659574442""},{""name"":""Ruiming Tang"",""id"":""/profile/81488661679""},{""name"":""Xiuqiang He"",""id"":""/profile/81331494271""},{""name"":""Zhenguo Li"",""id"":""/profile/87259499257""},{""name"":""Yong Yu"",""id"":""/profile/81548005779""}]","[""Gabriel Bender. 2019. Understanding and simplifying one-shot architecture search. In CVPR.Google Scholar"",""Alex Beutel, Paul Covington, Sagar Jain, Can Xu, Jia Li, Vince Gatto, and Ed H. Chi. 2018. Latent Cross: Making Use of Context in Recurrent Recommender Systems. In WSDM. 46--54.Google Scholar"",""Shih-Kang Chao and Guang Cheng. 2019. A generalization of regularized dual averaging and its dynamics. In CoRR. abs/1909.10072 (2019).Google Scholar"",""Tianqi Chen and Carlos Guestrin. 2016. XGBoost:A Scalable Tree Boosting System. In SIGKDD. 785--794.Google Scholar"",""Hengtze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Deepak Chandra, Hrishi Aradhye, Glen Anderson, Greg S Corrado, Wei Chai, Mustafa Ispir, et almbox. 2016. Wide \u0026 Deep Learning for Recommender Systems. In [email protected]Google Scholar"",""Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep Neural Networks for YouTube Recommendations. In RecSys. 191--198.Google Scholar"",""Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: A Factorization-Machine based Neural Network for CTR Prediction. In IJCAI. 1725--1731.Google Scholar"",""Chaoyang He, Haishan Ye, Li Shen, and Tong Zhang. 2020. MiLeNAS: Efficient Neural Architecture Search via Mixed-Level Reformulation. In CVPR.Google Scholar"",""Xiangnan He and Tat-Seng Chua. 2017. Neural Factorization Machines for Sparse Predictive Analytics. In SIGIR. 355--364.Google Scholar"",""Xinran He, Junfeng Pan, Ou Jin, Tianbing Xu, Bo Liu, Tao Xu, Yanxin Shi, Antoine Atallah, Ralf Herbrich, and Stuart Bowers. 2014. Practical Lessons from Predicting Clicks on Ads at Facebook. In [email protected] 5:1--5:9.Google Scholar"",""Kurt Hornik, Maxwell B. Stinchcombe, and Halbert White. 1989. Multilayer feedforward networks are universal approximators. In Neural Networks.Google Scholar"",""Sergey Ioffe and Christian Szegedy. 2015. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. In ICML. 448--456.Google ScholarDigital Library"",""Yu-Chin Juan, Yong Zhuang, Wei-Sheng Chin, and Chih-Jen Lin. 2016. Field-aware Factorization Machines for CTR Prediction. In RecSys.Google Scholar"",""YuChin Juan, Yong Zhuang, and Wei-Sheng Chin. 2014. 3 Idiots' Approach for Display Advertising Challenge. https://www.csie.ntu.edu.tw/ r01922136/kaggle-2014-criteo.pdf.Google Scholar"",""Yehuda Koren, Robert M. Bell, and Chris Volinsky. 2009. Matrix Factorization Techniques for Recommender Systems. IEEE Computer, Vol. 42, 8 (2009), 30--37.Google ScholarDigital Library"",""Guilin Li, Xing Zhang, Zitong Wang, Zhenguo Li, and Tong Zhang. 2019. StacNAS: Towards stable and consistent optimization for differentiable Neural Architecture Search. arXiv preprint arXiv:1909.11926 (2019).Google Scholar"",""Jianxun Lian, Xiaohuan Zhou, Fuzheng Zhang, Zhongxia Chen, Xing Xie, and Guangzhong Sun. 2018. xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems. In KDD.Google Scholar"",""Bin Liu, Ruiming Tang, Yingzhi Chen, Jinkai Yu, Huifeng Guo, and Yuzhou Zhang. 2019 b. Feature Generation by Convolutional Neural Network for Click-Through Rate Prediction. In WWW. ACM, 1119--1129.Google Scholar"",""Hanxiao Liu, Karen Simonyan, and Yiming Yang. 2019 a. DARTS: Differentiable Architecture Search. In ICLR.Google Scholar"",""Yuanfei Luo, Mengshuo Wang, Hao Zhou, Quanming Yao, Wei-Wei Tu, Yuqiang Chen, Wenyuan Dai, and Qiang Yang. 2019. AutoCross: Automatic Feature Crossing for Tabular Data in Real-World Applications. In KDD. 1936--1945.Google Scholar"",""H. Brendan McMahan, Gary Holt, David Sculley, Michael Young, Dietmar Ebner, Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, Sharat Chikkerur, Dan Liu, Martin Wattenberg, Arnar Mar Hrafnkelsson, Tom Boulos, and Jeremy Kubica. 2013. Ad click prediction: a view from the trenches. In KDD.Google Scholar"",""Junwei Pan, Jian Xu, Alfonso Lobos Ruiz, Wenliang Zhao, Shengjun Pan, Yu Sun, and Quan Lu. 2018. Field-weighted factorization machines for click-through rate prediction in display advertising. In WWW. 1349--1357.Google Scholar"",""Yanru Qu, Han Cai, Kan Ren, Weinan Zhang, Yong Yu, Ying Wen, and Jun Wang. 2016. Product-Based Neural Networks for User Response Prediction. (2016), 1149--1154.Google Scholar"",""Yanru Qu, Bohui Fang, Weinan Zhang, Ruiming Tang, Minzhe Niu, Huifeng Guo, Yong Yu, and Xiuqiang He. 2019. Product-Based Neural Networks for User Response Prediction over Multi-Field Categorical Data. ACM Trans. Inf. Syst., Vol. 37, 1 (2019), 5:1--5:35.Google ScholarDigital Library"",""James Kwok Yong Li Cho-Jui Hsieh Quanming Yao, Xiangning Chen. 2020. Efficient Neural Interaction Function Search for Collaborative Filtering. In WWW.Google Scholar"",""Steffen Rendle. 2010. Factorization Machines. In ICDM. 995--1000.Google Scholar"",""Shai Shalev-Shwartz, Ohad Shamir, and Shaked Shammah. 2017. Failures of Gradient-Based Deep Learning. In ICML. 3067--3075.Google Scholar"",""Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. 2017. Deep \u0026 cross network for ad click predictions. In [email protected] 12.Google Scholar"",""Jun Xiao, Hao Ye, Xiangnan He, Hanwang Zhang, Fei Wu, and Tat-Seng Chua. 2017. Attentional Factorization Machines: Learning the Weight of Feature Interactions via Attention Networks. In IJCAI. 3119--3125.Google Scholar"",""Weinan Zhang, Tianming Du, and Jun Wang. 2016. Deep learning over multi-field categorical data. In European conference on information retrieval. Springer, 45--57.Google ScholarCross Ref"",""Guorui Zhou, Xiaoqiang Zhu, Chengru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep Interest Network for Click-Through Rate Prediction. In KDD. 1059--1068.Google Scholar""]"
https://doi.org/10.1145/3394486.3403315,City Metro Network Expansion with Reinforcement Learning,"City metro network expansion, included in the transportation network design, aims to design new lines based on the existing metro network. Existing methods in the field of transportation network design either (i) can hardly formulate this problem efficiently, (ii) depend on expert guidance to produce solutions, or (iii) appeal to problem-specific heuristics which are difficult to design. To address these limitations, we propose a reinforcement learning based method for the city metro network expansion problem. In this method, we formulate the metro line expansion as a Markov decision process (MDP), which characterizes the problem as a process of sequential station selection. Then, we train an actor-critic model to design the next metro line on the basis of the existing metro network. The actor is an encoder-decoder network with an attention mechanism to generate the parameterized policy which is used to select the stations. The critic estimates the expected cumulative reward to assist the training of the actor by reducing training variance. The proposed method does not require expert guidance during design, since the learning procedure only relies on the reward calculation to tune the policy for better station selection. Also, it avoids the difficulty of heuristics designing by the policy formalizing the station selection. Considering origin-destination (OD) trips and social equity, we expand the current metro network in Xi'an, China, based on the real mobility information of 24,770,715 mobile phone users in the whole city. The results demonstrate the advantages of our method compared with existing approaches.","[{""name"":""Yu Wei"",""id"":""/profile/99659574466""},{""name"":""Minjia Mao"",""id"":""/profile/99659461958""},{""name"":""Xi Zhao"",""id"":""/profile/81496668314""},{""name"":""Jianhua Zou"",""id"":""/profile/81496653500""},{""name"":""Ping An"",""id"":""/profile/99659574095""},{""name"":""Yu Wei"",""id"":""/profile/99659574466""},{""name"":""Minjia Mao"",""id"":""/profile/99659461958""},{""name"":""Xi Zhao"",""id"":""/profile/81496668314""},{""name"":""Jianhua Zou"",""id"":""/profile/81496653500""},{""name"":""Ping An"",""id"":""/profile/99659574095""}]","[""Elisabete Arsenio, Karel Martens, and Floridea Di Ciommo. 2016. Sustainable urban mobility plans: Bridging climate change and equity targets? Research in Transportation Economics, Vol. 55 (2016), 30--39.Google ScholarCross Ref"",""Hamid Behbahani, Sobhan Nazari, Masood Jafari Kang, and Todd Litman. 2019. A conceptual framework to formulate transportation network design problem considering social equity criteria. Transportation Research Part A: Policy and Practice, Vol. 125 (2019), 171--183.Google ScholarCross Ref"",""Irwan Bello, Hieu Pham, Quoc V Le, Mohammad Norouzi, and Samy Bengio. 2016. Neural combinatorial optimization with reinforcement learning. arXiv preprint arXiv:1611.09940 (2016).Google Scholar"",""Giuseppe Bruno, Michel Gendreau, and Gilbert Laporte. 2002. A heuristic for the location of a rapid transit line. Computers \u0026 Operations Research, Vol. 29, 1 (2002), 1--12.Google ScholarCross Ref"",""Partha Chakroborty. 2003. Genetic algorithms for optimal urban transit network design. Computer-Aided Civil and Infrastructure Engineering, Vol. 18, 3 (2003), 184--200.Google ScholarCross Ref"",""Hélène Dufourd, Michel Gendreau, and Gilbert Laporte. 1996. Locating a transit line using tabu search. Location Science, Vol. 4, 1--2 (1996), 1--19.Google ScholarCross Ref"",""Wei Fan and Randy B Machemehl. 2006. Using a simulated annealing algorithm to solve the transit route network design problem. Journal of transportation engineering, Vol. 132, 2 (2006), 122--132.Google ScholarCross Ref"",""Reza Zanjirani Farahani, Elnaz Miandoabchi, Wai Yuen Szeto, and Hannaneh Rashidi. 2013. A review of urban transportation network design problems. European Journal of Operational Research, Vol. 229, 2 (2013), 281--302.Google ScholarCross Ref"",""Xavier Glorot and Yoshua Bengio. 2010. Understanding the difficulty of training deep feedforward neural networks. In Proceedings of the thirteenth international conference on artificial intelligence and statistics. 249--256.Google Scholar"",""Ivo Grondman, Lucian Busoniu, Gabriel AD Lopes, and Robert Babuska. 2012. A survey of actor-critic reinforcement learning: Standard and natural policy gradients. IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews), Vol. 42, 6 (2012), 1291--1307.Google ScholarDigital Library"",""Gabriel Gutiérrez-Jarpa, Gilbert Laporte, and Vladimir Marianov. 2018. Corridor-based metro network design with travel flow capture. Computers \u0026 Operations Research, Vol. 89 (2018), 58--67.Google ScholarDigital Library"",""Gabriel Gutiérrez-Jarpa, Carlos Obreque, Gilbert Laporte, and Vladimir Marianov. 2013. Rapid transit network design for optimal cost and origin--destination demand capture. Computers \u0026 Operations Research, Vol. 40, 12 (2013), 3000--3009.Google ScholarDigital Library"",""Peter Henderson, Riashat Islam, Philip Bachman, Joelle Pineau, Doina Precup, and David Meger. 2018. Deep reinforcement learning that matters. In Thirty-Second AAAI Conference on Artificial Intelligence.Google Scholar"",""Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural computation, Vol. 9, 8 (1997), 1735--1780.Google Scholar"",""Konstantinos Kepaptsoglou and Matthew Karlaftis. 2009. Transit route network design problem. Journal of transportation engineering, Vol. 135, 8 (2009), 491--505.Google ScholarCross Ref"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Vijay R Konda and John N Tsitsiklis. 2000. Actor-critic algorithms. In Advances in neural information processing systems. 1008--1014.Google Scholar"",""Michael Kuntz and Marco Helbich. 2014. Geostatistical mapping of real estate prices: an empirical comparison of kriging and cokriging. International Journal of Geographical Information Science, Vol. 28, 9 (2014), 1904--1921.Google ScholarDigital Library"",""Gilbert Laporte and Juan A Mesa. 2015. The design of rapid transit networks. In Location science. Springer, 581--594.Google Scholar"",""Gilbert Laporte, Juan A Mesa, and Francisco A Ortega. 2000. Optimization methods for the planning of rapid transit systems. European Journal of Operational Research, Vol. 122, 1 (2000), 1--10.Google ScholarCross Ref"",""Gilbert Laporte, Juan A Mesa, Francisco A Ortega, and Ignacio Sevillano. 2005. Maximizing trip coverage in the location of a single rapid transit alignment. Annals of Operations Research, Vol. 136, 1 (2005), 49--63.Google ScholarCross Ref"",""Gilbert Laporte and Marta MB Pascoal. 2015. Path based algorithms for metro network design. Computers \u0026 Operations Research, Vol. 62 (2015), 78--94.Google ScholarDigital Library"",""Timothy P Lillicrap, Jonathan J Hunt, Alexander Pritzel, Nicolas Heess, Tom Erez, Yuval Tassa, David Silver, and Daan Wierstra. 2015. Continuous control with deep reinforcement learning. arXiv preprint arXiv:1509.02971 (2015).Google Scholar"",""Kevin Manaugh, Madhav G Badami, and Ahmed M El-Geneidy. 2015. Integrating social equity into urban transportation planning: A critical evaluation of equity objectives and measures in transportation plans in North America. Transport policy, Vol. 37 (2015), 167--176.Google Scholar"",""Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin Riedmiller. 2013. Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602 (2013).Google Scholar"",""Mahmoud Owais and Mostafa K Osman. 2018. Complete hierarchical multi-objective genetic algorithm for transit network design problem. Expert Systems with Applications, Vol. 114 (2018), 143--154.Google ScholarCross Ref"",""Yanshuo Sun, Paul Schonfeld, and Qianwen Guo. 2018. Optimal extension of rail transit lines. International Journal of Sustainable Transportation, Vol. 12, 10 (2018), 753--769.Google ScholarCross Ref"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems. 5998--6008.Google Scholar"",""Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. 2015. Pointer networks. In Advances in Neural Information Processing Systems. 2692--2700.Google Scholar"",""Yi Wei, Jian Gang Jin, Jingfeng Yang, and Linjun Lu. 2019. Strategic network expansion of urban rapid transit systems: A bi-objective programming model. Computer-Aided Civil and Infrastructure Engineering, Vol. 34, 5 (2019), 431--443.Google ScholarDigital Library"",""Ronald J Williams. 1992. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning, Vol. 8, 3--4 (1992), 229--256.Google Scholar"",""Zhongzhen Yang, Bin Yu, and Chuntian Cheng. 2007. A parallel ant colony algorithm for bus network optimization. Computer-Aided Civil and Infrastructure Engineering, Vol. 22, 1 (2007), 44--55.Google ScholarCross Ref"",""Yang Ye, Yu Zheng, Yukun Chen, Jianhua Feng, and Xing Xie. 2009. Mining individual life pattern based on location history. In 2009 tenth international conference on mobile data management: systems, services and middleware. IEEE, 1--10.Google Scholar"",""Junjun Yin, Aiman Soliman, Dandong Yin, and Shaowen Wang. 2017. Depicting urban boundaries from a mobility network of spatial interactions: a case study of Great Britain with geo-located Twitter data. International Journal of Geographical Information Science, Vol. 31, 7 (2017), 1293--1313.Google ScholarDigital Library"",""Xiangyu Zhao, Liang Zhang, Zhuoye Ding, Long Xia, Jiliang Tang, and Dawei Yin 2018. Recommendations with negative feedback via pairwise deep reinforcement learning. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1040--1048.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403316,Game Action Modeling for Fine Grained Analyses of Player Behavior in Multi-player Card Games (Rummy as Case Study),"We present a deep learning framework for game action modeling, which enables fine-grained analyses of player behavior. We develop CNN-based supervised models that effectively learn the critical game play decisions from skilled players, and use these models to assess player characteristics in the system, such as their retention, engagement, deposit buckets, etc. We show that with a carefully constructed input format, that efficiently represents the game state and history as a multi-dimensional image, along with a custom architecture the model learns the strategies of the game accurately. It is further enhanced with look-ahead achieved by self-play simulation to better estimate the game state, and this information is used in a new loss function. Next, we show that analyzing the players with these models as reference has immense benefit in understanding player potential in terms of engagement and revenue. We also use the model to understand the various contexts under which players tend to make mistakes, and use these insights to up-skill players.","[{""name"":""Sharanya Eswaran"",""id"":""/profile/81436598486""},{""name"":""Mridul Sachdeva"",""id"":""/profile/99659574313""},{""name"":""Vikram Vimal"",""id"":""/profile/99659573333""},{""name"":""Deepanshi Seth"",""id"":""/profile/99659574491""},{""name"":""Suhaas Kalpam"",""id"":""/profile/99659575207""},{""name"":""Sanjay Agarwal"",""id"":""/profile/99659574387""},{""name"":""Tridib Mukherjee"",""id"":""/profile/99659574730""},{""name"":""Samrat Dattagupta"",""id"":""/profile/99659574065""},{""name"":""Sharanya Eswaran"",""id"":""/profile/81436598486""},{""name"":""Mridul Sachdeva"",""id"":""/profile/99659574313""},{""name"":""Vikram Vimal"",""id"":""/profile/99659573333""},{""name"":""Deepanshi Seth"",""id"":""/profile/99659574491""},{""name"":""Suhaas Kalpam"",""id"":""/profile/99659575207""},{""name"":""Sanjay Agarwal"",""id"":""/profile/99659574387""},{""name"":""Tridib Mukherjee"",""id"":""/profile/99659574730""},{""name"":""Samrat Dattagupta"",""id"":""/profile/99659574065""}]","[""Board Games Market - Global Outlook and Forecast 2018--2023.Google Scholar"",""Playing Cards And Board Games Market Size, Share and Trends Analysis 2019--25Google Scholar"",""M. Moravcik, et al. DeepStack:Expert-level artificial intelligence in heads-up no-limit poker. Science Vol 356:6337 2017Google ScholarCross Ref"",""X. Guo, et al. Deep Learning for Real-Time Atari Game Play Using Offline Monte Carlo Tree Search Planning. NIPS 2014Google Scholar"",""D. Silver, et al. Mastering the Game of Go without Human Knowledge. Nature vol. 550, pp 354--359, 2017Google ScholarCross Ref"",""D. Silver, et al. Mastering the game of Go with Deep Neural Networks and tree search. Nature vol. 529(7587):484--489, 2016Google ScholarCross Ref"",""D. Silver, et al. A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. Science vol. 362, no. 6419, pp. 1140--1144, 2018Google ScholarCross Ref"",""S. Gao, et al. Improved Data Structure and Deep CNN Design for Haifu Data Learning in the Game of Mahjong. IPSJ Workshop, 2018.Google Scholar"",""B. Wang, et al. Beyond Winning and Losing: Modeling Human Motivations and Behaviors Using Inverse Reinforcement Learning. AIIDE 2019Google Scholar"",""M.Richards, E. Amir. Information Set Generation in Partially Observable Games. AAAI 2012Google Scholar"",""D. Vinkemeier. Predicting Folds in Poker Using Action Unit Detectors. IEEE FDG 2018Google Scholar"",""G. Tesauro. Temporal difference learning and TD-Gammon. Communications of the ACM 38, 58, 1995Google ScholarDigital Library"",""J. Schaeffer, R. Lake, P. Lu, M. Bryant. CHINOOK The World Man-Machine Checkers Champion. AI Magazine 17:21, 1996.Google Scholar"",""M. Campbell, A. J. Hoane Jr., F. Hsu. Deep Blue. Artificial Intelligence 134:57, 2002.Google ScholarDigital Library"",""D. Ferrucci. Introduction to \""This is Watson\"". IBM Journal of Research and Development 56, 1:1 (2012).Google ScholarDigital Library"",""V. Mnih, et al. Human-level control through deep reinforcement learning. Nature 518, 529--533, 2015.Google ScholarCross Ref"",""S. Eswaran, et al. GAIM: Game Action Info Mining Framework for Multiplayer Online Card Games. PAKDD 2020Google Scholar"",""JRS. Blair, et al. Games with Imperfect Information. AAAI TR, Fall Symposimum, 1993Google Scholar"",""I. Frank. Search in games with incomplete info: Bridge case study. Elsevier AI, vol.100:1, 1998Google Scholar"",""S. Ganzfried, T. Sandholm. Computing Equilibria in Partially observable stochastic games. IJCAI 2009Google Scholar"",""N. Brown et al. Superhuman AI for multiplayer poker. Science 10.1126/science.aay2400, 2019Google Scholar"",""X. Chen and X. Deng. Settling the complexity of 2- player Nash equilibrium. FOCS 2006.Google ScholarDigital Library"",""K. Vis, N. van Rijn, W. Takes. The Complexity of Rummikub Problems. BNAIC 2015.Google Scholar"",""Z. Chen et al. Q-DeckRec: A Fast Deck Recommendation System for Collectible Card Games. IEEE CIG 2018.Google Scholar"",""K. Simonyan et al. Very Deep CNN for Large-Scale Image Recognition. ICLR 2015Google Scholar"",""G.Huang et al. Densely Connected Convolutional Networks. CVPR 2017Google Scholar"",""K.He et al. Deep Residual Learning for Image Recognition. CVPR 2016Google Scholar"",""C. Szegedy et al. Going Deeper with Convolutions. CVPR 2015Google Scholar"",""K. He. Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification. ICLR 2015Google Scholar"",""P. Auer, et al. Finite-time analysis of the Multi-arm bandit problem. Machine Learning, 47(2):235--256, 2002.Google ScholarDigital Library"",""J. Yoon, et al. GAIN: Missing Data Imputation using Generative Adversarial Nets. ICML 2018Google Scholar"",""K. Satoppa, et al. Finding a \""Kneedle\"" in a Haystack: Detecting Knee Points in System Behavior. IEEE ICDCSW 2011Google Scholar"",""T. Hothorn, et al. Unbiased Recursive Partitioning: A Conditional Inference Framework. J. of Comp and Graphical Stats, 2012Google Scholar""]"
https://doi.org/10.1145/3394486.3403317,Cascade-LSTM: A Tree-Structured Neural Classifier for Detecting Misinformation Cascades,"Misinformation in social media - such as fake news, rumors, or other forms of deceptive content - poses a significant threat to society and, hence, scalable strategies for an early detection of online cascades with misinformation are in dire need. The prominent approach in detecting online cascades with misinformation builds upon neural networks based on sequences of simple structural features of the propagation dynamics (e.g., cascade size, average retweeting time). However, these structural features neglect large parts of the information in the cascade. As a remedy, we propose a novel tree-structured neural network named Cascade-LSTM.Our Cascade-LSTM draws upon a tree-structured long short-term memory network that is carefully engineered to the structure of online information cascades. Specifically, we suggest a novel bi-directional encoding similar to the information flow, extend inner nodes with further covariates from retweets, and fuse the network with global information from the root. As a result, our Cascade-LSTM overcomes inherent limitations from feature engineering, since it learns propagation features along the complete cascade. The effectiveness of our Cascade-LSTM is demonstrated based on a classification task to predict the veracity of 2,156 Twitter cascades. We improve the detection if misinformation in terms of AUC over the status quo with cascade features by 2.8%.Altogether, our Cascade-LSTM entails important implications: (1) it presents the first neural classifier that learns the complete cascade. (2) It demonstrates a promising approach to practitioners for detecting misinformation through mining retweet behavior. (3) The model is fairly general, which ensures widespread applicability for inferences from online cascades.","[{""name"":""Francesco Ducci"",""id"":""/profile/99659348430""},{""name"":""Mathias Kraus"",""id"":""/profile/99659227583""},{""name"":""Stefan Feuerriegel"",""id"":""/profile/83458675557""},{""name"":""Francesco Ducci"",""id"":""/profile/99659348430""},{""name"":""Mathias Kraus"",""id"":""/profile/99659227583""},{""name"":""Stefan Feuerriegel"",""id"":""/profile/83458675557""}]","[""Hunt Allcott and Matthew Gentzkow. 2017. Social media and fake news in the 2016 election. Journal of Economic Perspectives, Vol. 31, 2 (2017), 211--236.Google ScholarCross Ref"",""Eytan Bakshy, Solomon Messing, and Lada A. Adamic. 2015. Exposure to ideologically diverse news and opinion on Facebook. Science, Vol. 348, 6239 (2015), 1130--1132.Google Scholar"",""Eytan Bakshy, Itamar Rosenn, Cameron Marlow, and Lada Adamic. 2012. The role of social networks in information diffusion. In WWW.Google Scholar"",""Bernhard Kratzwald, Suzana Ilić, Mathias Kraus, Stefan Feuerriegel, and Helmut Prendinger. 2018. Deep learning for affective computing: Text-based emotion recognition in decision support. Decision Support Systems, Vol. 115 (2018), 24--35.Google ScholarCross Ref"",""Alessandro Bessi, Mauro Coletto, George A. Davidescu, Antonio Scala, Guido Caldarelli, and Walter Quattrociocchi. 2015. Science vs conspiracy: Collective narratives in the age of misinformation. PLOS ONE, Vol. 10, 2 (2015), e0118093.Google ScholarCross Ref"",""Meeyoung Cha, Alan Mislove, and Krishna P. Gummadi. 2009. A measurement-driven analysis of information propagation in the Flickr social network. In WWW. 721--730.Google Scholar"",""Justin Cheng, Lada A. Adamic, Alex P. Dow, Jon M. Kleinberg, and Jure Leskovec. 2014. Can cascades be predicted?. In WWW.Google Scholar"",""Mauro Conti, Daniele Lain, Riccardo Lazzeretti, Giulio Lovisotto, and Walter Quattrociocchi. 2017. It's always April fools' day!: On the difficulty of social network misinformation classification via propagation features. In IEEE Workshop on Information Forensics and Security (WIFS).Google ScholarCross Ref"",""Riley Crane and Didier Sornette. 2008. Robust dynamic classes revealed by measuring the response function of a social system. PNAS, Vol. 105, 41 (2008), 15649--15653.Google ScholarCross Ref"",""Adrien Friggeri, Lada A. Adamic, Dean Eckles, and Justin Cheng. 2014. Rumor cascades. In ICWSM.Google Scholar"",""Sharad Goel, Ashton Anderson, Jake Hofman, and Duncan J. Watts. 2015. The structural virality of online diffusion. Management Science, Vol. 62, 1 (2015), 180--196.Google Scholar"",""Caitlin Gray, Lewis Mitchell, and Matthew Roughan. 2018. Super-blockers and the effect of network structure on information cascades. In WWW. 1435--1441.Google Scholar"",""Liangjie Hong, Ovidiu Dan, and Brian D. Davison. 2011. Predicting popular messages in Twitter. In WWW.Google Scholar"",""Wenjian Hu, Krishna Kumar Singh, Fanyi Xiao, Jinyoung Han, Chen-Nee Chuah, and Yong Jae Lee. 2018. Who Will Share My Image?. In WSDM.Google Scholar"",""Diederik P. Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Ryota Kobayashi and Renaud Lambiotte. 2016. Tideh: Time-dependent Hawkes process for predicting retweet dynamics. In ICWSM.Google Scholar"",""Mathias Kraus and Stefan Feuerriegel. 2019. Sentiment analysis based on rhetorical structure theory: Learning deep neural networks from discourse trees. Expert Systems with Applications, Vol. 118 (2019), 65--79.Google ScholarCross Ref"",""Haewoon Kwak, Changhyun Lee, Hosung Park, and Sue Moon. 2010. What is Twitter, a social network or a news media?. In WWW.Google Scholar"",""Sejeong Kwon, Meeyoung Cha, Kyomin Jung, Wei Chen, and Yajun Wang. 2013. Prominent features of rumor propagation in online social media. In ICDM.Google Scholar"",""Daniel J. Lasser. 1961. Topological Ordering of a list of randomly-numbered elements of a network. Commun. ACM, Vol. 4, 4 (1961), 167--168.Google ScholarDigital Library"",""Jorma Laurikkala. 2001. Improving identification of difficult small classes by balancing class distribution. In Conference on Artificial Intelligence in Medicine in Europe (AIME).Google ScholarCross Ref"",""David M. J. Lazer, Matthew A. Baum, Yochai Benkler, Adam J. Berinsky, Kelly M. Greenhill, Filippo Menczer, Miriam J. Metzger, Brendan Nyhan, Gordon Pennycook, David Rothschild, Michael Schudson, Steven A. Sloman, Cass R. Sunstein, Emily A. Thorson, Duncan J. Watts, and Jonathan L. Zittrain. 2018. The science of fake news. Science, Vol. 359, 6380 (2018), 1094--1096.Google Scholar"",""Kristina Lerman and Rumi Ghosh. 2010. Information contagion: An empirical study of the spread of news on Digg and Twitter social networks. In ICWSM.Google Scholar"",""Jure Leskovec, Mary McGlohon, Christos Faloutsos, Natalie Glance, and Matthew Hurst. 2007. Patterns of cascading behavior in large blog graphs. In SDM.Google Scholar"",""Xiangang Li and Xihong Wu. 2015. Constructing long short-term memory based deep recurrent neural networks for large vocabulary speech recognition. In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).Google ScholarCross Ref"",""Yang Liu and Yi-Fang Brook Wu. 2018. Early detection of fake news on social media through propagation path classification with recurrent and convolutional networks. In AAAI.Google Scholar"",""Huaishao Luo, Tianrui Li, Bing Liu, Bin Wang, and Herwig Unger. 2018. Improving aspect term extraction with bidirectional dependency tree representation. arXiv preprint arXiv:1805.07889 (2018).Google Scholar"",""Jing Ma, Wei Gao, Prasenjit Mitra, Sejeong Kwon, Bernard J. Jansen, Kam-Fai Wong, and Meeyoung Cha. 2016. Detecting rumors from microblogs with recurrent neural networks. In IJCAI.Google Scholar"",""Jing Ma, Wei Gao, and Kam-Fai Wong. 2018. Rumor detection on Twitter with tree-structured recursive neural networks. In ACL.Google Scholar"",""Makoto Miwa and Mohit Bansal. 2016. End-to-end relation extraction using LSTMs on sequences and tree structures. In ACL.Google Scholar"",""Seth A. Myers and Jure Leskovec. 2014. The bursty dynamics of the Twitter information network. In WWW.Google Scholar"",""Seth A. Myers, Chenguang Zhu, and Jure Leskovec. 2012. Information diffusion and external influence in networks. In KDD. 33--41.Google Scholar"",""Gordon Pennycook, Tyrone D. Cannon, and David G. Rand. 2018. Prior exposure increases perceived accuracy of fake news. Journal of Experimental Psychology. General, Vol. 147, 12 (2018), 1865--1880.Google Scholar"",""Chengcheng Shao, Giovanni Luca Ciampaglia, Alessandro Flammini, and Filippo Menczer. 2016. Hoaxy: A platform for tracking online misinformation. In WWW.Google Scholar"",""Sofus A. Macskassy and Matthew Michelson. 2011. Why do people retweet? Anti-homophily wins the day!. In ICWSM.Google Scholar"",""Karthik Subbian, Aditya B. Prakash, and Lada A. Adamic. 2017. Detecting large reshare cascades in social networks. In WWW.Google Scholar"",""Kai Sheng Tai, Richard Socher, and Christopher D. Manning. 2015. Improved semantic representations from Tree-structured long short-term memory networks. In ACL.Google Scholar"",""Marcella Tambuscio, Giancarlo Ruffo, Alessandro Flammini, and Filippo Menczer. 2015. Fact-checking effect on viral hoaxes: A model of misinformation spread in social networks. In WWW.Google Scholar"",""Io Taxidou and Peter M. Fischer. 2014. Online analysis of information diffusion in Twitter. In WWW.Google Scholar"",""Zhiyang Teng and Yue Zhang. 2017. Head-lexicalized bidirectional Tree LSTMs. Transactions of the Association for Computational Linguistics, Vol. 5, 2 (2017), 163--177.Google ScholarCross Ref"",""The Economist. 2017. How the world was trolled. 9065, Vol. 425 (2017), 21--24.Google Scholar"",""Ivan Tomek. 1976. Two modifications of CNN. IEEE Transactions on Systems, Man, and Cybernetics, Vol. 6, 11 (1976), 769--772.Google Scholar"",""Svitlana Volkova, Kyle Shaffer, Jin Yea Jang, and Nathan Hodas. 2017. Separating facts from fiction: Linguistic models to classify suspicious and trusted news posts on Twitter. In ACL.Google Scholar"",""Soroush Vosoughi. 2015. Automatic detection and verification of rumors on Twitter. Ph.D. Dissertation. Massachusetts Institute of Technology.Google Scholar"",""Soroush Vosoughi, Mostafa `Neo' Mohsenvand, and Deb Roy. 2017. Rumor Gauge: Predicting the veracity of rumors on Twitter. ACM Transactions on Knowledge Discovery from Data, Vol. 11, 4 (2017), 1--36.Google Scholar"",""Soroush Vosoughi, Deb Roy, and Sinan Aral. 2018. The spread of true and false news online. Science, Vol. 359, 6380 (2018), 1146--1151.Google Scholar"",""Przemyslaw M. Waszak, Wioleta Kasprzycka-Waszak, and Alicja Kubanek. 2018. The spread of medical fake news in social media: The pilot quantitative study. Health Policy and Technology, Vol. 7, 2 (2018), 115--118.Google ScholarCross Ref"",""Karol Wegrzycki, Piotr Sankowski, Andrzej Pacuk, and Piotr Wygocki. 2017. Why do cascade sizes follow a power-law?. In WWW.Google Scholar"",""Lilian Weng, Filippo Menczer, and Yong-Yeol Ahn. 2013. Virality prediction and community structure in social networks. Scientific Reports, Vol. 3 (2013), 2522.Google ScholarCross Ref"",""Xianghua Fu, Wangwang Liu, Yingying Xu, Chong Yu, and Ting Wang. 2016. Long short-term memory network over rhetorical structure theory for sentence-level sentiment analysis. In Asian Conference on Machine Learning (ACML).Google Scholar"",""Jaewon Yang and Jure Leskovec. 2010. Modeling information diffusion in implicit networks. In ICDM.Google Scholar"",""Chengxi Zang, Peng Cui, Chaoming Song, Christos Faloutsos, and Wenwu Zhu. 2017. Quantifying structural patterns of information cascades. In WWW.Google Scholar"",""Xiaodan Zhu, Parinaz Sobhani, and Hongyu Guo. 2015. Long short-term memory over recursive structures. In ICML.Google Scholar""]"
https://doi.org/10.1145/3394486.3403318,Personalized Prefix Embedding for POI Auto-Completion in the Search Engine of Baidu Maps,"Point of interest auto-completion (POI-AC) is a featured function in the search engine of many Web mapping services. This function keeps suggesting a dynamic list of POIs as a user types each character, and it can dramatically save the effort of typing, which is quite useful on mobile devices. Existing approaches on POI-AC for industrial use mainly adopt various learning to rank (LTR) models with handcrafted features and even historically clicked POIs are taken into account for personalization. However, these prior arts tend to reach performance bottlenecks as both heuristic features and search history of users cannot directly model personal input habits. In this paper, we present an end-to-end neural-based framework for POI-AC, which has been recently deployed in the search engine of Baidu Maps, one of the largest Web mapping applications with hundreds of millions monthly active users worldwide. In order to establish connections among users, their personal input habits, and correspondingly interested POIs, the proposed framework (abbr. P3AC) is composed of three components, i.e., a multi-layer Bi-LSTM network to adapt to personalized prefixes, a CNN-based network to model multi-sourced information on POIs, and a triplet ranking loss function to optimize both personalized prefix embeddings and distributed representations of POIs. We first use large-scale real-world search logs of Baidu Maps to assess the performance of P3AC offline measured by multiple metrics, including Mean Reciprocal Rank (MRR), Success Rate (SR), and normalized Discounted Cumulative Gain (nDCG). Extensive experimental results demonstrate that it can achieve substantial improvements. Then we decide to launch it online and observe that some other critical indicators on user satisfaction, such as the average number of keystrokes and the average typing speed at keystrokes in a POI-AC session, which significantly decrease as well. In addition, we have released both the source codes of P3AC and the experimental data to the public for reproducibility tests.","[{""name"":""Jizhou Huang"",""id"":""/profile/99659140595""},{""name"":""Haifeng Wang"",""id"":""/profile/99659137977""},{""name"":""Miao Fan"",""id"":""/profile/81548359156""},{""name"":""An Zhuo"",""id"":""/profile/99659479819""},{""name"":""Ying Li"",""id"":""/profile/99659455657""},{""name"":""Jizhou Huang"",""id"":""/profile/99659140595""},{""name"":""Haifeng Wang"",""id"":""/profile/99659137977""},{""name"":""Miao Fan"",""id"":""/profile/81548359156""},{""name"":""An Zhuo"",""id"":""/profile/99659479819""},{""name"":""Ying Li"",""id"":""/profile/99659455657""}]","[""Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural Machine Translation by Jointly Learning to Align and Translate. CoRR, Vol. abs/1409.0473 (2014). arxiv: 1409.0473 http://arxiv.org/abs/1409.0473Google Scholar"",""Ziv Bar-Yossef and Naama Kraus. 2011. Context-sensitive Query Auto-completion. In Proceedings of the 20th International Conference on World Wide Web (WWW '11). ACM, New York, NY, USA, 107--116. https://doi.org/10.1145/1963405.1963424Google ScholarDigital Library"",""Fei Cai and Maarten de Rijke. 2016a. Selectively Personalizing Query Auto-Completion. In Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '16). ACM, New York, NY, USA, 993--996. https://doi.org/10.1145/2911451.2914686Google ScholarDigital Library"",""Fei Cai and Maarten de Rijke. 2016b. A Survey of Query Auto Completion in Information Retrieval. Found. Trends Inf. Retr., Vol. 10, 4 (Sept. 2016), 273--363. https://doi.org/10.1561/1500000055Google ScholarDigital Library"",""Fei Cai, Shangsong Liang, and Maarten de Rijke. 2014. Time-sensitive Personalized Query Auto-Completion. In Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management (CIKM '14). ACM, New York, NY, USA, 1599--1608. https://doi.org/10.1145/2661829.2661921Google ScholarDigital Library"",""Fei Cai, Ridho Reinanda, and Maarten De Rijke. 2016. Diversifying Query Auto-Completion. ACM Transactions on Information Systems (TOIS), Vol. 34, 4, Article 25 (June 2016), bibinfonumpages33 pages. https://doi.org/10.1145/2910579Google ScholarDigital Library"",""V. S. Dandagi and N. Sidnal. 2018. Review on Query Auto-Completion. In 2018 International Conference on Computational Techniques, Electronics and Mechanical Systems. 119--123.Google Scholar"",""Huizhong Duan and Bo-June (Paul) Hsu. 2011. Online Spelling Correction for Query Completion. In Proceedings of the 20th International Conference on World Wide Web (WWW '11). ACM, New York, NY, USA, 117--126. https://doi.org/10.1145/1963405.1963425Google ScholarDigital Library"",""Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long Short-term Memory. Neural computation, Vol. 9, 8 (1997), 1735--1780.Google Scholar"",""Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirectional LSTM-CRF models for sequence tagging. arXiv preprint arXiv:1508.01991 (2015).Google Scholar"",""Muhammad Ibrahim and Mark Carman. 2016. Comparing pointwise and listwise objective functions for random-forest-based learning-to-rank. ACM Transactions on Information Systems (TOIS), Vol. 34, 4 (2016), 20.Google ScholarDigital Library"",""Jyun-Yu Jiang and Pu-Jen Cheng. 2016. Classifying User Search Intents for Query Auto-Completion. In Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval (ICTIR '16). Association for Computing Machinery, New York, NY, USA, 49--58. https://doi.org/10.1145/2970398.2970400Google ScholarDigital Library"",""Manojkumar Rangasamy Kannadasan and Grigor Aslanyan. 2019. Personalized Query Auto-Completion Through a Lightweight Representation of the User Context. In Proceedings of the SIGIR 2019 Workshop on eCommerce, co-located with the 42st International ACM SIGIR Conference on Research and Development in Information Retrieval, [email protected] 2019, Paris, France, July 25, 2019.Google Scholar"",""Yoon Kim. 2014. Convolutional Neural Networks for Sentence Classification. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP'14). Association for Computational Linguistics, Doha, Qatar, 1746--1751. https://doi.org/10.3115/v1/D14-1181Google ScholarCross Ref"",""Yann LeCun, Yoshua Bengio, et almbox. 1995. Convolutional networks for images, speech, and time series. The handbook of brain theory and neural networks, Vol. 3361, 10 (1995), 1995.Google Scholar"",""Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep Learning. Nature, Vol. 521, 7553 (2015), 436--444.Google Scholar"",""Liangda Li, Hongbo Deng, Anlei Dong, Yi Chang, Hongyuan Zha, and Ricardo Baeza-Yates. 2015. Analyzing User's Sequential Behavior in Query Auto-Completion via Markov Processes. In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '15). ACM, New York, NY, USA, 123--132. https://doi.org/10.1145/2766462.2767723Google ScholarDigital Library"",""Ying Li, Jizhou Huang, Miao Fan, Jinyi Lei, Haifeng Wang, and Enhong Chen. 2020. Personalized Query Auto-Completion for Large-Scale POI Search at Baidu Maps. ACM Trans. Asian Low-Resour. Lang. Inf. Process., Vol. 19, 5, Article 70 (May 2020), 16 pages. https://doi.org/10.1145/3394137Google ScholarDigital Library"",""Tie-Yan Liu. 2009. Learning to Rank for Information Retrieval. Foundations and Trends in Information Retrieval, Vol. 3, 3 (March 2009), 225--331.Google Scholar"",""Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013a. Efficient Estimation of Word Representations in Vector Space. arXiv preprint arXiv:1301.3781 (2013).Google Scholar"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013b. Distributed Representations of Words and Phrases and Their Compositionality. In Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 2 (NIPS'13). Curran Associates Inc., USA, 3111--3119.Google ScholarDigital Library"",""Guy M Morton. 1966. A computer oriented geodetic data base and a new technique in file sequencing. Technical Report. International Business Machines Company New York.Google Scholar"",""F. Schroff, D. Kalenichenko, and J. Philbin. 2015. FaceNet: A unified embedding for face recognition and clustering. In 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 815--823. https://doi.org/10.1109/CVPR.2015.7298682Google ScholarCross Ref"",""Mike Schuster and Kuldip K Paliwal. 1997. Bidirectional recurrent neural networks. IEEE Transactions on Signal Processing, Vol. 45, 11 (1997), 2673--2681.Google ScholarDigital Library"",""Milad Shokouhi. 2013. Learning to Personalize Query Auto-completion. In Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '13). ACM, New York, NY, USA, 103--112. https://doi.org/10.1145/2484028.2484076Google ScholarDigital Library"",""Yang Song, Dengyong Zhou, and Li-wei He. 2011. Post-ranking Query Suggestion by Diversifying Search Results. In Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '11). ACM, New York, NY, USA, 815--824. https://doi.org/10.1145/2009916.2010025Google ScholarDigital Library"",""Jiang Wang, Yang Song, Thomas Leung, Chuck Rosenberg, Jingbin Wang, James Philbin, Bo Chen, and Ying Wu. 2014. Learning Fine-Grained Image Similarity with Deep Ranking. In Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition (CVPR '14). IEEE Computer Society, Washington, DC, USA, 1386--1393. https://doi.org/10.1109/CVPR.2014.180Google ScholarDigital Library"",""Stewart Whiting, Andrew James McMinn, and Joemon M Jose. 2013. Exploring Real-Time Temporal Query Auto-Completion. In DIR Workshop. 12--15.Google Scholar"",""Fen Xia, Tie-Yan Liu, Jue Wang, Wensheng Zhang, and Hang Li. 2008. Listwise Approach to Learning to Rank: Theory and Algorithm. In Proceedings of the 25th International Conference on Machine Learning (ICML '08). ACM, New York, NY, USA, 1192--1199. https://doi.org/10.1145/1390156.1390306Google ScholarDigital Library"",""Aston Zhang, Amit Goyal, Weize Kong, Hongbo Deng, Anlei Dong, Yi Chang, Carl A. Gunter, and Jiawei Han. 2015. adaQAC: Adaptive Query Auto-Completion via Implicit Negative Feedback. In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '15). ACM, New York, NY, USA, 143--152. https://doi.org/10.1145/2766462.2767697Google ScholarDigital Library"",""Zhaohui Zheng, Keke Chen, Gordon Sun, and Hongyuan Zha. 2007. A Regression Framework for Learning Ranking Functions Using Relative Relevance Judgments. In Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '07). ACM, New York, NY, USA, 287--294. https://doi.org/10.1145/1277741.1277792Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403319,Category-Specific CNN for Visual-aware CTR Prediction at JD.com,"As one of the largest B2C e-commerce platforms in China, JD.com also powers a leading advertising system, serving millions of advertisers with fingertip connection to hundreds of millions of customers. In our system, as well as most e-commerce scenarios, ads are displayed with images. This makes visual-aware Click Through Rate (CTR) prediction of crucial importance to both business effectiveness and user experience. Existing algorithms usually extract visual features using off-the-shelf Convolutional Neural Networks (CNNs) and late fuse the visual and non-visual features for the finally predicted CTR. Despite being extensively studied, this field still face two key challenges. First, although encouraging progress has been made in offline studies, applying CNNs in real systems remains non-trivial, due to the strict requirements for efficient end-to-end training and low-latency online serving. Second, the off-the-shelf CNNs and late fusion architectures are suboptimal. Specifically, off-the-shelf CNNs were designed for classification thus never take categories as input features. While in e-commerce, categories are precisely labeled and contain abundant visual priors that will help the visual modeling. Unaware of the ad category, these CNNs may extract some unnecessary category-unrelated features, wasting CNN's limited expression ability. To overcome the two challenges, we propose Category-specific CNN (CSCNN) specially for CTR prediction. CSCNN early incorporates the category knowledge with a light-weighted attention-module on each convolutional layer. This enables CSCNN to extract expressive category-specific visual patterns that benefit the CTR prediction. Offline experiments on benchmark and a 10 billion scale real production dataset from JD, together with an Online A/B test show that CSCNN outperforms all compared state-of-the-art algorithms. We also build a highly efficient infrastructure to accomplish end-to-end training with CNN on the 10 billion scale real production dataset within 24 hours, and meet the low latency requirements of online system (20ms on CPU). CSCNN is now deployed in the search advertising system of JD, serving the main traffic of hundreds of millions of active users.","[{""name"":""Hu Liu"",""id"":""/profile/99659573345""},{""name"":""Jing Lu"",""id"":""/profile/99659019247""},{""name"":""Hao Yang"",""id"":""/profile/99659444794""},{""name"":""Xiwei Zhao"",""id"":""/profile/99659573731""},{""name"":""Sulong Xu"",""id"":""/profile/99659573483""},{""name"":""Hao Peng"",""id"":""/profile/99659573482""},{""name"":""Zehua Zhang"",""id"":""/profile/99659574882""},{""name"":""Wenjie Niu"",""id"":""/profile/99659573825""},{""name"":""Xiaokun Zhu"",""id"":""/profile/99659575128""},{""name"":""Yongjun Bao"",""id"":""/profile/99659479096""},{""name"":""Weipeng Yan"",""id"":""/profile/99659478340""},{""name"":""Hu Liu"",""id"":""/profile/99659573345""},{""name"":""Jing Lu"",""id"":""/profile/99659019247""},{""name"":""Hao Yang"",""id"":""/profile/99659444794""},{""name"":""Xiwei Zhao"",""id"":""/profile/99659573731""},{""name"":""Sulong Xu"",""id"":""/profile/99659573483""},{""name"":""Hao Peng"",""id"":""/profile/99659573482""},{""name"":""Zehua Zhang"",""id"":""/profile/99659574882""},{""name"":""Wenjie Niu"",""id"":""/profile/99659573825""},{""name"":""Xiaokun Zhu"",""id"":""/profile/99659575128""},{""name"":""Yongjun Bao"",""id"":""/profile/99659479096""},{""name"":""Weipeng Yan"",""id"":""/profile/99659478340""}]","[""Ken Chatfield, Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. 2014. Return of the devil in the details: Delving deep into convolutional nets. arXiv preprint arXiv:1405.3531 (2014).Google Scholar"",""Junxuan Chen, Baigui Sun, Hao Li, Hongtao Lu, and Xian-Sheng Hua. 2016. Deep ctr prediction in display advertising. In Proceedings of the 24th ACM international conference on Multimedia. ACM, 811--820.Google ScholarDigital Library"",""Long Chen, Hanwang Zhang, Jun Xiao, Liqiang Nie, Jian Shao, Wei Liu, and Tat-Seng Chua. 2017. Sca-cnn: Spatial and channel-wise attention in convolutional networks for image captioning. In Proceedings of the IEEE conference on computer vision and pattern recognition. 5659--5667.Google ScholarCross Ref"",""Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et almbox. 2016. Wide \u0026 deep learning for recommender systems. In Proceedings of the 1st workshop on deep learning for recommender systems. 7--10.Google ScholarDigital Library"",""Zilin Gao, Jiangtao Xie, Qilong Wang, and Peihua Li. 2019. Global Second-order Pooling Convolutional Networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 3024--3033.Google ScholarCross Ref"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016b. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition. 770--778.Google ScholarCross Ref"",""Ruining He, Chunbin Lin, Jianguo Wang, and Julian McAuley. 2016a. Sherlock: sparse hierarchical embeddings for visually-aware one-class collaborative filtering. arXiv preprint arXiv:1604.05813 (2016).Google Scholar"",""Ruining He and Julian McAuley. 2016. VBPR: visual bayesian personalized ranking from implicit feedback. In Thirtieth AAAI Conference on Artificial Intelligence .Google Scholar"",""Xinran He, Junfeng Pan, Ou Jin, Tianbing Xu, Bo Liu, Tao Xu, Yanxin Shi, Antoine Atallah, Ralf Herbrich, Stuart Bowers, et almbox. 2014. Practical lessons from predicting clicks on ads at facebook. In Proceedings of the Eighth International Workshop on Data Mining for Online Advertising. ACM, 1--9.Google ScholarDigital Library"",""Jie Hu, Li Shen, Samuel Albanie, Gang Sun, and Andrea Vedaldi. 2018a. Gather-excite: Exploiting feature context in convolutional neural networks. In Advances in Neural Information Processing Systems. 9401--9411.Google Scholar"",""Jie Hu, Li Shen, and Gang Sun. 2018b. Squeeze-and-excitation networks. In Proceedings of the IEEE conference on computer vision and pattern recognition. 7132--7141.Google ScholarCross Ref"",""Wang-Cheng Kang, Chen Fang, Zhaowen Wang, and Julian McAuley. 2017. Visually-aware fashion recommendation and design with generative image models. In 2017 IEEE International Conference on Data Mining (ICDM). IEEE, 207--216.Google ScholarCross Ref"",""Shuang Li, Tong Xiao, Hongsheng Li, Bolei Zhou, Dayu Yue, and Xiaogang Wang. 2017. Person search with natural language description. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 1970--1979.Google ScholarCross Ref"",""Qiang Liu, Shu Wu, and Liang Wang. 2017. DeepStyle: Learning user preferences for visual recommendation. In Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM, 841--844.Google ScholarDigital Library"",""Jing Lu, Steven Hoi, and Jialei Wang. 2013. Second order online collaborative filtering. In Asian Conference on Machine Learning . 325--340.Google Scholar"",""Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van Den Hengel. 2015. Image-based recommendations on styles and substitutes. In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM, 43--52.Google ScholarDigital Library"",""H Brendan McMahan, Gary Holt, David Sculley, Michael Young, Dietmar Ebner, Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, et almbox. 2013. Ad click prediction: a view from the trenches. In Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 1222--1230.Google ScholarDigital Library"",""Kaixiang Mo, Bo Liu, Lei Xiao, Yong Li, and Jie Jiang. 2015. Image feature learning for cold start problem in display advertising. In Twenty-Fourth International Joint Conference on Artificial Intelligence .Google Scholar"",""Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. [n.d.]. BPR: Bayesian personalized ranking from implicit feedback. In Proceedings of the twenty-fifth conference on uncertainty in artificial intelligence .Google Scholar"",""Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. 2015. Going deeper with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition. 1--9.Google ScholarCross Ref"",""Jialei Wang, Steven CH Hoi, Peilin Zhao, and Zhi-Yong Liu. 2013. Online multi-task collaborative filtering for on-the-fly recommender systems. In Proceedings of the 7th ACM conference on Recommender systems. ACM, 237--244.Google ScholarDigital Library"",""Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. 2017. Deep \u0026 cross network for ad click predictions. In Proceedings of the ADKDD'17. ACM, 12.Google ScholarDigital Library"",""Sanghyun Woo, Jongchan Park, Joon-Young Lee, and In So Kweon. 2018. Cbam: Convolutional block attention module. In Proceedings of the European Conference on Computer Vision (ECCV). 3--19.Google ScholarCross Ref"",""Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhudinov, Rich Zemel, and Yoshua Bengio. 2015. Show, attend and tell: Neural image caption generation with visual attention. In International conference on machine learning. 2048--2057.Google ScholarDigital Library"",""Xiao Yang, Tao Deng, Weihan Tan, Xutian Tao, Junwei Zhang, Shouke Qin, and Zongyao Ding. 2019. Learning Compositional, Visual and Relational Representations for CTR Prediction in Sponsored Search. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management . 2851--2859.Google ScholarDigital Library"",""Zichao Yang, Xiaodong He, Jianfeng Gao, Li Deng, and Alex Smola. 2016. Stacked attention networks for image question answering. In Proceedings of the IEEE conference on computer vision and pattern recognition. 21--29.Google ScholarCross Ref"",""Zhichen Zhao, Lei Li, Bowen Zhang, Meng Wang, Yuning Jiang, Li Xu, Fengkun Wang, and Weiying Ma. 2019. What You Look Matters? Offline Evaluation of Advertising Creatives for Cold-start Problem. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management . 2605--2613.Google Scholar""]"
https://doi.org/10.1145/3394486.3403320,ConSTGAT: Contextual Spatial-Temporal Graph Attention Network for Travel Time Estimation at Baidu Maps,"The task of travel time estimation (TTE), which estimates the travel time for a given route and departure time, plays an important role in intelligent transportation systems such as navigation, route planning, and ride-hailing services. This task is challenging because of many essential aspects, such as traffic prediction and contextual information. First, the accuracy of traffic prediction is strongly correlated with the traffic speed of the road segments in a route. Existing work mainly adopts spatial-temporal graph neural networks to improve the accuracy of traffic prediction, where spatial and temporal information is used separately. However, one drawback is that the spatial and temporal correlations are not fully exploited to obtain better accuracy. Second, contextual information of a route, i.e., the connections of adjacent road segments in the route, is an essential factor that impacts the driving speed. Previous work mainly uses sequential encoding models to address this issue. However, it is difficult to scale up sequential models to large-scale real-world services. In this paper, we propose an end-to-end neural framework named ConSTGAT, which integrates traffic prediction and contextual information to address these two problems. Specifically, we first propose a spatial-temporal graph neural network that adopts a novel graph attention mechanism, which is designed to fully exploit the joint relations of spatial and temporal information. Then, in order to efficiently take advantage of the contextual information, we design a computationally efficient model that applies convolutions over local windows to capture a route's contextual information and further employs multi-task learning to improve the performance. In this way, the travel time of each road segment can be computed in parallel and in advance. Extensive experiments conducted on large-scale real-world datasets demonstrate the superiority of ConSTGAT. In addition, ConSTGAT has already been deployed in production at Baidu Maps, and it successfully keeps serving tens of billions of requests every day. This confirms that ConSTGAT is a practical and robust solution for large-scale real-world TTE services.","[{""name"":""Xiaomin Fang"",""id"":""/profile/99659574848""},{""name"":""Jizhou Huang"",""id"":""/profile/99659140595""},{""name"":""Fan Wang"",""id"":""/profile/99659573679""},{""name"":""Lingke Zeng"",""id"":""/profile/99659573894""},{""name"":""Haijin Liang"",""id"":""/profile/99659574494""},{""name"":""Haifeng Wang"",""id"":""/profile/99659137977""},{""name"":""Xiaomin Fang"",""id"":""/profile/99659574848""},{""name"":""Jizhou Huang"",""id"":""/profile/99659140595""},{""name"":""Fan Wang"",""id"":""/profile/99659573679""},{""name"":""Lingke Zeng"",""id"":""/profile/99659573894""},{""name"":""Haijin Liang"",""id"":""/profile/99659574494""},{""name"":""Haifeng Wang"",""id"":""/profile/99659137977""}]","[""Pouria Amirian, Anahid Basiri, and Jeremy Morley. 2016. Predictive analytics for enhancing travel time estimation in navigation apps of Apple, Google, and Microsoft. In Proceedings of SIGSPATIAL. 31--36.Google ScholarDigital Library"",""Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural Machine Translation by Jointly Learning to Align and Translate. In Proceedings of ICLR.Google Scholar"",""Michael Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolutional neural networks on graphs with fast localized spectral filtering. In Proceedings of NIPS. 3844--3852.Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of NAACL. 4171--4186.Google Scholar"",""Marco Gori, Gabriele Monfardini, and Franco Scarselli. 2005. A new model for learning in graph domains. In Proceedings of IJCNN. 729--734.Google ScholarCross Ref"",""Shengnan Guo, Youfang Lin, Ning Feng, Chao Song, and Huaiyu Wan. 2019. Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting. In Proceedings of AAAI. 922--929.Google ScholarCross Ref"",""Zhixiang He, Chi-Yin Chow, and Jia-Dong Zhang. 2018. STANN: A Spatio--Temporal Attentive Neural Network for Traffic Prediction. IEEE Access, Vol. 7 (2018), 4795--4806.Google ScholarCross Ref"",""Peter J. Huber. 1964. Robust Estimation of a Location Parameter. Annals of Mathematical Statistics, Vol. 35, 1 (1964), 73--101.Google ScholarCross Ref"",""Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012. ImageNet Classification with Deep Convolutional Neural Networks. In Proceedings of NIPS. 1097--1105.Google Scholar"",""Yaguang Li, Kun Fu, Zheng Wang, Cyrus Shahabi, Jieping Ye, and Yan Liu. 2018a. Multi-task representation learning for travel time estimation. In Proceedings of KDD. 1695--1704.Google ScholarDigital Library"",""Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. 2018b. Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting. In Proceedings of ICLR.Google Scholar"",""David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. 1985. Learning internal representations by error propagation. Technical Report. California Univ San Diego La Jolla Inst for Cognitive Science.Google Scholar"",""Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. 2008. The graph neural network model. IEEE Transactions on Neural Networks, Vol. 20, 1 (2008), 61--80.Google ScholarDigital Library"",""Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2018a. Graph Attention Networks. In Proceedings of ICLR. https://openreview.net/forum?id=rJXMpikCZGoogle Scholar"",""Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2018b. Graph Attention Networks. In Proceedings of ICLR.Google Scholar"",""Dong Wang, Junbo Zhang, Wei Cao, Jian Li, and Yu Zheng. 2018b. When Will You Arrive? Estimating Travel Time Based on Deep Neural Networks. In Proceedings of AAAI. 2500--2507.Google Scholar"",""Hongjian Wang, Xianfeng Tang, Yu-Hsuan Kuo, Daniel Kifer, and Zhenhui Li. 2019. A Simple Baseline for Travel Time Estimation Using Large-scale Trip Data. ACM Transactions on Intelligent Systems and Technology (TIST), Vol. 10, 2, Article 19 (2019), 22 pages.Google Scholar"",""Yilun Wang, Yu Zheng, and Yexiang Xue. 2014. Travel time estimation of a path using sparse trajectories. In Proceedings of KDD. 25--34.Google ScholarDigital Library"",""Zheng Wang, Kun Fu, and Jieping Ye. 2018a. Learning to estimate the travel time. In Proceedings of KDD. 858--866.Google ScholarDigital Library"",""Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and Philip S Yu. 2019. A comprehensive survey on graph neural networks. arXiv preprint arXiv:1901.00596 (2019).Google Scholar"",""Bing Yu, Mengzhang Li, Jiyong Zhang, and Zhanxing Zhu. 2019. 3D Graph Convolutional Networks with Temporal Graphs: A Spatial Information Free Framework For Traffic Forecasting. arXiv preprint arXiv:1903.00919 (2019).Google Scholar"",""Bing Yu, Haoteng Yin, and Zhanxing Zhu. 2018. Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting. In Proceedings of IJCAI. 3634--3640.Google ScholarCross Ref"",""Hanyuan Zhang, Hao Wu, Weiwei Sun, and Baihua Zheng. 2018b. DeepTravel: a Neural Network Based Travel Time Estimation Model with Auxiliary Supervision. In Proceedings of IJCAI. 3655--3661.Google ScholarCross Ref"",""Jiani Zhang, Xingjian Shi, Junyuan Xie, Hao Ma, Irwin King, and Dit-Yan Yeung. 2018a. GaAN: Gated Attention Networks for Learning on Large and Spatiotemporal Graphs. In Proceedings of UAI. 339--349.Google Scholar""]"
https://doi.org/10.1145/3394486.3403321,Faster Secure Data Mining via Distributed Homomorphic Encryption,"Due to the rising privacy demand in data mining, Homomorphic Encryption (HE) is receiving more and more attention recently for its capability to do computations over the encrypted field. By using the HE technique, it is possible to securely outsource model learning to the not fully trustful but powerful public cloud computing environments. However, HE-based training scales badly because of the high computation complexity. It is still an open problem whether it is possible to apply HE to large-scale problems. In this paper, we propose a novel general distributed HE-based data mining framework towards one step of solving the scaling problem. The main idea of our approach is to use the slightly more communication overhead in exchange of shallower computational circuit in HE, so as to reduce the overall complexity. We verify the efficiency and effectiveness of our new framework by testing over various data mining algorithms and benchmark data-sets. For example, we successfully train a logistic regression model to recognize the digit 3 and 8 within around 5 minutes, while a centralized counterpart needs almost 2 hours.","[{""name"":""Junyi Li"",""id"":""/profile/99659574970""},{""name"":""Heng Huang"",""id"":""/profile/99659523758""},{""name"":""Junyi Li"",""id"":""/profile/99659574970""},{""name"":""Heng Huang"",""id"":""/profile/99659523758""}]","[""Yoshinori Aono, Takuya Hayashi, Le Trieu Phong, and Lihua Wang. 2016. Scalable and secure logistic regression via homomorphic encryption. In Proceedings of the Sixth ACM Conference on Data and Application Security and Privacy. 142--144.Google ScholarDigital Library"",""Charlotte Bonte and Frederik Vercauteren. 2018. Privacy-preserving logistic regression training. BMC medical genomics, Vol. 11, 4 (2018), 86.Google Scholar"",""Zvika Brakerski, Craig Gentry, and Vinod Vaikuntanathan. 2014. (Leveled) fully homomorphic encryption without bootstrapping. ACM Transactions on Computation Theory (TOCT), Vol. 6, 3 (2014), 1--36.Google ScholarDigital Library"",""Zvika Brakerski and Vinod Vaikuntanathan. 2011. Fully homomorphic encryption from ring-LWE and security for key dependent messages. In Annual cryptology conference. Springer, 505--524.Google ScholarDigital Library"",""Zvika Brakerski and Vinod Vaikuntanathan. 2014. Efficient fully homomorphic encryption from (standard) LWE. SIAM J. Comput., Vol. 43, 2 (2014), 831--871.Google ScholarCross Ref"",""Alon Brutzkus, Oren Elisha, and Ran Gilad-Bachrach. 2018. Low latency privacy preserving inference. arXiv preprint arXiv:1812.10659 (2018).Google Scholar"",""Sebastian Caldas, Peter Wu, Tian Li, Jakub Konevc nỳ, H Brendan McMahan, Virginia Smith, and Ameet Talwalkar. 2018. Leaf: A benchmark for federated settings. arXiv preprint arXiv:1812.01097 (2018).Google Scholar"",""Sergiu Carpov, Nicolas Gama, Mariya Georgieva, and Juan Ramón Troncoso-Pastoriza. 2019. Privacy-preserving semi-parallel logistic regression training with Fully Homomorphic Encryption. IACR Cryptology ePrint Archive, Vol. 2019 (2019), 101.Google Scholar"",""Ratnakumari Challa. 2020. Homomorphic Encryption: Review and Applications. In Advances in Data Science and Management. Springer, 273--281.Google Scholar"",""David Champagne and Ruby B Lee. 2010. Scalable architectural support for trusted software. In HPCA-16 2010 The Sixteenth International Symposium on High-Performance Computer Architecture. IEEE, 1--12.Google ScholarCross Ref"",""Kewei Cheng, Tao Fan, Yilun Jin, Yang Liu, Tianjian Chen, and Qiang Yang. 2019. Secureboost: A lossless federated learning framework. arXiv preprint arXiv:1901.08755 (2019).Google Scholar"",""Jung Hee Cheon, Andrey Kim, Miran Kim, and Yongsoo Song. 2017. Homomorphic encryption for arithmetic of approximate numbers. In International Conference on the Theory and Application of Cryptology and Information Security. Springer, 409--437.Google ScholarCross Ref"",""Jung Hee Cheon, Duhyeong Kim, Yongdai Kim, and Yongsoo Song. 2018. Ensemble method for privacy-preserving logistic regression based on homomorphic encryption. IEEE Access, Vol. 6 (2018), 46938--46948.Google ScholarCross Ref"",""Jung Hee Cheon, Duhyeong Kim, and Jai Hyun Park. 2019. Towards a practical cluster analysis over encrypted data. In International Conference on Selected Areas in Cryptography. Springer, 227--249.Google Scholar"",""Jack LH Crawford, Craig Gentry, Shai Halevi, Daniel Platt, and Victor Shoup. 2018. Doing real work with FHE: the case of logistic regression. In Proceedings of the 6th Workshop on Encrypted Computing \u0026 Applied Homomorphic Cryptography. 1--12.Google ScholarDigital Library"",""Cynthia Dwork. 2008. Differential privacy: A survey of results. In International conference on theory and applications of models of computation. Springer, 1--19.Google ScholarDigital Library"",""Cynthia Dwork, Aaron Roth, et almbox. 2014. The algorithmic foundations of differential privacy. Foundations and Trends® in Theoretical Computer Science, Vol. 9, 3--4 (2014), 211--407.Google Scholar"",""Jerome Friedman, Trevor Hastie, and Robert Tibshirani. 2001. The elements of statistical learning. Vol. 1. Springer series in statistics New York.Google Scholar"",""Craig Gentry. 2009. A fully homomorphic encryption scheme. Vol. 20. Stanford university Stanford.Google Scholar"",""Ran Gilad-Bachrach, Nathan Dowlin, Kim Laine, Kristin Lauter, Michael Naehrig, and John Wernsing. 2016. Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy. In International Conference on Machine Learning. 201--210.Google ScholarDigital Library"",""Richard L Graham, Timothy S Woodall, and Jeffrey M Squyres. 2005. Open MPI: A flexible high performance MPI. In International Conference on Parallel Processing and Applied Mathematics. Springer, 228--239.Google Scholar"",""Kyoohyung Han, Seungwan Hong, Jung Hee Cheon, and Daejun Park. 2018. Efficient Logistic Regression on Large Encrypted Data. IACR Cryptology ePrint Archive, Vol. 2018 (2018), 662.Google Scholar"",""Stephen Hardy, Wilko Henecka, Hamish Ivey-Law, Richard Nock, Giorgio Patrini, Guillaume Smith, and Brian Thorne. 2017. Private federated learning on vertically partitioned data via entity resolution and additively homomorphic encryption. arXiv preprint arXiv:1711.10677 (2017).Google Scholar"",""Angela Jäschke and Frederik Armknecht. 2018. Unsupervised machine learning on encrypted data. In International Conference on Selected Areas in Cryptography. Springer, 453--478.Google Scholar"",""Xiaoqian Jiang, Miran Kim, Kristin Lauter, and Yongsoo Song. 2018. Secure outsourced matrix computation and application to neural networks. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security. 1209--1222.Google ScholarDigital Library"",""Chiraag Juvekar, Vinod Vaikuntanathan, and Anantha Chandrakasan. 2018. $$GAZELLE$$: A low latency framework for secure neural network inference. In 27th {USENIX} Security Symposium ({USENIX} Security 18). 1651--1669.Google Scholar"",""Jakub Konevc nỳ , H Brendan McMahan, Daniel Ramage, and Peter Richtárik. 2016a. Federated optimization: Distributed machine learning for on-device intelligence. arXiv preprint arXiv:1610.02527 (2016).Google Scholar"",""Jakub Konevc nỳ, H Brendan McMahan, Felix X Yu, Peter Richtárik, Ananda Theertha Suresh, and Dave Bacon. 2016b. Federated learning: Strategies for improving communication efficiency. arXiv preprint arXiv:1610.05492 (2016).Google Scholar"",""Frank McKeen, Ilya Alexandrovich, Alex Berenzon, Carlos V Rozas, Hisham Shafi, Vedvyas Shanbhogue, and Uday R Savagaonkar. 2013. Innovative instructions and software model for isolated execution. [email protected] isca, Vol. 10, 1 (2013).Google Scholar"",""Pradeep Kumar Mishra, Deevashwer Rathee, Dung Hoang Duong, and Masaya Yasuda. 2018. Fast Secure Matrix Multiplications over Ring-Based Homomorphic Encryption. IACR Cryptology ePrint Archive, Vol. 2018 (2018), 663.Google Scholar"",""Pascal Paillier. 1999. Public-key cryptosystems based on composite degree residuosity classes. In International conference on the theory and applications of cryptographic techniques. Springer, 223--238.Google ScholarDigital Library"",""Protection Regulation. 2016. Regulation (EU) 2016/679 of the European Parliament and of the Council. REGULATION (EU), Vol. 679 (2016), 2016.Google Scholar"",""Dalia Tourky, Mohamed ElKawkagy, and Arabi Keshk. 2016. Homomorphic encryption the ?holy grail\"" of cryptography. In 2016 2nd IEEE International Conference on Computer and Communications (ICCC). IEEE, 196--201.Google ScholarCross Ref"",""Marten Van Dijk, Craig Gentry, Shai Halevi, and Vinod Vaikuntanathan. 2010. Fully homomorphic encryption over the integers. In Annual International Conference on the Theory and Applications of Cryptographic Techniques. Springer, 24--43.Google Scholar"",""Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. 2019. Federated machine learning: Concept and applications. ACM Transactions on Intelligent Systems and Technology (TIST), Vol. 10, 2 (2019), 1--19.Google ScholarDigital Library"",""Andrew Chi-Chih Yao. 1986. How to generate and exchange secrets. In 27th Annual Symposium on Foundations of Computer Science (sfcs 1986). IEEE, 162--167.Google Scholar"",""Chenzhuo Zhu, Song Han, Huizi Mao, and William J Dally. 2016. Trained ternary quantization. arXiv preprint arXiv:1612.01064 (2016).Google Scholar""]"
https://doi.org/10.1145/3394486.3403322,Contagious Chain Risk Rating for Networked-guarantee Loans,"The small and medium-sized enterprises (SMEs) are allowed to guarantee each other and form complex loan networks to receive loans from banks during the economic expansion stage. However, external shocks may weaken the robustness, and an accidental default may spread across the network and lead to large-scale defaults, even systemic crisis. Thus, predicting and rating the default contagion chains in the guarantee network in order to reduce or prevent potential systemic financial risk, attracts a grave concern from the Regulatory Authority and the banks. Existing credit risk models in the banking industry utilize machine learning methods to generate a credit score for each customer. Such approaches dismiss the contagion risk from guarantee chains and need extensive feature engineering with deep domain expertise. To this end, we propose a novel approach to rate the risk of contagion chains in the bank industry with the deep neural network. We employed the temporal inter-chain attention network on graph-structured loan behavior data to compute risk scores for the contagion chains. We show that our approach is significantly better than the state-of-the-art baselines on the dataset from a major financial institution in Asia. Besides, we conducted empirical studies on the real-world loan dataset for risk assessment. The proposed approach enabled loan managers to monitor risks in a boarder view and avoid significant financial losses for the financial institution.","[{""name"":""Dawei Cheng"",""id"":""/profile/99659471993""},{""name"":""Zhibin Niu"",""id"":""/profile/99659472151""},{""name"":""Yiyi Zhang"",""id"":""/profile/99659480021""},{""name"":""Dawei Cheng"",""id"":""/profile/99659471993""},{""name"":""Zhibin Niu"",""id"":""/profile/99659472151""},{""name"":""Yiyi Zhang"",""id"":""/profile/99659480021""}]","[""Eliana Angelini, Giacomo di Tollo, and Andrea Roli. 2008. A neural network approach for credit risk evaluation. The quarterly review of economics and finance , Vol. 48, 4 (2008), 733--755.Google Scholar"",""Baruch Awerbuch. 1985. Complexity of network synchronization. Journal of the ACM (JACM) , Vol. 32, 4 (1985), 804--823.Google ScholarDigital Library"",""Dmitrii Babaev, Maxim Savchenko, Alexander Tuzhilin, and Dmitrii Umerenkov. 2019. E.T.-RNN: Applying Deep Learning to Credit Loan Applications. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining . 2183--2190.Google ScholarDigital Library"",""Bart Baesens, Rudy Setiono, Christophe Mues, and Jan Vanthienen. 2003. Using neural network rule extraction and decision tables for credit-risk evaluation. Management science , Vol. 49, 3 (2003), 312--329.Google Scholar"",""Adrià Barja, Alejandro Mart'inez, Alex Arenas, Pablo Fleurquin, Jordi Nin, José J Ramasco, and Elena Tomás. 2019. Assessing the risk of default propagation in interconnected sectoral financial networks. EPJ Data Science , Vol. 8, 1 (2019), 32.Google ScholarCross Ref"",""Diana Bonfim. 2009. Credit risk drivers: Evaluating the contribution of firm level information and of macroeconomic dynamics. Journal of Banking \u0026 Finance , Vol. 33, 2 (2009), 281--299.Google ScholarCross Ref"",""Cristián Bravo, Lyn C Thomas, and Richard Weber. 2015. Improving credit scoring by differentiating defaulter behaviour. Journal of the Operational Research Society , Vol. 66, 5 (2015), 771--781.Google ScholarCross Ref"",""Markus K Brunnermeier and Martin Oehmke. 2012. Bubbles, financial crises, and systemic risk . Technical Report. National Bureau of Economic Research.Google Scholar"",""C Bayan Bruss, Anish Khazane, Jonathan Rider, Richard Serpe, Antonia Gogoglou, and Keegan E Hines. 2019. Deeptrax: Embedding graphs of financial transactions. arXiv preprint arXiv:1907.07225 (2019).Google Scholar"",""Mark Carey, Anil Kashyap, Raghuram Rajan, and René Stulz. 2012. Market Institutions and Financial Market Risk .Elsevier, Journal of Financial Economics. http://www.nber.org/books/care10--1Google Scholar"",""Dawei Cheng, Yi Tu, Zhenwei Ma, Zhibin Niu, and Liqing Zhang. 2019 a. Risk assessment for networked-guarantee loans using high-order graph attention representation. In Proceedings of the 28th International Joint Conference on Artificial Intelligence. AAAI Press, 5822--5828.Google ScholarCross Ref"",""Dawei Cheng, Sheng Xiang, Chencheng Shang, Yiyi Zhang, Fangzhou Yang, and Liqing Zhang. 2020. Spatio-Temporal Attention-Based Neural Network for Credit Card Fraud Detection. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 34. 362--369.Google ScholarCross Ref"",""Dawei Cheng, Yiyi Zhang, Fangzhou Yang, Yi Tu, Zhibin Niu, and Liqing Zhang. 2019 b. A Dynamic Default Prediction Framework for Networked-guarantee Loans. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management . 2547--2555.Google ScholarDigital Library"",""Junyoung Chung, Caglar Gulcehre, Kyunghyun Cho, and Yoshua Bengio. 2014. Empirical evaluation of gated recurrent neural networks on sequence modeling. In NIPS 2014 Workshop on Deep Learning, December 2014 .Google Scholar"",""Rama Cont, Amal Moussa, et almbox. 2010. Network structure and systemic risk in banking systems. Edson Bastos e, Network Structure and Systemic Risk in Banking Systems (December 1, 2010) (2010).Google Scholar"",""Rama Cont, Amal Moussa, Andreea Minca, and Edson Basto. 2009. Too interconnected to fail: contagion and systemic risk in financial networks. Lecture presented at the IMF, May (2009).Google Scholar"",""Elena Dumitrescu, Sullivan Hue, Christophe Hurlin, and Sessi Tokpavi. 2018. Machine Learning for Credit Scoring: Improving Logistic Regression with Non Linear Decision Tree Effects. (2018).Google Scholar"",""Eva Maria Falkner and Martin RW Hiebl. 2015. Risk management in SMEs: a systematic review of available evidence. The Journal of Risk Finance , Vol. 16, 2 (2015), 122--144.Google ScholarCross Ref"",""Gerhard H Fischer and Ivo W Molenaar. 2012. Rasch models: Foundations, recent developments, and applications .Springer Science \u0026 Business Media.Google Scholar"",""Trevor Fitzpatrick and Christophe Mues. 2016. An empirical comparison of classification algorithms for mortgage default prediction: evidence from a distressed mortgage market. European Journal of Operational Research , Vol. 249, 2 (2016), 427--439.Google ScholarCross Ref"",""Jean-Pierre Fouque and Joseph A Langsam. 2013. Handbook on systemic risk .Cambridge University Press.Google Scholar"",""Cheng-Lung Huang, Mu-Chen Chen, and Chieh-Jen Wang. 2007. Credit scoring with a data mining approach based on support vector machines. Expert systems with applications , Vol. 33, 4 (2007), 847--856.Google Scholar"",""Maximilian Jager, Thomas Siemsen, and Johannes Vilsmeier. 2020. Interbank Risk Assessment--A Simulation Approach. (2020).Google Scholar"",""Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. 2017. Lightgbm: A highly efficient gradient boosting decision tree. In NeurIPS . 3146--3154.Google Scholar"",""Amir E Khandani, Adlar J Kim, and Andrew W Lo. 2010. Consumer credit-risk models via machine-learning algorithms. Journal of Banking \u0026 Finance , Vol. 34, 11 (2010), 2767--2787.Google ScholarCross Ref"",""Diederik P Kingma and Jimmy Lei Ba. 2014. Adam: Amethod for stochastic optimization. In Proc. 3rd Int. Conf. Learn. Representations .Google Scholar"",""Erkki K Laitinen. 1999. Predicting a corporate credit analyst's risk estimate by logistic and linear models. International review of financial analysis , Vol. 8, 2 (1999), 97--121.Google Scholar"",""Alejandro Mart'inez, Jordi Nin, Elena Tomás, and Alberto Rubio. 2019. Graph convolutional networks on customer/supplier graph data to improve default prediction. In International Workshop on Complex Networks . Springer, 135--146.Google ScholarCross Ref"",""Geoff N Masters. 1982. A Rasch model for partial credit scoring. Psychometrika , Vol. 47, 2 (1982), 149--174.Google ScholarCross Ref"",""H Brendan McMahan. 2011. Follow-the-regularized-leader and mirror descent: Equivalence theorems and l1 regularization. (2011).Google Scholar"",""Xinhai Liu Xiangfeng Meng. 2015. Credit risk evaluation for loan guarantee chain in China. (2015).Google Scholar"",""Atif Mian and Amir Sufi. 2009. The consequences of mortgage credit expansion: Evidence from the US mortgage default crisis. The Quarterly Journal of Economics , Vol. 124, 4 (2009), 1449--1496.Google ScholarCross Ref"",""Yabo Ni, Dan Ou, Shichen Liu, Xiang Li, Wenwu Ou, Anxiang Zeng, and Luo Si. 2018. Perceive your users in depth: Learning universal user representations from multiple e-commerce tasks. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining . 596--605.Google ScholarDigital Library"",""Zhibin Niu, Dawei Cheng, Liqing Zhang, and Jiawan Zhang. 2018. Visual analytics for networked-guarantee loans risk management. In 2018 IEEE Pacific Visualization Symposium (PacificVis). IEEE, 160--169.Google ScholarCross Ref"",""Fei Tan, Xiurui Hou, Jie Zhang, Zhi Wei, and Zhenyu Yan. 2018. A deep learning approach to competing risks representation in peer-to-peer lending. IEEE transactions on neural networks and learning systems (2018).Google Scholar"",""Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2018. Graph attention networks. In ICLR .Google Scholar""]"
https://doi.org/10.1145/3394486.3403323,AutoKnow: Self-Driving Knowledge Collection for Products of Thousands of Types,"Can one build a knowledge graph (KG) for all products in the world? Knowledge graphs have firmly established themselves as valuable sources of information for search and question answering, and it is natural to wonder if a KG can contain information about products offered at online retail sites. There have been several successful examples of generic KGs, but organizing information about products poses many additional challenges, including sparsity and noise of structured data for products, complexity of the domain with millions of product types and thousands of attributes, heterogeneity across large number of categories, as well as large and constantly growing number of products.We describe AutoKnow, our automatic (self-driving) system that addresses these challenges. The system includes a suite of novel techniques for taxonomy construction, product property identification, knowledge extraction, anomaly detection, and synonym discovery. AutoKnow is (a) automatic, requiring little human intervention, (b) multi-scalable, scalable in multiple dimensions (many domains, many products, and many attributes), and (c) integrative, exploiting rich customer behavior logs. AutoKnow has been operational in collecting product knowledge for over 11K product types.","[{""name"":""Xin Luna Dong"",""id"":""/profile/99659531494""},{""name"":""Xiang He"",""id"":""/profile/99659574937""},{""name"":""Andrey Kan"",""id"":""/profile/81548396856""},{""name"":""Xian Li"",""id"":""/profile/99659462223""},{""name"":""Yan Liang"",""id"":""/profile/99659575079""},{""name"":""Jun Ma"",""id"":""/profile/99659573982""},{""name"":""Yifan Ethan Xu"",""id"":""/profile/99659461704""},{""name"":""Chenwei Zhang"",""id"":""/profile/99659574421""},{""name"":""Tong Zhao"",""id"":""/profile/99659452891""},{""name"":""Gabriel Blanco Saldana"",""id"":""/profile/99659574921""},{""name"":""Saurabh Deshpande"",""id"":""/profile/99659573634""},{""name"":""Alexandre Michetti Manduca"",""id"":""/profile/99659574407""},{""name"":""Jay Ren"",""id"":""/profile/99659574760""},{""name"":""Surender Pal Singh"",""id"":""/profile/99659574143""},{""name"":""Fan Xiao"",""id"":""/profile/99659575096""},{""name"":""Haw-Shiuan Chang"",""id"":""/profile/99659325039""},{""name"":""Giannis Karamanolakis"",""id"":""/profile/99659314175""},{""name"":""Yuning Mao"",""id"":""/profile/99659574589""},{""name"":""Yaqing Wang"",""id"":""/profile/99659286574""},{""name"":""Christos Faloutsos"",""id"":""/profile/81100373169""},{""name"":""Andrew McCallum"",""id"":""/profile/81339516345""},{""name"":""Jiawei Han"",""id"":""/profile/81548005096""},{""name"":""Xin Luna Dong"",""id"":""/profile/99659531494""},{""name"":""Xiang He"",""id"":""/profile/99659574937""},{""name"":""Andrey Kan"",""id"":""/profile/81548396856""},{""name"":""Xian Li"",""id"":""/profile/99659462223""},{""name"":""Yan Liang"",""id"":""/profile/99659575079""},{""name"":""Jun Ma"",""id"":""/profile/99659573982""},{""name"":""Yifan Ethan Xu"",""id"":""/profile/99659461704""},{""name"":""Chenwei Zhang"",""id"":""/profile/99659574421""},{""name"":""Tong Zhao"",""id"":""/profile/99659452891""},{""name"":""Gabriel Blanco Saldana"",""id"":""/profile/99659574921""},{""name"":""Saurabh Deshpande"",""id"":""/profile/99659573634""},{""name"":""Alexandre Michetti Manduca"",""id"":""/profile/99659574407""},{""name"":""Jay Ren"",""id"":""/profile/99659574760""},{""name"":""Surender Pal Singh"",""id"":""/profile/99659574143""},{""name"":""Fan Xiao"",""id"":""/profile/99659575096""},{""name"":""Haw-Shiuan Chang"",""id"":""/profile/99659325039""},{""name"":""Giannis Karamanolakis"",""id"":""/profile/99659314175""},{""name"":""Yuning Mao"",""id"":""/profile/99659574589""},{""name"":""Yaqing Wang"",""id"":""/profile/99659286574""},{""name"":""Christos Faloutsos"",""id"":""/profile/81100373169""},{""name"":""Andrew McCallum"",""id"":""/profile/81339516345""},{""name"":""Jiawei Han"",""id"":""/profile/81548005096""}]","[""Ziawasch Abedjan, Xu Chu, Dong Deng, Raul Castro Fernandez, Ihab F Ilyas, Mourad Ouzzani, Paolo Papotti, Michael Stonebraker, and Nan Tang. 2016. Detecting data errors: Where are we and what needs to be done? Proceedings of the VLDB Endowment, Vol. 9, 12 (2016), 993--1004.Google ScholarDigital Library"",""Mohit Bansal, David Burkett, Gerard De Melo, and Dan Klein. 2014. Structured Learning for Taxonomy Induction with Belief Propagation.. In ACL.Google Scholar"",""Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. Enriching word vectors with subword information. TACL, Vol. 5 (2017), 135--146.Google ScholarCross Ref"",""Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: a collaboratively created graph database for structuring human knowledge. In Sigmod. AcM, 1247--1250.Google Scholar"",""Georgeta Bordea, Els Lefever, and Paul Buitelaar. 2016. Semeval-2016 task 13: Taxonomy extraction evaluation (texeval-2). In SemEval-2016. 1081--1091.Google Scholar"",""Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr Settles, Estevam R Hruschka Jr, and Tom M Mitchell. 2010. Toward an architecture for never-ending language learning.. In AAAI, Vol. 5. Atlanta, 3.Google ScholarDigital Library"",""Christopher De Sa, Alex Ratner, Christopher Ré, Jaeho Shin, Feiran Wang, Sen Wu, and Ce Zhang. 2016. Deepdive: Declarative knowledge base construction. ACM SIGMOD Record, Vol. 45, 1 (2016), 60--67.Google ScholarDigital Library"",""Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Ni Lao, Kevin Murphy, Thomas Strohmann, Shaohua Sun, and Wei Zhang. 2014a. Knowledge vault: A web-scale approach to probabilistic knowledge fusion. In SigKDD. ACM, 601--610.Google Scholar"",""Xin Luna Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Kevin Murphy, Shaohua Sun, and Wei Zhang. 2014b. From Data Fusion to Knowledge Fusion. PVLDB (2014).Google Scholar"",""MS Fabian, K Gjergji, Weikum Gerhard, et almbox. 2007. Yago: A core of semantic knowledge unifying wordnet and wikipedia. In WWW. 697--706.Google Scholar"",""Tim Furche, Georg Gottlob, Giovanni Grasso, Omer Gunes, Xiaoanan Guo, Andrey Kravchenko, Giorgio Orsi, Christian Schallhart, Andrew Sellers, and Cheng Wang. 2012. DIADEM: domain-centric, intelligent, automated data extraction methodology. In WWW. ACM, 267--270.Google Scholar"",""Yuqing Gao, Jisheng Liang, Benjamin Han, Mohamed Yakout, and Ahmed Mohamed. 2018. Building a large-scale, accurate and fresh knowledge graph. In SigKDD.Google Scholar"",""Pankaj Gulhane, Amit Madaan, Rupesh Mehta, Jeyashankher Ramamirtham, Rajeev Rastogi, Sandeep Satpal, Srinivasan H Sengamedu, Ashwin Tengli, and Charu Tiwari. 2011. Web-scale information extraction with Vertex. In ICDE. 1209--1220.Google Scholar"",""Johannes Hoffart, Fabian M Suchanek, Klaus Berberich, and Gerhard Weikum. 2013. YAGO2: A spatially and temporally enhanced knowledge base from Wikipedia. Artificial Intelligence, Vol. 194 (2013), 28--61.Google ScholarDigital Library"",""Andrew Hopkinson, Amit Gurdasani, Dave Palfrey, and Arpit Mittal. 2018. Demand-Weighted Completeness Prediction for a Knowledge Base. In NAACL. 200--207.Google Scholar"",""Giannis Karamanolakis, Jun Ma, and Xin Luna Dong. 2020. TXtract: Taxonomy-Aware Knowledge Extraction for Thousands of Product Categories. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.Google ScholarCross Ref"",""Greg Linden, Brent Smith, and Jeremy York. 2003. Amazon. com recommendations: Item-to-item collaborative filtering. IEEE Internet computing, Vol. 7, 1 (2003), 76--80.Google Scholar"",""Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. 2008. Isolation forest. In 2008 Eighth IEEE International Conference on Data Mining. IEEE, 413--422.Google ScholarDigital Library"",""Xiaodong Liu, Pengcheng He, Weizhu Chen, and Jianfeng Gao. 2019. Multi-Task Deep Neural Networks for Natural Language Understanding. In ACL. 4487--4496.Google Scholar"",""Colin Lockard, Xin Luna Dong, Arash Einolghozati, and Prashant Shiralkar. 2018. CERES: Distantly Supervised Relation Extraction from the Semi-structured Web. PVLDB (2018), 1084--1096.Google Scholar"",""Yuning Mao, Xiang Ren, Jiaming Shen, Xiaotao Gu, and Jiawei Han. 2018. End-to-End Reinforcement Learning for Automatic Taxonomy Induction. In ACL. 2462--2472.Google Scholar"",""Yuning Mao, Tong Zhao, Andrey Kan, Chenwei Zhang, Xin Luna Dong, Christos Faloutsos, and Jiawei Han. 2020. OCTET: Online Catalog Taxonomy Enrichment with Self-Supervision. In SigKDD.Google Scholar"",""Maximillian Nickel and Douwe Kiela. 2017. Poincaré embeddings for learning hierarchical representations. In NIPS. 6338--6347.Google Scholar"",""George Papadakis, Jonathan Svirsky, Avigdor Gal, and Themis Palpanas. 2016. Comparative analysis of approximate blocking techniques for entity resolution. Proceedings of the VLDB Endowment, Vol. 9, 9 (2016), 684--695.Google ScholarDigital Library"",""Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. In EMNLP. 1532--1543.Google Scholar"",""Disheng Qiu, Luciano Barbosa, Xin Luna Dong, Yanyan Shen, and Divesh Srivastava. 2015. Dexter: large-scale discovery and extraction of product specifications on the web. Proceedings of the VLDB Endowment, Vol. 8, 13 (2015), 2194--2205.Google ScholarDigital Library"",""Simon Razniewski, Vevake Balaraman, and Werner Nutt. 2017. Doctoral advisor or medical condition: Towards entity-specific rankings of knowledge base properties. In International Conference on Advanced Data Mining and Applications.Google ScholarCross Ref"",""Martin Rezk, Laura Alonso Alemany, Lasguido Nio, and Ted Zhang. 2019. Accurate product attribute extraction on the field. In ICDE. 1862--1873.Google Scholar"",""Michael Schlichtkrull and Héctor Martínez Alonso. 2016. Msejrku at semeval-2016 task 14: Taxonomy enrichment by evidence ranking. In SemEval.Google Scholar"",""Jingbo Shang, Jialu Liu, Meng Jiang, Xiang Ren, Clare R Voss, and Jiawei Han. 2018. Automated phrase mining from massive text corpora. IEEE Transactions on Knowledge and Data Engineering, Vol. 30, 10 (2018), 1825--1837.Google ScholarCross Ref"",""Shengjie Sun, Dong Yang, Hongchun Zhang, Yanxu Chen, Chao Wei, Xiaonan Meng, and Yi Hu. 2018. Important Attribute Identification in Knowledge Graph. arXiv preprint arXiv:1810.05320 (2018).Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998--6008.Google Scholar"",""Jingjing Wang, Changsung Kang, Yi Chang, and Jiawei Han. 2014. A hierarchical dirichlet model for taxonomy expansion for search engines. In WWW.Google Scholar"",""Da Xu, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, and Kannan Achan. 2020. Product Knowledge Graph Embedding for E-commerce. In Proceedings of the 13th International Conference on Web Search and Data Mining. 672--680.Google ScholarDigital Library"",""Huimin Xu, Wenting Wang, Xinnian Mao, Xinyu Jiang, and Man Lan. 2019. Scaling up Open Tagging from Tens to Thousands: Comprehension Empowered Attribute Value Extraction from Product Title. In ACL. 5214--5223.Google Scholar"",""Dongxu Zhang, Subhabrata Mukherjee, Colin Lockard, Xin Luna Dong, and Andrew McCallum. 2019. OpenKI: Integrating Open Information Extraction and Knowledge Bases with Relation Inference. arXiv preprint arXiv:1904.12606 (2019).Google Scholar"",""Guineng Zheng, Subhabrata Mukherjee, Xin Luna Dong, and Feifei Li. 2018. OpenTag: Open Attribute Value Extraction from Product Profiles. In SigKDD.Google Scholar""]"
https://doi.org/10.1145/3394486.3403324,Personalized Image Retrieval with Sparse Graph Representation Learning,"Personalization is essential for enhancing the customer experience in retrieval tasks. In this paper, we develop a novel method CA-GCN for personalized image retrieval in the Adobe Stock image system. The proposed method CA-GCN leverages user behavior data in a Graph Convolutional Neural Network (GCN) model to learn user and image embeddings simultaneously. Standard GCN performs poorly on sparse user-image interaction graphs due to the limited knowledge gain from less representative neighbors. To address this challenge, we propose to augment the sparse user-image interaction data by considering the similarities among images. Specifically, we detect clusters of similar images and introduce a set of hidden super-nodes in the graph to represent clusters. We show that such an augmented graph structure can significantly improve the retrieval performance on real-world data collected from Adobe Stock service. In particular, when testing the proposed method on real users' stock image retrieval sessions, we get promoted average click position from 70 to 51.","[{""name"":""Xiaowei Jia"",""id"":""/profile/99658654989""},{""name"":""Handong Zhao"",""id"":""/profile/99658745217""},{""name"":""Zhe Lin"",""id"":""/profile/81384617584""},{""name"":""Ajinkya Kale"",""id"":""/profile/99659573085""},{""name"":""Vipin Kumar"",""id"":""/profile/81452613746""},{""name"":""Xiaowei Jia"",""id"":""/profile/99658654989""},{""name"":""Handong Zhao"",""id"":""/profile/99658745217""},{""name"":""Zhe Lin"",""id"":""/profile/81384617584""},{""name"":""Ajinkya Kale"",""id"":""/profile/99659573085""},{""name"":""Vipin Kumar"",""id"":""/profile/81452613746""}]","[""2019. Ebay steps up personalization efforts to improve search, ads and experience. https://www.modernretail.co/platforms/ebay-steps-up-personalizationefforts-to-improve-search-ads-and-experience/.Google Scholar"",""2019. How Amazon set the standard for product recommendations. https://www.retentionscience.com/blog/how-amazon-set-the-standardfor-product-recommendations/.Google Scholar"",""Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, et almbox. 2016. TensorFlow: A System for Large-Scale Machine Learning. In 12th USENIX Symposium on Operating Systems Design and Implementation, OSDI. 265--283.Google Scholar"",""Pranav Aggarwal, Zhe Lin, Baldo Faieta, and Saeid Motiian. 2019. Multitask Text-to-Visual Embedding with Titles and Clickthrough Data. arXiv preprint arXiv:1905.13339 (2019).Google Scholar"",""Somnath Banerjee and Krishnan Ramanathan. 2008. Collaborative filtering on skewed datasets. In WWW. 1135--1136.Google Scholar"",""Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2016. Enriching Word Vectors with Subword Information. arXiv:1607.04606 (2016).Google Scholar"",""Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, and Cho-Jui Hsieh. 2019. Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks. arXiv preprint arXiv:1905.07953 (2019).Google Scholar"",""Wenqi Fan, Yao Ma, Qing Li, Yuan He, Eric Zhao, Jiliang Tang, and Dawei Yin. 2019. Graph Neural Networks for Social Recommendation. In WWW. ACM.Google Scholar"",""Xiaoxiao Guo, Hui Wu, Yupeng Gao, Steven Rennie, and Rogerio Feris. 2019. The Fashion IQ Dataset: Retrieving Images by Combining Side Information and Relative Natural Language Feedback. arXiv preprint arXiv:1905.12794 (2019).Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In Advances in Neural Information Processing Systems.Google Scholar"",""Peng Han, Peng Yang, Peilin Zhao, Shuo Shang, Yong Liu, Jiayu Zhou, Xin Gao, and Panos Kalnis. 2019. GCN-MF: Disease-Gene Association Identification By Graph Convolutional Networks and Matrix Factorization. In Proceedings of the 25th ACM SIGKDD. 705--713.Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In CVPR. 770--778.Google Scholar"",""Zhenyan Ji, Weina Yao, Huaiyu Pi, Wei Lu, Jing He, and Haishuai Wang. 2017. A survey of personalised image retrieval and recommendation. In National Conference of Theoretical Computer Science. Springer, 233--247.Google Scholar"",""Xiaowei Jia, Sheng Li, Handong Zhao, Sungchul Kim, and Vipin Kumar. 2019. Towards robust and discriminative sequential data learning: When and how to perform adversarial training?. In Proceedings of the 25th ACM SIGKDD.Google Scholar"",""Xiaowei Jia, Xiaoyi Li, Kang Li, Vishrawas Gopalakrishnan, Guangxu Xun, and Aidong Zhang. 2016. Collaborative restricted Boltzmann machine for social event recommendation. In 2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM). IEEE, 402--405.Google Scholar"",""Xiaowei Jia, Aosen Wang, Xiaoyi Li, Guangxu Xun, Wenyao Xu, and Aidong Zhang. 2015. Multi-modal learning for video recommendation based on mobile application usage. In 2015 IEEE International Conference on Big Data (Big Data).Google Scholar"",""Da-Cheng Juan, Chun-Ta Lu, Zhen Li, Futang Peng, Aleksei Timofeev, Yi-Ting Chen, Yaxi Gao, Tom Duerig, Andrew Tomkins, and Sujith Ravi. 2019. Graph-rise: Graph-regularized image semantic embedding. arXiv preprint arXiv:1902.10814 (2019).Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Joonseok Lee, Sami Abu-El-Haija, Balakrishnan Varadarajan, and Apostol Natsev. 2018. Collaborative deep metric learning for video understanding. In Proceedings of the 24th ACM SIGKDD.Google Scholar"",""Sanghoon Lee, Mohamed Masoud, Janani Balaji, Saeid Belkasim, Rajshekhar Sunderraman, and Seung-Jin Moon. 2017. A survey of tag-based information retrieval. International Journal of Multimedia Information Retrieval (2017).Google Scholar"",""Kunpeng Li, Yulun Zhang, Kai Li, Yuanyuan Li, and Yun Fu. 2019. Visual semantic reasoning for image-text matching. In ICCV.Google Scholar"",""Zhiwei Liu, Mengting Wan, Stephen Guo, Kannan Achan, and Philip S Yu. 2020. BasConv: Aggregating Heterogeneous Interactions for Basket Recommendation with Graph Convolutional Neural Network. arXiv:2001.09900 (2020).Google Scholar"",""Yao Ma, Suhang Wang, Charu C Aggarwal, and Jiliang Tang. 2019. Graph convolutional networks with eigenpooling. In Proceedings of the 25th ACM SIGKDD.Google Scholar"",""Tomas Mikolov, Edouard Grave, Piotr Bojanowski, Christian Puhrsch, and Armand Joulin. 2018. Advances in Pre-Training Distributed Word Representations. In LREC 2018.Google Scholar"",""Nils Murrugarra-Llerena and Adriana Kovashka. 2019. Cross-Modality Personalization for Retrieval. In CVPR.Google Scholar"",""Marcel Nassar. 2018. Hierarchical Bipartite Graph Convolution Networks. arXiv preprint arXiv:1812.03813 (2018).Google Scholar"",""Qi Qi, Qiming Huo, Jingyu Wang, Haifeng Sun, Yufei Cao, and Jianxin Liao. 2019. Personalized Sketch-Based Image Retrieval by Convolutional Neural Network and Deep Transfer Learning. IEEE Access, Vol. 7 (2019), 16537--16549.Google Scholar"",""Mehwish Rehman, Muhammad Iqbal, Muhammad Sharif, and Mudassar Raza. 2012. Content based image retrieval: survey. World Applied Sciences Journal, Vol. 19, 3 (2012), 404--412.Google Scholar"",""Karen Sparck Jones. 1972. A statistical interpretation of term specificity and its application in retrieval. Journal of documentation, Vol. 28, 1 (1972), 11--21.Google Scholar"",""Xiaocheng Tang, Zhiwei Qin, Fan Zhang, Zhaodong Wang, Zhe Xu, Yintai Ma, Hongtu Zhu, and Jieping Ye. 2019. A deep value-network based approach for multi-driver order dispatching. In Proceedings of the 25th ACM SIGKDD.Google Scholar"",""Nam Vo, Lu Jiang, Chen Sun, Kevin Murphy, Li-Jia Li, Li Fei-Fei, and James Hays. 2019. Composing text and image for image retrieval-an empirical odyssey. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.Google Scholar"",""Yuandong Wang, Hongzhi Yin, Hongxu Chen, Tianyu Wo, Jie Xu, and Kai Zheng. 2019. Origin-destination matrix prediction via graph convolution: a new perspective of passenger demand modeling. In Proceedings of the 25th ACM SIGKDD.Google Scholar"",""Le Wu, Peijie Sun, Richang Hong, Yanjie Fu, Xiting Wang, and Meng Wang. 2018. SocialGCN: An Efficient Graph Convolutional Network based Model for Social Recommendation. arXiv preprint arXiv:1811.02815 (2018).Google Scholar"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale recommender systems. In Proceedings of the 24th ACM SIGKDD. ACM, 974--983.Google Scholar"",""Jing Yu, Yuhang Lu, Zengchang Qin, Weifeng Zhang, Yanbing Liu, Jianlong Tan, and Li Guo. 2018. Modeling text with graph convolutional network for cross-modal information retrieval. In Pacific Rim Conference on Multimedia. Springer.Google Scholar"",""Jiani Zhang, Xingjian Shi, Shenglin Zhao, and Irwin King. 2019. STAR-GCN: Stacked and Reconstructed Graph Convolutional Networks for Recommender Systems. arXiv preprint arXiv:1905.13129 (2019).Google Scholar"",""Handong Zhao, Zhengming Ding, and Yun Fu. 2017. Multi-View Clustering via Deep Matrix Factorization. In AAAI.Google Scholar"",""Handong Zhao and Yun Fu. 2015. Semantic Single Video Segmentation with Robust Graph Representation. In IJCAI.Google Scholar"",""Jun Zhao, Zhou Zhou, Ziyu Guan, Wei Zhao, Wei Ning, Guang Qiu, and Xiaofei He. 2019. IntentGC: a Scalable Graph Convolution Framework Fusing Heterogeneous Information for Recommendation. In Proceedings of the 25th ACM SIGKDD.Google Scholar"",""Lei Zhu, Jialie Shen, Liang Xie, and Zhiyong Cheng. 2016. Unsupervised visual hashing with semantic assistant for content-based image retrieval. IEEE Transactions on Knowledge and Data Engineering, Vol. 29, 2 (2016), 472--486.Google Scholar""]"
https://doi.org/10.1145/3394486.3403325,Comprehensive Information Integration Modeling Framework for Video Titling,"In e-commerce, consumer-generated videos, which in general deliver consumers' individual preferences for the different aspects of certain products, are massive in volume. To recommend these videos to potential consumers more effectively, diverse and catchy video titles are critical. However, consumer-generated videos seldom accompany appropriate titles. To bridge this gap, we integrate comprehensive sources of information, including the content of consumer-generated videos, the narrative comment sentences supplied by consumers, and the product attributes, in an end-to-end modeling framework. Although automatic video titling is very useful and demanding, it is much less addressed than video captioning. The latter focuses on generating sentences that describe videos as a whole while our task requires the product-aware multi-grained video analysis. To tackle this issue, the proposed method consists of two processes, i.e., granular-level interaction modeling and abstraction-level story-line summarization. Specifically, the granular-level interaction modeling first utilizes temporal-spatial landmark cues, descriptive words, and abstractive attributes to builds three individual graphs and recognizes the intra-actions in each graph through Graph Neural Networks (GNN). Then the global-local aggregation module is proposed to model inter-actions across graphs and aggregate heterogeneous graphs into a holistic graph representation. The abstraction-level story-line summarization further considers both frame-level video features and the holistic graph to utilize the interactions between products and backgrounds, and generate the story-line topic of the video. We collect a large-scale dataset accordingly from real-world data in Taobao, a world-leading e-commerce platform, and will make the desensitized version publicly available to nourish further development of the research community. Relatively extensive experiments on various datasets demonstrate the efficacy of the proposed method.","[{""name"":""Shengyu Zhang"",""id"":""/profile/99659574633""},{""name"":""Ziqi Tan"",""id"":""/profile/99659573104""},{""name"":""Zhou Zhao"",""id"":""/profile/99658748124""},{""name"":""Jin Yu"",""id"":""/profile/99659193494""},{""name"":""Kun Kuang"",""id"":""/profile/99659192894""},{""name"":""Tan Jiang"",""id"":""/profile/99659573298""},{""name"":""Jingren Zhou"",""id"":""/profile/99659315652""},{""name"":""Hongxia Yang"",""id"":""/profile/99659259298""},{""name"":""Fei Wu"",""id"":""/profile/81384610687""},{""name"":""Shengyu Zhang"",""id"":""/profile/99659574633""},{""name"":""Ziqi Tan"",""id"":""/profile/99659573104""},{""name"":""Zhou Zhao"",""id"":""/profile/99658748124""},{""name"":""Jin Yu"",""id"":""/profile/99659193494""},{""name"":""Kun Kuang"",""id"":""/profile/99659192894""},{""name"":""Tan Jiang"",""id"":""/profile/99659573298""},{""name"":""Jingren Zhou"",""id"":""/profile/99659315652""},{""name"":""Hongxia Yang"",""id"":""/profile/99659259298""},{""name"":""Fei Wu"",""id"":""/profile/81384610687""}]","[""Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural Machine Translation by Jointly Learning to Align and Translate.. In ICLR.Google Scholar"",""Satanjeev Banerjee and Alon Lavie. 2005. METEOR: An automatic metric for MT evaluation with improved correlation with human judgments. In ACL. 65--72.Google Scholar"",""David L. Chen and William B. Dolan. 2011. Collecting Highly Parallel Data for Paraphrase Evaluation.. In ACL.Google Scholar"",""Mia Xu Chen, Orhan Firat, Ankur Bapna, Melvin Johnson, Wolfgang Macherey, George Foster, Llion Jones, Mike Schuster, Noam Shazeer, Niki Parmar, and et al. 2018. The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation.. In ACL.Google Scholar"",""Qibin Chen, Junyang Lin, Yichang Zhang, Hongxia Yang, Jingren Zhou, and Jie Tang. 2019. Towards Knowledge-Based Personalized Product Description Generation in E-commerce.. In KDD.Google Scholar"",""Guan-Yu Cheng, Hui-Qin Xiao, Jian Wei Li, Dong Wei Zhao, and Xiaosheng Wu. 2019. ICME Grand Challenge on Short Video Understanding.. In ICME Workshop.Google Scholar"",""Kyunghyun Cho, Bart Van Merriënboer, Dzmitry Bahdanau, and Yoshua Bengio. 2014. On the properties of neural machine translation: Encoder-decoder approaches. arXiv preprint arXiv:1409.1259 (2014).Google Scholar"",""Abhishek Das, Satwik Kottur, Khushi Gupta, Avi Singh, Deshraj Yadav, José M. F. Moura, Devi Parikh, and Dhruv Batra. 2017. Visual Dialog.. In CVPR.Google Scholar"",""Pradipto Das, Chenliang Xu, Richard F. Doell, and Jason J. Corso. 2013. A Thousand Frames in Just a Few Words: Lingual Description of Videos through Latent Topics and Sparse Object Stitching.. In CVPR.Google Scholar"",""Christoph Feichtenhofer, Axel Pinz, and Richard P. Wildes. 2016. Spatiotemporal Residual Networks for Video Action Recognition.. In NIPS.Google Scholar"",""Matthias Fey and Jan Eric Lenssen. 2019. Fast Graph Representation Learning with PyTorch Geometric.. In ICLR Workshop.Google Scholar"",""Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N Dauphin. 2017. Convolutional sequence to sequence learning. In ICML.Google Scholar"",""Sergio Guadarrama, Niveda Krishnamoorthy, Girish Malkarnenkar, Subhashini Venugopalan, Raymond J. Mooney, Trevor Darrell, and Kate Saenko. 2013. YouTube2Text: Recognizing and Describing Arbitrary Activities Using Semantic Hierarchies and Zero-Shot Recognition.. In ICCV.Google Scholar"",""Kensho Hara, Hirokatsu Kataoka, and Yutaka Satoh. 2018. Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?. In CVPR.Google Scholar"",""Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Optimization.. In ICML.Google Scholar"",""Thomas N Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional networks. In ICLR.Google Scholar"",""Atsuhiro Kojima, Takeshi Tamura, and Kunio Fukunaga. 2002. Natural Language Description of Human Activities from Video Images Based on Concept Hierarchy of Actions. IJCV (2002).Google Scholar"",""Jiwei Li, Will Monroe, Tianlin Shi, Sébastien Jean, Alan Ritter, and Dan Jurafsky. 2017. Adversarial Learning for Neural Dialogue Generation.. In EMNLP.Google Scholar"",""Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries. In ACL. 74--81.Google Scholar"",""Jingyuan Liu and Hong Lu. 2018. Deep Fashion Analysis with Feature Map Upsampling and Landmark-Driven Attention. In ECCV. Springer.Google Scholar"",""Ziwei Liu, Sijie Yan, Ping Luo, Xiaogang Wang, and Xiaoou Tang. 2016. Fashion Landmark Detection in the Wild.. In ECCV.Google Scholar"",""Jiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee. 2019. Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks. In NIPS.Google Scholar"",""Shuming Ma, Lei Cui, Damai Dai, Furu Wei, and Xu Sun. 2019. LiveBot: Generating Live Video Comments Based on Visual and Textual Contexts.. In AAAI.Google Scholar"",""Pingbo Pan, Zhongwen Xu, Yi Yang, Fei Wu, and Yueting Zhuang. 2016. Hierarchical Recurrent Neural Encoder for Video Representation with Application to Captioning.. In CVPR.Google Scholar"",""Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In ACL. Association for Computational Linguistics, 311--318.Google Scholar"",""Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. 2017. Automatic differentiation in PyTorch. In NIPS-W.Google Scholar"",""Xufeng Qian, Yueting Zhuang, Yimeng Li, Shaoning Xiao, Shiliang Pu, and Jun Xiao. 2019. Video Relation Detection with Spatio-Temporal Graph.. In MM.Google Scholar"",""Michaela Regneri, Marcus Rohrbach, Dominikus Wetzel, Stefan Thater, Bernt Schiele, and Manfred Pinkal. 2013. Grounding Action Descriptions in Videos. TACL (2013).Google Scholar"",""Anna Rohrbach, Marcus Rohrbach, Wei Qiu, Annemarie Friedrich, Manfred Pinkal, and Bernt Schiele. 2014. Coherent Multi-sentence Video Description with Variable Level of Detail.. In GCPR.Google Scholar"",""Anna Rohrbach, Marcus Rohrbach, Niket Tandon, and Bernt Schiele. 2015. A dataset for Movie Description.. In CVPR.Google Scholar"",""Marcus Rohrbach, Wei Qiu, Ivan Titov, Stefan Thater, Manfred Pinkal, and Bernt Schiele. 2013. Translating Video Content to Natural Language Descriptions.. In ICCV.Google Scholar"",""Abigail See, Peter J. Liu, and Christopher D. Manning. 2017. Get To The Point: Summarization with Pointer-Generator Networks.. In ACL.Google Scholar"",""Gunnar A. Sigurdsson, Gül Varol, Xiaolong Wang, Ali Farhadi, Ivan Laptev, and Abhinav Gupta. 2016. Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding.. In ECCV.Google Scholar"",""Atousa Torabi, Christopher J. Pal, Hugo Larochelle, and Aaron C. Courville. 2015. Using Descriptive Video Services to Create a Large Data Source for Video Annotation Research. Arxiv (2015).Google Scholar"",""Ramakrishna Vedantam, C Lawrence Zitnick, and Devi Parikh. 2015. Cider: Consensus-based image description evaluation. In CVPR. 4566--4575.Google Scholar"",""Subhashini Venugopalan, Marcus Rohrbach, Jeffrey Donahue, Raymond J. Mooney, Trevor Darrell, and Kate Saenko. 2015a. Sequence to Sequence - Video to Text.. In ICCV.Google Scholar"",""Subhashini Venugopalan, Huijuan Xu, Jeff Donahue, Marcus Rohrbach, Raymond J. Mooney, and Kate Saenko. 2015b. Translating Videos to Natural Language Using Deep Recurrent Neural Networks.. In NAACL.Google Scholar"",""Bairui Wang, Lin Ma, Wei Zhang, and Wei Liu. 2018. Reconstruction Network for Video Captioning.. In CVPR.Google Scholar"",""Wenguan Wang, Xiankai Lu, Jianbing Shen, David J Crandall, and Ling Shao. 2019. Zero-shot video object segmentation via attentive graph neural networks. In ICCV.Google Scholar"",""Xiaolong Wang and Abhinav Gupta. 2018. Videos as Space-Time Region Graphs.. In ECCV.Google Scholar"",""Ronald J. Williams and David Zipser. 1989. A Learning Algorithm for Continually Running Fully Recurrent Neural Networks. Neural Computation (1989).Google Scholar"",""Li Yao, Atousa Torabi, Kyunghyun Cho, Nicolas Ballas, Christopher J. Pal, Hugo Larochelle, and Aaron C. Courville. 2015. Describing Videos by Exploiting Temporal Structure.. In ICCV.Google Scholar"",""Daniel Zeman, Jan Hajic, Martin Popel, Martin Potthast, Milan Straka, Filip Ginter, Joakim Nivre, and Slav Petrov. 2018. CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies.. In ACL.Google Scholar"",""Kuo-Hao Zeng, Tseng-Hung Chen, Juan Carlos Niebles, and Min Sun. 2016. Title Generation for User Generated Videos.. In ECCV.Google Scholar"",""Runhao Zeng, Wenbing Huang, Mingkui Tan, Yu Rong, Peilin Zhao, Junzhou Huang, and Chuang Gan. 2019. Graph convolutional networks for temporal action localization. In ICCV.Google Scholar""]"
https://doi.org/10.1145/3394486.3403326,Acoustic Measures for Real-Time Voice Coaching,"Our voices can convey many different types of thoughts and intent; how our voices carry them is often not consciously controlled and as a consequence, unintended effects may arise that negatively impact our relationships. How we say things is as important as what we say. This paper presents methodologies for computing a set of physical properties from sound waves of a speaker's voice directly, referred to as acoustic measures. Experiments are designed and conducted to establish the correlations between physical properties and auditory measures for human perception of sound waves. Based on these correlations, a voice coaching app can guide users, in real-time or deferred retrospective, to modify their speech's auditory measures, such as rate of speech, energy level, and intonation, to achieve their intended communication goals.","[{""name"":""Ying Li"",""id"":""/profile/99659575267""},{""name"":""Abraham Miller"",""id"":""/profile/99659573516""},{""name"":""Arthur Liu"",""id"":""/profile/99659574399""},{""name"":""Kyle Coburn"",""id"":""/profile/99659575067""},{""name"":""Luis J. Salazar"",""id"":""/profile/99658731915""},{""name"":""Ying Li"",""id"":""/profile/99659575267""},{""name"":""Abraham Miller"",""id"":""/profile/99659573516""},{""name"":""Arthur Liu"",""id"":""/profile/99659574399""},{""name"":""Kyle Coburn"",""id"":""/profile/99659575067""},{""name"":""Luis J. Salazar"",""id"":""/profile/99658731915""}]","[""Vered Aharonson, Eran Aharonson, Katia Levi, Aviv Sotzianu, Ofer Amir, and Ovadia-Blechman Zehava. 2017. A Real-Time Phoneme Counting Algorithm and Application for Speech Rate Monitoring. Journal of Fluency Disorders 51 (01 2017). https://doi.org/10.1016/j.jfludis.2017.01.001Google Scholar"",""Moataz M. H. El Ayadi, Mohamed S. Kamel, and Fakhri Karray. 2011. Survey on speech emotion recognition: Features, classification schemes, and databases. Pattern Recognition 44 (2011), 572--587.Google ScholarDigital Library"",""Paul Boersma. 1993. ACCURATE SHORT-TERM ANALYSIS OF THE FUNDAMENTAL FREQUENCY AND THE HARMONICS-TO-NOISE RATIO OF A SAMPLED SOUND. In Proceedings, Institute of Phonetic Science. University of Amsterdam, 97--110.Google Scholar"",""Paul Boersma and David Weenink. 2020. Praat: doing phonetics by computer. http://www.praat.org/Google Scholar"",""Alain de Cheveigné and Hideki Kawahara. 2002. YIN, a fundamental frequency estimator for speech and music. The Journal of the Acoustical Society of America 111 4 (2002), 1917--30.Google Scholar"",""David Dean, Sridha Sridharan, Robert Vogt, and Michael Mason. 2010. The QUTNOISE-TIMIT corpus for the evaluation of voice activity detection algorithms. In Proceedings of 11th Annual Conference of the International Speech Communication Association (INTERSPEECH), K Hirose, S Nakamura, and T Kaboyashi (Eds.). 3110--3113.Google Scholar"",""Laurence Devillers and Laurence Vidrascu. 2006. Real-life emotions detection with lexical and paralinguistic cues on human-human call center dialogs. In INTERSPEECH 2006.Google Scholar"",""Laurence Devillers and Laurence Vidrascu. 2006. Real-life emotions detection with lexical and paralinguistic cues on human-human call center dialogs.. In INTERSPEECH 2006 - ICSLP, Ninth International Conference on Spoken Language Processing. 801 -- 804.Google Scholar"",""Dong Wang, Lie Lu, and Hong-Jiang Zhang. 2003. Speech segmentation without speech recognition. In 2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings. (ICASSP '03)., Vol. 1. I--I. https://doi.org/10.1109/ICASSP.2003.1198819Google Scholar"",""Sorin Dusan and Lawrence Rabiner. 2006. On the relation between maximum spectral transition positions and phone boundaries. In Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH, Vol. 2.Google Scholar"",""Gustav Theodor Fechner, Edwin G Boring, and Davis H Howes. 1966. Elements of Psychophysics: Transl. by Helmut E. Adler. Holt, Rinehart and Winston.Google Scholar"",""Sadaoki Furui. 1986. On the role of spectral transition for speech perception. The Journal of the Acoustical Society of America 80 (11 1986), 1016--25. https://doi.org/10.1121/1.393842Google Scholar"",""John S. Garofolo, Lori F. Lamel, William M. Fisher, Jonathan G. Fiscus, David S. Pallett, Nancy L. Dahlgren, and Victor Zue. 1993. TIMIT Acoustic-Phonetic Continuous Speech Corpus LDC93S1. https://catalog.ldc.upenn.edu/LDC93S1Google Scholar"",""E. Georganti, T. May, S. van de Par, A. Harma, and J. Mourjopoulos. 2011. Speaker Distance Detection Using a Single Microphone. IEEE Transactions on Audio, Speech, and Language Processing 19, 7 (Sep. 2011), 1949--1961. https://doi.org/10. 1109/TASL.2011.2104953Google ScholarDigital Library"",""Steven Greenberg, Hannah Carvey, Leah Hitchcock, and Shuangyu Chang. 2003. Temporal properties of spontaneous speech - a syllable-centric perspective. J. Phonetics 31 (2003), 465--485.Google ScholarCross Ref"",""Daniel Hirst and Albert di Cristo. 1999. A survey of intonation systems. In Intonation Systems, A Survey of Twenty Languages, Daniel Hirst and Albert di Cristo (Eds.). Cambridge University Press, Chapter 1, 1--44.Google Scholar"",""Xuedong Huang, Alex Acero, Hsiao-Wuen Hon, and Raj Reddy. 2001. Spoken Language Processing: A Guide to Theory, Algorithm, and System Development (1st ed.). Prentice Hall PTR, USA.Google Scholar"",""Judd Humpherys. 2012. Your Speech Patterns Affect Sales Performance. https://ezinearticles.com/?Your-Speech-Patterns-Affect-SalesPerformance\u0026id=7306149Google Scholar"",""Alexei Kapterev. 2011. Presentation Secrets: Do What You Never Thought Possible with Your Presentations (1st ed.). Wiley, USA.Google ScholarCross Ref"",""William H. Kruskal. 1952. A Nonparametric test for the Several Sample Problem. Ann. Math. Statist. 23, 4 (1952), 525--540.Google ScholarCross Ref"",""David Lewis and G. Riley Mills. 2012. The Pin Drop Principle (1st ed.). Jossey-Bass, USA.Google Scholar"",""Steven R. Livingstone and Frank A. Russo. 2018. The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English. PLOS ONE 13, 5 (05 2018), 1--35. https://doi.org/10.1371/journal.pone.0196391Google Scholar"",""Lawrence Marks and Mary Florentine. 2010. Measurement of Loudness, Part I: Methods, Problems, and Pitfalls. 17--56. https://doi.org/10.1007/978-1-4419-6712-1_2Google Scholar"",""Brian McFee, Colin Raffel, Dawen Liang, Daniel PW Ellis, Matt McVicar, Eric Battenberg, and Oriol Nieto. 2015. librosa: Audio and music signal analysis in python. In Proceedings of the 14th python in science conference. 18--25.Google ScholarCross Ref"",""Vikramjit Mitra and Elizabeth Shriberg. 2015. Effects of feature type, learning algorithm and speaking style for depression detection from speech. In 2015 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2015, South Brisbane, Queensland, Australia, April 19-24, 2015. 4774--4778. https: //doi.org/10.1109/ICASSP.2015.7178877Google ScholarCross Ref"",""Nelson Morgan, Eric Fosler-Lussier, and Nikki Mirghafori. 1997. Speech Recognition Using On-Line Estimation Of Speaking Rate. In Fifth European Conference on Speech Communication and Technology, EUROSPEECH 1997, Vol. 4.Google Scholar"",""Gregor Pirker, Michael Wohlmayr, Stefan Petrik, and Franz Pernkopf. 2011. A Pitch Tracking Corpus with Evaluation on Multipitch Tracking Scenario. In INTERSPEECH 2011. 1509--1512.Google Scholar"",""Tim Polzehl, S. Möller, and Florian Metze. 2010. Automatically Assessing Personality from Speech. In IEEE Fourth International Conference on Semantic Computing (ICSC). 134--140. https://doi.org/10.1109/ICSC.2010.41Google ScholarDigital Library"",""The WebRTC project authors. 2011 (accessed Novemver, 2019). The WebRTC project. https://webrtc.org/Google Scholar"",""Thomas F. Quatieri. 2001. Discrete-Time Speech Signal Processing: Principles and Practice (1st ed.). Prentice Hall, USA.Google Scholar"",""Mirco Ravanelli, Titouan Parcollet, and Yoshua Bengio. 2018. The Pytorch-kaldi Speech Recognition Toolkit. ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (2018), 6465--6469.Google Scholar"",""Emma Rodero. 2012. A comparative analysis of speech rate and perception in radio bulletins. Text and Talk 32 (05 2012), 391--411. https://doi.org/10.1515/text2012-0019Google Scholar"",""Bruce P. Ryan. 2000. Speaking rate, conversational speech acts, interruption, and linguistic complexity of 20 pre-school stuttering and non-stuttering children and their mothers. Clinical Linguistics \u0026 Phonetics 14, 1 (2000), 25--51. https:// doi.org/10.1080/026992000298931 arXiv:https://doi.org/10.1080/026992000298931 PMID: 22091696.Google ScholarCross Ref"",""B. Schuller. 2011. Voice and speech analysis in search of states and traits. In Computer Analysis of Human Behavior. Springer, 227--253.Google Scholar"",""Björn W. Schuller, Stefan Steidl, Anton Batliner, Felix Burkhardt, Laurence Devillers, Christian A. Müller, and Shrikanth S. Narayanan. 2010. The INTERSPEECH 2010 paralinguistic challenge. In INTERSPEECH 2010.Google Scholar"",""Piotr Sorokowski, David Puts, Janie Johnson, Olga ókiewicz, Agnieszka Sorokowska, Marta Kowal, Basia Borkowska, and Katarzyna Pisanski. 2019. Voice of Authority: Professionals Lower Their Vocal Frequencies When Giving Expert Advice. Journal of Nonverbal Behavior (05 2019). https://doi.org/10.1007/s10919-019-00307-0Google Scholar"",""S. Tong, H. Gu, and K. Yu. 2016. A comparative study of robustness of deep learning approaches for VAD. In 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). 5695--5699. https://doi.org/10.1109/ICASSP.2016.7472768Google ScholarCross Ref"",""Benjamin Weiss and Felix Burkhardt. 2012. Is 'not bad' good enough? Aspects of unknown voices' likability. In INTERSPEECH 2012.Google Scholar"",""Jiahong Yuan, Mark Liberman, and Christopher Cieri. 2006. Towards an Integrated Understanding of Speaking Rate in Conversation. In Proceedings of INTERSPEECH 2006.Google Scholar""]"
https://doi.org/10.1145/3394486.3403327,Geodemographic Influence Maximization,"Given a set of locations in a city, on which ones should we place ads on so as to reach as many people as possible within a limited budget? Past research has addressed this question under the assumption that dense trajectory data are available to determine the reach of each ad. However, the data that are available in most industrial settings do not consist of dense, long-range trajectories; instead, they consist of statistics on people's short-range point-to-point movements. In this paper, we address the natural problem that arises such data: given a distribution of population and point-to-point movement statistics over a network, find a set of locations within a budget that achieves maximum expected reach. We call this problem geodemographic influence maximization (GIM). We show that the problem is NP-hard, but its objective function is monotone and submodular, thus admits a greedy algorithm with a 1 over 2 (1-1 over e) approximation ratio. Still, this algorithm is inapplicable on large-scale data for high-frequency digital signage ads. We develop an efficient deterministic algorithm, Lazy-Sower, exploiting a novel, tight double-bounding scheme of marginal influence gain as well as the locality proprieties of the problem; a learning-based variant, NN-Sower, utilizes randomization and deep learning to further improve efficiency, with a slight loss of quality. Our exhaustive experimental study on two real-world urban datasets demonstrates the efficacy and efficiency of our solutions compared to baselines.","[{""name"":""Kaichen Zhang"",""id"":""/profile/99659574477""},{""name"":""Jingbo Zhou"",""id"":""/profile/99659520172""},{""name"":""Donglai Tao"",""id"":""/profile/99659573559""},{""name"":""Panagiotis Karras"",""id"":""/profile/81100001061""},{""name"":""Qing Li"",""id"":""/profile/99659574317""},{""name"":""Hui Xiong"",""id"":""/profile/81451596433""},{""name"":""Kaichen Zhang"",""id"":""/profile/99659574477""},{""name"":""Jingbo Zhou"",""id"":""/profile/99659520172""},{""name"":""Donglai Tao"",""id"":""/profile/99659573559""},{""name"":""Panagiotis Karras"",""id"":""/profile/81100001061""},{""name"":""Qing Li"",""id"":""/profile/99659574317""},{""name"":""Hui Xiong"",""id"":""/profile/81451596433""}]","[""Christian Borgs, Michael Brautbar, Jennifer T. Chayes, and Brendan Lucier. 2014. Maximizing Social Influence in Nearly Optimal Time. In SODA. 946--957.Google Scholar"",""Wei Chen, Chi Wang, and Yajun Wang. 2010. Scalable influence maximization for prevalent viral marketing in large-scale social networks. In KDD. 1029--1038.Google Scholar"",""Yves-Alexandre De Montjoye, Laura Radaelli, Vivek Kumar Singh, et almbox. 2015. Unique in the shopping mall: On the reidentifiability of credit card metadata. Science, Vol. 347, 6221 (2015), 536--539.Google Scholar"",""Charles Dennis, Richard Michon, J. Jocko Brakus, Andrew Newman, and Eleftherios Alamanos. 2012. New insights into the impact of digital signage as a retail atmospheric tool. Journal of Consumer Behaviour, Vol. 11, 6 (2012), 454--466.Google ScholarCross Ref"",""Aram Galstyan, Vahe Musoyan, and Paul Cohen. 2009. Maximizing influence propagation in networks with community structure. Physical Review E, Vol. 79, 5 (2009), 056102.Google ScholarCross Ref"",""Long Guo, Dongxiang Zhang, Gao Cong, Wei Wu, and Kian-Lee Tan. 2016. Influence maximization in trajectory databases. IEEE TKDE, Vol. 29, 3 (2016), 627--641.Google Scholar"",""Tianyi Hao, Jingbo Zhou, Yunsheng Cheng, Longbo Huang, and Haishan Wu. 2016. User identification in cyber-physical space: a case study on mobile query logs and trajectories. In SIGSPATIAL. 1--4.Google Scholar"",""Tianyi Hao, Jingbo Zhou, Yunsheng Cheng, Longbo Huang, and Haishan Wu. 2020. A Unified Framework for User Identification across Online and Offline Data. IEEE TKDE (2020).Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In CVPR. 770--778.Google Scholar"",""Thibaut Horel. 2015. Notes on Greedy Algorithms for Submodular Maximization. Online.Google Scholar"",""Shixun Huang, Zhifeng Bao, J Shane Culpepper, and Bang Zhang. 2019. Finding Temporal Influential Users over Evolving Social Networks. In ICDE. 398--409.Google Scholar"",""Sergei Ivanov, Konstantinos Theocharidis, Manolis Terrovitis, and Panagiotis Karras. 2017. Content Recommendation for Viral Social Influence. In SIGIR.Google Scholar"",""David Kempe, Jon Kleinberg, and Éva Tardos. 2003. Maximizing the spread of influence through a social network. In KDD. 137--146.Google Scholar"",""Samir Khuller, Anna Moss, and Joseph Seffi Naor. 1999. The budgeted maximum coverage problem. Inform. Process. Lett., Vol. 70, 1 (1999), 39--45.Google ScholarDigital Library"",""Jure Leskovec, Andreas Krause, Carlos Guestrin, Christos Faloutsos, Christos Faloutsos, Jeanne VanBriesen, and Natalie Glance. 2007. Cost-effective outbreak detection in networks. In KDD. 420--429.Google Scholar"",""Guoliang Li, Shuo Chen, Jianhua Feng, Kian-Lee Tan, and Wen-Syan Li. 2014. Efficient location-aware influence maximization. In SIGMOD. 87--98.Google Scholar"",""Yuchen Li, Ju Fan, George V. Ovchinnikov, and Panagiotis Karras. 2019. Maximizing Multifaceted Network Influence. In ICDE. 446--457.Google Scholar"",""Alvis Logins and Panagiotis Karras. 2019 a. Content-Based Network Influence Probabilities: Extraction and Application. In ICDM Workshops. 69--72.Google Scholar"",""Alvis Logins and Panagiotis Karras. 2019 b. An Experimental Study on Network Immunization. In EDBT. 726--729.Google Scholar"",""Alvis Logins, Yuchen Li, and Panagiotis Karras. 2020. On the Robustness of Cascade Diffusion under Node Attacks. In WWW. 2711--2717.Google Scholar"",""Michel Minoux. 1978. Accelerated greedy algorithms for maximizing submodular set functions. In IFIP Conference on Optimization Techniques. 234--243.Google ScholarCross Ref"",""Baharan Mirzasoleiman, Ashwinkumar Badanidiyuru, Amin Karbasi, Jan Vondrak, and Andreas Kraus. 2015. Lazier Than Lazy Greedy. In AAAI. 1812--1818.Google Scholar"",""G. L. Nemhauser and L. A Wolsey. 1978. Best algorithms for approximating the maximum of a submodular set function. Math. Operat. Res., Vol. 3, 3 (1978), 177--188.Google ScholarDigital Library"",""Lex van Meurs and Mandy Aristoff. 2009. Split-Second Recognition: What Makes Outdoor Advertising Work? Journal of Advertising Research, Vol. 49, 1 (2009), 82--92.Google ScholarCross Ref"",""Yu Wang, Gao Cong, Guojie Song, and Kunqing Xie. 2010. Community-based greedy algorithm for mining top-k influential nodes in mobile social networks. In KDD. 1039--1048.Google Scholar"",""Ping Zhang, Zhifeng Bao, Yuchen Li, Guoliang Li, Yipeng Zhang, and Zhiyong Peng. 2018. Trajectory-driven Influential Billboard Placement. In KDD.Google Scholar"",""Yipeng Zhang, Yuchen Li, Zhifeng Bao, Songsong Mo, and Ping Zhang. 2019. Optimizing Impression Counts for Outdoor Advertising. In KDD. 1205--1215.Google Scholar"",""Jingbo Zhou, Hongbin Pei, and Haishan Wu. 2018. Early warning of human crowds based on query data from Baidu maps: Analysis based on Shanghai stampede. In Big data support of urban planning and management. 19--41.Google Scholar"",""Jingbo Zhou, Anthony KH Tung, Wei Wu, and Wee Siong Ng. 2013a. R2-D2: a system to support probabilistic path prediction in dynamic environments via \""semi-lazy\"" learning. VLDB, Vol. 6, 12 (2013), 1366--1369.Google ScholarDigital Library"",""Jingbo Zhou, Anthony KH Tung, Wei Wu, and Wee Siong Ng. 2013b. A ?semi-lazy\"" approach to probabilistic path prediction in dynamic environments. In KDD.Google Scholar"",""Tao Zhou, Jiuxin Cao, Bo Liu, Shuai Xu, Ziqing Zhu, and Junzhou Luo. 2015. Location-based influence maximization in social networks. In CIKM. 1211--1220.Google Scholar""]"
https://doi.org/10.1145/3394486.3403328,A Self-Evolving Mutually-Operative Recurrent Network-based Model for Online Tool Condition Monitoring in Delay Scenario,"With the increasing demand of product supply, manufacturers are in urgent need of online tool condition monitoring (TCM) without compromising with the maintenance cost in terms of time as well as man-power requirement. However, the existing machine learning models for TCM are mostly offline and not suitable for the non-stationary environment of the machining settings. Moreover, the access of the ground truth always imposes a shutdown of the machining process and the existing models are severely affected by such delay in receiving labelled samples. In order to tackle these issues, we propose SERMON as a novel learning model based on a pair of self-evolving mutually-operative recurrent neural networks. The proposed SERMON is well-equipped with features for automated and real-time monitoring of machine fault status even in the finite/infinite label delay scenario. The experimental evaluation of SERMON using real-world dataset on 3D-printing process demonstrates its effectiveness in online fault detection under non-stationary as well as delayed label context of the machining process. Additional comparative study on large-scale benchmark streaming datasets further exhibits the scalability power of SERMON.","[{""name"":""Monidipa Das"",""id"":""/profile/99658990120""},{""name"":""Mahardhika Pratama"",""id"":""/profile/81487654940""},{""name"":""Tegoeh Tjahjowidodo"",""id"":""/profile/81440620195""},{""name"":""Monidipa Das"",""id"":""/profile/99658990120""},{""name"":""Mahardhika Pratama"",""id"":""/profile/81487654940""},{""name"":""Tegoeh Tjahjowidodo"",""id"":""/profile/81440620195""}]","[""Andri Ashfahani and Mahardhika Pratama. 2019. Autonomous Deep Learning: Continual Learning Approach for Dynamic Environments. In SIAM International Conference on Data Mining (SDM).Google Scholar"",""Pierre Baldi, Peter Sadowski, and Daniel Whiteson. 2014. Searching for exotic particles in high-energy physics with deep learning. Nature communications, Vol. 5 (2014), 4308.Google Scholar"",""C Brecher, M Klatte, and F Tzanetos. 2017. Analysis of spatial and temporal dependencies of the TCP-dislocation measurement for the assessment of the thermo-elastic behavior of 3-axis machine tools. In Proceedings of the 12th International LAMDAMAP Conference, Bristol, UK. 122--132.Google Scholar"",""Yunpeng Chen, Jianan Li, Huaxin Xiao, Xiaojie Jin, Shuicheng Yan, and Jiashi Feng. 2017. Dual path networks. In Advances in Neural Information Processing Systems. 4467--4475.Google Scholar"",""Sohyung Cho, Sultan Binsaeid, and Shihab Asfour. 2010. Design of multisensor fusion-based tool condition monitoring system in end milling. The International Journal of Advanced Manufacturing Technology, Vol. 46, 5--8 (2010), 681--694.Google ScholarCross Ref"",""M Das, M Pratama, A Ashfahani, and S Samanta. 2019 a. FERNN: A Fast and Evolving Recurrent Neural Network Model for Streaming Data Classification. In Proceedings of the International Joint Conference on Neural Networks 2019.Google ScholarCross Ref"",""M Das, M Pratama, S Savitri, and J Zhang. 2019 b. MUSE-RNN: A Multilayer Self-Evolving Recurrent Neural Network for Data Stream Classification. In 2019 IEEE International Conference on Data Mining (ICDM). IEEE.Google Scholar"",""M Das, M Pratama, J Zhang, and Y S Ong. 2020. A Skip-connected Evolving Recurrent Neural Network for Data Stream Classification under Label Latency Scenario. In In Proceedings of the Thirty-Fourth AAAI Conference on Artificial Intelligence. 1--8.Google ScholarCross Ref"",""Gregory Ditzler and Robi Polikar. 2013. Incremental learning of concept drift from streaming imbalanced data. IEEE Transactions on Knowledge and Data Engineering, Vol. 25, 10 (2013), 2283--2301.Google ScholarDigital Library"",""Karl B Dyer, Robert Capo, and Robi Polikar. 2014. Compose: A semisupervised learning framework for initially labeled nonstationary streaming data. IEEE transactions on neural networks and learning systems, Vol. 25, 1 (2014), 12--26.Google Scholar"",""Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio. 2016. Deep learning. Vol. 1. MIT press Cambridge.Google Scholar"",""PoTsang B Huang, Cheng-Chieh Ma, and Chia-Hao Kuo. 2015. A PNN self-learning tool breakage detection system in end milling operations. Applied Soft Computing, Vol. 37 (2015), 114--124.Google ScholarDigital Library"",""Jeongtae Lee, Jaehong Yun, Sungju Hwang, and Eunho Yang. 2018. Lifelong Learning with Dynamically Expandable Networks. In International Conference on Learning Representations (ICLR). 1--11.Google Scholar"",""CK Madhusudana, Hemantha Kumar, and S Narendranath. 2016. Condition monitoring of face milling tool using K-star algorithm and histogram features of vibration signal. Engineering science and technology, an international journal, Vol. 19, 3 (2016), 1543--1551.Google Scholar"",""T Mikołajczyk, K Nowicki, A Bustillo, and D Yu Pimenov. 2018. Predicting tool life in turning operations using neural networks and image processing. Mechanical systems and signal processing, Vol. 104 (2018), 503--513.Google Scholar"",""K Patra, AK Jha, Tibor Szalay, J Ranjan, and László Monostori. 2017. Artificial neural network based tool condition monitoring in micro mechanical peck drilling using thrust force signals. Precision Engineering, Vol. 48 (2017), 279--291.Google ScholarCross Ref"",""Mahardhika Pratama, Eric Dimla, Tegoeh Tjahjowidodo, Witold Pedrycz, and Edwin Lughofer. 2018. Online tool condition monitoring based on parsimonious ensemble. IEEE Transactions on Cybernetics (2018).Google Scholar"",""Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, and Raia Hadsell. 2016. Progressive neural networks. arXiv preprint arXiv:1606.04671 (2016).Google Scholar"",""Joan Serrà, D'idac Sur'is, Marius Miron, and Alexandros Karatzoglou. 2018. Overcoming catastrophic forgetting with hard attention to the task. In 35th International Conference on Machine Learning. 4548--4557.Google Scholar"",""Vinícius MA Souza, Diego F Silva, Jo ao Gama, and Gustavo EAPA Batista. 2015. Data stream classification guided by clustering on nonstationary environments and extreme verification latency. In Proceedings of the 2015 SIAM International Conference on Data Mining. SIAM, 873--881.Google ScholarCross Ref"",""DA Tobon-Mejia, Kamal Medjaher, and Noureddine Zerhouni. 2012. CNC machine tool's wear diagnostic and prognostic by using dynamic Bayesian networks. Mechanical Systems and Signal Processing, Vol. 28 (2012), 167--182.Google ScholarCross Ref"",""K Vernekar, H Kumar, and KV Gangadharan. 2015. Fault diagnosis of gears through discrete wavelet features based on a decision tree and support vector machine. International Journal of Condition Monitoring, Vol. 5, 2 (2015), 23--29.Google ScholarCross Ref"",""Dianhui Wang and Ming Li. 2017. Stochastic configuration networks: Fundamentals and algorithms. IEEE transactions on cybernetics, Vol. 47, 10 (2017), 3466--3479.Google Scholar"",""Cunji Zhang, Xifan Yao, Jianming Zhang, and Hong Jin. 2016. Tool condition monitoring and remaining useful life prognostic based on a wireless sensor in dry milling operations. Sensors, Vol. 16, 6 (2016), 795.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403329,Maximizing Cumulative User Engagement in Sequential Recommendation: An Online Optimization Perspective,"To maximize cumulative user engagement (e.g. cumulative clicks) in sequential recommendation, it is often needed to tradeoff two potentially conflicting objectives, that is, pursuing higher immediate user engagement (e.g., click-through rate) and encouraging user browsing (i.e., more items exposured). Existing works often study these two tasks separately, thus tend to result in sub-optimal results. In this paper, we study this problem from an online optimization perspective, and propose a flexible and practical framework to explicitly tradeoff longer user browsing length and high immediate user engagement. Specifically, by considering items as actions, user's requests as states and user leaving as an absorbing state, we formulate each user's behavior as a personalized Markov decision process (MDP), and the problem of maximizing cumulative user engagement is reduced to a stochastic shortest path (SSP) problem. Meanwhile, with immediate user engagement and quit probability estimation, it is shown that the SSP problem can be efficiently solved via dynamic programming. Experiments on real-world datasets demonstrate the effectiveness of the proposed approach. Moreover, this approach is deployed at a large E-commerce platform, achieved over 7% improvement of cumulative clicks.","[{""name"":""Yifei Zhao"",""id"":""/profile/99659573488""},{""name"":""Yu-Hang Zhou"",""id"":""/profile/99659573327""},{""name"":""Mingdong Ou"",""id"":""/profile/99659574109""},{""name"":""Huan Xu"",""id"":""/profile/99659454563""},{""name"":""Nan Li"",""id"":""/profile/99659336186""},{""name"":""Yifei Zhao"",""id"":""/profile/99659573488""},{""name"":""Yu-Hang Zhou"",""id"":""/profile/99659573327""},{""name"":""Mingdong Ou"",""id"":""/profile/99659574109""},{""name"":""Huan Xu"",""id"":""/profile/99659454563""},{""name"":""Nan Li"",""id"":""/profile/99659336186""}]","[""Jaume Amores. 2013. Multiple instance classification: review, taxonomy and comparative study. Artificial intelligence, Vol. 201 (2013), 81--105.Google Scholar"",""Stuart Andrews, Ioannis Tsochantaridis, and Thomas Hofmann. 2003. Support vector machines for multiple-instance learning. In Advances in Neural Information Processing Systems. Vancouver, Canada, 577--584.Google Scholar"",""Andrew G Barto, Steven J Bradtke, and Satinder P Singh. 1995. Learning to act using real-time dynamic programming. Artificial Intelligence, Vol. 72, 1--2 (1995), 81--138.Google ScholarCross Ref"",""Dimitri P Bertsekas and John N Tsitsiklis. 1991. An analysis of stochastic shortest path problems. Mathematics of Operations Research, Vol. 16, 3 (1991), 580--595.Google ScholarDigital Library"",""Blai Bonet and Hector Geffner. 2003. Labeled RTDP: improving the convergence of real-time dynamic programming.. In Proceedings of the Thirteenth International Conference on Automated Planning and Scheduling, Vol. 3. Trento, Italy, 12--21.Google Scholar"",""Razvan C Bunescu and Raymond J Mooney. 2007. Multiple instance learning for sparse positive bags. In Proceedings of the Twenty-Fourth International Conference on Machine Learning. ACM, Corvallis, Oregon, USA, 105--112.Google ScholarDigital Library"",""Jaime Carbonell and Jade Goldstein. 1998. The use of MMR, diversity-based reranking for reordering documents and producing summaries. In Proceedings of the Twentiy-First Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM, Melbourne, Australia, 335--336.Google ScholarDigital Library"",""Xu Chen, Hongteng Xu, Yongfeng Zhang, Jiaxi Tang, Yixin Cao, Zheng Qin, and Hongyuan Zha. 2018. Sequential recommendation with user memory networks. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. ACM, Los Angeles, California, USA, 108--116.Google ScholarDigital Library"",""Robin Devooght and Hugues Bersini. 2017. Long and short-term recommendations with recurrent neural networks. In Proceedings of The Twenty-Fifth Conference on User Modeling, Adaptation and Personalization. ACM, Bratislava, Slovakia, 13--21.Google ScholarDigital Library"",""Thomas G Dietterich, Richard H Lathrop, and Tomás Lozano-Pérez. 1997. Solving the multiple instance problem with axis-parallel rectangles. Artificial Intelligence, Vol. 89, 1--2 (1997), 31--71.Google ScholarDigital Library"",""Tim Donkers, Benedikt Loepp, and Jürgen Ziegler. 2017. Sequential user-based recurrent neural network recommendations. In Proceedings of the Eleventh ACM Conference on Recommender Systems. ACM, Como, Italy, 152--160.Google ScholarDigital Library"",""Travis Ebesu, Bin Shen, and Yi Fang. 2018. Collaborative memory network for recommendation systems. arXiv preprint arXiv:1804.10862 (2018).Google Scholar"",""Thomas G\""artner, Peter A Flach, Adam Kowalczyk, and Alexander J Smola. 2002. Multi-instance kernels. In Proceedings of the Nineteenth International Conference on Machine Learning, Vol. 2. Sydney, Australia, 179--186.Google Scholar"",""Xinran He, Junfeng Pan, Ou Jin, Tianbing Xu, Bo Liu, Tao Xu, Yanxin Shi, Antoine Atallah, Ralf Herbrich, Stuart Bowers, et almbox. 2014. Practical lessons from predicting clicks on ads at facebook. In Proceedings of the Eighth International Workshop on Data Mining for Online Advertising. ACM, New York, NY, USA, 1--9.Google ScholarDigital Library"",""Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2015. Session-based recommendations with recurrent neural networks. arXiv preprint arXiv:1511.06939 (2015).Google Scholar"",""Jin Huang, Wayne Xin Zhao, Hongjian Dou, Ji-Rong Wen, and Edward Y Chang. 2018. Improving sequential recommendation with knowledge-enhanced memory networks. In Proceedings of the Forty-First International ACM SIGIR Conference on Research \u0026 Development in Information Retrieval. ACM, Ann Arbor Michigan, USA, 505--514.Google ScholarDigital Library"",""Andrey Kolobov, Mausam Mausam, Daniel S Weld, and Hector Geffner. 2011. Heuristic search for generalized stochastic shortest path MDPs. In Proceedings of the Twenty-First International Conference on Automated Planning and Scheduling. Freiburg, Germany.Google ScholarDigital Library"",""Hsuan-Tien Lin, Chih-Jen Lin, and Ruby C Weng. 2007. A note on Platt's probabilistic outputs for support vector machines. Machine learning, Vol. 68, 3 (2007), 267--276.Google Scholar"",""Oded Maron and Tomás Lozano-Pérez. 1998. A framework for multiple-instance learning. In Advances in Neural Information Processing Systems. Massachusetts, USA, 570--576.Google Scholar"",""Alexandru Niculescu-Mizil and Rich Caruana. 2005. Predicting good probabilities with supervised learning. In Proceedings of the Twenty-Second International Conference on Machine Learning. ACM, Bonn, Germany, 625--632.Google ScholarDigital Library"",""George H Polychronopoulos and John N Tsitsiklis. 1996. Stochastic shortest path problems with recourse. Networks: An International Journal, Vol. 27, 2 (1996), 133--143.Google ScholarCross Ref"",""Jiaxi Tang and Ke Wang. 2018. Personalized top-n sequential recommendation via convolutional sequence embedding. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. ACM, Los Angeles, California, USA, 565--573.Google ScholarDigital Library"",""Choon Hui Teo, Houssam Nassif, Daniel Hill, Sriram Srinivasan, Mitchell Goodman, Vijai Mohan, and SVN Vishwanathan. 2016. Adaptive, personalized diversity for visual discovery. In Proceedings of The Tenth ACM Conference on Recommender Systems. ACM, Boston, MA, USA, 35--38.Google ScholarDigital Library"",""Felipe W Trevizan, Sylvie Thiébaux, Pedro Henrique Santana, and Brian Charles Williams. 2016. Heuristic search in dual space for constrained stochastic shortest path problems.. In Proceedings of the Thirteenth International Conference on Automated Planning and Scheduling. London, UK, 326--334.Google Scholar"",""Chao-Yuan Wu, Amr Ahmed, Alex Beutel, Alexander J Smola, and How Jing. 2017. Recurrent recommender networks. In Proceedings of The Tenth ACM International Conference on Web Search and Data Mining. ACM, Cambridge, UK, 495--503.Google ScholarDigital Library"",""Qi Zhang and Sally A Goldman. 2002. EM-DD: An improved multiple-instance learning technique. In Advances in Neural Information Processing Systems. Vancouver, British Columbia, Canada, 1073--1080.Google Scholar""]"
https://doi.org/10.1145/3394486.3403330,Domain Specific Knowledge Graphs as a Service to the Public: Powering Social-Impact Funding in the US,"Web and mobile technologies enable ubiquitous access to information. Yet, it is getting harder, even for subject matter experts, to quickly identify quality, trustworthy, and reliable content available online through search engines powered by advanced knowledge graphs. This paper explores the practical applications of Domain Specific Knowledge Graphs that allow for the extraction of information from trusted published and unpublished sources, to map the extracted information to an ontology defined in collaboration with sector experts, and to enable the public to go from single queries into ongoing conversations meeting their knowledge needs reliably. We focused on Social-Impact Funding, an area of need for over one million nonprofit organizations, foundations, government entities, social entrepreneurs, impact investors, and academic institutions in the US.","[{""name"":""Ying Li"",""id"":""/profile/99659575267""},{""name"":""Vitalii Zakhozhyi"",""id"":""/profile/99659573276""},{""name"":""Daniel Zhu"",""id"":""/profile/99659573656""},{""name"":""Luis J. Salazar"",""id"":""/profile/99658731915""},{""name"":""Ying Li"",""id"":""/profile/99659575267""},{""name"":""Vitalii Zakhozhyi"",""id"":""/profile/99659573276""},{""name"":""Daniel Zhu"",""id"":""/profile/99659573656""},{""name"":""Luis J. Salazar"",""id"":""/profile/99658731915""}]","[""Piero A. Bonatti, Michael Cochez, Stefan Decker, Axel, Polleres, and Valentina Presutti. 2018. Knowledge Graphs: New Directions for Knowledge Representation on the Semantic Web. In Dagstuhl Seminar 18371. https://www.dagstuhl.de/18371Google Scholar"",""Samantha Bradshaw and Philip N. Howard. 2019. The Global Disinformation Disorder: 2019 Global Inventory of Organised Social Media Manipulation. https://comprop.oii.ox.ac.uk/research/cybertroops2019/Google Scholar"",""Microsoft Corporation. 2019. Text Analytics API documentation. https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/Google Scholar"",""Lisa Ehrlinger and Wolfram Wöß. 2016. Towards a Definition of Knowledge Graphs. In SEMANTiCS.Google Scholar"",""Emilio Ferrara, Pasquale De Meo, Giacomo Fiumara, and Robert Baumgartner. 2014. Web data extraction, applications and techniques: A survey. Knowledge-Based Systems, Vol. 70 (Nov 2014), 301--323. https://doi.org/10.1016/j.knosys.2014.07.007Google Scholar"",""National Center for Charitable Statistics of the Urban Institute. 2019 a. National Taxonomy of Exempt Entities (NTEE) Codes. https://nccs.urban.org/project/national-taxonomy-exempt-entities-ntee-codesGoogle Scholar"",""National Center for Charitable Statistics of the Urban Institute. 2019 b. The Nonprofit Sector in Brief. https://nccs.urban.org/project/nonprofit-sector-briefGoogle Scholar"",""Yuqing Gao, Jisheng Liang, Benjamin Han, Mohamed Yakout, and Ahmed Mohamed. 2018. Building a Large-Scale, Accurate and Fresh Knowledge Graph. https://kdd2018tutorialt39.azurewebsites.net/KDD%20Tutorial%20T39.pdfGoogle Scholar"",""M.K. Gugerty and D. Karlan. 2018. The Goldilocks Challenge: Right-fit Evidence for the Social Sector. Oxford University Press. 2017043942 https://books.google.com/books?id=6qZTDwAAQBAJGoogle Scholar"",""Dr Lisa Hehenberger, Anna-Marie Harling, and Peter Scholten. 2015. A Practical Guide to Measuring and Managing Impact. Technical Report. European Venture Philanthropy Association. https://evpa.eu.com/knowledge-centre/publications/measuring-and-managing-impact-a-practical-guideGoogle Scholar"",""Arne Holst. 2019. Smartphone Penetration in the US 2010--2021. https://www.statista.com/statistics/201183/forecast-of-smartphone-penetration-in-the-us/Google Scholar"",""Thomas Hubauer, Steffen Lamparter, Peter Haase, and Daniel M. Herzig. 2018. Use Cases of the Industrial Knowledge Graph at Siemens. In International Semantic Web Conference.Google Scholar"",""Ilma Ibrisevic. 2018. Measuring Nonprofit Social Impact: A Crash Course. https://donorbox.org/nonprofit-blog/measuring-nonprofit-social-impact/Google Scholar"",""Google Inc. 2019 a. AutoML Natural Language. https://cloud.google.com/natural-language/#overviewGoogle Scholar"",""Google Inc. 2019 b. Google Machine Learning: Text Classification. https://developers.google.com/machine-learning/guides/text-classification/step-2-5Google Scholar"",""IRS. 2016. IRS 990 Filings on AWS. https://registry.opendata.aws/irs990/Google Scholar"",""Watróbski Jarosŀaw. 2018. An Attempt to Knowledge Conceptualization of Methods and Tools Supporting Ontology Evaluation Process. Procedia Computer Science, Vol. 126 (2018), 2238--2247. https://doi.org/10.1016/j.procs.2018.07.225 Knowledge-Based and Intelligent Information and Engineering Systems: Proceedings of the 22nd International Conference, KES-2018, Belgrade, Serbia.Google ScholarCross Ref"",""Mark Jensen. 2016. Sustainable Development Goals Interface Ontology. In ICBO/BioCreative. https://github.com/SDG-InterfaceOntology/sdgio/tree/master/docs/term%20listsGoogle Scholar"",""Yan Jia, Yulu Qi, Huaijun Shang, Rong Jiang, and Aiping Li. 2018. A Practical Approach to Constructing a Knowledge Graph for Cybersecurity. Engineering, Vol. 4, 1 (2018), 53--60. https://doi.org/10.1016/j.eng.2018.01.004 Cybersecurity.Google ScholarCross Ref"",""Maulik R. Kamdar, Tymor Hamamsy, Shea Shelton, Ayin Vala, Tome Eftimov, James Zou, and Suzanne Tamang. 2019. A Knowledge Graph-based Approach for Exploring the U.S. Opioid Epidemic. arxiv: cs.CY/1905.11513 https://arxiv.org/abs/1905.11513Google Scholar"",""Mayank Kejriwal. 2019. Domain-Specific Knowledge Graph Construction.Springer. https://doi.org/10.1007/978-3-030-12375-8Google Scholar"",""Natthawut Kertkeidkachorn and Ryutaro Ichise. 2017. T2KG: An End-to-End System for Creating Knowledge Graph from Unstructured Text. In AAAI Workshops.Google Scholar"",""Su Nam Kim, Timothy Baldwin, and Min-Yen Kan. 2009. Extracting Domain-Specific Words - A Statistical Approach. In Proceedings of the Australasian Language Technology Association Workshop 2009. Sydney, Australia, 94--98. https://www.aclweb.org/anthology/U09-1013Google Scholar"",""Agnieszka Konys. 2018. Knowledge systematization for ontology learning methods. Procedia Computer Science, Vol. 126 (2018), 2194--2207. https://doi.org/10.1016/j.procs.2018.07.229 Knowledge-Based and Intelligent Information and Engineering Systems: Proceedings of the 22nd International Conference, KES-2018, Belgrade, Serbia.Google ScholarCross Ref"",""Zdeňka Linková, Radim Nedbal, and Martin Rimnac. 2005. Building Ontologies for GIS. (01 2005).Google Scholar"",""Christoper Manning and Hinrich Schütze. 1999. Foundations of Statistical Natural Language Processing.Google Scholar"",""Tomas Mikolov, Kai Chen, Greg S. Corrado, and Jeffrey Dean. 2013. Efficient Estimation of Word Representations in Vector Space. (2013). http://arxiv.org/abs/1301.3781Google Scholar"",""United Nations. 2015. The United Nation Sustainable Development Goals. https://sustainabledevelopment.un.org/sdgsGoogle Scholar"",""M. Nickel, K. Murphy, V. Tresp, and E. Gabrilovich. 2016. A Review of Relational Machine Learning for Knowledge Graphs. Proc. IEEE, Vol. 104, 1 (Jan 2016), 11--33. https://doi.org/10.1109/JPROC.2015.2483592Google ScholarCross Ref"",""Natasha Noy, Yuqing Gao, Anshu Jain, Anant Narayanan, Alan Patterson, and Jamie Taylor. 2019. Industry-Scale Knowledge Graphs: Lessons and Challenges. Commun. ACM, Vol. 62, 8 (July 2019), 36--43. https://doi.org/10.1145/3331166Google Scholar"",""N. Noy and Deborah Mcguinness. 2001. Ontology Development 101: A Guide to Creating Your First Ontology. Knowledge Systems Laboratory, Vol. 32 (01 2001).Google Scholar"",""Jeff Pan, Guido Vetere, Jose Manuel Gomez-Perez, and Honghan Wu. 2017. Exploiting Linked Data and Knowledge Graphs in Large Organisations. https://doi.org/10.1007/978-3-319-45654-6Google Scholar"",""Heiko Paulheim. 2016. Knowledge graph refinement: A survey of approaches and evaluation methods. Semantic Web, Vol. 8 (2016), 489--508.Google ScholarCross Ref"",""Gorka Sadowksi and Philip Rathle. 2017. Fraud Detection: Discovering Connections with Graph Databases. https://go.neo4j.com/rs/710-RRC-335/images/Neo4j_WP-Fraud-Detection-with-Graph-Databases.pdf?_ga=2.152229817.1435723348.1577409683-120002542.1565112145Google Scholar"",""A. Singhal. 2012. Introducing the Knowledge Graph: Things, Not Strings. http://goo.gl/zivFVGoogle Scholar"",""Pedro Szekely, Craig A. Knoblock, Jason Slepicka, Andrew Philpot, Amandeep Singh, Chengye Yin, Dipsy Kapoor, Prem Natarajan, Daniel Marcu, Kevin Knight, David Stallard, Subessware S. Karunamoorthy, Rajagopal Bojanapalli, Steven Minton, Brian Amanatullah, Todd Hughes, Mike Tamayo, David Flynt, Rachel Artiss, Shih-Fu Chang, Tao Chen, Gerald Hiebel, and Lidia Ferreira. 2015. Building and Using a Knowledge Graph to Combat Human Trafficking. In The Semantic Web - ISWC 2015. Springer International Publishing, 205--221.Google Scholar"",""Giving USA. 2019. Giving USA 2019: The Annual Report on Philanthropy for the Year 2018. https://givingusa.org/giving-usa-2019-americans-gave-427--71-billion-to-charity-in-2018-amid-complex-year-for-charitable-giving/Google Scholar"",""Kuansan Wang, Zhihong Shen, Chiyuan Huang, Chieh-Han Wu, Darrin Eide, Yuxiao Dong, Junjie Qian, Anshul Kanakia, Alvin Chen, and Richard Rogahn. 2019. A Review of Microsoft Academic Services for Science of Science Studies. Frontiers in Big Data, Vol. 2 (2019), 45. https://doi.org/10.3389/fdata.2019.00045Google ScholarCross Ref"",""Andrew Winter. 2019. Drug Repositioning Investigation Workflow on a \""Virtualized\"" Knowledge Graph. https://siren.io/drug-repositioning-investigation-on-virtualized-knowledge-graph/Google Scholar"",""Mingxiong Zhao, Han Wang, Jin Guo, Di Liu, Cheng Xie, Qing Liu, and Zhibo Cheng. 2019. Construction of an Industrial Knowledge Graph for Unstructured Chinese Text Learning. Applied Sciences, Vol. 9, 13 (2019). https://doi.org/10.3390/app9132720Google ScholarCross Ref"",""Yueqin Zhu, Wenwen Zhou, Yang Xu, Ji Liu, and Yongjie Tan. 2017. Intelligent Learning for Knowledge Graph towards Geological Data. Scientific Programming, Vol. 2017 (02 2017), 1--13. https://doi.org/10.1155/2017/5072427Google Scholar""]"
https://doi.org/10.1145/3394486.3403331,LRSpeech: Extremely Low-Resource Speech Synthesis and Recognition,"Speech synthesis (text to speech, TTS) and recognition (automatic speech recognition, ASR) are important speech tasks, and require a large amount of text and speech pairs for model training. However, there are more than 6,000 languages in the world and most languages are lack of speech training data, which poses significant challenges when building TTS and ASR systems for extremely low-resource languages. In this paper, we develop LRSpeech, a TTS and ASR system under the extremely low-resource setting, which can support rare languages with low data cost. LRSpeech consists of three key techniques: 1) pre-training on rich-resource languages and fine-tuning on low-resource languages; 2) dual transformation between TTS and ASR to iteratively boost the accuracy of each other; 3) knowledge distillation to customize the TTS model on a high-quality target-speaker voice and improve the ASR model on multiple voices. We conduct experiments on an experimental language (English) and a truly low-resource language (Lithuanian) to verify the effectiveness of LRSpeech. Experimental results show that LRSpeech 1) achieves high quality for TTS in terms of both intelligibility (more than $98%$ intelligibility rate) and naturalness (above 3.5 mean opinion score (MOS)) of the synthesized speech, which satisfy the requirements for industrial deployment, 2) achieves promising recognition accuracy for ASR, and 3) last but not least, uses extremely low-resource training data. We also conduct comprehensive analyses on LRSpeech with different amounts of data resources, and provide valuable insights and guidances for industrial deployment. We are currently deploying LRSpeech into a commercialized cloud speech service to support TTS on more rare languages.","[{""name"":""Jin Xu"",""id"":""/profile/99659573797""},{""name"":""Xu Tan"",""id"":""/profile/99659364242""},{""name"":""Yi Ren"",""id"":""/profile/99659574292""},{""name"":""Tao Qin"",""id"":""/profile/81100549718""},{""name"":""Jian Li"",""id"":""/profile/81548012987""},{""name"":""Sheng Zhao"",""id"":""/profile/99659573467""},{""name"":""Tie-Yan Liu"",""id"":""/profile/81350580267""},{""name"":""Jin Xu"",""id"":""/profile/99659573797""},{""name"":""Xu Tan"",""id"":""/profile/99659364242""},{""name"":""Yi Ren"",""id"":""/profile/99659574292""},{""name"":""Tao Qin"",""id"":""/profile/81100549718""},{""name"":""Jian Li"",""id"":""/profile/81548012987""},{""name"":""Sheng Zhao"",""id"":""/profile/99659573467""},{""name"":""Tie-Yan Liu"",""id"":""/profile/81350580267""}]","[""Mikel Artetxe, Sebastian Ruder, and Dani Yogatama. 2019. On the cross-lingual transferability of monolingual representations. arXiv preprint arXiv:1910.11856 (2019).Google Scholar"",""Alexei Baevski, Michael Auli, and Abdelrahman Mohamed. 2019. Effectiveness of self-supervised pre-training for speech recognition. arXiv preprint arXiv:1911.03912 (2019).Google Scholar"",""Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473 (2014).Google Scholar"",""Antoine Bruguier, Anton Bakhtin, and Dravyansh Sharma. 2018. Dictionary Augmented Sequence-to-Sequence Neural Network for Grapheme to Phoneme Prediction. Proc. Interspeech 2018 (2018), 3733--3737.Google ScholarCross Ref"",""Hui Bu, Jiayu Du, Xingyu Na, Bengu Wu, and Hao Zheng. 2017. Aishell-1: An open-source mandarin speech corpus and a speech recognition baseline. In 2017 20th Conference of the Oriental Chapter of the International Coordinating Committee on Speech Databases and Speech I/O Systems and Assessment (O-COCOSDA). IEEE, 1--5.Google ScholarCross Ref"",""William Chan, Navdeep Jaitly, Quoc Le, and Oriol Vinyals. 2016. Listen, attend and spell: A neural network for large vocabulary conversational speech recognition. In Acoustics, Speech and Signal Processing (ICASSP), 2016 IEEE International Conference on. IEEE, 4960--4964.Google ScholarCross Ref"",""Tian-Yi Chen, Lan Zhang, Shi-Cong Zhang, Zi-Long Li, and Bai-Chuan Huang. 2019 b. Extensible cross-modal hashing. In Proceedings of the 28th International Joint Conference on Artificial Intelligence. AAAI Press, 2109--2115.Google ScholarCross Ref"",""Yi-Chen Chen, Chia-Hao Shen, Sung-Feng Huang, and Hung-yi Lee. 2018. Towards Unsupervised Automatic Speech Recognition Trained by Unaligned Speech and Text only. arXiv preprint arXiv:1803.10952 (2018).Google Scholar"",""Yuan-Jui Chen, Tao Tu, Cheng-chieh Yeh, and Hung-Yi Lee. 2019 a. End-to-end text-to-speech for low-resource languages by cross-lingual transfer learning. Proc. Interspeech 2019 (2019), 2075--2079.Google ScholarCross Ref"",""Chung-Cheng Chiu, Tara N Sainath, Yonghui Wu, Rohit Prabhavalkar, Patrick Nguyen, Zhifeng Chen, Anjuli Kannan, Ron J Weiss, Kanishka Rao, Ekaterina Gonina, et almbox. 2018. State-of-the-art speech recognition with sequence-to-sequence models. In 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 4774--4778.Google ScholarCross Ref"",""Jan Chorowski, Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. End-to-end continuous speech recognition using attention-based recurrent nn: First results. In NIPS 2014 Workshop on Deep Learning, December 2014.Google Scholar"",""Yu-An Chung, Yuxuan Wang, Wei-Ning Hsu, Yu Zhang, and RJ Skerry-Ryan. 2019. Semi-supervised training for improving data efficiency in end-to-end speech synthesis. In ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 6940--6944.Google ScholarCross Ref"",""Erica Cooper, Emily Li, and Julia Hirschberg. 2018. Characteristics of Text-to-Speech and Other Corpora. Proceedings of Speech Prosody 2018 (2018).Google ScholarCross Ref"",""Erica Lindsay Cooper. 2019. Text-to-speech synthesis using found data for low-resource languages. Ph.D. Dissertation. Columbia University.Google Scholar"",""Joel Harband. 2010. Text-to-Speech Costs - Licensing and Pricing. http://elearningtech.blogspot.com/2010/11/text-to-speech-costs-licensing-and.htmlGoogle Scholar"",""Takaaki Hori, Ramon Astudillo, Tomoki Hayashi, Yu Zhang, Shinji Watanabe, and Jonathan Le Roux. 2019. Cycle-consistency training for end-to-end speech recognition. In ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 6271--6275.Google ScholarCross Ref"",""Keith Ito. 2017. The LJ Speech Dataset. https://keithito.com/LJ-Speech-Dataset/.Google Scholar"",""Yoon Kim and Alexander M Rush. 2016. Sequence-Level Knowledge Distillation. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. 1317--1327.Google ScholarCross Ref"",""Patricia K Kuhl, Barbara T Conboy, Sharon Coffey-Corina, Denise Padden, Maritza Rivera-Gaxiola, and Tobey Nelson. 2008. Phonetic learning as a pathway to language: new data and native language magnet theory expanded (NLM-e). Philosophical Transactions of the Royal Society B: Biological Sciences, Vol. 363, 1493 (2008), 979--1000.Google ScholarCross Ref"",""Sigita Laurinčiukaitė, Laimutis Telksnys, Pijus Kasparaitis, Regina Kliukienė, and Vilma Paukštytė 2018. Lithuanian Speech Corpus Liepa for development of human-computer interfaces working in voice recognition and synthesis mode. Informatica, Vol. 29, 3 (2018), 487--498.Google ScholarCross Ref"",""M Paul Lewis and F Gary. 2013. Simons, and Charles D. Fennig (eds.).(2015). Ethnologue: Languages of the World, Dallas, Texas: SIL International. Online version: http://www. ethnologue. com (2013).Google Scholar"",""Naihan Li, Shujie Liu, Yanqing Liu, Sheng Zhao, Ming Liu, and M Zhou. 2019. Neural Speech Synthesis with Transformer Network. AAAI.Google Scholar"",""Alexander H Liu, Tao Tu, Hung-yi Lee, and Lin-shan Lee. 2019. Towards Unsupervised Speech Recognition and Synthesis with Quantized Speech Representation Learning. arXiv preprint arXiv:1910.12729 (2019).Google Scholar"",""Da-Rong Liu, Kuan-Yu Chen, Hung-yi Lee, and Lin-shan Lee. 2018. Completely Unsupervised Phoneme Recognition by Adversarially Learning Mapping Relationships from Audio Embeddings. Proc. Interspeech 2018 (2018), 3748--3752.Google ScholarCross Ref"",""Minh-Thang Luong, Hieu Pham, and Christopher D Manning. 2015. Effective Approaches to Attention-based Neural Machine Translation. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. 1412--1421.Google ScholarCross Ref"",""Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur. 2015. Librispeech: an ASR corpus based on public domain audio books. In 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 5206--5210.Google ScholarCross Ref"",""Daniel S Park, William Chan, Yu Zhang, Chung-Cheng Chiu, Barret Zoph, Ekin D Cubuk, and Quoc V Le. 2019. SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition. Proc. Interspeech 2019 (2019), 2613--2617.Google ScholarCross Ref"",""Wei Ping, Kainan Peng, Andrew Gibiansky, Sercan O. Arik, Ajay Kannan, Sharan Narang, Jonathan Raiman, and John Miller. 2018. Deep Voice 3: 2000-Speaker Neural Text-to-Speech. In International Conference on Learning Representations.Google Scholar"",""Ofir Press and Lior Wolf. 2017. Using the Output Embedding to Improve Language Models. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers. 157--163.Google ScholarCross Ref"",""Yi Ren, Yangjun Ruan, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, and Tie-Yan Liu. 2019 a. Fastspeech: Fast, robust and controllable text to speech. In Advances in Neural Information Processing Systems. 3165--3174.Google Scholar"",""Yi Ren, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, and Tie-Yan Liu. 2019 b. Almost Unsupervised Text to Speech and Automatic Speech Recognition. In International Conference on Machine Learning. 5410--5419.Google Scholar"",""Andrew Rosenberg, Yu Zhang, Bhuvana Ramabhadran, Ye Jia, Pedro Moreno, Yonghui Wu, and Zelin Wu. 2019. Speech Recognition with Augmented Synthesized Speech. arXiv preprint arXiv:1909.11699 (2019).Google Scholar"",""Steffen Schneider, Alexei Baevski, Ronan Collobert, and Michael Auli. 2019. wav2vec: Unsupervised Pre-Training for Speech Recognition. Proc. Interspeech 2019 (2019), 3465--3469.Google ScholarCross Ref"",""Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016. Improving Neural Machine Translation Models with Monolingual Data. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Vol. 1. 86--96.Google ScholarCross Ref"",""Jonathan Shen, Ruoming Pang, Ron J Weiss, Mike Schuster, Navdeep Jaitly, Zongheng Yang, Zhifeng Chen, Yu Zhang, Yuxuan Wang, Rj Skerrv-Ryan, et almbox. 2018. Natural tts synthesis by conditioning wavenet on mel spectrogram predictions. In 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 4779--4783.Google ScholarCross Ref"",""Hao Sun, Xu Tan, Jun-Wei Gan, Hongzhi Liu, Sheng Zhao, Tao Qin, and Tie-Yan Liu. 2019. Token-Level Ensemble Distillation for Grapheme-to-Phoneme Conversion. Proc. Interspeech 2019 (2019), 2115--2119.Google ScholarCross Ref"",""Xu Tan, Yi Ren, Di He, Tao Qin, and Tie-Yan Liu. 2019. Multilingual Neural Machine Translation with Knowledge Distillation. In International Conference on Learning Representations. https://openreview.net/forum?id=S1gUsoR9YXGoogle Scholar"",""Ye Kyaw Thu, Win Pa Pa, Yoshinori Sagisaka, and Naoto Iwahashi. 2016. Comparison of grapheme-to-phoneme conversion methods on a myanmar pronunciation dictionary. In Proceedings of the 6th Workshop on South and Southeast Asian Natural Language Processing (WSSANLP2016). 11--22.Google Scholar"",""Andros Tjandra, Sakriani Sakti, and Satoshi Nakamura. 2017. Listening while speaking: Speech chain by deep learning. In Automatic Speech Recognition and Understanding Workshop (ASRU), 2017 IEEE. IEEE, 301--308.Google ScholarCross Ref"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems. 5998--6008.Google Scholar"",""Yuxuan Wang, RJ Skerry-Ryan, Daisy Stanton, Yonghui Wu, Ron J Weiss, Navdeep Jaitly, Zongheng Yang, Ying Xiao, Zhifeng Chen, Samy Bengio, et almbox. 2017. Tacotron: Towards End-to-End Speech Synthesis. Proc. Interspeech 2017 (2017), 4006--4010.Google ScholarCross Ref"",""Jan Wind. 1989. The evolutionary history of the human speech organs. Studies in language origins, Vol. 1 (1989), 173--197.Google Scholar"",""Junichi Yamagishi, Bela Usabaev, Simon King, Oliver Watts, John Dines, Jilei Tian, Yong Guan, Rile Hu, Keiichiro Oura, Yi-Jian Wu, et almbox. 2010. Thousands of voices for HMM-based speech synthesis--Analysis and application of TTS systems built on various ASR corpora. IEEE Transactions on Audio, Speech, and Language Processing, Vol. 18, 5 (2010), 984--1004.Google ScholarDigital Library"",""Ryuichi Yamamoto, Eunwoo Song, and Jae-Min Kim. 2019. Parallel WaveGAN: A fast waveform generation model based on generative adversarial networks with multi-resolution spectrogram. arXiv preprint arXiv:1910.11480 (2019).Google Scholar"",""Chih-Kuan Yeh, Jianshu Chen, Chengzhu Yu, and Dong Yu. 2019. Unsupervised Speech Recognition via Segmental Empirical Output Distribution Matching. ICLR (2019).Google Scholar"",""Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. 2017. Unpaired image-to-image translation using cycle-consistent adversarial networks. In Proceedings of the IEEE international conference on computer vision. 2223--2232.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403332,Doing in One Go: Delivery Time Inference Based on Couriers' Trajectories,"The rapid development of e-commerce requires efficient and reliable logistics services. Nowadays, couriers are still the main solution to address the ""last mile"" problem in logistics. They are usually required to record the accurate delivery time of each parcel manually, which provides vital information for applications like delivery insurances, delivery performance evaluations, and customer available time discovery. Couriers' trajectories generated by their PDAs provide a chance to infer the delivery time automatically to ease the burdens on the couriers. However, directly using the nearest stay point to infer the delivery time is under satisfactory due to two challenges: 1) inaccurate delivery locations, and 2) various stay scenarios. To this end, we propose Delivery Time Inference (DTInf), to automatically infer the delivery time of waybills based on couriers' trajectories. Our solution is composed of three steps: 1) Data Pre-processing, which detects stay points from trajectories, and separates stay points and waybills by delivery trips, 2) Delivery Location Correction, which infers true delivery locations of waybills by mining historical deliveries, and 3) Delivery Event-based Matching, which selects the best-matched stay point for waybills in the same delivery location to infer the delivery time. Extensive experiments and case studies based on large scale real-world waybill and trajectory data from JD Logistics confirm the effectiveness of our approach. Finally, we introduce a system based on DTInf, which is deployed and used internally in JD Logistics.","[{""name"":""Sijie Ruan"",""id"":""/profile/99659193110""},{""name"":""Zi Xiong"",""id"":""/profile/99659573645""},{""name"":""Cheng Long"",""id"":""/profile/81758961657""},{""name"":""Yiheng Chen"",""id"":""/profile/99659574799""},{""name"":""Jie Bao"",""id"":""/profile/99658970413""},{""name"":""Tianfu He"",""id"":""/profile/99659193606""},{""name"":""Ruiyuan Li"",""id"":""/profile/99658735197""},{""name"":""Shengnan Wu"",""id"":""/profile/99659574725""},{""name"":""Zhongyuan Jiang"",""id"":""/profile/99659232896""},{""name"":""Yu Zheng"",""id"":""/profile/81350600388""},{""name"":""Sijie Ruan"",""id"":""/profile/99659193110""},{""name"":""Zi Xiong"",""id"":""/profile/99659573645""},{""name"":""Cheng Long"",""id"":""/profile/81758961657""},{""name"":""Yiheng Chen"",""id"":""/profile/99659574799""},{""name"":""Jie Bao"",""id"":""/profile/99658970413""},{""name"":""Tianfu He"",""id"":""/profile/99659193606""},{""name"":""Ruiyuan Li"",""id"":""/profile/99658735197""},{""name"":""Shengnan Wu"",""id"":""/profile/99659574725""},{""name"":""Zhongyuan Jiang"",""id"":""/profile/99659232896""},{""name"":""Yu Zheng"",""id"":""/profile/81350600388""}]","[""Basma H Albanna, Ibrahim F Moawad, Sherin M Moussa, and Mahmoud A Sakr. 2015. Semantic trajectories: a survey from modeling to application. In IF\u0026GIS. Springer, 59--76.Google Scholar"",""Luis Otavio Alvares, Vania Bogorny, Bart Kuijpers, Jose Antonio Fernandes de Macedo, Bart Moelans, and Alejandro Vaisman. 2007. A model for enriching trajectories with semantic geographical information. In Proceedings of the 15th annual ACM international symposium on Advances in geographic information systems. 1--8.Google ScholarDigital Library"",""Daniel Ashbrook and Thad Starner. 2002. Learning significant locations and predicting user movement with GPS. In Proceedings. Sixth International Symposium on Wearable Computers. IEEE, 101--108.Google ScholarCross Ref"",""Jie Bao, Tianfu He, Sijie Ruan, Yanhua Li, and Yu Zheng. 2017. Planning Bike Lanes Based on Sharing-Bikes' Trajectories. In KDD. 1377--1386.Google Scholar"",""Dong-Wan Choi, Jian Pei, and Thomas Heinis. 2017. Efficient mining of regional movement patterns in semantic trajectories. VLDB, Vol. 10, 13 (2017), 2073--2084.Google ScholarDigital Library"",""Sina Dabiri and Kevin Heaslip. 2018. Inferring transportation modes from GPS trajectories using a convolutional neural network. Transportation research part C: emerging technologies, Vol. 86 (2018), 360--371.Google Scholar"",""Takashi Fuse and Keita Kamiya. 2017. Statistical anomaly detection in human dynamics monitoring using a hierarchical dirichlet process hidden markov model. TITS, Vol. 18, 11 (2017), 3083--3092.Google Scholar"",""Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. Deep learning. MIT.Google Scholar"",""Songtao He, Favyen Bastani, Sofiane Abbar, Mohammad Alizadeh, Hari Balakrishnan, Sanjay Chawla, and Sam Madden. 2018. RoadRunner: improving the precision of road network inference from GPS trajectories. In SIGSPATIAL. 3--12.Google Scholar"",""Shenggong Ji, Yu Zheng, Zhaoyuan Wang, and Tianrui Li. 2019. A Deep Reinforcement Learning-Enabled Dynamic Redeployment System for Mobile Ambulances. IMWUT, Vol. 3, 1 (2019), 1--20.Google Scholar"",""Shuhui Jiang, Xueming Qian, Tao Mei, and Yun Fu. 2016. Personalized travel sequence recommendation on multi-source big social media. TBD, Vol. 2, 1 (2016), 43--56.Google ScholarCross Ref"",""Ilkcan Keles, Matthias Schubert, Peer Kröger, Simonas vS altenis, and Christian S Jensen. 2017. Extracting visited points of interest from vehicle trajectories. In Proceedings of the Fourth International ACM Workshop on Managing and Mining Enriched Geo-Spatial Data. 1--6.Google ScholarDigital Library"",""Quannan Li, Yu Zheng, Xing Xie, Yukun Chen, Wenyu Liu, and Wei-Ying Ma. 2008. Mining user similarity based on location history. In SIGSPATIAL. ACM, 34.Google Scholar"",""Ruiyuan Li, Huajun He, Rubin Wang, Yuchuan Huang, Junwen Liu, Sijie Ruan, Tianfu He, Jie Bao, and Yu Zheng. 2020. JUST: JD Urban Spatio-Temporal Data Engine. In ICDE. IEEE.Google Scholar"",""Yuhong Li, Jie Bao, Yanhua Li, Yingcai Wu, Zhiguo Gong, and Yu Zheng. 2016. Mining the most influential k-location set from massive trajectories. In SIGSPATIAL. 1--4.Google Scholar"",""Junming Liu, Leilei Sun, Weiwei Chen, and Hui Xiong. 2016. Rebalancing bike sharing systems: A multi-source data smart optimization. In SIGKDD. 1005--1014.Google Scholar"",""Paul Newson and John Krumm. 2009. Hidden Markov map matching through noise and sparseness. In SIGSPATIAL. 336--343.Google Scholar"",""Sijie Ruan, Cheng Long, Jie Bao, Chunyang Li, Zisheng Yu, Ruiyuan Li, Yuxuan Liang, Tianfu He, and Yu Zheng. 2020. Learning to generate maps from trajectories. AAAI.Google Scholar"",""Jun Suzuki, Yoshihiko Suhara, Hiroyuki Toda, and Kyosuke Nishida. 2019. Personalized visited-poi assignment to individual raw GPS trajectories. TSAS, Vol. 5, 3 (2019), 1--28.Google ScholarDigital Library"",""Hongjian Wang, Daniel Kifer, Corina Graif, and Zhenhui Li. 2016. Crime rate inference with big data. In KDD. 635--644.Google Scholar"",""Suyi Wang, Yusu Wang, and Yanjie Li. 2015. Efficient map reconstruction and augmentation via topological methods. In SIGSPATIAL. ACM, 25.Google Scholar"",""Joe H Ward Jr. 1963. Hierarchical grouping to optimize an objective function. Journal of the American statistical association, Vol. 58, 301 (1963), 236--244.Google ScholarCross Ref"",""Zhixian Yan, Dipanjan Chakraborty, Christine Parent, Stefano Spaccapietra, and Karl Aberer. 2013. Semantic trajectories: Mobility data computation and annotation. TIST, Vol. 4, 3 (2013), 1--38.Google ScholarDigital Library"",""Xiuwen Yi, Junbo Zhang, Zhaoyuan Wang, Tianrui Li, and Yu Zheng. 2018. Deep distributed fusion network for air quality prediction. In KDD. 965--973.Google Scholar"",""Jing Yuan, Yu Zheng, Chengyang Zhang, Xing Xie, and Guang-Zhong Sun. 2010. An interactive-voting based map matching algorithm. In MDM. IEEE, 43--52.Google Scholar"",""Huichu Zhang, Yu Zheng, and Yong Yu. 2018b. Detecting urban anomalies using multiple spatio-temporal data sources. IMWUT, Vol. 2, 1 (2018), 1--18.Google Scholar"",""Ping Zhang, Zhifeng Bao, Yuchen Li, Guoliang Li, Yipeng Zhang, and Zhiyong Peng. 2018a. Trajectory-driven influential billboard placement. In KDD. 2748--2757.Google Scholar"",""Yongping Zhang, Diao Lin, and Zhifu Mi. 2019. Electric fence planning for dockless bike-sharing services. Journal of cleaner production, Vol. 206 (2019), 383--393.Google ScholarCross Ref"",""Lisheng Zhao, Jiali Mao, Min Pu, Guoping Liu, Cheqing Jin, Weining Qian, Aoying Zhou, Xiang Wen, Runbo Hu, and Hua Chai. 2020. Automatic Calibration of Road Intersection Topology using Trajectories. (2020).Google Scholar"",""Vincent W Zheng, Yu Zheng, Xing Xie, and Qiang Yang. 2010. Collaborative location and activity recommendations with GPS history data. In WWW. 1029--1038.Google Scholar"",""Yu Zheng. 2015. Trajectory data mining: an overview. TIST, Vol. 6, 3 (2015), 29.Google ScholarDigital Library"",""Yu Zheng, Licia Capra, Ouri Wolfson, and Hai Yang. 2014. Urban computing: concepts, methodologies, and applications. TIST, Vol. 5, 3 (2014), 38.Google ScholarDigital Library"",""Yu Zheng, Like Liu, Longhao Wang, and Xing Xie. 2008. Learning transportation mode from raw gps data for geographic applications on the web. In WWW. 247--256.Google Scholar"",""Yu Zheng, Lizhu Zhang, Xing Xie, and Wei-Ying Ma. 2009. Mining interesting locations and travel sequences from GPS trajectories. In WWW. 791--800.Google Scholar"",""Changqing Zhou, Dan Frankowski, Pamela Ludford, Shashi Shekhar, and Loren Terveen. 2004. Discovering personal gazetteers: an interactive clustering approach. In Proceedings of the 12th annual ACM international workshop on Geographic information systems. 266--273.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403333,Improving Deep Learning for Airbnb Search,"The application of deep learning to search ranking was one of the most impactful product improvements at Airbnb. But what comes next after you launch a deep learning model? In this paper we describe the journey beyond, discussing what we refer to as the ABCs of improving search: A for architecture, ℬ for bias and ℂ for cold start. For architecture, we describe a new ranking neural network, focusing on the process that evolved our existing DNN beyond a fully connected two layer network. On handling positional bias in ranking, we describe a novel approach that led to one of the most significant improvements in tackling inventory that the DNN historically found challenging. To solve cold start, we describe our perspective on the problem and changes we made to improve the treatment of new listings on the platform. We hope ranking teams transitioning to deep learning will find this a practical case study of how to iterate on DNNs.","[{""name"":""Malay Haldar"",""id"":""/profile/99659454547""},{""name"":""Prashant Ramanathan"",""id"":""/profile/99659453226""},{""name"":""Tyler Sax"",""id"":""/profile/99659574845""},{""name"":""Mustafa Abdool"",""id"":""/profile/99659454264""},{""name"":""Lanbo Zhang"",""id"":""/profile/99659573302""},{""name"":""Aamir Mansawala"",""id"":""/profile/99659573846""},{""name"":""Shulin Yang"",""id"":""/profile/99659455034""},{""name"":""Bradley Turnbull"",""id"":""/profile/99659370400""},{""name"":""Junshuo Liao"",""id"":""/profile/99659573176""},{""name"":""Malay Haldar"",""id"":""/profile/99659454547""},{""name"":""Prashant Ramanathan"",""id"":""/profile/99659453226""},{""name"":""Tyler Sax"",""id"":""/profile/99659574845""},{""name"":""Mustafa Abdool"",""id"":""/profile/99659454264""},{""name"":""Lanbo Zhang"",""id"":""/profile/99659573302""},{""name"":""Aamir Mansawala"",""id"":""/profile/99659573846""},{""name"":""Shulin Yang"",""id"":""/profile/99659455034""},{""name"":""Bradley Turnbull"",""id"":""/profile/99659370400""},{""name"":""Junshuo Liao"",""id"":""/profile/99659573176""}]","[""Aman Agarwal, Ivan Zaitsev, Xuanhui Wang, Cheng Li, Marc Najork, and Thorsten Joachims. 2019. Estimating Position Bias Without Intrusive Interventions. In Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining (WSDM '19). ACM, New York, NY, USA, 474--482. https://doi.org/10.1145/3289600.3291017Google ScholarDigital Library"",""Lucas Bernardi, Themistoklis Mavridis, and Pablo Estevez. 2019. 150 Successful Machine Learning Models: 6 Lessons Learned at Booking.Com. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining (KDD '19). ACM, New York, NY, USA, 1743--1751. https://doi.org/10.1145/3292500.3330744Google ScholarDigital Library"",""Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, Rohan Anil, Zakaria Haque, Lichan Hong, Vihan Jain, Xiaobing Liu, and Hemal Shah. 2016. Wide \u0026 Deep Learning for Recommender Systems. In Proceedings of the 1st Workshop on Deep Learning for Recommender Systems (DLRS 2016). ACM, New York, NY, USA, 7--10. https://doi.org/10.1145/2988450.2988454Google ScholarDigital Library"",""Aleksandr Chuklin, Ilya Markov, and Maarten de Rijke. 2015. Click Models for Web Search. Synthesis Lectures on Information Concepts, Retrieval, and Services, Vol. 7, 3 (2015), 1--115. https://doi.org/10.2200/S00654ED1V01Y201507ICR043Google ScholarCross Ref"",""Alex Goldstein, Adam Kapelner, Justin Bleich, and Emil Pitkin. 2015. Peeking Inside the Black Box: Visualizing Statistical Learning With Plots of Individual Conditional Expectation. Journal of Computational and Graphical Statistics, Vol. 24, 1 (2015), 44--65. https://doi.org/10.1080/10618600.2014.907095Google ScholarCross Ref"",""Malay Haldar, Mustafa Abdool, Prashant Ramanathan, Tao Xu, Shulin Yang, Huizhong Duan, Qing Zhang, Nick Barrow-Williams, Bradley C. Turnbull, Brendan M. Collins, and Thomas Legrand. 2019. Applying Deep Learning to Airbnb Search. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining (KDD '19). ACM, New York, NY, USA, 1927--1935. https://doi.org/10.1145/3292500.3330658Google ScholarDigital Library"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep Residual Learning for Image Recognition. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR).Google Scholar"",""Sergey Ioffe and Christian Szegedy. 2015. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. In Proceedings of the 32nd International Conference on Machine Learning (Proceedings of Machine Learning Research), Francis Bach and David Blei (Eds.), Vol. 37. PMLR, Lille, France, 448--456. http://proceedings.mlr.press/v37/ioffe15.htmlGoogle ScholarDigital Library"",""Thorsten Joachims, Adith Swaminathan, and Tobias Schnabel. 2017. Unbiased Learning-to-Rank with Biased Feedback. In Proceedings of the Tenth ACM International Conference on Web Search and Data Mining (WSDM '17). ACM, New York, NY, USA, 781--789. https://doi.org/10.1145/3018661.3018699Google ScholarDigital Library"",""Walid Krichene, Nicolas Mayoraz, Steffen Rendle, Li Zhang, Xinyang Yi, Lichan Hong, Ed Chi, and John Anderson. 2018. Efficient Training on Very Large Corpora via Gramian Estimation. arxiv: stat.ML/1807.07187Google Scholar"",""Andrew I. Schein, Alexandrin Popescul, Lyle H. Ungar, and David M. Pennock. 2002. Methods and Metrics for Cold-start Recommendations. In Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '02). ACM, New York, NY, USA, 253--260. https://doi.org/10.1145/564376.564421Google Scholar"",""Florian Schroff, Dmitry Kalenichenko, and James Philbin. 2015. FaceNet: A Unified Embedding for Face Recognition and Clustering. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR).Google Scholar"",""Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: A Simple Way to Prevent Neural Networks from Overfitting. Journal of Machine Learning Research, Vol. 15 (2014), 1929--1958. http://jmlr.org/papers/v15/srivastava14a.htmlGoogle ScholarDigital Library"",""Chen Sun, Abhinav Shrivastava, Saurabh Singh, and Abhinav Gupta. 2017. Revisiting Unreasonable Effectiveness of Data in Deep Learning Era. In The IEEE International Conference on Computer Vision (ICCV).Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In Advances in Neural Information Processing Systems 30, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.). Curran Associates, Inc., 5998--6008. http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdfGoogle ScholarDigital Library"",""Martin Wattenberg, Fernanda Viégas, and Ian Johnson. 2016. How to Use t-SNE Effectively. Distill (2016). https://doi.org/10.23915/distill.00002Google Scholar"",""Wikipedia. 2019. Control Variable. https://en.wikipedia.org/wiki/Controlling_for_a_variableGoogle Scholar"",""Seungil You, David Ding, Kevin Canini, Jan Pfeifer, and Maya Gupta. 2017. Deep Lattice Networks and Partial Monotonic Functions. In Advances in Neural Information Processing Systems 30, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.). Curran Associates, Inc., 2981--2989. http://papers.nips.cc/paper/6891-deep-lattice-networks-and-partial-monotonic-functions.pdfGoogle Scholar""]"
https://doi.org/10.1145/3394486.3403334,General-Purpose User Embeddings based on Mobile App Usage,"In this paper, we report our recent practice at Tencent for user modeling based on mobile app usage. User behaviors on mobile app usage, including retention, installation, and uninstallation, can be a good indicator for both long-term and short-term interests of users. For example, if a user installs Snapseed recently, she might have a growing interest in photographing. Such information is valuable for numerous downstream applications, including advertising, recommendations, etc. Traditionally, user modeling from mobile app usage heavily relies on handcrafted feature engineering, which requires onerous human work for different downstream applications, and could be sub-optimal without domain experts. However, automatic user modeling based on mobile app usage faces unique challenges, including (1) retention, installation, and uninstallation are heterogeneous but need to be modeled collectively, (2) user behaviors are distributed unevenly over time, and (3) many long-tailed apps suffer from serious sparsity. In this paper, we present a tailored Auto Encoder-coupled Transformer Network (AETN), by which we overcome these challenges and achieve the goals of reducing manual efforts and boosting performance. We have deployed the model at Tencent, and both online/offline experiments from multiple domains of downstream applications have demonstrated the effectiveness of the output user embeddings.","[{""name"":""Junqi Zhang"",""id"":""/profile/99659574384""},{""name"":""Bing Bai"",""id"":""/profile/99659573560""},{""name"":""Ye Lin"",""id"":""/profile/99659573241""},{""name"":""Jian Liang"",""id"":""/profile/99659573706""},{""name"":""Kun Bai"",""id"":""/profile/99659567987""},{""name"":""Fei Wang"",""id"":""/profile/99658710924""},{""name"":""Junqi Zhang"",""id"":""/profile/99659574384""},{""name"":""Bing Bai"",""id"":""/profile/99659573560""},{""name"":""Ye Lin"",""id"":""/profile/99659573241""},{""name"":""Jian Liang"",""id"":""/profile/99659573706""},{""name"":""Kun Bai"",""id"":""/profile/99659567987""},{""name"":""Fei Wang"",""id"":""/profile/99658710924""}]","[""Martíin Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et almbox. 2016. Tensorflow: A system for large-scale machine learning. In 12th USENIX Symposium on Operating Systems Design and Implementation. 265--283.Google ScholarDigital Library"",""Pierre Baldi. 2012. Autoencoders, unsupervised learning, and deep architectures. In Proceedings of ICML workshop on unsupervised and transfer learning. 37--49.Google ScholarDigital Library"",""Yoshua Bengio, Aaron Courville, and Pascal Vincent. 2013. Representation learning: A review and new perspectives. IEEE transactions on pattern analysis and machine intelligence, Vol. 35, 8 (2013), 1798--1828.Google Scholar"",""Narayan Bhamidipati, Ravi Kant, and Shaunak Mishra. 2017. A large scale prediction engine for app install clicks and conversions. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management. ACM, 167--175.Google ScholarDigital Library"",""Tianqi Chen and Carlos Guestrin. 2016. Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining. 785--794.Google ScholarDigital Library"",""Xusong Chen, Dong Liu, Chenyi Lei, Rui Li, Zheng-Jun Zha, and Zhiwei Xiong. 2019. BERT4SessRec: Content-Based Video Relevance Prediction with Bidirectional Encoder Representations from Transformer. In Proceedings of the 27th ACM International Conference on Multimedia. 2597--2601.Google ScholarDigital Library"",""Jean-Baptiste Cordonnier, Andreas Loukas, and Martin Jaggi. 2020. On the Relationship between Self-Attention and Convolutional Layers. In International Conference on Learning Representations.Google Scholar"",""Zihang Dai, Zhilin Yang, Yiming Yang, Jaime G Carbonell, Quoc Le, and Ruslan Salakhutdinov. 2019. Transformer-XL: Attentive Language Models beyond a Fixed-Length Context. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. 2978--2988.Google ScholarCross Ref"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. Bert: Pre-training of deep bidirectional transformers for language understanding. 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics (2019).Google Scholar"",""Djordje Gligorijevic, Jelena Gligorijevic, Aravindan Raghuveer, Mihajlo Grbovic, and Zoran Obradovic. 2018. Modeling mobile user actions for purchase recommendation using deep memory networks. In The 41st International ACM SIGIR Conference on Research \u0026 Development in Information Retrieval. ACM, 1021--1024.Google ScholarDigital Library"",""Jillian Gogel. 2018. AppsFlyer Forecasts Global App Install Ad Spend to Reach $64B by 2020. https://www.appsflyer.com/blog/app-install-ad-spend-predictions-2017--2020/ Retrieved October 22, 2019 from https://www.appsflyer.com/blog/appinstall-ad-spend-predictions-2017-2020/Google Scholar"",""Jiatao Gu, James Bradbury, Caiming Xiong, Victor OK Li, and Richard Socher. 2018. Non-autoregressive neural machine translation. In International Conference on Learning Representations.Google Scholar"",""Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. 2019. Momentum contrast for unsupervised visual representation learning. arXiv preprint arXiv:1911.05722 (2019).Google Scholar"",""Balázs Hidasi and Alexandros Karatzoglou. 2018. Recurrent neural networks with top-k gains for session-based recommendations. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management. ACM, 843--852.Google ScholarDigital Library"",""Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and D Tikk. 2016. Session-based recommendations with recurrent neural networks. In International Conference on Learning Representations.Google Scholar"",""Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural computation, Vol. 9, 8 (1997), 1735--1780.Google Scholar"",""Cheng-Zhi Anna Huang, Ashish Vaswani Jakob Uszkoreit Noam Shazeer, and Monica Dinculescu Douglas Eck. 2019. Music transformer: Generating music with long-term structure. In International Conference on Learning Representations.Google Scholar"",""Nikita Kitaev, Łukasz Kaiser, and Anselm Levskaya. 2020. Reformer: The Efficient Transformer. In International Conference on Learning Representations.Google Scholar"",""Joowon Lee and Dong-Hee Shin. 2016. Targeting potential active users for mobile app install advertising: An exploratory study. International Journal of Human-Computer Interaction, Vol. 32, 11 (2016), 827--834.Google ScholarCross Ref"",""Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, and Jun Ma. 2017. Neural attentive session-based recommendation. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management. ACM, 1419--1428.Google ScholarDigital Library"",""Soo Ling Lim, Peter J Bentley, Natalie Kanakam, Fuyuki Ishikawa, and Shinichi Honiden. 2014. Investigating country differences in mobile app user behavior and challenges for software engineering. IEEE Transactions on Software Engineering, Vol. 41, 1 (2014), 40--64.Google ScholarCross Ref"",""Jixiong Liu, Jiakun Shi, Wanling Cai, Bo Liu, Weike Pan, Qiang Yang, and Zhong Ming. 2017. Transfer Learning from APP Domain to News Domain for Dual Cold-Start Recommendation.. In RecSysKTL. 38--41.Google Scholar"",""Weifeng Liu, Tengzhou Ma, Dapeng Tao, and Jane You. 2016. HSAE: A Hessian regularized sparse auto-encoders. Neurocomputing, Vol. 187 (2016), 59--65.Google ScholarDigital Library"",""Yudan Liu, Kaikai Ge, Xu Zhang, and Leyu Lin. 2019. Real-time Attention Based Look-alike Model for Recommender System. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 2765--2773.Google ScholarDigital Library"",""Eric Hsueh-Chan Lu, Yi-Wei Lin, and Jing-Bin Ciou. 2014. Mining mobile application sequential patterns for usage prediction. In 2014 IEEE International Conference on Granular Computing (GrC). IEEE, 185--190.Google Scholar"",""Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu, and Kun Gai. 2018. Entire space multi-task model: An effective approach for estimating post-click conversion rate. In The 41st International ACM SIGIR Conference on Research \u0026 Development in Information Retrieval. 1137--1140.Google ScholarDigital Library"",""Andrew L Maas, Awni Y Hannun, and Andrew Y Ng. 2013. Rectifier nonlinearities improve neural network acoustic models. In Proc. icml, Vol. 30. 3.Google Scholar"",""Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow, and Brendan Frey. 2015. Adversarial autoencoders. arXiv preprint arXiv:1511.05644 (2015).Google Scholar"",""Ashish Mangalampalli, Adwait Ratnaparkhi, Andrew O Hatch, Abraham Bagherjeiran, Rajesh Parekh, and Vikram Pudi. 2011. A feature-pair-based associative classification approach to look-alike modeling for conversion-oriented user-targeting in tail campaigns. In Proceedings of the 20th international conference companion on World wide web. 85--86.Google ScholarDigital Library"",""Yunchen Pu, Zhe Gan, Ricardo Henao, Xin Yuan, Chunyuan Li, Andrew Stevens, and Lawrence Carin. 2016. Variational autoencoder for deep learning of images, labels and captions. In Advances in neural information processing systems. 2352--2360.Google Scholar"",""Vladan Radosavljevic, Mihajlo Grbovic, Nemanja Djuric, Narayan Bhamidipati, Daneo Zhang, Jack Wang, Jiankai Dang, Haiying Huang, Ananth Nagarajan, and Peiji Chen. 2016. Smartphone app categorization for interest targeting in advertising marketplace. In Proceedings of the 25th International Conference Companion on World Wide Web. International World Wide Web Conferences Steering Committee, 93--94.Google ScholarDigital Library"",""Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management. 1441--1450.Google ScholarDigital Library"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998--6008.Google Scholar"",""Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine Manzagol. 2008. Extracting and composing robust features with denoising autoencoders. In Proceedings of the 25th international conference on Machine learning. 1096--1103.Google ScholarDigital Library"",""Pascal Vincent, Hugo Larochelle, Isabelle Lajoie, Yoshua Bengio, and Pierre-Antoine Manzagol. 2010. Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion. Journal of machine learning research, Vol. 11, Dec (2010), 3371--3408.Google ScholarDigital Library"",""Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. 2017. Deep \u0026 cross network for ad click predictions. In Proceedings of the ADKDD'17. 1--7.Google ScholarDigital Library"",""Daokun Zhang, Jie Yin, Xingquan Zhu, and Chengqi Zhang. 2018. Network representation learning: A survey. IEEE transactions on Big Data (2018).Google Scholar"",""Weinan Zhang, Lingxi Chen, and Jun Wang. 2016. Implicit Look-Alike Modelling in Display Ads. In European Conference on Information Retrieval. Springer, 589--601.Google Scholar"",""Hengshu Zhu, Hui Xiong, Yong Ge, and Enhong Chen. 2014. Mobile app recommendations with security and privacy awareness. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. 951--960.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403335,Unsupervised Translation via Hierarchical Anchoring: Functional Mapping of Places across Cities,"Unsupervised translation has become a popular task in natural language processing (NLP) due to difficulties in collecting large scale parallel datasets. In the urban computing field, place embeddings generated using human mobility patterns via recurrent neural networks are used to understand the functionality of urban areas. Translating place embeddings across cities allow us to transfer knowledge across cities, which may be used for various downstream tasks such as planning new store locations. Despite such advances, current methods fail to translate place embeddings across domains with different scales (e.g. Tokyo to Niigata), due to the straightforward adoption of neural machine translation (NMT) methods from NLP, where vocabulary sizes are similar across languages. We refer to this issue as the domain imbalance problem in unsupervised translation tasks. We address this problem by proposing an unsupervised translation method that translates embeddings by exploiting common hierarchical structures that exist across imbalanced domains. The effectiveness of our method is tested using place embeddings generated from mobile phone data in 6 Japanese cities of heterogeneous sizes. Validation using landuse data clarify that using hierarchical anchors improves the translation accuracy across imbalanced domains. Our method is agnostic to input data type, thus could be applied to unsupervised translation tasks in various fields in addition to linguistics and urban computing.","[{""name"":""Takahiro Yabe"",""id"":""/profile/99659110490""},{""name"":""Kota Tsubouchi"",""id"":""/profile/81385602051""},{""name"":""Toru Shimizu"",""id"":""/profile/99659455489""},{""name"":""Yoshihide Sekimoto"",""id"":""/profile/81490692810""},{""name"":""Satish V. Ukkusuri"",""id"":""/profile/81336493421""},{""name"":""Takahiro Yabe"",""id"":""/profile/99659110490""},{""name"":""Kota Tsubouchi"",""id"":""/profile/81385602051""},{""name"":""Toru Shimizu"",""id"":""/profile/99659455489""},{""name"":""Yoshihide Sekimoto"",""id"":""/profile/81490692810""},{""name"":""Satish V. Ukkusuri"",""id"":""/profile/81336493421""}]","[""Francesco Calabrese, Giusy Di Lorenzo, Liang Liu, and Carlo Ratti. 2011. Estimating Origin-Destination flows using opportunistically collected mobile phone location data from one million users in Boston Metropolitan Area. IEEE Pervasive Computing 10, 4 (2011), 36--44.Google ScholarDigital Library"",""Yizong Cheng. 1995. Mean shift, mode seeking, and clustering. IEEE transactions on pattern analysis and machine intelligence 17, 8 (1995), 790--799.Google Scholar"",""Thomas Louail, Maxime Lenormand, Oliva G Cantu Ros, Miguel Picornell, Ricardo Herranz, Enrique Frias-Martinez, José J Ramasco, and Marc Barthelemy. 2014. From mobile phone data to the spatial structure of cities. Scientific reports 4 (2014), 5276.Google Scholar"",""Takashi Wada and Tomoharu Iwata. 2018. Unsupervised cross-lingual word embedding by multilingual neural language models. arXiv preprint arXiv:1809.02306 (2018Google Scholar""]"
https://doi.org/10.1145/3394486.3403336,Debiasing Grid-based Product Search in E-commerce,"The widespread usage of e-commerce websites in daily life and the resulting wealth of implicit feedback data form the foundation for systems that train and test e-commerce search ranking algorithms. While convenient to collect, implicit feedback data inherently suffers from various types of bias since user feedback is limited to products they are exposed to by existing search ranking algorithms and impacted by how the products are displayed. In the literature, a vast majority of existing methods have been proposed towards unbiased learning to rank for list-based web search scenarios. However, such methods cannot be directly adopted by e-commerce websites mainly for two reasons. First, in e-commerce websites, search engine results pages (SERPs) are displayed in 2-dimensional grids. The existing methods have not considered the difference in user behavior between list-based web search and grid-based product search. Second, there can be multiple types of implicit feedback (e.g., clicks and purchases) on e-commerce websites. We aim to utilize all types of implicit feedback as the supervision signals. In this work, we extend unbiased learning to rank to the world of e-commerce search via considering a grid-based product search scenario. We propose a novel framework which (1) forms the theoretical foundations to allow multiple types of implicit feedback in unbiased learning to rank and (2) incorporates the row skipping and slower decay click models to capture unique user behavior patterns in grid-based product search for inverse propensity scoring. Through extensive experiments on real-world e-commerce search log datasets across browsing devices and product taxonomies, we show that the proposed framework outperforms the state of the art unbiased learning to rank algorithms. These results also reveal important insights on how user behavior patterns vary in e-commerce SERPs across browsing devices and product taxonomies.","[{""name"":""Ruocheng Guo"",""id"":""/profile/99659315332""},{""name"":""Xiaoting Zhao"",""id"":""/profile/99659535690""},{""name"":""Adam Henderson"",""id"":""/profile/99659347226""},{""name"":""Liangjie Hong"",""id"":""/profile/81438595662""},{""name"":""Huan Liu"",""id"":""/profile/81557050356""},{""name"":""Ruocheng Guo"",""id"":""/profile/99659315332""},{""name"":""Xiaoting Zhao"",""id"":""/profile/99659535690""},{""name"":""Adam Henderson"",""id"":""/profile/99659347226""},{""name"":""Liangjie Hong"",""id"":""/profile/81438595662""},{""name"":""Huan Liu"",""id"":""/profile/81557050356""}]","[""Aman Agarwal, Ivan Zaitsev, and Thorsten Joachims. 2018. Counterfactual Learning-to-Rank for Additive Metrics and Deep Models. arXiv preprint arXiv:1805.00065 (2018).Google Scholar"",""Qingyao Ai, Keping Bi, Cheng Luo, Jiafeng Guo, and W Bruce Croft. 2018. Unbiased Learning to Rank with Unbiased Propensity Estimation. In The 41st International ACM SIGIR Conference on Research \u0026 Development in Information Retrieval. ACM, 385--394.Google ScholarDigital Library"",""Qingyao Ai, Yongfeng Zhang, Keping Bi, Xu Chen, and W Bruce Croft. 2017. Learning a hierarchical embedding model for personalized product search. In SIGIR. ACM, 645--654.Google Scholar"",""Leo Breiman. 2001. Random forests. Machine learning, Vol. 45, 1 (2001), 5--32.Google Scholar"",""Christopher JC Burges. 2010. From ranknet to lambdarank to lambdamart: An overview. Learning, Vol. 11, 23--581 (2010), 81.Google Scholar"",""Zhe Cao, Tao Qin, Tie-Yan Liu, Ming-Feng Tsai, and Hang Li. 2007. Learning to rank: from pairwise approach to listwise approach. In ICML. ACM, 129--136.Google Scholar"",""Nick Craswell, Onno Zoeter, Michael Taylor, and Bill Ramsey. 2008. An experimental comparison of click position-bias models. In WSDM. ACM, 87--94.Google Scholar"",""Yoav Freund, Raj Iyer, Robert E Schapire, and Yoram Singer. 2003. An efficient boosting algorithm for combining preferences. JML, Vol. 4, Nov (2003), 933--969.Google Scholar"",""Jerome H Friedman. 2001. Greedy function approximation: a gradient boosting machine. Annals of statistics (2001), 1189--1232.Google Scholar"",""Anjan Goswami, Prasant Mohapatra, and Chengxiang Zhai. 2019. Quantifying and Visualizing the Demand and Supply Gap from E-commerce Search Data using Topic Models. In Companion Proceedings of WWW. ACM, 348--353.Google ScholarDigital Library"",""Anjan Goswami, ChengXiang Zhai, and Prasant Mohapatra. 2018. Towards Optimization of E-Commerce Search and Discovery. In The 2018 SIGIR Workshop On eCommerce.Google Scholar"",""Ruocheng Guo, Lu Cheng, Jundong Li, P Richard Hahn, and Huan Liu. 2018. A survey of learning causality with data: Problems and methods. arXiv preprint arXiv:1809.09337 (2018).Google Scholar"",""Malay Haldar, Mustafa Abdool, Prashant Ramanathan, Tao Xu, Shulin Yang, Huizhong Duan, Qing Zhang, Nick Barrow-Williams, Bradley C Turnbull, Brendan M Collins, et almbox. 2019. Applying deep learning to Airbnb search. In SIGKDD. ACM, 1927--1935.Google ScholarDigital Library"",""Ziniu Hu, Yang Wang, Qu Peng, and Hang Li. 2019. Unbiased LambdaMART: An Unbiased Pairwise Learning-to-Rank Algorithm. In The World Wide Web Conference. ACM, 2830--2836.Google Scholar"",""Thorsten Joachims. 2002. Optimizing search engines using clickthrough data. SIGKDD. ACM, 133--142.Google Scholar"",""Thorsten Joachims, Adith Swaminathan, and Tobias Schnabel. 2017. Unbiased learning-to-rank with biased feedback. In Proceedings of the Tenth ACM International Conference on Web Search and Data Mining. ACM, 781--789.Google ScholarDigital Library"",""Shubhra Kanti Karmaker Santu, Parikshit Sondhi, and ChengXiang Zhai. 2017. On application of learning to rank for e-commerce search. In SIGIR. ACM, 475--484.Google Scholar"",""Alistair Moffat and Justin Zobel. 2008. Rank-biased precision for measurement of retrieval effectiveness. TOIS, Vol. 27, 1 (2008), 2.Google ScholarDigital Library"",""Daria Sorokina and Erick Cantu-Paz. 2016. Amazon search: The joy of ranking products. In SIGIR. ACM, 459--460.Google Scholar"",""Andrew Stanton, Liangjie Hong, and Manju Rajashekhar. 2018. Buzzsaw: A System for High Speed Feature Engineering. In SysML.Google Scholar"",""Christophe Van Gysel, Maarten de Rijke, and Evangelos Kanoulas. 2016. Learning latent vector spaces for product search. CIKM. ACM, 165--174.Google Scholar"",""Xuanhui Wang, Michael Bendersky, Donald Metzler, and Marc Najork. 2016. Learning to rank with selection bias in personal search. In SIGIR. ACM, 115--124.Google Scholar"",""Xuanhui Wang, Nadav Golbandi, Michael Bendersky, Donald Metzler, and Marc Najork. 2018. Position bias estimation for unbiased learning to rank in personal search. In WSDM. ACM, 610--618.Google Scholar"",""Liang Wu, Diane Hu, Liangjie Hong, and Huan Liu. 2018. Turning clicks into purchases: Revenue optimization for product search in e-commerce. In The 41st International ACM SIGIR Conference on Research \u0026 Development in Information Retrieval. ACM, 365--374.Google ScholarDigital Library"",""Qiang Wu, Christopher JC Burges, Krysta M Svore, and Jianfeng Gao. 2010. Adapting boosting for information retrieval measures. Information Retrieval, Vol. 13, 3 (2010), 254--270.Google ScholarDigital Library"",""Fen Xia, Tie-Yan Liu, Jue Wang, Wensheng Zhang, and Hang Li. 2008. Listwise approach to learning to rank: theory and algorithm. In ICML. ACM, 1192--1199.Google Scholar"",""Xiaohui Xie, Jiaxin Mao, Yiqun Liu, Maarten de Rijke, Yunqiu Shao, Zixin Ye, Min Zhang, and Shaoping Ma. 2019. Grid-based Evaluation Metrics for Web Image Search. (2019).Google Scholar""]"
https://doi.org/10.1145/3394486.3403337,Forecasting the Evolution of Hydropower Generation,"Hydropower is the largest renewable energy source for electricity generation in the world, with numerous benefits in terms of: environment protection (near-zero air pollution and climate impact), cost-effectiveness (long-term use, without significant impacts of market fluctuation), and reliability (quickly respond to surge in demand). However, the effectiveness of hydropower plants is affected by multiple factors such as reservoir capacity, rainfall, temperature and fluctuating electricity demand, and particularly their complicated relationships, which make the prediction/recommendation of station operational output a difficult challenge. In this paper, we present DeepHydro, a novel stochastic method for modeling multivariate time series (e.g., water inflow/outflow and temperature) and forecasting power generation of hydropower stations. DeepHydro captures temporal dependencies in co-evolving time series with a new conditioned latent recurrent neural networks, which not only considers the hidden states of observations but also preserves the uncertainty of latent variables. We introduce a generative network parameterized on a continuous normalizing flow to approximate the complex posterior distribution of multivariate time series data, and further use neural ordinary differential equations to estimate the continuous-time dynamics of the latent variables constituting the observable data. This allows our model to deal with the discrete observations in the context of continuous dynamic systems, while being robust to the noise. We conduct extensive experiments on real-world datasets from a large power generation company consisting of cascade hydropower stations. The experimental results demonstrate that the proposed method can effectively predict the power production and significantly outperform the possible candidate baseline approaches.","[{""name"":""Fan Zhou"",""id"":""/profile/81472647601""},{""name"":""Liang Li"",""id"":""/profile/99659573620""},{""name"":""Kunpeng Zhang"",""id"":""/profile/99658632396""},{""name"":""Goce Trajcevski"",""id"":""/profile/81100539524""},{""name"":""Fuming Yao"",""id"":""/profile/99659573829""},{""name"":""Ying Huang"",""id"":""/profile/99659573694""},{""name"":""Ting Zhong"",""id"":""/profile/99659316153""},{""name"":""Jiahao Wang"",""id"":""/profile/99659575236""},{""name"":""Qiao Liu"",""id"":""/profile/81501672985""},{""name"":""Fan Zhou"",""id"":""/profile/81472647601""},{""name"":""Liang Li"",""id"":""/profile/99659573620""},{""name"":""Kunpeng Zhang"",""id"":""/profile/99658632396""},{""name"":""Goce Trajcevski"",""id"":""/profile/81100539524""},{""name"":""Fuming Yao"",""id"":""/profile/99659573829""},{""name"":""Ying Huang"",""id"":""/profile/99659573694""},{""name"":""Ting Zhong"",""id"":""/profile/99659316153""},{""name"":""Jiahao Wang"",""id"":""/profile/99659575236""},{""name"":""Qiao Liu"",""id"":""/profile/81501672985""}]","[""Anastasia Borovykh, Sander Bohte, and Cornelis W Oosterlee. 2017. Conditional time series forecasting with convolutional neural networks. arXiv preprint arXiv:1703.04691 (2017).Google Scholar"",""Juan Chen and Ping-An Zhong. 2019. A multi-time-scale power prediction model of hydropower station considering multiple uncertainties. Science of The Total Environment, Vol. 677 (2019), 612--625.Google ScholarCross Ref"",""Pudi Chen, Shenghua Liu, Chuan Shi, Bryan Hooi, Bai Wang, and Xueqi Cheng. 2018a. NeuCast: Seasonal Neural Forecast of Power Grid Time Series. In IJCAI. 3315--3321.Google Scholar"",""Tian Qi Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud. 2018b. Neural ordinary differential equations. In NeuIPS.Google Scholar"",""Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. 2014. Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555 (2014).Google Scholar"",""Djork-Arné Clevert, Thomas Unterthiner, and Sepp Hochreiter. 2015. Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs). arXiv preprint arXiv:1511.07289 (2015).Google Scholar"",""John R Dormand and Peter J Prince. 1980. A family of embedded Runge-Kutta formulae. Journal of computational and applied mathematics, Vol. 6, 1 (1980), 19--26.Google ScholarCross Ref"",""Chenyou Fan, Yuze Zhang, Yi Pan, Xiaoyue Li, Chi Zhang, Rong Yuan, Di Wu, Wensheng Wang, Jian Pei, and Heng Huang. 2019. Multi-Horizon Time Series Forecasting with Temporal Attention Learning. In KDD. 2527--2535.Google Scholar"",""Marco Fraccaro, Søren Kaae Sønderby, Ulrich Paquet, and Ole Winther. 2016. Sequential neural models with stochastic layers. In NIPS. 2199--2207.Google Scholar"",""Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural computation, Vol. 9, 8 (1997), 1735--1780.Google Scholar"",""Bryan Hooi, Hyun Ah Song, Amritanshu Pandey, Marko Jereminov, Larry Pileggi, and Christos Faloutsos. 2018. Streamcast: Fast and online mining of power grid time sequences. In SDM. SIAM, 531--539.Google Scholar"",""Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, and Eric P Xing. 2017. Toward controlled generation of text. In ICML. 1587--1596.Google Scholar"",""Kyle Hundman, Valentino Constantinou, Christopher Laporte, Ian Colwell, and Tom Soderstrom. 2018. Detecting spacecraft anomalies using lstms and nonparametric dynamic thresholding. In KDD. 387--395.Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv: 1412.6980 (2014).Google Scholar"",""Diederik P Kingma and Max Welling. 2014. Auto-encoding variational bayes. In ICLR.Google Scholar"",""Yuxuan Liang, Kun Ouyang, Lin Jing, Sijie Ruan, Ye Liu, Junbo Zhang, David S Rosenblum, and Yu Zheng. 2019. UrbanFM: Inferring Fine-Grained Urban Flows. In KDD. 3132--3142.Google Scholar"",""Qiao Liu, Yifu Zeng, Refuoe Mokhosi, and Haibin Zhang. 2018. STAMP: short-term attention/memory priority model for session-based recommendation. In KDD. 1831--1839.Google Scholar"",""Zheyi Pan, Yuxuan Liang, Weifeng Wang, Yong Yu, Yu Zheng, and Junbo Zhang. 2019. Urban traffic prediction from spatio-temporal data using deep meta learning. In KDD. 1720--1730.Google Scholar"",""Yue Pang, Bo Yao, Xiangdong Zhou, Yong Zhang, Yiming Xu, and Zijing Tan. 2018. Hierarchical Electricity Time Series Forecasting for Integrating Consumption Patterns Analysis and Aggregation Consistency.. In IJCAI. 3506--3512.Google Scholar"",""George Papamakarios, Eric Nalisnick, Danilo Jimenez Rezende, Shakir Mohamed, and Balaji Lakshminarayanan. 2019. Normalizing Flows for Probabilistic Modeling and Inference. arXiv preprint arXiv:1912.02762 (2019).Google Scholar"",""Syama Sundar Rangapuram, Matthias W. Seeger, Jan Gasthaus, Lorenzo Stella, Yuyang Wang, and Tim Januschowski. 2018. Deep State Space Models for Time Series Forecasting. In NeurIPS. 7796--7805.Google Scholar"",""Danilo Rezende and Shakir Mohamed. 2015. Variational Inference with Normalizing Flows. In ICML. 1530--1538.Google Scholar"",""Yulia Rubanova, Tian Qi Chen, and David K Duvenaud. 2019. Latent Ordinary Differential Equations for Irregularly-Sampled Time Series. In NeurIPS. 5321--5331.Google Scholar"",""Tárik S Salem, Karan Kathuria, Heri Ramampiaro, and Helge Langseth. 2019. Forecasting intra-hour imbalances in electric power systems. In AAAI, Vol. 33. 9595--9600.Google ScholarCross Ref"",""Rajat Sen, Hsiang-Fu Yu, and Inderjit S Dhillon. 2019. Think globally, act locally: A deep neural network approach to high-dimensional time series forecasting. In NeurIPS. 4838--4847.Google Scholar"",""Maximilian Sölch, Justin Bayer, Marvin Ludersdorfer, and Patrick van der Smagt. 2016. Variational inference for on-line anomaly detection in high-dimensional time series. arXiv preprint arXiv:1602.07109 (2016).Google Scholar"",""Dongjin Song, Ning Xia, Wei Cheng, Haifeng Chen, and Dacheng Tao. 2018. Deep r-th Root of Rank Supervised Joint Binary Embedding for Multivariate Time Series Retrieval. KDD (2018), 2229--2238.Google Scholar"",""Hyun Ah Song, Bryan Hooi, Marko Jereminov, Amritanshu Pandey, Larry Pileggi, and Christos Faloutsos. 2017. PowerCast: Mining and forecasting power grid sequences. In ECML-PKDD. 606--621.Google Scholar"",""Ya Su, Youjian Zhao, Chenhao Niu, Rong Liu, Wei Sun, and Dan Pei. 2019. Robust Anomaly Detection for Multivariate Time Series through Stochastic Recurrent Neural Network. In KDD. 2828--2837.Google Scholar"",""Jingyuan Wang, Yang Zhang 0032, Ke Tang, Junjie Wu, and Zhang Xiong. 2019. AlphaStock: A Buying-Winners-and-Selling-Losers Investment Strategy using Interpretable Deep Reinforcement Attention Networks. KDD (2019), 1900--1908.Google ScholarDigital Library"",""Jingyuan Wang, Ze Wang, Jianfeng Li, and Junjie Wu. 2018. Multilevel Wavelet Decomposition Network for Interpretable Time Series Analysis. In KDD. 2437--2446.Google Scholar"",""Haowen Xu, Wenxiao Chen, Nengwen Zhao, Zeyan Li, Jiahao Bu, Zhihan Li, Ying Liu, Youjian Zhao, Dan Pei, Yang Feng, et almbox. 2018. Unsupervised anomaly detection via variational auto-encoder for seasonal kpis in web applications. In WWW. 187--196.Google Scholar"",""Yumo Xu and Shay B Cohen. 2018. Stock Movement Prediction from Tweets and Historical Prices. ACL (2018), 1970--1979.Google ScholarCross Ref"",""Ting Zhong, Zijing Wen, Fan Zhou, Goce Trajcevski, and Kunpeng Zhang. 2020. Session-based Recommendation via Flow-based Deep Generative Networks and Bayesian Inference. Neurocomputing (2020).Google Scholar"",""Ali Ziat, Edouard Delasalles, Ludovic Denoyer, and Patrick Gallinari. 2017. Spatio-Temporal Neural Networks for Space-Time Series Forecasting and Relations Discovery. In ICDM. 705--714.Google Scholar""]"
https://doi.org/10.1145/3394486.3403338,Salience and Market-aware Skill Extraction for Job Targeting,"At LinkedIn, we want to create economic opportunity for everyone in the global workforce. To make this happen, LinkedIn offers a reactive Job Search system, and a proactive Jobs You May Be Interested In (JYMBII) system to match the best candidates with their dream jobs. One of the most challenging tasks for developing these systems is to properly extract important skill entities from job postings and then target members with matched attributes. In this work, we show that the commonly used text-based salience and market-agnostic skill extraction approach is sub-optimal because it only considers skill mention and ignores the salient level of a skill and its market dynamics, i.e., the market supply and demand influence on the importance of skills. To address the above drawbacks, we present Job2Skills, our deployed salience and market-aware skill extraction system. The proposed Job2Skills shows promising results in improving the online performance of job recommendation (JYMBII) (+1.92% job apply) and skill suggestions for job posters (-37% suggestion rejection rate). Lastly, we present case studies to show interesting insights that contrast traditional skill recognition method and the proposed Job2Skills from occupation, industry, country, and individual skill levels. Based on the above promising results, we deployed the Job2Skills online to extract job targeting skills for all 20M job postings served at LinkedIn.","[{""name"":""Baoxu Shi"",""id"":""/profile/99659535228""},{""name"":""Jaewon Yang"",""id"":""/profile/81479641186""},{""name"":""Feng Guo"",""id"":""/profile/99659574557""},{""name"":""Qi He"",""id"":""/profile/81508702134""},{""name"":""Baoxu Shi"",""id"":""/profile/99659535228""},{""name"":""Jaewon Yang"",""id"":""/profile/81479641186""},{""name"":""Feng Guo"",""id"":""/profile/99659574557""},{""name"":""Qi He"",""id"":""/profile/81508702134""}]","[""Fabian Abel. 2015. We know where you should work next summer: job recommendations. In RecSys.Google Scholar"",""Fabian Abel, Yashar Deldjoo, Mehdi Elahi, and Daniel Kohlsdorf. 2017. Recsys challenge 2017: Offline and online evaluation. In RecSys.Google Scholar"",""Deepak Agarwal, Bee-Chung Chen, and Pradheep Elango. 2009. Spatio-temporal models for estimating click-through rate. In WWW.Google Scholar"",""David H Autor, Frank Levy, and Richard J Murnane. 2003. The skill content of recent technological change: An empirical exploration. The Quarterly journal of economics, Vol. 118, 4 (2003).Google Scholar"",""Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. Enriching word vectors with subword information. TACL, Vol. 5 (2017).Google ScholarCross Ref"",""Fedor Borisyuk, Liang Zhang, and Krishnaram Kenthapadi. 2017. LiJAR: A system for job application redistribution towards efficient career marketplace. In KDD.Google Scholar"",""Daniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua, Nicole Limtiaco, Rhomni St John, Noah Constant, Mario Guajardo-Cespedes, Steve Yuan, Chris Tar, et almbox. 2018. Universal sentence encoder. arXiv preprint arXiv:1803.11175 (2018).Google Scholar"",""Tianqi Chen and Carlos Guestrin. 2016. Xgboost: A scalable tree boosting system. In KDD.Google ScholarDigital Library"",""Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et almbox. 2016. Wide \u0026 deep learning for recommender systems. In DLRS.Google Scholar"",""National Research Council et almbox. 2010. A database for a changing economy: Review of the Occupational Information Network (O* NET).Google Scholar"",""Vachik S Dave, Baichuan Zhang, Mohammad Al Hasan, Khalifeh AlJadda, and Mohammed Korayem. 2018. A combined representation learning approach for better job and skill recommendation. In CIKM.Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).Google Scholar"",""Yupeng Gu, Bo Zhao, David Hardtke, and Yizhou Sun. 2016. Learning global term weights for content-based recommender systems. In WWW.Google Scholar"",""Cheng Guo, Hongyu Lu, Shaoyun Shi, Bin Hao, Bin Liu, Min Zhang, Yiqun Liu, and Shaoping Ma. 2017. How Integration helps on Cold-Start Recommendations. In RecSys Challenge 2017.Google Scholar"",""Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In WWW.Google Scholar"",""Chao Huang, Xian Wu, Xuchao Zhang, Chuxu Zhang, Jiashu Zhao, Dawei Yin, and Nitesh V Chawla. 2019. Online Purchase Prediction via Multi-Scale Modeling of Behavior Dynamics. In KDD.Google Scholar"",""Brian Johnston, Benjamin Zweig, Michael Peran, Charlie Wang, and Rachel Rosenfeld. 2017. Estimating skill fungibility and forecasting services labor demand. In Big Data.Google Scholar"",""Krishnaram Kenthapadi, Benjamin Le, and Ganesh Venkataraman. 2017. Personalized job recommendation system at linkedin: Practical challenges and lessons learned. In RecSys.Google Scholar"",""Jia Li, Dhruv Arya, Viet Ha-Thuc, and Shakti Sinha. 2016. How to get them a dream job?: Entity-aware features for personalized job search ranking. In KDD.Google Scholar"",""Liangyue Li, How Jing, Hanghang Tong, Jaewon Yang, Qi He, and Bee-Chung Chen. 2017. Nemo: Next career move prediction with contextual embedding. In WWW.Google ScholarDigital Library"",""Shan Li, Baoxu Shi, Jaewon Yang, Ji Yan, Shuai Wang, Fei Chen, and Qi He. 2020. Deep Job Understanding at LinkedIn. In SIGIR.Google Scholar"",""Yin Lou and Mikhail Obukhov. 2017. BDT: Gradient Boosted Decision Tables for High Accuracy and Scoring Efficiency. In KDD.Google ScholarDigital Library"",""Qingxin Meng, Hengshu Zhu, Keli Xiao, Le Zhang, and Hui Xiong. 2019. A Hierarchical Career-Path-Aware Neural Network for Job Mobility Prediction. In KDD. ACM.Google Scholar"",""David Nadeau and Satoshi Sekine. 2007. A survey of named entity recognition and classification. Lingvisticae Investigationes, Vol. 30, 1 (2007).Google Scholar"",""Ioannis Paparrizos, B Barla Cambazoglu, and Aristides Gionis. 2011. Machine learned job recommendation. In RecSys.Google Scholar"",""Norman G Peterson, Michael D Mumford, Walter C Borman, P Richard Jeanneret, Edwin A Fleishman, Kerry Y Levin, Michael A Campion, Melinda S Mayfield, Frederick P Morgeson, Kenneth Pearlman, et almbox. 2001. Understanding work using the Occupational Information Network (O* NET): Implications for practice and research. Personnel Psychology, Vol. 54, 2 (2001).Google ScholarCross Ref"",""Bipin Prabhakar, Charles R Litecky, and Kirk Arnett. 2005. IT skills in a tough job market. Commun. ACM, Vol. 48, 10 (2005).Google ScholarDigital Library"",""Chuan Qin, Hengshu Zhu, Tong Xu, Chen Zhu, Liang Jiang, Enhong Chen, and Hui Xiong. 2018. Enhancing person-job fit for talent recruitment: An ability-aware neural network approach. In SIGIR.Google Scholar"",""Chuan Qin, Hengshu Zhu, Chen Zhu, Tong Xu, Fuzhen Zhuang, Chao Ma, Jingshuai Zhang, and Hui Xiong. 2019. DuerQuiz: A Personalized Question Recommender System for Intelligent Job Interview. In KDD.Google Scholar"",""Alex Radermacher, Gursimran Walia, and Dean Knudson. 2014. Investigating the skill gap between graduating students and industry expectations. In ICSE.Google Scholar"",""Rohan Ramanath, Hakan Inan, Gungor Polatkan, Bo Hu, Qi Guo, Cagri Ozcaglar, Xianren Wu, Krishnaram Kenthapadi, and Sahin Cem Geyik. 2018. Towards Deep and Representation Learning for Talent Search at LinkedIn. In CIKM. 2253--2261.Google Scholar"",""Ellu Saar and Mari Liis Räis. 2017. Participation in job-related training in European countries: the impact of skill supply and demand characteristics. Journal of Education and Work, Vol. 30, 5 (2017).Google ScholarCross Ref"",""Baoxu Shi, Shan Li, Jaewon Yang, Mustafa Emre Kazdagli, and Qi He. 2020. Learning to Ask Screening Questions for Job Postings. In SIGIR.Google Scholar"",""Baoxu Shi, Jaewon Yang, Tim Weninger, Jing How, and Qi He. 2019. Representation Learning in Heterogeneous Professional Social Networks with Ambiguous Social Connections. In IEEE BigData.Google Scholar"",""Ying Sun, Fuzhen Zhuang, Hengshu Zhu, Xin Song, Qing He, and Hui Xiong. 2019. The Impact of Person-Organization Fit on Talent Management: A Structure-Aware Convolutional Neural Network Approach. In KDD.Google Scholar"",""Shrihari Vasudevan, Moninder Singh, Joydeep Mondal, Michael Peran, Benjamin Zweig, Brian Johnston, and Rachel Rosenfeld. 2018. Estimating Fungibility Between Skills by Combining Skill Similarities Obtained from Multiple Data Sources. Data Science and Engineering, Vol. 3, 3 (2018).Google ScholarCross Ref"",""Maksims Volkovs, Guang Wei Yu, and Tomi Poutanen. 2017. Content-based Neighbor Models for Cold Start in Recommender Systems. In RecSys.Google Scholar"",""Wei Lee Woon, Zeyar Aung, Wala AlKhader, Davor Svetinovic, and Mohammad Atif Omar. 2015. Changes in occupational skills-a case study using non-negative matrix factorization. In ICONIP.Google Scholar"",""Xunxian Wu, Tong Xu, Hengshu Zhu, Le Zhang, Enhong Chen, and Hui Xiong. 2019. Trend-aware tensor factorization for job skill demand analysis. In IJCAI.Google Scholar"",""Lianghao Xia, Chao Huang, Yong Xu, Peng Dai, Bo Zhang, and Liefeng Bo. 2020. Multiplex Behavioral Relation Learning for Recommendation via Memory Augmented Transformer Network. In SIGIR.Google Scholar"",""Tong Xu, Hengshu Zhu, Chen Zhu, Pan Li, and Hui Xiong. 2018. Measuring the popularity of job skills in recruitment market: A multi-criteria approach. In AAAI.Google Scholar"",""Xiao Yan, Jaewon Yang, Mikhail Obukhov, Lin Zhu, Joey Bai, Shiqi Wu, and Qi He. 2019. Social Skill Validation at LinkedIn. In KDD.Google Scholar"",""Yuyang Ye, Hengshu Zhu, Tong Xu, Fuzhen Zhuang, Runlong Yu, and Hui Xiong. 2019. Identifying High Potential Talent: A Neural Network Based Dynamic Social Profiling Approach. In ICDM.Google Scholar"",""XianXing Zhang, Yitong Zhou, Yiming Ma, Bee-Chung Chen, Liang Zhang, and Deepak Agarwal. 2016. Glmix: Generalized linear mixed models for large-scale response prediction. In KDD.Google ScholarDigital Library"",""Chen Zhu, Hengshu Zhu, Hui Xiong, Chao Ma, Fang Xie, Pengliang Ding, and Pan Li. 2018. Person-Job Fit: Adapting the Right Talent for the Right Job with Joint Representation Learning. TMIS, Vol. 9, 3 (2018).Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403339,DATE: Dual Attentive Tree-aware Embedding for Customs Fraud Detection,"Intentional manipulation of invoices that lead to undervaluation of trade goods is the most common type of customs fraud to avoid ad valorem duties and taxes. To secure government revenue without interrupting legitimate trade flows, customs administrations around the world strive to develop ways to detect illicit trades. This paper proposes DATE, a model of Dual-task Attentive Tree-aware Embedding, to classify and rank illegal trade flows that contribute the most to the overall customs revenue when caught. The strength of DATE comes from combining a tree-based model for interpretability and transaction-level embeddings with dual attention mechanisms. To accurately identify illicit transactions and predict tax revenue, DATE learns simultaneously from illicitness and surtax of each transaction. With a five-year amount of customs import data with a test illicit ratio of 2.24%, DATE shows a remarkable precision of 92.7% on illegal cases and a recall of 49.3% on revenue after inspecting only 1% of all trade flows. We also discuss issues on deploying DATE in Nigeria Customs Service, in collaboration with the World Customs Organization.","[{""name"":""Sundong Kim"",""id"":""/profile/99659574221""},{""name"":""Yu-Che Tsai"",""id"":""/profile/99659574564""},{""name"":""Karandeep Singh"",""id"":""/profile/99659572921""},{""name"":""Yeonsoo Choi"",""id"":""/profile/99659574862""},{""name"":""Etim Ibok"",""id"":""/profile/99659575153""},{""name"":""Cheng-Te Li"",""id"":""/profile/81413602545""},{""name"":""Meeyoung Cha"",""id"":""/profile/99659573061""},{""name"":""Sundong Kim"",""id"":""/profile/99659574221""},{""name"":""Yu-Che Tsai"",""id"":""/profile/99659574564""},{""name"":""Karandeep Singh"",""id"":""/profile/99659572921""},{""name"":""Yeonsoo Choi"",""id"":""/profile/99659574862""},{""name"":""Etim Ibok"",""id"":""/profile/99659575153""},{""name"":""Cheng-Te Li"",""id"":""/profile/81413602545""},{""name"":""Meeyoung Cha"",""id"":""/profile/99659573061""}]","[""Aisha Abdallah, Mohd Aizaini Maarof, and Anazida Zainal. 2016. Fraud detection system: A survey. Journal of Network and Computer Applications, Vol. 68 (2016).Google ScholarDigital Library"",""Aderemi O Adewumi and Andronicus A Akinyelu. 2017. A survey of machine-learning and nature-inspired based credit card fraud detection techniques. International Journal of System Assurance Engineering and Management, Vol. 8, 2 (2017).Google ScholarCross Ref"",""Mohiuddin Ahmed, Abdun Naser Mahmood, and Md. Rafiqul Islam. 2016. A survey of anomaly detection techniques in financial domain. Future Generation Computer Systems, Vol. 55 (2016), 278--288.Google ScholarDigital Library"",""Ismail Babajide Mustapha and Faisal Saeed. 2016. Bioactive molecule prediction using extreme gradient boosting. Molecules, Vol. 21, 8 (2016), 983.Google ScholarCross Ref"",""Jonathan Burez and Dirk Van den Poel. 2009. Handling class imbalance in customer churn prediction. Expert Systems with Applications, Vol. 36, 3 (2009).Google ScholarDigital Library"",""Canrakerta, Achmad Nizar Hidayanto, and Yova Ruldeviyani. 2020. Application of business intelligence for customs declaration: A case study in Indonesia. Journal of Physics: Conference Series, Vol. 1444 (2020), 012028.Google ScholarCross Ref"",""Tianqi Chen and Carlos Guestrin. 2016. XGBoost: A scalable tree boosting system. In KDD. 785--794.Google Scholar"",""Bassem Chermiti. 2019. Establishing risk and targeting profiles using data mining: Decision trees. World Customs Journal, Vol. 13 (2019).Google Scholar"",""Yeonsoo Choi. 2019. Identifying trade mis-invoicing through customs data analysis. World Customs Journal, Vol. 13, 2 (2019).Google Scholar"",""Daniel de Roux, Boris Perez, Andrés Moreno, Maria del Pilar Villamil, and César Figueroa. 2018. Tax fraud detection for under-reporting declarations using an unsupervised machine learning approach. In KDD. 215--222.Google Scholar"",""Jorge Jambeiro Filho. 2015. Artificial intelligence in the customs selection system through machine learning (SISAM). Receita Federal do Brasil (2015).Google Scholar"",""Jorge Jambeiro Filho and Jacques Wainer. 2008. HPB: A model for handling BN nodes with high cardinality parents. JMLR, Vol. 9 (2008), 2141--2170.Google Scholar"",""Christopher Grigoriou. 2019. Revenue maximisation versus trade facilitation: the contribution of automated risk management. World Customs Journal, Vol. 13 (2019).Google Scholar"",""Xinran He, Junfeng Pan, Ou Jin, Tianbing Xu, Bo Liu, Tao Xu, Yanxin Shi, Antoine Atallah, Ralf Herbrich, Stuart Bowers, et almbox. 2014. Practical lessons from predicting clicks on ads at facebook. In ADKDD. 1--9.Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Maria Krivko. 2010. A hybrid model for plastic card fraud detection systems. Expert Systems with Applications, Vol. 37, 8 (2010), 6070--6076.Google ScholarDigital Library"",""YiĞit Kültür and Mehmet Ufuk ÇaĞlayan. 2017. Hybrid approaches for detecting credit card fraud. Expert Systems, Vol. 34, 2 (2017), e12191.Google ScholarCross Ref"",""Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. 2008. Isolation forest. In ICDM. 413--422.Google Scholar"",""Liyuan Liu, Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao, and Jiawei Han. 2019. On the variance of the adaptive learning rate and beyond arXiv preprint arXiv:1908.03265 (2019).Google Scholar"",""Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2017. Adversarial multi-task learning for text classification. arXiv preprint arXiv:1704.05742 (2017).Google Scholar"",""Andrea Dal Pozzolo, Giacomo Boracchi, Olivier Caelen, Cesare Alippi, and Gianluca Bontempi. 2018. Credit Card Fraud Detection: A Realistic Modeling and a Novel Learning Strategy. IEEE Transactions on Neural Networks and Learning Systems, Vol. 29, 8 (2018), 3784--3797.Google ScholarCross Ref"",""Muhamad Ridwan Tri Prabowo, Siti Nuryanah, and Sardar M.N. Islam. 2019. The implementation of Benford's law testing method to detect fraud in customs audit. In Proceedings of the 33rd International Business Information Management Association Conference. 9329--9339.Google Scholar"",""Ram Hari Regmi and Arun K. Timalsina. 2018. Risk Management in customs using Deep Neural Network. In IEEE International Conference on Computing, Communication and Security. 133--137.Google Scholar"",""Sebastian Ruder. 2017. An overview of multi-task learning in deep neural networks. arXiv preprint arXiv:1706.05098 (2017).Google Scholar"",""Ron Triepels, Hennie Daniels, and Ad Feelders. 2018. Data-driven fraud detection in international shipping. Expert Systems with Applications, Vol. 99 (2018), 193--202.Google ScholarCross Ref"",""Jellis Vanhoeyveld, David Martens, and Bruno Peeters. 2019. Customs fraud detection: Assessing the value of behavioural and high-cardinality data under the imbalanced learning issue. Pattern Analysis and Applications (2019).Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In NeurIPS. 5998--6008.Google Scholar"",""Xiang Wang, Xiangnan He, Fuli Feng, Liqiang Nie, and Tat-Seng Chua. 2018. TEM: Tree-enhanced embedding model for explainable recommendation. In WWW. 1543--1552.Google ScholarDigital Library"",""Jarrod West and Maumita Bhattacharya. 2016. Intelligent financial fraud detection: A comprehensive review. Computers \u0026 Security, Vol. 57 (2016), 47--66.Google ScholarDigital Library"",""Lei Xu, Maria Skoularido, Alfredo Cuesta-Infante, and Kalyan Veeramachaneni. 2019. Modeling Tabular data using Conditional GAN. In NeurIPS.Google Scholar"",""Michael Zhang, James Lucas, Jimmy Ba, and Geoffrey E Hinton. 2019. Lookahead Optimizer: k steps forward, 1 step back. In NeurIPS. 9593--9604.Google Scholar"",""Xin Zhou. 2019. Data mining in customs risk detection with cost'sensitive classification. World Customs Journal, Vol. 13 (2019).Google Scholar""]"
https://doi.org/10.1145/3394486.3403340,User Sentiment as a Success Metric: Persistent Biases Under Full Randomization,"We study user sentiment (reported via optional surveys) as a metric for fully randomized A/B tests. Both user-level covariates and treatment assignment can impact response propensity. We show that a simple mean comparison produces biased population level estimates and propose a set of consistent estimators for the average and local treatment effects on treated and respondent users. We show that our problem can be mapped onto the intersection of the missing data problem and observational causal inference, and we identify conditions under which consistent estimators exist. Finally, we evaluate the performance of estimators and find that more complicated models do not necessarily provide superior performance as long as models satisfy consistency criteria.","[{""name"":""Ercan Yildiz"",""id"":""/profile/84758712957""},{""name"":""Joshua Safyan"",""id"":""/profile/99659574329""},{""name"":""Marc Harper"",""id"":""/profile/99659573371""},{""name"":""Ercan Yildiz"",""id"":""/profile/84758712957""},{""name"":""Joshua Safyan"",""id"":""/profile/99659574329""},{""name"":""Marc Harper"",""id"":""/profile/99659573371""}]","[""Eugene W. Anderson. 1998. Customer Satisfaction and Word of Mouth. Journal of Service Research 1, 1 (1998), 5--17. https://doi.org/10.1177/109467059800100102Google ScholarCross Ref"",""Eugene W. Anderson and Mary W. Sullivan. 1993. The Antecedents and Consequences of Customer Satisfaction for Firms. Marketing Science 12, 2 (1993), 125--143. http://www.jstor.org/stable/184036Google ScholarDigital Library"",""Heejung Bang and James M. Robins. 2005. Doubly Robust Estimation in Missing Data and Causal Inference Models. Biometrics 61, 4 (2005), 962--973. https://doi.org/10.1111/j.1541-0420.2005.00377.x arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1541-0420.2005.00377.xGoogle ScholarCross Ref"",""J Michael Brick and Graham Kalton. 1996. Handling missing data in survey research. Statistical methods in medical research 5, 3 (1996), 215--238.Google Scholar"",""Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins. 2018. Double/debiased machine learning for treatment and structural parameters. The Econometrics Journal 21, 1 (2018), C1--C68. https://doi.org/10.1111/ectj.12097 arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1111/ectj.12097Google ScholarCross Ref"",""Edith D. de Leeuw. 2012. Counting and Measuring Online: The Quality of Internet Surveys. BMS: Bulletin of Sociological Methodology / Bulletin de Méthodologie Sociologique 114 (2012), 68--78. http://www.jstor.org/stable/24311411Google ScholarCross Ref"",""Frederick F Reichheld. 2004. The One Number you Need to Grow. Harvard business review 81 (06 2004), 46--54, 124.Google Scholar"",""Anders Gustafsson, Michael Johnson, and Inger Roos. 2005. The Effects of Customer Satisfaction, Relationship Commitment Dimensions, and Triggers on Customer Retention. Journal of Marketing - J MARKETING 69 (10 2005), 210--218. https://doi.org/10.1509/jmkg.2005.69.4.210Google Scholar"",""Jens Hainmueller. 2012. Entropy Balancing for Causal Effects: A Multivariate Reweighting Method to Produce Balanced Samples in Observational Studies. Political Analysis 20, 1 (2012), 25--46. https://doi.org/10.1093/pan/mpr025Google ScholarCross Ref"",""Guido W. Imbens and Donald B. Rubin. 2015. Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction. Cambridge University Press. https://doi.org/10.1017/CBO9781139025751Google Scholar"",""G. Kalton. 1983. Compensating for missing survey data. Survey Research Center, Institute for Social Research, the University of Michigan. https://books.google. com/books?id=vTpHAAAAMAAJGoogle Scholar"",""Graham Kalton and Ismael Flores-Cervantes. 2003. Weighting methods. Journal of official statistics 19, 2 (2003), 81.Google Scholar"",""Joseph D. Y. Kang and Joseph L. Schafer. 2007. Demystifying Double Robustness: A Comparison of Alternative Strategies for Estimating a Population Mean from Incomplete Data. Statist. Sci. 22, 4 (11 2007), 523--539. https://doi.org/10.1214/07- STS227Google Scholar"",""Ron Kohavi, Alex Deng, Brian Frasca, Toby Walker, Ya Xu, and Nils Pohlmann. 2013. Online Controlled Experiments at Large Scale. In Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (Chicago, Illinois, USA) (KDD '13). ACM, New York, NY, USA, 1168--1176. https: //doi.org/10.1145/2487575.2488217Google ScholarDigital Library"",""Roderick J A Little and Donald B Rubin. 1986. Statistical Analysis with Missing Data. John Wiley \u0026 Sons, Inc., New York, NY, USA.Google Scholar"",""Neil A. Morgan, Eugene W. Anderson, and Vikas Mittal. 2005. Understanding Firms' Customer Satisfaction Information Usage. Journal of Marketing 69, 3 (2005), 131--151. http://www.jstor.org/stable/30162061Google ScholarCross Ref"",""Hendrik Muller and Aaron Sedley. 2014. HaTS: Large-scale In-product Measurement of User Attitudes: Experiences with Happiness Tracking Surveys. In Proceedings of the 26th Australian Computer-Human Interaction Conference on Designing Futures: The Future of Design (Sydney, New South Wales, Australia) (OzCHI '14). ACM, New York, NY, USA, 308--315. https://doi.org/10.1145/2686612.2686656Google Scholar"",""J.H. Myers. 1999. Measuring Customer Satisfaction: Hot Buttons and Other Measurement Issues. American Marketing Association. https://books.google.com/ books?id=PdlmQgAACAAJGoogle Scholar"",""Optimizely. 2019. Optimizely. https://www.optimizely.com/Google Scholar"",""Michal Ozery-Flato, Pierre Thodoroff, and Tal El-Hay. 2018. Adversarial Balancing for Causal Inference. arXiv e-prints, Article arXiv:1810.07406 (Oct 2018), arXiv:1810.07406 pages. arXiv:1810.07406 [cs.LG]Google Scholar"",""Judea Pearl. 2009. Causality: Models, Reasoning and Inference (2nd ed.). Cambridge University Press, New York, NY, USA.Google ScholarDigital Library"",""Donald B. Rubin. 1976. Inference and Missing Data. Biometrika 63, 3 (1976), 581--592. http://www.jstor.org/stable/2335739Google ScholarCross Ref"",""Xiaolin Shi, Somit Gupta, Pavel Dmitriev, and Xin Fu. 2019. Tutorial: Challenges, Best Practicesand Pitfalls in Evaluating Results of Online Controlled Experiments. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery Data Mining (Anchorage, AK, USA) (KDD '19). ACM, New York, NY, USA. https://sites.google.com/view/kdd2019-exp-evaluation/Google ScholarDigital Library"",""Louisa H Smith and Tyler J VanderWeele. 2019. Bounding bias due to selection. Epidemiology (Cambridge, Mass.) 30, 4 (2019), 509.Google Scholar"",""Diane Tang, Ashish Agarwal, Deirdre O'Brien, and Mike Meyer. 2010. Overlapping Experiment Infrastructure: More, Better, Faster Experimentation. In Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (Washington, DC, USA) (KDD '10). ACM, New York, NY, USA, 17--26. https://doi.org/10.1145/1835804.1835810Google Scholar"",""Eugene W. Anderson, Claes Fornell, and Roland T. Rust. 1997. Customer Satisfaction, Productivity, and Profitability: Differences Between Goods and Services. Marketing Science 16 (05 1997), 129--145. https://doi.org/10.1287/mksc.16.2.129Google Scholar"",""Xiaojing Wang, Jingang Miao, and Yunting Sun. 2019. A Python Library For Empirical Calibration. arXiv preprint arXiv:1906.11920 (2019).Google Scholar"",""Ya Xu, Nanyu Chen, Addrian Fernandez, Omar Sinno, and Anmol Bhasin. 2015. From Infrastructure to Culture: A/B Testing Challenges in Large Scale Social Networks. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (Sydney, NSW, Australia) (KDD '15). ACM, New York, NY, USA, 2227--2236. https://doi.org/10.1145/2783258.2788602Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403341,Improving Recommendation Quality in Google Drive,"Quick Access is a machine-learned system in Google Drive that predicts which files a user wants to open. Adding Quick Access recommendations to the Drive homepage cut the amount of time that users spend locating their files in half. Aggregated over the ~1 billion users of Drive, the time saved up adds up to ~1000 work weeks every day. In this paper, we discuss both the challenges of iteratively improving the quality of a personal recommendation system as well as the variety of approaches that we took in order to improve this feature. We explored different deep network architectures, novel modeling techniques, additional data sources, and the effects of latency and biases in the UX. We share both pitfalls as well as successes in our attempts to improve this product, and also discuss how we scaled and managed the complexity of the system. We believe that these insights will be especially useful to those who are working with private corpora as well as those who are building a large-scale production recommendation system.","[{""name"":""Suming J. Chen"",""id"":""/profile/99659574309""},{""name"":""Zhen Qin"",""id"":""/profile/99659315793""},{""name"":""Zac Wilson"",""id"":""/profile/99659573994""},{""name"":""Brian Calaci"",""id"":""/profile/99659575186""},{""name"":""Michael Rose"",""id"":""/profile/99659574565""},{""name"":""Ryan Evans"",""id"":""/profile/99659573034""},{""name"":""Sean Abraham"",""id"":""/profile/99659574786""},{""name"":""Donald Metzler"",""id"":""/profile/81100129957""},{""name"":""Sandeep Tata"",""id"":""/profile/99659192915""},{""name"":""Michael Colagrosso"",""id"":""/profile/99659192827""},{""name"":""Suming J. Chen"",""id"":""/profile/99659574309""},{""name"":""Zhen Qin"",""id"":""/profile/99659315793""},{""name"":""Zac Wilson"",""id"":""/profile/99659573994""},{""name"":""Brian Calaci"",""id"":""/profile/99659575186""},{""name"":""Michael Rose"",""id"":""/profile/99659574565""},{""name"":""Ryan Evans"",""id"":""/profile/99659573034""},{""name"":""Sean Abraham"",""id"":""/profile/99659574786""},{""name"":""Donald Metzler"",""id"":""/profile/81100129957""},{""name"":""Sandeep Tata"",""id"":""/profile/99659192915""},{""name"":""Michael Colagrosso"",""id"":""/profile/99659192827""}]","[""Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng 2015. TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems. http://tensorflow.org/ Software available from tensorflow.org.Google Scholar"",""Gediminas Adomavicius, Jesse Bockstedt, Shawn Curley, and Jingjing Zhang. 2014. De-biasing user preference ratings in recommender systems. In RecSys 2014 Workshop on Interfaces and Human Decision Making for Recommender Systems (IntRS 2014). 2--9.Google Scholar"",""Gediminas Adomavicius and Alexander Tuzhilin. 2008. Context-aware Recommender Systems. In RecSys. 335--336.Google Scholar"",""Denis Baylor, Eric Breck, Heng-Tze Cheng, Noah Fiedel, Chuan Yu Foo, Zakaria Haque, Salem Haykal, Mustafa Ispir, Vihan Jain, Levent Koc, Chiu Yuen Koo, Lukasz Lew, Clemens Mewald, Akshay Naresh Modi, Neoklis Polyzotis, Sukriti Ramesh, Sudip Roy, Steven Euijong Whang, Martin Wicke, Jarek Wilkiewicz, Xin Zhang, and Martin Zinkevich. 2017. TFX: A TensorFlow-Based Production-Scale Machine Learning Platform. In KDD.Google Scholar"",""Alex Beutel, Paul Covington, Sagar Jain, Can Xu, Jia Li, Vince Gatto, and Ed H. Chi. 2018. Latent Cross: Making Use of Context in Recurrent Recommender Systems. In WSDM. 46--54.Google Scholar"",""Zhe Cao, Tao Qin, Tie-Yan Liu, Ming-Feng Tsai, and Hang Li. 2007. Learning to Rank: From Pairwise Approach to Listwise Approach. In ICML. 129--136.Google Scholar"",""Allison J. B. Chaney, Brandon M. Stewart, and Barbara E. Engelhardt. 2018. How Algorithmic Confounding in Recommendation Systems Increases Homogeneity and Decreases Utility. In RecSys. 224--232.Google Scholar"",""Suming J Chen, Xuanhui Wang, Zhen Qin, and Donald Metzler. 2020. Parameter Tuning in Personal Search Systems. In Proceedings of the 13th International Conference on Web Search and Data Mining. 97--105.Google ScholarDigital Library"",""Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et almbox. 2016. Wide \u0026 deep learning for recommender systems. In Proceedings of the 1st workshop on deep learning for recommender systems. 7--10.Google ScholarDigital Library"",""Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep Neural Networks for YouTube Recommendations. In RecSys.Google Scholar"",""Hanjun Dai, Yichen Wang, Rakshit Trivedi, and Le Song. 2016. Recurrent Coevolutionary Latent Feature Processes for Continuous-Time Recommendation. In Proceedings of the 1st Workshop on Deep Learning for Recommender Systems. 29--34.Google ScholarDigital Library"",""Tim Donkers, Benedikt Loepp, and Jürgen Ziegler. 2017. Sequential User-based Recurrent Neural Network Recommendations. In RecSys. 152--160.Google Scholar"",""Elad Eban, Mariano Schain, Alan Mackey, Ariel Gordon, Ryan Rifkin, and Gal Elidan. 2017. Scalable Learning of Non-Decomposable Objectives. In AISTATS. 832--840.Google Scholar"",""Simen Eide and Ning Zhou. 2018. Deep Neural Network Marketplace Recommenders in Online Experiments. In RecSys. 387--391.Google Scholar"",""Daniel Golovin, Benjamin Solnik, Subhodeep Moitra, Greg Kochanski, John Karro, and D. Sculley. 2017. Google Vizier: A Service for Black-Box Optimization. In KDD. 1487--1495.Google ScholarDigital Library"",""Malay Haldar, Mustafa Abdool, Prashant Ramanathan, Tao Xu, Shulin Yang, Huizhong Duan, Qing Zhang, Nick Barrow-Williams, Bradley C. Turnbull, Brendan M. Collins, and Thomas Legrand. 2018. Applying Deep Learning To Airbnb Search. CoRR, Vol. abs/1810.09591 (2018). arxiv: 1810.09591 http://arxiv.org/abs/1810.09591Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep Residual Learning for Image Recognition. In CVPR. 770--778.Google Scholar"",""Sergey Ioffe and Christian Szegedy. 2015. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. In ICML. 448--456.Google ScholarDigital Library"",""Tor Lattimore and Csaba Szepesvári. 2020. Bandit algorithms. Cambridge University Press.Google Scholar"",""Pan Li, Zhen Qin, Xuanhui Wang, and Donald Metzler. 2019. Combining Decision Trees and Neural Networks for Learning-to-Rank in Personal Search. In KDD. 2032--2040.Google Scholar"",""Jianxun Lian, Xiaohuan Zhou, Fuzheng Zhang, Zhongxia Chen, Xing Xie, and Guangzhong Sun. 2018. xdeepfm: Combining explicit and implicit feature interactions for recommender systems. In KDD. 1754--1763.Google Scholar"",""David C. Liu, Stephanie Rogers, Raymond Shiau, Dmitry Kislyuk, Kevin C. Ma, Zhigang Zhong, Jenny Liu, and Yushi Jing. 2017. Related Pins at Pinterest: The Evolution of a Real-World Recommender System. In WWW. 583--592.Google Scholar"",""Tie-Yan Liu. 2009. Learning to Rank for Information Retrieval. Found. Trends Inf. Retr., Vol. 3, 3 (March 2009), 225--331.Google Scholar"",""Rama Kumar Pasumarthi, Xuanhui Wang, Cheng Li, Sebastian Bruch, Michael Bendersky, Marc Najork, Jan Pfeifer, Nadav Golbandi, Rohan Anil, and Stephan Wolf. 2019. TF-Ranking: Scalable TensorFlow Library for Learning-to-Rank. In KDD.Google Scholar"",""Zhen Qin, Suming J. Chen, Donald Metzler, Yongwoo Noh, Jingzheng Qin, and Xuanhui Wang. 2020. Attribute-based Propensity for Unbiased Learning in Recommender Systems: Algorithm and Case Studies. In KDD.Google Scholar"",""Tobias Schnabel, Adith Swaminathan, Ashudeep Singh, Navin Chandak, and Thorsten Joachims. 2016. Recommendations as Treatments: Debiasing Learning and Evaluation. In ICML. 1670--1679.Google Scholar"",""Sandeep Tata, Vlad Panait, Suming J. Chen, and Mike Colagrosso. 2019. ItemSuggest: A Data Management Platform for Machine Learned Ranking Services. In CIDR.Google Scholar"",""Sandeep Tata, Alexandrin Popescul, Marc Najork, Mike Colagrosso, Julian Gibbons, Alan Green, Alexandre Mah, Michael Smith, Divanshu Garg, Cayden Meyer, and Reuben Kan. 2017. Quick Access: Building a Smart Experience for Google Drive. In KDD. 1643--1651.Google ScholarDigital Library"",""Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. 2017. Deep \u0026 cross network for ad click predictions. In ADKDD. 1--7.Google Scholar"",""Dawei Yin, Yuening Hu, Jiliang Tang, Tim Daly Jr., Mianwei Zhou, Hua Ouyang, Jianhui Chen, Changsung Kang, Hongbo Deng, Chikashi Nobata, Jean-Marc Langlois, and Yi Chang. 2016. Ranking Relevance in Yahoo Search. In KDD. 323--332.Google Scholar"",""Shuai Zhang, Lina Yao, Aixin Sun, and Yi Tay. 2019. Deep Learning Based Recommender System: A Survey and New Perspectives. ACM Comput. Surv., Vol. 52, 1 (Feb. 2019), 5:1--5:38.Google ScholarDigital Library"",""Zhe Zhao, Lichan Hong, Li Wei, Jilin Chen, Aniruddh Nath, Shawn Andrews, Aditee Kumthekar, Maheswaran Sathiamoorthy, Xinyang Yi, and Ed Chi. 2019. Recommending what video to watch next: a multitask ranking system. In RecSys. ACM, 43--51.Google Scholar""]"
https://doi.org/10.1145/3394486.3403342,Large-Scale Training System for 100-Million Classification at Alibaba,"In the last decades, extreme classification has become an essential topic for deep learning. It has achieved great success in many areas, especially in computer vision and natural language processing (NLP). However, it is very challenging to train a deep model with millions of classes due to the memory and computation explosion in the last output layer. In this paper, we propose a large-scale training system to address these challenges. First, we build a hybrid parallel training framework to make the training process feasible. Second, we propose a novel softmax variation named KNN softmax, which reduces both the GPU memory consumption and computation costs and improves the throughput of training. Then, to eliminate the communication overhead, we propose a new overlapping pipeline and a gradient sparsification method. Furthermore, we design a fast continuous convergence strategy to reduce total training iterations by adaptively adjusting learning rate and updating model parameters. With the help of all the proposed methods, we gain 3.9× throughput of our training system and reduce almost 60% of training iterations. The experimental results show that using an in-house 256 GPUs cluster, we could train a classifier of 100 million classes on Alibaba Retail Product Dataset in about five days while achieving a comparable accuracy with the naive softmax training process.","[{""name"":""Liuyihan Song"",""id"":""/profile/99659574398""},{""name"":""Pan Pan"",""id"":""/profile/99659286763""},{""name"":""Kang Zhao"",""id"":""/profile/99659287881""},{""name"":""Hao Yang"",""id"":""/profile/99659573590""},{""name"":""Yiming Chen"",""id"":""/profile/99659574800""},{""name"":""Yingya Zhang"",""id"":""/profile/99659288077""},{""name"":""Yinghui Xu"",""id"":""/profile/99659547763""},{""name"":""Rong Jin"",""id"":""/profile/81100054575""},{""name"":""Liuyihan Song"",""id"":""/profile/99659574398""},{""name"":""Pan Pan"",""id"":""/profile/99659286763""},{""name"":""Kang Zhao"",""id"":""/profile/99659287881""},{""name"":""Hao Yang"",""id"":""/profile/99659573590""},{""name"":""Yiming Chen"",""id"":""/profile/99659574800""},{""name"":""Yingya Zhang"",""id"":""/profile/99659288077""},{""name"":""Yinghui Xu"",""id"":""/profile/99659547763""},{""name"":""Rong Jin"",""id"":""/profile/81100054575""}]","[""Alham Fikri Aji and Kenneth Heafield. 2017. Sparse Communication for Distributed Gradient Descent. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP). 440--445.Google ScholarCross Ref"",""Kush Bhatia, Himanshu Jain, Purushottam Kar, Manik Varma, and Prateek Jain. 2015. Sparse local embeddings for extreme multi-label classification. In Advances in Neural Information Processing Systems (NeurIPS). 730--738.Google Scholar"",""Léon Bottou, Frank E Curtis, and Jorge Nocedal. 2018. Optimization methods for large-scale machine learning. Siam Review, Vol. 60, 2 (2018), 223--311.Google ScholarCross Ref"",""Tianqi Chen, Mu Li, Yutian Li, Min Lin, Naiyan Wang, Minjie Wang, Tianjun Xiao, Bing Xu, Chiyuan Zhang, and Zheng Zhang. 2015. Mxnet: A flexible and efficient machine learning library for heterogeneous distributed systems. arXiv preprint arXiv:1512.01274 (2015).Google Scholar"",""Wenlin Chen, David Grangier, and Michael Auli. 2016. Strategies for Training Large Vocabulary Neural Language Models. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL). 1975--1985.Google ScholarCross Ref"",""Jiankang Deng, Jia Guo, Niannan Xue, and Stefanos Zafeiriou. 2019. Arcface: Additive angular margin loss for deep face recognition. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 4690--4699.Google ScholarCross Ref"",""Joshua Goodman. 2001. Classes for fast maximum entropy training. In IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (ICASSP), Vol. 1. IEEE, 561--564.Google ScholarCross Ref"",""Priya Goyal, Piotr Dollár, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He. 2017. Accurate, large minibatch sgd: Training imagenet in 1 hour. arXiv preprint arXiv:1706.02677 (2017).Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 770--778.Google ScholarCross Ref"",""Sergey Ioffe and Christian Szegedy. 2015. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. In International Conference on Machine Learning (ICML). 448--456.Google ScholarDigital Library"",""Xianyan Jia, Shutao Song, Wei He, Yangzihao Wang, Haidong Rong, Feihu Zhou, Liqiang Xie, Zhenyu Guo, Yuanzhou Yang, Liwei Yu, et almbox. 2018. Highly scalable deep learning training system with mixed-precision: Training imagenet in four minutes. arXiv preprint arXiv:1807.11205 (2018).Google Scholar"",""Sai Praneeth Karimireddy, Quentin Rebjock, Sebastian Stich, and Martin Jaggi. 2019. Error Feedback Fixes SignSGD and other Gradient Compression Schemes. In International Conference on Machine Learning (ICML). 3252--3261.Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Alex Krizhevsky. 2014. One weird trick for parallelizing convolutional neural networks. arXiv preprint arXiv:1404.5997 (2014).Google Scholar"",""Mu Li, David G Andersen, Jun Woo Park, Alexander J Smola, Amr Ahmed, Vanja Josifovski, James Long, Eugene J Shekita, and Bor-Yiing Su. 2014. Scaling distributed machine learning with the parameter server. In 11th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 14). 583--598.Google Scholar"",""Yujun Lin, Song Han, Huizi Mao, Yu Wang, and William J Dally. 2017. Deep gradient compression: Reducing the communication bandwidth for distributed training. arXiv preprint arXiv:1712.01887 (2017).Google Scholar"",""Tharun Kumar Reddy Medini, Qixuan Huang, Yiqiu Wang, Vijai Mohan, and Anshumali Shrivastava. 2019. Extreme Classification in Log Memory using Count-Min Sketch: A Case Study of Amazon Search with 50M Products. In Advances in Neural Information Processing Systems (NeurIPS). 13244--13254.Google Scholar"",""Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen, David Garcia, Boris Ginsburg, Michael Houston, Oleksii Kuchaiev, Ganesh Venkatesh, et almbox. 2017. Mixed precision training. arXiv preprint arXiv:1710.03740 (2017).Google Scholar"",""Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781 (2013).Google Scholar"",""Priyanka Nigam, Yiwei Song, Vijai Mohan, Vihan Lakshman, Weitian Ding, Ankit Shingavi, Choon Hui Teo, Hao Gu, and Bing Yin. 2019. Semantic product search. In Proceedings of the 25th International Conference on Knowledge Discovery and Data Mining (SIGKDD). 2876--2885.Google ScholarDigital Library"",""Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et almbox. 2019. PyTorch: An imperative style, high-performance deep learning library. In Advances in Neural Information Processing Systems (NeurIPS). 8024--8035.Google Scholar"",""Samuel L Smith, Pieter-Jan Kindermans, Chris Ying, and Quoc V Le. 2017. Don't decay the learning rate, increase the batch size. arXiv preprint arXiv:1711.00489 (2017).Google Scholar"",""Peng Sun, Wansen Feng, Ruobing Han, Shengen Yan, and Yonggang Wen. 2019. Optimizing Network Performance for Distributed DNN Training on GPU Clusters: ImageNet/AlexNet Training in 1.5 Minutes. arXiv preprint arXiv:1902.06855 (2019).Google Scholar"",""Yi Sun, Yuheng Chen, Xiaogang Wang, and Xiaoou Tang. 2014. Deep learning face representation by joint identification-verification. In Advances in Neural Information Processing Systems (NeurIPS). 1988--1996.Google Scholar"",""Yukihiro Tagami. 2017. Annexml: Approximate nearest neighbor search for extreme multi-label classification. In Proceedings of the 23rd International Conference on Knowledge Discovery and Data Mining (SIGKDD). 455--464.Google ScholarDigital Library"",""Thijs Vogels, Sai Praneeth Karimireddy, and Martin Jaggi. 2019. PowerSGD: Practical low-rank gradient compression for distributed optimization. In Advances in Neural Information Processing Systems (NeurIPS). 14236--14245.Google Scholar"",""Yang You, Igor Gitman, and Boris Ginsburg. 2017. Scaling sgd batch size to 32k for imagenet training. arXiv preprint arXiv:1708.03888, Vol. 6 (2017).Google Scholar"",""Yang You, Zhao Zhang, Cho-Jui Hsieh, James Demmel, and Kurt Keutzer. 2018. Imagenet training in minutes. In Proceedings of the 47th International Conference on Parallel Processing (ICPP). ACM, 1.Google ScholarDigital Library"",""Xingcheng Zhang, Lei Yang, Junjie Yan, and Dahua Lin. 2018. Accelerated training for massive classification via dynamic class selection. In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI).Google Scholar"",""Kang Zhao, Pan Pan, Yun Zheng, Yanhao Zhang, Changxu Wang, Yingya Zhang, Yinghui Xu, and Rong Jin. 2019. Large-Scale Visual Search with Binary Distributed Graph at Alibaba. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management (CIKM). 2567--2575.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403343,Mining Implicit Relevance Feedback from User Behavior for Web Question Answering,"Training and refreshing a web-scale Question Answering (QA) system for a multi-lingual commercial search engine often requires a huge amount of training examples. One principled idea is to mine implicit relevance feedback from user behavior recorded in search engine logs. All previous works on mining implicit relevance feedback target at relevance of web documents rather than passages. Due to several unique characteristics of QA tasks, the existing user behavior models for web documents cannot be applied to infer passage relevance. In this paper, we make the first study to explore the correlation between user behavior and passage relevance, and propose a novel approach for mining training data for Web QA. We conduct extensive experiments on four test datasets and the results show our approach significantly improves the accuracy of passage ranking without extra human labeled data. In practice, this work has proved effective to substantially reduce the human labeling cost for the QA service in a global commercial search engine, especially for languages with low resources. Our techniques have been deployed in multi-language services.","[{""name"":""Linjun Shou"",""id"":""/profile/99659493597""},{""name"":""Shining Bo"",""id"":""/profile/99659573777""},{""name"":""Feixiang Cheng"",""id"":""/profile/99659573598""},{""name"":""Ming Gong"",""id"":""/profile/99659494115""},{""name"":""Jian Pei"",""id"":""/profile/81100323054""},{""name"":""Daxin Jiang"",""id"":""/profile/81452599802""},{""name"":""Linjun Shou"",""id"":""/profile/99659493597""},{""name"":""Shining Bo"",""id"":""/profile/99659573777""},{""name"":""Feixiang Cheng"",""id"":""/profile/99659573598""},{""name"":""Ming Gong"",""id"":""/profile/99659494115""},{""name"":""Jian Pei"",""id"":""/profile/81100323054""},{""name"":""Daxin Jiang"",""id"":""/profile/81452599802""}]","[""Eugene Agichtein, Eric Brill, and Susan T. Dumais. 2018. Improving Web Search Ranking by Incorporating User Behavior Information. SIGIR Forum, Vol. 52, 2 (2018), 11--18.Google ScholarDigital Library"",""David Ahn, Valentin Jijkoun, Gilad Mishne, Karin Müller, Maarten de Rijke, Stefan Schlobach, M Voorhees, and L Buckland. 2004. Using Wikipedia at the TREC QA Track.. In TREC. Citeseer.Google Scholar"",""Kamal Ali and Chi Chao Chang. 2006. On the relationship between click rate and relevance for search engines. WIT Transactions on Information and Communication Technologies, Vol. 37 (2006).Google Scholar"",""Mikhail Bilenko and Ryen W. White. 2008. Mining the Search Trails of Surfing Crowds: Identifying Relevant Websites from User Activity. In WWW. ACM, New York, NY, USA, 51--60.Google Scholar"",""Eric Brill, Susan T. Dumais, and Michele Banko. 2002. An Analysis of the AskMSR Question-Answering System. In EMNLP.Google Scholar"",""Davide Buscaldi and Paolo Rosso. 2006. Mining knowledge from wikipedia for the question answering task. In Proceedings of the International Conference on Language Resources and Evaluation. 727--730.Google Scholar"",""Olivier Chapelle and Ya Zhang. 2009. A dynamic bayesian network click model for web search ranking. In WWW. 1--10.Google Scholar"",""Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017. Reading wikipedia to answer open-domain questions. arXiv preprint arXiv:1704.00051 (2017).Google Scholar"",""Daniel Cohen, Liu Yang, and W. Bruce Croft. 2018. WikiPassageQA: A Benchmark Collection for Research on Non-factoid Answer Passage Retrieval. In SIGIR. 1165--1168.Google Scholar"",""Nick Craswell, Onno Zoeter, Michael J. Taylor, and Bill Ramsey. 2008. An experimental comparison of click position-bias models. In WSDM. 87--94.Google Scholar"",""Hang Cui, Renxu Sun, Keya Li, Min-Yen Kan, and Tat-Seng Chua. 2005. Question answering passage retrieval using dependency relations. In SIGIR. 400--407.Google Scholar"",""Georges Dupret and Benjamin Piwowarski. 2008. A user browsing model to predict search engine click data from past observations. In SIGIR. 331--338.Google Scholar"",""Abdessamad Echihabi, Ulf Hermjakob, Eduard Hovy, Daniel Marcu, Eric Melz, and Deepak Ravichandran. 2008. How to Select an Answer String? In Advances in open domain question answering. Springer, 383--406.Google Scholar"",""Jianfeng Gao, Kristina Toutanova, and Wen tau Yih. 2011. Clickthrough-based latent semantic models for web search. In SIGIR '11.Google ScholarDigital Library"",""Haoyang Huang, Yaobo Liang, Nan Duan, Ming Gong, Linjun Shou, Daxin Jiang, and Ming Zhou. 2019. Unicoder: A Universal Language Encoder by Pre-training with Multiple Cross-lingual Tasks. In EMNLP/IJCNLP.Google Scholar"",""Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero, and Larry P. Heck. 2013. Learning deep structured semantic models for web search using clickthrough data. In CIKM. 2333--2338.Google Scholar"",""Thorsten Joachims. 2002. Optimizing search engines using clickthrough data. In Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, July 23--26, 2002, Edmonton, Alberta, Canada. 133--142.Google ScholarDigital Library"",""Thorsten Joachims, Laura A. Granka, Bing Pan, Helene Hembrooke, and Geri Gay. 2005. Accurately interpreting clickthrough data as implicit feedback. In SIGIR 2005: Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, Salvador, Brazil, August 15-19, 2005. 154--161.Google ScholarDigital Library"",""Thorsten Joachims, Laura A. Granka, Bing Pan, Helene Hembrooke, and Geri Gay. 2017. Accurately Interpreting Clickthrough Data as Implicit Feedback. SIGIR Forum, Vol. 51, 1 (2017), 4--11. https://doi.org/10.1145/3130332.3130334Google ScholarDigital Library"",""Michael Kaisser and Tilman Becker. 2004. Question Answering by Searching Large Corpora With Linguistic Methods.. In TREC.Google Scholar"",""Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. 2017. Lightgbm: A highly efficient gradient boosting decision tree. In Advances in Neural Information Processing Systems. 3146--3154.Google ScholarDigital Library"",""Bernhard Kratzwald and Stefan Feuerriegel. 2019. Learning from On-Line User Feedback in Neural Question Answering on the Web. In The World Wide Web Conference. ACM, 906--916.Google ScholarDigital Library"",""Andy Liaw, Matthew Wiener, et almbox. 2002. Classification and regression by randomForest. R news, Vol. 2, 3 (2002), 18--22.Google Scholar"",""Yosi Mass, Haggai Roitman, Shai Erera, Or Rivlin, Bar Weiner, and David Konopnicki. 2019. A Study of BERT for Non-Factoid Question-Answering under Passage Length Constraints. CoRR, Vol. abs/1908.06780 (2019). arxiv: 1908.06780Google Scholar"",""Scott Menard. 2002. Applied logistic regression analysis. Vol. 106. Sage.Google Scholar"",""Dan I. Moldovan, Sanda M. Harabagiu, Marius Pasca, Rada Mihalcea, Roxana Girju, Richard Goodrum, and Vasile Rus. 2000. The Structure and Performance of an Open-Domain Question Answering System. In ACL.Google Scholar"",""Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, and Li Deng. 2016. MS MARCO: A Human Generated MAchine Reading COmprehension Dataset. In Proceedings of the Workshop on Cognitive Computation: Integrating neural and symbolic approaches 2016 co-located with the 30th Annual Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain, December 9, 2016.Google Scholar"",""Dragomir Radev, Weiguo Fan, Hong Qi, Harris Wu, and Amardeep Grewal. 2002. Probabilistic question answering on the web. In WWW. ACM, 408--419.Google Scholar"",""Joseph Rocchio. 1971. Relevance feedback in information retrieval. The Smart retrieval system-experiments in automatic document processing (1971), 313--323.Google Scholar"",""S Rasoul Safavian and David Landgrebe. 1991. A survey of decision tree classifier methodology. IEEE transactions on systems, man, and cybernetics, Vol. 21, 3 (1991), 660--674.Google Scholar"",""Ming Tan, Cícero Nogueira dos Santos, Bing Xiang, and Bowen Zhou. 2016. Improved Representation Learning for Question Answer Matching. In ACL.Google Scholar"",""Ming Tan, Bing Xiang, and Bowen Zhou. 2015. LSTM-based Deep Learning Models for non-factoid answer selection. CoRR, Vol. abs/1511.04108 (2015). arxiv: 1511.04108Google Scholar"",""Paul Thomas and David Hawking. 2006. Evaluation by comparing result sets in context. In Proceedings of the 15th ACM international conference on Information and knowledge management. ACM, 94--101.Google ScholarDigital Library"",""Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang, Tim Klinger, Wei Zhang, Shiyu Chang, Gerry Tesauro, Bowen Zhou, and Jing Jiang. 2018. R(mbox3): Reinforced Ranker-Reader for Open-Domain Question Answering. In AAAI, New Orleans, Louisiana, USA, February 2--7, 2018. 5981--5988.Google Scholar"",""Zhiguo Wang, Wael Hamza, and Radu Florian. 2017. Bilateral Multi-Perspective Matching for Natural Language Sentences. In Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI 2017, Melbourne, Australia, August 19-25, 2017. 4144--4150.Google ScholarCross Ref"",""Zhiguo Wang, Patrick Ng, Xiaofei Ma, Ramesh Nallapati, and Bing Xiang. 2019. Multi-passage BERT: A Globally Normalized BERT Model for Open-domain Question Answering. CoRR, Vol. abs/1908.08167 (2019). arxiv: 1908.08167Google Scholar"",""Ryen W. White, Mikhail Bilenko, and Silviu Cucerzan. 2007. Studying the Use of Popular Destinations to Enhance Web Search Interaction. In Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '07). ACM, New York, NY, USA, 159--166.Google ScholarDigital Library"",""Liu Yang, Qingyao Ai, Jiafeng Guo, and W. Bruce Croft. 2016. aNMM: Ranking Short Answer Texts with Attention-Based Neural Matching Model. In CIKM, Indianapolis, IN, USA, October 24-28, 2016. 287--296.Google ScholarDigital Library"",""Zhilin Yang, Zihang Dai, Yiming Yang, Jaime G. Carbonell, Ruslan Salakhutdinov, and Quoc V. Le. 2019. XLNet: Generalized Autoregressive Pretraining for Language Understanding. CoRR, Vol. abs/1906.08237 (2019). arxiv: 1906.08237Google Scholar"",""Ze Yang, Linjun Shou, Ming Gong, Wutao Lin, and Daxin Jiang. 2020. Model Compression with Two-stage Multi-teacher Knowledge Distillation for Web Question Answering System. Proceedings of the 13th International Conference on Web Search and Data Mining (2020).Google ScholarDigital Library"",""Xuchen Yao, Benjamin Van Durme, Chris Callison-Burch, and Peter Clark. 2013. Answer Extraction as Sequence Tagging with Tree Edit Distance. In Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics, Proceedings, June 9-14, 2013, Westin Peachtree Plaza Hotel, Atlanta, Georgia, USA. 858--867.Google Scholar"",""Fei Yuan, Linjun Shou, Xuanyu Bai, Ming Gong, Yaobo Liang, Nan Duan, Yan Fu, and Daxin Jiang. 2020. Enhancing Answer Boundary Detection for Multilingual Machine Reading Comprehension. ArXiv, Vol. abs/2004.14069 (2020).Google Scholar""]"
https://doi.org/10.1145/3394486.3403344,Controllable Multi-Interest Framework for Recommendation,"Recently, neural networks have been widely used in e-commerce recommender systems, owing to the rapid development of deep learning. We formalize the recommender system as a sequential recommendation problem, intending to predict the next items that the user might be interacted with. Recent works usually give an overall embedding from a user's behavior sequence. However, a unified user embedding cannot reflect the user's multiple interests during a period. In this paper, we propose a novel controllable multi-interest framework for the sequential recommendation, called ComiRec. Our multi-interest module captures multiple interests from user behavior sequences, which can be exploited for retrieving candidate items from the large-scale item pool. These items are then fed into an aggregation module to obtain the overall recommendation. The aggregation module leverages a controllable factor to balance the recommendation accuracy and diversity. We conduct experiments for the sequential recommendation on two real-world datasets, Amazon and Taobao. Experimental results demonstrate that our framework achieves significant improvements over state-of-the-art models. Our framework has also been successfully deployed on the offline Alibaba distributed cloud platform.","[{""name"":""Yukuo Cen"",""id"":""/profile/99659453771""},{""name"":""Jianwei Zhang"",""id"":""/profile/99659316554""},{""name"":""Xu Zou"",""id"":""/profile/99659453278""},{""name"":""Chang Zhou"",""id"":""/profile/99659371467""},{""name"":""Hongxia Yang"",""id"":""/profile/99659259298""},{""name"":""Jie Tang"",""id"":""/profile/81548005696""},{""name"":""Yukuo Cen"",""id"":""/profile/99659453771""},{""name"":""Jianwei Zhang"",""id"":""/profile/99659316554""},{""name"":""Xu Zou"",""id"":""/profile/99659453278""},{""name"":""Chang Zhou"",""id"":""/profile/99659371467""},{""name"":""Hongxia Yang"",""id"":""/profile/99659259298""},{""name"":""Jie Tang"",""id"":""/profile/81548005696""}]","[""Gediminas Adomavicius and YoungOk Kwon. 2011. Improving aggregate recommendation diversity using ranking-based techniques. TKDE, Vol. 24, 5 (2011), 896--911.Google ScholarDigital Library"",""Sujoy Bag, Abhijeet Ghadge, and Manoj Kumar Tiwari. 2019. An integrated recommender system for improved accuracy and aggregate diversity. Computers \u0026 Industrial Engineering, Vol. 130 (2019), 187--197.Google ScholarCross Ref"",""Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473 (2014).Google Scholar"",""Keith Bradley and Barry Smyth. 2001. Improving recommendation diversity. In AICS'01. Citeseer, 85--94.Google Scholar"",""Peter J Burt. 1988. Attention mechanisms for vision in a dynamic world. In ICPR'88. IEEE, 977--987.Google ScholarCross Ref"",""Yukuo Cen, Xu Zou, Jianwei Zhang, Hongxia Yang, Jingren Zhou, and Jie Tang. 2019. Representation learning for attributed multiplex heterogeneous network. In KDD'19. 1358--1368.Google ScholarDigital Library"",""Xu Chen, Hongteng Xu, Yongfeng Zhang, Jiaxi Tang, Yixin Cao, Zheng Qin, and Hongyuan Zha. 2018. Sequential recommendation with user memory networks. In WSDM'18. ACM, 108--116.Google ScholarDigital Library"",""Peizhe Cheng, Shuaiqiang Wang, Jun Ma, Jiankai Sun, and Hui Xiong. 2017. Learning to recommend accurate and diverse items. In WWW'17. 183--192.Google ScholarDigital Library"",""Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep neural networks for youtube recommendations. In RecSys'16. ACM, 191--198.Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).Google Scholar"",""Tommaso Di Noia, Vito Claudio Ostuni, Jessica Rosati, Paolo Tomeo, and Eugenio Di Sciascio. 2014. An analysis of users' propensity toward diversity in recommendations. In RecSys'14. 285--288.Google Scholar"",""Travis Ebesu, Bin Shen, and Yi Fang. 2018. Collaborative memory network for recommendation systems. In SIGIR'18. ACM, 515--524.Google ScholarDigital Library"",""Anupriya Gogna and Angshul Majumdar. 2017. Balancing accuracy and diversity in recommendations using matrix completion framework. Knowledge-Based Systems, Vol. 125 (2017), 83--95.Google ScholarDigital Library"",""Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: a factorization-machine based neural network for CTR prediction. In IJCAI'17.Google ScholarCross Ref"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In NIPS'17. 1024--1034.Google ScholarDigital Library"",""Ruining He, Wang-Cheng Kang, and Julian McAuley. 2017a. Translation-based recommendation. In RecSys'17. ACM, 161--169.Google Scholar"",""Ruining He and Julian McAuley. 2016a. Fusing similarity models with markov chains for sparse sequential recommendation. In ICDM'16. IEEE, 191--200.Google ScholarCross Ref"",""Ruining He and Julian McAuley. 2016b. Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering. In WWW'16. International World Wide Web Conferences Steering Committee, 507--517.Google ScholarDigital Library"",""Xiangnan He and Tat-Seng Chua. 2017. Neural factorization machines for sparse predictive analytics. In SIGIR'17. ACM, 355--364.Google ScholarDigital Library"",""Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017b. Neural collaborative filtering. In WWW'17. International World Wide Web Conferences Steering Committee, 173--182.Google ScholarDigital Library"",""Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2016. Session-based recommendations with recurrent neural networks. In ICLR'16.Google Scholar"",""Geoffrey E Hinton, Alex Krizhevsky, and Sida D Wang. 2011. Transforming auto-encoders. In ICANN'11. Springer, 44--51.Google ScholarCross Ref"",""Kalervo Järvelin and Jaana Kekäläinen. 2000. IR evaluation methods for retrieving highly relevant documents. In SIGIR'00. ACM, 41--48.Google ScholarDigital Library"",""Sébastien Jean, Kyunghyun Cho, Roland Memisevic, and Yoshua Bengio. 2015. On using very large target vocabulary for neural machine translation. ACL'15.Google ScholarCross Ref"",""Jeff Johnson, Matthijs Douze, and Hervé Jégou. 2017. Billion-scale similarity search with GPUs. arXiv preprint arXiv:1702.08734 (2017).Google Scholar"",""M Kalaivanan and K Vengatesan. 2013. Recommendation system based on statistical analysis of ranking from user. In ICICES'13. IEEE, 479--484.Google ScholarCross Ref"",""Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recommendation. In ICDM'18. IEEE, 197--206.Google ScholarCross Ref"",""George Karypis. 2001. Evaluation of item-based top-n recommendation algorithms. In CIKM'01. ACM, 247--254.Google ScholarDigital Library"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix factorization techniques for recommender systems. Computer 8 (2009), 30--37.Google ScholarDigital Library"",""Chao Li, Zhiyuan Liu, Mengmeng Wu, Yuchi Xu, Pipei Huang, Huan Zhao, Guoliang Kang, Qiwei Chen, Wei Li, and Dik Lun Lee. 2019 a. Multi-Interest Network with Dynamic Routing for Recommendation at Tmall. arXiv preprint arXiv:1904.08030 (2019).Google Scholar"",""Chenliang Li, Cong Quan, Li Peng, Yunwei Qi, Yuming Deng, and Libing Wu. 2019 b. A Capsule Network for Recommendation and Explaining What You Like and Dislike. In SIGIR'19. ACM, 275--284.Google ScholarDigital Library"",""Jianxun Lian, Xiaohuan Zhou, Fuzheng Zhang, Zhongxia Chen, Xing Xie, and Guangzhong Sun. 2018. xDeepFM: Combining explicit and implicit feature interactions for recommender systems. In KDD'18. ACM, 1754--1763.Google ScholarDigital Library"",""Dawen Liang, Rahul G Krishnan, Matthew D Hoffman, and Tony Jebara. 2018. Variational autoencoders for collaborative filtering. In WWW'18. 689--698.Google ScholarDigital Library"",""Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen Zhou, and Yoshua Bengio. 2017. A structured self-attentive sentence embedding. In ICLR'17.Google Scholar"",""Fuyu Lv, Taiwei Jin, Changlong Yu, Fei Sun, Quan Lin, Keping Yang, and Wilfred Ng. 2019. SDM: Sequential deep matching model for online large-scale recommender system. In CIKM'19. 2635--2643.Google ScholarDigital Library"",""Jianxin Ma, Chang Zhou, Peng Cui, Hongxia Yang, and Wenwu Zhu. 2019. Learning disentangled representations for recommendation. In NIPS'19. 5712--5723.Google Scholar"",""Benjamin Marlin. 2004. Collaborative filtering: A machine learning perspective. University of Toronto Toronto.Google Scholar"",""Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van Den Hengel. 2015. Image-based recommendations on styles and substitutes. In SIGIR'15. ACM, 43--52.Google ScholarDigital Library"",""Katja Niemann and Martin Wolpers. 2013. A new collaborative filtering approach for increasing the aggregate diversity of recommender systems. In KDD'13. 955--963.Google ScholarDigital Library"",""Umberto Panniello, Alexander Tuzhilin, and Michele Gorgoglione. 2014. Comparing context-aware recommender systems in terms of accuracy and diversity. UMUAI, Vol. 24, 1--2 (2014), 35--65.Google Scholar"",""Qi Pi, Weijie Bian, Guorui Zhou, Xiaoqiang Zhu, and Kun Gai. 2019. Practice on long sequential user behavior modeling for click-through rate prediction. In KDD'19. 2671--2679.Google ScholarDigital Library"",""Lijing Qin and Xiaoyan Zhu. 2013. Promoting diversity in recommendation by entropy regularizer. In IJCAI'13.Google Scholar"",""Steffen Rendle. 2010. Factorization machines. In ICDM'10. IEEE, 995--1000.Google ScholarDigital Library"",""Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Factorizing personalized markov chains for next-basket recommendation. In WWW'10. ACM, 811--820.Google ScholarDigital Library"",""Sara Sabour, Nicholas Frosst, and Geoffrey E Hinton. 2017. Dynamic routing between capsules. In NIPS'17. 3856--3866.Google Scholar"",""Badrul Munir Sarwar, George Karypis, Joseph A Konstan, John Riedl, et almbox. 2001. Item-based collaborative filtering recommendation algorithms. WWW'01 (2001), 285--295.Google ScholarDigital Library"",""J Ben Schafer, Dan Frankowski, Jon Herlocker, and Shilad Sen. 2007. Collaborative filtering recommender systems. In The adaptive web. Springer, 291--324.Google ScholarDigital Library"",""Malcolm Slaney and William White. 2006. Measuring playlist diversity for recommendation systems. In AMCMM'06 workshop. 77--82.Google ScholarDigital Library"",""Yaoru Sun and Robert Fisher. 2003. Object-based visual attention for computer vision. Artificial intelligence, Vol. 146, 1 (2003), 77--123.Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In NIPS'17. 5998--6008.Google ScholarDigital Library"",""Pengfei Wang, Jiafeng Guo, Yanyan Lan, Jun Xu, Shengxian Wan, and Xueqi Cheng. 2015. Learning hierarchical representation model for nextbasket recommendation. In SIGIR'15. ACM, 403--412.Google ScholarDigital Library"",""Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. 2017. Deep \u0026 cross network for ad click predictions. In ADKDD'17. ACM, 12.Google ScholarDigital Library"",""Chao-Yuan Wu, Amr Ahmed, Alex Beutel, Alexander J Smola, and How Jing. 2017. Recurrent recommender networks. In WSDM'17. ACM, 495--503.Google ScholarDigital Library"",""Hong-Jian Xue, Xinyu Dai, Jianbing Zhang, Shujian Huang, and Jiajun Chen. 2017. Deep Matrix Factorization Models for Recommender Systems.. In IJCAI'17. 3203--3209.Google ScholarCross Ref"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale recommender systems. In KDD'18. ACM, 974--983.Google ScholarDigital Library"",""Feng Yu, Qiang Liu, Shu Wu, Liang Wang, and Tieniu Tan. 2016. A dynamic recurrent model for next basket recommendation. In SIGIR'16. ACM, 729--732.Google ScholarDigital Library"",""Ting Yu, Junpeng Guo, Wenhua Li, Harry Jiannan Wang, and Ling Fan. 2019. Recommendation with diversity: An adaptive trust-aware model. Decision Support Systems, Vol. 123 (2019), 113073.Google ScholarCross Ref"",""Chang Zhou, Jinze Bai, Junshuai Song, Xiaofei Liu, Zhengchao Zhao, Xiusi Chen, and Jun Gao. 2018a. Atrank: An attention-based user behavior modeling framework for recommendation. In AAAI'18.Google Scholar"",""Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018b. Deep interest network for click-through rate prediction. In KDD'18. ACM, 1059--1068.Google ScholarDigital Library"",""Han Zhu, Xiang Li, Pengye Zhang, Guozheng Li, Jie He, Han Li, and Kun Gai. 2018. Learning tree-based deep model for recommender systems. In KDD'18. ACM, 1079--1088.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403345,Managing Diversity in Airbnb Search,"One of the long-standing questions in search systems is the role of diversity in results. From a product perspective, showing diverse results provides the user with more choice and should lead to an improved experience. However, this intuition is at odds with common machine learning approaches to ranking which directly optimize the relevance of each individual item without a holistic view of the result set. In this paper, we describe our journey in tackling the problem of diversity for Airbnb search, starting from heuristic based approaches and concluding with a novel deep learning solution that produces an embedding of the entire query context by leveraging Recurrent Neural Networks (RNNs). We hope our lessons learned will prove useful to others and motivate further research in this area.","[{""name"":""Mustafa Abdool"",""id"":""/profile/99659454264""},{""name"":""Malay Haldar"",""id"":""/profile/99659454547""},{""name"":""Prashant Ramanathan"",""id"":""/profile/99659453226""},{""name"":""Tyler Sax"",""id"":""/profile/99659574845""},{""name"":""Lanbo Zhang"",""id"":""/profile/99659573302""},{""name"":""Aamir Manaswala"",""id"":""/profile/99659574731""},{""name"":""Lynn Yang"",""id"":""/profile/99659574637""},{""name"":""Bradley Turnbull"",""id"":""/profile/99659370400""},{""name"":""Qing Zhang"",""id"":""/profile/99659455076""},{""name"":""Thomas Legrand"",""id"":""/profile/99659454809""},{""name"":""Mustafa Abdool"",""id"":""/profile/99659454264""},{""name"":""Malay Haldar"",""id"":""/profile/99659454547""},{""name"":""Prashant Ramanathan"",""id"":""/profile/99659453226""},{""name"":""Tyler Sax"",""id"":""/profile/99659574845""},{""name"":""Lanbo Zhang"",""id"":""/profile/99659573302""},{""name"":""Aamir Manaswala"",""id"":""/profile/99659574731""},{""name"":""Lynn Yang"",""id"":""/profile/99659574637""},{""name"":""Bradley Turnbull"",""id"":""/profile/99659370400""},{""name"":""Qing Zhang"",""id"":""/profile/99659455076""},{""name"":""Thomas Legrand"",""id"":""/profile/99659454809""}]","[""Qingyao Ai, Keping Bi, Jiafeng Guo, and W Bruce Croft. 2018. Learning a deep listwise context model for ranking refinement. In The 41st International ACM SIGIR Conference on Research \u0026 Development in Information Retrieval. 135--144.Google ScholarDigital Library"",""Qingyao Ai, Xuanhui Wang, Sebastian Bruch, Nadav Golbandi, Michael Bendersky, and Marc Najork. 2019. Learning Groupwise Multivariate Scoring Functions Using Deep Neural Networks. In Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval. 85--92.Google ScholarDigital Library"",""Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473 (2014).Google Scholar"",""Irwan Bello, Sayali Kulkarni, Sagar Jain, Craig Boutilier, Ed Chi, Elad Eban, Xiyang Luo, Alan Mackey, and Ofer Meshi. 2018. Seq2Slate: Re-ranking and Slate Optimization with RNNs. arxiv: 1810.02019 [cs.IR]Google Scholar"",""Jon Louis Bentley. 1975. Multidimensional binary search trees used for associative searching. Commun. ACM, Vol. 18, 9 (1975), 509--517.Google ScholarDigital Library"",""Zhe Cao, Tao Qin, Tie-Yan Liu, Ming-Feng Tsai, and Hang Li. 2007. Learning to rank: from pairwise approach to listwise approach. In Proceedings of the 24th international conference on Machine learning. 129--136.Google ScholarDigital Library"",""Jaime Carbonell and Jade Goldstein. 1998. The use of MMR, diversity-based reranking for reordering documents and producing summaries. In Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval. 335--336.Google ScholarDigital Library"",""Charles LA Clarke, Maheedhar Kolla, Gordon V Cormack, Olga Vechtomova, Azin Ashkan, Stefan Büttcher, and Ian MacKinnon. 2008. Novelty and diversity in information retrieval evaluation. In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval. 659--666.Google ScholarDigital Library"",""Thompson J.M Dowsland K.A. 2012. Simulated Annealing. In: Rozenberg G., Bäck T., Kok J.N. (eds) Handbook of Natural Computing. Springer, Berlin, Heidelberg. Springer, Berlin, Heidelberg.Google Scholar"",""Malay Haldar, Mustafa Abdool, Prashant Ramanathan, Tao Xu, Shulin Yang, Huizhong Duan, Qing Zhang, Nick Barrow-Williams, Bradley C. Turnbull, Brendan M. Collins, and Thomas Legrand. 2019. Applying Deep Learning to Airbnb Search. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining (Anchorage, AK, USA) (KDD '19). ACM, New York, NY, USA, 1927--1935. https://doi.org/10.1145/3292500.3330658Google ScholarDigital Library"",""Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural computation, Vol. 9, 8 (1997), 1735--1780.Google Scholar"",""Prashant Ramanathan Tyler Sax Lanbo Zhang Aamir Manasawala Shulin Yang Bradley Turnbull Malay Haldar, Mustafa Abdool and Junshuo Liao. 2020. Improving Deep Learning for Airbnb Search.Google Scholar"",""Jan Overgoor Maxim Charkov, Riley Newman. 2013. Location Relevance at Airbnb. https://medium.com/airbnb-engineering/location-relevance-at-airbnb-12c004247b07Google Scholar"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems. 3111--3119.Google Scholar"",""George L Nemhauser, Laurence A Wolsey, and Marshall L Fisher. 1978. An analysis of approximations for maximizing submodular set functions-I. Mathematical programming, Vol. 14, 1 (1978), 265--294.Google Scholar"",""Choon Hui Teo, Houssam Nassif, Daniel Hill, Sriram Srinivasan, Mitchell Goodman, Vijai Mohan, and SVN Vishwanathan. 2016. Adaptive, personalized diversity for visual discovery. In Proceedings of the 10th ACM conference on recommender systems. 35--38.Google ScholarDigital Library"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In Advances in Neural Information Processing Systems 30, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.). Curran Associates, Inc., 5998--6008. http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdfGoogle ScholarDigital Library"",""Martin Wattenberg, Fernanda Viégas, and Ian Johnson. 2016. How to Use t-SNE Effectively. Distill (2016). https://doi.org/10.23915/distill.00002Google Scholar""]"
https://doi.org/10.1145/3394486.3403346,Molecular Inverse-Design Platform for Material Industries,"The discovery of new materials has been the essential force which brings a discontinuous improvement to industrial products' performance. However, the extra-vast combinatorial design space of material structures exceeds human experts' capability to explore all, thereby hampering material development. In this paper, we present a material industry-oriented web platform of an AI-driven molecular inverse-design system, which automatically designs brand new molecular structures rapidly and diversely. Different from existing inverse-design solutions, in this system, the combination of substructure-based feature encoding and molecular graph generation algorithms allows a user to gain high-speed, interpretable, and customizable design process. Also, a hierarchical data structure and user-oriented UI provide a flexible and intuitive workflow. The system is deployed on IBM's and our client's cloud servers and has been used by 5 partner companies. To illustrate actual industrial use cases, we exhibit inverse-design of sugar and dye molecules, that were carried out by experimental chemists in those client companies. Compared to a general human chemist's standard performance, the molecular design speed was accelerated more than 10 times, and greatly increased variety was observed in the inverse-designed molecules without loss of chemical realism.","[{""name"":""Seiji Takeda"",""id"":""/profile/99659575147""},{""name"":""Toshiyuki Hama"",""id"":""/profile/99659574652""},{""name"":""Hsiang-Han Hsu"",""id"":""/profile/99659574032""},{""name"":""Victoria A. Piunova"",""id"":""/profile/99659573504""},{""name"":""Dmitry Zubarev"",""id"":""/profile/99659573243""},{""name"":""Daniel P. Sanders"",""id"":""/profile/99659574920""},{""name"":""Jed W. Pitera"",""id"":""/profile/81342507521""},{""name"":""Makoto Kogoh"",""id"":""/profile/99659573131""},{""name"":""Takumi Hongo"",""id"":""/profile/99659574490""},{""name"":""Yenwei Cheng"",""id"":""/profile/99659574369""},{""name"":""Wolf Bocanett"",""id"":""/profile/99659573721""},{""name"":""Hideaki Nakashika"",""id"":""/profile/99659573575""},{""name"":""Akihiro Fujita"",""id"":""/profile/99659574156""},{""name"":""Yuta Tsuchiya"",""id"":""/profile/99659572987""},{""name"":""Katsuhiko Hino"",""id"":""/profile/99659574266""},{""name"":""Kentaro Yano"",""id"":""/profile/99659573685""},{""name"":""Shuichi Hirose"",""id"":""/profile/99659573160""},{""name"":""Hiroki Toda"",""id"":""/profile/99659574226""},{""name"":""Yasumitsu Orii"",""id"":""/profile/99659574773""},{""name"":""Daiju Nakano"",""id"":""/profile/99659572983""},{""name"":""Seiji Takeda"",""id"":""/profile/99659575147""},{""name"":""Toshiyuki Hama"",""id"":""/profile/99659574652""},{""name"":""Hsiang-Han Hsu"",""id"":""/profile/99659574032""},{""name"":""Victoria A. Piunova"",""id"":""/profile/99659573504""},{""name"":""Dmitry Zubarev"",""id"":""/profile/99659573243""},{""name"":""Daniel P. Sanders"",""id"":""/profile/99659574920""},{""name"":""Jed W. Pitera"",""id"":""/profile/81342507521""},{""name"":""Makoto Kogoh"",""id"":""/profile/99659573131""},{""name"":""Takumi Hongo"",""id"":""/profile/99659574490""},{""name"":""Yenwei Cheng"",""id"":""/profile/99659574369""},{""name"":""Wolf Bocanett"",""id"":""/profile/99659573721""},{""name"":""Hideaki Nakashika"",""id"":""/profile/99659573575""},{""name"":""Akihiro Fujita"",""id"":""/profile/99659574156""},{""name"":""Yuta Tsuchiya"",""id"":""/profile/99659572987""},{""name"":""Katsuhiko Hino"",""id"":""/profile/99659574266""},{""name"":""Kentaro Yano"",""id"":""/profile/99659573685""},{""name"":""Shuichi Hirose"",""id"":""/profile/99659573160""},{""name"":""Hiroki Toda"",""id"":""/profile/99659574226""},{""name"":""Yasumitsu Orii"",""id"":""/profile/99659574773""},{""name"":""Daiju Nakano"",""id"":""/profile/99659572983""}]","[""Regine S. Bohacek, Colin. McMartin, and Wayne C. Guida, The art and practice of structure-based drug design: A molecular modeling perspective, Medicinal Research Reviews, 16 (1), 3--50 (1996).Google ScholarCross Ref"",""David. Rogers and Mathew Hahn, Extended-connectivity fingerprints, Journal of chemical information and modeling, 50(5), 742--754 (2010).Google Scholar"",""David Duvenaud, Dougal Maclaurin, Jorge Aguilera-Iparraguirre, Rafael Gómez-Bombarelli, Timothy Hirzel, Alán Aspuru-Guzik, Ryan P. Adams, Convolutional networks on graphs for learning molecular fingerprints, Proceedings of the 28th International Conference on Neural Information Processing Systems, 2224--2232 (2015).Google Scholar"",""Justin Gilmer, Samuel S. Schoenholz, Patrick F. Riley, Oriol Vinyals, George E. Dahl, Neural message passing or Quantum chemistry, ICML'17: Proceedings of the 34th International Conference on Machine Learning, vol.70, pp.1263--1272 (2017).Google Scholar"",""Han. Altae-Tran, Bharath. Ramsundar, Aneesh. S. Pappu, and Vijay. Pande, Low data drug discovery with one-shot learning, ACS Central Science 3, 283 (2017)Google ScholarCross Ref"",""Matthias Rupp, Alexandre Tkatchenko, Klaus-Robert Müller, and O. Anatole von Lilienfeld, Fast and accurate modeling of molecular atomization energies with machine learning, Phys. Rev. Lett., 108, 053801 (2012).Google ScholarCross Ref"",""Rafael Gómez-Bombarelli, Jennifer N. Wei, David Duvenaud, José Miguel Hernández-Lobato, Benjamín Sánchez-Lengeling, Dennis Sheberla, Jorge Aguilera-Iparraguirre, Timothy D. Hirzel, Ryan P. Adams, Alán Aspuru-Guzik, Automatic chemical design using a data-driven continuous representation of molecules, ACS Central Science, 4, pp.268--276 (2018).Google Scholar"",""Marwin H. Segler, Thierry. Kogej, Christian Trychan, and Mark P. Waller, Generating focused molecule libraries for drug discovery with recurrent neural networks, ACS Central Science, 4, 120--131 (2018)Google ScholarCross Ref"",""Benjamin Sanchez-Lengeling, Carlos Outeiral, Gabriel L. Guimaraes, Alan Aspuru-Guzik: Optimizing distributions over molecular space. An Objective-Reinforced Generative Adversarial Network for Inverse-design Chemistry (ORGANIC), ChemRxiv. (2017)Google Scholar"",""Garret B. Goh, Charles Siegel, Abhinav Vishnu, and Nathan Hodas: Using Rule-Based Labels for Weak Supervised Learning: A ChemNet for Transferable Chemical Property Prediction, Proceedings of 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining (2018)Google Scholar"",""Aaron M. Virshup, Julia Contreras-García, Peter Wipf, Weitao Yang, David N. Beratan: Stochastic Voyages into Uncharted Chemical Space Produce a Representative Library of All Possible Drug-Like Compounds, Journal of the American Chemical Society, 135, 7296--7303 (2013).Google ScholarCross Ref"",""Rafael Gómez-Bombarelli, Jorge Aguilera-Iparraguirre, Timothy D. Hirzel, David Duvenaud, Dougal Maclaurin, Martin A. Blood-Forsythe, Hyun Sik Chae, Markus Einzinger, Dong-Gwang Ha, Tony Wu, Georgios Markopoulos, Soonok Jeon, Hosuk Kang, Hiroshi Miyazaki, Masaki Numata, Sunghan Kim, Wenliang Huang, Seong Ik Hong, Marc Baldo, Ryan P. Adams, Alán Aspuru-Guzik, Design of efficient molecular organic light-emitting diodes by a high-throughput virtual screening and experimental approach, Nature Materials, 15, 1120--1128 (2016).Google ScholarCross Ref"",""Gabriel L. Guimaraes, Benjamin S.-Lengeling, Pedro L. C. Farias and Alán Aspuru-Guzik: Objective-Reinforced Generative Adversarial Networks (ORGAN) for Sequence Generation Models.\"" ArXiv abs/1705.10843 (2017)Google Scholar"",""Edward. O. Pyzer-Knapp, Changwon Suh, Rafael Gómez-Bombarelli, Jorge Aguilera-Iparraguirre, and Alán Aspuru-Guzik, What is high-thoughput virtual screening? A perspective from organic materials discovery, Annual Review of Materials Research, 45, 195--216 (2015).Google ScholarCross Ref"",""X. Yang, J. Zhang, K. Yoshizoe, K. Terayama and K. Tsuda, ChemTS: an efficient python library for de novo molecular generation, Science and Technology of Advanced Material,s 18, 972--976, 2017.Google Scholar"",""Nicola De Cao, Thomas Kipf, MolGAN: An implicit generative model for small molecular graphs, arXiv:1805.11973 [stat.ML]Google Scholar"",""Daniel C. Elton, Zois Boukouvalas, Mark D. Fuge, Peter W. Chung, Deep learning for molecular design -- a review of the state of the art, arXiv:1903.04388 [cs.LG]Google Scholar"",""N. M. Kriege, F. D. Johansson, C. A. Morris, Survey on graph kernels. Applied Network Science 5, 6 (2020).Google ScholarCross Ref"",""Brendan D. McKay. Isomorph-free exhaustive generation. Journal of Algorithms, 26(2):306--324 (1998)Google ScholarDigital Library"",""A. Kerber, R. Laue, T. Grüner, M. Meringer, MOLGEN 4.0, MATCH Communications in Mathematical and in Computer Chemistry 37, 205--208, (1998)Google Scholar"",""Stephen G. Hartke and A. J. Radcliffe. Mckay's canonical graph labeling algorithm. In Communicating Mathematics, 479, 99--111 (2009)Google Scholar"",""Raghunathan Ramakrishnan, Pavlo O. Dral, Matthias Rupp, O. Anatole vol Lilienfeld: Quantum chemistry structures and properties of 134 kilo molecules, Scientific Data, 1, 140022 (2014).Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403347,Learning to Score Economic Development from Satellite Imagery,"Reliable and timely measurements of economic activities are fundamental for understanding economic development and designing government policies. However, many developing countries still lack reliable data. In this paper, we introduce a novel approach for measuring economic development from high-resolution satellite images in the absence of ground truth statistics. Our method consists of three steps. First, we run a clustering algorithm on satellite images that distinguishes artifacts from nature (siCluster). Second, we generate a partial order graph of the identified clusters based on the level of economic development, either by human guidance or by low-resolution statistics (siPog). Third, we use a CNN-based sorter that assigns differentiable scores to each satellite grid based on the relative ranks of clusters (siScore). The novelty of our method is that we break down a computationally hard problem into sub-tasks, which involves a human-in-the-loop solution. With the combination of unsupervised learning and the partial orders of dozens of urban vs. rural clusters, our method can estimate the economic development scores of over 10,000 satellite grids consistently with other baseline development proxies (Spearman correlation of 0.851). This efficient method is interpretable and robust; we demonstrate how to apply our method to both developed (e.g., South Korea) and developing economies (e.g., Vietnam and Malawi).","[{""name"":""Sungwon Han"",""id"":""/profile/99659453826""},{""name"":""Donghyun Ahn"",""id"":""/profile/99659574600""},{""name"":""Sungwon Park"",""id"":""/profile/99659574034""},{""name"":""Jeasurk Yang"",""id"":""/profile/99659574929""},{""name"":""Susang Lee"",""id"":""/profile/99659575224""},{""name"":""Jihee Kim"",""id"":""/profile/99658639957""},{""name"":""Hyunjoo Yang"",""id"":""/profile/99659573588""},{""name"":""Sangyoon Park"",""id"":""/profile/99659574033""},{""name"":""Meeyoung Cha"",""id"":""/profile/99659573060""},{""name"":""Sungwon Han"",""id"":""/profile/99659453826""},{""name"":""Donghyun Ahn"",""id"":""/profile/99659574600""},{""name"":""Sungwon Park"",""id"":""/profile/99659574034""},{""name"":""Jeasurk Yang"",""id"":""/profile/99659574929""},{""name"":""Susang Lee"",""id"":""/profile/99659575224""},{""name"":""Jihee Kim"",""id"":""/profile/99658639957""},{""name"":""Hyunjoo Yang"",""id"":""/profile/99659573588""},{""name"":""Sangyoon Park"",""id"":""/profile/99659574033""},{""name"":""Meeyoung Cha"",""id"":""/profile/99659573060""}]","[""Qingyao Ai, Keping Bi, Jiafeng Guo, and W Bruce Croft. 2018. Learning a deep listwise context model for ranking refinement. In proc. of the ACM SIGIR. 135--144.Google ScholarDigital Library"",""Adrian Albert, Jasleen Kaur, and Marta C Gonzalez. 2017. Using convolutional networks and satellite imagery to identify patterns in urban environments at a large scale. In proc. of the ACM SIGKDD. 1357--1366.Google ScholarDigital Library"",""Hasi Bagan and Yoshiki Yamagata. 2015. Analysis of urban growth and estimating population density using satellite images of nighttime lights and land-use and population data. GIScience \u0026 Remote Sensing, Vol. 52, 6 (2015), 765--780.Google ScholarCross Ref"",""Christopher JC Burges. 2010. From ranknet to lambdarank to lambdamart: An overview. Learning, Vol. 11, 23--581 (2010), 81.Google Scholar"",""Mathilde Caron, Piotr Bojanowski, Armand Joulin, and Matthijs Douze. 2018. Deep clustering for unsupervised learning of visual features. In proc. of the ECCV. 132--149.Google ScholarCross Ref"",""Mayuri Chaturvedi, Tilottama Ghosh, and Laveesh Bhandari. 2011. Assessing Income Distribution at the District Level for India Using Nighttime Satellite Imagery. In proc. of the APAN.Google ScholarCross Ref"",""Qing Cheng, Huanfeng Shen, Liangpei Zhang, Qiangqiang Yuan, and Chao Zeng. 2014. Cloud removal for remotely sensed images by similar pixel replacement guided with a spatio-temporal MRF model. ISPRS journal of photogrammetry and remote sensing, Vol. 92 (2014), 54--68.Google Scholar"",""Dave Donaldson and Adam Storeygard. 2016. The view from above: Applications of satellite data in economics. Journal of Economic Perspectives, Vol. 30, 4 (2016), 171--98.Google ScholarCross Ref"",""Erin Doxsey-Whitfield, Kytt MacManus, Susana B Adamo, Linda Pistolesi, John Squires, Olena Borkovska, and Sandra R Baptista. 2015. Taking advantage of the improved availability of census data: a first look at the gridded population of the world, version 4. Papers in Applied Geography, Vol. 1, 3 (2015), 226--234.Google ScholarCross Ref"",""Martin Engilberge, Louis Chevallier, Patrick Pérez, and Matthieu Cord. 2019. SoDeep: a Sorting Deep net to learn ranking loss surrogates. In proc. of the IEEE CVPR. 10792--10801.Google ScholarCross Ref"",""Facebook. 2020. Data for Good program. Available at https://data.humdata.org/organization/facebook. Date accessed 29 Jan 2020.Google Scholar"",""Jonathan A Foley, Ruth DeFries, Gregory P Asner, Carol Barford, Gordon Bonan, Stephen R Carpenter, F Stuart Chapin, Michael T Coe, Gretchen C Daily, Holly K Gibbs, et almbox. 2005. Global consequences of land use. Science, Vol. 309, 5734 (2005), 570--574.Google Scholar"",""Tilottama Ghosh, Sharolyn Anderson, Christopher Elvidge, and Paul Sutton. 2013. Using nighttime satellite imagery as a proxy measure of human well-being. Sustainability, Vol. 5, 12 (2013), 4988--5019.Google ScholarCross Ref"",""Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. Deep learning. MIT press.Google Scholar"",""Patrick Griffiths, Patrick Hostert, Oliver Gruebner, and Sebastian V. der Linden. 2010. Mapping megacity growth with multi-sensor data. Remote Sensing of Environment, Vol. 114, 2 (2010), 426--439.Google ScholarCross Ref"",""Sungwon Han, Donghyun Ahn, Hyunji Cha, Jeasurk Yang, Sungwon Park, and Meeyoung Cha. 2020. Lightweight and Robust Representation of Economic Scales from Satellite Imagery. In proc. of the AAAI.Google Scholar"",""Jing He, Xin Li, and Lejian Liao. 2017. Category-aware Next Point-of-Interest Recommendation via Listwise Bayesian Personalized Ranking. In proc. of the IJCAI. 1837--1843.Google ScholarCross Ref"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In proc. of the IEEE CVPR.Google ScholarCross Ref"",""Andrew Head, Mélanie Manguin, Nhat Tran, and Joshua E. Blumenstock. 2017. Can Human Development be Measured with Satellite Imagery?. In proc. of the ICTD.Google Scholar"",""Andreas Holzinger, Markus Plass, Michael Kickmeier-Rust, Katharina Holzinger, Gloria Cerasela Crişan, Camelia-M. Pintea, and Vasile Palade. 2019. Interactive machine learning: experimental evidence for the human in the algorithmic loop. Applied Intelligence, Vol. 49 (2019), 2401--2414.Google ScholarDigital Library"",""Ziniu Hu, Yang Wang, Qu Peng, and Hang Li. 2019. Unbiased LambdaMART: An Unbiased Pairwise Learning-to-Rank Algorithm. In proc. of the WWW. 2830--2836.Google Scholar"",""Neal Jean, Marshall Burke, Michael Xie, W Matthew Davis, David B Lobell, and Stefano Ermon. 2016. Combining satellite imagery and machine learning to predict poverty. Science, Vol. 353, 6301 (2016), 790--794.Google ScholarCross Ref"",""Xu Ji, Joao F Henriques, and Andrea Vedaldi. 2019. Invariant information clustering for unsupervised image classification and segmentation. In proc. of the IEEE ICCV. 9865--9874.Google ScholarCross Ref"",""Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012. Imagenet classification with deep convolutional neural networks. In proc. of the NIPS. 1097--1105.Google Scholar"",""Husi Letu, Gegen Tana, Masanao Hara, and Fumihiko Nishio. 2011. Monitoring the electric power consumption by lighting from DMSP/OLS nighttime satellite imagery. In prof. of the IEEE IGARSS.Google Scholar"",""Nikhil Naik, Scott Duke Kominers, Ramesh Raskar, Edward L Glaeser, and César A Hidalgo. 2017. Computer vision uncovers predictors of physical urban change. PNAS, Vol. 114, 29 (2017), 7571--7576.Google ScholarCross Ref"",""Arthur O'Sullivan. 2019. Urban Economics, Nineth Edition. McGraw-Hill.Google Scholar"",""Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. 2017. Grad-cam: Visual explanations from deep networks via gradient-based localization. In IEEE ICCV. 618--626.Google Scholar"",""Evan Sheehan, Chenlin Meng, Matthew Tan, Burak Uzkent, Neal Jean, Marshall Burke, David Lobell, and Stefano Ermon. 2019. Predicting economic development using geolocated wikipedia articles. In proc. of the ACM SIGKDD. 2698--2706.Google ScholarDigital Library"",""Jessica E Steele, Pål Roe Sundsøy, Carla Pezzulo, Victor A Alegana, Tomas J Bird, Joshua Blumenstock, Johannes Bjelland, Kenth Engø-Monsen, Yves-Alexandre de Montjoye, Asif M Iqbal, et almbox. 2017. Mapping poverty using mobile phone and satellite data. Journal of The Royal Society Interface, Vol. 14, 127 (2017), 20160690.Google ScholarCross Ref"",""Antti Tarvainen and Harri Valpola. 2017. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In proc. of the NIPS.Google Scholar"",""Yi Tay, Minh C Phan, Luu Anh Tuan, and Siu Cheung Hui. 2017. Learning to rank question answer pairs with holographic dual LSTM architecture. In proc. of the ACM SIGIR. 695--704.Google ScholarDigital Library"",""Henderson J. Vernon. 2003. Urbanization and Economic Development. Annals of Economics and Finance, Vol. 4, 2 (2003), 275--341.Google Scholar""]"
https://doi.org/10.1145/3394486.3403348,A Request-level Guaranteed Delivery Advertising Planning: Forecasting and Allocation,"The guaranteed delivery model is widely used in online advertising. The publisher sells impressions in advance by promising to serve each advertiser an agreed-upon number of target impressions that satisfy specific attribute requirements over a fixed time period. Previous efforts usually model the service as a crowd-level or user-level supply allocation problem and focus on searching optimal allocation for online serving, assuming that forecasts of supply are available and contracts are already signed. Existing techniques are not sufficient to meet the needs of today's industry trends: 1) advertisers pursue more precise targeting, which requires not only user-level attributes but also request-level attributes; 2) users prefer more friendly ad serving, which imposes more diverse serving constraints; 3) the bottleneck of the publisher's revenue growth lies in not only the ad serving, but also the forecast accuracy and sales strategy. These issues are non-trivial to address, since the scale of the request-level model is orders of magnitude larger than that of the crowd-level or user-level models. Facing the challenges, we present a holistic design of a request-level guaranteed delivery advertising planning system with careful optimization for all three critical components including impression forecasting, selling and serving. Our system has been deployed in the Tencent online guaranteed delivery advertising system serving billion level users for nearly one year. Evaluations on large-scale real data and the performance of the deployed system both demonstrate that our design can significantly increase the request-level impression forecast accuracy and delivery rate.","[{""name"":""Hong Zhang"",""id"":""/profile/99659574638""},{""name"":""Lan Zhang"",""id"":""/profile/99659520030""},{""name"":""Lan Xu"",""id"":""/profile/99659454690""},{""name"":""Xiaoyang Ma"",""id"":""/profile/99659453265""},{""name"":""Zhengtao Wu"",""id"":""/profile/99659454552""},{""name"":""Cong Tang"",""id"":""/profile/99659573752""},{""name"":""Wei Xu"",""id"":""/profile/99659573418""},{""name"":""Yiguo Yang"",""id"":""/profile/99659574711""},{""name"":""Hong Zhang"",""id"":""/profile/99659574638""},{""name"":""Lan Zhang"",""id"":""/profile/99659520030""},{""name"":""Lan Xu"",""id"":""/profile/99659454690""},{""name"":""Xiaoyang Ma"",""id"":""/profile/99659453265""},{""name"":""Zhengtao Wu"",""id"":""/profile/99659454552""},{""name"":""Cong Tang"",""id"":""/profile/99659573752""},{""name"":""Wei Xu"",""id"":""/profile/99659573418""},{""name"":""Yiguo Yang"",""id"":""/profile/99659574711""}]","[""Mohammad Taha Bahadori, Qi Rose Yu, and Yan Liu. 2014. Fast multivariate spatio-temporal analysis via low rank tensor learning. In NIPS. 3491--3499.Google Scholar"",""Vijay Bharadwaj, Peiji Chen, Wenjing Ma, Chandrashekhar Nagarajan, John Tomlin, Sergei Vassilvitskii, Erik Vee, and Jian Yang. 2012. Shale: an efficient algorithm for allocation of guaranteed display advertising. In ACM SIGKDD. 1195--1203.Google Scholar"",""Preeti Bhargava, Thomas Phan, Jiayu Zhou, and Juhan Lee. 2015. Who, what, when, and where: Multi-dimensional collaborative recommendations using tensor factorization on sparse user-generated data. In WWW. ACM.Google Scholar"",""Peiji Chen, Wenjing Ma, Srinath Mandalapu, Chandrashekhar Nagarjan, Jayavel Shanmugasundaram, Sergei Vassilvitskii, Erik Vee, Manfai Yu, and Jason Zien. 2012. Ad serving using a compact allocation plan. In 13th ACM Conference on Electronic Commerce. 319--336.Google ScholarDigital Library"",""Zhen Fang, Yang Li, Chuanren Liu, Wenxiang Zhu, Yu Zheng, and Wenjun Zhou. 2019. Large-Scale Personalized Delivery for Guaranteed Display Advertising with Real-Time Pacing. In ICDM. IEEE, 190--199.Google Scholar"",""Jon Feldman, Aranyak Mehta, Vahab Mirrokni, and Shan Muthukrishnan. 2009. Online stochastic matching: Beating 1--1/e. In 50th Annual IEEE Symposium on Foundations of Computer Science. IEEE, 117--126.Google ScholarDigital Library"",""Ali Hojjat, John Turner, Suleyman Cetintas, and Jian Yang. 2014. Delivering guaranteed display ads under reach and frequency requirements. In AAAI.Google Scholar"",""Ali Hojjat, John Turner, Suleyman Cetintas, and Jian Yang. 2017. A unified framework for the scheduling of guaranteed targeted display advertising under reach and frequency requirements. Operations Research, Vol. 65, 2 (2017), 289--313.Google ScholarDigital Library"",""Chinmay Karande, Aranyak Mehta, and Pushkar Tripathi. 2011. Online bipartite matching with unknown distributions. In 43rd annual ACM symposium on Theory of computing. 587--596.Google Scholar"",""Xiaoyang Ma, Lan Zhang, Lan Xu, Zhicheng Liu, Ge Chen, Zhili Xiao, Yang Wang, and Zhengtao Wu. 2019. Large-scale User Visits Understanding and Forecasting with Deep Spatial-Temporal Tensor Factorization Framework. In ACM SIGKDD. 2403--2411.Google Scholar"",""Vahab S Mirrokni, Shayan Oveis Gharan, and Morteza Zadimoghaddam. 2012. Simultaneous approximations for adversarial and stochastic online budgeted allocation. In 23rd annual ACM-SIAM symposium on Discrete Algorithms. SIAM, 1690--1701.Google Scholar"",""Erik Vee, Sergei Vassilvitskii, and Jayavel Shanmugasundaram. 2010. Optimal online assignment with forecasts. In 11th ACM conference on Electronic commerce. 109--118.Google ScholarDigital Library"",""Ulrike Von Luxburg et almbox. 2010. Clustering stability: an overview. Foundations and Trends® in Machine Learning, Vol. 2, 3 (2010), 235--274.Google Scholar"",""Jia Zhang, Zheng Wang, Qian Li, Jialin Zhang, Yanyan Lan, Qiang Li, and Xiaoming Sun. 2017. Efficient delivery policy to minimize user traffic consumption in guaranteed advertising. In AAAI.Google Scholar""]"
https://doi.org/10.1145/3394486.3403349,Two Sides of the Same Coin: White-box and Black-box Attacks for Transfer Learning,"Transfer learning has become a common practice for training deep learning models with limited labeled data in a target domain. On the other hand, deep models are vulnerable to adversarial attacks. Though transfer learning has been widely applied, its effect on model robustness is unclear. To figure out this problem, we conduct extensive empirical evaluations to show that fine-tuning effectively enhances model robustness under white-box FGSM attacks. We also propose a black-box attack method for transfer learning models which attacks the target model with the adversarial examples produced by its source model. To systematically measure the effect of both white-box and black-box attacks, we propose a new metric to evaluate how transferable are the adversarial examples produced by a source model to a target model. Empirical results show that the adversarial examples are more transferable when fine-tuning is used than they are when the two networks are trained independently.","[{""name"":""Yinghua Zhang"",""id"":""/profile/99659575108""},{""name"":""Yangqiu Song"",""id"":""/profile/81317500799""},{""name"":""Jian Liang"",""id"":""/profile/99659573706""},{""name"":""Kun Bai"",""id"":""/profile/99659567987""},{""name"":""Qiang Yang"",""id"":""/profile/81548761456""},{""name"":""Yinghua Zhang"",""id"":""/profile/99659575108""},{""name"":""Yangqiu Song"",""id"":""/profile/81317500799""},{""name"":""Jian Liang"",""id"":""/profile/99659573706""},{""name"":""Kun Bai"",""id"":""/profile/99659567987""},{""name"":""Qiang Yang"",""id"":""/profile/81548761456""}]","[""Pin-Yu Chen, Huan Zhang, Yash Sharma, Jinfeng Yi, and Cho-Jui Hsieh. 2017. Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models. In Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security. 15--26.Google ScholarDigital Library"",""Patryk Chrabaszcz, Ilya Loshchilov, and Frank Hutter. 2017. A downsampled variant of imagenet as an alternative to the cifar datasets. arXiv preprint arXiv:1707.08819 (2017).Google Scholar"",""Adam Coates, Andrew Ng, and Honglak Lee. 2011. An analysis of single-layer networks in unsupervised feature learning. In Proceedings of the fourteenth international conference on artificial intelligence and statistics. 215--223.Google Scholar"",""Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Francc ois Laviolette, Mario Marchand, and Victor Lempitsky. 2016. Domain-adversarial training of neural networks. The Journal of Machine Learning Research, Vol. 17, 1 (2016), 2096--2030.Google ScholarDigital Library"",""Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra Malik. 2014. Rich feature hierarchies for accurate object detection and semantic segmentation. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition. 580--587.Google ScholarDigital Library"",""Ian Goodfellow, Jonathon Shlens, and Christian Szegedy. 2015. Explaining and harnessing adversarial examples. (2015). http://arxiv.org/abs/1412.6572Google Scholar"",""Dan Hendrycks, Kimin Lee, and Mantas Mazeika. 2019. Using Pre-Training Can Improve Model Robustness and Uncertainty. In International Conference on Machine Learning. 2712--2721.Google Scholar"",""Jonathan J. Hull. 1994. A database for handwritten text recognition research. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 16, 5 (1994), 550--554.Google ScholarDigital Library"",""Andrej Karpathy, George Toderici, Sanketh Shetty, Thomas Leung, Rahul Sukthankar, and Li Fei-Fei. 2014. Large-scale video classification with convolutional neural networks. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition. 1725--1732.Google ScholarDigital Library"",""Alex Krizhevsky, Geoffrey Hinton, et almbox. 2009. Learning multiple layers of features from tiny images. Technical Report. Citeseer.Google Scholar"",""Yann LeCun, Léon Bottou, Yoshua Bengio, Patrick Haffner, et almbox. 1998. Gradient-based learning applied to document recognition. Proc. IEEE, Vol. 86, 11 (1998), 2278--2324.Google ScholarCross Ref"",""Yanpei Liu, Xinyun Chen, Chang Liu, and Dawn Song. 2017. Delving into transferable adversarial examples and black-box attacks. (2017). https://openreview.net/forum?id=Sys6GJqxlGoogle Scholar"",""Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. 2018. Towards deep learning models resistant to adversarial attacks. (2018). https://openreview.net/forum?id=rJzIBfZAbGoogle Scholar"",""Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. 2011. Reading digits in natural images with unsupervised feature learning. (2011).Google Scholar"",""Maxime Oquab, Leon Bottou, Ivan Laptev, and Josef Sivic. 2014. Learning and transferring mid-level image representations using convolutional neural networks. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition. 1717--1724.Google ScholarDigital Library"",""Sinno Jialin Pan and Qiang Yang. 2010. A survey on transfer learning. IEEE Transactions on Knowledge and Data Engineering, Vol. 22, 10 (2010), 1345--1359.Google ScholarDigital Library"",""Nicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z Berkay Celik, and Ananthram Swami. 2017. Practical black-box attacks against machine learning. In Proceedings of the 2017 ACM on Asia conference on computer and communications security. 506--519.Google ScholarDigital Library"",""Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. 2015. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision, Vol. 115, 3 (2015), 211--252.Google ScholarDigital Library"",""Ludwig Schmidt, Shibani Santurkar, Dimitris Tsipras, Kunal Talwar, and Aleksander Madry. 2018. Adversarially robust generalization requires more data. In Advances in Neural Information Processing Systems. 5014--5026.Google Scholar"",""Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. 2014. Intriguing properties of neural networks. (2014). http://arxiv.org/abs/1312.6199Google Scholar"",""Subhashini Venugopalan, Marcus Rohrbach, Jeffrey Donahue, Raymond Mooney, Trevor Darrell, and Kate Saenko. 2015a. Sequence to sequence-video to text. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition. 4534--4542.Google ScholarDigital Library"",""Subhashini Venugopalan, Huijuan Xu, Jeff Donahue, Marcus Rohrbach, Raymond Mooney, and Kate Saenko. 2015b. Translating Videos to Natural Language Using Deep Recurrent Neural Networks. In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 1494--1504.Google ScholarCross Ref"",""Oriol Vinyals, Alexander Toshev, Samy Bengio, and Dumitru Erhan. 2015. Show and tell: A neural image caption generator. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition. 3156--3164.Google ScholarCross Ref"",""Karl Weiss, Taghi M Khoshgoftaar, and Dingding Wang. 2016. A survey of transfer learning. Journal of Big Data, Vol. 3, 1 (2016), 1--40.Google ScholarCross Ref"",""Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson. 2014. How transferable are features in deep neural networks?. In Advances in Neural Information Processing Systems. 3320--3328.Google Scholar"",""Xiaoyong Yuan, Pan He, Qile Zhu, and Xiaolin Li. 2019. Adversarial examples: Attacks and defenses for deep learning. IEEE Transactions on Neural Networks and Learning Systems, Vol. 30, 9 (2019), 2805--2824.Google ScholarCross Ref"",""Sergey Zagoruyko and Nikos Komodakis. 2016. Wide residual networks. arXiv preprint arXiv:1605.07146 (2016).Google Scholar""]"
https://doi.org/10.1145/3394486.3403350,Learning to Generate Personalized Query Auto-Completions via a Multi-View Multi-Task Attentive Approach,"In this paper, we study the task of Query Auto-Completion (QAC), which is a very significant feature of modern search engines. In real industrial application, there always exist two major problems of QAC - weak personalization and unseen queries. To address these problems, we propose M2A, a multi-view multi-task attentive framework to learn personalized query auto-completion models. We propose a new Transformer-based hierarchical encoder to model different kinds of sequential behaviors, which can be seen as multiple distinct views of the user's searching history, and then a prefix-to-history attention mechanism is used to select the most relevant information to compose the final intention representation. To learn more informative representations, we propose to incorporate multi-task learning into the model training. Two different kinds of supervisory information provided by query logs are utilized at the same time by jointly training a CTR prediction model and a query generation model.To bridge the gap between the setting of research work and the real scenario, we release a new large-scale query log dataset - TaobaoQAC, which contains rich real prefix-to-query click behaviors. We conduct experiments on TaobaoQAC to demonstrate the effectiveness or our approach, and results show that M2A achieves superior performance compared with several strong baselines in both candidate ranking and query generation. We also conduct an online A/B testing and our approach has been deployed online.","[{""name"":""Di Yin"",""id"":""/profile/99659573613""},{""name"":""Jiwei Tan"",""id"":""/profile/99659345721""},{""name"":""Zhe Zhang"",""id"":""/profile/99659574888""},{""name"":""Hongbo Deng"",""id"":""/profile/81413600167""},{""name"":""Shujian Huang"",""id"":""/profile/81486646888""},{""name"":""Jiajun Chen"",""id"":""/profile/81438594955""},{""name"":""Di Yin"",""id"":""/profile/99659573613""},{""name"":""Jiwei Tan"",""id"":""/profile/99659345721""},{""name"":""Zhe Zhang"",""id"":""/profile/99659574888""},{""name"":""Hongbo Deng"",""id"":""/profile/81413600167""},{""name"":""Shujian Huang"",""id"":""/profile/81486646888""},{""name"":""Jiajun Chen"",""id"":""/profile/81438594955""}]","[""Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural Machine Translation by Jointly Learning to Align and Translate. In ICLR 2015.Google Scholar"",""Ziv Bar-Yossef and Naama Kraus. 2011. Context-Sensitive Query Auto-Completion. In Proceedings of WWW 2011. ACM.Google ScholarDigital Library"",""Fei Cai and Maarten de Rijke. 2016. A Survey of Query Auto Completion in Information Retrieval. In Foundations and Trends in Information Retrieval.Google Scholar"",""Fei Cai, Shangsong Liang, and Maarten de Rijke. 2014. Time-sensitive Personalized Query Auto-Completion. In Proceedings of CIKM 2014. 1599--1608.Google ScholarDigital Library"",""Mostafa Dehghani, Sascha Rothe, Enrique Alfonseca, and Pascal Fleury. 2017. Learning to Attend, Copy, and Generate for Session-Based Query Suggestion. In Proceedings of CIKM 2017. 1747--1756.Google ScholarDigital Library"",""Hui Fang, Danning Zhang, Yiheng Shu, and Guibing Guo. 2019. Deep Learning-based Sequential Recommender Systems: Concepts, Algorithms, and Evaluations. (2019).Google Scholar"",""Nicolas Fiorini and Zhiyong Lu. 2018. Personalized neural language models for real-world query auto completion. (2018).Google Scholar"",""Balá zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2016. Session-based Recommendations with Recurrent Neural Networks. In Proceedings of ICLR 2016.Google Scholar"",""Sepp Hochreiter and Jü rgen Schmidhuber. 1997. Long Short-Term Memory. Neural Computation, Vol. 9, 8 (1997), 1735--1780.Google ScholarDigital Library"",""Zhiting Hu, Haoran Shi, Bowen Tan, Wentao Wang, Zichao Yang, Tiancheng Zhao, Junxian He, Lianhui Qin, Di Wang, Xuezhe Ma, Zhengzhong Liu, Xiaodan Liang, Wanrong Zhu, Devendra Singh Sachan, and Eric P. Xing. 2019. Texar: A Modularized, Versatile, and Extensible Toolkit for Text Generation. In Proceedings of ACL 2019, Volume 3: System Demonstrations. 159--164.Google Scholar"",""Fakultit F/Jr Informatik, Yoshua Bengio, Paolo Frasconi, and Jfirgen Schmidhuber. 2001. Gradient Flow in Recurrent Nets: the Difficulty of Learning Long-Term Dependencies. (2001).Google Scholar"",""Aaron Jaech and Mari Ostendorf. 2018. Personalized Language Model for Query Auto-Completion. (2018).Google Scholar"",""Jyun-Yu Jiang, Yen-Yu Ke, Pao-Yu Chien, and Pu-Jen Cheng. 2014. Learning User Reformulation Behavior for Query Auto-Completion. In SIGIR 2014.Google Scholar"",""Wang-Cheng Kang and Julian J. McAuley. 2018. Self-Attentive Sequential Recommendation. In Proceedings of ICDM 2018. 197--206.Google Scholar"",""Jiwei Li, Minh-Thang Luong, and Dan Jurafsky. 2015b. A Hierarchical Neural Autoencoder for Paragraphs and Documents. In Proceedings of ACL 2015.Google ScholarCross Ref"",""Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, and Jun Ma. 2017b. Neural Attentive Session-based Recommendation. In Proceedings of CIKM 2017.Google ScholarDigital Library"",""Liangda Li, Hongbo Deng, Jianhui Chen, and Yi Chang. 2017a. Learning Parametric Models for Context-Aware Query Auto-Completion via Hawkes Processes. In Proceedings of WSDM 2017. 131--139.Google ScholarDigital Library"",""Liangda Li, Hongbo Deng, Anlei Dong, Yi Chang, Hongyuan Zha, and Ricardo Baeza-Yates. 2015a. Analyzing User's Sequential Behavior in Query Auto-Completion via Markov Processes. In Proceedings of SIGIR 2015. ACM.Google ScholarDigital Library"",""Tie-Yan Liu. 2009. Learning to Rank for Information Retrieval. Foundations and Trends in Information Retrieval, Vol. 3, 3 (2009), 225--331.Google ScholarDigital Library"",""Bhaskar Mitra and Nick Craswell. 2015. Query Auto-Completion for Rare Prefixes. In Proceedings of CIKM 2015. 1755--1758.Google ScholarDigital Library"",""Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a Method for Automatic Evaluation of Machine Translation. In ACL 2002.Google Scholar"",""Dae Hoon Park and Rikio Chiba. 2017. A Neural Language Model for Query Auto-Completion. In Proceedings of SIGIR 2017.Google ScholarDigital Library"",""Iulian Vlad Serban, Alessandro Sordoni, Yoshua Bengio, Aaron C. Courville, and Joelle Pineau. 2016. Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models. In Proceedings of AAAI 2016. 3776--3784.Google Scholar"",""Milad Shokouhi. 2013. Learning to Personalize Query Auto-Completion. In Proceedings of SIGIR 2013. ACM.Google ScholarDigital Library"",""Milad Shokouhi and Kira Radinsky. 2012. Time-Sensitive Query Auto-Completion. In Proceedings of SIGIR 2012. ACM.Google ScholarDigital Library"",""Alessandro Sordoni, Yoshua Bengio, Hossein Vahabi, Christina Lioma, Jakob Grue Simonsen, and Jian-Yun Nie. 2015. A Hierarchical Recurrent Encoder-Decoder for Generative Context-Aware Query Suggestion. In CIKM 2015.Google ScholarDigital Library"",""Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014. Sequence to Sequence Learning with Neural Networks. In Proceedings of NIPS 2014. 3104--3112.Google ScholarDigital Library"",""Yong Kiam Tan, Xinxing Xu, and Yong Liu. 2016. Improved Recurrent Neural Networks for Session-based Recommendations. In [email protected] 2016. 17--22.Google Scholar"",""Trinh Xuan Tuan and Tu Minh Phuong. 2017. 3D Convolutional Networks for Session-based Recommendation with Content Features. In RecSys 2017.Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In Proceedings of NIPS 2017. 5998--6008.Google ScholarDigital Library"",""Pengfei Wang, Jiafeng Guo, Yanyan Lan, Jun Xu, Shengxian Wan, and Xueqi Cheng. 2015. Learning Hierarchical Representation Model for Next Basket Recommendation. In Proceedings of SIGIR 2015. 403--412.Google ScholarDigital Library"",""Xuanhui Wang, Nadav Golbandi, Michael Bendersky, Donald Metzler, and Marc Najork. 2018. Position Bias Estimation for Unbiased Learning to Rank in Personal Search. In Proceedings of WSDM 2018. 610--618.Google ScholarDigital Library"",""Yingfei Wang, Ouyang Hua, Hongbo Deng, and Chang Yi. 2017. Learning Online Trends for Interactive Query Auto-Completion. IEEE TKDE (2017).Google Scholar"",""Stewart Whiting and Joemon M. Jose. 2014. Recent and robust query auto-completion. In Proceedings of WWW 2014. 971--982.Google Scholar"",""Qiang Wu, Christopher J. C. Burges, Krysta Marie Svore, and Jianfeng Gao. 2010. Adapting boosting for information retrieval measures. IR (2010).Google Scholar"",""Shuai Zhang, Yi Tay, Lina Yao, and Aixin Sun. 2018. Next Item Recommendation with Self-Attention. CoRR, Vol. abs/1808.06414 (2018).Google Scholar"",""Yu Zhang and Qiang Yang. 2017. A Survey on Multi-Task Learning. CoRR, Vol. abs/1707.08114 (2017).Google Scholar"",""Guorui Zhou, Xiaoqiang Zhu, Chengru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep Interest Network for Click-Through Rate Prediction. In Proceedings of KDD 2018. 1059--1068.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403351,"A Sleeping, Recovering Bandit Algorithm for Optimizing Recurring Notifications","Many online and mobile applications rely on daily emails and push notifications to increase and maintain user engagement. The multi-armed bandit approach provides a useful framework for optimizing the content of these notifications, but a number of complications (such as novelty effects and conditional eligibility) make conventional bandit algorithms unsuitable in practice. In this paper, we introduce the Recovering Difference Softmax Algorithm to address the particular challenges of this problem domain, and use it to successfully optimize millions of daily reminders for the online language-learning app Duolingo. This lead to a 0.5%. increase in total daily active users (DAUs) and a 2%, increase in new user retention over a strong baseline. We provide technical details of its design and deployment, and demonstrate its efficacy through both offline and online evaluation experiments.","[{""name"":""Kevin P. Yancey"",""id"":""/profile/99659574087""},{""name"":""Burr Settles"",""id"":""/profile/99659574697""},{""name"":""Kevin P. Yancey"",""id"":""/profile/99659574087""},{""name"":""Burr Settles"",""id"":""/profile/99659574697""}]","[""Peter Auer. 2002. Using confidence bounds for exploitation-exploration trade-offs. Journal of Machine Learning Research, Vol. 3, Nov (2002), 397--422.Google ScholarDigital Library"",""Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer. 2002 a. Finite-time analysis of the multiarmed bandit problem. Machine learning, Vol. 47, 2--3 (2002), 235--256.Google Scholar"",""Peter Auer, Nicolo Cesa-Bianchi, Yoav Freund, and Robert E Schapire. 2002 b. The nonstochastic multiarmed bandit problem. SIAM journal on computing, Vol. 32, 1 (2002), 48--77.Google Scholar"",""Omar Besbes, Yonatan Gur, and Assaf Zeevi. 2014. Stochastic multi-armed-bandit problem with non-stationary rewards. In Advances in neural information processing systems. 199--207.Google Scholar"",""Wei Chu, Lihong Li, Lev Reyzin, and Robert Schapire. 2011. Contextual bandits with linear payoff functions. In Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics. 208--214.Google Scholar"",""Corinna Cortes, Giulia DeSalvo, Vitaly Kuznetsov, Mehryar Mohri, and Scott Yang. 2017. Discrepancy-based algorithms for non-stationary rested bandits. arXiv preprint arXiv:1710.10657 (2017).Google Scholar"",""Hermann Ebbinghaus. 1885. Memory: a contribution to experimental psychology. 1885. New York: Teachers College, Columbia University (1885).Google Scholar"",""Daniel G Horvitz and Donovan J Thompson. 1952. A generalization of sampling without replacement from a finite universe. Journal of the American statistical Association, Vol. 47, 260 (1952), 663--685.Google ScholarCross Ref"",""Leslie Kish. 1965. Survey Sampling.] ohn Wiley. New York (1965).Google Scholar"",""Robert Kleinberg, Alexandru Niculescu-Mizil, and Yogeshwer Sharma. 2010. Regret bounds for sleeping experts and bandits. Machine learning, Vol. 80, 2--3 (2010), 245--272.Google Scholar"",""Nir Levine, Koby Crammer, and Shie Mannor. 2017. Rotting bandits. In Advances in neural information processing systems. 3074--3083.Google Scholar"",""Ciara Pike-Burke and Steffen Grunewalder. 2019. Recovering Bandits. In Advances in Neural Information Processing Systems. 14122--14131.Google Scholar"",""Herbert Robbins. 1952. Some aspects of the sequential design of experiments. Bull. Amer. Math. Soc., Vol. 58, 5 (1952), 527--535.Google ScholarCross Ref"",""Burr Settles and Brendan Meeder. 2016. A trainable spaced repetition model for language learning. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. ACL, 1848--1858.Google ScholarCross Ref"",""Julien Seznec, Andrea Locatelli, Alexandra Carpentier, Alessandro Lazaric, and Michal Valko. 2018. Rotting bandits are no harder than stochastic ones. arXiv preprint arXiv:1811.11043 (2018).Google Scholar"",""Aleksandrs Slivkins et almbox. 2019. Introduction to multi-armed bandits. Foundations and Trends® in Machine Learning, Vol. 12, 1--2 (2019), 1--286.Google Scholar"",""Richard S Sutton and Andrew G Barto. 2018. Reinforcement learning: An introduction. MIT press.Google Scholar""]"
https://doi.org/10.1145/3394486.3403352,Multi-objective Optimization for Guaranteed Delivery in Video Service Platform,"Guaranteed-Delivery (GD) is one of the important display strategies for the IP videos in video service platform. Different from the traditional recommendation strategy, GD requires the delivery system to guarantee the exposure amount (also called impressions in some works) for the content, where the amount generally comes from the purchase contract or business consideration of the platform. In this paper, we study the problem of how to maximize certain gains, such as video view (VV) or fairness of different contents (CTR variations between contents) under the GD constraints. We formulate such a problem as a constrained nonlinear programming problem, in which the objectives are to maximize the total VVs of contents and the exposure fairness between contents. In order to capture the trends of VV versus the impression number (page views, PV) for each video content, we propose a parameterized ordinary differential equation (ODE) model, and the parameters of the ODE are fitted by the video historical PV and CLICK datas. To solve the constrained nonlinear programming, we use genetic algorithm (GA) with a specific design of coding scheme considering the ODE constraints. The empirical study based on real-world data and online test on Youku.com verifies the effectiveness and superiority of our approach compared with the state of the art in the industry practice.","[{""name"":""Hang Lei"",""id"":""/profile/99659573409""},{""name"":""Yin Zhao"",""id"":""/profile/99659573486""},{""name"":""Longjun Cai"",""id"":""/profile/99659572929""},{""name"":""Hang Lei"",""id"":""/profile/99659573409""},{""name"":""Yin Zhao"",""id"":""/profile/99659573486""},{""name"":""Longjun Cai"",""id"":""/profile/99659572929""}]","[""Vijay Bharadwaj, Peiji Chen, Wenjing Ma, Chandrashekhar Nagarajan, John Tomlin, Sergei Vassilvitskii, Erik Vee, and Jian Yang. 2012. SHALE: An Efficient Algorithm for Allocation of Guaranteed Display Advertising. CoRR abs/1203.3619 (2012). arXiv:1203.3619 http://arxiv.org/abs/1203.3619Google Scholar"",""Srinivas Bollapragada, Michael R. Bussieck, and Suman Mallik. 2004. Scheduling Commercial Videotapes in Broadcast Television. Operations Research 52, 5 (2004), 679--689. https://doi.org/10.1287/opre.1040.0119 arXiv:https://doi.org/10.1287/opre.1040.0119Google ScholarDigital Library"",""Srinivas Bollapragada, Hong Cheng, Mary Phillips, Marc Garbiras, Michael Scholes, Tim Gibbs, and Mark Humphreville. 2002. NBC's Optimization Systems Increase Revenues and Productivity. INFORMS Journal on Applied Analytics 32, 1 (2002), 47--60. https://doi.org/10.1287/inte.32.1.47.19 arXiv:https://pubsonline.informs.org/doi/pdf/10.1287/inte.32.1.47.19Google ScholarDigital Library"",""Srinivas Bollapragada and Marc Garbiras. 2004. Scheduling Commercials on Broadcast Television. Operations Research 52, 3 (2004), 337--345. https://doi.org/ 10.1287/opre.1030.0083 arXiv:https://doi.org/10.1287/opre.1030.0083Google ScholarDigital Library"",""Olivier Chapelle. 2014. Modeling Delayed Feedback in Display Advertising. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '14). ACM, New York, NY, USA, 1097--1105. https://doi.org/10.1145/2623330.2623634Google ScholarDigital Library"",""Olivier Chapelle. 2015. Offline Evaluation of Response Prediction in Online Advertising Auctions. In Proceedings of the 24th International Conference on World Wide Web (WWW '15 Companion). ACM, New York, NY, USA, 919--922. https: //doi.org/10.1145/2740908.2742566Google ScholarDigital Library"",""Olivier Chapelle, Eren Manavoglu, and Romer Rosales. 2015. Simple and Scalable Response Prediction for Display Advertising. ACM Trans. Intell. Syst. Technol. 5, 4, Article Article 61 (Dec. 2015), 34 pages. https://doi.org/10.1145/2532128Google ScholarDigital Library"",""David Maxwell Chickering and David Heckerman. 2003. Targeted Advertising on the Web with Inventory Management. INFORMS Journal on Applied Analytics 33, 5 (2003), 71--77. https://doi.org/10.1287/inte.33.5.71.19248 arXiv:https://pubsonline.informs.org/doi/pdf/10.1287/inte.33.5.71.19248Google ScholarDigital Library"",""Gila E. Fruchter and Shlomo Kalish. 1998. Dynamic promotional budgeting and media allocation. European Journal of Operational Research 111, 1 (1998), 15--27. https://doi.org/10.1016/S0377-2217(97)00315-9Google ScholarCross Ref"",""Kun Gai, Xiaoqiang Zhu, Han Li, Kai Liu, and Zhe Wang. 2017. Learning Piece-wise Linear Models from Large Scale Data for Ad Click Prediction. arXiv:stat.ML/1704.05194Google Scholar"",""Thore Graepel, Joaquin Quinonero Candela, Thomas Borchert, and Ralf Herbrich. 2010. Web-scale bayesian click-through rate prediction for sponsored search advertising in microsoft's bing search engine. Omnipress.Google Scholar"",""Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: A Factorization-Machine based Neural Network for CTR Prediction. arXiv:cs.IR/1703.04247Google Scholar"",""Ferenc Hartung, Tibor Krisztin, Hans-Otto Walther, and Jianhong Wu. 2006. Chapter 5 Functional Differential Equations with State-Dependent Delays: Theory and Applications. Handbook of Differential Equations: Ordinary Differential Equations, Vol. 3. North-Holland, 435--545. https://doi.org/10.1016/S1874-5725(06)80009-XGoogle ScholarCross Ref"",""Xinran He, Junfeng Pan, Ou Jin, Tianbing Xu, Bo Liu, Tao Xu, Yanxin Shi, Antoine Atallah, Ralf Herbrich, Stuart Bowers, and Joaquin Quiñonero Candela. 2014. Practical Lessons from Predicting Clicks on Ads at Facebook. In Proceedings of the Eighth International Workshop on Data Mining for Online Advertising (ADKDD'14). ACM, New York, NY, USA, Article 5, 9 pages. https://doi.org/10.1145/2648584. 2648589Google ScholarDigital Library"",""Alf Kimms and Michael Muller-Bungart. 2007. Revenue management for broadcasting commercials: the channel's problem of selecting and scheduling the advertisements to be aired. International Journal of Revenue Management 1, 1 (2007), 28--44. https://ideas.repec.org/a/ids/ijrevm/v1y2007i1p28-44.htmlGoogle ScholarCross Ref"",""Kuang-chih Lee, Burkay Orten, Ali Dasdan, and Wentong Li. 2012. Estimating Conversion Rate in Display Advertising from Past Erformance Data. In Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '12). ACM, New York, NY, USA, 768--776. https://doi.org/10.1145/2339530.2339651Google Scholar"",""Qiang Liu, Feng Yu, Shu Wu, and Liang Wang. 2015. A Convolutional Click Prediction Model. In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management (CIKM '15). ACM, New York, NY, USA, 1743--1746. https://doi.org/10.1145/2806416.2806603Google ScholarDigital Library"",""H Brendan McMahan. [n. d.]. Follow-the-Regularized-Leader and Mirror Descent: Equivalence Theorems and L1 Regularization. ([n. d.]).Google Scholar"",""A Mihiotis and I Tsakiris. 2004. A mathematical programming study of advertising allocation problem. Appl. Math. Comput. 148, 2 (2004), 373--379. https://doi. org/10.1016/S0096-3003(02)00853-6Google ScholarDigital Library"",""H. Mühlenbein, M. Gorges-Schleuter, and O. Krämer. 1988. Evolution algorithms in combinatorial optimization. Parallel Comput. 7, 1 (1988), 65--85. https: //doi.org/10.1016/0167-8191(88)90098-1Google ScholarCross Ref"",""Richard J. Oentaryo, Ee-Peng Lim, Jia-Wei Low, David Lo, and Michael Finegold. 2014. Predicting Response in Mobile Advertising with Hierarchical Importanceaware Factorization Machine. In Proceedings of the 7th ACM International Conference on Web Search and Data Mining (WSDM '14). ACM, New York, NY, USA, 123--132. https://doi.org/10.1145/2556195.2556240Google ScholarDigital Library"",""Paulo A. Pereira, Fernando A. C. C. Fontes, and Dalila B. M. M. Fontes. 2008. A Decision Support System for Planning Promotion Time Slots. In Operations Research Proceedings 2007, Jörg Kalcsics and Stefan Nickel (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 147--152.Google Scholar"",""Yanru Qu, Han Cai, Kan Ren, Weinan Zhang, Yong Yu, Ying Wen, and Jun Wang. 2016. Product-based Neural Networks for User Response Prediction. arXiv:cs.LG/1611.00144Google Scholar"",""Lili Shan, Lei Lin, Chengjie Sun, and Xiaolong Wang. 2016. Predicting ad clickthrough rates via feature-based fully coupled interaction tensor factorization. Electronic Commerce Research and Applications 16 (2016), 30--42. https://doi. org/10.1016/j.elerap.2016.01.004Google ScholarDigital Library"",""Nitasha Soni and Dr. Tribhuwan Kumar. 2014. Study of Various Crossover Operators in Genetic Algorithms.Google Scholar"",""A. Ta. 2015. Factorization machines with follow-the-regularized-leader for CTR prediction in display advertising. In 2015 IEEE International Conference on Big Data (Big Data). 2889--2891. https://doi.org/10.1109/BigData.2015.7364112Google ScholarDigital Library"",""John Turner. 2012. The Planning of Guaranteed Targeted Display Advertising. Operations Research 60, 1 (2012), 18--33. https://doi.org/10.1287/opre.1110.0996 arXiv:https://doi.org/10.1287/opre.1110.0996Google ScholarDigital Library"",""Flavian Vasile and Damien Lefortier. 2016. Cost-sensitive Learning for Bidding in Online Advertising Auctions. CoRR abs/1603.03713 (2016). arXiv:1603.03713 http://arxiv.org/abs/1603.03713Google Scholar"",""Xuerui Wang, Wei Li, Ying Cui, Ruofei Zhang, and Jianchang Mao. 2011. Clickthrough rate estimation for rare events in online advertising. In Online multimedia advertising: Techniques and technologies. IGI Global, 1--12.Google Scholar"",""Weinan Zhang, Tianming Du, and Jun Wang. 2016. Deep Learning over Multi-field Categorical Data: A Case Study on User Response Prediction. arXiv:cs.LG/1601.02376Google Scholar"",""Guorui Zhou, Chengru Song, Xiaoqiang Zhu, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2017. Deep Interest Network for Click-Through Rate Prediction. arXiv:stat.ML/1706.06978Google Scholar""]"
https://doi.org/10.1145/3394486.3403353,Delivery Scope: A New Way of Restaurant Retrieval for On-demand Food Delivery Service,"Recently on-demand food delivery service has become very popular in China. More than 30 million orders are placed by eaters of Meituan-Dianping everyday. Delicacies are delivered to eaters in 30 minutes on average. To fully leverage the ability of our couriers and restaurants, delivery scope is proposed as an infrastructure product for on-demand food delivery area. A delivery scope based retrieval system is designed and built on our platform. In order to draw suitable delivery scopes for millions of restaurant partners, we propose a pioneering delivery scope generation framework. In our framework, a single delivery scope generation algorithm is proposed by using spatial computational techniques and data mining techniques. Moreover, a scope scoring algorithm and decision algorithm are proposed by utilizing machine learning models and combinatorial optimization techniques. Specifically, we propose a novel delivery scope sample generation method and use the scope related features to estimate order numbers and average delivery time in a period of time for each delivery scope. Then we formalize the candidate scopes selection process as a binary integer programming problem. Both branch&bound algorithm and a heuristic search algorithm are integrated in our system. Results of online experiments show that scopes generated by our new algorithm significantly outperform manual generated ones. Our algorithm brings more orders without hurt of users' experience. After deployed online, our system has saved thousands of hours for operation staff, and it is considered to be one of the most useful operation tools to balance demand of eaters and supply of restaurants and couriers.","[{""name"":""Xuetao Ding"",""id"":""/profile/99659574868""},{""name"":""Runfeng Zhang"",""id"":""/profile/99659573876""},{""name"":""Zhen Mao"",""id"":""/profile/99659575169""},{""name"":""Ke Xing"",""id"":""/profile/99659573443""},{""name"":""Fangxiao Du"",""id"":""/profile/99659573563""},{""name"":""Xingyu Liu"",""id"":""/profile/99659574120""},{""name"":""Guoxing Wei"",""id"":""/profile/99659574961""},{""name"":""Feifan Yin"",""id"":""/profile/99659574022""},{""name"":""Renqing He"",""id"":""/profile/99659573134""},{""name"":""Zhizhao Sun"",""id"":""/profile/99659573567""},{""name"":""Xuetao Ding"",""id"":""/profile/99659574868""},{""name"":""Runfeng Zhang"",""id"":""/profile/99659573876""},{""name"":""Zhen Mao"",""id"":""/profile/99659575169""},{""name"":""Ke Xing"",""id"":""/profile/99659573443""},{""name"":""Fangxiao Du"",""id"":""/profile/99659573563""},{""name"":""Xingyu Liu"",""id"":""/profile/99659574120""},{""name"":""Guoxing Wei"",""id"":""/profile/99659574961""},{""name"":""Feifan Yin"",""id"":""/profile/99659574022""},{""name"":""Renqing He"",""id"":""/profile/99659573134""},{""name"":""Zhizhao Sun"",""id"":""/profile/99659573567""}]","[""Jie Bao, Yu Zheng, and Mohamed F Mokbel. 2012. Location-based and preference-aware recommendation using sparse geo-social networking data. In Proceedings of the 20th international conference on advances in geographic information systems. 199--208.Google ScholarDigital Library"",""Stephen Boyd and Lieven Vandenberghe. 2004. Convex optimization. Cambridge university press.Google Scholar"",""Stephen P Bradley, Arnoldo C Hax, and Thomas L Magnanti. 1977. Applied mathematical programming. (1977).Google Scholar"",""Tianqi Chen and Carlos Guestrin. 2016. Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining. 785--794.Google ScholarDigital Library"",""Jens Clausen. 1999. Branch and bound algorithms-principles and examples. Department of Computer Science, University of Copenhagen (1999), 1--30.Google Scholar"",""Matt Duckham, Lars Kulik, Mike Worboys, and Antony Galton. 2008. Efficient generation of simple polygons for characterizing the shape of a set of points in the plane. Pattern recognition, Vol. 41, 10 (2008), 3224--3236.Google Scholar"",""Martin Ester, Hans-Peter Kriegel, Jörg Sander, Xiaowei Xu, et almbox. 1996. A density-based algorithm for discovering clusters in large spatial databases with noise.. In Kdd, Vol. 96. 226--231.Google ScholarDigital Library"",""Ying Cha Feng Guo Jinghua Hao Renqing He and Zhizhao Sun Huanyu Zheng, Shengyao Wang. 2019. A Two-Stage Fast Heuristic for Food Delivery RoutePlanning Problem.Google Scholar"",""Scott Kirkpatrick, C Daniel Gelatt, and Mario P Vecchi. 1983. Optimization by simulated annealing. science, Vol. 220, 4598 (1983), 671--680.Google Scholar"",""Hendrik W Lenstra Jr. 1983. Integer programming with a fixed number of variables. Mathematics of operations research, Vol. 8, 4 (1983), 538--548.Google Scholar"",""Andy Liaw, Matthew Wiener, et almbox. 2002. Classification and regression by randomForest. R news, Vol. 2, 3 (2002), 18--22.Google Scholar"",""Shawn Mankad, Masha Shunko, and Qiuping Yu. 2019. How To Find Your Most Valuable Service Outlets: Measuring Influence Using Network Analysis. Available at SSRN 3366127 (2019).Google Scholar"",""Stuart J Russell and Peter Norvig. 2016. Artificial intelligence: a modern approach. Malaysia; Pearson Education Limited,.Google Scholar"",""Anders Skovsgaard and Christian S Jensen. 2014. Top-k point of interest retrieval using standard indexes. In Proceedings of the 22nd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems. 173--182.Google ScholarDigital Library"",""S-T Wu and MERCEDES ROCio GONZALES Marquez. 2003. A non-self-intersection Douglas-Peucker algorithm. In 16th Brazilian symposium on computer graphics and Image Processing (SIBGRAPI 2003). IEEE, 60--66.Google ScholarCross Ref"",""Min Xie, Hongzhi Yin, Hao Wang, Fanjiang Xu, Weitong Chen, and Sen Wang. 2016. Learning graph-based poi embedding for location-based recommendation. In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management. 15--24.Google ScholarDigital Library"",""Baris Yildiz and Martin Savelsbergh. 2019. Service and capacity planning in crowd-sourced delivery. Transportation Research Part C: Emerging Technologies, Vol. 100 (2019), 177--199.Google ScholarCross Ref"",""Shenglin Zhao, Tong Zhao, Haiqin Yang, Michael R Lyu, and Irwin King. 2016. STELLAR: spatial-temporal latent ranking for successive point-of-interest recommendation. In Thirtieth AAAI conference on artificial intelligence.Google Scholar"",""Fan Zhou, Ruiyang Yin, Kunpeng Zhang, Goce Trajcevski, Ting Zhong, and Jin Wu. 2019. Adversarial point-of-interest recommendation. In The World Wide Web Conference. 3462--34618.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403354,Fraud Transactions Detection via Behavior Tree with Local Intention Calibration,"Fraud transactions obtain the rights and interests of e-commerce platforms by illegal ways, and have been the emerging threats to the healthy development of these platforms. Recently, user behavioral data is extensively exploited to detect fraud transactions, and it is usually processed as a sequence consisting of individual actions. However, such sequence-like user behaviors have logical patterns associated with user intentions, which motivates a fine-grained management strategy that binds and cuts off these actions into intention-related segments. In this paper, we devise a tree-like structure named behavior tree to reorganize the user behavioral data, in which a group of successive sequential actions denoting a specific user intention are represented as a branch on the tree. We then propose a novel neural method coined LIC Tree-LSTM(Local Intention Calibrated Tree-LSTM) to utilize the behavior tree for fraud transactions detection. In our LIC Tree-LSTM, the global user intention is captured by an attentional method applied on different branches. Then, we calibrate the entire tree by attentions within tree branches to pinpoint the balance between global and local user intentions. We investigate the effectiveness of LIC Tree-LSTM on a real-world dataset of Alibaba platform, and the experimental results show that our proposed algorithm outperforms state-of-the-art methods in both offline and online modes. Furthermore, our model provides good interpretability which helps us better understand user behaviors.","[{""name"":""Can Liu"",""id"":""/profile/99659574629""},{""name"":""Qiwei Zhong"",""id"":""/profile/99659537547""},{""name"":""Xiang Ao"",""id"":""/profile/86158977757""},{""name"":""Li Sun"",""id"":""/profile/99659573428""},{""name"":""Wangli Lin"",""id"":""/profile/99659574367""},{""name"":""Jinghua Feng"",""id"":""/profile/99659537883""},{""name"":""Qing He"",""id"":""/profile/81320490313""},{""name"":""Jiayu Tang"",""id"":""/profile/99659536492""},{""name"":""Can Liu"",""id"":""/profile/99659574629""},{""name"":""Qiwei Zhong"",""id"":""/profile/99659537547""},{""name"":""Xiang Ao"",""id"":""/profile/86158977757""},{""name"":""Li Sun"",""id"":""/profile/99659573428""},{""name"":""Wangli Lin"",""id"":""/profile/99659574367""},{""name"":""Jinghua Feng"",""id"":""/profile/99659537883""},{""name"":""Qing He"",""id"":""/profile/81320490313""},{""name"":""Jiayu Tang"",""id"":""/profile/99659536492""}]","[""Mahtab Ahmed, Muhammad Rifayat Samee, and Robert E Mercer. 2019. Improving Tree-LSTM with tree attention. In ICSC.Google Scholar"",""Xiang Ao, Ping Luo, Chengkai Li, Fuzhen Zhuang, and Qing He. 2015. Online frequent episode mining. In ICDE. 891--902.Google Scholar"",""Xiang Ao, Ping Luo, Jin Wang, Fuzhen Zhuang, and Qing He. 2017. Mining precise-positioning episode rules from event sequences. IEEE TKDE 30, 3 (2017), 530--543.Google Scholar"",""Siddhartha Bhattacharyya, Sanjeev Jha, Kurian Tharakunnel, and J Christopher Westland. 2011. Data mining for credit card fraud: A comparative study. Decision Support Systems 50, 3 (2011), 602--613.Google ScholarDigital Library"",""Junyoung Chung, Caglar Gulcehre, Kyunghyun Cho, and Yoshua Bengio. 2014. Empirical evaluation of gated recurrent neural networks on sequence modeling. In NIPS.Google Scholar"",""Akiko Eriguchi, Kazuma Hashimoto, and Yoshimasa Tsuruoka. 2016. Tree-tosequence attentional neural machine translation. In ACL.Google Scholar"",""Kang Fu, Dawei Cheng, Yi Tu, and Liqing Zhang. 2016. Credit card fraud detection using convolutional neural networks. In ICONIP.Google Scholar"",""Qingyu Guo, Zhao Li, Bo An, Pengrui Hui, Jiaming Huang, Long Zhang, and Mengchen Zhao. 2019. Securing the deep fraud detector in large-scale ecommerce platform via adversarial machine learning approach. In WWW.Google Scholar"",""Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural Computation 9, 8 (1997), 1735--1780.Google ScholarDigital Library"",""Johannes Jurgovsky, Michael Granitzer, Konstantin Ziegler, Sylvie Calabretto, Pierre-Edouard Portier, Liyun He-Guelton, and Olivier Caelen. 2018. Sequence classification for credit-card fraud detection. Expert Systems with Applications 100 (2018), 234--245.Google ScholarCross Ref"",""Yoon Kim. 2014. Convolutional neural networks for sentence classification. In EMNLP.Google Scholar"",""Diederik P. Kingma and Jimmy Ba. 2015. Adam: A method for stochastic optimization. In ICLR.Google Scholar"",""Renxin Mao, Zhao Li, and Jinhua Fu. 2015. Fraud transaction recognition: A money flow network approach. In CIKM.Google Scholar"",""Makoto Miwa and Mohit Bansal. 2016. End-to-end relation extraction using lstms on sequences and tree structures. In ACL.Google Scholar"",""Lili Mou, Rui Men, Ge Li, Yan Xu, Lu Zhang, Rui Yan, and Zhi Jin. 2015. Natural language inference by tree-based convolution and heuristic matching. In ACL.Google Scholar"",""Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. 2019. PyTorch: An imperative style, high-performance deep learning library. In NeurIPS.Google Scholar"",""Jon TS Quah and M Sriganesh. 2008. Real-time credit card fraud detection using computational intelligence. Expert systems with applications 35, 4 (2008), 1721--1732.Google Scholar"",""Mike Schuster and Kuldip K Paliwal. 1997. Bidirectional recurrent neural networks. IEEE Transactions on Signal Processing 45, 11 (1997), 2673--2681.Google ScholarDigital Library"",""Ning Su, Yiqun Liu, Zhao Li, Yuli Liu, Min Zhang, and Shaoping Ma. 2018. Detecting crowdturfing add to favorites activities in online shopping. In WWW.Google Scholar"",""Kai Sheng Tai, Richard Socher, and Christopher D Manning. 2015. Improved semantic representations from tree-structured long short-term memory networks. In ACL.Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In NIPS.Google Scholar"",""Haiqin Weng, Zhao Li, Shouling Ji, Chen Chu, Haifeng Lu, Tianyu Du, and Qinming He. 2018. Online e-commerce fraud: a large-scale detection and analysis. In ICDE.Google Scholar"",""Dianmin Yue, Xiaodan Wu, Yunfeng Wang, Yue Li, and Chao-Hsien Chu. 2007. A review of data mining-based financial fraud detection research. In IWCMC.Google Scholar"",""Ashkan Zakaryazad and Ekrem Duman. 2016. A profit-driven Artificial Neural Network (ANN) with applications to fraud detection and direct marketing. Neurocomputing 175 (2016), 121--131.Google ScholarDigital Library"",""Mengchen Zhao, Zhao Li, Bo An, Haifeng Lu, Yifan Yang, and Chen Chu. 2018. Impression allocation for combating fraud in e-commerce via deep reinforcement learning with action norm penalty. In IJCAI.Google Scholar"",""Panpan Zheng, Shuhan Yuan, and Xintao Wu. 2019. Safe: A neural survival analysis model for fraud early detection. In AAAI.Google Scholar"",""Panpan Zheng, Shuhan Yuan, XintaoWu, Jun Li, and Aidong Lu. 2019. One-class adversarial nets for fraud detection. In AAAI.Google Scholar"",""Qiwei Zhong, Yang Liu, Xiang Ao, Binbin Hu, Jinghua Feng, Jiayu Tang, and Qing He. 2020. Financial Defaulter Detection on Online Credit Payment via Multi-view Attributed Heterogeneous Information Network. In WWW. 785--795.Google Scholar""]"
https://doi.org/10.1145/3394486.3403355,Balanced Order Batching with Task-Oriented Graph Clustering,"Balanced order batching problem (BOBP) arises from the process of warehouse picking in Cainiao, the largest logistics platform in China. Batching orders together in the picking process to form a single picking route, reduces travel distance. The reason for its importance is that order picking is a labor intensive process and, by using good batching methods, substantial savings can be obtained. The BOBP is a NP-hard combinational optimization problem and designing a good problem-specific heuristic under the quasi-real-time system response requirement is non-trivial. In this paper, rather than designing heuristics, we propose an end-to-end learning and optimization framework named Balanced Task-orientated Graph Clustering Network (BTOGCN) to solve the BOBP by reducing it to balanced graph clustering optimization problem. In BTOGCN, a task-oriented estimator network is introduced to guide the type-aware heterogeneous graph clustering networks to find a better clustering result related to the BOBP objective. Through comprehensive experiments on single-graph and multi-graphs, we show: 1) our balanced task-oriented graph clustering network can directly utilize the guidance of target signal and outperforms the two-stage deep embedding and deep clustering method; 2) our method obtains an average 4.57m and 0.13m picking distance reduction than the expert-designed algorithm on single and multi-graph set and has a good generalization ability to apply in practical scenario.","[{""name"":""Lu Duan"",""id"":""/profile/99659370786""},{""name"":""Haoyuan Hu"",""id"":""/profile/99659368546""},{""name"":""Zili Wu"",""id"":""/profile/99659370469""},{""name"":""Guozheng Li"",""id"":""/profile/99659574001""},{""name"":""Xinhang Zhang"",""id"":""/profile/99659574739""},{""name"":""Yu Gong"",""id"":""/profile/99659190195""},{""name"":""Yinghui Xu"",""id"":""/profile/99659190259""},{""name"":""Lu Duan"",""id"":""/profile/99659370786""},{""name"":""Haoyuan Hu"",""id"":""/profile/99659368546""},{""name"":""Zili Wu"",""id"":""/profile/99659370469""},{""name"":""Guozheng Li"",""id"":""/profile/99659574001""},{""name"":""Xinhang Zhang"",""id"":""/profile/99659574739""},{""name"":""Yu Gong"",""id"":""/profile/99659190195""},{""name"":""Yinghui Xu"",""id"":""/profile/99659190259""}]","[""Ashwin Bahulkar, Boleslaw K Szymanski, N Orkun Baycik, and Thomas C Sharkey. 2018. Community detection with edge augmentation in criminal networks. In 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM). IEEE, 1168--1175.Google ScholarCross Ref"",""Irwan Bello, Hieu Pham, Quoc V Le, Mohammad Norouzi, and Samy Bengio. 2016. Neural combinatorial optimization with reinforcement learning. arXiv preprint arXiv:1611.09940 (2016).Google Scholar"",""Yoshua Bengio. 1997. Using a financial training criterion rather than a prediction criterion. International Journal of Neural Systems, Vol. 8, 04 (1997), 433--443.Google ScholarCross Ref"",""Giulia Berlusconi, Francesco Calderoni, Nicola Parolini, Marco Verani, and Carlo Piccardi. 2016. Link prediction in criminal networks: A tool for criminal intelligence analysis. PloS one, Vol. 11, 4 (2016).Google Scholar"",""Matthew Burgess, Eytan Adar, and Michael Cafarella. 2016. Link-prediction enhanced consensus clustering for complex networks. PloS one, Vol. 11, 5 (2016).Google Scholar"",""Sandro Cavallari, Vincent W Zheng, Hongyun Cai, Kevin Chen-Chuan Chang, and Erik Cambria. 2017. Learning community embedding with community detection and node embedding on graphs. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management. 377--386.Google ScholarDigital Library"",""Di Chen, Yada Zhu, Xiaodong Cui, and Carla P Gomes. 2019. Task-Based Learning via Task-Oriented Prediction Network. arXiv preprint arXiv:1910.09357 (2019).Google Scholar"",""Priya Donti, Brandon Amos, and J Zico Kolter. 2017. Task-based end-to-end model learning in stochastic optimization. In Advances in Neural Information Processing Systems. 5484--5494.Google Scholar"",""Adam N Elmachtoub and Paul Grigas. 2017. Smart\"" predict, then optimize\"". arXiv preprint arXiv:1710.08005 (2017).Google Scholar"",""Aaron Ferber, Bryan Wilder, Bistra Dilina, and Milind Tambe. 2019. MIPaaL: Mixed integer program as a layer. arXiv preprint arXiv:1907.05912 (2019).Google Scholar"",""Edward Frazelle and Ed Frazelle. 2002. World-class warehousing and material handling. Vol. 1. McGraw-Hill New York.Google Scholar"",""Noud Gademann and Steef Velde. 2005. Order batching to minimize total travel time in a parallel-aisle warehouse. IIE transactions, Vol. 37, 1 (2005), 63--75.Google Scholar"",""Boyan Gao, Yongxin Yang, Henry Gouk, and Timothy M Hospedales. 2019. Deep clustering with concrete k-means. arXiv preprint arXiv:1910.08031 (2019).Google Scholar"",""Aude Genevay, Gabriel Dulac-Arnold, and Jean-Philippe Vert. 2019. Differentiable Deep Clustering with Cluster Size Constraints. arXiv preprint arXiv:1910.09036 (2019).Google Scholar"",""Google. 2019. OR-Tools. https://developers.google.com/optimizationGoogle Scholar"",""Xifeng Guo, Long Gao, Xinwang Liu, and Jianping Yin. 2017. Improved deep embedded clustering with local structure preservation.. In IJCAI. 1753--1759.Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In Advances in neural information processing systems. 1024--1034.Google Scholar"",""Sebastian Henn, Sören Koch, Karl F Doerner, Christine Strauss, and Gerhard Wäscher. 2010. Metaheuristics for the order batching problem in manual order picking systems. Business Research, Vol. 3, 1 (2010), 82--105.Google ScholarCross Ref"",""Geoffrey E Hinton, Simon Osindero, and Yee-Whye Teh. 2006. A fast learning algorithm for deep belief nets. Neural computation, Vol. 18, 7 (2006), 1527--1554.Google Scholar"",""Ying-Chin Ho, Teng-Sheng Su, and Zhi-Bin Shi. 2008. Order-batching methods for an order-picking warehouse with two cross aisles. Computers \u0026 Industrial Engineering, Vol. 55, 2 (2008), 321--347.Google ScholarDigital Library"",""Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirectional LSTM-CRF models for sequence tagging. arXiv preprint arXiv:1508.01991 (2015).Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).Google Scholar"",""Wouter Kool, Herke Van Hoof, and Max Welling. 2018. Attention, learn to solve routing problems! arXiv preprint arXiv:1803.08475 (2018).Google Scholar"",""Timothy P Lillicrap, Jonathan J Hunt, Alexander Pritzel, Nicolas Heess, Tom Erez, Yuval Tassa, David Silver, and Daan Wierstra. 2015. Continuous control with deep reinforcement learning. arXiv preprint arXiv:1509.02971 (2015).Google Scholar"",""Ziqi Liu, Chaochao Chen, Xinxing Yang, Jun Zhou, Xiaolong Li, and Le Song. 2018. Heterogeneous graph neural networks for malicious account detection. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management. 2077--2085.Google ScholarDigital Library"",""Mikko I Malinen and Pasi Fr\""anti. 2014. Balanced k-means for clustering. In Joint IAPR International Workshops on Statistical Techniques in Pattern Recognition (SPR) and Structural and Syntactic Pattern Recognition (SSPR). Springer, 32--41.Google ScholarDigital Library"",""Vinod Nair and Geoffrey E Hinton. 2010. Rectified linear units improve restricted boltzmann machines. In Proceedings of the 27th international conference on machine learning (ICML-10). 807--814.Google ScholarDigital Library"",""Luis Perez and Jason Wang. 2017. The effectiveness of data augmentation in image classification using deep learning. arXiv preprint arXiv:1712.04621 (2017).Google Scholar"",""Andrew Perrault, Bryan Wilder, Eric Ewing, Aditya Mate, Bistra Dilkina, and Milind Tambe. 2019. Decision-focused learning of adversary behavior in security games. arXiv preprint arXiv:1903.00958 (2019).Google Scholar"",""Ted K Ralphs, Leonid Kopman, William R Pulleyblank, and Leslie E Trotter. 2003. On the capacitated vehicle routing problem. Mathematical programming, Vol. 94, 2--3 (2003), 343--359.Google Scholar"",""Benedek Rozemberczki, Ryan Davies, Rik Sarkar, and Charles Sutton. 2019. Gemsec: Graph embedding with self clustering. In Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining. 65--72.Google ScholarDigital Library"",""Chao Shang, Qinqing Liu, Ko-Shin Chen, Jiangwen Sun, Jin Lu, Jinfeng Yi, and Jinbo Bi. 2018. Edge attention-based multi-relational graph convolutional networks. arXiv preprint arXiv:1802.04944 (2018).Google Scholar"",""Suo-Yi Tan, Jun Wu, Linyuan Lü, Meng-Jun Li, and Xin Lu. 2016. Efficient network disintegration under incomplete information: the comic effect of link prediction. Scientific reports, Vol. 6, 1 (2016), 1--9.Google Scholar"",""James A Tompkins, John A White, Yavuz A Bozer, and Jose Mario Aza na Tanchoco. 2010. Facilities planning. John Wiley \u0026 Sons.Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998--6008.Google Scholar"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph attention networks. arXiv preprint arXiv:1710.10903 (2017).Google Scholar"",""Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. 2015. Pointer networks. In Advances in neural information processing systems. 2692--2700.Google Scholar"",""Jizhe Wang, Pipei Huang, Huan Zhao, Zhibo Zhang, Binqiang Zhao, and Dik Lun Lee. 2018. Billion-scale commodity embedding for e-commerce recommendation in alibaba. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 839--848.Google ScholarDigital Library"",""Bryan Wilder, Bistra Dilkina, and Milind Tambe. 2019 a. Melding the data-decisions pipeline: Decision-focused learning for combinatorial optimization. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 1658--1665.Google ScholarCross Ref"",""Bryan Wilder, Eric Ewing, Bistra Dilkina, and Milind Tambe. 2019 b. End to end learning and optimization on graphs. In Advances in Neural Information Processing Systems. 4674--4685.Google Scholar"",""Junyuan Xie, Ross Girshick, and Ali Farhadi. 2016. Unsupervised deep embedding for clustering analysis. In International conference on machine learning. 478--487.Google ScholarDigital Library"",""Bowen Yan and Steve Gregory. 2012. Detecting community structure in networks using edge prediction methods. Journal of Statistical Mechanics: Theory and Experiment, Vol. 2012, 09 (2012), P09008.Google ScholarCross Ref"",""Bo Yang, Xiao Fu, Nicholas D Sidiropoulos, and Mingyi Hong. 2017. Towards k-means-friendly spaces: Simultaneous deep learning and clustering. In Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 3861--3870.Google Scholar"",""Hongjing Zhang, Sugato Basu, and Ian Davidson. 2019. A Framework for Deep Constrained Clustering-Algorithms and Advances. arXiv preprint arXiv:1901.10061 (2019).Google Scholar"",""Shichao Zhu, Chuan Zhou, Shirui Pan, Xingquan Zhu, and Bin Wang. 2019. Relation Structure-Aware Heterogeneous Graph Neural Network. In 2019 IEEE International Conference on Data Mining (ICDM). IEEE, 1534--1539.Google Scholar""]"
https://doi.org/10.1145/3394486.3403356,Efficiently Solving the Practical Vehicle Routing Problem: A Novel Joint Learning Approach,"Our model is based on the graph convolutional network (GCN) with node feature (coordination and demand) and edge feature (the real distance between nodes) as input and embedded. Separate decoders are proposed to decode the representations of these two features. The output of one decoder is the supervision of the other decoder. We propose a strategy that combines the reinforcement learning manner with the supervised learning manner to train the model. Through comprehensive experiments on real-world data, we show that 1) the edge feature is important to be explicitly considered in the model; 2) the joint learning strategy can accelerate the convergence of the training and improve the solution quality; 3) our model significantly outperforms several well-known algorithms in the literature, especially when the problem size is large; 3) our method is generalized beyond the size of problem instances they were trained on.","[{""name"":""Lu Duan"",""id"":""/profile/99659370786""},{""name"":""Yang Zhan"",""id"":""/profile/99659573754""},{""name"":""Haoyuan Hu"",""id"":""/profile/99659368546""},{""name"":""Yu Gong"",""id"":""/profile/99659190195""},{""name"":""Jiangwen Wei"",""id"":""/profile/99659368420""},{""name"":""Xiaodong Zhang"",""id"":""/profile/99659371354""},{""name"":""Yinghui Xu"",""id"":""/profile/99659190259""},{""name"":""Lu Duan"",""id"":""/profile/99659370786""},{""name"":""Yang Zhan"",""id"":""/profile/99659573754""},{""name"":""Haoyuan Hu"",""id"":""/profile/99659368546""},{""name"":""Yu Gong"",""id"":""/profile/99659190195""},{""name"":""Jiangwen Wei"",""id"":""/profile/99659368420""},{""name"":""Xiaodong Zhang"",""id"":""/profile/99659371354""},{""name"":""Yinghui Xu"",""id"":""/profile/99659190259""}]","[""Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. 2016. Layer normalization. arXiv preprint arXiv:1607.06450 (2016).Google Scholar"",""Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473 (2014).Google Scholar"",""Irwan Bello, Hieu Pham, Quoc V. Le, Mohammad Norouzi, and Samy Bengio. 2016. Neural combinatorial optimization with reinforcement learning. arXiv preprint arXiv:1611.09940 (2016).Google Scholar"",""Kyunghyun Cho, Bart Van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078 (2014).Google Scholar"",""Hanjun Dai, Bo Dai, and Le Song. 2016. Discriminative embeddings of latent variable models for structured data. In International Conference on Machine Learning. 2702--2711.Google ScholarDigital Library"",""Michel Deudon, Pierre Cournut, Alexandre Lacoste, Yossiri Adulyasak, and Louis-Martin Rousseau. 2018. Learning heuristics for the tsp by policy gradient. In International Conference on the Integration of Constraint Programming, Artificial Intelligence, and Operations Research. Springer, 170--181.Google ScholarCross Ref"",""Ricardo Fukasawa, Humberto Longo, Jens Lysgaard, Marcus Poggi de Arag ao, Marcelo Reis, Eduardo Uchoa, and Renato F Werneck. 2006. Robust branch-and-cut-and-price for the capacitated vehicle routing problem. Mathematical Programming, Vol. 106, 3 (2006), 491--511.Google ScholarCross Ref"",""Bezalel Gavish and Stephen C. Graves. 1978. The travelling salesman problem and related problems. (1978).Google Scholar"",""Bruce L. Golden, Subramanian Raghavan, and Edward A. Wasil. 2008. The vehicle routing problem: latest advances and new challenges. Vol. 43. Springer Science \u0026 Business Media.Google Scholar"",""Google. 2019. OR-Tools . https://developers.google.com/optimizationGoogle Scholar"",""Gurobi Optimization, LLC. 2019. Gurobi Optimizer Reference Manual. http://www.gurobi.comGoogle Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In Advances in Neural Information Processing Systems. 1024--1034.Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 770--778.Google ScholarCross Ref"",""Keld Helsgaun. 2017. An extension of the Lin-Kernighan-Helsgaun TSP solver for constrained traveling salesman and vehicle routing problems. Roskilde: Roskilde University (2017).Google Scholar"",""Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural computation, Vol. 9, 8 (1997), 1735--1780.Google Scholar"",""JQ James, Wen Yu, and Jiatao Gu. 2019. Online vehicle routing with neural combinatorial optimization and deep reinforcement learning. IEEE Transactions on Intelligent Transportation Systems, Vol. 20, 10 (2019), 3806--3817.Google ScholarCross Ref"",""Chaitanya K Joshi, Thomas Laurent, and Xavier Bresson. 2019. An efficient graph convolutional network technique for the travelling salesman problem. arXiv preprint arXiv:1906.01227 (2019).Google Scholar"",""Yoav Kaempfer and Lior Wolf. 2018. Learning the multiple traveling salesmen problem with permutation invariant pooling networks. arXiv preprint arXiv:1803.09621 (2018).Google Scholar"",""Elias Khalil, Hanjun Dai, Yuyu Zhang, Bistra Dilkina, and Le Song. 2017. Learning combinatorial optimization algorithms over graphs. In Advances in Neural Information Processing Systems. 6348--6358.Google Scholar"",""Vijay R Konda and John N Tsitsiklis. 2000. Actor-critic algorithms. In Advances in Neural Information Processing Systems. 1008--1014.Google Scholar"",""Wouter Kool, Herke van Hoof, and Max Welling. 2019. Attention, learn to solve routing problems! In International Conference on Learning Representations (2019).Google Scholar"",""Gilbert Laporte. 1992. The vehicle routing problem: An overview of exact and approximate algorithms. European Journal of Operational Research, Vol. 59, 3 (1992), 345--358.Google ScholarCross Ref"",""Gilbert Laporte, Michel Gendreau, J-Y Potvin, and Frédéric Semet. 2000. Classical and modern heuristics for the vehicle routing problem. International Transactions in Operational Research, Vol. 7, 4--5 (2000), 285--300.Google ScholarCross Ref"",""Humberto Longo, Marcus Poggi De Aragao, and Eduardo Uchoa. 2006. Solving capacitated arc routing problems using a transformation to the CVRP. Computers \u0026 Operations Research, Vol. 33, 6 (2006), 1823--1837.Google ScholarDigital Library"",""Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin Riedmiller. 2013. Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602 (2013).Google Scholar"",""Mohammadreza Nazari, Afshin Oroojlooy, Lawrence Snyder, and Martin Takác. 2018. Reinforcement learning for solving the vehicle routing problem. In Advances in Neural Information Processing Systems. 9839--9849.Google Scholar"",""Alex Nowak, Soledad Villar, Afonso S Bandeira, and Joan Bruna. 2017. A note on learning algorithms for quadratic assignment with graph neural networks. Stat, Vol. 1050 (2017), 22.Google Scholar"",""Ted K Ralphs, Leonid Kopman, William R Pulleyblank, and Leslie E Trotter. 2003. On the capacitated vehicle routing problem. Mathematical Programming, Vol. 94, 2--3 (2003), 343--359.Google ScholarCross Ref"",""Richard S Sutton and Andrew G Barto. 2018. Reinforcement learning: An introduction .MIT press.Google Scholar"",""Paolo Toth and Daniele Vigo. 2002. The vehicle routing problem .SIAM.Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems. 5998--6008.Google Scholar"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph attention networks. arXiv preprint arXiv:1710.10903 (2017).Google Scholar"",""Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. 2015. Pointer networks. In Advances in neural information processing systems. 2692--2700.Google Scholar"",""Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et almbox. 2016. Google's neural machine translation system: Bridging the gap between human and machine translation. arXiv preprint arXiv:1609.08144 (2016).Google Scholar"",""Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2018a. How powerful are graph neural networks? arXiv preprint arXiv:1810.00826 (2018).Google Scholar"",""Keyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi, and Stefanie Jegelka. 2018b. Representation learning on graphs with jumping knowledge networks. arXiv preprint arXiv:1806.03536 (2018).Google Scholar""]"
https://doi.org/10.1145/3394486.3403357,Meta-Learning for Query Conceptualization at Web Scale,"Concepts naturally constitute an abstraction for fine-grained entities and knowledge in the open domain. They enable search engines and recommendation systems to enhance user experience by discovering high-level abstraction of a search query and the user intent behind it. In this paper, we study the problem of query conceptualization, which is to find the most appropriate matching concepts for any given search query from a large pool of pre-defined concepts. We propose a coarse-to-fine approach to first reduce the search space for each query through a shortlisting scheme and then identify the matching concepts using pre-trained language models, which are meta-tuned to our query-concept matching task. Our shortlisting scheme involves using a GRU-based Relevant Words Generator (RWG) to first expand and complete the context of the given query and then shortlisting the candidate concepts through a scoring mechanism based on word overlaps. To accurately identify the most appropriate matching concepts for a query, even when the concepts may have zero verbatim overlaps with the query, we meta-fine-tune a BERT pairwise text-matching model under the Reptile meta-learning algorithm, which achieves zero-shot transfer learning on the conceptualization problem. Our two-stage framework can be trained with data completely derived from a search click graph, without requiring any human labelling efforts. For evaluation, we have constructed a large click graph based on more than $7$ million instances of the click history recorded in Tencent QQ browser and performed the query conceptualization task based on a large ontology with $159,148$ unique concepts. Results from a range of evaluation methods, including an offline evaluation procedure on the click graph, human evaluation, online A/B testing and case studies, have demonstrated the superiority of our approach over a number of competitive pre-trained language models and fine-tuned neural network baselines.","[{""name"":""Fred X. Han"",""id"":""/profile/99659260158""},{""name"":""Di Niu"",""id"":""/profile/87658907857""},{""name"":""Haolan Chen"",""id"":""/profile/99659082515""},{""name"":""Weidong Guo"",""id"":""/profile/99659370730""},{""name"":""Shengli Yan"",""id"":""/profile/99659574904""},{""name"":""Bowei Long"",""id"":""/profile/99659574660""},{""name"":""Fred X. Han"",""id"":""/profile/99659260158""},{""name"":""Di Niu"",""id"":""/profile/87658907857""},{""name"":""Haolan Chen"",""id"":""/profile/99659082515""},{""name"":""Weidong Guo"",""id"":""/profile/99659370730""},{""name"":""Shengli Yan"",""id"":""/profile/99659574904""},{""name"":""Bowei Long"",""id"":""/profile/99659574660""}]","[""Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W Hoffman, David Pfau, Tom Schaul, Brendan Shillingford, and Nando De Freitas. 2016. Learning to learn by gradient descent by gradient descent. In Advances in neural information processing systems. 3981--3989.Google Scholar"",""Ioannis Antonellis, Hector Garcia Molina, and Chi Chao Chang. 2008. Simrank : query rewriting through link analysis of the click graph. Proceedings of the VLDB Endowment, Vol. 1, 1 (2008), 408--421.Google ScholarDigital Library"",""Sören Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary Ives. 2007. Dbpedia: A nucleus for a web of open data. In The semantic web. Springer, 722--735.Google ScholarDigital Library"",""Samy Bengio, Yoshua Bengio, Jocelyn Cloutier, and Jan Gecsei. 1992. On the optimization of a synaptic learning rule. In Preprints Conf. Optimality in Artificial and Biological Neural Networks. Univ. of Texas, 6--8.Google Scholar"",""Wanxiang Che, Yijia Liu, Yuxuan Wang, Bo Zheng, and Ting Liu. 2018. Towards Better UD Parsing: Deep Contextualized Word Embeddings, Ensemble, and Treebank Concatenation. In Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics, Brussels, Belgium, 55--64.Google Scholar"",""Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. 2014. Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555 (2014).Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).Google Scholar"",""Murhaf Fares, Andrey Kutuzov, Stephan Oepen, and Erik Velldal. 2017. Word vectors, reuse, and replicability: Towards a community repository of large-text resources. In Proceedings of the 21st Nordic Conference on Computational Linguistics. Association for Computational Linguistics, Gothenburg, Sweden, 271--276.Google Scholar"",""Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017. Model-agnostic meta-learning for fast adaptation of deep networks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 1126--1135.Google ScholarDigital Library"",""Bruno M Fonseca, Paulo Golgher, Bruno Pôssas, Berthier Ribeiro-Neto, and Nivio Ziviani. 2005. Concept-based interactive query expansion. In Proceedings of the 14th ACM international conference on Information and knowledge management. ACM, 696--703.Google ScholarDigital Library"",""Jianfeng Gao, Xiaodong He, Shasha Xie, and Alnur Ali. 2012. Learning lexicon models from search logs for query expansion. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. 666--676.Google ScholarDigital Library"",""Jianfeng Gao and Jian-Yun Nie. 2012. Towards concept-based translation models using search logs for query expansion. In Proceedings of the 21st ACM international conference on Information and knowledge management. ACM, 1.Google ScholarDigital Library"",""Fred X Han, Di Niu, Haolan Chen, Kunfeng Lai, Yancheng He, and Yu Xu. 2019 a. A deep generative approach to search extrapolation and recommendation. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM.Google ScholarDigital Library"",""Fred X. Han, Di Niu, Weidong Guo, Kunfeng Lai, Yancheng He, and Yu Xu. 2019 b. Inferring Search Queries from Web Documents via a Graph-Augmented Sequence to Attention Network. In Proceedings of The Web Conference 2019.Google ScholarDigital Library"",""Yunlong He, Jiliang Tang, Hua Ouyang, Changsung Kang, Dawei Yin, and Yi Chang. 2016. Learning to rewrite queries. In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management. ACM, 1443--1452.Google ScholarDigital Library"",""Glen Jeh and Jennifer Widom. 2002. SimRank: a measure of structural-context similarity. In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 538--543.Google ScholarDigital Library"",""Jeff Johnson, Matthijs Douze, and Hervé Jégou. 2017. Billion-scale similarity search with GPUs. arXiv preprint arXiv:1702.08734 (2017).Google Scholar"",""Rosie Jones and Daniel C Fain. 2003. Query word deletion prediction. In Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval. ACM, 435--436.Google ScholarDigital Library"",""Gregory Koch, Richard Zemel, and Ruslan Salakhutdinov. 2015. Siamese neural networks for one-shot image recognition. In ICML deep learning workshop, Vol. 2.Google Scholar"",""Ke Li and Jitendra Malik. 2016. Learning to optimize. arXiv preprint arXiv:1606.01885 (2016).Google Scholar"",""Zhenguo Li, Fengwei Zhou, Fei Chen, and Hang Li. 2017. Meta-SGD: Learning to learn quickly for few-shot learning. arXiv preprint arXiv:1707.09835 (2017).Google Scholar"",""Bang Liu, Weidong Guo, Di Niu, Chaoyue Wang, Shunnan Xu, Jinghong Lin, Kunfeng Lai, and Yu Xu. 2019. A User-Centered Concept Mining System for Query and Document Understanding at Tencent. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM.Google ScholarDigital Library"",""Christopher D. Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven J. Bethard, and David McClosky. 2014. The Stanford CoreNLP Natural Language Processing Toolkit. In Association for Computational Linguistics (ACL) System Demonstrations. 55--60.Google Scholar"",""Devang K Naik and RJ Mammone. 1992. Meta-neural networks that learn by learning. In [Proceedings 1992] IJCNN International Joint Conference on Neural Networks, Vol. 1. IEEE, 437--442.Google Scholar"",""Alex Nichol, Joshua Achiam, and John Schulman. 2018. On first-order meta-learning algorithms. arXiv preprint arXiv:1803.02999 (2018).Google Scholar"",""Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. Deep contextualized word representations. arXiv preprint arXiv:1802.05365 (2018).Google Scholar"",""Sachin Ravi and Hugo Larochelle. 2016. Optimization as a model for few-shot learning. (2016).Google Scholar"",""Stefan Riezler and Yi Liu. 2010. Query rewriting using monolingual statistical machine translation. Computational Linguistics, Vol. 36, 3 (2010), 569--582.Google ScholarDigital Library"",""Stefan Riezler, Yi Liu, and Alexander Vasserman. 2008. Translating queries into snippets for improved query expansion. In Proceedings of the 22nd International Conference on Computational Linguistics-Volume 1. Association for Computational Linguistics, 737--744.Google ScholarDigital Library"",""Jürgen Schmidhuber. 1992. Learning to control fast-weight memories: An alternative to dynamic recurrent networks. Neural Computation, Vol. 4, 1 (1992), 131--139.Google ScholarDigital Library"",""Jake Snell, Kevin Swersky, and Richard Zemel. 2017. Prototypical networks for few-shot learning. In Advances in Neural Information Processing Systems. 4077--4087.Google Scholar"",""Yan Song, Shuming Shi, Jing Li, and Haisong Zhang. 2018. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers). Association for Computational Linguistics, 175--180.Google Scholar"",""Yangqiu Song, Haixun Wang, Zhongyuan Wang, Hongsong Li, and Weizhu Chen. 2011. Short text conceptualization using a probabilistic knowledgebase. In Twenty-Second International Joint Conference on Artificial Intelligence.Google Scholar"",""Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: A Simple Way to Prevent Neural Networks from Overfitting. Journal of Machine Learning Research, Vol. 15 (2014), 1929--1958.Google ScholarDigital Library"",""Fabian M Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. Yago: a core of semantic knowledge. In Proceedings of the 16th international conference on World Wide Web. ACM, 697--706.Google ScholarDigital Library"",""Flood Sung, Yongxin Yang, Li Zhang, Tao Xiang, Philip HS Torr, and Timothy M Hospedales. 2018. Learning to compare: Relation network for few-shot learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 1199--1208.Google ScholarCross Ref"",""Egidio Terra and Charles LA Clarke. 2004. Scoring missing terms in information retrieval tasks. In Proceedings of the thirteenth ACM international conference on Information and knowledge management. ACM, 50--58.Google ScholarDigital Library"",""Sebastian Thrun and Lorien Pratt. 2012. Learning to learn. Springer Science \u0026 Business Media.Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998--6008.Google Scholar"",""Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et almbox. 2016. Matching networks for one shot learning. In Advances in neural information processing systems. 3630--3638.Google Scholar"",""Jingang Wang, Junfeng Tian, Long Qiu, Sheng Li, Jun Lang, Luo Si, and Man Lan. 2018. A Multi-task Learning Approach for Improving Product Title Compression with User Search Log Data. arXiv preprint arXiv:1801.01725 (2018).Google Scholar"",""Zhongyuan Wang, Kejun Zhao, Haixun Wang, Xiaofeng Meng, and Ji-Rong Wen. 2015. Query understanding through knowledge-based conceptualization. In Twenty-Fourth International Joint Conference on Artificial Intelligence.Google Scholar"",""Wentao Wu, Hongsong Li, Haixun Wang, and Kenny Q Zhu. 2012. Probase: A probabilistic taxonomy for text understanding. In Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data. ACM, 481--492.Google ScholarDigital Library"",""Zi Yin, Keng-hao Chang, and Ruofei Zhang. 2017. Deepprobe: Information directed sequence understanding and chatbot design via recurrent neural networks. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 2131--2139.Google ScholarDigital Library"",""Wei Vivian Zhang, Xiaofei He, Benjamin Rey, and Rosie Jones. 2007. Query rewriting using active learning for sponsored search. In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval. ACM, 853--854.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403358,Hybrid Spatio-Temporal Graph Convolutional Network: Improving Traffic Prediction with Navigation Data,"Traffic forecasting has recently attracted increasing interest due to the popularity of online navigation services, ridesharing and smart city projects. Owing to the non-stationary nature of road traffic, forecasting accuracy is fundamentally limited by the lack of contextual information. To address this issue, we propose the Hybrid Spatio-Temporal Graph Convolutional Network (H-STGCN), which is able to ""deduce"" future travel time by exploiting the data of upcoming traffic volume. Specifically, we propose an algorithm to acquire the upcoming traffic volume from an online navigation engine. Taking advantage of the piecewise-linear flow-density relationship, a novel transformer structure converts the upcoming volume into its equivalent in travel time. We combine this signal with the commonly-utilized travel-time signal, and then apply graph convolution to capture the spatial dependency. Particularly, we construct a compound adjacency matrix which reflects the innate traffic proximity. We conduct extensive experiments on real-world datasets. The results show that H-STGCN remarkably outperforms state-of-the-art methods in various metrics, especially for the prediction of non-recurring congestion.","[{""name"":""Rui Dai"",""id"":""/profile/81458650224""},{""name"":""Shenkun Xu"",""id"":""/profile/99659573484""},{""name"":""Qian Gu"",""id"":""/profile/99659574915""},{""name"":""Chenguang Ji"",""id"":""/profile/99659573891""},{""name"":""Kaikui Liu"",""id"":""/profile/99659574249""},{""name"":""Rui Dai"",""id"":""/profile/81458650224""},{""name"":""Shenkun Xu"",""id"":""/profile/99659573484""},{""name"":""Qian Gu"",""id"":""/profile/99659574915""},{""name"":""Chenguang Ji"",""id"":""/profile/99659573891""},{""name"":""Kaikui Liu"",""id"":""/profile/99659574249""}]","[""Hannah Bast, Daniel Delling, Andrew Goldberg, Matthias Müller-Hannemann, Thomas Pajor, Peter Sanders, Dorothea Wagner, and Renato F Werneck. 2016. Route planning in transportation networks. In Algorithm engineering. Springer, 19--80.Google Scholar"",""Moshe Ben-Akiva, Michel Bierlaire, Haris Koutsopoulos, and Rabi Mishalani. 1998. DynaMIT: A simulation-based system for traffic prediction. In DACCORD Short Term Forecasting Workshop. Delft, The Netherlands, 1--12.Google Scholar"",""Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann Lecun. 2014. Spectral networks and locally connected networks on graphs. In Proceedings of the 2nd International Conference on Learning Representations (ICLR).Google Scholar"",""Wilco Burghout. 2004. Hybrid microscopic-mesoscopic traffic simulation modelling. Ph.D. Dissertation. PhD thesis, Dept of Infrastracture, Royal Institute of Technology, Stockholm, Sweden.Google Scholar"",""Djork-Arné Clevert, Thomas Unterthiner, and Sepp Hochreiter. 2016. Fast and accurate deep network learning by exponential linear units (ELUs). In Proceedings of the 4th International Conference on Learning Representations (ICLR).Google Scholar"",""Daniel J Dailey and Trepanier Ted. 2006. The use of weather data to predict non-recurring traffic congestion. Technical Report. Technical report to Washington State Transportation Commission, Washington State Department of Transportation, University of Washington TransNow, and Federal Highway Administration.Google Scholar"",""Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolutional neural networks on graphs with fast localized spectral filtering. In Advances in neural information processing systems. 3844--3852.Google Scholar"",""Shen Fang, Qi Zhang, Gaofeng Meng, Shiming Xiang, and Chunhong Pan. 2019. Gstnet: Global spatial-temporal network for traffic flow prediction. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI. 10--16.Google ScholarCross Ref"",""Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio. 2016. Deep learning. Vol. 1. MIT press Cambridge.Google Scholar"",""Jingrui He, Wei Shen, Phani Divakaruni, Laura Wynter, and Rick Lawrence. 2013. Improving traffic prediction with tweet semantics. In Proceedings of the 23rd International Joint Conference on Artificial Intelligence (IJCAI). 1387--1393.Google Scholar"",""Serge P Hoogendoorn and Piet HL Bovy. 2001. State-of-the-art of vehicular traffic flow modelling. Proceedings of the Institution of Mechanical Engineers, Part I: Journal of Systems and Control Engineering, Vol. 215, 4 (2001), 283--303.Google ScholarCross Ref"",""George Karypis and Vipin Kumar. 1998. A fast and high quality multilevel scheme for partitioning irregular graphs. SIAM Journal on scientific Computing, Vol. 20, 1 (1998), 359--392.Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2015. Adam: A method for stochastic optimization. In Proceedings of the 3rd International Conference on Learning Representations (ICLR).Google Scholar"",""Arief Koesdwiady, Ridha Soua, and Fakhreddine Karray. 2016. Improving prediction with weather information in connected cars: A deep learning approach. IEEE Transactions on Vehicular Technology, Vol. 65, 12 (2016), 9508--9517.Google ScholarCross Ref"",""Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. 2018. Diffusion convolutional recurrent neural network: Data-driven traffic forecasting. In Proceedings of the 6th International Conference on Learning Representations (ICLR).Google Scholar"",""Binbing Liao, Jingqing Zhang, Chao Wu, Douglas McIlwraith, Tong Chen, Shengwen Yang, Yike Guo, and Fei Wu. 2018. Deep Sequence Learning with Auxiliary Information for Traffic Prediction. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM.Google ScholarDigital Library"",""Yin Lou, Chengyang Zhang, Yu Zheng, Xing Xie, Wei Wang, and Yan Huang. 2009. Map-matching for low-sampling-rate GPS trajectories. In Proceedings of the 17th ACM SIGSPATIAL international conference on advances in geographic information systems. 352--361.Google ScholarDigital Library"",""Yisheng Lv, Yanjie Duan, Wenwen Kang, Zhengxi Li, Fei-Yue Wang, et almbox. 2015. Traffic flow prediction with big data: A deep learning approach. IEEE Trans. Intelligent Transportation Systems, Vol. 16, 2 (2015), 865--873.Google Scholar"",""Alessandra Pascale and Monica Nicoli. 2011. Adaptive Bayesian network for traffic flow prediction. In 2011 IEEE Statistical Signal Processing Workshop (SSP). IEEE, 177--180.Google ScholarCross Ref"",""Alexey Tsymbal. 2004. The problem of concept drift: definitions and related work. Computer Science Department, Trinity College Dublin, Vol. 106, 2 (2004), 58.Google Scholar"",""Eleni I Vlahogianni. 2015. Computational intelligence and optimization for transportation big data: challenges and opportunities. In Engineering and Applied Sciences Optimization. Springer, 107--128.Google Scholar"",""Ulrike Von Luxburg. 2007. A tutorial on spectral clustering. Statistics and computing, Vol. 17, 4 (2007), 395--416.Google Scholar"",""Hua Wei, Guanjie Zheng, Huaxiu Yao, and Zhenhui Li. 2018. Intellilight: A reinforcement learning approach for intelligent traffic light control. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining, KDD 2018, London, UK, August 19-23, 2018. 2496--2505.Google ScholarDigital Library"",""Bing Yu, Haoteng Yin, and Zhanxing Zhu. 2018. Spatio-Temporal Graph Convolutional Neural Network: A Deep Learning Framework for Traffic Forecasting. In Proceedings of the 27th International Joint Conference on Artificial Intelligence (IJCAI).Google Scholar"",""Junping Zhang, Fei-Yue Wang, Kunfeng Wang, Wei-Hua Lin, Xin Xu, and Cheng Chen. 2011. Data-driven intelligent transportation systems: A survey. IEEE Transactions on Intelligent Transportation Systems, Vol. 12, 4 (2011), 1624--1639.Google ScholarDigital Library"",""Chuanpan Zheng, Xiaoliang Fan, Chenglu Wen, Longbiao Chen, Cheng Wang, and Jonathan Li. 2019. DeepSTD: Mining spatio-temporal disturbances of multiple context factors for citywide traffic flow prediction. IEEE Transactions on Intelligent Transportation Systems (2019).Google Scholar""]"
https://doi.org/10.1145/3394486.3403359,Multitask Mixture of Sequential Experts for User Activity Streams,"It is often desirable to model multiple objectives in real-world web applications, such as user satisfaction and user engagement in recommender systems. Multi-task learning has become the standard approach for such applications recently.While most of the multi-task recommendation model architectures proposed to date are focusing on using non-sequential input features (e.g., query and context), input data is often sequential in real-world web application scenarios. For example, user behavior streams, such as user search logs in search systems, are naturally atemporal sequence. Modeling user sequential behaviors as explicit sequential representations can empower the multi-task model to incorporate temporal dependencies, thus predicting future user behavior more accurately. Furthermore, user activity streams can come from heterogeneous data sources, such as user search logs and user browsing logs. They typically possess very different properties such as data sparsity and thus need careful treatment when being modeled jointly.In this work, we study the challenging problem of how to model sequential user behavior in the neural multi-task learning settings. Our major contribution is a novel framework, Mixture of Sequential Experts (MoSE). It explicitly models sequential user behavior using Long Short-Term Memory (LSTM) in the state-of-art Multi-gate Mixture-of-Expert multi-task modeling framework. In experiments, we show the effectiveness of the MoSE architecture over seven alternative architectures on both synthetic and noisy real-world user data in G Suite. We also demonstrate the effectiveness and flexibility of the MoSE architecture in a real-world decision making engine in GMail that involves millions of users, balancing between search quality and resource costs.","[{""name"":""Zhen Qin"",""id"":""/profile/99659315793""},{""name"":""Yicheng Cheng"",""id"":""/profile/99659574368""},{""name"":""Zhe Zhao"",""id"":""/profile/81464642056""},{""name"":""Zhe Chen"",""id"":""/profile/99659574417""},{""name"":""Donald Metzler"",""id"":""/profile/81100129957""},{""name"":""Jingzheng Qin"",""id"":""/profile/99659536430""},{""name"":""Zhen Qin"",""id"":""/profile/99659315793""},{""name"":""Yicheng Cheng"",""id"":""/profile/99659574368""},{""name"":""Zhe Zhao"",""id"":""/profile/81464642056""},{""name"":""Zhe Chen"",""id"":""/profile/99659574417""},{""name"":""Donald Metzler"",""id"":""/profile/81100129957""},{""name"":""Jingzheng Qin"",""id"":""/profile/99659536430""}]","[""2014. 32 Google Drive Tips You've Probably Never Heard Before. https://www. process.st/25-google-drive-tips-youve-probably-never-heard-before/. Accessed: 2020-02-01.Google Scholar"",""Martin Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, et almbox. 2016. Tensorflow: A system for large-scale machine learning. In OSDI. 265--283.Google Scholar"",""Alex Beutel, Paul Covington, Sagar Jain, Can Xu, Jia Li, Vince Gatto, and Ed H Chi. 2018. Latent cross: Making use of context in recurrent recommender systems. In WSDM. 46--54.Google Scholar"",""Jiajiong Cao, Yingming Li, and Zhongfei Zhang. 2018. Partially Shared Multi-task Convolutional Neural Network with Local Constraint for Face Attribute Learning. In CVPR. 4290--4299.Google Scholar"",""David Carmel, Elad Haramaty, Arnon Lazerson, and Liane Lewin-Eytan. 2020. Multi-objective Ranking Optimization for Product Search Using Stochastic Label Aggregation. In WWW.Google Scholar"",""Xu Chen, Hongteng Xu, Yongfeng Zhang, Jiaxi Tang, Yixin Cao, Zheng Qin, and Hongyuan Zha. 2018. Sequential recommendation with user memory networks. In WSDM. 108--116.Google Scholar"",""Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. 2014. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling. arxiv: 1412.3555Google Scholar"",""Carlo Ciliberto, Alessandro Rudi, Lorenzo Rosasco, and Massimiliano Pontil. 2017. Consistent Multitask Learning with Nonlinear Output Relations. In NeurIPs. 1983--1993.Google Scholar"",""Onkar Dalal, Srinivasan H. Sengenmedu, and Subhajit Sanyal. 2012. Multi-objective Ranking of Comments on Web. In WWW.Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In ACL-HLT. 4171--4186.Google Scholar"",""Long Duong, Trevor Cohn, Steven Bird, and Paul Cook. 2015. Low Resource Dependency Parsing: Cross-lingual Parameter Sharing in a Neural Network Parser. In ACL. 845--850.Google Scholar"",""David Eigen, Marc'Aurelio Ranzato, and Ilya Sutskever. 2013. Learning factored representations in a deep mixture of experts. arxiv: 1312.4314Google Scholar"",""Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2015. Session-based recommendations with recurrent neural networks. arxiv: 1511.06939Google Scholar"",""Geoffrey Hinton, Oriol Vinyals, and Jeffrey Dean. 2015. Distilling the Knowledge in a Neural Network. In NIPS Deep Learning and Representation Learning Workshop. http://arxiv.org/abs/1503.02531Google Scholar"",""Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long Short-Term Memory. Neural Comput. (1997), 1735--1780.Google Scholar"",""Melvin Johnson, Mike Schuster, Quoc V Le, Maxim Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat, Fernanda Viégas, Martin Wattenberg, Greg Corrado, et almbox. 2017. Google's multilingual neural machine translation system: Enabling zero-shot translation. Transactions of the Association for Computational Linguistics (2017), 339--351.Google Scholar"",""Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recommendation. In ICDM. 197--206.Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arxiv: 1412.6980Google Scholar"",""Ang Li, Suming J. Chen, Jingzheng Qin, and Zhen Qin. 2020. Training Machine Learning Models With Causal Logic. In WWW Companion. 557--561.Google Scholar"",""Xiao Lin, Hongjie Chen, Changhua Pei, Fei Sun, Xuanji Xiao, Hanxiao Sun, Yongfeng Zhang, Peng Jiang, and Wenwu Ou. 2019. A Pareto-Efficient Algorithm for Multiple Objective Optimization in E-Commerce Recommendation. In RecSys. 1--9.Google Scholar"",""Shikun Liu, Edward Johns, and Andrew J Davison. 2019. End-to-end multi-task learning with attention. In CVPR. 1871--1880.Google Scholar"",""Minh-Thang Luong, Quoc V Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. 2015. Multi-task sequence to sequence learning. arxiv: 1511.06114Google Scholar"",""Jiaqi Ma, Zhe Zhao, Jilin Chen, Ang Li, Lichan Hong, and Ed H. Chi. 2019. SNR: Sub-Network Routing for Flexible Parameter Sharing in Multi-task Learning. In AAAI.Google Scholar"",""Jiaqi Ma, Zhe Zhao, Xinyang Yi, Jilin Chen, Lichan Hong, and Ed H. Chi. 2018b. Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts. In KDD. 1930--1939.Google Scholar"",""Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu, and Kun Gai. 2018a. Entire space multi-task model: An effective approach for estimating post-click conversion rate. In SIGIR. 1137--1140.Google Scholar"",""Hongyuan Mei and Jason M Eisner. 2017. The neural hawkes process: A neurally self-modulating multivariate point process. In NeurIPs. 6754--6764.Google Scholar"",""Ishan Misra, Abhinav Shrivastava, Abhinav Gupta, and Martial Hebert. 2016. Cross-stitch networks for multi-task learning. In CVPR. 3994--4003.Google Scholar"",""Zhen Qin, Zhongliang Li, Michael Bendersky, and Donald Metzler. 2020. Matching Cross Network for Learning to Rank in Personal Search. In WWW. 2835--2841.Google Scholar"",""Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2019. Exploring the limits of transfer learning with a unified text-to-text transformer. arXiv preprint arXiv:1910.10683 (2019).Google Scholar"",""Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Factorizing personalized markov chains for next-basket recommendation. In WWW. 811--820.Google Scholar"",""Marco Tulio Ribeiro, Nivio Ziviani, Edleno Silva De Moura, Itamar Hata, Anisio Lacerda, and Adriano Veloso. 2014. Multiobjective Pareto-Efficient Approaches for Recommender Systems. ACM Trans. Intell. Syst. Technol. (2014), 53:1--53:20.Google Scholar"",""Sebastian Ruder. 2017. An overview of multi-task learning in deep neural networks. arxiv: 1706.05098Google Scholar"",""Jiaxi Tang, Francois Belletti, Sagar Jain, Minmin Chen, Alex Beutel, Can Xu, and Ed H. Chi. 2019. Towards Neural Mixture Recommender for Long Range Dependent User Sequences. In WWW. 1782--1793.Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention Is All You Need. arxiv: 1706.03762Google Scholar"",""Ruoxi Wang, Zhe Zhao, Xinyang Yi, Ji Yang, Derek Zhiyuan Cheng, Lichan Hong, Steve Tjoa, Jieqi Kang, Evan Ettinger, and H Chi. 2019. Improving Relevance Prediction with Transfer Learning in Large-scale Retrieval Systems. (2019).Google Scholar"",""Liang Wu, Diane Hu, Liangjie Hong, and Huan Liu. 2018. Turning Clicks into Purchases: Revenue Optimization for Product Search in E-Commerce. In SIGIR. 365--374.Google Scholar"",""Yonghui Wu et almbox. 2016. Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation. arxiv: 1609.08144Google Scholar"",""Yongxin Yang and Timothy Hospedales. 2016. Deep multi-task representation learning: A tensor factorisation approach. arxiv: 1605.06391Google Scholar"",""Feng Yu, Qiang Liu, Shu Wu, Liang Wang, and Tieniu Tan. 2016. A dynamic recurrent model for next basket recommendation. In SIGIR. 729--732.Google Scholar"",""Yu Zhang and Qiang Yang. 2017. A Survey on Multi-Task Learning. arxiv: 1707.08114Google Scholar"",""Jiejie Zhao, Bowen Du, Leilei Sun, Fuzhen Zhuang, Weifeng Lv, and Hui Xiong. 2019 a. Multiple Relational Attention Network for Multi-Task Learning. In KDD. 1123--1131.Google Scholar"",""Zhe Zhao, Lichan Hong, Li Wei, Jilin Chen, Aniruddh Nath, Shawn Andrews, Aditee Kumthekar, Maheswaran Sathiamoorthy, Xinyang Yi, and Ed Chi. 2019 b. Recommending what video to watch next: a multitask ranking system. In RecSys. 43--51.Google Scholar""]"
https://doi.org/10.1145/3394486.3403360,Identifying Homeless Youth At-Risk of Substance Use Disorder: Data-Driven Insights for Policymakers,"Substance Use Disorder (SUD) is a devastating disease that leads to significant mental and behavioral impairments. Its negative effects damage the homeless youth population more severely (as compared to stably housed counterparts) because of their high-risk behaviors. To assist policymakers in devising effective and accurate long-term strategies to mitigate SUD, it is necessary to critically analyze environmental, psychological, and other factors associated with SUD among homeless youth. Unfortunately, there is no definitive data-driven study on analyzing factors associated with SUD among homeless youth. While there have been a few prior studies in the past, they (i) do not analyze variation in the associated factors for SUD with geographical heterogeneity in their studies; and (ii) only consider a few contributing factors to SUD in relatively small samples. This work aims to fill this gap by making the following three contributions: (i) we use a real-world dataset collected from ~1,400 homeless youth (across six American states) to build accurate Machine Learning (ML) models for predicting the susceptibility of homeless youth to SUD; (ii) we find a representative set of factors associated with SUD among this population by analyzing feature importance values associated with our ML models; and (iii) we investigate the effect of geographical heterogeneity on the factors associated with SUD. Our results show that our system using adaptively boosted decision trees achieves the best predictive accuracy out of several algorithms on the SUD prediction task, achieving an Area Under the ROC Curve of 0.85. Further, among other things, we also find that both Post-Traumatic Stress Disorder (PTSD) and depression are very strongly associated with SUD among homeless youth because of their propensity to self-medicate to alleviate stress. This work is done in collaboration with social work scientists, who are currently evaluating the results for potential future deployment.","[{""name"":""Maryam Tabar"",""id"":""/profile/99659574918""},{""name"":""Heesoo Park"",""id"":""/profile/99659513475""},{""name"":""Stephanie Winkler"",""id"":""/profile/99659573723""},{""name"":""Dongwon Lee"",""id"":""/profile/81452592724""},{""name"":""Anamika Barman-Adhikari"",""id"":""/profile/99658977207""},{""name"":""Amulya Yadav"",""id"":""/profile/99658981343""},{""name"":""Maryam Tabar"",""id"":""/profile/99659574918""},{""name"":""Heesoo Park"",""id"":""/profile/99659513475""},{""name"":""Stephanie Winkler"",""id"":""/profile/99659573723""},{""name"":""Dongwon Lee"",""id"":""/profile/81452592724""},{""name"":""Anamika Barman-Adhikari"",""id"":""/profile/99658977207""},{""name"":""Amulya Yadav"",""id"":""/profile/99658981343""}]","[""American Psychiatric Association. 2013. Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition (DSM-5). American Psychiatric Association.Google Scholar"",""Anamika Barman-Adhikari, Hsun-Ta Hsu, Daphne Brydon, Robin Petering, Diana Santa Maria, Sarah Narendorf, Jama Shelton, Kimberly Bender, and Kristin Ferguson. 2019. Prevalence and correlates of nonmedical use of prescription drugs (NMUPD) among Young adults experiencing homelessness in seven cities across the United States. Drug and Alcohol Dependence, Vol. 200 (2019), 153--160.Google ScholarCross Ref"",""Kimberly Bender, Samantha M. Brown, Sanna J. Thompson, Kristin M. Ferguson, and Lisa Langenderfer. 2015. Multiple Victimizations Before and After Leaving Home Associated With PTSD, Depression, and Substance Use Disorder Among Homeless Youth. Child Maltreatment, Vol. 20, 2 (2015), 115--124.Google ScholarCross Ref"",""Leo Breiman, Jerome Friedman, Charles J Stone, and Richard A Olshen. 1984. Classification and Regression Trees. CRC press.Google Scholar"",""Nancy H. Busen and Joan C. Engebretson. 2008. Facilitating risk reduction among homeless and street-involved youth. Journal of the American Academy of Nurse Practitioners, Vol. 20, 11 (2008), 567--575.Google ScholarCross Ref"",""Giffords Law Center. 2020. Annual Gun Law Scoreboard. https://lawcenter.giffords.org/scorecard/. [Online; accessed 2-February-2020].Google Scholar"",""Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A library for support vector machines. ACM transactions on intelligent systems and technology (TIST), Vol. 2, 3, Article 27 (2011).Google ScholarDigital Library"",""Nitesh V. Chawla, Kevin W. Bowyer, Lawrence O. Hall, and W. Philip Kegelmeyer. 2002. SMOTE: Synthetic Minority Over-sampling Technique. Journal of artificial intelligence research, Vol. 16, 1 (2002), 321--357.Google ScholarDigital Library"",""Tianqi Chen and Carlos Guestrin. 2016. XGBoost: A scalable tree boosting system. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. Association for Computing Machinery, 785--794.Google ScholarDigital Library"",""Jordan P. Davis, Emily R. Dworkin, Jesse Helton, John Prindle, Sadiq Patel, Tara M. Dumas, and Sarah Miller. 2019. Extending poly-victimization theory: Differential effects of adolescents' experiences of victimization on substance use disorder diagnosis upon treatment entry. Child Abuse \u0026 Neglect, Vol. 89 (2019), 165--177.Google ScholarCross Ref"",""Tracy L. Dietz. 2007. Predictors of reported current and lifetime substance abuse problems among a national sample of U.S. homeless. Substance Use \u0026 Misuse, Vol. 42 (2007), 1745--1766.Google ScholarCross Ref"",""Tao Ding, Warren K Bickel, and Shimei Pan. 2017. Multi-view unsupervised user feature embedding for social media-based substance use prediction. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. 2275--2284.Google ScholarCross Ref"",""Yoav Freund and Robert E Schapire. 1997. A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting. J. Comput. System Sci., Vol. 55, 1 (1997), 119--139.Google ScholarDigital Library"",""Robin M Hartinger-Saunders, Barbara Rittner, William Wieczorek, Thomas Nochajski, Christine M Rine, and John Welte. 2011. Victimization, psychological distress and subsequent offending among youth. Children and Youth Services Review, Vol. 33, 11 (2011), 2375--2385.Google ScholarCross Ref"",""Saeed Hassanpour, Naofumi Tomita, Timothy Delise, Benjamin Crosier, and Lisa A. Marsch. 2019. Identifying substance use risk based on deep neural networks and Instagram social media data. Neuropsychopharmacology, Vol. 44, 3 (2019), 487--494.Google ScholarCross Ref"",""Simon Haykin. 1998. Neural Networks: A Comprehensive Foundation 2nd ed.). Prentice Hall PTR.Google ScholarDigital Library"",""Laura M. Heath, Lise Laporte, Joel Paris, Kevin Hamdullahpur, and Kathryn J. Gill. 2018. Substance misuse is associated with increased psychiatric severity among treatment-seeking individuals with borderline personality disorders . Journal of Personality Disorders, Vol. 32, 5 (2018), 694--708.Google ScholarCross Ref"",""Torsten Hothorn, Peter Bühlmann, Sandrine Dudoit, Annette Molinaro, and Mark J. Van Der Laan. 2006. Survival ensembles. Biostatistics, Vol. 7, 3 (2006), 355--373.Google ScholarCross Ref"",""Thomas M. Kelly and Denis C. Daley. 2013. Integrated Treatment of Substance Use and Psychiatric Disorders. Social work in public health, Vol. 28 (2013), 388--406.Google Scholar"",""Dean G Kilpatrick, Kenneth J Ruggiero, Ron Acierno, Benjamin E Saunders, Heidi S Resnick, and Connie L Best. 2003. Violence and risk of PTSD, major depression, substance abuse/dependence, and comorbidity: results from the National Survey of Adolescents. Journal of consulting and clinical psychology, Vol. 71, 4 (2003), 692--700.Google ScholarCross Ref"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization . arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Barrett A. Lee and Christopher J. Schreck. 2005. Danger on the Streets: Marginality and Victimization Among Homeless People. American Behavioral Scientist, Vol. 48, 8 (2005), 1055--1081.Google ScholarCross Ref"",""Murdoch Leeies, Jina Pagura, Jitender Sareen, and James M Bolton. 2010. The use of alcohol and drugs to self-medicate symptoms of posttraumatic stress disorder. Depression and anxiety, Vol. 27, 8 (2010), 731--736.Google Scholar"",""Gilles Louppe, Louis Wehenkel, Antonio Sutera, and Pierre Geurts. 2013. Understanding variable importances in forests of randomized trees. In Advances in neural information processing systems. 431--439.Google Scholar"",""National Institute on Drug Abuse. 2019. Treatment Approaches for Drug Addiction. www.drugabuse.gov/publications/drugfacts/treatment-approaches-drug-addiction. [Online; accessed 2-February-2020].Google Scholar"",""National Institute on Drug Abuse. 2020. Costs of Substance Abuse. www.drugabuse.gov/drug-topics/trends-statistics/costs-substance-abuse. [Online; accessed 14-June-2020].Google Scholar"",""Robin Petering, Harmony Rhoades, Hailey Winetrobe, David Dent, and Eric Rice. 2017. Violence, Trauma, Mental Health, and Substance Use Among Homeless Youth Juggalos. Child Psychiatry and Human Development, Vol. 48, 4 (2017), 642--650.Google ScholarCross Ref"",""Christopher J. Przemieniecki, Samantha Compitello, and Josiah D. Lindquist. 2020. Juggalos - Whoop! Whoop! A family or a gang? A participant observation study on an FBI defined 'hybrid' gang. Deviant Behavior, Vol. 41, 8 (2020), 977--990.Google ScholarCross Ref"",""Aida Rahmattalabi, Anamika Barman-Adhikari, Phebe Vayanos, Milind Tambe, Eric Rice, and Robin Baker. 2019 a. Social Network Based Substance Abuse Prevention via Network Modification (A Preliminary Study). arXiv preprint arXiv:1902.00171 (2019).Google Scholar"",""Aida Rahmattalabi, Phebe Vayanos, Anthony Fulginiti, Eric Rice, Bryan Wilder, Amulya Yadav, and Milind Tambe. 2019 b. Exploring algorithmic fairness in robust graph covering problems. In Advances in Neural Information Processing Systems. 15776--15787.Google Scholar"",""Darrel A. Regier, Mary E. Farmer, Donald S. Rae, Ben Z. Locke, Samuel J. Keith, Lewis L. Judd, and Frederick K. Goodwin. 1990. Comorbidity of Mental Disorders With Alcohol and Other Drug Abuse: Results From the Epidemiologic Catchment Area (ECA) Study. JAMA, Vol. 264, 19 (1990), 2511--2518.Google ScholarCross Ref"",""Michael W Ross and Mark L Williams. 2001. Sexual behavior and illicit drug use . Annual review of sex research, Vol. 12, 1 (2001), 290--310.Google Scholar"",""Stephen Ross and Eric Peselow. 2012. Co-Occurring Psychotic and Addictive Disorders . Clinical neuropharmacology, Vol. 35 (2012), 235--43.Google Scholar"",""Bill Sanders. 2012. Gang youth, substance use patterns, and drug normalization. Journal of Youth Studies, Vol. 15, 8 (2012), 978--994.Google ScholarCross Ref"",""Julia Thornton Snider, Margaret E. Duncan, Mugdha R. Gore, Seth Seabury, Alison R. Silverstein, Mahlet G. Tebeka, and Dana P. Goldman. 2019. Association Between State Medicaid Eligibility Thresholds and Deaths Due to Substance Use Disorders. JAMA Network Open, Vol. 2, 4 (2019).Google Scholar"",""Richard Speiglman and Rex S. Green. 1999. Homeless and Nonhomeless Arrestees: Distinctions in Prevalence and in Socio Demographic, Drug Use, and Arrest Characteristics across DUF Sites. (1999).Google Scholar"",""Daniel J. Stekhoven and Peter Buehlmann. 2012. MissForest--non-parametric missing value imputation for mixed-type data. Bioinformatics, Vol. 28 (2012), 112--118.Google ScholarDigital Library"",""Angela J Stewart, Mandy Steiman, Ana Mari Cauce, Bryan N Cochran, Les B Whitbeck, and Dan R Hoyt. 2004. Victimization and Posttraumatic Stress Disorder Among Homeless Adolescents. Journal of the American Academy of Child \u0026 Adolescent Psychiatry, Vol. 43, 3 (2004), 325--331.Google ScholarCross Ref"",""Substance Abuse and Mental Health Services Administration. 2018. Key Substance Use and Mental Health Indicators in the United States: Results from the 2017 National Survey on Drug Use and Health. Center for Behavioral Health Statistics and Quality, Substance Abuse and Mental Health Services Administration.Google Scholar"",""Joel Swendsen, Kevin P. Conway, Louisa Degenhardt, Meyer Glantz, Robert Jin, and Kathleen R. Merikangas. 2010. Mental disorders as risk factors for substance use, abuse and dependence: results from the 10-year follow-up of the National Comorbidity Survey. Addiction, Vol. 105 (2010), 1117--1128.Google ScholarCross Ref"",""The Sentencing Project. 2019. State-by-State Data. https://www.sentencingproject.org/the-facts/map. [Online; accessed 2-February-2020].Google Scholar"",""Sanna J. Thompson, Kimberly Bender, Kristin M. Ferguson, and Yeonwoo Kim. 2015. Factors associated with substance use disorders among traumatized homeless youth. Journal of social Work Practice in the Addictions, Vol. 15 (2015), 66--89.Google ScholarCross Ref"",""Kimberly Tyler, Lisa Kort-Butler, and Alexis Swendener. 2014. The Effect of Victimization, Mental Health, and Protective Factors on Crime and Illicit Drug Use Among Homeless Young Adults. Violence and victims, Vol. 29, 2 (2014), 348--362.Google Scholar"",""Kimberly A. Tyler and Katherine Johnson. 2006. Pathways in and out of substance use among homeless-emerging adults. Journal of Adolescent Research, Vol. 21 (2006), 133--157.Google ScholarCross Ref"",""Kimberly A. Tyler and Lisa A. Melander. 2015. Child Abuse, Street Victimization, and Substance Use Among Homeless Young Adults. Youth \u0026 Society, Vol. 47, 4 (2015), 502--519.Google ScholarCross Ref"",""Luis Villalobos-Gallegos, Maria Elena Medina-Mora, Corina Benjit, Silvia Ruiz-Velasco, Carlos Margis-Rodriguez, and Rodrigo Marin-Navarrete. 2019. Multidimensional patterns of sexual risk behavior and psychiatric disorders in men with substance use disorders. Archives of Sexual Behavior, Vol. 48, 2 (2019), 599--607.Google ScholarCross Ref"",""Wikipedia contributors. 2020. Gathering of the Juggalos -- Wikipedia, The Free Encyclopedia. https://en.wikipedia.org/wiki/Gathering_of_the_Juggalos. [Online; accessed 2-February-2020].Google Scholar"",""Amulya Yadav, Hau Chan, Albert Xin Jiang, Haifeng Xu, Eric Rice, and Milind Tambe. 2016. Using Social Networks to Aid Homeless Shelters: Dynamic Influence Maximization under Uncertainty. In Proceedings of the 2016 International Conference on Autonomous Agents \u0026 Multiagent Systems. 740--748.Google ScholarDigital Library"",""Amulya Yadav, Bryan Wilder, Eric Rice, Robin Petering, Jaih Craddock, Amanda Yoshioka-Maxwell, Mary Hemler, Laura Onasch-Vera, Milind Tambe, and Darlene Woo. 2017. Influence Maximization in the Field: The Arduous Journey from Emerging to Deployed Application. In Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems. 150--158.Google ScholarDigital Library"",""Kevin A. Yoder, Les B. Whitbeck, and Dan R. Hoyt. 2003. Gang Involvement and Membership among Homeless and Runaway Youth. Youth \u0026 Society, Vol. 34, 4 (2003), 441--467.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403361,Interleaved Sequence RNNs for Fraud Detection,"Payment card fraud causes multibillion dollar losses for banks and merchants worldwide, often fueling complex criminal activities. To address this, many real-time fraud detection systems use tree-based models, demanding complex feature engineering systems to efficiently enrich transactions with historical data while complying with millisecond-level latencies. In this work, we do not require those expensive features by using recurrent neural networks and treating payments as an interleaved sequence, where the history of each card is an unbounded, irregular sub-sequence. We present a complete RNN framework to detect fraud in real-time, proposing an efficient ML pipeline from preprocessing to deployment. We show that these feature-free, multi-sequence RNNs outperform state-of-the-art models saving millions of dollars in fraud detection and using fewer computational resources.","[{""name"":""Bernardo Branco"",""id"":""/profile/99659573395""},{""name"":""Pedro Abreu"",""id"":""/profile/99659573648""},{""name"":""Ana Sofia Gomes"",""id"":""/profile/99659574126""},{""name"":""Mariana S. C. Almeida"",""id"":""/profile/99659573352""},{""name"":""João Tiago Ascensão"",""id"":""/profile/99659574769""},{""name"":""Pedro Bizarro"",""id"":""/profile/99659574580""},{""name"":""Bernardo Branco"",""id"":""/profile/99659573395""},{""name"":""Pedro Abreu"",""id"":""/profile/99659573648""},{""name"":""Ana Sofia Gomes"",""id"":""/profile/99659574126""},{""name"":""Mariana S. C. Almeida"",""id"":""/profile/99659573352""},{""name"":""João Tiago Ascensão"",""id"":""/profile/99659574769""},{""name"":""Pedro Bizarro"",""id"":""/profile/99659574580""}]","[""Aisha Abdallah, Mohd Aizaini Maarof, and Anazida Zainal. 2016. Fraud detection system: A survey. Journal of Network and Computer Applications, Vol. 68 (2016), 90--113. https://doi.org/10.1016/j.jnca.2016.04.007Google ScholarDigital Library"",""Yoshihiro Ando, Hidehito Gomi, and Hidehiko Tanaka. 2016. Detecting Fraudulent Behavior Using Recurrent Neural Networks. In Computer Security Symp.Google Scholar"",""Alejandro Correa Bahnsen, Djamila Aouada, Aleksandar Stojanovic, and Bjö rn E. Ottersten. 2016. Feature engineering strategies for credit card fraud detection. Expert Syst. Appl., Vol. 51 (2016), 134--142. https://doi.org/10.1016/j.eswa.2015.12.030Google ScholarDigital Library"",""Siddhartha Bhattacharyya, Sanjeev Jha, Kurian K. Tharakunnel, and J. Christopher Westland. 2011. Data mining for credit card fraud: A comparative study. Decis. Support Syst., Vol. 50, 3 (2011), 602--613. https://doi.org/10.1016/j.dss.2010.08.008Google ScholarDigital Library"",""Richard J. Bolton and David J. Hand. 2002. Statistical Fraud Detection: A Review. Statist. Sci., Vol. 17, 3 (08 2002), 235--255. https://doi.org/10.1214/ss/1042727940Google Scholar"",""Tianqi Chen and Carlos Guestrin. 2016. XGBoost: A Scalable Tree Boosting System. In KDD '16. ACM, New York, NY, USA, 785--794. https://doi.org/10.1145/2939672.2939785Google ScholarDigital Library"",""Kyunghyun Cho, Bart van Merrienboer, cC aglar Gü lcc ehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation. In EMNLP 2014. Association for Computational Linguistics, Doha, Qatar, 1724--1734. https://doi.org/10.3115/v1/d14-1179Google Scholar"",""Howard Chu. 2011. MDB: A memory-mapped database and backend for OpenLDAP. https://www.openldap.org/pub/hyc/mdm-paper.Google Scholar"",""Alexandre de Bré bisson, É tienne Simon, Alex Auvolat, Pascal Vincent, and Yoshua Bengio. 2015. Artificial Neural Networks Applied to Taxi Destination Prediction. In ECML/PKDD 2015. CEUR-WS.org, Aachen, DEU, 40--51. http://ceur-ws.org/Vol-1526/paper21.pdfGoogle Scholar"",""Facebook. 2013. RocksDB: A Persistent Key-Value Store for Flash and RAM Storage. https://github.com/facebook/rocksdb.Google Scholar"",""Google. 2020. Tensorflow Model Optimization. https://www.tensorflow.org/lite/performance/model_optimization.Google Scholar"",""Tao Guo and Gui-Yang Li. 2008. Neural data mining for credit card fraud detection. In Proceedings 11th International Conference on Tools with Artificial Intelligence, Vol. 7. IEEE, 3630--3634. https://doi.org/10.1109/ICMLC.2008.4621035Google Scholar"",""Sepp Hochreiter and Jü rgen Schmidhuber. 1997. Long Short-Term Memory. Neural Computation, Vol. 9, 8 (1997), 1735--1780. https://doi.org/10.1162/neco.1997.9.8.1735Google ScholarDigital Library"",""Inc. HSN Consultants. 2019. The Nilson Report. https://nilsonreport.com/upload/content_promo/The_Nilson_Report_10-17-2016.pdfGoogle Scholar"",""Johannes Jurgovsky, Michael Granitzer, Konstantin Ziegler, Sylvie Calabretto, Pierre-Edouard Portier, Liyun He-Guelton, and Olivier Caelen. 2018. Sequence classification for credit-card fraud detection. Expert Systems with Applications, Vol. 100 (2018), 234--245. https://doi.org/10.1016/j.eswa.2018.01.037Google ScholarCross Ref"",""Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. 2017. LightGBM: A Highly Efficient Gradient Boosting Decision Tree. In NIPS. Curran Associates Inc., Red Hook, NY, USA, 3146--3154.Google Scholar"",""Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep learning. Nature, Vol. 521, 7553 (2015), 436--444. https://doi.org/10.1038/nature14539Google Scholar"",""X. Li, W. Yu, T. Luwang, J. Zheng, X. Qiu, J. Zhao, L. Xia, and Y. Li. 2018. Transaction Fraud Detection Using GRU-centered Sandwich-structured Model. In IEEE CSCWD 2018. IEEE, 467--472.Google ScholarCross Ref"",""Arjun Mannaly. 2018. HaloDB. https://github.com/yahoo/HaloDB.Google Scholar"",""Patrick E. O'Neil, Edward Cheng, Dieter Gawlick, and Elizabeth J. O'Neil. 1996. The Log-Structured Merge-Tree (LSM-Tree). Acta Inf., Vol. 33, 4 (1996), 351--385. https://doi.org/10.1007/s002360050048Google ScholarDigital Library"",""David E. Rumelhart, Geoffrey E. Hinton, and Ronald J. Williams. 1986. Learning representations by back-propagating errors. Nature, Vol. 323, 6088 (1986), 533--536. https://doi.org/10.1038/323533a0Google ScholarCross Ref"",""Jü rgen Schmidhuber. 2015. Deep learning in neural networks: An overview. Neural Networks, Vol. 61 (2015), 85--117. https://doi.org/10.1016/j.neunet.2014.09.003Google ScholarDigital Library"",""Evan Shelhamer, Jonathan Long, and Trevor Darrell. 2017. Fully Convolutional Networks for Semantic Segmentation. IEEE Trans. Pattern Anal. Mach. Intell., Vol. 39, 4 (2017), 640--651. https://doi.org/10.1109/TPAMI.2016.2572683Google ScholarDigital Library"",""Nic Watson. 2011. Universal Python binding for the LMDB 'Lightning' Database. https://github.com/jnwatson/py-lmdb.Google Scholar"",""C. Whitrow, David Hand, P. Juszczak, David Weston, and Niall Adams. 2009. Transaction aggregation as a strategy for credit card fraud detection. Data Mining and Knowledge Discovery, Vol. 18 (02 2009), 30--55.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403362,Attention based Multi-Modal New Product Sales Time-series Forecasting,"Trend driven retail industries such as fashion, launch substantial new products every season. In such a scenario, an accurate demand forecast for these newly launched products is vital for efficient downstream supply chain planning like assortment planning and stock allocation. While classical time-series forecasting algorithms can be used for existing products to forecast the sales, new products do not have any historical time-series data to base the forecast on. In this paper, we propose and empirically evaluate several novel attention-based multi-modal encoder-decoder models to forecast the sales for a new product purely based on product images, any available product attributes and also external factors like holidays, events, weather, and discount. We experimentally validate our approaches on a large fashion dataset and report the improvements in achieved accuracy and enhanced model interpretability as compared to existing k-nearest neighbor based baseline approaches.","[{""name"":""Vijay Ekambaram"",""id"":""/profile/99659574396""},{""name"":""Kushagra Manglik"",""id"":""/profile/99659572978""},{""name"":""Sumanta Mukherjee"",""id"":""/profile/99659574107""},{""name"":""Surya Shravan Kumar Sajja"",""id"":""/profile/99659524593""},{""name"":""Satyam Dwivedi"",""id"":""/profile/99659573611""},{""name"":""Vikas Raykar"",""id"":""/profile/81100214434""},{""name"":""Vijay Ekambaram"",""id"":""/profile/99659574396""},{""name"":""Kushagra Manglik"",""id"":""/profile/99659572978""},{""name"":""Sumanta Mukherjee"",""id"":""/profile/99659574107""},{""name"":""Surya Shravan Kumar Sajja"",""id"":""/profile/99659524593""},{""name"":""Satyam Dwivedi"",""id"":""/profile/99659573611""},{""name"":""Vikas Raykar"",""id"":""/profile/81100214434""}]","[""United States Environmental Protection Agency. 2017. Textiles: Material-Specific Data. https://www.epa.gov/facts-and-figures-about-materials-waste-and-recycling/textiles-material-specific-dataGoogle Scholar"",""Lennart Baardman, Igor Levin, Georgia Perakis, and Divya Singhvi. 2017. Leveraging comparables for new product sales forecasting. SSRN 3086237 (2017).Google Scholar"",""Tsan-Ming Choi, Chi-Leung Hui, and Yong Yu. 2013. Intelligent fashion forecasting systems: models and applications. Springer.Google Scholar"",""Jan K Chorowski, Dzmitry Bahdanau, Dmitriy Serdyuk, Kyunghyun Cho, and Yoshua Bengio. 2015. Attention-based models for speech recognition. In Advances in neural information processing systems. 577--585.Google Scholar"",""Giuseppe Craparotta, Sébastien Thomassey, and Amedeo Biolatti. 2019. A Siamese Neural Network Application for Sales Forecasting of New Fashion Products Using Heterogeneous Data. International Journal of Computational Intelligence Systems, Vol. 12 (11 2019). https://doi.org/10.2991/ijcis.d.191122.002Google ScholarCross Ref"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In CVPR. 770--778.Google Scholar"",""Kenneth B Kahn. 2014. Solving the problems of new product forecasting. Business Horizons, Vol. 57, 5 (2014), 607--615.Google ScholarCross Ref"",""Nadia Khomami. 2018. Burberry destroys pounds28m of stock to guard against counterfeits. https://www.theguardian.com/fashion/2018/jul/19/burberry-destroys-28m-stock-guard-against-counterfeitsGoogle Scholar"",""Spyros Makridakis, Steven C Wheelwright, and Rob J Hyndman. 2008. Forecasting methods and applications. John wiley \u0026 sons.Google Scholar"",""Elizabeth Paton. 2018. H\u0026M, a Fashion Giant, Has a Problem: $4.3 Billion in Unsold Clothes. https://www.nytimes.com/2018/03/27/business/hm-clothes-stock-sales.htmlGoogle Scholar"",""Pawan Kumar Singh, Yadunath Gupta, Nilpa Jha, and Aruna Rajan. 2019. Fashion Retail: Forecasting Demand for New Items. In The fourth international workshop on fashion and KDD. Anchorage, Alaska - USA.Google Scholar"",""Jesper Starn. 2017. A Power Plant Is Burning H\u0026M Clothes Instead of Coal. https://www.bloomberg.com/news/articles/2017-11-24/burning-h-m-rags-is-new-black-as-swedish-plant-ditches-coalGoogle Scholar"",""Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. 2016. Rethinking the inception architecture for computer vision. In CVPR.Google Scholar"",""Sébastien Thomassey. 2014. Sales forecasting in apparel and fashion industry: A review. In Intelligent fashion forecasting systems: Models and applications. Springer, 9--27.Google Scholar"",""Sébastien Thomassey and Antonio Fiordaliso. 2006. A hybrid sales forecasting system based on clustering and decision trees. Decision Support Systems, Vol. 42, 1 (2006), 408--421.Google ScholarDigital Library"",""Sébastien Thomassey and Michel Happiette. 2007. A neural clustering and classification system for sales forecasting of new apparel items. Applied Soft Computing, Vol. 7, 4 (2007), 1177--1187.Google ScholarDigital Library"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. (2017).Google Scholar"",""Ronald J Williams and David Zipser. 1989. A learning algorithm for continually running fully recurrent neural networks. Neural computation, Vol. 1, 2 (1989), 270--280.Google Scholar"",""Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhutdinov, Richard Zemel, and Yoshua Bengio. 2015. Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. (2015).Google Scholar""]"
https://doi.org/10.1145/3394486.3403363,Pest Management In Cotton Farms: An AI-System Case Study from the Global South,"Nearly 100 million families across the world rely on cotton farming for their livelihood. Cotton is particularly vulnerable to pest attacks, leading to overuse of pesticides, lost income for farmers, and in some cases farmer suicides. We address this problem by presenting a new solution for pesticide management that uses deep learning, smartphone cameras, inexpensive pest traps, existing digital pipelines, and agricultural extension-worker programs. Although generic, the platform is specifically designed to assist smallholder farmers in the developing world. In addition to outlining the solution, we consider the set of unique constraints this context places on it: data diversity, annotation challenges, shortcomings with traditional evaluation metrics, computing on low-resource devices, and deployment through intermediaries. This paper summarizes key lessons learned while developing and deploying the proposed solution. Such lessons may be applicable to other teams interested in building AI solutions for global development.","[{""name"":""Aman Dalmia"",""id"":""/profile/99659574048""},{""name"":""Jerome White"",""id"":""/profile/99659573835""},{""name"":""Ankit Chaurasia"",""id"":""/profile/99659574043""},{""name"":""Vishal Agarwal"",""id"":""/profile/99659574986""},{""name"":""Rajesh Jain"",""id"":""/profile/99659575061""},{""name"":""Dhruvin Vora"",""id"":""/profile/99659572902""},{""name"":""Balasaheb Dhame"",""id"":""/profile/99659574993""},{""name"":""Raghu Dharmaraju"",""id"":""/profile/99659574204""},{""name"":""Rahul Panicker"",""id"":""/profile/99659342516""},{""name"":""Aman Dalmia"",""id"":""/profile/99659574048""},{""name"":""Jerome White"",""id"":""/profile/99659573835""},{""name"":""Ankit Chaurasia"",""id"":""/profile/99659574043""},{""name"":""Vishal Agarwal"",""id"":""/profile/99659574986""},{""name"":""Rajesh Jain"",""id"":""/profile/99659575061""},{""name"":""Dhruvin Vora"",""id"":""/profile/99659572902""},{""name"":""Balasaheb Dhame"",""id"":""/profile/99659574993""},{""name"":""Raghu Dharmaraju"",""id"":""/profile/99659574204""},{""name"":""Rahul Panicker"",""id"":""/profile/99659342516""}]","[""A. Cross, N. Gupta, and et al. 2019. 99DOTS: A Low-Cost Approach to Monitoring and Improving Medication Adherence. In Intl. Conf. on Information and Comm. Technologies and Development. ACM, Article 15, bibinfonumpages12 pages.Google Scholar"",""W. Ding and G. Taylor. 2016. Automatic moth detection from trap images for pest management. Computers and Electronics in Agriculture, Vol. 123 (2016), 17--28.Google ScholarDigital Library"",""M. Haldar, M. Abdool, and et al. 2019. Applying Deep Learning to Airbnb Search. In Intl. Conf. on Knowledge Discovery \u0026 Data Mining. ACM, 1927--1935.Google Scholar"",""C. Hartung, A. Lerer, and et al. 2010. Open Data Kit: Tools to Build Information Services for Developing Regions. In Intl. Conf. on Information and Comm. Technologies and Development. ACM, 18:1--18:12.Google Scholar"",""M. Jain, P. Kumar, I. Bhansali, and et al. 2018. FarmChat: A Conversational Agent to Answer Farmer Queries. Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 2, 4, Article 170 (December 2018), 22 pages.Google Scholar"",""R. Kalamatianos, I. Karydis, D. Doukakis, and M. Avlonitis. 2018. DIRT: The Dacus Image Recognition Toolkit. Journal of Imaging, Vol. 4, 11 (2018).Google ScholarCross Ref"",""Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner. 1998. Gradient-based learning applied to document recognition. Proc. IEEE, Vol. 86, 11 (Nov 1998), 2278--2324.Google ScholarCross Ref"",""T. Lin, M. Maire, S. Belongie, and et al. 2014. Microsoft coco: Common objects in context. In European conf. on computer vision. Springer, 740--755.Google Scholar"",""L. Liu, R. Wang, C. Xie, and et al. 2019. PestNet: An End-to-End Deep Learning Approach for Large-Scale Multi-Class Pest Detection and Classification. IEEE Access, Vol. 7 (2019), 45301--45312.Google ScholarCross Ref"",""Q. Liu, J. Chao, T. Mahoney, and et al. 2018. Lessons Learned from Developing and Deploying a Large-Scale Employer Name Normalization System for Online Recruitment. In Intl. Conf. on Knowledge Discovery \u0026 Data Mining. ACM, 556--565.Google Scholar"",""W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C. Fu, and A. Berg. 2016a. SSD: Single shot multibox detector. In European Conf. on computer vision. Springer, 21--37.Google Scholar"",""Z. Liu, J. Gao, G. Yang, H. Zhang, and Y. He. 2016b. Localization and Classification of Paddy Field Pests using a Saliency Map and Deep Convolutional Neural Network. Scientific Reports, Vol. 6, 20410 (2016).Google Scholar"",""W. Ma, K. Nowocin, N. Marathe, and G. Chen. 2019. An Interpretable Produce Price Forecasting System for Small and Marginal Farmers in India Using Collaborative Filtering and Adaptive Nearest Neighbors. In Intl. Conf. on Information and Comm. Technologies and Development. ACM.Google Scholar"",""F. Mancini, J. Jiggins, and M. O'Malley. 2009. Reducing the Incidence of Acute Pesticide Poisoning by Educating Farmers on Integrated Pest Management in South India. Intl. J. of Occupational and Environmental Health, Vol. 15, 2 (2009), 143--151.Google ScholarCross Ref"",""F. Mancini, A. van Bruggen, and J. Jiggins. 2007. Evaluating cotton integrated pest management (IPM) farmer field school outcomes using the sustainable livelihoods approach in India. Experimental Agriculture, Vol. 43, 1 (2007), 97--112.Google ScholarCross Ref"",""Meena Menon. 2018. The pink bollworm menace adds to Maharashtra cotton farmers distress. Scroll (August 2018).Google Scholar"",""E. Mique and T. Palaoag. 2018. Rice Pest and Disease Detection Using Convolutional Neural Network. In Proceedings of the 2018 Intl. Conf. on Information Science and System. ACM, 147--151.Google Scholar"",""A. Moitra, V. Das, and et al. 2016. Design Lessons from Creating a Mobile-Based Community Media Platform in Rural India. In Intl. Conf. on Information and Comm. Technologies and Development. ACM, Article 14, bibinfonumpages11 pages.Google Scholar"",""P. Molchanov, S. Tyree, T. Karras, and et al. 2017. Pruning convolutional neural networks for resource efficient inference. In Conf. on Learning Representations.Google Scholar"",""N. Nam and P. Hung. 2018. Pest Detection on Traps Using Deep Convolutional Neural Networks. In Proceedings of the 2018 Intl. Conf. on Control and Computer Vision. ACM, 33--38.Google Scholar"",""A. Parikh, M. Raval, C. Parmar, and S. Chaudhary. 2016. Disease Detection and Severity Estimation in Cotton Plant from Unconstrained Images. In Intl. Conf. on Data Science and Advanced Analytics. IEEE, 594--601.Google Scholar"",""B. Prajapati, V. Dabhi, and H. Prajapati. 2016. A survey on detection and classification of cotton leaf diseases. In Intl. Conf. on Electrical, Electronics, and Optimization Techniques. 2499--2506.Google Scholar"",""P. Revathi and M. Hemalatha. 2012. Advance computing enrichment evaluation of cotton leaf spot disease detection using Image Edge detection. In Intl. Conf. on Computing, Comm. and Networking Technologies. 1--5.Google Scholar"",""A. Sarangdhar and V. Pawar. 2017. Machine learning regression technique for cotton leaf disease detection and controlling using IoT. In Intl. Conf. of Electronics, Comm. and Aerospace Technology, Vol. 2. 449--454.Google Scholar"",""M. Selvaraj, A. Vergara, H. Ruiz, and et al. 2019. AI-powered banana diseases and pest detection. Plant Methods, Vol. 15, 92 (2019).Google Scholar"",""Y. Shen, H. Zhou, J. Li, F. Jian, and D. Jayas. 2018. Detection of stored-grain insects using deep learning. Computers and Electronics in AgricultureOA, Vol. 145 (2018), 319--325.Google ScholarCross Ref"",""K. Simonyan and A. Zisserman. 2015. Very deep convolutional networks for large-scale image recognition. In Intl. Conf. on Learning Representations.Google Scholar"",""Y. Sun, X. Liu, M. Yuan, L. Ren, J. Wang, and Z. Chen. 2018. Automatic in-trap pest detection using deep learning for pheromone-based Dendroctonus valens monitoring. Biosystems Engineering, Vol. 176 (2018), 140--150.Google ScholarCross Ref"",""TechnoServe. 2019. Towards Doubling Cotton Farmer Income. Technical Report. The Sustainable Trade Initiative.Google Scholar"",""C. Valderrama, F. Marzbanrad, L. Stroux, and et al. 2018. Improving the Quality of Point of Care Diagnostics with Real-Time Machine Learning in Low Literacy LMIC Settings. In Conf. on Computing and Sustainable Societies. ACM, Article 2, bibinfonumpages11 pages.Google Scholar"",""X. Wu, C. Zhan, Y. Lai, M. Cheng, and J. Yang. 2019. IP102: A Large-Scale Benchmark Dataset for Insect Pest Recognition. In Conf. on Computer Vision and Pattern Recognition. IEEE, 8787--8796.Google Scholar"",""C. Xie, R. Wang, J. Zhang, and et al. 2018. Multi-level learning features for automatic classification of field crop pests. Computers and Electronics in Agriculture, Vol. 152 (2018), 233--241.Google ScholarCross Ref"",""C. Xie, J. Zhang, R. Li, J. Li, P. Hong, J. Xia, and P. Chen. 2015. Automatic classification for field crop insects via multiple-task sparse representation and multiple-kernel learning. Computers and Electronics in Agriculture, Vol. 119 (2015), 123--132.Google ScholarDigital Library"",""F. Yang, A. Kale, Y. Bubnov, and et al. 2017. Visual Search at eBay. In Intl. Conf. on Knowledge Discovery and Data Mining. ACM, 2101--2110.Google Scholar"",""Y. Zhang, P. Pan, Y. Zheng, and et al. 2018. Visual Search at Alibaba. In Intl. Conf. on Knowledge Discovery \u0026 Data Mining. ACM, 993--1001.Google Scholar""]"
https://doi.org/10.1145/3394486.3403364,TIES: Temporal Interaction Embeddings for Enhancing Social Media Integrity at Facebook,"Since its inception, Facebook has become an integral part of the online social community. People rely on Facebook to connect with others and build communities. As a result, it is paramount to protect the integrity of such a large network in a fast and scalable manner. In this paper, we present our efforts to protect various social media entities at Facebook from people who try to abuse our platform. We present a novel Temporal Interaction EmbeddingS (TIES) model that is designed to capture rogue social interactions and flag them for further suitable actions. TIES is a supervised, deep learning, production ready model at Facebook-scale networks. Prior works on integrity problems are mostly focused on capturing either only static or certain dynamic features of social entities. In contrast, TIES can capture both these variant behaviors in a unified model owing to the recent strides made in the domains of graph embedding and deep sequential pattern learning. To show the real-world impact of TIES, we present a few applications especially for preventing spread of misinformation, fake account detection, and reducing ads payment risks in order to enhance Facebook platform's integrity.","[{""name"":""Nima Noorshams"",""id"":""/profile/81460655192""},{""name"":""Saurabh Verma"",""id"":""/profile/99659574572""},{""name"":""Aude Hofleitner"",""id"":""/profile/99658675391""},{""name"":""Nima Noorshams"",""id"":""/profile/81460655192""},{""name"":""Saurabh Verma"",""id"":""/profile/99659574572""},{""name"":""Aude Hofleitner"",""id"":""/profile/99658675391""}]","[""[n. d.]. Facebook for Small Businesses. https://www.facebook.com/business/success/categories/small-business. Accessed: 2020-01-02.Google Scholar"",""[n. d.]. Facebook Transparency Report - Bullying and Harassment. https://transparency.facebook.com/community-standardsenforcement#bullying-and-harassment. Accessed: 2019-10-28.Google Scholar"",""[n. d.]. Facebook Transparency Report - Hate Speech. https://transparency.facebook.com/community-standards-enforcement#hatespeech. Accessed: 2019-10-28.Google Scholar"",""[n. d.]. TorchScript documentation. https://pytorch.org/docs/stable/jit.html. Accessed: 2020-01-03.Google Scholar"",""Michael Wiegand Anna Schmidt. 2017. A Survey on Hate Speech Detection using Natural Language Processing. In Proceedings of the Fifth International Workshop on Natural Language Processing for Social Media. 1--10.Google ScholarCross Ref"",""Kalina Bontcheva Maria Liakata Rob Procter Arkaitz Zubiaga, Ahmet Aker. 2018. Detection and Resolution of Rumours in Social Media: A Survey. ACM Computing Surveys (CSUR), Vol. 51, 32 (2018).Google Scholar"",""Umme Zahoora Aqsa Saeed Qureshi Asifullah Khan, Anabia Sohail. 2019. A Survey of the Recent Architectures of Deep Convolutional Neural Networks. ArXiv, Vol. abs/1901.06032 (2019).Google Scholar"",""Yazan Boshmaf, Dionysios Logothetis, Georgos Siganos, Jorge Ler'ia, Jose Lorenzo, Matei Ripeanu, and Konstantin Beznosov. 2015. Integro: Leveraging Victim Prediction for Robust Fake Account Detection in OSNs.. In NDSS, Vol. 15. 8--11.Google Scholar"",""Yeh-Cheng Chen and Shyhtsun Felix Wu. 2018. FakeBuster: A Robust Fake Account Detection by Activity Analysis. In Proceedings of 9th International Symposium on Parallel Architectures, Algorithms and Programming (PAAP). IEEE, 108--110.Google ScholarCross Ref"",""Achint Thomas Yashar Mehdad Yashar Mehdad Chikashi Nobata, Joel Tetreault. 2016. Abusive Language Detection in Online User Content. In Proceedings of 25th International World Wide Web Conference.Google Scholar"",""Armand Joulin Tomas Mikolov Douwe Kiela, Edouard Grave. 2018. Efficient Large-Scale Multi-Modal Classification. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence. 5198--5204.Google Scholar"",""Shu Wu Liang Wang Tieniu Tan Feng Yu, Qiang Liu. 2017. A Convolutional Approach for Misinformation Identification. In Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence. 3901--3907.Google Scholar"",""Björn Gambäck and Utpal Kumar Sikdar. 2017. Using Convolutional Neural Networks to Classify Hate-Speech. In Proceedings of the First Workshop on Abusive Language Online. 85--90.Google ScholarCross Ref"",""Anna Squicciarini Sarah Rajtmajer Christopher Griffin David Miller Cornelia Caragea Haoti Zhong, Hao Li. 2016. Content-Driven Detection of Cyberbullying on the Instagram Social Network. In Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence (IJCAI-16). 3952--3958.Google Scholar"",""Rahat Ibn Rafiq Richard Han Qin Lv Shivakant Mishra Homa Hosseinmardi, Sabrina Arredondo Mattson. 2015. Detection of Cyberbullying Incidents on the Instagram Social Network. Technical Report. University of Colorado at Boulder. https://arxiv.org/abs/1503.03909Google Scholar"",""Prasenjit Mitra Hamad Bin Khalifa Sejeong Kwon Bernard J. Jansen Kam-Fai Wong Meeyoung Cha Jing Ma, Wei Gao. 2016. Detecting rumors from microblogs with recurrent neural networks. In Proceedings of the 25th International Joint Conference on Artificial Intelligence. 3818--3824.Google Scholar"",""Catherine Havasi Henry Lieberman Karthik Dinakar, Birago Jones and Rosalind Picard. 2012. Common Sense Reasoning for Detection, Prevention, and Mitigation of Cyberbullying. ACM Transactions on Interactive Intelligent Systems, Vol. 2, 3 (2012).Google Scholar"",""Srijan Kumar, Xikun Zhang, and Jure Leskovec. 2019. Predicting dynamic embedding trajectory in temporal interaction networks. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 1269--1278.Google ScholarDigital Library"",""Adam Lerer, Ledell Wu, Jiajun Shen, Timothee Lacroix, Luca Wehrstedt, Abhijit Bose, and Alex Peysakhovich. 2019. PyTorch-BigGraph: A Large-scale Graph Embedding System. arXiv preprint arXiv:1903.12287 (2019).Google Scholar"",""Yixuan Li, Oscar Martinez, Xing Chen, Yi Li, and John E Hopcroft. 2016. In a world that counts: Clustering and detecting fake social engagement at scale. In Proceedings of the 25th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 111--120.Google ScholarDigital Library"",""Siamak Ravanbakhsh Barnabás Póczos Ruslan Salakhutdinov Alexander J. Smola Manzil Zaheer, Satwik Kottur. 2017. Deep Sets. In Advances in Neural Information Processing (NIPS).Google Scholar"",""Roeland Ordelman Maral Dadvar, Dolf Trieschnigg and Franciska de Jong. 2013. Improving cyberbullying detection with user context. In Proceedings of European Conference on Information Retrieval. 693--696.Google Scholar"",""Robin Morris Mihajlo Grbovic Vladan Radosavljevic Narayan Bhamidipati Nemanja Djuric, Jing Zhou. 2015. Hate Speech Detection with Comment Embeddings. In Proceedings of 24th International World Wide Web Conference. 29--30.Google Scholar"",""Shirin Nilizadeh, Francc ois Labrèche, Alireza Sedighian, Ali Zand, José Fernandez, Christopher Kruegel, Gianluca Stringhini, and Giovanni Vigna. 2017. Poised: Spotting twitter spam off the beaten paths. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. ACM, 1159--1174.Google ScholarDigital Library"",""Mauricio Perez Anderson Rocha Paulo Vitorino, Sandra Avila. 2018. Leveraging deep neural networks to fight child pornography in the age of social media. Journal of Visual Communication and Image Representation, Vol. 50 (2018), 303--313.Google ScholarCross Ref"",""Matthew L Williams Pete Burnap. 2016. Us and them: identifying cyber hate on Twitter across multiple protected characteristics. EPJ Data Science, Vol. 5, 11 (2016).Google Scholar"",""Manish Gupta Vasudeva Varma Pinkesh Badjatiya, Shashank Gupta. 2017. Deep Learning for Hate Speech Detection in Tweets. In Proceedings of the 26th International Conference on World Wide Web Companion. 759--760.Google ScholarDigital Library"",""Mona T Diab Sardar Hamidian. 2016. Rumor Identification and Belief Investigation on Twitter. In Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis. 3--8.Google ScholarCross Ref"",""Gianluca Stringhini, Pierre Mourlanne, Gregoire Jacob, Manuel Egele, Christopher Kruegel, and Giovanni Vigna. 2015. {EVILCOHORT}: Detecting Communities of Malicious Accounts on Online Services. In 24th $$USENIX$$ Security Symposium ($$USENIX$$ Security 15). 563--578.Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998--6008.Google Scholar"",""Cao Xiao, David Mandell Freeman, and Theodore Hwa. 2015. Detecting clusters of fake accounts in online social networks. In Proceedings of the 8th ACM Workshop on Artificial Intelligence and Security. ACM, 91--101.Google ScholarDigital Library"",""Chao Yang, Robert Harkreader, Jialong Zhang, Seungwon Shin, and Guofei Gu. 2012. Analyzing spammers' social networks for fun and profit: a case study of cyber criminal ecosystem on twitter. In Proceedings of the 21st international conference on World Wide Web. ACM, 71--80.Google ScholarDigital Library"",""Fang Yu Qifa Ke Yuan Yu Yan Chen Yao Zhao, Yinglian Xie and Eliot Gillum. 2009. BotGraph: Large Scale Spamming Botnet Detection. In 6th USENIX Symposium on Networked Systems Design and Implementation.Google Scholar"",""Sencun Zhu Heng Xu Ying Chen, Yilu Zhou. 2012. Detecting Offensive Language in Social Media to Protect Adolescent Online Safety. In 2012 International Conference on Privacy, Security, Risk and Trust and 2012 International Confernece on Social Computing. IEEE.Google ScholarDigital Library"",""Charles Elkan Zachary Lipton, John Berkowitz. 2015. A Critical Review of Recurrent Neural Networks for Sequence Learning. ArXiv, Vol. abs/1506.00019 (2015).Google Scholar"",""Dirk Hovy Zeerak Waseem. 2016. Hateful Symbols or Hateful People? Predictive Features for Hate Speech Detection on Twitter. In Proceedings of the NAACL Student Research Workshop. 88--93.Google Scholar""]"
https://doi.org/10.1145/3394486.3403365,Price Investment using Prescriptive Analytics and Optimization in Retail,"As the world's largest retailer, Walmart's core mission is to save people money so they can live better. We call the strategy we use to accomplish this goal our Every Day Low Price strategy. By keeping operational expenses as low as possible, we can continually apply a downward pressure on our prices, in turn increasing the amount of traffic, and ultimately, sales within our stores. In this paper, we apply Machine Learning (ML) algorithms and Operations Research techniques for forecasting and optimization to build a new price recommendation system, which improves our ability to generate price recommendations accurately and automatically. Comprised of a demand forecasting step, two optimizations, and causal inference analysis, our system was evaluated in the form of forecast backtests and live pricing experiments, both of which suggested that our approach was more effective than the current rule-based pricing system.","[{""name"":""Prakhar Mehrotra"",""id"":""/profile/99659574945""},{""name"":""Linsey Pang"",""id"":""/profile/99659573408""},{""name"":""Karthick Gopalswamy"",""id"":""/profile/99659288010""},{""name"":""Avinash Thangali"",""id"":""/profile/81309487194""},{""name"":""Timothy Winters"",""id"":""/profile/99658718183""},{""name"":""Ketki Gupte"",""id"":""/profile/99659573666""},{""name"":""Dnyanesh Kulkarni"",""id"":""/profile/99659574501""},{""name"":""Sunil Potnuru"",""id"":""/profile/99659574335""},{""name"":""Supreeth Shastry"",""id"":""/profile/99659574997""},{""name"":""Harshada Vuyyuri"",""id"":""/profile/99659574729""},{""name"":""Prakhar Mehrotra"",""id"":""/profile/99659574945""},{""name"":""Linsey Pang"",""id"":""/profile/99659573408""},{""name"":""Karthick Gopalswamy"",""id"":""/profile/99659288010""},{""name"":""Avinash Thangali"",""id"":""/profile/81309487194""},{""name"":""Timothy Winters"",""id"":""/profile/99658718183""},{""name"":""Ketki Gupte"",""id"":""/profile/99659573666""},{""name"":""Dnyanesh Kulkarni"",""id"":""/profile/99659574501""},{""name"":""Sunil Potnuru"",""id"":""/profile/99659574335""},{""name"":""Supreeth Shastry"",""id"":""/profile/99659574997""},{""name"":""Harshada Vuyyuri"",""id"":""/profile/99659574729""}]","[""Kimberly Lewis. The advantage brick-and-mortar stores will always have overonline retail, Sep 2018. https://www.forbes.com/sites/forbesnonprofitcouncil/2018/09/04/the-advantage-brick-and-mortar-stores-will-always-have-over-online-retail/#8b8b750772db.Google Scholar"",""Hanssens Srinivasan, Pauwels and Dekimpe. Who benefits from price promo-tions?, Aug 2014. https://hbr.org/2002/09/who-benefits-from-price-promotions.Google Scholar"",""About nielsen global connect and nielsen global media.What People Watch,Listen To and Buy. https://www.nielsen.com/eu/en/about-us/.Google Scholar"",""Harry Markowitz. Portfolio selection.The journal of finance, 7(1):77--91, 1952.Google Scholar"",""G.B. King, A.E. Lovell, L. Neufcourt, and F.M. Nunes. Direct comparison betweenbayesian and frequentist uncertainty quantification for nuclear reactions.PhysicaReview Letters, 122(23), Jun 2019. http://dx.doi.org/10.1103/PhysRevLett.122. 232502.Google Scholar"",""Kay H. Brodersen, Fabian Gallusser, Jim Koehler, Nicolas Remy, and Steven L. Scott. Inferring causal impact using bayesian structural time-series models. Annals of Applied Statistics, 9:247--274, 2015.Google ScholarCross Ref"",""Steven L. Scott. add.trig: Trigonometric seasonal state component in bsts: Bayesian structural time series, Sep 2019.Google Scholar"",""Andrew Harvey. Forecasting with Unobserved Components Time Series Models. In G. Elliott, C. Granger, and A. Timmermann, editors, Handbook of Economic Forecasting, volume 1 of Handbook of Economic Forecasting, chapter 7, pages 327--412. Elsevier, 2006.Google Scholar"",""Hemant Ishwaran and J. Sunil Rao. Spike and slab variable selection: Frequentist and bayesian strategies. Ann. Statist., 33(2):730--773, 04 2005. https://doi.org/10. 1214/009053604000001147.Google ScholarCross Ref"",""Package bsts. https://cran.r-project.org/web/packages/bsts/index.html.Google Scholar"",""P. M. Swamidass, editor. MAPE (mean absolute percentage error)MEAN ABSOLUTE PERCENTAGE ERROR (MAPE), pages 462--462. Springer US, Boston, MA, 2000. https://doi.org/10.1007/1-4020-0612-8_580.Google Scholar""]"
https://doi.org/10.1145/3394486.3403366,Climate Downscaling Using YNet: A Deep Convolutional Network with Skip Connections and Fusion,"Climate change is one of the major challenges to human beings in our time. It brings many unexpected disasters which cause drastic losses including lives and properties. To better understand climate change, scientists developed various Global Climate Models (GCMs) to simulate the global climate and make projections for future climate values. These global climate models have coarse grids (i.e., low resolutions both in space and time) due to limitations of computing power and simulation time. Although they are helpful in predicting large scale long term trend in climate, they are too coarse for impact analysis in smaller scales such as in regional or local scale. However, climate conditions in regional or local scale are very important in making decisions related to climate conditions such as infrastructure, transportation and evacuation, as they highly depend on small scale climate conditions. In this paper, we proposed YNet, a novel deep convolutional neural network (CNN) with skip connections and fusion capabilities to perform downscaling for climate variables, on multiple GCMs directly rather than on reanalysis data. We analyzed and compared our proposed method with four other methods on datasets of three climate variables: mean precipitation, and extreme values (maximum temperature and minimum temperature). The results show the effectiveness of the proposed method.","[{""name"":""Yumin Liu"",""id"":""/profile/99659455816""},{""name"":""Auroop R. Ganguly"",""id"":""/profile/81100305556""},{""name"":""Jennifer Dy"",""id"":""/profile/81100485643""},{""name"":""Yumin Liu"",""id"":""/profile/99659455816""},{""name"":""Auroop R. Ganguly"",""id"":""/profile/81100305556""},{""name"":""Jennifer Dy"",""id"":""/profile/81100485643""}]","[""Jose Caballero, Christian Ledig, Andrew Aitken, Alejandro Acosta, Johannes Totz, Zehan Wang, and Wenzhe Shi. 2017. Real-time video super-resolution with spatio-temporal networks and motion compensation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 4778--4787.Google ScholarCross Ref"",""P Caffrey and A Farmer. 2014. A review of Downscaling methods for climate change projections. Tetra Tech ARD (2014).Google Scholar"",""Kai Chen, Arlene M Fiore, Renjie Chen, Leiwen Jiang, Bryan Jones, Alexandra Schneider, Annette Peters, Jun Bi, Haidong Kan, and Patrick L Kinney. 2018. Future ozone-related acute excess mortality under climate and population change scenarios in China: A modeling study. PLoS medicine, Vol. 15, 7 (2018).Google Scholar"",""Christopher Daly, Michael Halbleib, Joseph I Smith, Wayne P Gibson, Matthew K Doggett, George H Taylor, Jan Curtis, and Phillip P Pasteris. 2008. Physiographically sensitive mapping of climatological temperature and precipitation across the conterminous United States. International Journal of Climatology: a Journal of the Royal Meteorological Society, Vol. 28, 15 (2008), 2031--2064.Google Scholar"",""Chao Dong, Chen Change Loy, Kaiming He, and Xiaoou Tang. 2014. Learning a deep convolutional network for image super-resolution. In European conference on computer vision. Springer, 184--199.Google ScholarCross Ref"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition. 770--778.Google ScholarCross Ref"",""Jiwon Kim, Jung Kwon Lee, and Kyoung Mu Lee. 2016a. Accurate image super-resolution using very deep convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern recognition. 1646--1654.Google ScholarCross Ref"",""Jiwon Kim, Jung Kwon Lee, and Kyoung Mu Lee. 2016b. Deeply-recursive convolutional network for image super-resolution. In Proceedings of the IEEE conference on computer vision and pattern recognition. 1637--1645.Google ScholarCross Ref"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Frank Kreienkamp, Andreas Paxian, Barbara Früh, Philip Lorenz, and Christoph Matulla. 2019. Evaluation of the empirical--statistical downscaling method EPISODES. Climate dynamics, Vol. 52, 1--2 (2019), 991--1026.Google Scholar"",""Wei-Sheng Lai, Jia-Bin Huang, Narendra Ahuja, and Ming-Hsuan Yang. 2017. Deep laplacian pyramid networks for fast and accurate super-resolution. In Proceedings of the IEEE conference on computer vision and pattern recognition. 624--632.Google ScholarCross Ref"",""Christian Ledig, Lucas Theis, Ferenc Huszár, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, et almbox. 2017. Photo-realistic single image super-resolution using a generative adversarial network. In Proceedings of the IEEE conference on computer vision and pattern recognition. 4681--4690.Google ScholarCross Ref"",""Zhen Li, Jinglei Yang, Zheng Liu, Xiaomin Yang, Gwanggil Jeon, and Wei Wu. 2019. Feedback network for image super-resolution. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 3867--3876.Google ScholarCross Ref"",""Bee Lim, Sanghyun Son, Heewon Kim, Seungjun Nah, and Kyoung Mu Lee. 2017. Enhanced deep residual networks for single image super-resolution. In Proceedings of the IEEE conference on computer vision and pattern recognition workshops. 136--144.Google ScholarCross Ref"",""Xiaojiao Mao, Chunhua Shen, and Yu-Bin Yang. 2016. Image restoration using very deep convolutional encoder-decoder networks with symmetric skip connections. In Advances in neural information processing systems. 2802--2810.Google Scholar"",""Q Miao, B Pan, H Wang, K Hsu, and S Sorooshian. 2019. Improving Monsoon Precipitation Prediction Using Combined Convolutional and Long Short Term Memory Neural Network, Water, 11, 977.Google ScholarCross Ref"",""Saptarshi Misra, Sudeshna Sarkar, and Pabitra Mitra. 2018. Statistical downscaling of precipitation using long short-term memory recurrent neural networks. Theoretical and Applied Climatology, Vol. 134, 3--4 (2018), 1179--1196.Google ScholarCross Ref"",""Augustus Odena, Vincent Dumoulin, and Chris Olah. 2016. Deconvolution and Checkerboard Artifacts. Distill (2016). https://doi.org/10.23915/distill.00003Google Scholar"",""Eduardo Rocha Rodrigues, Igor Oliveira, Renato Cunha, and Marco Netto. 2018. DeepDownscale: a deep learning strategy for high-resolution weather forecast. In 2018 IEEE 14th International Conference on e-Science (e-Science). IEEE, 415--422.Google ScholarCross Ref"",""Olaf Ronneberger, Philipp Fischer, and Thomas Brox. 2015. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computer-assisted intervention. Springer, 234--241.Google ScholarCross Ref"",""Wenzhe Shi, Jose Caballero, Ferenc Huszár, Johannes Totz, Andrew P Aitken, Rob Bishop, Daniel Rueckert, and Zehan Wang. 2016a. Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network. In Proceedings of the IEEE conference on computer vision and pattern recognition. 1874--1883.Google ScholarCross Ref"",""Wenzhe Shi, Jose Caballero, Lucas Theis, Ferenc Huszar, Andrew Aitken, Christian Ledig, and Zehan Wang. 2016b. Is the deconvolution layer the same as a convolutional layer? arXiv preprint arXiv:1609.07009 (2016).Google Scholar"",""Craig D Smith. 2008. The relationship between monthly precipitation and elevation in the Alberta foothills during the foothills orographic precipitation experiment. In Cold Region Atmospheric and Hydrologic Studies. The Mackenzie GEWEX Experience. Springer, 167--185.Google Scholar"",""Ying Tai, Jian Yang, and Xiaoming Liu. 2017. Image super-resolution via deep recursive residual network. In Proceedings of the IEEE conference on computer vision and pattern recognition. 3147--3155.Google ScholarCross Ref"",""Yusuke Tanaka, Tomoharu Iwata, Toshiyuki Tanaka, Takeshi Kurashima, Maya Okawa, and Hiroyuki Toda. 2019. Refining coarse-grained spatial data using auxiliary spatial data sets with various granularities. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 5091--5099.Google ScholarCross Ref"",""Duong Tran Anh, Song P Van, Thanh D Dang, and Long P Hoang. 2019. Downscaling rainfall using deep learning long short-term memory and feedforward neural network. International Journal of Climatology, Vol. 39, 10 (2019), 4170--4188.Google ScholarCross Ref"",""Sylwia Trzaska and Emilie Schnarr. 2014. A review of downscaling methods for climate change projections. United States Agency for International Development by Tetra Tech ARD (2014), 1--42.Google Scholar"",""Thomas Vandal, Evan Kodra, and Auroop R Ganguly. 2019. Intercomparison of machine learning methods for statistical downscaling: The case of daily and extreme precipitation. Theoretical and Applied Climatology, Vol. 137, 1--2 (2019), 557--570.Google ScholarCross Ref"",""Thomas Vandal, Evan Kodra, Sangram Ganguly, Andrew Michaelis, Ramakrishna Nemani, and Auroop R Ganguly. 2017. Deepsd: Generating high resolution climate change projections through single image super-resolution. In Proceedings of the 23rd acm sigkdd international conference on knowledge discovery and data mining. ACM, 1663--1672.Google ScholarDigital Library"",""John E Walsh, Uma S Bhatt, Jeremy S Littell, Matthew Leonawicz, Michael Lindgren, Thomas A Kurkowski, Peter A Bieniek, Richard Thoman, Stephen Gray, and T Scott Rupp. 2018. Downscaling of climate model output for Alaskan stakeholders. Environmental modelling \u0026 software, Vol. 110 (2018), 38--51.Google Scholar"",""Xintao Wang, Ke Yu, Chao Dong, and Chen Change Loy. 2018. Recovering realistic texture in image super-resolution by deep spatial feature transform. In Proceedings of the IEEE conference on computer vision and pattern recognition. 606--615.Google ScholarCross Ref"",""Zhaowen Wang, Ding Liu, Jianchao Yang, Wei Han, and Thomas Huang. 2015. Deep Networks for Image Super-Resolution With Sparse Prior. In The IEEE International Conference on Computer Vision (ICCV).Google Scholar"",""Andrew W Wood, Lai R Leung, Venkataramana Sridhar, and DP Lettenmaier. 2004. Hydrologic implications of dynamical and statistical approaches to downscaling climate model outputs. Climatic change, Vol. 62, 1--3 (2004), 189--216.Google Scholar"",""Mengchao Xu, Qian Liu, Dexuan Sha, Manzhu Yu, Daniel Q Duffy, William M Putman, Mark Carroll, Tsengdar Lee, and Chaowei Yang. 2020. PreciPatch: A Dictionary-based Precipitation Downscaling Method. Remote Sensing, Vol. 12, 6 (2020), 1030.Google ScholarCross Ref"",""Zhongfeng Xu, Ying Han, and Zongliang Yang. 2019. Dynamical downscaling of regional climate: A review of methods and limitations. Science China Earth Sciences, Vol. 62, 2 (2019), 365--375.Google ScholarCross Ref"",""Yulun Zhang, Yapeng Tian, Yu Kong, Bineng Zhong, and Yun Fu. 2018. Residual dense network for image super-resolution. In Proceedings of the IEEE conference on computer vision and pattern recognition. 2472--2481.Google ScholarCross Ref"",""Zachary Zobel, Jiali Wang, Donald J Wuebbles, and V Rao Kotamarthi. 2017. High-resolution dynamical downscaling ensemble projections of future extreme temperature distributions for the United States. Earth's Future, Vol. 5, 12 (2017), 1234--1251.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403367,Cracking the Black Box: Distilling Deep Sports Analytics,"This paper addresses the trade-off between Accuracy and Transparency for deep learning applied to sports analytics. Neural nets achieve great predictive accuracy through deep learning, and are popular in sports analytics. But it is hard to interpret a neural net model and harder still to extract actionable insights from the knowledge implicit in it. Therefore, we built a simple and transparent model that mimics the output of the original deep learning model and represents the learned knowledge in an explicit interpretable way. Our mimic model is a linear model tree, which combines a collection of linear models with a regression-tree structure. The tree version of a neural network achieves high fidelity, explains itself, and produces insights for expert stakeholders such as athletes and coaches. We propose and compare several scalable model tree learning heuristics to address the computational challenge from datasets with millions of data points.","[{""name"":""Xiangyu Sun"",""id"":""/profile/99659573839""},{""name"":""Jack Davis"",""id"":""/profile/99659574443""},{""name"":""Oliver Schulte"",""id"":""/profile/81100278948""},{""name"":""Guiliang Liu"",""id"":""/profile/99659335691""},{""name"":""Xiangyu Sun"",""id"":""/profile/99659573839""},{""name"":""Jack Davis"",""id"":""/profile/99659574443""},{""name"":""Oliver Schulte"",""id"":""/profile/81100278948""},{""name"":""Guiliang Liu"",""id"":""/profile/99659335691""}]","[""Peter Andras. 2002. The equivalence of support vector machine and regularization neural networks. Neural Processing Letters, Vol. 15, 2 (2002), 97--104.Google ScholarDigital Library"",""Machine Learning Group at the University of Waikato. 2020. Weka. https://www.cs.waikato.ac.nz/ml/weka/Google Scholar"",""Jimmy Ba and Rich Caruana. 2014. Do Deep Nets Really Need to be Deep?. In Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems 2014, December 8--13 2014, Montreal, Quebec, Canada. 2654--2662.Google Scholar"",""Przemyslaw Biecek. 2018. DALEX: Explainers for Complex Predictive Models in R . J. Mach. Learn. Res. , Vol. 19 (2018), 84:1--84:5. http://jmlr.org/papers/v19/18--416.htmlGoogle Scholar"",""Leo Breiman. 2017. Classification and regression trees .Routledge.Google Scholar"",""Brian Burke. 2019. DeepQB: deep learning with player tracking to quantify quarterback decision-making \u0026 performance. In Proceedings of the 2019 MIT Sloan Sports Analytics Conference .Google Scholar"",""Dan Cervone, Alexander D'Amour, Luke Bornn, and Kirk Goldsberry. 2014. POINTWISE: Predicting points and valuing decisions in real time with NBA optical tracking data. In Proceedings of the 8th MIT Sloan Sports Analytics Conference, Boston, MA, USA, Vol. 28. 3.Google Scholar"",""Zhengping Che, Sanjay Purushotham, Robinder G. Khemani, and Yan Liu. 2016. Interpretable Deep Models for ICU Outcome Prediction. In AMIA 2016, American Medical Informatics Association Annual Symposium, Chicago, IL, USA, November 12--16, 2016 .Google Scholar"",""Darren Dancey, Zuhair Bandar, and David McLean. 2007. Logistic Model Tree Extraction From Artificial Neural Networks. IEEE Trans. Systems, Man, and Cybernetics, Part B , Vol. 37, 4 (2007), 794--802. https://doi.org/10.1109/TSMCB.2007.895334Google ScholarDigital Library"",""Alin Dobra and Johannes Gehrke. 2002. SECRET: a scalable linear regression tree algorithm. In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining . 481--487.Google ScholarDigital Library"",""Javier Fernández, Luke Bornn, and Dan Cervone. 2019. Decomposing the immeasurable sport: A deep learning expected possession value framework for soccer. In 13th MIT Sloan Sports Analytics Conference .Google Scholar"",""Riccardo Guidotti, Anna Monreale, Stan Matwin, and Dino Pedreschi. 2019. Black Box Explanation by Learning Image Exemplars in the Latent Feature Space. (2019).Google Scholar"",""Tin Kam Ho. 1995. Random decision forests. In Proceedings of 3rd international conference on document analysis and recognition, Vol. 1. IEEE, 278--282.Google ScholarDigital Library"",""Elena Ikonomovska, Jo ao Gama, and Savs o Dvz eroski. 2011. Learning model trees from evolving data streams. Data mining and knowledge discovery , Vol. 23, 1 (2011), 128--168.Google Scholar"",""Ulf Johansson, Cecilia Sönströd, and Rikard König. 2014. Accurate and interpretable regression trees using oracle coaching. In 2014 IEEE Symposium on Computational Intelligence and Data Mining (CIDM). IEEE, 194--201.Google ScholarCross Ref"",""Austin FS Lee. 1992. Optimal sample sizes determined by two--sample welch's t test. Communications in Statistics-Simulation and Computation , Vol. 21, 3 (1992), 689--696.Google ScholarCross Ref"",""Guiliang Liu and Oliver Schulte. 2018. Deep Reinforcement Learning in Ice Hockey for Context-Aware Player Evaluation. In Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI 2018, July 13--19, 2018, Stockholm, Sweden . 3442--3448.Google ScholarCross Ref"",""Wei-Yin Loh. 2020. GUIDE Classification and Regression Trees and Forests. http://pages.stat.wisc.edu/ loh/guide.htmlGoogle Scholar"",""Tom M. Mitchell. 1997. Machine learning .McGraw-Hill. http://www.worldcat.org/oclc/61321007Google Scholar"",""Vito MR Muggeo. 2003. Estimating regression models with unknown break-points. Statistics in medicine , Vol. 22, 19 (2003), 3055--3071.Google Scholar"",""Gavin A Rummery and Mahesan Niranjan. 1994. On-line Q-learning using connectionist systems. Vol. 37. University of Cambridge, Department of Engineering Cambridge, UK.Google Scholar"",""Oliver Schulte, Zeyu Zhao, Mehrsan Javan, and Philippe Desaulniers. 2017. Apples-to-apples: Clustering and ranking NHL players using location information and scoring impact. In Proceedings of the MIT Sloan Sports Analytics Conference .Google Scholar"",""William TB Uther and Manuela M Veloso. 1998. Tree based discretization for continuous state space reinforcement learning. In Aaai/iaai . 769--774.Google Scholar"",""Celine Vens and Hendrik Blockeel. 2006. A simple regression based heuristic for learning model trees. Intelligent Data Analysis , Vol. 10, 3 (2006), 215--236.Google ScholarDigital Library"",""Jiaxuan Wang, Ian Fox, Jonathan Skaza, Nick Linck, Satinder Singh, and Jenna Wiens. 2018. The advantage of doubling: a deep reinforcement learning approach to studying the double team in the NBA. arXiv preprint arXiv:1803.02940 (2018).Google Scholar"",""Ronald Yurko, Samuel Ventura, and Maksim Horowitz. 2019. nflWAR: a reproducible method for offensive player evaluation in football. Journal of Quantitative Analysis in Sports , Vol. 15, 3 (2019), 163--183.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403368,Taming Pretrained Transformers for Extreme Multi-label Text Classification,"We consider the extreme multi-label text classification (XMC) problem: given an input text, return the most relevant labels from a large label collection. For example, the input text could be a product description on Amazon.com and the labels could be product categories. XMC is an important yet challenging problem in the NLP community. Recently, deep pretrained transformer models have achieved state-of-the-art performance on many NLP tasks including sentence classification, albeit with small label sets. However, naively applying deep transformer models to the XMC problem leads to sub-optimal performance due to the large output space and the label sparsity issue. In this paper, we propose X-Transformer, the first scalable approach to fine-tuning deep transformer models for the XMC problem. The proposed method achieves new state-of-the-art results on four XMC benchmark datasets. In particular, on a Wiki dataset with around 0.5 million labels, the [email protected] of X-Transformer is 77.28%, a substantial improvement over state-of-the-art XMC approaches Parabel (linear) and AttentionXML (neural), which achieve 68.70% and 76.95% [email protected], respectively. We further apply X-Transformer to a product2query dataset from Amazon and gained 10.7% relative improvement on [email protected] over Parabel.","[{""name"":""Wei-Cheng Chang"",""id"":""/profile/83058659857""},{""name"":""Hsiang-Fu Yu"",""id"":""/profile/81557688556""},{""name"":""Kai Zhong"",""id"":""/profile/99659030609""},{""name"":""Yiming Yang"",""id"":""/profile/81351593798""},{""name"":""Inderjit S. Dhillon"",""id"":""/profile/81100098715""},{""name"":""Wei-Cheng Chang"",""id"":""/profile/83058659857""},{""name"":""Hsiang-Fu Yu"",""id"":""/profile/81557688556""},{""name"":""Kai Zhong"",""id"":""/profile/99659030609""},{""name"":""Yiming Yang"",""id"":""/profile/81351593798""},{""name"":""Inderjit S. Dhillon"",""id"":""/profile/81100098715""}]","[""Rohit Babbar and Bernhard Schölkopf. 2017. DiSMEC: distributed sparse machines for extreme multi-label classification. In WSDM .Google Scholar"",""Rohit Babbar and Bernhard Schölkopf. 2019. Data scarcity, robustness and extreme multi-label classification. Machine Learning (2019), 1--23.Google Scholar"",""Kush Bhatia, Himanshu Jain, Purushottam Kar, Manik Varma, and Prateek Jain. 2015. Sparse local embeddings for extreme multi-label classification. In NIPS .Google Scholar"",""Wei-Cheng Chang, Felix X. Yu, Yin-Wen Chang, Yiming Yang, and Sanjiv Kumar. 2020. Pre-training Tasks for Embedding-based Large-scale Retrieval. In International Conference on Learning Representations .Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. Bert: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL) .Google Scholar"",""Chuan Guo, Ali Mousavi, Xiang Wu, Daniel N Holtmann-Rice, Satyen Kale, Sashank Reddi, and Sanjiv Kumar. 2019. Breaking the Glass Ceiling for Embedding-Based Classifiers for Large Output Spaces. In Advances in Neural Information Processing Systems. 4944--4954.Google Scholar"",""Himanshu Jain, Venkatesh Balasubramanian, Bhanu Chunduri, and Manik Varma. 2019. Slice: Scalable Linear Extreme Classifiers Trained on 100 Million Labels for Related Searches. In Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining. ACM, 528--536.Google ScholarDigital Library"",""Himanshu Jain, Yashoteja Prabhu, and Manik Varma. 2016. Extreme multi-label loss functions for recommendation, tagging, ranking \u0026 other missing label applications. In KDD .Google Scholar"",""Sujay Khandagale, Han Xiao, and Rohit Babbar. 2019. Bonsai-Diverse and Shallow Trees for Extreme Multi-label Classification. arXiv preprint arXiv:1904.08249 (2019).Google Scholar"",""Diederik Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. In Proceedings of the International Conference on Learning Representations .Google Scholar"",""Kenton Lee, Ming-Wei Chang, and Kristina Toutanova. 2019. Latent retrieval for weakly supervised open domain question answering. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL) .Google ScholarCross Ref"",""Jingzhou Liu, Wei-Cheng Chang, Yuexin Wu, and Yiming Yang. 2017. Deep learning for extreme multi-label text classification. In Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM, 115--124.Google ScholarDigital Library"",""Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. RoBERTa: A Robustly Optimized BERT Pretraining Approach. arXiv preprint arXiv:1907.11692 (2019).Google Scholar"",""Mikko I Malinen and Pasi Fr\""anti. 2014. Balanced k-means for clustering. In Joint IAPR International Workshops on Statistical Techniques in Pattern Recognition (SPR) and Structural and Syntactic Pattern Recognition (SSPR). Springer, 32--41.Google ScholarDigital Library"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems. 3111--3119.Google Scholar"",""Jinseok Nam, Eneldo Loza Menc'ia, Hyunwoo J Kim, and Johannes Fürnkranz. 2017. Maximizing Subset Accuracy with Recurrent Neural Networks in Multi-label Classification. In NIPS .Google Scholar"",""Ioannis Partalas, Aris Kosmopoulos, Nicolas Baskiotis, Thierry Artieres, George Paliouras, Eric Gaussier, Ion Androutsopoulos, Massih-Reza Amini, and Patrick Galinari. 2015. LSHTC: A benchmark for large-scale text classification. arXiv preprint arXiv:1503.08581 (2015).Google Scholar"",""Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove: Global vectors for word representation. In EMNLP. 1532--1543.Google Scholar"",""Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. Deep contextualized word representations. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL) .Google ScholarCross Ref"",""Yashoteja Prabhu, Anil Kag, Shrutendra Harsola, Rahul Agrawal, and Manik Varma. 2018. Parabel: Partitioned label trees for extreme classification with application to dynamic search advertising. In WWW .Google ScholarDigital Library"",""Yashoteja Prabhu and Manik Varma. 2014. Fastxml: A fast, accurate and stable tree-classifier for extreme multi-label learning. In KDD .Google ScholarDigital Library"",""Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 2018. Improving language understanding by generative pre-training. (2018).Google Scholar"",""Sashank J Reddi, Satyen Kale, Felix Yu, Dan Holtmann-Rice, Jiecao Chen, and Sanjiv Kumar. 2019. Stochastic Negative Mining for Learning with Large Output Spaces. In AISTATS .Google Scholar"",""Yukihiro Tagami. 2017. AnnexML: Approximate nearest neighbor search for extreme multi-label classification. In Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 455--464.Google ScholarDigital Library"",""Manik Varma. 2019. The Extreme Classification Repository: Multi-label Datasets \u0026 Code. http://manikvarma.org/downloads/XC/XMLRepository.html .Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In NIPS .Google Scholar"",""Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R Bowman. 2018. Glue: A multi-task benchmark and analysis platform for natural language understanding. arXiv preprint arXiv:1804.07461 (2018).Google Scholar"",""Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R'emi Louf, Morgan Funtowicz, and Jamie Brew. 2019. HuggingFace's Transformers: State-of-the-art Natural Language Processing. ArXiv , Vol. abs/1910.03771 (2019).Google Scholar"",""Marek Wydmuch, Kalina Jasinska, Mikhail Kuznetsov, Róbert Busa-Fekete, and Krzysztof Dembczynski. 2018. A no-regret generalization of hierarchical softmax to extreme multi-label classification. In NIPS .Google Scholar"",""Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, and Quoc V Le. 2019. XLNet: Generalized Autoregressive Pretraining for Language Understanding. In NIPS .Google Scholar"",""Ian EH Yen, Xiangru Huang, Wei Dai, Pradeep Ravikumar, Inderjit Dhillon, and Eric Xing. 2017. PPDsparse: A parallel primal-dual sparse method for extreme classification. In KDD. ACM.Google Scholar"",""Ronghui You, Zihan Zhang, Ziye Wang, Suyang Dai, Hiroshi Mamitsuka, and Shanfeng Zhu. 2019. AttentionXML: Label Tree-based Attention-Aware Deep Model for High-Performance Extreme Multi-Label Text Classification. In Advances in Neural Information Processing Systems. 5812--5822.Google Scholar""]"
https://doi.org/10.1145/3394486.3403369,Prediction of Hourly Earnings and Completion Time on a Crowdsourcing Platform,"We study the problem of predicting future hourly earnings and task completion time for a crowdsourcing platform user who sees the list of available tasks and wants to select one of them to execute. Namely, for each task shown in the list, one needs to have an estimated value of the user's performance (i.e., hourly earnings and completion time) that will be if she selects this task. We address this problem on real crowd tasks completed on one of the global crowdsourcing marketplaces by (1) conducting a survey and an A/B test on real users; the results confirm the dominance of monetary incentives and importance of knowledge on hourly earnings for users; (2) an in-depth analysis of user behavior that shows that the prediction problem is challenging: (a) users and projects are highly heterogeneous, (b) there exists the so-called ""learning effect"" of a user selected a new task; and (3) the solution to the problem of predicting user performance that demonstrates improvement of prediction quality by up to 25% for hourly earnings and up to $32%$ completion time w.r.t. a naive baseline which is based solely on historical performance of users on tasks. In our experimentation, we use data about 18 million real crowdsourcing tasks performed by $161$ thousand users on the crowd platform; we publish this dataset. The hourly earning prediction has been deployed in Yandex.Toloka.","[{""name"":""Anna Lioznova"",""id"":""/profile/99659573108""},{""name"":""Alexey Drutsa"",""id"":""/profile/99658681639""},{""name"":""Vladimir Kukushkin"",""id"":""/profile/99658740732""},{""name"":""Anastasia Bezzubtseva"",""id"":""/profile/87259001257""},{""name"":""Anna Lioznova"",""id"":""/profile/99659573108""},{""name"":""Alexey Drutsa"",""id"":""/profile/99658681639""},{""name"":""Vladimir Kukushkin"",""id"":""/profile/99658740732""},{""name"":""Anastasia Bezzubtseva"",""id"":""/profile/87259001257""}]","[""R. Budylin, A. Drutsa, G. Gusev, P. Serdyukov, and I. Yashkov. 2018. Online evaluation for effective web service development. Tutorial at KDD'2018.Google Scholar"",""Ricardo Buettner. 2015. A systematic literature review of crowdsourcing research from a human resource management perspective. In HICSS.Google Scholar"",""Chris Callison-Burch. 2014. Crowd-Workers: Aggregating Information Across Turkers to Help Them Find Higher Paying Work. In HCOMP.Google Scholar"",""Justin Cheng, Jaime Teevan, and Michael S. Bernstein. 2015. Measuring Crowdsourcing Effort with Error-Time Curves. In CHI.Google Scholar"",""Djellel Eddine Difallah, Michele Catasta, Gianluca Demartini, Panagiotis G Ipeirotis, and Philippe Cudré-Mauroux. 2015. The dynamics of micro-task crowdsourcing: The case of amazon mturk. In WWW. 238--247.Google Scholar"",""A. Drutsa, V. Farafonova, V. Fedorova, O. Megorskaya, E. Zerminova, and O. Zhilinskaya. 2019. Practice of Efficient Data Collection via Crowdsourcing at Large-Scale. Tutorial at KDD'2019.Google Scholar"",""A. Drutsa, V. Fedorova, D. Ustalov, O. Megorskaya, E. Zerminova, and D. Baidakova. 2020 a. Practice of Efficient Data Collection via Crowdsourcing: Aggregation, Incremental Relabelling, and Pricing. In WSDM'2020. 873--876.Google Scholar"",""Alexey Drutsa, Gleb Gusev, and Pavel Serdyukov. 2017. Using the Delay in a Treatment Effect to Improve Sensitivity and Preserve Directionality of Engagement Metrics in A/B Experiments. In WWW'2017.Google ScholarDigital Library"",""A. Drutsa, D. Rogachevsky, O. Megorskaya, A. Slesarev, E. Zerminova, D. Baidakova, A. Rykov, and A. Golomedov. 2020 b. Efficient Data Annotation for Self-Driving Cars via Crowdsourcing on a Large-Scale. In CVPR'2020.Google Scholar"",""Alexey Drutsa, Anna Ufliand, and Gleb Gusev. 2015. Practical Aspects of Sensitivity in Online Experimentation with User Engagement Metrics. In CIKM'2015.Google Scholar"",""A. Drutsa, D. Ustalov, E. Zerminova, V. Fedorova, O. Megorskaya, and D. Baidakova. 2020 c. Crowdsourcing Practice for Efficient Data Labeling: Aggregation, Incremental Relabeling, and Pricing. In SIGMOD'2020. 2623--2627.Google Scholar"",""David S Evans and Richard Schmalensee. 2016. Matchmakers: the new economics of multisided platforms. Harvard Business Review Press.Google Scholar"",""Siamak Faradani, Björn Hartmann, and Panagiotis G Ipeirotis. 2011. What's the Right Price? Pricing Tasks for Finishing on Time. Human comp., Vol. 11 (2011), 11.Google Scholar"",""Tanya Goyal, Tyler McDonnell, Mucahid Kutlu, Tamer Elsayed, and Matthew Lease. 2018. Your Behavior Signals Your Reliability: Modeling Crowd Behavioral Traces to Ensure Quality Relevance Annotations. In HCOMP.Google Scholar"",""B.V Hanrahan, D. Martin, J. Willamowski, and J.M Carroll. 2018. Investigating the Amazon Mechanical Turk Market Through Tool Design. CSCW, Vol. 27, 3--6 (2018).Google Scholar"",""Benjamin V Hanrahan, Jutta K Willamowski, Saiganesh Swaminathan, and David B Martin. 2015. TurkBench: Rendering the market for Turkers. In HFCS.Google Scholar"",""Kotaro Hara, Abigail Adams, Kristy Milland, Saiph Savage, Chris Callison-Burch, and Jeffrey P Bigham. 2018. A Data-Driven Analysis of Workers' Earnings on Amazon Mechanical Turk. In CHI.Google Scholar"",""Simo Hosio, Jorge Goncalves, Vili Lehdonvirta, Denzil Ferreira, and Vassilis Kostakos. 2014. Situated crowdsourcing using a market model. In UIST. ACM.Google Scholar"",""Panagiotis G Ipeirotis. 2010. Analyzing the amazon mechanical turk marketplace. XRDS: Crossroads, The ACM Magazine for Students, Vol. 17, 2 (2010), 16--21.Google ScholarDigital Library"",""Lilly C Irani and M Silberman. 2013. Turkopticon: Interrupting worker invisibility in amazon mechanical turk. In CHI.Google ScholarDigital Library"",""T. Kaplan, S. Saito, K. Hara, and J. P Bigham. 2018. Striving to earn more: a survey of work strategies and tool use among crowd workers. In HCOMP'2018.Google Scholar"",""R. Kohavi, R. Longbotham, D. Sommerfield, and R. M Henne. 2009. Controlled experiments on the web: survey and practical guide. DMKD, Vol. 18, 1 (2009).Google ScholarDigital Library"",""Pavel Kucherbaev, Florian Daniel, Stefano Tranquillini, and Maurizio Marchese. 2016. ReLauncher: crowdsourcing micro-tasks runtime controller. In CSCWSC.Google Scholar"",""Adam Marcus, Aditya Parameswaran, et almbox. 2015. Crowdsourced data management: Industry and academic perspectives. FTD, Vol. 6, 1--2 (2015), 1--161.Google ScholarDigital Library"",""David Martin, Benjamin V Hanrahan, Jacki O'Neill, and Neha Gupta. 2014. Being a turker. In CSCWSC.Google Scholar"",""P. Minder, S. Seuken, A. Bernstein, and M. Zollinger. 2012. Crowdmanager-combinatorial allocation and pricing of crowdsourcing tasks with time constraints. In Workshop on Social Computing and User Generated Content in ACM EC.Google Scholar"",""Liudmila Prokhorenkova, Gleb Gusev, Aleksandr Vorobev, Anna Veronika Dorogush, and Andrey Gulin. 2018. CatBoost: unbiased boosting with categorical features. In Advances in Neural Information Processing Systems. 6638--6648.Google Scholar"",""John Prpić, Araz Taeihagh, and James Melton. 2015. The fundamentals of policy crowdsourcing. Policy \u0026 Internet, Vol. 7, 3 (2015), 340--361.Google ScholarCross Ref"",""Mejdl Safran and Dunren Che. 2018. Efficient Learning-Based Recommendation Algorithms for Top-N Tasks and Top-N Workers in Large-Scale Crowdsourcing Systems. ACM Transactions on Information Systems (TOIS), Vol. 37, 1 (2018), 2.Google Scholar"",""Susumu Saito, Chun-Wei Chiang, Saiph Savage, Teppei Nakano, Tetsunori Kobayashi, and Jeffrey P Bigham. 2019. TurkScanner: Predicting the Hourly Wage of Microtasks. In The World Wide Web Conference. ACM, 3187--3193.Google Scholar"",""Thimo Schulze, Simone Krug, and Martin Schader. 2012. Workers' task choice in crowdsourcing and human computation markets. (2012).Google Scholar"",""Jing Wang, Siamak Faridani, and Panagiotis Ipeirotis. 2011. Estimating the completion time of crowdsourced tasks using survival analysis models. Crowdsourcing for search and data mining (CSDM 2011), Vol. 31 (2011).Google Scholar"",""Jing Wang and Panagiotis Ipeirotis. 2013. A framework for quality assurance in crowdsourcing. (2013).Google Scholar"",""Chaolun Xia and Shan Muthukrishnan. 2017. Revenue-Maximizing Stable Pricing in Online Labor Markets. (2017).Google Scholar"",""Yandex. Since 2014. Yandex.Toloka. http://toloka.aiGoogle Scholar"",""Yandex.Toloka. 2020. Dataset \""Toloka Users \u0026 Tasks\"". https://toloka.ai/datasetsGoogle Scholar"",""Y. Zhang, H. Qin, B. Li, J. Wang, S. Lee, and Zh. Huang. 2018. Truthful mechanism for crowdsourcing task assignment. Tsinghua Science and Technology, Vol. 23, 6 (2018).Google Scholar""]"
https://doi.org/10.1145/3394486.3403370,SimClusters: Community-Based Representations for Heterogeneous Recommendations at Twitter,"Personalized recommendation products at Twitter target a multitude of heterogeneous items: Tweets, Events, Topics, Hashtags, and users. Each of these targets varies in their cardinality (which affects the scale of the problem) and their ""shelf life'' (which constrains the latency of generating the recommendations). Although Twitter has built a variety of recommendation systems before dating back a decade, solutions to the broader problem were mostly tackled piecemeal. In this paper, we present SimClusters, a general-purpose representation layer based on overlapping communities into which users as well as heterogeneous content can be captured as sparse, interpretable vectors to support a multitude of recommendation tasks. We propose a novel algorithm for community discovery based on Metropolis-Hastings sampling, which is both more accurate and significantly faster than off-the-shelf alternatives. SimClusters scales to networks with billions of users and has been effective across a variety of deployed applications at Twitter.","[{""name"":""Venu Satuluri"",""id"":""/profile/81375618822""},{""name"":""Yao Wu"",""id"":""/profile/99659573359""},{""name"":""Xun Zheng"",""id"":""/profile/99658714929""},{""name"":""Yilei Qian"",""id"":""/profile/99659574168""},{""name"":""Brian Wichers"",""id"":""/profile/99659574772""},{""name"":""Qieyun Dai"",""id"":""/profile/99659573764""},{""name"":""Gui Ming Tang"",""id"":""/profile/99659573680""},{""name"":""Jerry Jiang"",""id"":""/profile/99659077889""},{""name"":""Jimmy Lin"",""id"":""/profile/81471640432""},{""name"":""Venu Satuluri"",""id"":""/profile/81375618822""},{""name"":""Yao Wu"",""id"":""/profile/99659573359""},{""name"":""Xun Zheng"",""id"":""/profile/99658714929""},{""name"":""Yilei Qian"",""id"":""/profile/99659574168""},{""name"":""Brian Wichers"",""id"":""/profile/99659574772""},{""name"":""Qieyun Dai"",""id"":""/profile/99659573764""},{""name"":""Gui Ming Tang"",""id"":""/profile/99659573680""},{""name"":""Jerry Jiang"",""id"":""/profile/99659077889""},{""name"":""Jimmy Lin"",""id"":""/profile/81471640432""}]","[""Edoardo M. Airoldi, David M. Blei, Stephen E. Fienberg, and Eric P. Xing. 2008. Mixed Membership Stochastic Blockmodels. JMLR, Vol. 9 (June 2008), 1981--2014.Google Scholar"",""Iván Cantador and Paolo Cremonesi. 2014. Tutorial on Cross-domain Recommender Systems. In RecSys '14. 401--402.Google Scholar"",""Andrzej Cichocki and Anh-Huy Phan. 2009. Fast Local Algorithms for Large Scale Nonnegative Matrix and Tensor Factorizations. IEICE Transactions, Vol. 92-A (03 2009), 708--721.Google ScholarCross Ref"",""Graham Cormode and Shan Muthukrishnan. 2005. An improved data stream summary: the count-min sketch and its applications. Journal of Algorithms, Vol. 55, 1 (2005), 58--75.Google ScholarDigital Library"",""Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep Neural Networks for YouTube Recommendations. In RecSys '16. 191--198.Google Scholar"",""Maurizio Ferrari Dacrema, Paolo Cremonesi, and Dietmar Jannach. 2019. Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches. In Recsys'19. 101--109.Google Scholar"",""Inderjit S. Dhillon, Yuqiang Guan, and Brian Kulis. 2007. Weighted Graph Cuts Without Eigenvectors A Multilevel Approach. IEEE Trans. Pattern Anal. Mach. Intell., Vol. 29, 11 (Nov. 2007), 1944--1957.Google ScholarDigital Library"",""Ali Mamdouh Elkahky, Yang Song, and Xiaodong He. 2015. A multi-view deep learning approach for cross domain user modeling in recommendation systems. In WWW'15. 278--288.Google ScholarDigital Library"",""Ajeet Grewal, Jerry Jiang, Gary Lam, Tristan Jung, Lohith Vuddemarri, Quannan Li, Aaditya Landge, and Jimmy Lin. 2018. Recservice: Distributed Real-Time Graph Processing at Twitter. In HotCloud'18. USENIX Association, 3.Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. Node2Vec: Scalable Feature Learning for Networks. In KDD '16. 855--864.Google ScholarDigital Library"",""Pankaj Gupta, Ashish Goel, Jimmy Lin, Aneesh Sharma, Dong Wang, and Reza Zadeh. 2013. WTF: The Who to Follow Service at Twitter. In WWW '13. 505--514.Google ScholarDigital Library"",""Pankaj Gupta, Venu Satuluri, Ajeet Grewal, Siva Gurumurthy, Volodymyr Zhabiuk, Quannan Li, and Jimmy Lin. 2014. Real-Time Twitter Recommendation: Online Motif Detection in Large Dynamic Graphs. Proceedings of the VLDB Endowment, Vol. 7, 13 (2014), 1379--1380.Google ScholarDigital Library"",""William L. Hamilton, Rex Ying, and Jure Leskovec. 2017. Inductive Representation Learning on Large Graphs. In NIPS'17. 1025--1035.Google Scholar"",""Krishna Kamath, Aneesh Sharma, Dong Wang, and Zhijun Yin. 2014. Realgraph: User interaction prediction at twitter. In User Engagement Optimization Workshop at KDD'14.Google Scholar"",""Richard M Karp, Scott Shenker, and Christos H Papadimitriou. 2003. A simple algorithm for finding frequent elements in streams and bags. ACM Transactions on Database Systems (TODS), Vol. 28, 1 (2003), 51--55.Google ScholarDigital Library"",""Thomas N Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional networks. In ICLR'17.Google Scholar"",""Jon M. Kleinberg. 1999. Authoritative Sources in a Hyperlinked Environment. J. ACM, Vol. 46, 5 (Sept. 1999), 604--632.Google ScholarDigital Library"",""Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix Factorization Techniques for Recommender Systems. Computer, Vol. 42, 8 (Aug. 2009), 30--37.Google ScholarDigital Library"",""Jérôme Kunegis. 2013. KONECT -- The Koblenz Network Collection. In Proc. Int. Conf. on World Wide Web Companion. 1343--1350.Google Scholar"",""R. Lempel and S. Moran. 2001. SALSA: The Stochastic Approach for Link-Structure Analysis. ACM Trans. Inf. Syst., Vol. 19, 2 (April 2001), 131--160.Google ScholarDigital Library"",""Jure Leskovec and Rok Sosivc. 2016. SNAP: A General-Purpose Network Analysis and Graph-Mining Library. ACM Transactions on Intelligent Systems and Technology (TIST), Vol. 8, 1 (2016), 1.Google ScholarDigital Library"",""Dawen Liang, Rahul G. Krishnan, Matthew D. Hoffman, and Tony Jebara. 2018. Variational Autoencoders for Collaborative Filtering. In WWW '18. 689--698.Google Scholar"",""David Melamed. 2014. Community Structures in Bipartite Networks: A Dual-Projection Approach. PLOS ONE, Vol. 9, 5 (05 2014), 1--5.Google ScholarCross Ref"",""Feng Niu, Benjamin Recht, Christopher Re, and Stephen J. Wright. 2011. HOGWILD!: A Lock-free Approach to Parallelizing Stochastic Gradient Descent. In NIPS'11. 693--701.Google ScholarDigital Library"",""F. et. al. Pedregosa. 2011. Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, Vol. 12 (2011), 2825--2830.Google ScholarDigital Library"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In KDD'14. 701--710.Google ScholarDigital Library"",""Steffen Rendle. 2010. Factorization machines. In ICDM'10. IEEE, 995--1000.Google ScholarDigital Library"",""Venu Satuluri and Srinivasan Parthasarathy. 2011. Symmetrizations for Clustering Directed Graphs. In EDBT/ICDT '11. 343--354.Google Scholar"",""Venu Satuluri, Srinivasan Parthasarathy, and Yiye Ruan. 2011. Local Graph Sparsification for Scalable Clustering. In SIGMOD '11. 721--732.Google Scholar"",""Sebastian Schelter, Venu Satuluri, and Reza Bosagh Zadeh. 2014. Factorbird - a Parameter Server Approach to Distributed Matrix Factorization. ArXiv, Vol. abs/1411.0602 (2014).Google Scholar"",""Aneesh Sharma, Jerry Jiang, Praveen Bommannavar, Brian Larson, and Jimmy Lin. 2016. GraphJet: Real-time Content Recommendations at Twitter. Proc. VLDB Endow., Vol. 9, 13 (Sept. 2016), 1281--1292.Google ScholarDigital Library"",""Aneesh Sharma, C. Seshadhri, and Ashish Goel. 2017. When Hashes Met Wedges: A Distributed Algorithm for Finding High Similarity Vectors. In WWW '17. 431--440.Google ScholarDigital Library"",""Charalampos Tsourakakis. 2015. Provably Fast Inference of Latent Features from Networks: With Applications to Learning Social Circles and Multilabel Classification. In WWW'15. 1111--1121.Google ScholarDigital Library"",""Jaewon Yang and Jure Leskovec. 2013. Overlapping Community Detection at Scale: A Nonnegative Matrix Factorization Approach. In WSDM'13. 587--596.Google ScholarDigital Library"",""Jaewon Yang, Julian McAuley, and Jure Leskovec. 2014. Detecting Cohesive and 2-Mode Communities Indirected and Undirected Networks. In WSDM'14. 323--332.Google ScholarDigital Library"",""Xinyang Yi, Ji Yang, Lichan Hong, Derek Zhiyuan Cheng, Lukasz Heldt, Aditee Kumthekar, Zhe Zhao, Li Wei, and Ed Chi. 2019. Sampling-bias-corrected neural modeling for large corpus item recommendations. In Recsys'19. 269--277.Google Scholar"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L. Hamilton, and Jure Leskovec. 2018. Graph Convolutional Neural Networks for Web-Scale Recommender Systems. In KDD '18. 974--983.Google Scholar"",""Xiao Yu, Xiang Ren, Yizhou Sun, Quanquan Gu, Bradley Sturt, Urvashi Khandelwal, Brandon Norick, and Jiawei Han. 2014. Personalized entity recommendation: A heterogeneous information network approach. In WSDM'14. 283--292.Google ScholarDigital Library"",""Yongfeng Zhang, Qingyao Ai, Xu Chen, and W Bruce Croft. 2017. Joint representation learning for top-n recommendation with heterogeneous information sources. In CIKM'17. 1449--1458.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403371,Time-Aware User Embeddings as a Service,"Digital media companies typically collect rich data in the form of sequences of online user activities. Such data is used in various applications, involving tasks ranging from click or conversion prediction to recommendation or user segmentation. Nonetheless, each application depends upon specialized feature engineering that requires a lot of effort and typically disregards the time-varying nature of the online user behavior. Learning time-preserving vector representations of users (user embeddings), irrespective of a specific task, would save redundant effort and potentially lead to higher embedding quality. To that end, we address the limitations of the current state-of-the-art self-supervised methods for task-independent (unsupervised) sequence embedding, and propose a novel Time-Aware Sequential Autoencoder (TASA) that accounts for the temporal aspects of sequences of activities. The generated embeddings are intended to be readily accessible for many problem formulations and seamlessly applicable to desired tasks, thus sidestepping the burden of task-driven feature engineering. The proposed TASA shows improvements over alternative self-supervised models in terms of sequence reconstruction. Moreover, the embeddings generated by TASA yield increases in predictive performance on both proprietary and public data. It also achieves comparable results to supervised approaches that are trained on individual tasks separately and require substantially more computational effort. TASA has been incorporated within a pipeline designed to provide time-aware user embeddings as a service, and the use of its embeddings exhibited lifts in conversion prediction AUC on four audiences.","[{""name"":""Martin Pavlovski"",""id"":""/profile/99659334987""},{""name"":""Jelena Gligorijevic"",""id"":""/profile/99659281711""},{""name"":""Ivan Stojkovic"",""id"":""/profile/99659139708""},{""name"":""Shubham Agrawal"",""id"":""/profile/99659575041""},{""name"":""Shabhareesh Komirishetty"",""id"":""/profile/99659573922""},{""name"":""Djordje Gligorijevic"",""id"":""/profile/99659082580""},{""name"":""Narayan Bhamidipati"",""id"":""/profile/81387602666""},{""name"":""Zoran Obradovic"",""id"":""/profile/81100041040""},{""name"":""Martin Pavlovski"",""id"":""/profile/99659334987""},{""name"":""Jelena Gligorijevic"",""id"":""/profile/99659281711""},{""name"":""Ivan Stojkovic"",""id"":""/profile/99659139708""},{""name"":""Shubham Agrawal"",""id"":""/profile/99659575041""},{""name"":""Shabhareesh Komirishetty"",""id"":""/profile/99659573922""},{""name"":""Djordje Gligorijevic"",""id"":""/profile/99659082580""},{""name"":""Narayan Bhamidipati"",""id"":""/profile/81387602666""},{""name"":""Zoran Obradovic"",""id"":""/profile/81100041040""}]","[""Shahin Amiriparian, Michael Freitag, Nicholas Cummins, and Björn Schuller. 2017. Sequence to sequence autoencoders for unsupervised representation learning from audio. In Proc. of the DCASE 2017 Workshop.Google Scholar"",""Sarath Chandar AP, Stanislas Lauly, Hugo Larochelle, Mitesh Khapra, Balaraman Ravindran, Vikas C Raykar, and Amrita Saha. 2014. An autoencoder approach to learning bilingual word representations. In Advances in Neural Information Processing Systems. 1853--1861.Google Scholar"",""Tian Bai, Shanshan Zhang, Brian L Egleston, and Slobodan Vucetic. 2018. Interpretable representation learning for healthcare via capturing disease progression through time. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 43--51.Google ScholarDigital Library"",""Dana H Ballard. 1987. Modular Learning in Neural Networks.. In AAAI. 279--284.Google Scholar"",""Inci M Baytas, Cao Xiao, Xi Zhang, Fei Wang, Anil K Jain, and Jiayu Zhou. 2017. Patient subtyping via time-aware LSTM networks. In Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. ACM, 65--74.Google ScholarDigital Library"",""Sean Billings. 2018. Gradient Augmented Information Retrieval with Autoencoders and Semantic Hashing. arXiv preprint arXiv:1803.04494 (2018).Google Scholar"",""Hervé Bourlard and Yves Kamp. 1988. Auto-association by multilayer perceptrons and singular value decomposition. Biological cybernetics, Vol. 59, 4--5 (1988), 291--294.Google Scholar"",""Tianqi Chen and Carlos Guestrin. 2016. XGBoost: A Scalable Tree Boosting System. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 785--794.Google ScholarDigital Library"",""Yu-An Chung, Chao-Chung Wu, Chia-Hao Shen, Hung-Yi Lee, and Lin-Shan Lee. 2016. Audio word2vec: Unsupervised learning of audio segment representations using sequence-to-sequence autoencoder. arXiv preprint arXiv:1603.00982 (2016).Google Scholar"",""Andrew M Dai and Quoc V Le. 2015. Semi-supervised sequence learning. In Advances in neural information processing systems. 3079--3087.Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).Google Scholar"",""Khoa D Doan, Pranjul Yadav, and Chandan K Reddy. 2019. Adversarial Factorization Autoencoder for Look-alike Modeling. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management. 2803--2812.Google ScholarDigital Library"",""Djordje Gligorijevic, Jelena Gligorijevic, and Aaron Flores. 2019. Time-Aware Prospective Modeling of Users for Online Display Advertising. AdKDD 2019 workshop at the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (2019).Google Scholar"",""Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. Deep learning. MIT press.Google Scholar"",""Zhicheng He, Jie Liu, Na Li, and Yalou Huang. 2019. Learning Network-to-Network Model for Content-rich Network Embedding. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 1037--1045.Google ScholarDigital Library"",""Geoffrey E Hinton and Sam T Roweis. 2003. Stochastic neighbor embedding. In Advances in neural information processing systems. 857--864.Google Scholar"",""Geoffrey E Hinton and Richard S Zemel. 1994. Autoencoders, minimum description length and Helmholtz free energy. In Advances in neural information processing systems. 3--10.Google Scholar"",""Sébastien Jean, Kyunghyun Cho, Roland Memisevic, and Yoshua Bengio. 2014. On using very large target vocabulary for neural machine translation. arXiv preprint arXiv:1412.2007 (2014).Google Scholar"",""Ian Jolliffe. 2011. Principal component analysis. Springer.Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Alex Krizhevsky and Geoffrey E Hinton. 2011. Using very deep autoencoders for content-based image retrieval.. In ESANN, Vol. 1. 2.Google Scholar"",""Yann Le Cun. 1986. Modèles connexionnistes de l'apprentissage. These de Doctorat. Universite Paris (1986).Google Scholar"",""Daniel D Lee and H Sebastian Seung. 1999. Learning the parts of objects by non-negative matrix factorization. Nature, Vol. 401, 6755 (1999), 788.Google Scholar"",""Jiwei Li, Minh-Thang Luong, and Dan Jurafsky. 2015. A hierarchical neural autoencoder for paragraphs and documents. arXiv preprint arXiv:1506.01057 (2015).Google Scholar"",""Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries. In Text summarization branches out. 74--81.Google Scholar"",""Cheng-Yuan Liou, Wei-Chen Cheng, Jiun-Wei Liou, and Daw-Ran Liou. 2014. Autoencoder for words. Neurocomputing, Vol. 139 (2014), 84--96.Google ScholarDigital Library"",""Minh-Thang Luong, Quoc V Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. 2015. Multi-task sequence to sequence learning. arXiv preprint arXiv:1511.06114 (2015).Google Scholar"",""Geoffrey McLachlan. 2004. Discriminant analysis and statistical pattern recognition. Vol. 544. John Wiley \u0026 Sons.Google Scholar"",""Al Mead. 1992. Review of the development of multidimensional scaling methods. Journal of the Royal Statistical Society: Series D (The Statistician), Vol. 41, 1 (1992), 27--39.Google Scholar"",""Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting on association for computational linguistics. Association for Computational Linguistics, 311--318.Google Scholar"",""Viorica Patraucean, Ankur Handa, and Roberto Cipolla. 2015. Spatio-temporal video autoencoder with differentiable memory. arXiv preprint arXiv:1511.06309 (2015).Google Scholar"",""Wenjie Pei and David MJ Tax. 2018. Unsupervised Learning of Sequence Representations by Autoencoders. arXiv preprint arXiv:1804.00946 (2018).Google Scholar"",""Jonas Pfeiffer, Samuel Broscheit, Rainer Gemulla, and Mathias Göschl. 2018. A neural autoencoder approach for document ranking and query refinement in pharmacogenomic information retrieval. Association for Computational Linguistics.Google Scholar"",""Trang Pham, Truyen Tran, Dinh Phung, and Svetha Venkatesh. 2016. Deepcare: A deep dynamic memory model for predictive medicine. In Pacific-Asia Conference on Knowledge Discovery and Data Mining. Springer, 30--41.Google ScholarDigital Library"",""Sam T Roweis and Lawrence K Saul. 2000. Nonlinear dimensionality reduction by locally linear embedding. science, Vol. 290, 5500 (2000), 2323--2326.Google Scholar"",""Ruslan Salakhutdinov and Geoffrey Hinton. 2009. Semantic hashing. International Journal of Approximate Reasoning, Vol. 50, 7 (2009), 969--978.Google ScholarDigital Library"",""Nitish Srivastava, Elman Mansimov, and Ruslan Salakhudinov. 2015. Unsupervised learning of video representations using lstms. In International conference on machine learning. 843--852.Google ScholarDigital Library"",""Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Sequence to sequence learning with neural networks. In Advances in neural information processing systems. 3104--3112.Google Scholar"",""Joshua B Tenenbaum, Vin De Silva, and John C Langford. 2000. A global geometric framework for nonlinear dimensionality reduction. science, Vol. 290, 5500 (2000), 2319--2323.Google Scholar"",""Vincent Wan, Yannis Agiomyrgiannakis, Hanna Silen, and Jakub Vit. 2017. Google's Next-Generation Real-Time Unit-Selection Synthesizer Using Sequence-to-Sequence LSTM-Based Autoencoders.. In INTERSPEECH. 1143--1147.Google Scholar"",""Yuan Zhang, Xi Yang, Julie Ivy, and Min Chi. 2019. ATTAIN: Attention-based Time-Aware LSTM Networks for Disease Progression Modeling. IJCAI.Google Scholar"",""Yichao Zhou, Shaunak Mishra, Jelena Gligorijevic, Tarun Bhatia, and Narayan Bhamidipati. 2019. Understanding consumer journey using attention based recurrent neural networks. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 3102--3111.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403372,Shop The Look: Building a Large Scale Visual Shopping System at Pinterest,"As online content becomes ever more visual, the demand for searching by visual queries grows correspondingly stronger. Shop The Look is an online shopping discovery service at Pinterest, leveraging visual search to enable users to find and buy products within an image. In this work, we provide a holistic view of how we built Shop The Look, a shopping oriented visual search system, along with lessons learned from addressing shopping needs. We discuss topics including core technology across object detection and visual embeddings, serving infrastructure for realtime inference, and data labeling methodology for training/evaluation data collection and human evaluation. The user-facing impacts of our system design choices are measured through offline evaluations, human relevance judgements, and online A/B experiments. The collective improvements amount to cumulative relative gains of over 160% in end-to-end human relevance judgements and over 80% in engagement. Shop The Look is deployed in production at Pinterest.","[{""name"":""Raymond Shiau"",""id"":""/profile/99659154510""},{""name"":""Hao-Yu Wu"",""id"":""/profile/99659454434""},{""name"":""Eric Kim"",""id"":""/profile/99659574963""},{""name"":""Yue Li Du"",""id"":""/profile/99659155005""},{""name"":""Anqi Guo"",""id"":""/profile/99659574996""},{""name"":""Zhiyuan Zhang"",""id"":""/profile/99659574880""},{""name"":""Eileen Li"",""id"":""/profile/99659572992""},{""name"":""Kunlong Gu"",""id"":""/profile/99659573522""},{""name"":""Charles Rosenberg"",""id"":""/profile/99659455355""},{""name"":""Andrew Zhai"",""id"":""/profile/82658617457""},{""name"":""Raymond Shiau"",""id"":""/profile/99659154510""},{""name"":""Hao-Yu Wu"",""id"":""/profile/99659454434""},{""name"":""Eric Kim"",""id"":""/profile/99659574963""},{""name"":""Yue Li Du"",""id"":""/profile/99659155005""},{""name"":""Anqi Guo"",""id"":""/profile/99659574996""},{""name"":""Zhiyuan Zhang"",""id"":""/profile/99659574880""},{""name"":""Eileen Li"",""id"":""/profile/99659572992""},{""name"":""Kunlong Gu"",""id"":""/profile/99659573522""},{""name"":""Charles Rosenberg"",""id"":""/profile/99659455355""},{""name"":""Andrew Zhai"",""id"":""/profile/82658617457""}]","[""Sean Bell and Kavita Bala. 2015. Learning Visual Similarity for Product Design with Convolutional Neural Networks. ACM Trans. on Graphics (SIGGRAPH), Vol. 34, 4 (2015).Google ScholarDigital Library"",""Ross Girshick, Ilija Radosavovic, Georgia Gkioxari, Piotr Dollár, and Kaiming He. 2018. Detectron. https://github.com/facebookresearch/detectron.Google Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. Deep Residual Learning for Image Recognition. CoRR, Vol. abs/1512.03385 (2015). arxiv: 1512.03385 http://arxiv.org/abs/1512.03385Google Scholar"",""Houdong Hu, Yan Wang, Linjun Yang, Pavel Komlev, Li Huang, Xi (Stephen) Chen, Jiapei Huang, Ye Wu, Meenaz Merchant, and Arun Sacheti. 2018b. Web-Scale Responsive Visual Search at Bing. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining (London, United Kingdom) (KDD '18). Association for Computing Machinery, New York, NY, USA, 359--367. https://doi.org/10.1145/3219819.3219843Google ScholarDigital Library"",""Jie Hu, Li Shen, and Gang Sun. 2018a. Squeeze-and-Excitation Networks. IEEE Conference on Computer Vision and Pattern Recognition.Google Scholar"",""Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross Girshick, Sergio Guadarrama, and Trevor Darrell. 2014. Caffe: Convolutional Architecture for Fast Feature Embedding. arXiv preprint arXiv:1408.5093 (2014).Google Scholar"",""Yushi Jing, David Liu, Dmitry Kislyuk, Andrew Zhai, Jiajing Xu, Jeff Donahue, and Sarah Tavel. 2015. Visual Search at Pinterest. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (Sydney, NSW, Australia) (KDD '15). Association for Computing Machinery, New York, NY, USA, 1889--1898. https://doi.org/10.1145/2783258.2788621Google ScholarDigital Library"",""Arun Krishnan. 2019. StyleSnap will change the way you shop, forever. https://blog.aboutamazon.com/shopping/stylesnap-will-change-the-way-you-shop-forever. (Accessed on 02/04/2020).Google Scholar"",""Jie Li, Haifeng Liu, Chuanghua Gui, Jianyu Chen, Zhenyuan Ni, Ning Wang, and Yuan Chen. 2018. The Design and Implementation of a Real Time Visual Search System on JD E-commerce Platform. 9--16. https://doi.org/10.1145/3284028.3284030Google Scholar"",""Tsung-Yi Lin, Piotr Dollá r, Ross B. Girshick, Kaiming He, Bharath Hariharan, and Serge J. Belongie. 2016. Feature Pyramid Networks for Object Detection. CoRR, Vol. abs/1612.03144 (2016). arxiv: 1612.03144 http://arxiv.org/abs/1612.03144Google Scholar"",""Tsung-Yi Lin, Michael Maire, Serge J. Belongie, Lubomir D. Bourdev, Ross B. Girshick, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollá r, and C. Lawrence Zitnick. 2014. Microsoft COCO: Common Objects in Context. CoRR, Vol. abs/1405.0312 (2014). arxiv: 1405.0312 http://arxiv.org/abs/1405.0312Google Scholar"",""Zheng Liu. 2017. Manas: A high performing customized search system. https://medium.com/pinterest-engineering/manas-a-high-performing-customized-search-system-cf189f6ca40f. (Accessed on 02/10/2020).Google Scholar"",""Dhruv Kumar Mahajan, Ross B. Girshick, Vignesh Ramanathan, Kaiming He, Manohar Paluri, Yixuan Li, Ashwin Bharambe, and Laurens van der Maaten. 2018. Exploring the Limits of Weakly Supervised Pretraining. In ECCV.Google Scholar"",""Marius Muja and David Lowe. 2009. Fast Approximate Nearest Neighbors with Automatic Algorithm Configuration. VISAPP 2009 - Proceedings of the 4th International Conference on Computer Vision Theory and Applications, Vol. 1, 331--340.Google Scholar"",""Rajan Patel. 2018. Google Lens: real-time answers to questions about the world around you. https://www.blog.google/products/google-lens/google-lens-real-time-answers-questions-about-world-around-you/. (Accessed on 02/04/2020).Google Scholar"",""Shaoqing Ren, Kaiming He, Ross B. Girshick, and Jian Sun. 2015. Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks. CoRR, Vol. abs/1506.01497 (2015). arxiv: 1506.01497 http://arxiv.org/abs/1506.01497Google Scholar"",""Yina Tang, Fedor Borisyuk, Siddarth Malreddy, Yixuan Li, Yiqun Liu, and Sergey Kirshner. 2019. MSURU: Large Scale E-Commerce Image Classification with Weakly Supervised Search Data. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining (Anchorage, AK, USA) (KDD '19). Association for Computing Machinery, New York, NY, USA, 2518--2526. https://doi.org/10.1145/3292500.3330696Google ScholarDigital Library"",""Chao-Yuan Wu, R Manmatha, Alexander J Smola, and Philipp Krähenbühl. 2017. Sampling Matters in Deep Embedding Learning. In ICCV.Google Scholar"",""Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, and Kaiming He. 2016b. Aggregated Residual Transformations for Deep Neural Networks. arXiv preprint arXiv:1611.05431 (2016).Google Scholar"",""Saining Xie, Ross B. Girshick, Piotr Dollá r, Zhuowen Tu, and Kaiming He. 2016a. Aggregated Residual Transformations for Deep Neural Networks. CoRR, Vol. abs/1611.05431 (2016). arxiv: 1611.05431 http://arxiv.org/abs/1611.05431Google Scholar"",""K. Yamaguchi, M. H. Kiapour, and T. L. Berg. 2013. Paper Doll Parsing: Retrieving Similar Styles to Parse Clothing Items. In 2013 IEEE International Conference on Computer Vision (ICCV), Vol. 00. 3519--3526. https://doi.org/10.1109/ICCV.2013.437Google ScholarDigital Library"",""Fan Yang, Ajinkya Kale, Yury Bubnov, Leon Stein, Qiaosong Wang, Hadi Kiapour, and Robinson Piramuthu. 2017. Visual Search at EBay. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (Halifax, NS, Canada) (KDD '17). Association for Computing Machinery, New York, NY, USA, 2101--2110. https://doi.org/10.1145/3097983.3098162Google ScholarDigital Library"",""Andrew Zhai and Hao-Yu Wu. 2019. Classification is a Strong Baseline for Deep Metric Learning.. In BMVC.Google Scholar"",""Andrew Zhai, Hao-Yu Wu, Eric Tzeng, Dong Huk Park, and Charles Rosenberg. 2019. Learning a Unified Embedding for Visual Search at Pinterest. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining (Anchorage, AK, USA) (KDD '19). Association for Computing Machinery, New York, NY, USA, 2412--2420. https://doi.org/10.1145/3292500.3330739Google ScholarDigital Library"",""Yanhao Zhang, Pan Pan, Yun Zheng, Kang Zhao, Yingya Zhang, Xiaofeng Ren, and Rong Jin. 2018. Visual Search at Alibaba. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining (London, United Kingdom) (KDD '18). Association for Computing Machinery, New York, NY, USA, 993--1001. https://doi.org/10.1145/3219819.3219820Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403373,Dynamic Heterogeneous Graph Neural Network for Real-time Event Prediction,"Customer response prediction is critical in many industrial applications such as online advertising and recommendations. In particular, the challenge is greater for ride-hailing platforms such as Uber and DiDi, because the response prediction models need to consider historical and real-time event information in the physical environment, such as surrounding traffic and supply and demand conditions. In this paper, we propose to use dynamically constructed heterogeneous graph for each ongoing event to encode the attributes of the event and its surroundings. In addition, we propose a multi-layer graph neural network model to learn the impact of historical actions and the surrounding environment on the current events, and generate an effective event representation to improve the accuracy of the response model. We investigate this framework to two practical applications on the DiDi platform. Offline and online experiments show that the framework can significantly improve prediction performance. The framework has been deployed in the online production environment and serves tens of millions of event prediction requests every day.","[{""name"":""Wenjuan Luo"",""id"":""/profile/99659574691""},{""name"":""Han Zhang"",""id"":""/profile/99659574639""},{""name"":""Xiaodi Yang"",""id"":""/profile/99659575160""},{""name"":""Lin Bo"",""id"":""/profile/99659574693""},{""name"":""Xiaoqing Yang"",""id"":""/profile/99659575159""},{""name"":""Zang Li"",""id"":""/profile/99659574836""},{""name"":""Xiaohu Qie"",""id"":""/profile/99659458860""},{""name"":""Jieping Ye"",""id"":""/profile/99659193247""},{""name"":""Wenjuan Luo"",""id"":""/profile/99659574691""},{""name"":""Han Zhang"",""id"":""/profile/99659574639""},{""name"":""Xiaodi Yang"",""id"":""/profile/99659575160""},{""name"":""Lin Bo"",""id"":""/profile/99659574693""},{""name"":""Xiaoqing Yang"",""id"":""/profile/99659575159""},{""name"":""Zang Li"",""id"":""/profile/99659574836""},{""name"":""Xiaohu Qie"",""id"":""/profile/99659458860""},{""name"":""Jieping Ye"",""id"":""/profile/99659193247""}]","[""Apache. 2003. Apache Flink: Stateful Computations over Data Streams. https://flink.apache.org/.Google Scholar"",""Hidasi B, Karatzoglou A, and et al. Baltrunas L. 2015. Session-based Recommendation with Recurrent Neural Networks. arXiv preprint arXiv:1511.069397 (2015).Google Scholar"",""Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et almbox. 2016. Wide \u0026 deep learning for recommender systems. In Proceedings of the 1st workshop on deep learning for recommender systems. ACM, 7--10.Google ScholarDigital Library"",""Francc ois Chollet et almbox. 2018. Keras: The python deep learning library. Astrophysics Source Code Library (2018).Google Scholar"",""Yuxiao Dong, Nitesh V Chawla, and Ananthram Swami. 2017. metapath2vec: Scalable representation learning for heterogeneous networks. In Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. ACM, 135--144.Google ScholarDigital Library"",""Alex Graves, Greg Wayne, and Ivo Danihelka. 2014. Neural turing machines. arXiv preprint arXiv:1410.5401 (2014).Google Scholar"",""Mihajlo Grbovic. 2017. Search Ranking And Personalization at Airbnb. In the Eleventh ACM Conference.Google ScholarDigital Library"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. 855--864.Google ScholarDigital Library"",""Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: a factorization-machine based neural network for CTR prediction. arXiv preprint arXiv:1703.04247 (2017).Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In Advances in Neural Information Processing Systems. 1024--1034.Google Scholar"",""Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural computation, Vol. 9, 8 (1997), 1735--1780.Google Scholar"",""Chung J, Gulcehre C, Cho K, and et al. 2015. Gated feedback recurrent neural networks. In Proceedings of International Conference on Machine Learning. 2067--2075.Google Scholar"",""Zhou J, Cui G, and Zhang Z. 2018. Graph neural networks: A review of methods and applications. arXiv preprint arXiv:1812.08434 (2018). arxiv: 1812.08434 http://arxiv.org/abs/1812.08434Google Scholar"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).Google Scholar"",""Yucheng Lin, Xiaoqing Yang, Zang Li, and Jieping Ye. 2019. AHINE: Adaptive Heterogeneous Information Network Embedding. arXiv preprint arXiv:1909.01087 (2019).Google Scholar"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems. 3111--3119.Google Scholar"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. 701--710.Google ScholarDigital Library"",""Qi Pi, Weijie Bian, Guorui Zhou, Xiaoqiang Zhu, and Kun Gai. 2019. Practice on Long Sequential User Behavior Modeling for Click-Through Rate Prediction. arXiv preprint arXiv:1905.09248 (2019).Google Scholar"",""Mirco Ravanelli, Philemon Brakel, Maurizio Omologo, and Yoshua Bengio. 2017. Improving speech recognition by revising gated recurrent units. arXiv preprint arXiv:1710.00641 (2017).Google Scholar"",""Salvatore Sanfilippo. 2019. Redis: an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker. https://redis.io/.Google Scholar"",""Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. 2008. The graph neural network model. IEEE Transactions on Neural Networks, Vol. 20, 1 (2008), 61--80.Google ScholarDigital Library"",""Chuan Shi, Binbin Hu, Wayne Xin Zhao, and S Yu Philip. 2018. Heterogeneous information network embedding for recommendation. IEEE Transactions on Knowledge and Data Engineering, Vol. 31, 2 (2018), 357--370.Google ScholarDigital Library"",""Chen T and Guestrin C. 2016. Xgboost: A scalable tree boosting system. In Proceedings of the 22th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 785--794.Google Scholar"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. In Proceedings of the 24th international conference on world wide web. 1067--1077.Google ScholarDigital Library"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph attention networks. arXiv preprint arXiv:1710.10903 (2017).Google Scholar"",""Song W, Xiao Z, and et al Wang Y. 2019. Session-based social recommendation via dynamic graph attention networks. In Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining. ACM, 555--563.Google Scholar"",""Jizhe Wang, Pipei Huang, Huan Zhao, Zhibo Zhang, Binqiang Zhao, and Dik Lun Lee. 2018. Billion-scale commodity embedding for e-commerce recommendation in alibaba. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 839--848.Google ScholarDigital Library"",""Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, and Philip S Yu. 2019. Heterogeneous Graph Attention Network. In The World Wide Web Conference. ACM, 2022--2032.Google Scholar"",""Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, and Tieniu Tan. 2019. Session-based recommendation with graph neural networks. In Proceedings of the AAAI Conference on Artificial Intelligence. 346--353.Google ScholarCross Ref"",""Chuxu Zhang, Dongjin Song, Chao Huang, Ananthram Swami, and Nitesh V. Chawla. 2019. Heterogeneous Graph Neural Network. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 793--803.Google Scholar"",""Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Xiaoqiang Zhu, and Kun Gai. 2019. Deep interest evolution network for click-through rate prediction. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 5941--5948.Google ScholarCross Ref"",""Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through rate prediction. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 1059--1068.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403374,Bandit based Optimization of Multiple Objectives on a Music Streaming Platform,"Recommender systems powering online multi-stakeholder platforms often face the challenge of jointly optimizing multiple objectives, in an attempt to efficiently match suppliers and consumers. Examples of such objectives include user behavioral metrics (e.g. clicks, streams, dwell time, etc), supplier exposure objectives (e.g. diversity) and platform centric objectives (e.g. promotions). Jointly optimizing multiple metrics in online recommender systems remains a challenging task. Recent work has demonstrated the prowess of contextual bandits in powering recommendation systems to serve recommendation of interest to users. This paper aims at extending contextual bandits to multi-objective setting so as to power recommendations in a multi-stakeholder platforms.Specifically, in a contextual bandit setting, we learn a recommendation policy that can optimize multiple objectives simultaneously in a fair way. This multi-objective online optimization problem is formalized by using the Generalized Gini index (GGI) aggregation function, which combines and balances multiple objectives together. We propose an online gradient ascent learning algorithm to maximise the long-term vectorial rewards for different objectives scalarised using the GGI function. Through extensive experiments on simulated data and large scale music recommendation data from Spotify, a streaming platform, we show that the proposed algorithm learns a superior policy among the disparate objectives compared with other state-of-the-art approaches.","[{""name"":""Rishabh Mehrotra"",""id"":""/profile/99658716949""},{""name"":""Niannan Xue"",""id"":""/profile/99659566223""},{""name"":""Mounia Lalmas"",""id"":""/profile/81492641343""},{""name"":""Rishabh Mehrotra"",""id"":""/profile/99658716949""},{""name"":""Niannan Xue"",""id"":""/profile/99659566223""},{""name"":""Mounia Lalmas"",""id"":""/profile/81492641343""}]","[""Gediminas Adomavicius and YoungOk Kwon. 2007. New Recommendation Techniques for Multicriteria Rating Systems. IEEE Intelligent Systems (2007).Google Scholar"",""Deepak Agarwal, Bee-Chung, Pradheep, and Xuanhui. 2011. Click shaping to optimize multiple objectives. In Proceedings of KDD 2011.Google ScholarDigital Library"",""Deepak Agarwal, Bee-Chung Chen, Pradheep Elango, and Xuanhui Wang. 2012. Personalized click shaping through lagrangian duality for online recommendation. In Proceedings of SIGIR 2012.Google ScholarDigital Library"",""Leon Barrett and Srini Narayanan. 2008. Learning All Optimal Policies with Multiple Criteria. In ICML. 41--47.Google Scholar"",""Róbert Busa-Fekete, Balázs Szörényi, Paul Weng, and Shie Mannor. 2017. Multi-objective Bandits: Optimizing the Generalized Gini Index. In ICML.Google Scholar"",""Konstantina Christakopoulou, Jaya Kawale, and Arindam Banerjee. Recommendation with capacity constraints. In Proceedings of CIKM 2017.Google ScholarDigital Library"",""Wei Chu and Seung-Taek Park. 2009. Personalized Recommendation on Dynamic Content Using Predictive Bilinear Models. In WWW.Google Scholar"",""Paolo Cremonesi, Yehuda Koren, and Roberto Turrin. 2010. Performance of Recommender Algorithms on Top-n Recommendation Tasks. In RecSys.Google Scholar"",""M. M. Drugan and A. Nowe. 2013. Designing multi-objective multi-armed bandits algorithms: A study. In International Joint Conference on Neural Networks (IJCNN).Google Scholar"",""Zoltán Gábor, Zsolt Kalmár, and Csaba Szepesvári. 1998. Multi-criteria Reinforcement Learning. In ICML. 197--205.Google Scholar"",""Rupesh Gupta, Guanfeng Liang, Ravi Kiran Tseng, Xiaoyu Chen, and Romer Rosales. Email volume optimization at LinkedIn. In KDD 2016.Google ScholarDigital Library"",""Tamas Jambor and Jun Wang. Optimizing multiple objectives in collaborative filtering. In Proceedings of RecSys 2010.Google ScholarDigital Library"",""Dietmar Jannach and Malte Ludewig. 2017. When recurrent neural networks meet the neighborhood for session-based recommendation. In Proceedings of the Eleventh ACM Conference on Recommender Systems. ACM, 306--310.Google ScholarDigital Library"",""Thorsten Joachims. 2002. Optimizing search engines using clickthrough data. Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 133--142.Google ScholarDigital Library"",""I. Y. Kim and O. L. de Weck. 2006. Adaptive weighted sum method for multiobjective optimization: a new method for Pareto front generation. Structural and Multidisciplinary Optimization, Vol. 31, 2 (2006), 105--116.Google ScholarCross Ref"",""Anisio Lacerda. 2015. Contextual Bandits for Multi-objective Recommender Systems. In Proceedings of the 2015 Brazilian Conference on Intelligent Systems (BRACIS). 68--73.Google ScholarDigital Library"",""Kleanthi Lakiotaki, Nikolaos F Matsatsinis, and Alexis Tsoukias. 2011. Multicriteria user modeling in recommender systems. IEEE Intelligent Systems (2011).Google Scholar"",""John Langford and Tong Zhang. 2008. The Epoch-Greedy Algorithm for Multi-armed Bandits with Side Information. NIPS.Google Scholar"",""Lihong Li, Wei Chu, John Langford, and Robert E. Schapire. 2010. A Contextual-bandit Approach to Personalized News Article Recommendation. In WWW.Google Scholar"",""Lihong Li, Wei Chu, John Langford, and Xuanhui Wang. 2011. Unbiased Offline Evaluation of Contextual-bandit-based News Article Recommendation Algorithms. In WSDM.Google Scholar"",""C. Liu, X. Xu, and D. Hu. 2015. Multiobjective Reinforcement Learning: A Comprehensive Overview. IEEE Transactions on Systems, Man, and Cybernetics (2015).Google Scholar"",""Donald W. Marquardt and Ronald D. Snee. 1975. Ridge Regression in Practice. The American Statistician, Vol. 29, 1 (1975), 3--20.Google Scholar"",""James McInerney, Benjamin Lacker, Samantha Hansen, Karl Higley, Hugues Bouchard, Alois Gruson, and Rishabh Mehrotra. Explore, Exploit, and Explain: Personalizing Explainable Recommendations with Bandits. In Proceedings of RecSys 2018.Google Scholar"",""Rishabh Mehrotra and Benjamin Carterette. 2019. Recommendations in a marketplace. In Proceedings of the 13th ACM Conference on Recommender Systems. 580--581.Google ScholarDigital Library"",""Rishabh Mehrotra, James McInerney, Hugues Bouchard, Mounia Lalmas, and Fernando Diaz. 2018. Towards a Fair Marketplace: Counterfactual Evaluation of the trade-off between Relevance, Fairness \u0026 Satisfaction in Recommendation Systems. In CIKM.Google Scholar"",""K. Van Moffaert, K. Van Vaerenbergh, P. Vrancx, and A. Nowe.Google Scholar"",""Eric Moulines and Francis R. Bach. 2011. Non-Asymptotic Analysis of Stochastic Approximation Algorithms for Machine Learning. NIPS.Google Scholar"",""Wodzimierz Ogryczak and Tomasz Sliwinski. 2003. On solving linear programs with the ordered weighted averaging objective. European Journal of Operational Research, Vol. 148, 1 (2003), 80--91.Google ScholarCross Ref"",""Saba Q. Yahyaa, Madalina M. Drugan, and Bernard Manderick. 2014. Knowledge Gradient for Multi-objective Multi-armed Bandit Algorithms. In Proceedings of the 6th International Conference on Agents and Artificial Intelligence - Volume 1.Google Scholar"",""Marco Tulio Ribeiro, Lacerda, Veloso, and Ziviani. Pareto-efficient hybridization for multi-objective recommender systems. In RecSys 2012.Google Scholar"",""Herbert Robbins and Sutton Monro. 1951. A stochastic approximation method. The Annals of Mathematical Statistics, Vol. 22, 3 (1951), 400--407.Google ScholarCross Ref"",""Lili Shan, Lei Lin, and Chengjie Sun. Combined Regression and Tripletwise Learning for Conversion Rate Prediction in Real-Time Bidding Advertising. In SIGIR 2018.Google Scholar"",""Aleksandrs Slivkins. 2014. Contextual Bandits with Similarity Information. J. Mach. Learn. Res., Vol. 15, 1 (2014), 2533--2568.Google ScholarDigital Library"",""Richard S. Sutton and Francis Bach. 1998. Reinforcement Learning: An Introduction. MIT Press.Google Scholar"",""Krysta M Svore, Maksims N Volkovs, and Christopher JC Burges. Learning to rank with multiple objective functions. In Proceedings of WWW 2011.Google ScholarDigital Library"",""Cem Tekin and Eralp Turug ay. 2018. Multi-objective contextual multi-armed bandit with a dominant objective. IEEE Transactions on Signal Processing (2018).Google Scholar"",""Eralp Turug ay, Doruk Öner, and Cem Tekin. 2018. Multi-objective contextual bandit problem with similarity information. arXiv preprint arXiv:1803.04015 (2018).Google Scholar"",""Umair ul Hassan and Edward Curry. 2016. Efficient task assignment for spatial crowdsourcing: A combinatorial fractional optimization approach with semi-bandit learning. Expert Systems with Applications, Vol. 58 (2016), 36--56.Google ScholarDigital Library"",""John A. Weymark. 1981. Generalized Gini inequality indices. Mathematical Social Sciences, Vol. 1 (1981), 409--430.Google ScholarCross Ref"",""Lin Xiao, Minand, Zhaoquan, L Yiqun, and Ma Shaoping. Fairness-aware group recommendation with pareto-efficiency. In RecSys 2018.Google Scholar"",""R. R. Yager. On ordered weighted averaging aggregation operators in multicriteria decisionmaking. IEEE Transactions on Systems, Man, \u0026 Cybernetics ( ????).Google Scholar"",""Saba Yahyaa, Madalina Drugan, and Bernard Manderick. 2015. Thompson Sampling in the Adaptive Linear Scalarized Multi Objective Multi Armed Bandit. In Proceedings of the 7th International Conference on Agents and Artificial Intelligence.Google ScholarDigital Library"",""Xing Yi, Liangjie Hong, Erheng Zhong, Nanthan Nan Liu, and Suju Rajan. Beyond clicks: dwell time for personalization. In Proceedings of RecSys 2014.Google ScholarDigital Library"",""Chongjie Zhang and Julie A Shah. 2014. Fairness in Multi-Agent Sequential Decision-Making. NIPS. 2636--2644.Google Scholar""]"
https://doi.org/10.1145/3394486.3403375,Multimodal Deep Learning Based Crop Classification Using Multispectral and Multitemporal Satellite Imagery,"The Food and Agriculture Organization (FAO) of the United Nations predicts that in order to meet the needs of the expected 3 billion population growth by 2050, food production has to increase by 60%. Therefore, monitoring and mapping crops accurately is essential for estimating food production during each crop growing season across the globe. Traditionally, multispectral remote sensing imagery has been widely used for mapping crops worldwide. However, single date imagery does not capture temporal characteristics (phenology) of growing crops, leading to imprecise crop maps and food estimates. On the other hand, purely temporal classification approaches also produce inaccurate crop maps as they do not account for spatial autocorrelations. In this paper, we present a multimodal deep learning solution that jointly exploits spatial-spectral and phenological properties to identify major crop types. Using a two stream architecture, spatial characteristics are captured via a spatial stream consisting of very high resolution images (single date, 1m, 3-spectral bands, USDA NAIP) with a CNN and the phenological characteristics via a temporal stream images (biweekly, 250m, MODIS NDVI) with an LSTM. Experimental results show that the proposed multimodal solution reduces prediction error by 60%.","[{""name"":""Krishna Karthik Gadiraju"",""id"":""/profile/99659044705""},{""name"":""Bharathkumar Ramachandra"",""id"":""/profile/99659180743""},{""name"":""Zexi Chen"",""id"":""/profile/99659478766""},{""name"":""Ranga Raju Vatsavai"",""id"":""/profile/81100528438""},{""name"":""Krishna Karthik Gadiraju"",""id"":""/profile/99659044705""},{""name"":""Bharathkumar Ramachandra"",""id"":""/profile/99659180743""},{""name"":""Zexi Chen"",""id"":""/profile/99659478766""},{""name"":""Ranga Raju Vatsavai"",""id"":""/profile/81100528438""}]","[""European Space Agency. [n.d.]. GlobCover. http://due.esrin.esa.int/page_globcover.phpGoogle Scholar"",""Mariana Belgiu and Ovidiu Csillik. 2018. Sentinel-2 cropland mapping using pixel-based and object-based time-weighted dynamic time warping analysis. Remote sensing of environment, Vol. 204 (2018), 509--523.Google Scholar"",""P. Benedetti, D. Ienco, R. Gaetano, K. Ose, R. G. Pensa, and S. Dupuy. 2018. $M^3textFusion$: A Deep Learning Architecture for Multiscale Multimodal Multitemporal Satellite Data Fusion. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, Vol. 11, 12 (Dec 2018), 4939--4949. https://doi.org/10.1109/JSTARS.2018.2876357Google ScholarCross Ref"",""Jon Atli Benediktsson, Xavier Ceamanos Garcia, Bjorn Waske, Jocelyn Chanussot, Johannes R Sveinsson, and Mathieu Fauvel. 2008. Ensemble methods for classification of hyperspectral data. In IGARSS 2008--2008 IEEE International Geoscience and Remote Sensing Symposium, Vol. 1. IEEE, I--62.Google ScholarCross Ref"",""Claire Boryan, Zhengwei Yang, Rick Mueller, and Mike Craig. 2011. Monitoring US agriculture: the US department of agriculture, national agricultural statistics service, cropland data layer program. Geocarto International, Vol. 26, 5 (2011), 341--358.Google ScholarCross Ref"",""Gustavo Camps-Valls, Luis Gómez-Chova, Javier Calpe-Maravilla, Emilio Soria-Olivas, José David Mart'in-Guerrero, and J Moreno. 2003. Support vector machines for crop classification using hyperspectral data. In Iberian Conference on Pattern Recognition and Image Analysis. Springer, 134--141.Google ScholarCross Ref"",""Rich Caruana, Steve Lawrence, and C Lee Giles. 2001. Overfitting in neural nets: Backpropagation, conjugate gradient, and early stopping. In Advances in neural information processing systems. 402--408.Google Scholar"",""Isabel Luisa Castillejo-González, Francisca López-Granados, Alfonso Garc'ia-Ferrer, José Manuel Pe na-Barragán, Montserrat Jurado-Expósito, Manuel Sánchez de la Orden, and Mar'ia González-Audicana. 2009. Object-and pixel-based analysis for mapping crops and their agro-environmental associated measures using QuickBird imagery. Computers and Electronics in Agriculture, Vol. 68, 2 (2009), 207--215.Google ScholarDigital Library"",""Varun Chandola and Ranga Raju Vatsavai. 2010. Multi-temporal remote sensing image classification-A multi-view approach.. In CIDU . 258--270.Google Scholar"",""Franccois Chollet et almbox. 2015. Keras. https://keras.io .Google Scholar"",""Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. Imagenet: A large-scale hierarchical image database. In Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on. Ieee, 248--255.Google ScholarCross Ref"",""O Dubois, JM Faurès, E Felix, A Flammini, J Hoogeveen, L Pluschke, M Puri, and O Ünver. 2014. The Water-Energy-Food Nexus: A new approach in support of food security and sustainable agriculture. Rome, Food and Agriculture Organization of the United Nations (2014).Google Scholar"",""Christoph Feichtenhofer, Axel Pinz, and Andrew Zisserman. 2016. Convolutional two-stream network fusion for video action recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition . 1933--1941.Google ScholarCross Ref"",""Mark A Friedl, Damien Sulla-Menashe, Bin Tan, Annemarie Schneider, Navin Ramankutty, Adam Sibley, and Xiaoman Huang. 2010. MODIS Collection 5 global land cover: Algorithm refinements and characterization of new datasets. Remote sensing of Environment, Vol. 114, 1 (2010), 168--182.Google Scholar"",""Krishna Karthik Gadiraju. 2020 a. Github repository for Multi-Modal Crop Classification. https://github.com/kkgadiraju/multi-modal-crop-classificationGoogle Scholar"",""Krishna Karthik Gadiraju. 2020 b. MODISGoogle Scholar"",""NAIP multi-modal dataset for crop classification. https://bit.ly/2ORb16UGoogle Scholar"",""Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition. 770--778.Google ScholarCross Ref"",""Saihui Hou, Xu Liu, and Zilei Wang. 2017. Dualnet: Learn complementary features for image recognition. In Proceedings of the IEEE International Conference on Computer Vision. 502--510.Google ScholarCross Ref"",""Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. 2017. Densely connected convolutional networks.. In CVPR, Vol. 1. 3.Google Scholar"",""Alfredo Huete, Chris Justice, and Wim Van Leeuwen. 1999. MODIS vegetation index (MOD13). Algorithm theoretical basis document, Vol. 3, 213 (1999).Google Scholar"",""Koen Hufkens. 2017. A Google Earth Engine time series subset script and library. https://github.com/khufkens/gee_subsetGoogle Scholar"",""Markus Immitzer, Francesco Vuolo, and Clement Atzberger. 2016. First experience with Sentinel-2 data for crop and tree species classifications in central Europe. Remote Sensing, Vol. 8, 3 (2016), 166.Google ScholarCross Ref"",""Shunping Ji, Chi Zhang, Anjian Xu, Yun Shi, and Yulin Duan. 2018. 3D convolutional neural networks for crop classification with multi-temporal remote sensing images . Remote Sensing, Vol. 10, 1 (2018). https://doi.org/10.3390/rs10010075Google Scholar"",""Per Jönsson and Lars Eklundh. 2004. TIMESAT-a program for analyzing time-series of satellite sensor data. Computers \u0026 Geosciences, Vol. 30, 8 (2004), 833--845.Google ScholarCross Ref"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Nataliia Kussul, Mykola Lavreniuk, Sergii Skakun, and Andrii Shelestov. 2017. Deep learning classification of land cover and crop types using remote sensing data. IEEE Geoscience and Remote Sensing Letters, Vol. 14, 5 (2017), 778--782.Google ScholarCross Ref"",""Ajay Mathur and Giles M Foody. 2008. Crop classification by support vector machine with intelligently selected training data for an operational application. International Journal of Remote Sensing, Vol. 29, 8 (2008), 2227--2240.Google ScholarDigital Library"",""Frank Mueller. [n.d.]. ARC A Root Cluster for Research into Scalable Computer Systems. https://arcb.csc.ncsu.edu/ mueller/cluster/arc/Google Scholar"",""Alex Olsen, Dmitry A. Konovalov, Bronson Philippa, Peter Ridd, Jake C. Wood, Jamie Johns, Wesley Banks, Benjamin Girgenti, Owen Kenny, James Whinney, Brendan Calvert, Mostafa Rahimi Azghadi, and Ronald D. White. 2019. DeepWeeds: A Multiclass Weed Species Image Dataset for Deep Learning . Scientific Reports, Vol. 9, 2058 (14 2 2019). Issue 1. https://doi.org/10.1038/s41598-018--38343--3Google Scholar"",""F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011. Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, Vol. 12 (2011), 2825--2830.Google ScholarDigital Library"",""Javier Plaza, Antonio Plaza, and Cristina Barra. 2009. Multi-channel morphological profiles for classification of hyperspectral images using support vector machines. Sensors, Vol. 9, 1 (2009), 196--218.Google ScholarCross Ref"",""National Agriculture Imagery Program. [n.d.]. NAIP National Agriculture Imagery Program. https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/Google Scholar"",""Global Land Cover 2000 Project. [n.d.]. Global Land Cover 2000 Project. https://forobs.jrc.ec.europa.eu/products/glc2000/glc2000.phpGoogle Scholar"",""Tim GJ Rudner, Marc Rußwurm, Jakub Fil, Ramona Pelich, Benjamin Bischke, Veronika Kopavc ková, and Piotr Bili'nski. 2019. Multi3Net: segmenting flooded buildings via fusion of multiresolution, multisensor, and multitemporal satellite imagery. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 702--709.Google ScholarCross Ref"",""Marc Rußwurm and Marco Korner. 2017. Temporal vegetation modelling using long short-term memory networks for crop identification from medium-resolution multi-spectral satellite images. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops . 11--19.Google Scholar"",""Marc Rußwurm, Sébastien Lefèvre, and Marco Körner. 2019. BreizhCrops: A Satellite Time Series Dataset for Crop Type Identification. In International Conference on Machine Learning (ICML) (Time Series Workshop). arxiv: cs.LG, cs.CV, stat.ML/1905.11893Google Scholar"",""Sofia Siachalou, Giorgos Mallinis, and Maria Tsakiri-Strati. 2015. A hidden Markov models approach for crop classification: Linking crop phenology to time series of multi-sensor remote sensing data. Remote Sensing, Vol. 7, 4 (2015), 3633--3650.Google ScholarCross Ref"",""Karen Simonyan and Andrew Zisserman. 2014a. Two-stream convolutional networks for action recognition in videos. In Advances in neural information processing systems. 568--576.Google Scholar"",""Karen Simonyan and Andrew Zisserman. 2014b. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556 (2014).Google Scholar"",""Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research, Vol. 15, 1 (2014), 1929--1958.Google Scholar"",""W Verhoef. 1996. Application of harmonic analysis of NDVI time series (HANTS). Fourier analysis of temporal NDVI in the Southern African and American continents, Vol. 108 (1996), 19--24.Google Scholar"",""Liheng Zhong, Lina Hu, and Hang Zhou. 2019. Deep learning based multi-temporal crop classification . Remote Sensing of Environment, Vol. 221, December 2018 (2019), 430--443. https://doi.org/10.1016/j.rse.2018.11.032Google ScholarCross Ref"",""Zhuang Zhou, Shengyang Li, and Yuyang Shao. 2018. Object-oriented crops classification for remote sensing images based on convolutional neural network . (2018), 78. https://doi.org/10.1117/12.2317448Google Scholar""]"
https://doi.org/10.1145/3394486.3403376,BusTr: Predicting Bus Travel Times from Real-Time Traffic,"We present BusTr, a machine-learned model for translating road traffic forecasts into predictions of bus delays, used by Google Maps to serve the majority of the world's public transit systems where no official real-time bus tracking is provided. We demonstrate that our neural sequence model improves over DeepTTE, the state-of-the-art baseline, both in performance (-30% MAPE) and training stability. We also demonstrate significant generalization gains over simpler models, evaluated on longitudinal data to cope with a constantly evolving world.","[{""name"":""Richard Barnes"",""id"":""/profile/99659574405""},{""name"":""Senaka Buthpitiya"",""id"":""/profile/81458656780""},{""name"":""James Cook"",""id"":""/profile/99659573056""},{""name"":""Alex Fabrikant"",""id"":""/profile/81100590220""},{""name"":""Andrew Tomkins"",""id"":""/profile/81100269271""},{""name"":""Fangzhou Xu"",""id"":""/profile/99659574669""},{""name"":""Richard Barnes"",""id"":""/profile/99659574405""},{""name"":""Senaka Buthpitiya"",""id"":""/profile/81458656780""},{""name"":""James Cook"",""id"":""/profile/99659573056""},{""name"":""Alex Fabrikant"",""id"":""/profile/81100590220""},{""name"":""Andrew Tomkins"",""id"":""/profile/81100269271""},{""name"":""Fangzhou Xu"",""id"":""/profile/99659574669""}]","[""Anne Aguiléra and Jean Grébert. Passenger transport mode share in cities: exploration of actual and future trends with a worldwide survey. International Journal of Automotive Technology and Management, 14 (3--4): 203--216, 2014.Google ScholarCross Ref"",""Michael L Anderson. Subways, strikes, and slowdowns: The impacts of public transit on traffic congestion. American Economic Review, 104 (9): 2763--96, 2014.Google ScholarCross Ref"",""Richard Barnes. Optimal orientations of discrete global grids and the poles of inaccessibility. International Journal of Digital Earth, 0 (0): 1--14, 2019.Google Scholar"",""Candace Brakewood, Sean Barbeau, and Kari Watkins. An experiment evaluating the impacts of real-time transit information on bus riders in Tampa, Florida. Transportation Research Part A: Policy and Practice, 69: 409--422, 2014.Google ScholarCross Ref"",""Sandip Chakrabarti and Genevieve Giuliano. Does service reliability determine transit patronage? insights from the Los Angeles Metro bus system. Transport Policy, 42: 12--20, 2015. ISSN 0967-070X. URL http://www.sciencedirect.com/science/article/pii/S0967070X15300068.Google ScholarCross Ref"",""Mei Chen, Jason Yaw, Steven I. Chien, and Xiaobo Liu. Using automatic passenger counter data in bus arrival time prediction. Journal of Advanced Transportation, 41 (3): 267--283, 2007. URL https://onlinelibrary.wiley.com/doi/abs/10.1002/atr.5670410304.Google ScholarCross Ref"",""Raj Chetty and Nathaniel Hendren. The impacts of neighborhoods on intergenerational mobility I: Childhood exposure effects. The Quarterly Journal of Economics, 133 (3): 1107--1162, 2018.Google ScholarCross Ref"",""B. Dhivyabharathi, B. Anil Kumar, Avinash Achar, and Lelitha Vanajakshi. Bus travel time prediction: A lognormal auto-regressive (AR) modeling approach. arXiv: 1904.03444, 2019.Google Scholar"",""Alex Fabrikant. Predicting bus delays with machine learning. Google AI Blog, 2019. URL https://ai.googleblog.com/2019/06/predicting-bus-delays-with-machine.html.Google Scholar"",""Brian Ferris, Kari Watkins, and Alan Borning. OneBusAway: results from providing real-time arrival information for public transit. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pages 1807--1816. ACM, 2010.Google Scholar"",""Daniel Golovin, Benjamin Solnik, Subhodeep Moitra, Greg Kochanski, John Karro, and D. Sculley. Google Vizier: A Service for Black-Box Optimization. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '17, pages 1487--1495, Halifax, NS, Canada, 2017. ACM Press. ISBN 978-1-4503-4887-4.Google ScholarDigital Library"",""GTFS. GTFS Realtime Specification. https://developers.google.com/transit/gtfsrealtime/reference/, 2020.Google Scholar"",""GTFS. GTFS static overview. https://developers.google.com/transit/gtfs, 2020b.Google Scholar"",""M. Amac Guvensan, Burak Dusun, Baris Can, and H. Irem Turkmen. A novel segment-based approach for improving classification performance of transport mode detection. Sensors, 18 (1), 2018.Google Scholar"",""Cristina Heghedus. PhD Forum: Forecasting Public Transit Using Neural Network Models. In 2017 IEEE International Conference on Smart Computing (SMARTCOMP), pages 1--2, Hong Kong, China, May 2017. IEEE. ISBN 978-1-5090-6517-2.Google Scholar"",""Cristina Heghedus, Antorweep Chakravorty, and Chunming Rong. Neural Network Frameworks. Comparison on Public Transportation Prediction. In 2019 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW), pages 842--849, Rio de Janeiro, Brazil, May 2019. IEEE. ISBN 978-1-72813-510-6.Google Scholar"",""IPCC. Climate Change 2014: Mitigation of Climate Change. Cambridge University Press, 2014. ISBN 978-1-107-05821-7.Google Scholar"",""Ranhee Jeong and R Rilett. Bus arrival time prediction using artificial neural network model. In Proceedings. The 7th International IEEE Conference on Intelligent Transportation Systems (IEEE Cat. No. 04TH8749), pages 988--993. IEEE, 2004.Google ScholarCross Ref"",""Nikolas Julio, Ricardo Giesen, and Pedro Lizana. Real-time prediction of bus travel speeds using traffic shockwaves and machine learning algorithms. Research in Transportation Economics, 59: 250--257, 2016. ISSN 0739-8859. Competition and Ownership in Land Passenger Transport (selected papers from the Thredbo 14 conference).Google ScholarCross Ref"",""Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization, 2014.Google Scholar"",""Terence C. Lam and Kenneth A. Small. The value of time and reliability: measurement from a value pricing experiment. Transportation Research Part E: Logistics and Transportation Review, 37 (2): 231--251, 2001. ISSN 1366--5545. Advances in the Valuation of Travel Time Savings.Google ScholarCross Ref"",""Ehsan Mazloumi, Geoff Rose, Graham Currie, and Majid Sarvi. An integrated framework to predict bus travel time and its variability using traffic flow data. Journal of Intelligent Transportation Systems, 15 (2): 75--90, 2011.Google ScholarCross Ref"",""Claire McKnight, Herbert Levinson, Kaan Ozbay, Camille Kamga, and Robert Paaswell. Impact of traffic congestion on bus travel time in northern new jersey. Transportation Research Record, 1884: 27--35, 01 2004.Google ScholarCross Ref"",""Daniel L Mendoza, Martin P Buchert, and John C Lin. Modeling net effects of transit operations on vehicle miles traveled, fuel consumption, carbon dioxide, and criteria air pollutant emissions in a mid-size US metro area: findings from Salt Lake City, UT. Environmental Research Communications, 1 (9): 091002, Sep 2019.Google ScholarCross Ref"",""LiveTravelGeorg Osang, James Cook, Alex Fabrikant, and Marco Gruteser. Livetravel: Real-time matching of transit vehicle trajectories to transit routes at scale. In Proceedings of 2019 IEEE ITSC, pages 2244--2251, 2019.Google ScholarDigital Library"",""Rahul Pathak, Christopher K. Wyczalkowski, and Xi Huang. Public transit access and the changing spatial distribution of poverty. Regional Science and Urban Economics, 66: 198--212, 2017. ISSN 0166-0462.Google ScholarCross Ref"",""Thilo Reich, Marcin Budka, Derek Robbins, and David Hulbert. Survey of ETA prediction methods in public transport networks. arXiv: 1904.05037, 2019.Google Scholar"",""Kevin Sahr, Denis White, and A. Jon Kimerling. Geodesic discrete global grid systems. Cartography and Geographic Information Science, 30 (2): 121--134, 2003.Google ScholarCross Ref"",""G. Salvo, G. Amato, and Pietro Zito. Bus speed estimation by neural networks to improve the automatic fleet management. European Transport, 37: 93--104, 2007.Google Scholar"",""Benjamin Solnik, Daniel Golovin, Greg Kochanski, John Elliot Karro, Subhodeep Moitra, and D. Sculley. Bayesian optimization for a better dessert. In Proceedings of the 2017 NIPS Workshop on Bayesian Optimization, December 9, 2017, Long Beach, USA, 2017. The workshop is BayesOpt 2017 NIPS Workshop on Bayesian Optimization December 9, 2017, Long Beach, USA.Google Scholar"",""Sun2016F. Sun, Y. Pan, J. White, and A. Dubey. Real-time and predictive analytics for smart public transportation decision support system. In 2016 IEEE International Conference on Smart Computing (SMARTCOMP), May 2016.Google ScholarCross Ref"",""Yidan Sun, Guiyuan Jiang, Siew-Kei Lam, Shicheng Chen, and Peilan He. Bus Travel Speed Prediction using Attention Network of Heterogeneous Correlation Features. In Proceedings of ICDM. Society for Industrial and Applied Mathematics, May 2019. ISBN 978-1-61197-567-3. URL https://epubs.siam.org/doi/book/10.1137/1.9781611975673.Google ScholarCross Ref"",""Transit App. \""how we mapped the world's weirdest streets\"", 2015. URL \""https://medium.com/transit-app/hello-nairobi-cc27bb5a73b7\"".Google Scholar"",""Transit Center. Who's on board. Technical report, Transit Center, 2016. URL http://transitcenter.org/wp-content/uploads/2016/07/Whos-On-Board-2016-7_12_2016.pdf.Google Scholar"",""W. Treethidtaphat, W. Pattara-Atikom, and S. Khaimook. Bus arrival time prediction at any distance of bus route using deep neural network model. In 2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC), pages 988--992, Oct 2017.Google ScholarCross Ref"",""William Vincent and Lisa Callaghan Jerram. The potential for bus rapid transit to reduce transportation-related co_2 emissions. Journal of Public Transportation, 9 (3): 12, 2006.Google ScholarCross Ref"",""Jiafu Wan, Jianqi Liu, Zehui Shao, Athanasios V. Vasilakos, Muhammad Imran, and Keliang Zhou. Mobile crowd sensing for traffic prediction in internet of vehicles. Sensors (Basel), 16 (1), 2016.Google Scholar"",""Dong Wang, Junbo Zhang, Wei Cao, Jian Li, and Yu Zheng. When will you arrive? Estimating travel time based on deep neural networks. In Thirty-Second AAAI Conference on Artificial Intelligence, 2018.Google Scholar"",""Kari Edison Watkins, Brian Ferris, Alan Borning, G Scott Rutherford, and David Layton. Where is my bus? impact of mobile real-time information on the perceived and actual wait time of transit riders. Transportation Research Part A: Policy and Practice, 45 (8): 839--848, 2011.Google ScholarCross Ref"",""Nate Wessel, Jeff Allen, and Steven Farber. Constructing a routable retrospective transit timetable from a real-time vehicle location feed and GTFS. Journal of Transport Geography, 62: 92--97, 2017.Google ScholarCross Ref"",""Haitao Xu and Jing Ying. Bus arrival time prediction with real-time and historic data. Cluster Computing, 20 (4): 3099--3106, December 2017. ISSN 1573--7543.Google ScholarDigital Library"",""Feng Zhang, Qing Shen, and Kelly J. Clifton. Examination of traveler responses to real-time information about bus arrivals using panel data. Transportation Research Record, 2082 (1): 107--115, 2008.Google ScholarCross Ref"",""Chang-Jiang Zheng, Yi-Hua Zhang, and Xue-Jun Feng. Improved iterative prediction for multiple stop arrival time using a support vector machine. Transport, 27 (2): 158--164, 2012.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403377,Characterizing and Learning Representation on Customer Contact Journeys in Cellular Services,"Corporations spend billions of dollars annually caring for customers across multiple contact channels. A customer journey is the complete sequence of contacts that a given customer has with a company across multiple channels of communication. While each contact is important and contains rich information, studying customer journeys provides a better context to understand customers' behavior in order to improve customer satisfaction and loyalty, and to reduce care costs. However, journey sequences have a complex format due to the heterogeneity of user behavior: they are variable-length, multi-attribute, and exhibit a large cardinality in categories (e.g. contact reasons). The question of how to characterize and learn representations of customer journeys has not been studied in the literature. We propose to learn journey embeddings using a sequence-to-sequence framework that converts each customer journey into a fixed-length latent embedding. In order to improve the disentanglement and distributional properties of embeddings, the model is further modified by incorporating a Wasserstein autoencoder inspired regularization on the distribution of embeddings. Experiments conducted on an enterprise-scale dataset demonstrate the effectiveness of the proposed model and reveal significant improvements due to the regularization in both distinguishing journey pattern characteristics and predicting future customer engagement.","[{""name"":""Shuai Zhao"",""id"":""/profile/99659448687""},{""name"":""Wen-Ling Hsu"",""id"":""/profile/99659573704""},{""name"":""George Ma"",""id"":""/profile/99659574393""},{""name"":""Tan Xu"",""id"":""/profile/99659487154""},{""name"":""Guy Jacobson"",""id"":""/profile/81100030496""},{""name"":""Raif Rustamov"",""id"":""/profile/81331502900""},{""name"":""Shuai Zhao"",""id"":""/profile/99659448687""},{""name"":""Wen-Ling Hsu"",""id"":""/profile/99659573704""},{""name"":""George Ma"",""id"":""/profile/99659574393""},{""name"":""Tan Xu"",""id"":""/profile/99659487154""},{""name"":""Guy Jacobson"",""id"":""/profile/81100030496""},{""name"":""Raif Rustamov"",""id"":""/profile/81331502900""}]","[""Martin Arjovsky, Soumith Chintala, and Léon Bottou. 2017. Wasserstein gan. arXiv preprint arXiv:1701.07875 (2017).Google Scholar"",""Sanjeev Arora, Yingyu Liang, and Tengyu Ma. 2017. A simple but tough-to-beat baseline for sentence embeddings. In 5th International Conference on Learning Representations, ICLR 2017.Google Scholar"",""Shaojie Bai, J Zico Kolter, and Vladlen Koltun. 2018. An empirical evaluation of generic convolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:1803.01271 (2018).Google Scholar"",""Inci M Baytas, Cao Xiao, Xi Zhang, Fei Wang, Anil K Jain, and Jiayu Zhou. 2017. Patient subtyping via time-aware LSTM networks. In Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. 65--74.Google ScholarDigital Library"",""Y. Bengio, A. Courville, and P. Vincent. 2013. Representation Learning: A Review and New Perspectives. IEEE Transactions on Pattern Analysis and Machine Intelligence 35, 8 (Aug 2013), 1798--1828. https://doi.org/10.1109/TPAMI.2013.50Google ScholarDigital Library"",""Gaël Bernard and Periklis Andritsos. 2019. Contextual and Behavioral Customer Journey Discovery Using a Genetic Approach. In European Conference on Advances in Databases and Information Systems. Springer, 251--266.Google ScholarCross Ref"",""Kyunghyun Cho, Bart van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning Phrase Representations using RNN Encoder--Decoder for Statistical Machine Translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). 1724--1734.Google ScholarCross Ref"",""Alexis Conneau, Douwe Kiela, Holger Schwenk, Loïc Barrault, and Antoine Bordes. 2017. Supervised Learning of Universal Sentence Representations from Natural Language Inference Data. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Copenhagen, Denmark, 670--680. https://www.aclweb.org/anthology/ D17--1070Google ScholarCross Ref"",""Morris H DeGroot and Mark J Schervish. 2012. Probability and statistics. Pearson Education.Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).Google Scholar"",""Gallup. 2019. Behavioral Economics: Maximizing the Emotional Economy. https://www.gallup.com/services/170954/behavioral-economics.aspx.Google Scholar"",""Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N Dauphin. 2017. Convolutional sequence to sequence learning. In Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 1243--1252.Google ScholarDigital Library"",""Partha Ghosh, Mehdi SM Sajjadi, Antonio Vergari, Michael Black, and Bernhard Schölkopf. 2019. From variational to deterministic autoencoders. arXiv preprint arXiv:1903.12436 (2019).Google Scholar"",""Klaus Greff, Rupesh K Srivastava, Jan Koutník, Bas R Steunebrink, and Jürgen Schmidhuber. 2016. LSTM: A search space odyssey. IEEE transactions on neural networks and learning systems 28, 10 (2016), 2222--2232.Google Scholar"",""Arthur Gretton, Karsten M Borgwardt, Malte J Rasch, Bernhard Schölkopf, and Alexander Smola. 2012. A kernel two-sample test. Journal of Machine Learning Research 13, Mar (2012), 723--773.Google ScholarDigital Library"",""Ragnhild Halvorsrud, Knut Kvale, and Asbjørn Følstad. 2016. Improving service quality through customer journey analysis. (2016).Google Scholar"",""Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural computation 9, 8 (1997), 1735--1780.Google Scholar"",""Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirectional LSTM-CRF models for sequence tagging. arXiv preprint arXiv:1508.01991 (2015).Google Scholar"",""Sergey Ioffe and Christian Szegedy. 2015. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167 (2015).Google Scholar"",""Yozen Liu, Xiaolin Shi, Lucas Pierce, and Xiang Ren. 2019. Characterizing and Forecasting User Engagement with In-app Action Graph: A Case Study of Snapchat. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 2023--2031.Google ScholarDigital Library"",""Meena Mahajan, Prajakta Nimbhorkar, and Kasturi Varadarajan. 2012. The planar k-means problem is NP-hard. Theoretical Computer Science 442 (2012), 13--21.Google ScholarDigital Library"",""Christopher D Manning, Prabhakar Raghavan, and Hinrich Schütze. 2008. Introduction to information retrieval. Cambridge university press.Google Scholar"",""Asier Mujika, Florian Meier, and Angelika Steger. 2017. Fast-slowrecurrent neural networks. In Advances in Neural Information Processing Systems. 5915--5924.Google Scholar"",""Diederik P Kingma and Max Welling. 2014. Auto-Encoding Variational Bayes. In International Conference on Learning Representations.Google Scholar"",""JD Power. 2019. 2019 Wireless Customer Care Performance Studies. https://www.jdpower.com/business/press-releases/2019-wireless-customercare- performance-studies.Google Scholar"",""Raif M Rustamov. 2019. Closed-form Expressions for Maximum Mean Discrepancy with Applications to Wasserstein Auto-Encoders. arXiv preprint arXiv:1901.03227 (2019).Google Scholar"",""Tobias Schnabel, Igor Labutov, David Mimno, and Thorsten Joachims. 2015. Evaluation methods for unsupervised word embeddings. In Proceedings of the 2015 conference on empirical methods in natural language processing. 298--307.Google ScholarCross Ref"",""Jeffrey Spiess, Yves T'Joens, Raluca Dragnea, Peter Spencer, and Laurent Philippart. 2014. Using big data to improve customer experience and business performance. Bell labs technical journal 18, 4 (2014), 3--17.Google Scholar"",""I Tolstikhin, O Bousquet, S Gelly, and B Schölkopf. 2018. Wasserstein Auto- Encoders. In International Conference on Learning Representations (ICLR 2018). OpenReview. net.Google Scholar"",""Aaron van den Oord, Oriol Vinyals, and koray kavukcuoglu. 2017. Neural Discrete Representation Learning. In Advances in Neural Information Processing Systems 30, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.). Curran Associates, Inc., 6306--6315. http://papers.nips.cc/ paper/7210-neural-discrete-representation-learning.pdfGoogle Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998--6008.Google Scholar"",""Yan-BinWang, Zhu-Hong You, Xiao Li, Tong-Hai Jiang, Xing Chen, Xi Zhou, and Lei Wang. 2017. Predicting protein--protein interactions from protein sequences by a stacked sparse autoencoder deep neural network. Molecular BioSystems 13, 7 (2017), 1336--1344.Google ScholarCross Ref"",""QiongWu,Wen-Ling Hsu, Tan Xc, Zhenming Liu, George Ma, Guy Jacobson, and Shuai Zhao. 2019. Speaking with Actions-Learning Customer Journey Behavior. In 2019 IEEE 13th International Conference on Semantic Computing (ICSC). IEEE, 279--286.Google Scholar"",""Carl Yang, Xiaolin Shi, Luo Jie, and Jiawei Han. 2018. I Know You'll Be Back: Interpretable New User Clustering and Churn Prediction on a Mobile Social Application. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 914--922.Google ScholarDigital Library"",""Michael Zhai, Johnny Tan, and Jinho D Choi. 2016. Intrinsic and extrinsic evaluations of word embeddings. In Thirtieth AAAI Conference on Artificial Intelligence.Google ScholarDigital Library"",""Xunjie Zhu, Tingfeng Li, and Gerard De Melo. 2018. Exploring semantic properties of sentence embeddings. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). 632--637.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403378,CrowdQuake: A Networked System of Low-Cost Sensors for Earthquake Detection via Deep Learning,"Recently, low-cost acceleration sensors have been widely used to detect earthquakes due to the significant development of MEMS technologies. It, however, still requires a high-density network to fully harness the low-cost sensors, especially for real-time earthquake detection. The design of a high-performance and scalable networked system thus becomes essential to be able to process a large amount of sensor data from hundreds to thousands of the sensors. An efficient and accurate earthquake-detection algorithm is also necessary to distinguish earthquake waveforms from various kinds of non-earthquake ones within the huge data in real time. In this paper, we present CrowdQuake, a networked system based on low-cost acceleration sensors, which monitors ground motions and detects earthquakes, by developing a convolutional-recurrent neural network model. This model ensures high detection performance while maintaining false alarms at a negligible level. We also provide detailed case studies on two of a few small earthquakes that have been detected by CrowdQuake during its last one-year operation.","[{""name"":""Xin Huang"",""id"":""/profile/99659574086""},{""name"":""Jangsoo Lee"",""id"":""/profile/99659574142""},{""name"":""Young-Woo Kwon"",""id"":""/profile/99659448820""},{""name"":""Chul-Ho Lee"",""id"":""/profile/81367599602""},{""name"":""Xin Huang"",""id"":""/profile/99659574086""},{""name"":""Jangsoo Lee"",""id"":""/profile/99659574142""},{""name"":""Young-Woo Kwon"",""id"":""/profile/99659448820""},{""name"":""Chul-Ho Lee"",""id"":""/profile/81367599602""}]","[""2019. Apache Kafka. https://kafka.apache.org/Google Scholar"",""2019. ElasticSearch. https://www.elastic.co/Google Scholar"",""2019. Grafana. https://grafana.com/Google Scholar"",""2019. InfluxDB. https://kafka.apache.org/Google Scholar"",""C. M. Bishop. 2006. Pattern Recognition and Machine Learning. Springer.Google Scholar"",""R. W. Clayton, T. Heaton, M. Chandy, A. Krause, M. Kohler, J. Bunn, R. Guy, M. Olson, M. Faulkner, M. Cheng, L. Strand, R. Chandy, D. Obenshain, A. Liu, and M. Aivazis. 2011. Community seismic network. Annals of Geophysics, Vol. 54, 6 (2011).Google Scholar"",""E. Cochran, J. Lawrence, C. Christensen, and A. Chung. 2009. A novel strong-motion seismic network for community participation in earthquake monitoring. IEEE Instrumentation \u0026 Measurement Magazine, Vol. 12, 6 (2009).Google Scholar"",""A. D'Alessandro. 2016. Tiny accelerometers create Europe's first urban seismic network. Eos, Vol. 97, 10.1029 (2016).Google Scholar"",""J. Davis and M. Goadrich. 2006. The relationship between precision-recall and ROC curves. In Proceedings of ICML. 233--240.Google Scholar"",""M. Faulkner, R. Clayton, T. Heaton, K. M. Chandy, M. Kohler, J. J. Bunn, R. Guy, A. H. Liu, M. Olson, M. Cheng, and A. Krause. 2014. Community sense and response systems: Your phone as quake detector. Commun. ACM, Vol. 57 (2014), 66--75.Google ScholarDigital Library"",""M. Faulkner, M. Olson, R. Chandy, J. Krause, K. M. Chandy, and A. Krause. 2011. The next big one: Detecting earthquakes and other rare events from community-based sensors. In Proceedings of ACM/IEEE IPSN. 13--24.Google Scholar"",""T. Fawcett. 2006. An introduction to ROC analysis. Pattern Recognition Letters, Vol. 27, 8 (2006), 861--874.Google ScholarDigital Library"",""I. Goodfellow, Y. Bengio, and A. Courville. 2016. Deep Learning. MIT press.Google Scholar"",""S. Horiuchi, Y. Horiuchi, S. Yamamoto, H. Nakamura, C. Wu, P. A Rydelek, and M. Kachi. 2009. Home seismometer for earthquake early warning. Geophysical Research Letters, Vol. 36, 5 (2009).Google ScholarCross Ref"",""D. P. Kingma and J. Ba. 2015. Adam: A method for stochastic optimization. In Proceedings of the International Conference on Learning Representations (ICLR).Google Scholar"",""Q. Kong, R. M. Allen, L. Schreier, and Y.-W. Kwon. 2016. MyShake: A smartphone seismic network for earthquake early warning and beyond. Science Advances, Vol. 2, 2 (2016).Google Scholar"",""Q. Kong, A. Inbal, R. M. Allen, Q. Lv, and A. Puder. 2018. Machine learning aspects of the MyShake global smartphone seismic network. Seismological Research Letters, Vol. 90, 2A (December 2018), 546--552.Google Scholar"",""Q. Kong, Y.-W. Kwon, L. Schreierz, S Allen, R. Allen, and J. Strauss. 2015. Smartphone-based networks for earthquake detection. In Proceedings of 15th International Conference on Innovations for Community Services (I4CS). 1--8.Google Scholar"",""Q. Kong, Q. Lv, and R. M. Allen. 2019. Earthquake early warning and beyond: Systems challenges in smartphone-based seismic network. In Proceedings of ACM HotMobile. 57--62.Google Scholar"",""National Research Institute for Earth Science and Disaster Resilience (NIED). 2019. Strong-motion Seismograph Networks (K-NET, KiK-net). http://www.kyoshin.bosai.go.jp/kyoshin/data/index_en.htmlGoogle Scholar"",""T. Perol, M. Gharbi, and M. Denolle. 2018. Convolutional neural network for earthquake detection and location. Science Advances, Vol. 4, 2 (2018).Google Scholar"",""N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov. 2014. Dropout: A simple way to prevent neural networks from overfitting. Journal of Machine Learning Research (JMLR), Vol. 15, 1 (January 2014), 1929--1958.Google Scholar"",""D. J. Wald, V. Quitoriano, T. H. Heaton, and H. Kanamori. 1999. Relationships between peak ground acceleration, peak ground velocity, and modified Mercalli intensity in California. Earthquake Spectra, Vol. 15, 3 (1999), 557--564.Google ScholarCross Ref"",""Y.-M. Wu. 2015. Progress on development of an earthquake early warning system using low-cost sensors. Pure and Applied Geophysics, Vol. 172, 9 (2015), 2343--2351.Google ScholarCross Ref"",""W. Zhu and G. C. Beroza. 2018. PhaseNet: A deep-neural-network-based seismic arrival-time picking method. Geophysical Journal International, Vol. 216, 1 (2018), 261--273.Google Scholar""]"
https://doi.org/10.1145/3394486.3403379,An Empirical Analysis of Backward Compatibility in Machine Learning Systems,"In many applications of machine learning (ML), updates are performed with the goal of enhancing model performance. However, current practices for updating models rely solely on isolated, aggregate performance analyses, overlooking important dependencies, expectations, and needs in real-world deployments. We consider how updates, intended to improve ML models, can introduce new errors that can significantly affect downstream systems and users. For example, updates in models used in cloud-based classification services, such as image recognition, can cause unexpected erroneous behavior in systems that make calls to the services. Prior work has shown the importance of ""backward compatibility"" for maintaining human trust. We study challenges with backward compatibility across different ML architectures and datasets, focusing on common settings including data shifts with structured noise and ML employed in inferential pipelines. Our results show that (i) compatibility issues arise even without data shift due to optimization stochasticity, (ii) training on large-scale noisy datasets often results in significant decreases in backward compatibility even when model accuracy increases, and (iii) distributions of incompatible points align with noise bias, motivating the need for compatibility aware de-noising and robustness methods.","[{""name"":""Megha Srivastava"",""id"":""/profile/99659573855""},{""name"":""Besmira Nushi"",""id"":""/profile/81490688211""},{""name"":""Ece Kamar"",""id"":""/profile/81365597792""},{""name"":""Shital Shah"",""id"":""/profile/99659573915""},{""name"":""Eric Horvitz"",""id"":""/profile/81100323543""},{""name"":""Megha Srivastava"",""id"":""/profile/99659573855""},{""name"":""Besmira Nushi"",""id"":""/profile/81490688211""},{""name"":""Ece Kamar"",""id"":""/profile/81365597792""},{""name"":""Shital Shah"",""id"":""/profile/99659573915""},{""name"":""Eric Horvitz"",""id"":""/profile/81100323543""}]","[""Saleema Amershi, Andrew Begel, Christian Bird, Robert DeLine, Harald Gall, Ece Kamar, Nachiappan Nagappan, Besmira Nushi, and Thomas Zimmermann. 2019. Software engineering for machine learning: A case study. In ICSE-SEIP. IEEE.Google Scholar"",""Sean Andrist, Dan Bohus, Ece Kamar, and Eric Horvitz. 2017. What went wrong and why? diagnosing situated interaction failures in the wild. In ICSR.Google Scholar"",""Gagan Bansal, Besmira Nushi, Ece Kamar, Daniel S Weld, Walter S Lasecki, and Eric Horvitz. 2019. Updates in human-ai teams: Understanding and addressing the performance/compatibility tradeoff. In AAAI, Vol. 33. 2429--2437.Google ScholarCross Ref"",""Jan Bosch. 2009. From software product lines to software ecosystems. In SPLC.Google Scholar"",""Veronika Cheplygina, Marleen de Bruijne, and Josien PW Pluim. 2019. Not-so-supervised: a survey of semi-supervised, multi-instance, and transfer learning in medical image analysis. Medical image analysis, Vol. 54 (2019), 280--296.Google Scholar"",""Veronika Cheplygina, Isabel Pino Peña, Jesper Holst Pederson, David Lynch, Lauge Sørensen, and Marleen de Bruijne. 2018. Transfer Learning for Multicenter Classification of Chronic Obstructive Pulmonary Disease. IEEE Journal of Biomedical and Health Informatics, Vol. 22, 5 (2018), 1486--1496.Google ScholarCross Ref"",""Yeounoh Chung, Tim Kraska, Neoklis Polyzotis, Ki Hyun Tae, and Steven Euijong Whang. 2019. Slice finder: Automated data slicing for model validation. In ICDE.Google Scholar"",""Michele Dallachiesa, Amr Ebaid, Ahmed Eldawy, Ahmed K. Elmagarmid, Ihab F. Ilyas, Mourad Ouzzani, and Nan Tang. 2013. NADEEF: a commodity data cleaning system. In SIGMOD,, Kenneth A. Ross, Divesh Srivastava, and Dimitris Papadias (Eds.). ACM, 541--552. https://doi.org/10.1145/2463676.2465327Google Scholar"",""T. E. de Campos, B. R. Babu, and M. Varma. 2009. Character recognition in natural images. In VISAPP.Google Scholar"",""FICO. 2018 (accessed February 13, 2020). Explainable machine learning challenge. https://community.fico.com/s/explainable-machine-learning-challenge?tabset-3158a=4fbc8.Google Scholar"",""Benoît Frénay and Michel Verleysen. 2013. Classification in the presence of label noise: a survey. IEEE transactions on neural networks and learning systems, Vol. 25, 5 (2013), 845--869.Google Scholar"",""Robert M French. 1999. Catastrophic forgetting in connectionist networks. Trends in cognitive sciences, Vol. 3, 4 (1999), 128--135.Google Scholar"",""Ian J Goodfellow, Mehdi Mirza, Da Xiao, Aaron Courville, and Yoshua Bengio. 2013. An empirical investigation of catastrophic forgetting in gradient-based neural networks. arXiv preprint arXiv:1312.6211 (2013).Google Scholar"",""Dan Hendrycks and Thomas Dietterich. 2019. Benchmarking neural network robustness to common corruptions and perturbations. ICLR.Google Scholar"",""Lasse Holmstrom and Petri Koistinen. 1992. Using additive noise in back-propagation training. IEEE Transactions on Neural Networks, Vol. 3 (1992).Google ScholarDigital Library"",""Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and Li Fei-Fei. 2017. MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels. In ICML .Google Scholar"",""Andrej Karpathy. 2017. Software 2.0. https://medium.com/@karpathy/software-2-0-a64152b37c35Google Scholar"",""Ronald Kemker, Marc McClure, Angelina Abitino, Tyler L Hayes, and Christopher Kanan. 2018. Measuring catastrophic forgetting in neural networks. In AAAI.Google Scholar"",""Jonathan Krause, Benjamin Sapp, Andrew Howard, Howard Zhou, Alexander Toshev, Tom Duerig, James Philbin, and Li Fei-Fei. 2016. The unreasonable effectiveness of noisy data for fine-grained recognition. In ECCV.Google Scholar"",""Alex Krizhevsky. 2009. Learning multiple layers of features from tiny images. (2009).Google Scholar"",""Robert William Kruppa and Ravinder Prakash. U.S. Patent 0 298 668, Dec. 2008. Method for fraud detection using multiple scan technologies.Google Scholar"",""Alexey Kurakin, Ian J. Goodfellow, and Samy Bengio. 2017. Adversarial Machine Learning at Scale. ICLR.Google Scholar"",""Edith Law and Luis von Ahn. 2011. Human computation. Synthesis lectures on artificial intelligence and machine learning, Vol. 5, 3 (2011), 1--121.Google Scholar"",""Yann LeCun, Corinna Cortes, and CJ Burges. 2010. MNIST handwritten digit database. ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist, Vol. 2 (2010).Google Scholar"",""Yuncheng Li, Jianchao Yang, Yale Song, Liangliang Cao, Jiebo Luo, and Li-Jia Li. 2017. Learning from Noisy Labels with Distillation. ICCV, 1928--1936.Google ScholarCross Ref"",""Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. 2011. Learning Word Vectors for Sentiment Analysis. In ACL.Google Scholar"",""Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. 2017. Towards Deep Learning Models Resistant to Adversarial Attacks. ICLR.Google Scholar"",""Michael McCloskey and Neal J Cohen. 1989. Catastrophic interference in connectionist networks: The sequential learning problem. In Psychology of learning and motivation. Vol. 24. Elsevier, 109--165.Google Scholar"",""Gideon Mendels, Erica Cooper, Victor Soto, Julia Hirschberg, Mark Gales, Kate Knill, Anton Ragni, and Haipeng Wang. 2015. Improving Speech Recognition and Keyword Search for Low Resource Languages Using Web Data. ISCA (2015).Google Scholar"",""Nagarajan Natarajan, Inderjit S. Dhillon, Pradeep Ravikumar, and Ambuj Tewari. 2013. Learning with Noisy Labels. In NeurIPS .Google Scholar"",""Besmira Nushi, Ece Kamar, and Eric Horvitz. 2018. Towards accountable ai: Hybrid human-machine analyses for characterizing system failure. In HCOMP.Google Scholar"",""Besmira Nushi, Ece Kamar, Eric Horvitz, and Donald Kossmann. 2017. On human intellect and machine failures: Troubleshooting integrative machine learning systems. In AAAI.Google Scholar"",""Erhard Rahm and Hong Hai Do. 2000. Data cleaning: Problems and current approaches. IEEE Data Eng. Bull., Vol. 23, 4 (2000), 3--13.Google Scholar"",""Alexander Ratner, Stephen H Bach, Henry Ehrenberg, Jason Fries, Sen Wu, and Christopher Ré. 2019. Snorkel: Rapid training data creation with weak supervision. The VLDB Journal (2019), 1--22.Google Scholar"",""Theodoros Rekatsinas, Xu Chu, Ihab F. Ilyas, and Christopher Ré. 2017. HoloClean: Holistic Data Repairs with Probabilistic Inference. PVLDB, Vol. 10, 11 (2017), 1190--1201. https://doi.org/10.14778/3137628.3137631Google ScholarDigital Library"",""David Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, Michael Young, Jean-Francois Crespo, and Dan Dennison. 2015. Hidden technical debt in machine learning systems. In NeurIPS.Google Scholar"",""Sainbayar Sukhbaatar, Joan Bruna, Manohar Paluri, Lubomir D. Bourdev, and Rob Fergus. 2015. Training Convolutional Networks with Noisy Labels. In ICLR 2015.Google Scholar"",""Mariya Toneva, Alessandro Sordoni, Remi Tachet des Combes, Adam Trischler, Yoshua Bengio, and Geoffrey J Gordon. 2019. An empirical study of example forgetting during deep neural network learning. ICLR.Google Scholar"",""Luis Von Ahn, Manuel Blum, Nicholas J Hopper, and John Langford. 2003. CAPTCHA: Using hard AI problems for security. In EUROCRYPT. Springer.Google Scholar"",""Junfeng Wen, Chun-Nam Yu, and Russell Greiner. 2014. Robust Learning under Uncertain Test Distributions: Relating Covariate Shift to Model Misspecification. ICML.Google Scholar"",""Jiawei Zhang, Yang Wang, Piero Molino, Lezhi Li, and David S Ebert. 2018. Manifold: A model-agnostic framework for interpretation and diagnosis of machine learning models. TVCG, Vol. 25, 1 (2018), 364--373.Google ScholarDigital Library"",""Tianyi Zhang, Cuiyun Gao, Lei Ma, Michael R Lyu, and Miryung Kim. 2019. An empirical study of common challenges in developing deep learning applications. In ISSRE.Google Scholar""]"
https://doi.org/10.1145/3394486.3403380,DeepTriage: Automated Transfer Assistance for Incidents in Cloud Services,"As cloud services are growing and generating high revenues, the cost of downtime in these services is becoming significantly expensive. To reduce loss and service downtime, a critical primary step is to execute incident triage, the process of assigning a service incident to the correct responsible team, in a timely manner. An incorrect assignment risks additional incident reroutings and increases its time to mitigate by 10x. However, automated incident triage in large cloud services faces many challenges: (1) a highly imbalanced incident distribution from a large number of teams, (2) wide variety in formats of input data or data sources, (3) scaling to meet production-grade requirements, and (4) gaining engineers' trust in using machine learning recommendations. To address these challenges, we introduce DeepTriage, an intelligent incident transfer service combining multiple machine learning techniques - gradient boosted classifiers, clustering methods, and deep neural networks - in an ensemble to recommend the responsible team to triage an incident. Experimental results on real incidents in Microsoft Azure show that our service achieves 82.9% F1 score. For highly impacted incidents, DeepTriage achieves F1 score from 76.3% -- 91.3%. We have applied best practices and state-of-the-art frameworks to scale DeepTriage to handle incident routing for all cloud services. DeepTriage has been deployed in Azure since October 2017 and is used by thousands of teams daily.","[{""name"":""Phuong Pham"",""id"":""/profile/99659574237""},{""name"":""Vivek Jain"",""id"":""/profile/99659573067""},{""name"":""Lukas Dauterman"",""id"":""/profile/99659574232""},{""name"":""Justin Ormont"",""id"":""/profile/81372594091""},{""name"":""Navendu Jain"",""id"":""/profile/81310487383""},{""name"":""Phuong Pham"",""id"":""/profile/99659574237""},{""name"":""Vivek Jain"",""id"":""/profile/99659573067""},{""name"":""Lukas Dauterman"",""id"":""/profile/99659574232""},{""name"":""Justin Ormont"",""id"":""/profile/81372594091""},{""name"":""Navendu Jain"",""id"":""/profile/81310487383""}]","[""Zeeshan Ahmed, Saeed Amizadeh, Mikhail Bilenko, Rogan Carr, Wei-Sheng Chin, Yael Dekel, Xavier Dupre, Vadim Eksarevskiy, Senja Filipi, Tom Finley, Abhishek Goswami, Monte Hoover, Scott Inglis, Matteo Interlandi, Najeeb Kazmi, Gleb Krivosheev, Pete Luferenko, Ivan Matantsev, Sergiy Matusevych, Shahab Moradi, Gani Nazirov, Justin Ormont, Gal Oshri, Artidoro Pagnoni, Jignesh Parmar, Prabhat Roy, Mohammad Zeeshan Siddiqui, Markus Weimer, Shauheen Zahirazami, and Yiwen Zhu. 2019. Machine Learning at Microsoft with ML.NET. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining (Anchorage, AK, USA) (KDD '19). Association for Computing Machinery, New York, NY, USA, 2448--2458. https://doi.org/10.1145/3292500.3330667Google ScholarDigital Library"",""AppDynamics. 2015. The Real Cost of Downtime, The Real Potential of DevOps. https://www.appdynamics.com/blog/engineering/idc-devops-cost-downtime Retrieved February 13, 2020 fromGoogle Scholar"",""Microsoft Azure. 2020 a. Batch: Cloud-scale job scheduling and compute management. https://azure.microsoft.com/en-us/services/batch/ Retrieved February 13, 2020 fromGoogle Scholar"",""Microsoft Azure. 2020 b. Logic Apps: Quickly build powerful integration solutions. https://azure.microsoft.com/en-us/services/logic-apps/ Retrieved February 13, 2020 fromGoogle Scholar"",""Pamela Bhattacharya, Iulian Neamtiu, and Christian R Shelton. 2012. Automated, highly-accurate, bug assignment using machine learning and tossing graphs. Journal of Systems and Software, Vol. 85, 10 (2012), 2275--2292.Google ScholarDigital Library"",""Peter Bodik, Moises Goldszmidt, Armando Fox, Dawn B Woodard, and Hans Andersen. 2010. Fingerprinting the datacenter: automated classification of performance crises. In Proceedings of the 5th European conference on Computer systems. 111--124.Google ScholarDigital Library"",""Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. Enriching word vectors with subword information. Transactions of the Association for Computational Linguistics, Vol. 5 (2017), 135--146.Google ScholarCross Ref"",""Ronnie Chaiken, Bob Jenkins, Per-Åke Larson, Bill Ramsey, Darren Shakib, Simon Weaver, and Jingren Zhou. 2008. SCOPE: easy and efficient parallel processing of massive data sets. Proceedings of the VLDB Endowment, Vol. 1, 2 (2008), 1265--1276.Google ScholarDigital Library"",""Junjie Chen, Xiaoting He, Qingwei Lin, Yong Xu, Hongyu Zhang, Dan Hao, Feng Gao, Zhangwei Xu, Yingnong Dang, and Dongmei Zhang. 2019 a. An empirical investigation of incident triage for online service systems. In 2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP). IEEE, 111--120.Google ScholarDigital Library"",""Junjie Chen, Xiaoting He, Qingwei Lin, Hongyu Zhang, Dan Hao, Feng Gao, Zhangwei Xu, Yingnong Dang, and Dongmei Zhang. 2019 b. Continuous incident triage for large-scale online service systems. In 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 364--375.Google ScholarDigital Library"",""Edward Choi, Mohammad Taha Bahadori, Jimeng Sun, Joshua Kulas, Andy Schuetz, and Walter Stewart. 2016. Retain: An interpretable predictive model for healthcare using reverse time attention mechanism. In Advances in Neural Information Processing Systems. 3504--3512.Google Scholar"",""Yeounoh Chung, Tim Kraska, Neoklis Polyzotis, Ki Hyun Tae, and Steven Euijong Whang. 2019. Slice finder: Automated data slicing for model validation. In 2019 IEEE 35th International Conference on Data Engineering (ICDE). IEEE, 1550--1553.Google ScholarCross Ref"",""Ira Cohen, Jeffrey S Chase, Moises Goldszmidt, Terence Kelly, and Julie Symons. 2004. Correlating Instrumentation Data to System States: A Building Block for Automated Diagnosis and Control.. In OSDI, Vol. 4. 16--16.Google ScholarDigital Library"",""Ira Cohen, Steve Zhang, Moises Goldszmidt, Julie Symons, Terence Kelly, and Armando Fox. 2005. Capturing, indexing, clustering, and retrieving system history. ACM SIGOPS Operating Systems Review, Vol. 39, 5 (2005), 105--118.Google ScholarDigital Library"",""Forbes. 2019. Public Cloud Soaring To $331B By 2022 According To Gartner. https://www.forbes.com/sites/louiscolumbus/2019/04/07/public-cloud-soaring-to-331b-by-2022-according-to-gartner Retrieved February 13, 2020 fromGoogle Scholar"",""Business Insider. 2018. Amazon's one hour of downtime on Prime Day may have cost it up to $100 million in lost sales. https://www.businessinsider.com/amazon-prime-day-website-issues-cost-it-millions-in-lost-sales-2018-7 Retrieved February 13, 2020 fromGoogle Scholar"",""Gaeul Jeong, Sunghun Kim, and Thomas Zimmermann. 2009. Improving bug triage with bug tossing graphs. In Proceedings of the 7th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering. 111--120.Google ScholarDigital Library"",""Leif Jonsson, Markus Borg, David Broman, Kristian Sandahl, Sigrid Eldh, and Per Runeson. 2016. Automated bug assignment: Ensemble-based machine learning in large scale industrial contexts. Empirical Software Engineering, Vol. 21, 4 (2016), 1533--1578.Google ScholarDigital Library"",""Günter Klambauer, Thomas Unterthiner, Andreas Mayr, and Sepp Hochreiter. 2017. Self-normalizing neural networks. In Advances in neural information processing systems. 971--980.Google Scholar"",""Sun-Ro Lee, Min-Jae Heo, Chan-Gun Lee, Milhan Kim, and Gaeul Jeong. 2017. Applying deep learning based automatic bug triager to industrial projects. In Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering. 926--931.Google ScholarDigital Library"",""Jian-Guang Lou, Qingwei Lin, Rui Ding, Qiang Fu, Dongmei Zhang, and Tao Xie. 2013. Software analytics for incident management of online services: An experience report. In 2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 475--485.Google ScholarDigital Library"",""Jian-Guang Lou, Qingwei Lin, Rui Ding, Qiang Fu, Dongmei Zhang, and Tao Xie. 2017. Experience report on applying software analytics in incident management of online service. Automated Software Engineering, Vol. 24, 4 (2017), 905--941.Google ScholarDigital Library"",""Dominique Matter, Adrian Kuhn, and Oscar Nierstrasz. 2009. Assigning bug reports using a vocabulary-based expertise model of developers. In 2009 6th IEEE international working conference on mining software repositories. IEEE, 131--140.Google Scholar"",""G Murphy and D Cubranic. 2004. Automatic bug triage using text categorization. In Proceedings of the Sixteenth International Conference on Software Engineering \u0026 Knowledge Engineering. Citeseer.Google Scholar"",""Rahul Potharaju, Joseph Chan, Luhui Hu, Cristina Nita-Rotaru, Mingshi Wang, Liyuan Zhang, and Navendu Jain. 2015. ConfSeer: Leveraging Support Knowledge Bases for Automated Misconfiguration Detection. Proceedings of the VLDB Endowment, Vol. 8, 12 (2015), 1828--1839.Google ScholarDigital Library"",""Rahul Potharaju, Navendu Jain, and Cristina Nita-Rotaru. 2013. Juggling the jigsaw: Towards automated problem inference from network trouble tickets. In Presented as part of the 10th $$USENIX$$ Symposium on Networked Systems Design and Implementation ({NSDI} 13). 127--141.Google Scholar"",""Maja Rudolph, Francisco Ruiz, Stephan Mandt, and David Blei. 2016. Exponential family embeddings. In Advances in Neural Information Processing Systems. 478--486.Google Scholar"",""Carl Vondrick, Aditya Khosla, Tomasz Malisiewicz, and Antonio Torralba. 2013. Hoggles: Visualizing object detection features. In Proceedings of the IEEE International Conference on Computer Vision. 1--8.Google ScholarDigital Library"",""Maui Williams. 2019. Tips for Modern NOCs -- Alleviating Incident Routing Bottlenecks. https://www.bigpanda.io/blog/tips-for-modern-nocs-alleviating-incident-routing-bottlenecks/ Retrieved February 13, 2020 fromGoogle Scholar"",""Sheng-Qu Xi, Yuan Yao, Xu-Sheng Xiao, Feng Xu, and Jian Lv. 2019. Bug Triaging Based on Tossing Sequence Modeling. Journal of Computer Science and Technology, Vol. 34, 5 (2019), 942--956.Google ScholarCross Ref"",""Xin Xia, David Lo, Xinyu Wang, and Bo Zhou. 2013. Accurate developer recommendation for bug resolution. In 2013 20th Working Conference on Reverse Engineering (WCRE). IEEE, 72--81.Google ScholarCross Ref"",""Xihao Xie, Wen Zhang, Ye Yang, and Qing Wang. 2012. Dretom: Developer recommendation based on topic models for bug resolution. In Proceedings of the 8th international conference on predictive models in software engineering. 19--28.Google ScholarDigital Library"",""Wei Xu, Ling Huang, Armando Fox, David Patterson, and Michael I Jordan. 2009. Detecting large-scale system problems by mining console logs. In Proceedings of the ACM SIGOPS 22nd symposium on Operating systems principles. 117--132.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403381,"An Automatic Approach for Generating Rich, Linked Geo-Metadata from Historical Map Images","Historical maps contain detailed geographic information difficult to find elsewhere covering long-periods of time (e.g., 125 years for the historical topographic maps in the US). However, these maps typically exist as scanned images without searchable metadata. Existing approaches making historical maps searchable rely on tedious manual work (including crowd-sourcing) to generate the metadata (e.g., geolocations and keywords). Optical character recognition (OCR) software could alleviate the required manual work, but the recognition results are individual words instead of location phrases (e.g., ""Black'' and ""Mountain'' vs. ""Black Mountain''). This paper presents an end-to-end approach to address the real-world problem of finding and indexing historical map images. This approach automatically processes historical map images to extract their text content and generates a set of metadata that is linked to large external geospatial knowledge bases. The linked metadata in the RDF (Resource Description Framework) format support complex queries for finding and indexing historical maps, such as retrieving all historical maps covering mountain peaks higher than 1,000 meters in California. We have implemented the approach in a system called mapKurator. We have evaluated mapKurator using historical maps from several sources with various map styles, scales, and coverage. Our results show significant improvement over the state-of-the-art methods. The code has been made publicly available as modules of the Kartta Labs project at https://github.com/kartta-labs/Project.","[{""name"":""Zekun Li"",""id"":""/profile/99659481202""},{""name"":""Yao-Yi Chiang"",""id"":""/profile/81100152901""},{""name"":""Sasan Tavakkol"",""id"":""/profile/99659139642""},{""name"":""Basel Shbita"",""id"":""/profile/99659573549""},{""name"":""Johannes H. Uhl"",""id"":""/profile/99659226548""},{""name"":""Stefan Leyk"",""id"":""/profile/81323492617""},{""name"":""Craig A. Knoblock"",""id"":""/profile/81100628789""},{""name"":""Zekun Li"",""id"":""/profile/99659481202""},{""name"":""Yao-Yi Chiang"",""id"":""/profile/81100152901""},{""name"":""Sasan Tavakkol"",""id"":""/profile/99659139642""},{""name"":""Basel Shbita"",""id"":""/profile/99659573549""},{""name"":""Johannes H. Uhl"",""id"":""/profile/99659226548""},{""name"":""Stefan Leyk"",""id"":""/profile/81323492617""},{""name"":""Craig A. Knoblock"",""id"":""/profile/81100628789""}]","[""Yao-Yi Chiang. 2015. Querying historical maps as a unified, structured, and linked spatiotemporal source: Vision paper. In ACM SIGSPATIAL. New York, NY, USA, 16:1--16:4.Google Scholar"",""Yao-Yi Chiang, Weiwei Duan, Stefan Leyk, Johannes H Uhl, and Craig A Knoblock. 2020. Using Historical Maps in Scientific Studies: Applications, Challenges, and Best Practices. Springer.Google Scholar"",""Yao-Yi Chiang, Stefan Leyk, and Craig A Knoblock. 2014. A survey of digital map processing techniques. ACM Computing Surveys (CSUR), Vol. 47, 1 (2014), 1--44.Google ScholarDigital Library"",""Yao-Yi Chiang, Stefan Leyk, Narges Honarvar Nazari, Sima Moghaddam, and Tian Xiang Tan. 2016. Assessing the impact of graphical quality on automatic text recognition in digital maps. Computers \u0026 Geosciences, Vol. 93 (2016), 21--35.Google ScholarDigital Library"",""Martin Ester, Hans-Peter Kriegel, Jörg Sander, Xiaowei Xu, et almbox. 1996. A density-based algorithm for discovering clusters in large spatial databases with noise.. In ACM SIGKDD, Vol. 96. 226--231.Google Scholar"",""Laura Ferrari, Alberto Rosi, Marco Mamei, and Franco Zambonelli. 2011. Extracting urban patterns from location-based social networks. In Proceedings of the 3rd International Workshop on Location-Based Social Networks. 9--16.Google ScholarDigital Library"",""Xianping Ge. 2005. Address geocoding. US Patent 6,934,634.Google Scholar"",""Qing Guo, Wei Feng, Ce Zhou, Rui Huang, Liang Wan, and Song Wang. 2017. Learning dynamic siamese network for visual object tracking. In ICCV. 1763--1771.Google Scholar"",""Elad Hoffer and Nir Ailon. 2015. Deep metric learning using triplet network. In International Workshop on Similarity-Based Pattern Recognition. Springer, 84--92.Google ScholarCross Ref"",""RichardSocher JeffreyPennington and ChristopherD Manning. [n.d.]. Glove: Global vectors for word representation. Citeseer.Google Scholar"",""Anna Khoreva, Rodrigo Benenson, Jan Hosang, Matthias Hein, and Bernt Schiele. 2017. Simple does it: Weakly supervised instance and semantic segmentation. In CVPR. 876--885.Google Scholar"",""Zekun Li. 2019. Generating Historical Maps from Online Maps. In ACM SIGSPATIAL. 610--611.Google Scholar"",""Minghui Liao, Baoguang Shi, and Xiang Bai. 2018. Textboxes: A single-shot oriented scene text detector. IEEE transactions on image processing, Vol. 27, 8 (2018), 3676--3690.Google Scholar"",""New York Public Library. [n.d.]. Maps and Atlases - NYPL Digital Collections. https://digitalcollections.nypl.org/collections/lane/maps-atlasesGoogle Scholar"",""Google LLC. [n.d.]. Google Cloud Vision API. https://cloud.google.com/visionGoogle Scholar"",""Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. arXiv:1301.3781 (2013).Google Scholar"",""National Library of Scotland. [n.d.]. Ordnance Survey maps. https://maps.nls.uk/os/Google Scholar"",""Sina Rashidian, Xinyu Dong, Shubham Kumar Jain, and Fusheng Wang. 2018. EaserGeocoder: Integrative geocoding with machine learning (demo paper). In ACM SIGSPATIAL. 572--575.Google Scholar"",""Olaf Ronneberger, Philipp Fischer, and Thomas Brox. 2015. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computer-assisted intervention. Springer, 234--241.Google ScholarCross Ref"",""United States Geological Survey. [n.d.]. United States Geological Survey maps. https://www.usgs.gov/products/maps/overviewGoogle Scholar"",""Yaniv Taigman, Ming Yang, Marc'Aurelio Ranzato, and Lior Wolf. 2014. Deepface: Closing the gap to human-level performance in face verification. In CVPR. 1701--1708.Google Scholar"",""Sasan Tavakkol, Yao-Yi Chiang, Tim Waters, Feng Han, Kisalaya Prasad, and Raimondas Kiveris. 2019. Kartta labs: Unrendering historical maps. In Proceedings of the 3rd ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery. 48--51.Google ScholarDigital Library"",""Ruihan Xu, Luis Herranz, Shuqiang Jiang, Shuang Wang, Xinhang Song, and Ramesh Jain. 2015. Geolocalized modeling for dish recognition. IEEE Transactions on Multimedia, Vol. 17, 8 (2015), 1187--1199.Google ScholarCross Ref"",""Ronald Yu, Zexuan Luo, and Yao-Yi Chiang. 2016. Recognizing text in historical maps using maps from multiple time periods. In ICPR. IEEE, 3993--3998.Google Scholar"",""Xinyu Zhou, Cong Yao, He Wen, Yuzhi Wang, Shuchang Zhou, Weiran He, and Jiajun Liang. 2017. EAST: an efficient and accurate scene text detector. In CVPR. 5551--5560.Google Scholar""]"
https://doi.org/10.1145/3394486.3403382,Bootstrapping Complete The Look at Pinterest,"Putting together an ideal outfit is a process that involves creativity and style intuition. This makes it a particularly difficult task to automate. Existing styling products generally involve human specialists and a highly curated set of fashion items. In this paper, we will describe how we bootstrapped the Complete The Look (CTL) system at Pinterest. This is a technology that aims to learn the subjective task of ""style compatibility"" in order to recommend complementary items that complete an outfit. In particular, we want to show recommendations from other categories that are compatible with an item of interest. For example, what are some heels that go well with this cocktail dress? We will introduce our outfit dataset of over 1 million outfits and 4 million objects, a subset of which we will make available to the research community, and describe the pipeline used to obtain and refresh this dataset. Furthermore, we will describe how we evaluate this subjective task and compare model performance across multiple training methods. Lastly, we will share our lessons going from experimentation to working prototype, and how to mitigate failure modes in the production environment. Our work represents one of the first examples of an industrial-scale solution for compatibility-based fashion recommendation.","[{""name"":""Eileen Li"",""id"":""/profile/99659572992""},{""name"":""Eric Kim"",""id"":""/profile/99659574963""},{""name"":""Andrew Zhai"",""id"":""/profile/82658617457""},{""name"":""Josh Beal"",""id"":""/profile/99659575118""},{""name"":""Kunlong Gu"",""id"":""/profile/99659573522""},{""name"":""Eileen Li"",""id"":""/profile/99659572992""},{""name"":""Eric Kim"",""id"":""/profile/99659574963""},{""name"":""Andrew Zhai"",""id"":""/profile/82658617457""},{""name"":""Josh Beal"",""id"":""/profile/99659575118""},{""name"":""Kunlong Gu"",""id"":""/profile/99659573522""}]","[""[n.d.]. apex.amp - Apex 0.1.0 documentation. https://nvidia.github.io/apex/amp. html. (Accessed on 06/12/2020).Google Scholar"",""[n.d.]. Flashlight for Pinterest -- Visual Discovery on Steroids. http://www. mcng marketing.com/flashlight-pinterest-visual-discovery-steroids/. (Accessed on 02/05/2020).Google Scholar"",""Sean Bell and Kavita Bala. 2015. Learning Visual Similarity for Product Design with Convolutional Neural Networks. ACM Trans. Graph. 34, 4, Article 98 (July 2015), 10 pages. https://doi.org/10.1145/2766959Google ScholarDigital Library"",""Wen Chen, Pipei Huang, Jiaming Xu, Xin Guo, Cheng Guo, Fei Sun, Chao Li, Andreas Pfadler, Huan Zhao, and Binqiang Zhao. 2019. POG: Personalized Outfit Generation for Fashion Recommendation at Alibaba iFashion. (05 2019).Google Scholar"",""Zeyu Cui, Zekun Li, Shu Wu, Xiaoyu Zhang, and Liang Wang. 2019. Dressing as a Whole: Outfit Compatibility Learning Based on Node-wise Graph Neural Networks. (02 2019). https://doi.org/10.1145/3308558.3313444Google Scholar"",""Ross Girshick, Ilija Radosavovic, Georgia Gkioxari, Piotr Dollár, and Kaiming He. 2018. Detectron. https://github.com/facebookresearch/detectron.Google Scholar"",""Kunlong Gu. 2019. Automating Shop the Look on Pinterest - Pinterest Engineering Blog - Medium. https://medium.com/pinterest-engineering/automating-shopthe-look-on-pinterest-a17aeff0eae2. (Accessed on 02/02/2020).Google Scholar"",""Xintong Han, Zuxuan Wu, Yu-Gang Jiang, and Larry S. Davis. 2017. Learning Fashion Compatibility with Bidirectional LSTMs. In Proceedings of the 25th ACM International Conference on Multimedia (Mountain View, California, USA) (MM '17). Association for Computing Machinery, New York, NY, USA, 1078--1086. https://doi.org/10.1145/3123266.3123394Google Scholar"",""Ruining He, Charles Packer, and Julian McAuley. 2016. Learning Compatibility Across Categories for Heterogeneous Item Recommendation. 937--942. https: //doi.org/10.1109/ICDM.2016.0116Google Scholar"",""Ruining He, Charles Packer, and Julian McAuley. 2016. Learning Compatibility Across Categories for Heterogeneous Item Recommendation. 937--942. https://doi.org/10.1109/ICDM.2016.0116Google Scholar"",""Elad Hoffer and Nir Ailon. 2014. Deep Metric Learning Using Triplet Network. https://doi.org/10.1007/978-3-319-24261-3_7Google Scholar"",""Wei-Lin Hsiao and Kristen Grauman. 2017. Creating Capsule Wardrobes from Fashion Images. 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (2017), 7161--7170.Google Scholar"",""Wei-Lin Hsiao and Kristen Grauman. 2017. Learning the Latent \""Look\"": Unsupervised Discovery of a Style-Coherent Embedding from Fashion Images. (07 2017).Google Scholar"",""Jie Hu, Li Shen, and Gang Sun. 2017. Squeeze-and-Excitation Networks. CoRR abs/1709.01507 (2017). arXiv:1709.01507 http://arxiv.org/abs/1709.01507Google Scholar"",""Junshi Huang, Rogerio Feris, Qiang Chen, and Shuicheng Yan. 2015. Cross Domain Image Retrieval with a Dual Attribute-Aware Ranking Network. (05 2015). https://doi.org/10.1109/ICCV.2015.127Google Scholar"",""Vignesh Jagadeesh, Robinson Piramuthu, Anurag Bhardwaj, Wei di, and Neel Sundaresan. 2014. Large Scale Visual Recommendations From Street Fashion Images. Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (01 2014). https://doi.org/10.1145/2623330.2623332Google ScholarDigital Library"",""Yushi Jing, David C. Liu, Dmitry Kislyuk, Andrew Zhai, Jiajing Xu, Jeff Donahue, and Sarah Tavel. 2015. Visual Search at Pinterest. CoRR abs/1505.07647 (2015). arXiv:1505.07647 http://arxiv.org/abs/1505.07647Google Scholar"",""W. C. Kang, E. Kim, J. Leskovec, C. Rosenberg, and J. McAuley. 2018. Complete the Look: Scene-based Complementary Product Recommendation. arXiv:1812.01748 (2018). arXiv:arXiv:1812.01748Google Scholar"",""Adriana Kovashka, Devi Parikh, and Kristen Grauman. 2012. Whittle Search: Image Search with Relative Attribute Feedback. Proceedings / CVPR, IEEE Computer Society Conference on Computer Vision and Pattern Recognition. IEEE Computer Society Conference on Computer Vision and Pattern Recognition 115, 2973--2980. https://doi.org/10.1109/CVPR.2012.6248026Google Scholar"",""Hanbit Lee, Jinseok Seol, and Sang-goo Lee. 2017. Style2Vec: Representation Learning for Fashion Items from Style Sets. (08 2017).Google Scholar"",""Yuncheng Li, Liangliang Cao, Jiang Zhu, and Jiebo Luo. 2016. Mining Fashion Outfit Composition Using An End-to-End Deep Learning Approach on Set Data. IEEE Transactions on Multimedia PP (08 2016). https://doi.org/10.1109/TMM.2017. 2690144Google Scholar"",""Tsung-Yi Lin, Piotr Dollár, Ross B. Girshick, Kaiming He, Bharath Hariharan, and Serge J. Belongie. 2016. Feature Pyramid Networks for Object Detection. CoRR abs/1612.03144 (2016). arXiv:1612.03144 http://arxiv.org/abs/1612.03144Google Scholar"",""Si Liu, Tam Nguyen, Jiashi Feng, Meng Wang, and Shuicheng Yan. 2012. Hi, magic closet, tell me what to wear! 1333--1334. https://doi.org/10.1145/2393347.2396470Google Scholar"",""Ziwei Liu, Ping Luo, Shi Qiu, Xiaogang Wang, and Xiaoou Tang. 2016. DeepFashion: Powering Robust Clothes Recognition and Retrieval with Rich Annotations. 1096--1104. https://doi.org/10.1109/CVPR.2016.124Google Scholar"",""Alexander C. Berg Tamara L. Berg M. Hadi Kiapour, Kota Yamaguchi. 2014. Hipster Wars: Discovering Elements of Fashion Styles. In European Conference on Computer Vision.Google Scholar"",""Svetlana Lazebnik Alexander C. Berg Tamara L. Berg M. Hadi Kiapour, Xufeng Han. 2015. Where to Buy It:Matching Street Clothing Photos in Online Shops. In International Conference on Computer Vision.Google Scholar"",""Kevin Matzen, Kavita Bala, and Noah Snavely. 2017. StreetStyle: Exploring worldwide clothing styles from millions of photos. arXiv preprint arXiv:1706.01869 (2017).Google Scholar"",""Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Hengel. 2015. Image-Based Recommendations on Styles and Substitutes. (06 2015). https://doi.org/10.1145/2766462.2767755Google Scholar"",""Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. 2019. PyTorch: An imperative style, high-performance deep learning library. In Advances in Neural Information Processing Systems. 8024--8035.Google Scholar"",""Shaoqing Ren, Kaiming He, Ross B. Girshick, and Jian Sun. 2015. Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks. CoRR abs/1506.01497 (2015). arXiv:1506.01497 http://arxiv.org/abs/1506.01497Google Scholar"",""Edgar Simo-Serra and Hiroshi Ishikawa. 2016. Fashion Style in 128 Floats: Joint Ranking and Classification Using Weak Data for Feature Extraction. 298--307. https://doi.org/10.1109/CVPR.2016.39Google Scholar"",""Xuemeng Song, Fuli Feng, Jinhuan Liu, Zekun Li, Liqiang Nie, and Jun Ma. 2017. NeuroStylist: Neural Compatibility Modeling for Clothing Matching. 753--761. https://doi.org/10.1145/3123266.3123314Google Scholar"",""Mariya Vasileva, Bryan Plummer, Krishna Dusad, Shreya Rajpal, Ranjitha Kumar, and David Forsyth. 2018. Learning Type-Aware Embeddings for Fashion Compatibility. (03 2018).Google Scholar"",""Xianwang Wang and Tong Zhang. 2011. Clothes search in consumer photos via color matching and attribute learning. 1353--1356. https://doi.org/10.1145/ 2072298.2072013Google Scholar"",""Saining Xie, Ross B. Girshick, Piotr Dollár, Zhuowen Tu, and Kaiming He. 2016. Aggregated Residual Transformations for Deep Neural Networks. CoRR abs/1611.05431 (2016). arXiv:1611.05431 http://arxiv.org/abs/1611.05431Google Scholar"",""Andrew Zhai. [n.d.]. Building Pinterest Lens: a real world visual discovery system. https://medium.com/pinterest-engineering/building-pinterest-lens-areal-world-visual-discovery-system-59812d8cbfbc. (Accessed on 02/05/2020).Google Scholar"",""Andrew Zhai, Hao-Yu Wu, Eric Tzeng, Dong Huk Park, and Charles Rosenberg. 2019. Learning a Unified Embedding for Visual Search at Pinterest. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (Anchorage, AK, USA) (KDD '19). Association for Computing Machinery, New York, NY, USA, 2412--2420. https://doi.org/10.1145/3292500. 3330739Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403383,Explainable Classification of Brain Networks via Contrast Subgraphs,"Mining human-brain networks to discover patterns that can be used to discriminate between healthy individuals and patients affected by some neurological disorder, is a fundamental task in neuro-science. Learning simple and interpretable models is as important as mere classification accuracy. In this paper we introduce a novel approach for classifying brain networks based on extracting contrast subgraphs, i.e., a set of vertices whose induced subgraphs are dense in one class of graphs and sparse in the other. We formally define the problem and present an algorithmic solution for extracting contrast subgraphs. We then apply our method to a brain-network dataset consisting of children affected by Autism Spectrum Disorder and children Typically Developed. Our analysis confirms the interestingness of the discovered patterns, which match background knowledge in the neuro-science literature. Further analysis on other classification tasks confirm the simplicity, soundness, and high explainability of our proposal, which also exhibits superior classification accuracy, to more complex state-of-the-art methods.","[{""name"":""Tommaso Lanciano"",""id"":""/profile/99659501631""},{""name"":""Francesco Bonchi"",""id"":""/profile/81100305585""},{""name"":""Aristides Gionis"",""id"":""/profile/81100631289""},{""name"":""Tommaso Lanciano"",""id"":""/profile/99659501631""},{""name"":""Francesco Bonchi"",""id"":""/profile/81100305585""},{""name"":""Aristides Gionis"",""id"":""/profile/81100631289""}]","[""B. Adhikari, Y. Zhang, N. Ramakrishnan, and B. A. Prakash. Sub2vec: Feature learning for subgraphs. In PAKDD 2018.Google ScholarCross Ref"",""Y. Asahiro, K. Iwama, H. Tamaki, and T. Tokuyama. Greedily finding a dense subgraph. Journal of Algorithms, 34(2):203--221, 2000.Google ScholarDigital Library"",""O. D. Balalau, F. Bonchi, T. H. Chan, F. Gullo, and M. Sozio. Finding subgraphs with maximum total density and limited overlap. In WSDM 2015.Google ScholarDigital Library"",""B. Biswal, F. Z. Yetkin, V. M. Haughton, and J. S. Hyde. Functional connectivity in the motor cortex of resting human brain using echo-planar mri. Magnetic Resonance in Medicine, 34(4):537--541, oct 1995.Google ScholarCross Ref"",""B. Boden, S. Günnemann, H. Hoffmann, and T. Seidl. Mining coherent subgraphs in multi-layer graphs with edge labels. In KDD 2012.Google ScholarDigital Library"",""E. Bullmore and O. Sporns. Complex brain networks: graph theoretical analysis of structural and functional systems. Nature reviews neuroscience, 10(3):186--198, 2009.Google Scholar"",""J. Cadena, A. K. Vullikanti, and C. C. Aggarwal. On dense subgraphs in signed network streams. In ICDM 2016.Google ScholarCross Ref"",""L. Chu, S. Wang, S. Liu, Q. Huang, and J. Pei. ALID: scalable dominant cluster detection. PVLDB, 8(8):826--837, 2015.Google ScholarDigital Library"",""C. Craddock, Y. Benhajali, C. Chu, F. Chouinard, A. Evans, A. Jakab, B. S. Khundrakpam, J. D. Lewis, Q. Li, M. Milham, C. Yan, and P. Bellec. The neuro bureau preprocessing initiative: open sharing of preprocessed neuroimaging data and derivatives. Frontiers in Neuroinformatics, (41), 2013.Google Scholar"",""Y. Du, Z. Fu, and V. D. Calhoun. Classification and prediction of brain disorders using functional connectivity: Promising but challenging. Frontiers in Neuroscience, 12:525, 2018.Google ScholarCross Ref"",""L. T. Eyler, K. Pierce, and E. Courchesne. A failure of left temporal cortex to specialize for language is an early emerging and fundamental property of autism. Brain, 135(3):949--960, Feb. 2012.Google ScholarCross Ref"",""E. Galimberti, F. Bonchi, and F. Gullo. Core decomposition and densest subgraph in multilayer networks. In CIKM 2017.Google ScholarDigital Library"",""S. J. Gilbert, G. Bird, R. Brindley, C. D. Frith, and P. W. Burgess. Atypical recruitment of medial prefrontal cortex in autism spectrum disorders: An fMRI study of two executive function tasks. Neuropsychologia, 46(9):2281--2291, July 2008.Google ScholarCross Ref"",""A. Gionis and C. E. Tsourakakis. Dense subgraph discovery: Kdd 2015 tutorial. In KDD 2015.Google ScholarDigital Library"",""A. V. Goldberg. Finding a maximum density subgraph. Technical report, University of California at Berkeley, 1984.Google Scholar"",""L. Gutié rrez-Gó mez and J.-C. Delvenne. Unsupervised network embeddings with node identity awareness. Applied Network Science, 4(1), oct 2019.Google Scholar"",""D. Jiang and J. Pei. Mining frequent cross-graph quasi-cliques. TKDD, 2(4):16, 2009.Google ScholarDigital Library"",""N. Jin and W. Wang. Lts: Discriminative subgraph mining by learning from search history. In ICDE 2011.Google ScholarDigital Library"",""A. J. Khan, A. Nair, C. L. Keown, M. C. Datko, A. J. Lincoln, and R.-A. Müller. Cerebro-cerebellar resting-state functional connectivity in children and adolescents with autism spectrum disorder. Biological Psychiatry, 78(9):625--634, 2015. Adolescence, Cortical Functional Connectivity, and Psychopathology.Google ScholarCross Ref"",""N. M. Kleinhans, R.-A. Müller, D. N. Cohen, and E. Courchesne. Atypical functional lateralization of language in autism spectrum disorders. Brain Research, 1221:115--125, 2008.Google ScholarCross Ref"",""E. W. Lang, A. M. Tomé, I. R. Keck, J. M. Gó rriz-Sá ez, and C. G. Puntonet. Brain connectivity analysis: A short survey. Computational Intelligence and Neuroscience, 2012:1--21, 2012.Google ScholarDigital Library"",""J. B. Lee, R. Rossi, and X. Kong. Graph classification using structural attention. In KDD 2018.Google ScholarDigital Library"",""A. Lord, D. Horn, M. Breakspear, and M. Walter. Changes in community structure of resting state functional connectivity in unipolar depression. PLOS ONE, 7(8):1--15, 08 2012.Google ScholarCross Ref"",""A. D. Martino, C. Kelly, R. Grzadzinski, X.-N. Zuo, M. Mennes, M. A. Mairena, C. Lord, F. X. Castellanos, and M. P. Milham. Aberrant striatal functional connectivity in children with autism. Biological Psychiatry, 69(9):847--856, 2011. Genes, Autism, and Associated Phenotypes.Google ScholarCross Ref"",""L. Meng and J. Xiang. Brain network analysis and classification based on convolutional neural network. Frontiers in Computational Neuroscience, 12, dec 2018.Google Scholar"",""M. F. Misman, A. A. Samah, F. A. Ezudin, H. A. Majid, Z. A. Shah, H. Hashim, and M. F. Harun. Classification of adults with autism spectrum disorder using deep neural network. In 2019 1st International Conference on Artificial Intelligence and Data Sciences (AiDAS), pages 29--34, Sep. 2019.Google ScholarCross Ref"",""A. Narayanan, M. Chandramohan, R. Venkatesan, L. Chen, Y. Liu, and S. Jaiswal. graph2vec: Learning distributed representations of graphs, 2017.Google Scholar"",""J. A. Nielsen, B. A. Zielinski, P. Fletcher, A. L. Alexander, N. Lange, E. D. Bigler, J. E. Lainhart, and J. S. Anderson. Abnormal lateralization of functional connectivity between language and default mode regions in autism. Molecular Autism, 5(1):8, 2014.Google ScholarCross Ref"",""J. Pei, D. Jiang, and A. Zhang. On mining cross-graph quasi-cliques. In KDD 2005.Google ScholarDigital Library"",""M. Rubinov, S. A. Knock, C. J. Stam, S. Micheloyannis, A. W. Harris, L. M. Williams, and M. Breakspear. Small-world properties of nonlinear brain activity in schizophrenia. Human Brain Mapping, 30(2):403--416, 2009.Google ScholarCross Ref"",""N. Shervashidze, P. Schweitzer, E. J. v. Leeuwen, K. Mehlhorn, and K. M. Borgwardt. Weisfeiler-lehman graph kernels. Journal of Machine Learning Research, 12(Sep):2539--2561, 2011.Google Scholar"",""O. Sporns, G. Tononi, and R. Kötter. The human connectome: a structural description of the human brain. PLoS Comput Biol, 1(4), 2005.Google Scholar"",""M. Thoma, H. Cheng, A. Gretton, J. Han, H.-P. Kriegel, A. Smola, L. Song, P. S. Yu, X. Yan, and K. M. Borgwardt. Discriminative frequent subgraph mining with optimality guarantees. Statistical Analysis and Data Mining: The ASA Data Science Journal, 3(5):302--318, 2010.Google ScholarDigital Library"",""R. M. H. Ting and J. Bailey. Mining minimal contrast subgraph patterns. In Proceedings of the 2006 SIAM International Conference on Data Mining, pages 639--643, 2006.Google ScholarCross Ref"",""C. Tsourakakis. Streaming Graph Partitioning in the Planted Partition Model. In COSN 2015.Google Scholar"",""C. Tsourakakis, F. Bonchi, A. Gionis, F. Gullo, and M. Tsiarli. Denser than the densest subgraph: extracting optimal quasi-cliques with quality guarantees. In KDD 2013.Google ScholarDigital Library"",""N. Tzourio-Mazoyer, B. Landeau, D. Papathanassiou, F. Crivello, O. Etard, N. Delcroix, B. Mazoyer, and M. Joliot. Automated anatomical labeling of activations in spm using a macroscopic anatomical parcellation of the mni mri single-subject brain. NeuroImage, 15(1):273--289, 2002.Google ScholarCross Ref"",""S. Wang, L. He, B. Cao, C.-T. Lu, P. S. Yu, and A. B. Ragin. Structural deep brain network mining. In KDD 2017.Google ScholarDigital Library"",""J. Wu, J. He, and J. Xu. Demo-net: Degree-specific graph neural networks for node and graph classification. In KDD 2019.Google ScholarDigital Library"",""Y. Wu, X. Zhu, L. Li, W. Fan, R. Jin, and X. Zhang. Mining dual networks: Models, algorithms, and applications. TKDD, 10(4):40:1--40:37, 2016.Google ScholarDigital Library"",""X. Yan, H. Cheng, J. Han, and P. S. Yu. Mining significant graph patterns by leap search. In SIGMOD 2008.Google ScholarDigital Library"",""Y. Yan, J. Zhu, M. Duda, E. Solarz, C. Sripada, and D. Koutra. Groupinn: Grouping-based interpretable neural network for classification of limited, noisy brain data. In KDD 2019.Google ScholarDigital Library"",""P. Yanardag and S. Vishwanathan. Deep graph kernels. In KDD 2015.Google ScholarDigital Library"",""Y. Yang, L. Chu, Y. Zhang, Z. Wang, J. Pei, and E. Chen. Mining density contrast subgraphs. In ICDE 2018.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403384,Jointly Learning to Recommend and Advertise,"Online recommendation and advertising are two major income channels for online recommendation platforms (e.g. e-commerce and news feed site). However, most platforms optimize recommending and advertising strategies by different teams separately via different techniques, which may lead to suboptimal overall performances. To this end, in this paper, we propose a novel two-level reinforcement learning framework to jointly optimize the recommending and advertising strategies, where the first level generates a list of recommendations to optimize user experience in the long run; then the second level inserts ads into the recommendation list that can balance the immediate advertising revenue from advertisers and the negative influence of ads on long-term user experience. To be specific, the first level tackles high combinatorial action space problem that selects a subset items from the large item space; while the second level determines three internally related tasks, i.e., (i) whether to insert an ad, and if yes, (ii) the optimal ad and (iii) the optimal location to insert. The experimental results based on real-world data demonstrate the effectiveness of the proposed framework. We have released the implementation code to ease reproductivity.","[{""name"":""Xiangyu Zhao"",""id"":""/profile/99659217646""},{""name"":""Xudong Zheng"",""id"":""/profile/99659573541""},{""name"":""Xiwang Yang"",""id"":""/profile/99659530165""},{""name"":""Xiaobing Liu"",""id"":""/profile/99659567274""},{""name"":""Jiliang Tang"",""id"":""/profile/81496640622""},{""name"":""Xiangyu Zhao"",""id"":""/profile/99659217646""},{""name"":""Xudong Zheng"",""id"":""/profile/99659573541""},{""name"":""Xiwang Yang"",""id"":""/profile/99659530165""},{""name"":""Xiaobing Liu"",""id"":""/profile/99659567274""},{""name"":""Jiliang Tang"",""id"":""/profile/81496640622""}]","[""Richard Bellman. 2013. Dynamic programming. Courier Corporation.Google Scholar"",""Han Cai, Kan Ren, Weinan Zhang, Kleanthis Malialis, Jun Wang, Yong Yu, and Defeng Guo. 2017. Real-time bidding by reinforcement learning in display advertising. In Proceedings of the Tenth ACM International Conference on Web Search and Data Mining. ACM, 661--670.Google ScholarDigital Library"",""Haokun Chen, Xinyi Dai, Han Cai, Weinan Zhang, Xuejian Wang, Ruiming Tang, Yuzhou Zhang, and Yong Yu. 2018b. Large-scale Interactive Recommendation with Tree-structured Policy Gradient. arXiv preprint arXiv:1811.05869 (2018).Google Scholar"",""Minmin Chen, Alex Beutel, Paul Covington, Sagar Jain, Francois Belletti, and Ed Chi. 2018a. Top-K Off-Policy Correction for a REINFORCE Recommender System. arXiv preprint arXiv:1812.02353 (2018).Google Scholar"",""Shi-Yong Chen, Yang Yu, Qing Da, Jun Tan, Hai-Kuan Huang, and Hai-Hong Tang. 2018c. Stabilizing reinforcement learning in dynamic environment with application to online recommendation. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 1187--1196.Google ScholarDigital Library"",""Xinshi Chen, Shuang Li, Hui Li, Shaohua Jiang, Yuan Qi, and Le Song. 2019. Generative Adversarial User Model for Reinforcement Learning Based Recommendation System. In International Conference on Machine Learning. 1052--1061.Google Scholar"",""Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et almbox. 2016. Wide \u0026 deep learning for recommender systems. In Proceedings of the 1st workshop on deep learning for recommender systems. ACM, 7--10.Google ScholarDigital Library"",""Sungwoon Choi, Heonseok Ha, Uiwon Hwang, Chanju Kim, Jung-Woo Ha, and Sungroh Yoon. 2018. Reinforcement Learning based Recommender System using Biclustering Technique. arXiv preprint arXiv:1801.05532 (2018).Google Scholar"",""Thomas Degris, Martha White, and Richard S Sutton. 2012. Off-policy actor-critic. arXiv preprint arXiv:1205.4839 (2012).Google Scholar"",""Wenkui Ding, Tao Qin, Xu-Dong Zhang, and Tie-Yan Liu. 2013. Multi-armed bandit with budget constraint and variable costs. In Twenty-Seventh AAAI Conference on Artificial Intelligence.Google ScholarDigital Library"",""Gabriel Dulac-Arnold, Richard Evans, Hado van Hasselt, Peter Sunehag, Timothy Lillicrap, Jonathan Hunt, Timothy Mann, Theophane Weber, Thomas Degris, and Ben Coppin. 2015. Deep reinforcement learning in large discrete action spaces. arXiv preprint arXiv:1512.07679 (2015).Google Scholar"",""Jun Feng, Heng Li, Minlie Huang, Shichen Liu, Wenwu Ou, Zhirong Wang, and Xiaoyan Zhu. 2018. Learning to collaborate: Multi-scenario ranking via multi-agent reinforcement learning. In Proceedings of the 2018 World Wide Web Conference. International World Wide Web Conferences Steering Committee, 1939--1948.Google ScholarDigital Library"",""Margherita Gasparini, Alessandro Nuara, Francesco Trovò, Nicola Gatti, and Marcello Restelli. 2018. Targeting Optimization for Internet Advertising by Learning from Logged Bandit Feedback. In 2018 International Joint Conference on Neural Networks (IJCNN). IEEE, 1--8.Google ScholarCross Ref"",""Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: a factorization-machine based neural network for CTR prediction. arXiv preprint arXiv:1703.04247 (2017).Google Scholar"",""Matthew Hausknecht and Peter Stone. 2015. Deep recurrent q-learning for partially observable mdps. In 2015 AAAI Fall Symposium Series.Google Scholar"",""Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2015. Session-based recommendations with recurrent neural networks. arXiv preprint arXiv:1511.06939 (2015).Google Scholar"",""Junqi Jin, Chengru Song, Han Li, Kun Gai, Jun Wang, and Weinan Zhang. 2018. Real-time bidding with multi-agent reinforcement learning in display advertising. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management. ACM, 2193--2201.Google ScholarDigital Library"",""Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin Riedmiller. 2013. Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602 (2013).Google Scholar"",""Alessandro Nuara, Francesco Trovo, Nicola Gatti, and Marcello Restelli. 2018. A Combinatorial-Bandit Algorithm for the Online Joint Bid/Budget Optimization of Pay-per-Click Advertising Campaigns. In Thirty-Second AAAI Conference on Artificial Intelligence.Google Scholar"",""David Rohde, Stephen Bonner, Travis Dunlop, Flavian Vasile, and Alexandros Karatzoglou. 2018. RecoGym: A Reinforcement Learning Environment for the problem of Product Recommendation in Online Advertising. arXiv preprint arXiv:1808.00720 (2018).Google Scholar"",""Michael H Rothkopf. 2007. Thirteen reasons why the Vickrey-Clarke-Groves process is not practical. Operations Research, Vol. 55, 2 (2007), 191--197.Google ScholarDigital Library"",""Konstantin Salomatin, Tie-Yan Liu, and Yiming Yang. 2012. A unified optimization framework for auction and guaranteed delivery in online advertising. In Proceedings of the 21st ACM international conference on Information and knowledge management. ACM, 2005--2009.Google ScholarDigital Library"",""Eric M Schwartz, Eric T Bradlow, and Peter S Fader. 2017. Customer acquisition via display advertising using multi-armed bandit experiments. Marketing Science, Vol. 36, 4 (2017), 500--522.Google ScholarDigital Library"",""Hyungseok Song, Hyeryung Jang, Hai Tran Hong, Seeun Yun, Donggyu Yun, Hyoju Chung, and Yung Yi. 2019. Solving Continual Combinatorial Selection via Deep Reinforcement Learning. (2019).Google Scholar"",""Liang Tang, Romer Rosales, Ajit Singh, and Deepak Agarwal. 2013. Automatic ad format selection via contextual bandits. In Proceedings of the 22nd ACM international conference on Information \u0026 Knowledge Management. ACM, 1587--1594.Google ScholarDigital Library"",""Weixun Wang, Junqi Jin, Jianye Hao, Chunjie Chen, Chuan Yu, Weinan Zhang, Jun Wang, Yixi Wang, Han Li, Jian Xu, et almbox. 2018b. Learning to Advertise with Adaptive Exposure via Constrained Two-Level Reinforcement Learning. arXiv preprint arXiv:1809.03149 (2018).Google Scholar"",""Xiting Wang, Yiru Chen, Jie Yang, Le Wu, Zhengtao Wu, and Xing Xie. 2018a. A Reinforcement Learning Framework for Explainable Recommendation. In 2018 IEEE International Conference on Data Mining (ICDM). IEEE, 587--596.Google ScholarCross Ref"",""Ziyu Wang, Nando De Freitas, and Marc Lanctot. 2015. Dueling Network Architectures for Deep Reinforcement Learning. (2015).Google Scholar"",""Di Wu, Cheng Chen, Xun Yang, Xiujun Chen, Qing Tan, Jian Xu, and Kun Gai. 2018a. A Multi-Agent Reinforcement Learning Method for Impression Allocation in Online Display Advertising. arXiv preprint arXiv:1809.03152 (2018).Google Scholar"",""Di Wu, Xiujun Chen, Xun Yang, Hao Wang, Qing Tan, Xiaoxun Zhang, Jian Xu, and Kun Gai. 2018b. Budget constrained bidding by model-free reinforcement learning in display advertising. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management. ACM, 1443--1451.Google ScholarDigital Library"",""Min Xu, Tao Qin, and Tie-Yan Liu. 2013. Estimation bias in multi-armed bandit algorithms for search advertising. In Advances in Neural Information Processing Systems. 2400--2408.Google Scholar"",""Shuai Yuan, Jun Wang, and Maurice van der Meer. 2013. Adaptive keywords extraction with contextual bandits for advertising on parked domains. arXiv preprint arXiv:1307.3573 (2013).Google Scholar"",""Weinan Zhang, Xiangyu Zhao, Li Zhao, Dawei Yin, Grace Hui Yang, and Alex Beutel. 2020. Deep Reinforcement Learning for Information Retrieval: Fundamentals and Advances. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM.Google ScholarDigital Library"",""Xiangyu Zhao, Changsheng Gu, Haoshenglun Zhang, Xiaobing Liu, Xiwang Yang, and Jiliang Tang. 2019 a. Deep Reinforcement Learning for Online Advertising in Recommender Systems. arXiv preprint arXiv:1909.03602 (2019).Google Scholar"",""Xiangyu Zhao, Long Xia, Zhuoye Ding, Dawei Yin, and Jiliang Tang. 2019 b. Toward Simulating Environments in Reinforcement Learning Based Recommendations. arXiv preprint arXiv:1906.11462 (2019).Google Scholar"",""Xiangyu Zhao, Long Xia, Jiliang Tang, and Dawei Yin. 2019 c. Deep reinforcement learning for search, recommendation, and online advertising: a survey by Xiangyu Zhao, Long Xia, Jiliang Tang, and Dawei Yin with Martin Vesely as coordinator. ACM SIGWEB Newsletter Spring (2019), 4.Google Scholar"",""Xiangyu Zhao, Long Xia, Liang Zhang, Zhuoye Ding, Dawei Yin, and Jiliang Tang. 2018a. Deep Reinforcement Learning for Page-wise Recommendations. In Proceedings of the 12th ACM Recommender Systems Conference. ACM, 95--103.Google ScholarDigital Library"",""Xiangyu Zhao, Long Xia, Yihong Zhao, Dawei Yin, and Jiliang Tang. 2019 d. Model-Based Reinforcement Learning for Whole-Chain Recommendations. arXiv preprint arXiv:1902.03987 (2019).Google Scholar"",""Xiangyu Zhao, Liang Zhang, Zhuoye Ding, Long Xia, Jiliang Tang, and Dawei Yin. 2018b. Recommendations with Negative Feedback via Pairwise Deep Reinforcement Learning. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 1040--1048.Google ScholarDigital Library"",""Xiangyu Zhao, Liang Zhang, Zhuoye Ding, Dawei Yin, Yihong Zhao, and Jiliang Tang. 2017. Deep Reinforcement Learning for List-wise Recommendations. arXiv preprint arXiv:1801.00209 (2017).Google Scholar"",""Guanjie Zheng, Fuzheng Zhang, Zihan Zheng, Yang Xiang, Nicholas Jing Yuan, Xing Xie, and Zhenhui Li. 2018. DRN: A Deep Reinforcement Learning Framework for News Recommendation. In Proceedings of the 2018 World Wide Web Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 167--176.Google ScholarDigital Library"",""Lixin Zou, Long Xia, Yulong Gu, Xiangyu Zhao, Weidong Liu, Jimmy Xiangji Huang, and Dawei Yin. 2020. Neural Interactive Collaborative Filtering. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403385,Fitbit for Chickens?: Time Series Data Mining Can Increase the Productivity of Poultry Farms,"Chickens are the most important poultry species in the world. Globally, industrial-scale production systems account for most of the poultry meat and eggs produced. The welfare of these birds matters for both ethical and economic reasons. From an ethical perspective, poultry have a sufficient degree of awareness to suffer pain if their health is poor, or deprivation if poorly housed. From an economic viewpoint, consumers increasingly value poultry welfare, so better market access can be obtained by producers who demonstrate concern for their flocks. Recent advances in sensor technology has allowed the opportunity to record behavioral patterns in chickens, and several research groups have shown that such data can be exploited to enhance chicken welfare. However, classifying chicken behaviors poses several unique challenges which are not observed in the UCR archive or other classic benchmark collections. In particular, some behaviors are manifested in the shape of the subsequences, whereas others only in more abstract features. Most algorithms only work well for one such modality. In addition, our data of interest has classes that greatly differ in duration, and are only weakly labeled, again defying the assumptions of the classic benchmark datasets. In this work, we propose a general-purpose framework to robustly learn and classify from datasets exhibiting these issues. While our experience is with fowl, the lessons we have learned may be more generally applicable to real-world datasets in other domains including manufacturing and human health.","[{""name"":""Alireza Abdoli"",""id"":""/profile/99659574350""},{""name"":""Sara Alaee"",""id"":""/profile/99659369233""},{""name"":""Shima Imani"",""id"":""/profile/99659370773""},{""name"":""Amy Murillo"",""id"":""/profile/99659573841""},{""name"":""Alec Gerry"",""id"":""/profile/99659573538""},{""name"":""Leslie Hickle"",""id"":""/profile/99659573389""},{""name"":""Eamonn Keogh"",""id"":""/profile/81100209161""},{""name"":""Alireza Abdoli"",""id"":""/profile/99659574350""},{""name"":""Sara Alaee"",""id"":""/profile/99659369233""},{""name"":""Shima Imani"",""id"":""/profile/99659370773""},{""name"":""Amy Murillo"",""id"":""/profile/99659573841""},{""name"":""Alec Gerry"",""id"":""/profile/99659573538""},{""name"":""Leslie Hickle"",""id"":""/profile/99659573389""},{""name"":""Eamonn Keogh"",""id"":""/profile/81100209161""}]","[""A. Abdoli et al. \""Time series classification to improve poultry welfare.\"" 2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA). IEEE, 2018.Google Scholar"",""A. Abdoli, et al. \""Time Series Classification: Lessons Learned in the (Literal) Field while Studying Chicken Behavior.\"" 2019 IEEE International Conference on Big Data (Big Data). IEEE, 2019.Google Scholar"",""A. Mueen et al., \""The fastest similarity search algorithm for time series subsequences under euclidean distance\"", 2015.Google Scholar"",""A. C. Murillo, A. Abdoli, R. A. Blatchford, E. J. Keogh, and A. C. Gerry. \""parasitic mites alter chicken behaviour and negatively impact animal welfare.\"" Scientific Reports 10, no. 1 (2020): 1--12.Google Scholar"",""A. Reiss et al. \""Exploring and extending the boundaries of physical activity recognition.\"" 2011 IEEE International Conference on Systems, Man, and Cybernetics. IEEE, 2011.Google Scholar"",""B. Chiu, E. Keogh and S. Lonardi. \""Probabilistic discovery of time series motifs\"". In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining (pp. 493--498), 2003, ACM.Google ScholarDigital Library"",""B. D. Fulcher et al. \""Highly comparative time-series analysis: The empirical structure of time series and their methods.\"" Journal of the Royal Society Interface 10.83 (2013): 20130048.Google ScholarCross Ref"",""B. G. Smythe et al., \""Behavioral responses of cattle to naturally occurring seasonal populations of horn flies (Diptera: Muscidae) under rangel and conditions,\"" Journal of Economic Entomology, vol. 108, no. 6, pp. 2831--2836, 2015.Google ScholarCross Ref"",""C. Lubba et al., \""catch22: CAnonical Time-series Characteristics,\"" Data Mining and Knowledge Discovery, 33(6), 1821--1852, 2019.Google Scholar"",""D. Banerjee et al., \""Remote activity classification of hens using wireless body mounted sensors,\"" in Wearable and Implantable Body Sensor Networks (BSN), 2012 Ninth International Conference on, pp. 107--112, 2012, IEEE.Google Scholar"",""E. Walton et al., \""Evaluation of sampling frequency, window size and sensor position for classification of sheep behaviour,\"" Royal Society Open Science, vol. 5, no. 2, p. 171442, 2018.Google ScholarCross Ref"",""ELAN [Computer software]. Nijmegen: Max Planck Institute for Psycholinguistics. Retrieved from https://tla.mpi.nl/tools/tla-tools/elan/Google Scholar"",""F. Palumbo, C. Gallicchio, R. Pucci, and A. Micheli, \""Human activity recognition using multisensor data fusion based on reservoir computing,\"" Journal of Ambient Intelligence and Smart Environments, 8(2), 87--107, 2016.Google ScholarCross Ref"",""G. Batista, E. Keogh, O. Tataw, V. de Souza. \""CID: an efficient complexity-invariant distance for time series\"". Data Min. Knowl. Discov. 28(3): 634--669, 2014.Google ScholarDigital Library"",""G. E. Batista et al., \""SIGKDD demo: sensors and software to allow computational entomology, an emerging application of data mining,\"" in Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 761--764, 2011, ACM.Google Scholar"",""H. A. Dau and E. Keogh, \""Matrix Profile V: A Generic Technique to Incorporate Domain Knowledge into Motif Discovery\"", In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '17), pp.125--134, 2017, ACM.Google ScholarDigital Library"",""H. A. Dau, A. Bagnall, K. Kamgar, C. M. Yeh, Y. Zhu, S. Gharghabi, C. A. Ratanamahatana, and E. Keogh. \""The UCR time series archive.\"" IEEE/CAA Journal of Automatica Sinica 6, no. 6 (2019): 1293--1305.Google ScholarCross Ref"",""H. Ding et al., \""Querying and mining of time series data: experimental comparison of representations and distance measures,\"" Proceedings of the VLDB Endowment, vol. 1, no. 2, pp. 1542--1552, 2008.Google ScholarDigital Library"",""http://www.fao.org/poultry-production-products/production/management-and-housing/ [Last visited: February 2020]Google Scholar"",""http://www.fao.org/poultry-production-products/products-processing/en/ [Last visited: February 2020].Google Scholar"",""https://www.ciwf.com/farmed-animals/chickens/ [Last visited: 31 January 2020].Google Scholar"",""J. Amores. \""Multiple instance classification: Review, taxonomy and comparative study.\"" Artificial intelligence 201 (2013): 81--105.Google ScholarDigital Library"",""J. Barwick et al., \""Categorising sheep activity using a tri-axial accelerometer,\"" Computers and Electronics in Agriculture, vol. 145, pp. 289--297, 2018.Google ScholarCross Ref"",""J. Doppler et al., \""Variability in foot-worn sensor placement for activity recognition,\"" in Wearable Computers, 2009. ISWC'09. International Symposium on, pp. 143--144, 2009.Google Scholar"",""M. Kreil, B. Sick, and P. Lukowicz. \""Coping with variability in motion based activity recognition.\"" Proceedings of the 3rd International Workshop on Sensor-based Activity Recognition and Interaction. 2016.Google Scholar"",""M. Moreau et al., \""Use of a tri-axial accelerometer for automated recording and classification of goats' grazing behaviour,\"" Applied Animal Behaviour Science, vol. 119, no. 3-4, pp. 158--170, 2009.Google ScholarCross Ref"",""M. S. Dawkins, S. Donelly and T. A. Jones, \""Chicken welfare is influenced more by housing conditions than by stocking density,\"" Nature 427: 342--344, 2004.Google ScholarCross Ref"",""N. Li et al. \""Automated techniques for monitoring the behaviour and welfare of broilers and laying hens: towards the goal of precision livestock farming.\"" Animal, 1--9, 2019.Google Scholar"",""N. S. Brown, \""The effect of louse infestation, wet feathers, and relative humidity on the grooming behavior of the domestic chicken,\"" Poultry Science, vol. 53, no. 5, pp. 1717--1719, 1974.Google ScholarCross Ref"",""O. D. Lara, and M. A. Labrador. \""A survey on human activity recognition using wearable sensors.\"" IEEE communications surveys \u0026 tutorials 15.3 (2012): 1192--1209.Google Scholar"",""S. Alaee et al., \""Features or Shape\"" Tackling the False Dichotomy of Time Series Classification,\"" In Proceedings of the 2020 SIAM International Conference on Data Mining. Society for Industrial and Applied Mathematics, 2020.Google Scholar"",""S. Gharghabi et al., \""Matrix profile XII: MPdist: a novel time series distance measure to allow data mining in more challenging scenarios\"". In 2018 IEEE International Conference on Data Mining (ICDM), pp. 965--970. IEEE, 2018.Google ScholarCross Ref"",""S. Imani and E. Keogh. \""Matrix Profile XIX: Time Series Semantic Motifs: A New Primitive for Finding Higher-Level Structure in Time Series.\"" 2019 IEEE International Conference on Data Mining (ICDM). IEEE, 2019.Google Scholar"",""S. Imani et al., Matrix Profile XIII: Time Series Snippets: A New Primitive for Time Series Data Mining. In 2018 IEEE International Conference on Big Knowledge (ICBK) (pp. 382--389). IEEE, 2018.Google Scholar"",""Website: https://sites.google.com/site/chickenkdd/Google Scholar""]"
https://doi.org/10.1145/3394486.3403386,CompactETA: A Fast Inference System for Travel Time Prediction,"Computing estimated time of arrival (ETA) is one of the most important services for online ride-hailing platforms like DiDi and Uber. With billions of service queries per day on such platforms, a fast inference ETA module ensures the efficiency of the overall decision system to guarantee satisfied user experience, as well as saving significant operating cost. In this paper, we develop a novel ETA learning system named as CompactETA, which provides an accurate online travel time inference within 100 microseconds. In the proposed method, we encode high order spatial and temporal dependency into sophisticated representations by applying graph attention network on a spatiotemporal weighted road network graph. We further encode the sequential information of the travel route by positional encoding to avoid the recurrent network structure. The properly learnt representations enable us to apply a very simple multi-layer perceptron model for online real-time inference. Evaluation of both offline experiments and online A/B testing verifies that CompactETA reduces the inference latency by more than 100 times compared to a state-of-the-art system, while maintains competing prediction accuracy.","[{""name"":""Kun Fu"",""id"":""/profile/99659287466""},{""name"":""Fanlin Meng"",""id"":""/profile/99659575012""},{""name"":""Jieping Ye"",""id"":""/profile/99659193247""},{""name"":""Zheng Wang"",""id"":""/profile/99659573267""},{""name"":""Kun Fu"",""id"":""/profile/99659287466""},{""name"":""Fanlin Meng"",""id"":""/profile/99659575012""},{""name"":""Jieping Ye"",""id"":""/profile/99659193247""},{""name"":""Zheng Wang"",""id"":""/profile/99659573267""}]","[""Mohammad Asghari, Tobias Emrich, Ugur Demiryurek, and Cyrus Shahabi. 2015. Probabilistic Estimation of Link Travel Times in Dynamic Road Networks. In Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems.Google ScholarDigital Library"",""Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. 2014. Spectral networks and locally connected networks on graphs. In ICLR.Google Scholar"",""Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolutional neural networks on graphs with fast localized spectral filtering. In Advances in neural information processing systems (NeurIPS). 3844--3852.Google Scholar"",""Yanjie Duan, Yisheng Lv, and Fei-Yue Wang. 2016. Travel time prediction with LSTM neural network. In IEEE 19th International Conference on Intelligent Transportation Systems (ITSC '16).Google ScholarCross Ref"",""C. de Fabritiis, R. Ragona, and G. Valenti. 2008. Traffic Estimation And Prediction Based On Real Time Floating Car Data. In 2008 11th International IEEE Conference on Intelligent Transportation Systems.Google Scholar"",""Tao-yang Fu and Wang-Chien Lee. 2019. DeepIST: Deep Image-based Spatio-Temporal Network for Travel Time Estimation. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management. 69--78.Google Scholar"",""Ruipeng Gao, Xiaoyu Guo, Fuyong Sun, Lin Dai, Jiayan Zhu, Chenxi Hu, and Haibo Li. 2019. Aggressive driving saves more time? multi-task learning for customized travel time estimation. In Proceedings of the 28th International Joint Conference on Artificial Intelligence (IJCAI'19). AAAI Press. 1689--1696.Google ScholarCross Ref"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In Advances in Neural Information Processing Systems.Google Scholar"",""Mikael Henaff, Joan Bruna, and Yann LeCun. 2015. Deep convolutional networks on graph-structured data. arXiv preprint arXiv:1506.05163 (2015).Google Scholar"",""Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural computation, Vol. 9, 8 (1997), 1735--1780.Google Scholar"",""Diederik Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Optimization. In ICLR.Google Scholar"",""Thomas N Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional networks. In ICLR.Google Scholar"",""M. Kormáksson, L. Barbosa, M. R. Vieira, and B. Zadrozny. 2014. Bus Travel Time Predictions Using Additive Models. In IEEE International Conference on Data Mining (ICDM '14).Google Scholar"",""Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. 1998. Gradient-based learning applied to document recognition. Proc. IEEE, Vol. 86, 11 (1998), 2278--2324.Google ScholarCross Ref"",""Wang-Chien Lee, Weiping Si, Ling-Jyh Chen, and Meng Chang Chen. 2012. HTTP: A New Framework for Bus Travel Time Prediction Based on Historical Trajectories. In Proceedings of the 20th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems.Google ScholarDigital Library"",""Xiucheng Li, Gao Cong, Aixin Sun, and Yun Cheng. 2019. Learning Travel Time Distributions with Deep Generative Model. In The World Wide Web Conference. ACM, 1017--1027.Google Scholar"",""Yaguang Li, Kun Fu, Zheng Wang, Cyrus Shahabi, Jieping Ye, and Yan Liu. 2018a. Multi-task representation learning for travel time estimation. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 1695--1704.Google ScholarDigital Library"",""Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. 2018b. Diffusion convolutional recurrent neural network: Data-driven traffic forecasting. In ICLR.Google Scholar"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems (NeurIPS). 3111--3119.Google Scholar"",""Federico Monti, Davide Boscaini, Jonathan Masci, Emanuele Rodola, Jan Svoboda, and Michael M Bronstein. 2017. Geometric deep learning on graphs and manifolds using mixture model cnns. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 5115--5124.Google ScholarCross Ref"",""Charul Paliwal and Pravesh Biyani. 2019. To each route its own ETA: A generative modeling framework for ETA prediction. In 2019 IEEE Intelligent Transportation Systems Conference (ITSC). IEEE, 3076--3081.Google ScholarDigital Library"",""JWC Van Lint. 2008. Online learning solutions for freeway travel time prediction. IEEE Transactions on Intelligent Transportation Systems, Vol. 9, 1 (2008), 38--47.Google ScholarDigital Library"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems (NeurIPS). 5998--6008.Google Scholar"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2018. Graph attention networks. In ICLR.Google Scholar"",""Dong Wang, Junbo Zhang, Wei Cao, Jian Li, and Yu Zheng. 2018b. When will you arrive? estimating travel time based on deep neural networks. In Thirty-Second AAAI Conference on Artificial Intelligence.Google Scholar"",""Hongjian Wang, Yu-Hsuan Kuo, Daniel Kifer, and Zhenhui Li. 2016. A simple baseline for travel time estimation using large-scale trip data. In Proceedings of the 24th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems.Google ScholarDigital Library"",""Yilun Wang, Yu Zheng, and Yexiang Xue. 2014. Travel Time Estimation of a Path Using Sparse Trajectories. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '14).Google ScholarDigital Library"",""Zheng Wang, Kun Fu, and Jieping Ye. 2018a. Learning to estimate the travel time. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 858--866.Google ScholarDigital Library"",""Jiancheng Weng, Chang Wang, Hainan Huang, Yueyue Wang, and Ledian Zhang. 2016. Real-time bus travel speed estimation model based on bus GPS data. Advances in Mechanical Engineering, Vol. 8, 11 (2016), 1687814016678162.Google ScholarCross Ref"",""Chun-Hsin Wu, Jan-Ming Ho, and D. T. Lee. 2004. Travel-time prediction with support vector regression. IEEE Transactions on Intelligent Transportation Systems, Vol. 5, 4 (Dec 2004), 276--281.Google ScholarDigital Library"",""Bing Yu, Haoteng Yin, and Zhanxing Zhu. 2018. Spatio-temporal graph convolutional networks: A deep learning framework for traffic forecasting. In International Joint Conference on Artificial Intelligence (IJCAI).Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403387,Intelligent Exploration for User Interface Modules of Mobile App with Collective Learning,"A mobile app interface usually consists of a set of user interface modules. How to properly design these user interface modules is vital to achieving user satisfaction for a mobile app. However, there are few methods to determine design variables for user interface modules except for relying on the judgment of designers. Usually, a laborious post-processing step is necessary to verify the key change of each design variable. Therefore, there is only a very limited amount of design solutions that can be tested. It is time-consuming and almost impossible to figure out the best design solutions as there are many modules. To this end, we introduce FEELER, a framework to fast and intelligently explore design solutions of user interface modules with a collective machine learning approach. FEELER can help designers quantitatively measure the preference score of different design solutions, aiming to facilitate the designers to conveniently and quickly adjust user interface module. We conducted extensive experimental evaluations on two real-life datasets to demonstrate its applicability in real-life cases of user interface module design in the Baidu App, which is one of the most popular mobile apps in China.","[{""name"":""Jingbo Zhou"",""id"":""/profile/99659520172""},{""name"":""Zhenwei Tang"",""id"":""/profile/99659574039""},{""name"":""Min Zhao"",""id"":""/profile/99659574668""},{""name"":""Xiang Ge"",""id"":""/profile/99659572908""},{""name"":""Fuzhen Zhuang"",""id"":""""},{""name"":""Meng Zhou"",""id"":""/profile/99659573518""},{""name"":""Liming Zou"",""id"":""/profile/99659573953""},{""name"":""Chenglei Yang"",""id"":""/profile/81100356283""},{""name"":""Hui Xiong"",""id"":""/profile/81451596433""},{""name"":""Jingbo Zhou"",""id"":""/profile/99659520172""},{""name"":""Zhenwei Tang"",""id"":""/profile/99659574039""},{""name"":""Min Zhao"",""id"":""/profile/99659574668""},{""name"":""Xiang Ge"",""id"":""/profile/99659572908""},{""name"":""Fuzhen Zhuang"",""id"":""""},{""name"":""Meng Zhou"",""id"":""/profile/99659573518""},{""name"":""Liming Zou"",""id"":""/profile/99659573953""},{""name"":""Chenglei Yang"",""id"":""/profile/81100356283""},{""name"":""Hui Xiong"",""id"":""/profile/81451596433""}]","[""David Barber. 2012. Bayesian reasoning and machine learning. Cambridge University Press.Google Scholar"",""Bradley P Carlin and Siddhartha Chib. 1995. Bayesian model choice via Markov chain Monte Carlo methods. Journal of the Royal Statistical Society: Series B (Methodological), Vol. 57, 3 (1995), 473--484.Google ScholarCross Ref"",""Tianqi Chen and Carlos Guestrin. 2016. Xgboost: A scalable tree boosting system. In KDD. 785--794.Google ScholarDigital Library"",""Siddhartha Chib and Ivan Jeliazkov. 2001. Marginal likelihood from the Metropolis--Hastings output. J. Amer. Statist. Assoc., Vol. 96, 453 (2001), 270--281.Google ScholarCross Ref"",""Wei Chu and Zoubin Ghahramani. 2005. Preference learning with Gaussian processes. In ICML. 137--144.Google Scholar"",""Harris Drucker, Christopher JC Burges, Linda Kaufman, Alex J Smola, and Vladimir Vapnik. 1997. Support vector regression machines. In NIPS. 155--161.Google Scholar"",""Peitong Duan, Casimir Wierzynski, and Lama Nachman. 2020. Optimizing User Interface Layouts via Gradient Descent. In CHI. 1--12.Google Scholar"",""Alan M Ferrenberg and Robert H Swendsen. 1989. Optimized monte carlo data analysis. Computers in Physics, Vol. 3, 5 (1989), 101--104.Google ScholarCross Ref"",""Anhong Guo, Junhan Kong, Michael Rivera, Frank F Xu, and Jeffrey P Bigham. 2019. StateLens: A Reverse Engineering Solution for Making Existing Dynamic Touchscreens Accessible. In UIST. 371--385.Google Scholar"",""Ralf Herbrich, Tom Minka, and Thore Graepel. 2007. TrueSkill?: a Bayesian skill rating system. In NIPS. 569--576.Google Scholar"",""Neil Houlsby, Ferenc Huszar, Zoubin Ghahramani, and Jose M Hernández-Lobato. 2012. Collaborative Gaussian processes for preference learning. In NIPS. 2096--2104.Google Scholar"",""Claire Kayacik, Sherol Chen, Signe Noerly, Jess Holbrook, Adam Roberts, and Douglas Eck. 2019. Identifying the intersections: User experience research scientist collaboration in a generative machine learning interface. In CHI. ACM, CS09.Google Scholar"",""Mohammad M Khajah, Brett D Roads, Robert V Lindsey, Yun-En Liu, and Michael C Mozer. 2016. Designing engaging games using Bayesian optimization. In CHI. 5571--5582.Google Scholar"",""Hang Li. 2011. A short introduction to learning to rank. IEICE TRANSACTIONS on Information and Systems, Vol. 94, 10 (2011), 1854--1862.Google ScholarCross Ref"",""Yang Li, Samy Bengio, and Gilles Bailly. 2018. Predicting human performance in vertical menu selection using deep learning. In CHI. 1--7.Google Scholar"",""J Derek Lomas, Jodi Forlizzi, Nikhil Poonwala, Nirmal Patel, Sharan Shodhan, Kishan Patel, Ken Koedinger, and Emma Brunskill. 2016. Interface design optimization as a multi-armed bandit problem. In CHI. 4142--4153.Google Scholar"",""David JC MacKay. 1996. Bayesian methods for backpropagation networks. In Models of neural networks III. Springer, 211--254.Google Scholar"",""Thomas Peter Minka. 2001. A family of algorithms for approximate Bayesian inference. Ph.D. Dissertation. Massachusetts Institute of Technology.Google Scholar"",""Jonas Mockus, Vytautas Tiesis, and Antanas Zilinskas. 1978. The application of Bayesian methods for seeking the extremum. Towards global optimization, Vol. 2, 117--129 (1978), 2.Google Scholar"",""Daniel Preoct iuc-Pietro and Trevor Cohn. 2013. A temporal model of text periodicities using Gaussian Processes. In EMNLP. 977--988.Google Scholar"",""Julie Anne Seguin, Alec Scharff, and Kyle Pedersen. 2019. Triptech: A Method for Evaluating Early Design Concepts. In CHI. ACM, CS24.Google Scholar"",""Jasper Snoek, Hugo Larochelle, and Ryan P Adams. 2012. Practical bayesian optimization of machine learning algorithms. In NIPS. 2951--2959.Google Scholar"",""Amanda Swearngin and Yang Li. 2019. Modeling Mobile Interface Tappability Using Crowdsourcing and Deep Learning. In CHI. ACM, 75.Google Scholar"",""Jialei Wang, Nathan Srebro, and James Evans. 2014. Active collaborative permutation learning. In KDD. 502--511.Google Scholar"",""Ruixuan Wang and Stephen James McKenna. 2010. Gaussian process learning from order relationships using expectation propagation. In ICPR. IEEE, 605--608.Google Scholar"",""Christopher KI Williams and Carl Edward Rasmussen. 2006. Gaussian processes for machine learning. Vol. 2. MIT press Cambridge, MA.Google Scholar"",""Jingbo Zhou and Anthony KH Tung. 2015. Smiler: A semi-lazy time series prediction system for sensors. In SIGMOD. 1871--1886.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403388,Gemini: A Novel and Universal Heterogeneous Graph Information Fusing Framework for Online Recommendations,"Recently, network embedding has been successfully used in recommendation systems. Researchers have made efforts to utilize additional auxiliary information (e.g., social relations of users) to improve performance. However, such auxiliary information lacks compatibility for all recommendation scenarios, thus it is difficult to apply in some industrial scenarios where generality is required. Moreover, the heterogeneous nature between users and items aggravates the difficulty in network information fusion. Many works tried to transform user-item heterogeneous network to two homogeneous graphs (i.e., user-user and item-item), and then fuse information separately. This may limit the representation power of learned embedding due to ignoring the adjacent relationship in the original graph. In addition, the sparsity of user-item interactions is an urgent problem need to be solved. To solve the above problems, we propose a universal and effective framework named Gemini, which only relies on the common interaction logs, avoiding the dependence on auxiliary information and ensuring a better generality. For the purpose of keeping original adjacent relationship, Gemini transforms the original user-item heterogeneous graph into two semi homogeneous graphs from the perspective of users and items respectively. The transformed graphs consist of two types of nodes: network nodes coming from homogeneous nodes and attribute nodes coming from heterogeneous node. Then, the node representation is learned in a homogeneous way, with considering edge embedding at the same time. Simultaneously, the interaction sparsity problem is solved to some extent as the transformed graphs contain the original second-order neighbors. For training efficiently, we also propose an iterative training algorithm to reduce computational complexity. Experimental results on the five datasets and online A/B tests in recommendations of DiDiChuXing show that Gemini outperforms state-of-the-art algorithms.","[{""name"":""Jixing Xu"",""id"":""/profile/99659451204""},{""name"":""Zhenlong Zhu"",""id"":""/profile/99659451176""},{""name"":""Jianxin Zhao"",""id"":""/profile/99659574365""},{""name"":""Xuanye Liu"",""id"":""/profile/99659574122""},{""name"":""Minghui Shan"",""id"":""/profile/99659450865""},{""name"":""Jiecheng Guo"",""id"":""/profile/99659573186""},{""name"":""Jixing Xu"",""id"":""/profile/99659451204""},{""name"":""Zhenlong Zhu"",""id"":""/profile/99659451176""},{""name"":""Jianxin Zhao"",""id"":""/profile/99659574365""},{""name"":""Xuanye Liu"",""id"":""/profile/99659574122""},{""name"":""Minghui Shan"",""id"":""/profile/99659450865""},{""name"":""Jiecheng Guo"",""id"":""/profile/99659573186""}]","[""Amr Ahmed, Nino Shervashidze, Shravan Narayanamurthy, Vanja Josifovski, and Alexander J. Smola. 2013. Distributed Large-scale Natural Graph Factorization. In Proceedings of the 22nd international conference on World Wide Web .Google Scholar"",""Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. [n.d.]. Spectral Networks and Locally Connected Networks on Graphs. ( [n.,d.]).Google Scholar"",""Shaosheng Cao, Lu Wei, and Qiongkai Xu. 2015. GraRep: Learning Graph Representations with Global Structural Information.Google Scholar"",""Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et almbox. 2016. Wide \u0026 deep learning for recommender systems. In Proceedings of the 1st workshop on deep learning for recommender systems. ACM, 7--10.Google ScholarDigital Library"",""Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep neural networks for youtube recommendations. In Proceedings of the 10th ACM conference on recommender systems. 191--198.Google ScholarDigital Library"",""Yuxiao Dong, Nitesh V. Chawla, and Ananthram Swami. 2017. metapath2vec: Scalable Representation Learning for Heterogeneous Networks. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining .Google ScholarDigital Library"",""Tao-yang Fu, Wang-Chien Lee, and Zhen Lei. 2017. Hin2vec: Explore meta-paths in heterogeneous information networks for representation learning. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management. 1797--1806.Google Scholar"",""Ming Gao, Leihui Chen, Xiangnan He, and Aoying Zhou. 2018. Bine: Bipartite network embedding. In The 41st International ACM SIGIR Conference on Research \u0026 Development in Information Retrieval . 715--724.Google ScholarDigital Library"",""Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative Adversarial Networks. Advances in Neural Information Processing Systems , Vol. 3 (2014), 2672--2680.Google ScholarDigital Library"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 855--864.Google ScholarDigital Library"",""Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: a factorization-machine based neural network for CTR prediction. arXiv preprint arXiv:1703.04247 (2017).Google Scholar"",""William L. Hamilton, Rex Ying, and Jure Leskovec. [n.d.]. Inductive Representation Learning on Large Graphs. ( [n.,d.]).Google Scholar"",""F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context .Google Scholar"",""Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero, and Larry Heck. 2013. Learning deep structured semantic models for web search using clickthrough data. In Proceedings of the 22nd ACM international conference on Information \u0026 Knowledge Management. 2333--2338.Google ScholarDigital Library"",""Zhipeng Huang and Nikos Mamoulis. 2017. Heterogeneous information network embedding for meta path based proximity. arXiv preprint arXiv:1701.05291 (2017).Google Scholar"",""Rana Hussein, Dingqi Yang, and Philippe Cudré-Mauroux. 2018. Are Meta-Paths Necessary? Revisiting Heterogeneous Graph Embeddings. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management . 437--446.Google Scholar"",""Thomas N. Kipf and Max Welling. [n.d.]. Semi-Supervised Classification with Graph Convolutional Networks. ( [n.,d.]).Google Scholar"",""Ao Li, Zhou Qin, Runshi Liu, Yiqun Yang, and Dong Li. 2019. Spam Review Detection with Graph Convolutional Networks. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management . 2703--2711.Google ScholarDigital Library"",""Yuqi Li, Weizheng Chen, and Hongfei Yan. 2017. Learning graph-based embedding for time-aware product recommendation. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management . 2163--2166.Google ScholarDigital Library"",""Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient Estimation of Word Representations in Vector Space. Computer Science (2013).Google Scholar"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining . ACM, 701--710.Google ScholarDigital Library"",""Chuan Shi, Binbin Hu, Wayne Xin Zhao, and S Yu Philip. 2018a. Heterogeneous information network embedding for recommendation. IEEE Transactions on Knowledge and Data Engineering , Vol. 31, 2 (2018), 357--370.Google ScholarDigital Library"",""Yu Shi, Qi Zhu, Fang Guo, Chao Zhang, and Jiawei Han. 2018b. Easing embedding learning by comprehensive transcription of heterogeneous information networks. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining . 2190--2199.Google ScholarDigital Library"",""Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. In Proceedings of the 24th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 1067--1077.Google ScholarDigital Library"",""Guillem Cucurull, Arantxa Casanova, Adriana Romero, and Yoshua Bengio. [n.d.]. Graph Attention Networks. ( [n.,d.]).Google Scholar"",""Daixin Wang, Cui Peng, and Wenwu Zhu. 2016. Structural Deep Network Embedding. In the 22nd ACM SIGKDD International Conference .Google Scholar"",""Hongwei Wang, Jia Wang, Jialin Wang, Miao Zhao, Weinan Zhang, Fuzheng Zhang, Xing Xie, and Minyi Guo. [n.d.] b. GraphGAN: Graph Representation Learning with Generative Adversarial Nets. ( [n.,d.]).Google Scholar"",""Jizhe Wang, Pipei Huang, Huan Zhao, Zhibo Zhang, Binqiang Zhao, and Dik Lun Lee. [n.d.] a. Billion-scale Commodity Embedding for E-commerce Recommendation in Alibaba. ( [n.,d.]).Google Scholar"",""Le Wu, Peijie Sun, Yanjie Fu, Richang Hong, Xiting Wang, and Meng Wang. 2019. A neural influence diffusion model for social recommendation. In Proceedings of the 42nd international ACM SIGIR conference on research and development in information retrieval. 235--244.Google ScholarDigital Library"",""Min Xie, Hongzhi Yin, Hao Wang, Fanjiang Xu, Weitong Chen, and Sen Wang. 2016. Learning graph-based poi embedding for location-based recommendation. In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management. 15--24.Google ScholarDigital Library"",""Seongjun Yun, Minbyul Jeong, Raehyun Kim, Jaewoo Kang, and Hyunwoo J. Kim. [n.d.]. Graph Transformer Networks. ( [n.,d.]).Google Scholar"",""Daokun Zhang, Yin Jie, Zhu Xingquan, and Zhang Chengqi. [n.d.]. Network Representation Learning: A Survey. IEEE Transactions on Big Data ( [n.,d.]), 1--1.Google Scholar"",""Ziwei Zhang, Peng Cui, Xiao Wang, Jian Pei, Xuanrong Yao, and Wenwu Zhu. 2018. Arbitrary-order proximity preserved network embedding. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 2778--2786.Google ScholarDigital Library"",""Jun Zhao, Zhou Zhou, Ziyu Guan, Wei Zhao, Wei Ning, Guang Qiu, and Xiaofei He. 2019. IntentGC: a Scalable Graph Convolution Framework Fusing Heterogeneous Information for Recommendation. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining . 2347--2357.Google ScholarDigital Library"",""Zhenlong Zhu, Ruixuan Li, Minghui Shan, Yuhua Li, Lu Gao, Fei Wang, Jixing Xu, and Xiwu Gu. 2019. TDP: Personalized Taxi Demand Prediction Based on Heterogeneous Graph Embedding. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval. 1177--1180.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403389,Hypergraph Convolutional Recurrent Neural Network,"In this study, we present a hypergraph convolutional recurrent neural network (HGC-RNN), which is a prediction model for structured time-series sensor network data. Representing sensor networks in a graph structure is useful for expressing structural relationships among sensors. Conventional graph structure, however, has a limitation on representing complex structure in real world application, such as shared connections among multiple nodes. We use a hypergraph, which is capable of modeling complicated structures, for structural representation. HGC-RNN performs a hypergraph convolution operation on the input data represented in the hypergraph to extract hidden representations of the input, while considering the structural dependency of the data. HGC-RNN employs a recurrent neural network structure to learn temporal dependency from the data sequence. We conduct experiments to forecast taxi demand in NYC, traffic flow in the overhead hoist transfer system, and gas pressure in a gas regulator. We compare the performance of our method with those of other existing methods, and the result shows that HGC-RNN has strengths over baseline models.","[{""name"":""Jaehyuk Yi"",""id"":""/profile/99659573400""},{""name"":""Jinkyoo Park"",""id"":""/profile/99659574185""},{""name"":""Jaehyuk Yi"",""id"":""/profile/99659573400""},{""name"":""Jinkyoo Park"",""id"":""/profile/99659574185""}]","[""Tianqi Chen and Carlos Guestrin. 2016. XGBoost: A Scalable Tree Boosting System. In KDD. ACM, 785--794.Google Scholar"",""Yifan Feng, Haoxuan You, Zizhao Zhang, Rongrong Ji, and Yue Gao. 2019. Hypergraph Neural Networks. In AAAI. AAAI Press, 3558--3565.Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable Feature Learning for Networks. In KDD. ACM, 855--864.Google Scholar"",""Daniel Hsu. 2017. Anomaly Detection on Graph Time Series. CoRR, Vol. abs/1708.02975 (2017).Google Scholar"",""Jianwen Jiang, Yuxuan Wei, Yifan Feng, Jingxuan Cao, and Yue Gao. 2019. Dynamic Hypergraph Neural Networks. In IJCAI. ijcai.org, 2635--2641.Google Scholar"",""Thomas N. Kipf and Max Welling. 2016. Variational Graph Auto-Encoders. CoRR, Vol. abs/1611.07308 (2016).Google Scholar"",""Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In ICLR (Poster). OpenReview.net.Google Scholar"",""Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. 2018. Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting. In ICLR (Poster). Open Review.net.Google Scholar"",""Christopher Morris, Martin Ritzert, Matthias Fey, William L. Hamilton, Jan Eric Lenssen, Gaurav Rattan, and Martin Grohe. 2019. Weisfeiler and Leman Go Neural: Higher-Order Graph Neural Networks. In AAAI. AAAI Press, 4602--4609.Google Scholar"",""Junyoung Park and Jinkyoo Park. 2019. Physics-induced graph neural network: An application to wind-farm power estimation. Energy, Vol. 187 (08 2019), 115883. https://doi.org/10.1016/j.energy.2019.115883Google Scholar"",""Alvaro Sanchez-Gonzalez, Nicolas Heess, Jost Tobias Springenberg, Josh Merel, Martin A. Riedmiller, Raia Hadsell, and Peter W. Battaglia. 2018. Graph Networks as Learnable Physics Engines for Inference and Control. In ICML (Proceedings of Machine Learning Research), Vol. 80. PMLR, 4467--4476.Google Scholar"",""Adam Santoro, David Raposo, David G. T. Barrett, Mateusz Malinowski, Razvan Pascanu, Peter W. Battaglia, and Tim Lillicrap. 2017. A simple neural network module for relational reasoning. In NIPS. 4967--4976.Google Scholar"",""Xingjian Shi, Zhourong Chen, Hao Wang, Dit-Yan Yeung, Wai-Kin Wong, and Wang-chun Woo. 2015. Convolutional LS™ Network: A Machine Learning Approach for Precipitation Nowcasting. In NIPS. 802--810.Google Scholar"",""Chen Sun, Per Karlsson, Jiajun Wu, Joshua B. Tenenbaum, and Kevin Murphy. 2019. Stochastic Prediction of Multi-Agent Interactions from Partial Observations. In ICLR (Poster). OpenReview.net.Google Scholar"",""Ke Tu, Peng Cui, Xiao Wang, Fei Wang, and Wenwu Zhu. 2018. Structural Deep Embedding for Hyper-Networks. In AAAI. AAAI Press, 426--433.Google Scholar"",""Laurens van der Maaten and Geoffrey Hinton. 2008. Visualizing Data using t-SNE. Journal of Machine Learning Research, Vol. 9 (2008), 2579--2605. http://www.jmlr.org/papers/v9/vandermaaten08a.htmlGoogle Scholar"",""Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. 2018. Graph Attention Networks. In ICLR (Poster). OpenReview.net.Google Scholar"",""Tingwu Wang, Renjie Liao, Jimmy Ba, and Sanja Fidler. 2018. NerveNet: Learning Structured Policy with Graph Neural Networks. In ICLR (Poster). OpenReview.net.Google Scholar"",""Ying Xu and Dongsheng Li. 2019. Incorporating Graph Attention and Recurrent Architectures for City-Wide Taxi Demand Prediction. ISPRS Int. J. Geo-Information, Vol. 8, 9 (2019), 414.Google ScholarCross Ref"",""Naganand Yadati, Madhav Nimishakavi, Prateek Yadav, Vikram Nitin, Anand Louis, and Partha P. Talukdar. 2019. HyperGCN: A New Method For Training Graph Convolutional Networks on Hypergraphs. In NeurIPS. 1509--1520.Google Scholar"",""Huaxiu Yao, Xianfeng Tang, Hua Wei, Guanjie Zheng, and Zhenhui Li. 2019. Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction. In AAAI. AAAI Press, 5668--5675.Google Scholar"",""Huaxiu Yao, Fei Wu, Jintao Ke, Xianfeng Tang, Yitian Jia, Siyu Lu, Pinghua Gong, Jieping Ye, and Zhenhui Li. 2018. Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction. In AAAI. AAAI Press, 2588--2595.Google Scholar"",""Shuochao Yao, Shaohan Hu, Yiran Zhao, Aston Zhang, and Tarek F. Abdelzaher. 2017. DeepSense: A Unified Deep Learning Framework for Time-Series Mobile Sensing Data Processing. In WWW. ACM, 351--360.Google Scholar"",""Bing Yu, Haoteng Yin, and Zhanxing Zhu. 2018. Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting. In IJCAI. ijcai.org, 3634--3640.Google Scholar"",""Chuxu Zhang, Dongjin Song, Yuncong Chen, Xinyang Feng, Cristian Lumezanu, Wei Cheng, Jingchao Ni, Bo Zong, Haifeng Chen, and Nitesh V. Chawla. 2019 a. A Deep Neural Network for Unsupervised Anomaly Detection and Diagnosis in Multivariate Time Series Data. In AAAI. AAAI Press, 1409--1416.Google Scholar"",""Junbo Zhang, Yu Zheng, and Dekang Qi. 2017. Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction. In AAAI. AAAI Press, 1655--1661.Google Scholar"",""Muhan Zhang and Yixin Chen. 2018. Link Prediction Based on Graph Neural Networks. In NeurIPS. 5171--5181.Google Scholar"",""Ruochi Zhang, Yuesong Zou, and Jian Ma. 2019 b. Hyper-SAGNN: a self-attention based graph neural network for hypergraphs. CoRR, Vol. abs/1911.02613 (2019).Google Scholar"",""Dengyong Zhou, Jiayuan Huang, and Bernhard Schö lkopf. 2006. Learning with Hypergraphs: Clustering, Classification, and Embedding. In NIPS. MIT Press, 1601--1608.Google Scholar""]"
https://doi.org/10.1145/3394486.3403390,Towards Building an Intelligent Chatbot for Customer Service: Learning to Respond at the Appropriate Time,"In recent years, intelligent chatbots have been widely used in the field of customer service. One of the key challenges for chatbots to maintain fluent dialogues with customers is how to respond at the appropriate time. However, most of the state-of-the-art chatbots follow the turn-by-turn interaction scheme. Such chatbots respond after each time when a customer sends an utterance, which in some cases leads to inappropriate responses and misleads the process of the dialogues. In this paper, we propose a multi-turn response triggering model (MRTM) to address this problem. MRTM is learned from large-scale human-human dialogues between the customers and the agents with a self-supervised learning scheme. It leverages the semantic matching relationships between the context and the response to train a semantic matching model and obtains the weights of the co-occurring utterances in the context through an asymmetrical self-attention mechanism. The weights are then used to determine whether the given context should be responded to. We conduct extensive experiments on two dialogue datasets collected from the real-world online customer service systems. Results show that MRTM outperforms the baselines by a large margin. Furthermore, we incorporate MRTM into DiDi's customer service chatbot. Based on the ability to identify the appropriate time to respond, the chatbot can incrementally aggregate the information across multiple utterances and make more intelligent responses at the appropriate time.","[{""name"":""Che Liu"",""id"":""/profile/99659574626""},{""name"":""Junfeng Jiang"",""id"":""/profile/99659573342""},{""name"":""Chao Xiong"",""id"":""/profile/99659573627""},{""name"":""Yi Yang"",""id"":""/profile/99659574710""},{""name"":""Jieping Ye"",""id"":""/profile/99659193247""},{""name"":""Che Liu"",""id"":""/profile/99659574626""},{""name"":""Junfeng Jiang"",""id"":""/profile/99659573342""},{""name"":""Chao Xiong"",""id"":""/profile/99659573627""},{""name"":""Yi Yang"",""id"":""/profile/99659574710""},{""name"":""Jieping Ye"",""id"":""/profile/99659193247""}]","[""Mart'in Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et almbox. 2016. Tensorflow: A system for large-scale machine learning. In 12th $$USENIX$$ Symposium on Operating Systems Design and Implementation ($$OSDI$$ 16). 265--283.Google Scholar"",""Meng Chen, Ruixue Liu, Lei Shen, Shaozu Yuan, Jingyan Zhou, Youzheng Wu, Xiaodong He, and Bowen Zhou. 2019. The JDDC Corpus: A Large-Scale Multi-Turn Chinese Dialogue Dataset for E-commerce Customer Service. arXiv preprint arXiv:1911.09969 (2019).Google Scholar"",""Andrei C. Coman, Koichiro Yoshino, Yukitoshi Murase, Satoshi Nakamura, and Giuseppe Riccardi. 2019. An Incremental Turn-Taking Model for Task-Oriented Dialog Systems. In Proc. Interspeech 2019. 4155--4159. https://doi.org/10.21437/Interspeech.2019--1826Google ScholarCross Ref"",""David DeVault, Kenji Sagae, and David Traum. 2009. Can I finish?: learning when to respond to incremental interpretation results in interactive dialogue. In Proceedings of the SIGDIAL 2009 Conference: The 10th Annual Meeting of the Special Interest Group on Discourse and Dialogue. Association for Computational Linguistics, 11--20.Google ScholarCross Ref"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).Google Scholar"",""Carl Doersch, Abhinav Gupta, and Alexei A Efros. 2015. Unsupervised visual representation learning by context prediction. In Proceedings of the IEEE International Conference on Computer Vision. 1422--1430.Google ScholarDigital Library"",""Nouha Dziri, Ehsan Kamalloo, Kory Mathewson, and Osmar R Zaiane. 2019. Augmenting Neural Response Generation with Context-Aware Topical Attention. In Proceedings of the First Workshop on NLP for Conversational AI. 18--31.Google ScholarCross Ref"",""Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural computation, Vol. 9, 8 (1997), 1735--1780.Google Scholar"",""Anjuli Kannan, Karol Kurach, Sujith Ravi, Tobias Kaufmann, Andrew Tomkins, Balint Miklos, Greg Corrado, Laszlo Lukacs, Marina Ganea, Peter Young, et almbox. 2016. Smart reply: Automated response suggestion for email. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 955--964.Google ScholarDigital Library"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Feng-Lin Li, Minghui Qiu, Haiqing Chen, Xiongwei Wang, Xing Gao, Jun Huang, Juwei Ren, Zhongzhou Zhao, Weipeng Zhao, Lei Wang, et almbox. 2017. Alime assist: An intelligent assistant for creating an innovative e-commerce experience. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management. ACM, 2495--2498.Google ScholarDigital Library"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems. 3111--3119.Google Scholar"",""Vinod Nair and Geoffrey E Hinton. 2010. Rectified linear units improve restricted boltzmann machines. In Proceedings of the 27th international conference on machine learning (ICML-10). 807--814.Google ScholarDigital Library"",""Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 2018. Improving language understanding by generative pre-training. URL https://s3-us-west-2. amazonaws. com/openai-assets/researchcovers/languageunsupervised/language understanding paper. pdf (2018).Google Scholar"",""Iulian V Serban, Alessandro Sordoni, Yoshua Bengio, Aaron Courville, and Joelle Pineau. 2016. Building end-to-end dialogue systems using generative hierarchical neural network models. In Thirtieth AAAI Conference on Artificial Intelligence.Google ScholarDigital Library"",""Alessandro Sordoni, Michel Galley, Michael Auli, Chris Brockett, Yangfeng Ji, Margaret Mitchell, Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. 2015. A Neural Network Approach to Context-Sensitive Generation of Conversational Responses. In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 196--205.Google ScholarCross Ref"",""Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Sequence to sequence learning with neural networks. In Advances in neural information processing systems. 3104--3112.Google Scholar"",""Chongyang Tao, Wei Wu, Can Xu, Wenpeng Hu, Dongyan Zhao, and Rui Yan. 2019. One time of interaction may not be enough: Go deep with an interaction-over-interaction network for response selection in dialogues. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. 1--11.Google ScholarCross Ref"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998--6008.Google Scholar"",""Marilyn A Walker, Rebecca Passonneau, and Julie E Boland. 2001. Quantitative and qualitative evaluation of DARPA Communicator spoken dialogue systems. In Proceedings of the 39th Annual Meeting on Association for Computational Linguistics. Association for Computational Linguistics, 515--522.Google ScholarDigital Library"",""Haifeng Wang. 2016. Duer: Intelligent Personal Assistant. In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management. ACM, 427--427.Google ScholarDigital Library"",""Xiaolong Wang and Abhinav Gupta. 2015. Unsupervised learning of visual representations using videos. In Proceedings of the IEEE International Conference on Computer Vision. 2794--2802.Google ScholarDigital Library"",""Joseph Weizenbaum. 1966. ELIZA-a computer program for the study of natural language communication between man and machine. Commun. ACM, Vol. 9, 1 (1966), 36--45.Google ScholarDigital Library"",""Jason D Williams, Matthew Henderson, Antoine Raux, Blaise Thomson, Alan Black, and Deepak Ramachandran. 2014. The dialog state tracking challenge series. AI Magazine, Vol. 35, 4 (2014), 121--124.Google ScholarCross Ref"",""Jiawei Wu, Xin Wang, and William Yang Wang. 2019. Self-Supervised Dialogue Learning. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. 3857--3867.Google ScholarCross Ref"",""Yu Wu, Wei Wu, Chen Xing, Ming Zhou, and Zhoujun Li. 2017. Sequential Matching Network: A New Architecture for Multi-turn Response Selection in Retrieval-Based Chatbots. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 496--505.Google ScholarCross Ref"",""Rui Yan, Yiping Song, and Hua Wu. 2016. Learning to respond with deep neural networks for retrieval-based human-computer conversation system. In Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval. ACM, 55--64.Google ScholarDigital Library"",""Yi Yang, Wen-tau Yih, and Christopher Meek. 2015. Wikiqa: A challenge dataset for open-domain question answering. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. 2013--2018.Google ScholarCross Ref"",""Victor H Yngve. 1970. On getting a word in edgewise. Papers from the Sixth Regional Meeting of the Chicago Linguistic Society. Mary Ann Campbell et almbox.(Eds.). Chicago Linguistic Society, Chicago, IL, USA (1970).Google Scholar"",""Yizhe Zhang, Xiang Gao, Sungjin Lee, Chris Brockett, Michel Galley, Jianfeng Gao, and Bill Dolan. 2019. Consistent dialogue generation with self-supervised feature learning. arXiv preprint arXiv:1903.05759 (2019).Google Scholar"",""Li Zhou, Jianfeng Gao, Di Li, and Heung-Yeung Shum. 2018a. The design and implementation of XiaoIce, an empathetic social chatbot. Computational Linguistics Just Accepted (2018), 1--62.Google Scholar"",""Xiangyang Zhou, Lu Li, Daxiang Dong, Yi Liu, Ying Chen, Wayne Xin Zhao, Dianhai Yu, and Hua Wu. 2018b. Multi-turn response selection for chatbots with deep attention matching network. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 1118--1127.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3403391,Ads Allocation in Feed via Constrained Optimization,"Social networks and content publishing platforms have newsfeed applications, which show both organic content to drive engagement, and ads to drive revenue. This paper focuses on the problem of ads allocation in a newsfeed to achieve an optimal balance of revenue and engagement. To the best of our knowledge, we are the first to report practical solutions to this business-critical and popular problem in industry.The paper describes how large-scale recommender system like feed ranking works, and why it is useful to consider ads allocation as a post-operation once the ranking of organic items and (separately) the ranking of ads are done. A set of computationally lightweight algorithms are proposed based on various sets of assumptions in the context of ads on the LinkedIn newsfeed. Through both offline simulation and online A/B tests, benefits of the proposed solutions are demonstrated. The best performing algorithm is currently fully deployed on the LinkedIn newsfeed and is serving all live traffic.","[{""name"":""Jinyun Yan"",""id"":""/profile/99659287999""},{""name"":""Zhiyuan Xu"",""id"":""/profile/99659573737""},{""name"":""Birjodh Tiwana"",""id"":""/profile/81464665312""},{""name"":""Shaunak Chatterjee"",""id"":""/profile/99659060630""},{""name"":""Jinyun Yan"",""id"":""/profile/99659287999""},{""name"":""Zhiyuan Xu"",""id"":""/profile/99659573737""},{""name"":""Birjodh Tiwana"",""id"":""/profile/81464665312""},{""name"":""Shaunak Chatterjee"",""id"":""/profile/99659060630""}]","[""Gediminas Adomavicius, Nikos Manouselis, and YoungOk Kwon. 2011. Multi-criteria recommender systems. In Recommender systems handbook. Springer, 769--803.Google Scholar"",""Deepak Agarwal, Shaunak Chatterjee, Yang Yang, and Liang Zhang. 2015a. Constrained optimization for homepage relevance. In Proceedings of the 24th International Conference on World Wide Web. ACM, 375--384.Google ScholarDigital Library"",""Deepak Agarwal, Bee-Chung Chen, Pradheep Elango, and Xuanhui Wang. 2012. Personalized Click Shaping Through Lagrangian Duality for Online Recommendation. In SIGIR (Portland, Oregon, USA). ACM, New York, NY, USA, 485--494.Google Scholar"",""Deepak Agarwal, Bee-Chung Chen, Rupesh Gupta, Joshua Hartman, Qi He, Anand Iyer, Sumanth Kolar, Yiming Ma, Pannagadatta Shivaswamy, Ajit Singh, et almbox. 2014a. Activity ranking in LinkedIn feed. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. 1603--1612.Google ScholarDigital Library"",""Deepak Agarwal, Bee-Chung Chen, Qi He, Zhenhao Hua, Guy Lebanon, Yiming Ma, Pannagadatta Shivaswamy, Hsiao-Ping Tseng, Jaewon Yang, and Liang Zhang. 2015b. Personalizing linkedin feed. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 1651--1660.Google ScholarDigital Library"",""Deepak Agarwal, Bo Long, Jonathan Traupman, Doris Xin, and Liang Zhang. 2014b. Laser: A scalable response prediction platform for online advertising. In Proceedings of the 7th ACM international conference on Web search and data mining. 173--182.Google ScholarDigital Library"",""Jaime Arguello, Fernando Diaz, Jamie Callan, and Ben Carterette. 2011. A methodology for evaluating aggregated search results. In European Conference on Information Retrieval. Springer, 141--152.Google ScholarDigital Library"",""Stephen Boyd and Lieven Vandenberghe. 2004. Convex optimization. Cambridge university press.Google Scholar"",""Christopher Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds, Nicole Hamilton, and Gregory N Hullender. 2005. Learning to rank using gradient descent. In Proceedings of the 22nd International Conference on Machine learning (ICML-05). 89--96.Google ScholarDigital Library"",""Yair Censor. 1977. Pareto optimality in multiobjective problems. Applied Mathematics and Optimization, Vol. 4, 1 (1977), 41--59.Google ScholarDigital Library"",""Ye Chen, Pavel Berkhin, Bo Anderson, and Nikhil R Devanur. 2011. Real-time bidding algorithms for performance-based display ad allocation. In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 1307--1315.Google ScholarDigital Library"",""Thomas H Cormen, Charles E Leiserson, Ronald L Rivest, and Clifford Stein. 2009. Introduction to algorithms. MIT press.Google Scholar"",""Benjamin Edelman, Michael Ostrovsky, and Michael Schwarz. 2007. Internet advertising and the generalized second-price auction: Selling billions of dollars worth of keywords. American economic review, Vol. 97, 1 (2007), 242--259.Google Scholar"",""Yan Gao, Viral Gupta, Jinyun Yan, Changji Shi, Zhongen Tao, PJ Xiao, Curtis Wang, Shipeng Yu, Romer Rosales, Ajith Muralidharan, and Shaunak Chatterjee. 2018. Near Real-time Optimization of Activity-based Notifications. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 283--292.Google ScholarDigital Library"",""Mounia Lalmas. 2011. Aggregated search. In Advanced Topics in Information Retrieval. Springer, 109--123.Google Scholar"",""Nathan Mantel and William Haenszel. 1959. Statistical aspects of the analysis of data from retrospective studies of disease. Journal of the National Cancer Institute, Vol. 22, 4 (1959), 719--748.Google Scholar"",""Mario Rodriguez, Christian Posse, and Ethan Zhang. 2012. Multiple objective optimization in recommender systems. In Proceedings of the sixth ACM conference on Recommender systems. ACM, 11--18.Google ScholarDigital Library"",""Shanu Sushmita, Hideo Joho, Mounia Lalmas, and Robert Villa. 2010. Factors affecting click-through behavior in aggregated search interfaces. In Proceedings of the 19th ACM international conference on Information and knowledge management. 519--528.Google ScholarDigital Library"",""Krysta M Svore, Maksims N Volkovs, and Christopher JC Burges. 2011. Learning to rank with multiple objective functions. In Proceedings of the 20th international conference on World wide web. ACM, 367--376.Google ScholarDigital Library"",""Liang Tang, Bo Long, Bee-Chung Chen, and Deepak Agarwal. 2016. An empirical study on recommendation with multiple types of feedback. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 283--292.Google ScholarDigital Library"",""William R. Thompson. 1933. On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. Biometrika, Vol. 47 (1933), 285--294.Google ScholarCross Ref"",""Hal R Varian and Christopher Harris. 2014. The VCG auction in theory and practice. American Economic Review, Vol. 104, 5 (2014), 442--45.Google ScholarCross Ref"",""Bo Wang, Zhaonan Li, Jie Tang, Kuo Zhang, Songcan Chen, and Liyun Ru. 2011. Learning to advertise: how many ads are enough?. In Pacific-Asia Conference on Knowledge Discovery and Data Mining. Springer, 506--518.Google ScholarCross Ref"",""Bianca Zadrozny and Charles Elkan. 2002. Transforming classifier scores into accurate multiclass probability estimates. In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 694--699.Google ScholarDigital Library"",""XianXing Zhang, Yitong Zhou, Yiming Ma, Bee-Chung Chen, Liang Zhang, and Deepak Agarwal. 2016. Glmix: Generalized linear mixed models for large-scale response prediction. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 363--372.Google ScholarDigital Library"",""Bo Zhao, Koichiro Narita, Burkay Orten, and John Egan. 2018. Notification Volume Control and Optimization System at Pinterest. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 1012--1020.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3403392,USAD: UnSupervised Anomaly Detection on Multivariate Time Series,"The automatic supervision of IT systems is a current challenge at Orange. Given the size and complexity reached by its IT operations, the number of sensors needed to obtain measurements over time, used to infer normal and abnormal behaviors, has increased dramatically making traditional expert-based supervision methods slow or prone to errors. In this paper, we propose a fast and stable method called UnSupervised Anomaly Detection for multivariate time series (USAD) based on adversely trained autoencoders. Its autoencoder architecture makes it capable of learning in an unsupervised way. The use of adversarial training and its architecture allows it to isolate anomalies while providing fast training. We study the properties of our methods through experiments on five public datasets, thus demonstrating its robustness, training speed and high anomaly detection performance. Through a feasibility study using Orange's proprietary data we have been able to validate Orange's requirements on scalability, stability, robustness, training speed and high performance.","[{""name"":""Julien Audibert"",""id"":""/profile/99659573355""},{""name"":""Pietro Michiardi"",""id"":""/profile/81100123144""},{""name"":""Frédéric Guyard"",""id"":""/profile/99659573196""},{""name"":""Sébastien Marti"",""id"":""/profile/99659573340""},{""name"":""Maria A. Zuluaga"",""id"":""/profile/99659573921""},{""name"":""Julien Audibert"",""id"":""/profile/99659573355""},{""name"":""Pietro Michiardi"",""id"":""/profile/81100123144""},{""name"":""Frédéric Guyard"",""id"":""/profile/99659573196""},{""name"":""Sébastien Marti"",""id"":""/profile/99659573340""},{""name"":""Maria A. Zuluaga"",""id"":""/profile/99659573921""}]","[""Martín Arjovsky and Lé on Bottou. 2017. Towards Principled Methods for Training Generative Adversarial Networks. In 5th International Conference on Learning Representations, ICLR 2017. OpenReview.net, Toulon, France.Google Scholar"",""Raghavendra Chalapathy and Sanjay Chawla. 2019. Deep Learning for Anomaly Detection: A Survey. CoRR, Vol. abs/1901.03407 (2019).Google Scholar"",""Wanpracha Art Chaovalitwongse, Ya-Ju Fan, and Rajesh C. Sachdeo. 2007. On the Time Series K-Nearest Neighbor Classification of Abnormal Brain Activity. IEEE Trans. Systems, Man, and Cybernetics, Part A, Vol. 37, 6 (2007), 1005--1016.Google ScholarDigital Library"",""Jonathan Goh, Sridhar Adepu, Khurum Nazir Junejo, and Aditya Mathur. 2017. A Dataset to Support Research in the Design of Secure Water Treatment Systems. In Critical Information Infrastructures Security. Springer International Publishing, 88--99.Google Scholar"",""Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron C. Courville, and Yoshua Bengio. 2014. Generative Adversarial Nets. In Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems 2014. Montreal, Quebec, Canada, 2672--2680.Google Scholar"",""Manish Gupta, Jing Gao, Charu C Aggarwal, and Jiawei Han. 2013. Outlier detection for temporal data: A survey. IEEE Transactions on Knowledge and Data Engineering, Vol. 26, 9 (2013), 2250--2267.Google ScholarCross Ref"",""Sepp Hochreiter and Jü rgen Schmidhuber. 1997. Long Short-Term Memory. Neural Computation, Vol. 9, 8 (1997), 1735--1780.Google ScholarDigital Library"",""Kyle Hundman, Valentino Constantinou, Christopher Laporte, Ian Colwell, and Tom Sö derströ m. 2018. Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining, KDD 2018, London, UK, August 19-23, 2018. ACM, 387--395.Google ScholarDigital Library"",""Istvan Kiss, Bela Genge, Piroska Haller, and Gheorghe Sebestyen. 2014. Data clustering-based anomaly detection in industrial control systems. In Proceedings - 2014 IEEE 10th International Conference on Intelligent Computer Communication and Processing, ICCP 2014. IEEE, Cluj-Napoca, Romania, 275--281.Google ScholarCross Ref"",""Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. 2008. Isolation Forest. In Proceedings of the 8th IEEE International Conference on Data Mining (ICDM 2008), December 15-19, 2008. IEEE Computer Society, Pisa, Italy, 413--422.Google Scholar"",""Junshui Ma and Simon Perkins. 2003. Time-series Novelty Detection Using One-class Support Vector Machines. Proceedings of the International Joint Conference on Neural Networks, Vol. 3 (2003), 1741--1745.Google ScholarCross Ref"",""Pankaj Malhotra, Anusha Ramakrishnan, Gaurangi Anand, Lovekesh Vig, Puneet Agarwal, and Gautam Shroff. 2016. LSTM-based Encoder-Decoder for Multi-sensor Anomaly Detection. (2016).Google Scholar"",""Aditya P Mathur and Nils Ole Tippenhauer. 2016. SWaT: a water treatment testbed for research and training on ICS security. In 2016 International Workshop on Cyber-physical Systems for Smart Water Networks (CySWater). IEEE, 31--36.Google ScholarCross Ref"",""Daehyung Park, Yuuna Hoshi, and Charles C. Kemp. 2018. A Multimodal Anomaly Detector for Robot-Assisted Feeding Using an LS™-Based Variational Autoencoder. IEEE Robotics and Automation Letters, Vol. 3, 3 (jul 2018), 1544--1551.Google ScholarCross Ref"",""D. E. Rumelhart, G. E. Hinton, and R. J. Williams. 1986. Learning Internal Representations by Error Propagation. MIT Press, Cambridge, MA, USA, 318--362.Google Scholar"",""Roy Schwartz, Jesse Dodge, Noah A. Smith, and Oren Etzioni. 2019. Green AI. (jul 2019).Google Scholar"",""Ya Su, Rong Liu, Youjian Zhao, Wei Sun, Chenhao Niu, and Dan Pei. 2019. Robust anomaly detection for multivariate time series through stochastic recurrent neural network. Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Vol. 1485 (2019), 2828--2837.Google ScholarDigital Library"",""Ye Yuan, Guangxu Xun, Fenglong Ma, Yaqing Wang, Nan Du, Kebin Jia, Lu Su, and Aidong Zhang. 2018. MuVAN: A Multi-view Attention Network for Multivariate Temporal Data. Proceedings - IEEE International Conference on Data Mining, ICDM, Vol. 2018-November (2018), 717--726.Google ScholarCross Ref"",""Houssam Zenati, Manon Romain, Chuan-Sheng Foo, Bruno Lecouat, and Vijay Chandrasekhar. 2018. Adversarially Learned Anomaly Detection. In IEEE International Conference on Data Mining, ICDM 2018. IEEE Computer Society, Singapore, 727--736.Google Scholar"",""Chuxu Zhang, Dongjin Song, Yuncong Chen, Xinyang Feng, Cristian Lumezanu, Wei Cheng, Jingchao Ni, Bo Zong, Haifeng Chen, and Nitesh V. Chawla. 2019. A Deep Neural Network for Unsupervised Anomaly Detection and Diagnosis in Multivariate Time Series Data. Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33 (2019), 1409--1416.Google Scholar"",""Bo Zong, Qi Song, Martin Renqiang Min, Wei Cheng, Cristian Lumezanu, Daeki Cho, and Haifeng Chen. 2018. Deep autoencoding Gaussian mixture model for unsupervised anomaly detection. In 6th International Conference on Learning Representations, ICLR 2018. Toulon, France, 1--19.Google Scholar""]"
https://doi.org/10.1145/3394486.3403393,A Dual Heterogeneous Graph Attention Network to Improve Long-Tail Performance for Shop Search in E-Commerce,"Shop search has become an increasingly important service provided by Taobao, the China's largest e-commerce platform. By using shop search, a user can easily identify the desired shop that provides a full-scale of relevant items matching his information need. With the tremendous growth of users and shops, shop search faces several unique challenging problems: 1) many shop names do not fully express what they sell, i.e., the semantic gap between user query and shop name; 2) due to the lack of user interactions, it is difficult to deliver a good search result for the long-tail queries and retrieve long-tail shops that are highly relevant to a query.To address these two key challenges, we resort to graph neural networks (GNNs) which have various successful applications in arbitrarily structured graph data. Specifically, we propose a dual heterogeneous graph attention network (DHGAT) integrated with the two-tower architecture, using the user interaction data from both shop search and product search. At first, we build a heterogeneous graph in the context of shop search, by exploiting both the first-order and second-order proximity from user search behaviors, user click-through behaviors and user purchase records. Then, DHGAT is devised to attentively adopt heterogeneous and homogeneous neighbors of query and shop to enhance representations of themselves, which can help relieve the long-tail phenomenon. Besides, DHGAT enriches semantics of query text and shop name by compositing the titles of the relevant items to alleviate the semantic gap. Moreover, to enhance the graph representation learning, we augment DHGAT with a regularized neighbor proximity loss (NPL) to explicitly learn the graph topological structure and train whole framework in an end-to-end fashion. Compelling results from both offline evaluation and online A/B tests demonstrate the superiority of DHGAT over state-of-the-art methods, especially for long-tail queries and shops.","[{""name"":""Xichuan Niu"",""id"":""/profile/99659573007""},{""name"":""Bofang Li"",""id"":""/profile/99659573658""},{""name"":""Chenliang Li"",""id"":""/profile/99658620810""},{""name"":""Rong Xiao"",""id"":""/profile/99659345922""},{""name"":""Haochuan Sun"",""id"":""/profile/99659570001""},{""name"":""Hongbo Deng"",""id"":""/profile/81413600167""},{""name"":""Zhenzhong Chen"",""id"":""/profile/81435601745""},{""name"":""Xichuan Niu"",""id"":""/profile/99659573007""},{""name"":""Bofang Li"",""id"":""/profile/99659573658""},{""name"":""Chenliang Li"",""id"":""/profile/99658620810""},{""name"":""Rong Xiao"",""id"":""/profile/99659345922""},{""name"":""Haochuan Sun"",""id"":""/profile/99659570001""},{""name"":""Hongbo Deng"",""id"":""/profile/81413600167""},{""name"":""Zhenzhong Chen"",""id"":""/profile/81435601745""}]","[""Qingyao Ai, Daniel N Hill, SVN Vishwanathan, and W Bruce Croft. 2019. A zero attention model for personalized product search. In CIKM. 379--388.Google Scholar"",""Qingyao Ai, Yongfeng Zhang, Keping Bi, Xu Chen, and W Bruce Croft. 2017. Learning a hierarchical embedding model for personalized product search. In SIGIR. 645--654.Google Scholar"",""Yukuo Cen, Xu Zou, Jianwei Zhang, Hongxia Yang, Jingren Zhou, and Jie Tang. 2019. Representation Learning for Attributed Multiplex Heterogeneous Network. arXiv preprint arXiv:1905.01669 (2019).Google Scholar"",""Liheng Chen, Yanru Qu, Zhenghui Wang, Lin Qiu, Weinan Zhang, Ken Chen, Shaodian Zhang, and Yong Yu. 2019. Sampled in Pairs and Driven by Text: A New Graph Embedding Framework. In WWW. 2644--2651.Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).Google Scholar"",""Huizhong Duan and ChengXiang Zhai. 2015. Mining coordinated intent representation for entity search and recommendation. In CIKM. 333--342.Google Scholar"",""Huizhong Duan, ChengXiang Zhai, Jinxing Cheng, and Abhishek Gattani. 2013. A probabilistic mixture model for mining and analyzing product search log. In CIKM. 2179--2188.Google Scholar"",""John Duchi, Elad Hazan, and Yoram Singer. 2011. Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research, Vol. 12, Jul (2011), 2121--2159.Google ScholarDigital Library"",""Shaohua Fan, Junxiong Zhu, Xiaotian Han, Chuan Shi, Linmei Hu, Biyu Ma, and Yongliang Li. 2019 b. Metapath-Guided Heterogeneous Graph Neural Network for Intent Recommendation. In KDD. 2478--2486.Google Scholar"",""Wenqi Fan, Yao Ma, Qing Li, Yuan He, Eric Zhao, Jiliang Tang, and Dawei Yin. 2019 a. Graph Neural Networks for Social Recommendation. In WWW. 417--426.Google Scholar"",""Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In KDD. 855--864.Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In NeurIPS. 1024--1034.Google Scholar"",""Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In WWW. 173--182.Google Scholar"",""Yujing Hu, Qing Da, Anxiang Zeng, Yang Yu, and Yinghui Xu. 2018. Reinforcement learning to rank in e-commerce search engine: Formalization, analysis, and application. In KDD. 368--377.Google Scholar"",""Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero, and Larry Heck. 2013. Learning deep structured semantic models for web search using clickthrough data. In CIKM. 2333--2338.Google Scholar"",""Dietmar Jannach and Malte Ludewig. 2017. Investigating personalized search in e-commerce. In The Thirtieth International Flairs Conference.Google Scholar"",""Shubhra Kanti Karmaker Santu, Parikshit Sondhi, and ChengXiang Zhai. 2017. On application of learning to rank for e-commerce search. In SIGIR. 475--484.Google Scholar"",""Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).Google Scholar"",""Soon Chong Johnson Lim, Ying Liu, and Wing Bun Lee. 2010. Multi-facet product information search and retrieval using semantically annotated product family ontology. Information Processing and Management, Vol. 46, 4 (2010), 479--493.Google ScholarDigital Library"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In NeurIPS. 3111--3119.Google Scholar"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In KDD. 701--710.Google ScholarDigital Library"",""Ning Su, Jiyin He, Yiqun Liu, Min Zhang, and Shaoping Ma. 2018. User intent, behaviour, and perceived satisfaction in product search. In WSDM. 547--555.Google Scholar"",""Christophe Van Gysel, Maarten de Rijke, and Evangelos Kanoulas. 2016. Learning latent vector spaces for product search. In CIKM. 165--174.Google Scholar"",""Petar Velivc ković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph attention networks. arXiv preprint arXiv:1710.10903 (2017).Google Scholar"",""Jizhe Wang, Pipei Huang, Huan Zhao, Zhibo Zhang, Binqiang Zhao, and Dik Lun Lee. 2018. Billion-scale commodity embedding for e-commerce recommendation in alibaba. In KDD. 839--848.Google Scholar"",""Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, and Philip S Yu. 2019. Heterogeneous Graph Attention Network. In WWW. 2022--2032.Google Scholar"",""Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, and Tieniu Tan. 2019. Session-based recommendation with graph neural networks. In AAAI. 346--353.Google Scholar"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale recommender systems. In KDD. 974--983.Google Scholar"",""Yuan Zhang, Dong Wang, and Yan Zhang. 2019. Neural IR Meets Graph Embedding: A Ranking Model for Product Search. In WWW. 2390--2400.Google Scholar"",""Jun Zhao, Zhou Zhou, Ziyu Guan, Wei Zhao, Wei Ning, Guang Qiu, and Xiaofei He. 2019. IntentGC: a Scalable Graph Convolution Framework Fusing Heterogeneous Information for Recommendation. In KDD. 2347--2357.Google Scholar"",""Kui Zhao, Yuechuan Li, Zhaoqian Shuai, and Cheng Yang. 2018. Learning and Transferring IDs Representation in E-commerce. In KDD. 1031--1039.Google Scholar""]"
https://doi.org/10.1145/3394486.3403394,Learning with Limited Labels via Momentum Damped & Differentially Weighted Optimization,"As deep learning-based models are deployed more widely in search & recommender systems, system designers often face the issue of gathering large amounts of well-annotated data to train such neural models. While most user-centric systems rely on interaction signals as implicit feedback to train models, such signals are often weak proxies of user satisfaction, as compared to (say) explicit judgments from users, which are prohibitively expensive to collect. In this paper, we consider the task of learning from limited labeled data, wherein we aim at jointly leveraging strong supervision data (e.g. explicit judgments) along with weak supervision data (e.g. implicit feedback or labels from the related task) to train neural models.We present data mixing strategies based on submodular subset selection, and additionally, propose adaptive optimization techniques to enable the model to differentiate between a strong label data point and a weak supervision data point. Finally, we present two different case-studies (i) user satisfaction prediction with music recommendation and (ii) question-based video comprehension and demonstrate that the proposed adaptive learning strategies are better at learning from limited labels. Our techniques and findings provide practitioners with ways of leveraging external labeled data","[{""name"":""Rishabh Mehrotra"",""id"":""/profile/99658716949""},{""name"":""Ashish Gupta"",""id"":""/profile/99659574796""},{""name"":""Rishabh Mehrotra"",""id"":""/profile/99658716949""},{""name"":""Ashish Gupta"",""id"":""/profile/99659574796""}]","[""James S Bergstra, Rémi Bardenet, Yoshua Bengio, and Balázs Kégl. [n.d.]. Algorithms for hyper-parameter optimization. In NIPS 2011.Google ScholarDigital Library"",""Carla E Brodley and Mark A Friedl. 1999. Identifying mislabeled training data. Journal of artificial intelligence research, Vol. 11 (1999), 131--167.Google ScholarDigital Library"",""Mostafa Dehghani, Mehrjou, Gouws, Kamps, and Schölkopf. 2017a. Fidelity-weighted learning. arXiv preprint arXiv:1711.02799 (2017).Google Scholar"",""Mostafa Dehghani, Aliaksei Severyn, Sascha Rothe, and Jaap Kamps. 2017b. Learning to learn from weak supervision by full supervision. arXiv preprint arXiv:1711.11383 (2017).Google Scholar"",""Timothy Dozat. 2016. Incorporating nesterov momentum into adam. (2016).Google Scholar"",""John Duchi, Elad Hazan, and Yoram Singer. [n.d.]. Adaptive subgradient methods for online learning and stochastic optimization. JMLR 2011 ([n.,d.]).Google Scholar"",""Uriel Feige. 1998. A threshold of ln n for approximating set cover. J. ACM (1998).Google Scholar"",""Rahul Kidambi, Praneeth Netrapalli, Prateek Jain, and Sham Kakade. 2018. On the insufficiency of existing momentum schemes for stochastic optimization. In 2018 Information Theory and Applications Workshop (ITA). IEEE, 1--9.Google ScholarCross Ref"",""Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Julia Kiseleva, Kyle Williams, Hassan Awadallah, Crook, Zitouni, and Anastasakos. [n.d.]. Predicting user satisfaction with intelligent assistants. In SIGIR 2016.Google ScholarDigital Library"",""Hui Lin and Jeff Bilmes. [n.d.]. Multi-document summarization via budgeted maximization of submodular functions. In NAACL 2010.Google ScholarDigital Library"",""Hui Lin and Jeff Bilmes. 2011. A class of submodular functions for document summarization. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. 510--520.Google ScholarDigital Library"",""Eran Malach and Shai Shalev-Shwartz. 2017. Decoupling\"" when to update\"" from\"" how to update\"". In Advances in Neural Information Processing Systems. 960--970.Google Scholar"",""Rishabh Mehrotra, Ahmed Hassan Awadallah, Milad Shokouhi, Emine Yilmaz, Imed Zitouni, Ahmed El Kholy, and Madian Khabsa. 2017a. Deep sequential models for task satisfaction prediction. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management. 737--746.Google ScholarDigital Library"",""Rishabh Mehrotra, Mounia Lalmas, Doug Kenney, Thomas Lim-Meng, and Golli Hashemian. 2019. Jointly leveraging intent and interaction signals to predict user satisfaction with slate recommendations. In The World Wide Web Conference. 1256--1267.Google ScholarDigital Library"",""Rishabh Mehrotra and Emine Yilmaz. 2015. Representative \u0026 informative query selection for learning to rank using submodular functions. In Proceedings of the 38th international ACM sigir conference on research and development in information retrieval. 545--554.Google ScholarDigital Library"",""Rishabh Mehrotra, Imed Zitouni, Ahmed Hassan Awadallah, Ahmed El Kholy, and Madian Khabsa. 2017b. User interaction sequences for search satisfaction prediction. In Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval. 165--174.Google ScholarDigital Library"",""Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. [n.d.]. Distant supervision for relation extraction without labeled data. In ACL 2009.Google ScholarDigital Library"",""George L Nemhauser and Laurence A Wolsey. 1988. Integer and combinatorial optimization. Vol. 18. Wiley New York.Google Scholar"",""George L Nemhauser, Laurence A Wolsey, and Marshall L Fisher. 1978. An analysis of approximations for maximizing submodular set functions-I. Mathematical Programming (1978).Google Scholar"",""Giorgio Patrini, Frank Nielsen, and Carioni. [n.d.]. Loss factorization, weakly supervised learning and label noise robustness. In ICML 2016.Google Scholar"",""Ning Qian. 1999. On the momentum term in gradient descent learning algorithms. Neural networks, Vol. 12, 1 (1999), 145--151.Google Scholar"",""Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. Squad: 100,000 questions for machine comprehension of text. arXiv preprint arXiv:1606.05250 (2016).Google Scholar"",""A Ratner, S Bach, P Varma, and C Ré. [n.d.]. Weak supervision: the new programming paradigm for machine learning. Hazy Research.Google Scholar"",""Alexander Ratner, Stephen H Bach, Henry Ehrenberg, Jason Fries, Sen Wu, and Christopher Ré. 2017. Snorkel: Rapid training data creation with weak supervision. In Proceedings of the VLDB Endowment. International Conference on Very Large Data Bases, Vol. 11. NIH Public Access, 269.Google ScholarDigital Library"",""Ilya Sutskever, James Martens, George Dahl, and Geoffrey Hinton. [n.d.]. On the importance of initialization and momentum in deep learning. In ICML 2013.Google ScholarDigital Library"",""T Tieleman and G Hinton. 2017. Divide the gradient by a running average of its recent magnitude. coursera: Neural networks for machine learning. Technical Report. (2017).Google Scholar"",""Arash Vahdat. 2017. Toward robustness against label noise in training deep discriminative neural networks. In Advances in Neural Information Processing Systems. 5596--5605.Google Scholar"",""Andre Wibisono and Ashia C Wilson. 2015. On accelerated methods in optimization. arXiv preprint arXiv:1509.03616 (2015).Google Scholar"",""Kyle Williams, Julia Kiseleva, Aidan C Crook, Zitouni, Awadallah, and Khabsa. [n.d.]. Detecting good abandonment in mobile search. In WWW 2016.Google ScholarDigital Library"",""Ashia C Wilson, Benjamin Recht, and Michael I Jordan. 2016. A lyapunov analysis of momentum methods in optimization. arXiv preprint arXiv:1611.02635 (2016).Google Scholar""]"
https://doi.org/10.1145/3394486.3412862,Learning to Simulate Human Mobility,"Realistic simulation of a massive amount of human mobility data is of great use in epidemic spreading modeling and related health policy-making. Existing solutions for mobility simulation can be classified into two categories: model-based methods and model-free methods, which are both limited in generating high-quality mobility data due to the complicated transitions and complex regularities in human mobility. To solve this problem, we propose a model-free generative adversarial framework, which effectively integrates the domain knowledge of human mobility regularity utilized in the model-based methods. In the proposed framework, we design a novel self-attention based sequential modeling network as the generator to capture the complicated temporal transitions in human mobility. To augment the learning power of the generator with the advantages of model-based methods, we design an attention-based region network to introduce the prior knowledge of urban structure to generate a meaningful trajectory. As for the discriminator, we design a mobility regularity-aware loss to distinguish the generated trajectory. Finally, we utilize the mobility regularities of spatial continuity and temporal periodicity to pre-train the generator and discriminator to further accelerate the learning procedure. Extensive experiments on two real-life mobility datasets demonstrate that our framework outperforms seven state-of-the-art baselines significantly in terms of improving the quality of simulated mobility data by 35%. Furthermore, in the simulated spreading of COVID-19, synthetic data from our framework reduces MAPE from 5% ~ 10% (baseline performance) to 2%.","[{""name"":""Jie Feng"",""id"":""/profile/99659260208""},{""name"":""Zeyu Yang"",""id"":""/profile/99659371089""},{""name"":""Fengli Xu"",""id"":""/profile/99658756914""},{""name"":""Haisu Yu"",""id"":""/profile/99659573512""},{""name"":""Mudan Wang"",""id"":""/profile/99659573933""},{""name"":""Yong Li"",""id"":""/profile/81453640533""},{""name"":""Jie Feng"",""id"":""/profile/99659260208""},{""name"":""Zeyu Yang"",""id"":""/profile/99659371089""},{""name"":""Fengli Xu"",""id"":""/profile/99658756914""},{""name"":""Haisu Yu"",""id"":""/profile/99659573512""},{""name"":""Mudan Wang"",""id"":""/profile/99659573933""},{""name"":""Yong Li"",""id"":""/profile/81453640533""}]","[""Martin Arjovsky, Soumith Chintala, and Léon Bottou. 2017. Wasserstein gan. arXiv preprint arXiv:1701.07875 (2017).Google Scholar"",""M Batty. 2008. The size, scale, and shape of cities. Science, Vol. 319, 5864 (2008).Google Scholar"",""Jan Drchal, Michal Certický, and Michal Jakob. 2019. Data-driven activity scheduler for agent-based mobility models. Transportation Research Part C-emerging Technologies, Vol. 98 (2019), 370--390.Google ScholarCross Ref"",""Jie Feng, Yong Li, Zeyu Yang, Qiang Qiu, and Depeng Jin. 2020 a. Predicting Human Mobility with Semantic Motivation via Multi-task Attentional Recurrent Networks. IEEE Transactions on Knowledge and Data Engineering (TKDE) (2020).Google Scholar"",""Jie Feng, Yong Li, Chao Zhang, Funing Sun, Fanchao Meng, Ang Guo, and Depeng Jin. 2018. DeepMove: Predicting Human Mobility with Attentional Recurrent Networks. In Proceedings of the 2018 World Wide Web Conference.Google ScholarDigital Library"",""Jie Feng, Can Rong, Funing Sun, Diansheng Guo, and Yan-Ping Li. 2020 b. PMF: A Privacy-preserving Human Mobility Prediction Framework via Federated Learning. IMWUT, Vol. 4 (2020), 10:1--10:21.Google ScholarDigital Library"",""M. C. González, C. A. Hidalgo, and A. L. Barabási. 2008. Understanding individual human mobility patterns. Nature, Vol. 453, 7196 (2008), 779.Google Scholar"",""Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial nets. In Advances in Neural Information Processing Systems. 2672--2680.Google Scholar"",""Jonathan Ho and Stefano Ermon. 2016. Generative adversarial imitation learning. In Advances in neural information processing systems. 4565--4573.Google Scholar"",""Sibren Isaacman, Richard Becker, Ramon Caceres, Margaret Martonosi, James Rowland, Alexander Varshavsky, and Walter Willinger. 2012. Human mobility modeling at metropolitan scales. (2012), 239--252.Google Scholar"",""Shan Jiang, Yingxiang Yang, Siddharth Gupta, Daniele Veneziano, Shounak Athavale, and Marta C González. 2016. The TimeGeo modeling framework for urban mobility without travel surveys. PNAS, Vol. 113, 37 (2016).Google ScholarCross Ref"",""Sheng jie Lai, Nick W. Ruktanonchai, Liangcai Zhou, Olivia Prosper, Wei Luo, Jessica R Floyd, Amy Wesolowski, Mauricio Santillana, Chi Zhang, Xiangjun Du, Hongjie Yu, and Andrew J Tatem. 2020. Effect of non-pharmaceutical interventions to contain COVID-19 in China. Nature (2020).Google Scholar"",""Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. 2017. Progressive growing of gans for improved quality, stability, and variation. (2017).Google Scholar"",""Takehiro Kashiyama, Yanbo Pang, and Yoshihide Sekimoto. 2017. Open PFLOW: Creation and evaluation of an open dataset for typical people mass movement in urban areas. Transportation Research Part C-emerging Technologies, Vol. 85 (2017).Google ScholarCross Ref"",""Marc Olivier Killijian. 2012. Next place prediction using mobility Markov chains. In The Workshop on Measurement, Privacy, and Mobility. 3.Google Scholar"",""Vaibhav Kulkarni, Natasa Tagasovska, Thibault Vatter, and Benoit Garbinato. 2018. Generative Models for Simulating Mobility Trajectories. (2018).Google Scholar"",""Jiwei Li, Will Monroe, Tianlin Shi, Sébastien Jean, Alan Ritter, and Dan Jurafsky. 2017. Adversarial Learning for Neural Dialogue Generation. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. 2157--2169.Google ScholarCross Ref"",""Zhenhui Li, Bolin Ding, Jiawei Han, Roland Kays, and Peter Nye. 2010. Mining periodic behaviors for moving objects. In Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining. 1099--1108.Google ScholarDigital Library"",""Zhenhui Li, Jingjing Wang, and Jiawei Han. 2012. Mining event periodicity from incomplete observations. In KDD. 444--452.Google Scholar"",""Ziheng Lin, Mogeng Yin, Sidney Feygin, Madeleine Sheehan, Jean-Francois Paiement, and Alexei Pozdnoukhov. 2017. Deep Generative Models of Urban Mobility. (2017).Google Scholar"",""Qiang Liu, Shu Wu, Liang Wang, and Tieniu Tan. 2016. Predicting the next location: A recurrent model with spatial and temporal contexts. In AAAI.Google Scholar"",""Yonghong Luo, Xiangrui Cai, Ying Zhang, Jun Xu, et almbox. 2018. Multivariate time series imputation with generative adversarial networks. In Advances in Neural Information Processing Systems. 1596--1607.Google Scholar"",""Benjamin F. Maier and Dirk Brockmann. 2020. Effective containment explains subexponential growth in recent confirmed COVID-19 cases in China. Science (New York, N.y.) (2020).Google Scholar"",""Kun Ouyang, Reza Shokri, David S Rosenblum, and Wenzhuo Yang. 2018. A Non-Parametric Generative Model for Human Trajectories. In IJCAI. 3812--3817.Google Scholar"",""Jing-Cheng Shi, Yang Yu, Qing Da, Shi-Yong Chen, and Anxiang Zeng. 2019. Virtual-Taobao: Virtualizing Real-world Online Retail Environment for Reinforcement Learning. In AAAI.Google Scholar"",""Chaoming Song, Zehui Qu, Nicholas Blumm, and Albertlaszlo Barabasi. 2010. Limits of Predictability in Human Mobility. Science, Vol. 327, 5968 (2010), 1018--1021.Google Scholar"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems. 5998--6008.Google Scholar"",""Ronald J Williams. 1992. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning, Vol. 8, 3--4 (1992), 229--256.Google Scholar"",""Hao Wu, Ziyang Chen, Weiwei Sun, Baihua Zheng, and Wei Wang. 2017. Modeling trajectories with recurrent neural networks. IJCAI.Google Scholar"",""Mogeng Yin, Madeleine Sheehan, Sidney Feygin, Jean-Francc ois Paiement, and Alexei Pozdnoukhov. 2017. A generative model of urban activities from cellular data. IEEE Transactions on Intelligent Transportation Systems, Vol. 19, 6 (2017).Google Scholar"",""Lantao Yu, Weinan Zhang, Jun Wang, and Yong Yu. 2017. SeqGAN: Sequence generative adversarial nets with policy gradient. In AAAI.Google Scholar"",""Chao Zhang, Keyang Zhang, Quan Yuan, Luming Zhang, Tim Hanratty, and Jiawei Han. 2016. GMove: Group-Level Mobility Modeling Using Geo-Tagged Social Media. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD). 1305--1314.Google ScholarDigital Library"",""Guanjie Zheng, Hanyang Liu, Kai Xu, and Zhenhui Li. 2020. Learning to Simulate Vehicle Trajectories from Demonstrations. 2020 IEEE 36th International Conference on Data Engineering (ICDE) (2020), 1822--1825.Google ScholarCross Ref"",""Yu Zheng, Quannan Li, Yukun Chen, Xing Xie, and Wei-Ying Ma. 2008. Understanding mobility based on GPS data. In Proceedings of the 10th international conference on Ubiquitous computing. ACM, 312--321.Google ScholarDigital Library"",""Yu Zheng, Xing Xie, Wei-Ying Ma, et almbox. 2010. Geolife: A collaborative social networking service among user, location and trajectory. IEEE Data(base) Engineering Bulletin, Vol. 33, 2 (2010), 32--39.Google Scholar""]"
https://doi.org/10.1145/3394486.3412863,Data-driven Simulation and Optimization for Covid-19 Exit Strategies,"The rapid spread of the Coronavirus SARS-2 is a major challenge that led almost all governments worldwide to take drastic measures to respond to the tragedy. Chief among those measures is the massive lockdown of entire countries and cities, which beyond its global economic impact has created some deep social and psychological tensions within populations. While the adopted mitigation measures (including the lockdown) have generally proven useful, policymakers are now facing a critical question: how and when to lift the mitigation measures? A carefully-planned exit strategy is indeed necessary to recover from the pandemic without risking a new outbreak. Classically, exit strategies rely on mathematical modeling to predict the effect of public health interventions. Such models are unfortunately known to be sensitive to some key parameters, which are usually set based on rules-of-thumb.In this paper, we propose to augment epidemiological forecasting with actual data-driven models that will learn to fine-tune predictions for different contexts (e.g., per country). We have therefore built a pandemic simulation and forecasting toolkit that combines a deep learning estimation of the epidemiological parameters of the disease in order to predict the cases and deaths, and a genetic algorithm component searching for optimal trade-offs/policies between constraints and objectives set by decision-makers.Replaying pandemic evolution in various countries, we experimentally show that our approach yields predictions with much lower error rates than pure epidemiological models in 75% of the cases and achieves a 95% R² score when the learning is transferred and tested on unseen countries. When used for forecasting, this approach provides actionable insights into the impact of individual measures and strategies.","[{""name"":""Salah Ghamizi"",""id"":""/profile/99659456818""},{""name"":""Renaud Rwemalika"",""id"":""/profile/99659447290""},{""name"":""Maxime Cordy"",""id"":""/profile/81496686188""},{""name"":""Lisa Veiber"",""id"":""/profile/99659572945""},{""name"":""Tegawendé F. Bissyandé"",""id"":""/profile/81548005186""},{""name"":""Mike Papadakis"",""id"":""/profile/81453641325""},{""name"":""Jacques Klein"",""id"":""/profile/81344493148""},{""name"":""Yves Le Traon"",""id"":""/profile/81340493274""},{""name"":""Salah Ghamizi"",""id"":""/profile/99659456818""},{""name"":""Renaud Rwemalika"",""id"":""/profile/99659447290""},{""name"":""Maxime Cordy"",""id"":""/profile/81496686188""},{""name"":""Lisa Veiber"",""id"":""/profile/99659572945""},{""name"":""Tegawendé F. Bissyandé"",""id"":""/profile/81548005186""},{""name"":""Mike Papadakis"",""id"":""/profile/81453641325""},{""name"":""Jacques Klein"",""id"":""/profile/81344493148""},{""name"":""Yves Le Traon"",""id"":""/profile/81340493274""}]","[""Sina F Ardabili, Amir Mosavi, Pedram Ghamisi, Filip Ferdinand, Annamaria R Varkonyi-Koczy, Uwe Reuter, Timon Rabczuk, and Peter M Atkinson. 2020. Covid19 outbreak prediction with machine learning. Available at SSRN 3580188 (2020).Google Scholar"",""K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan. 2002. A fast and elitist multiobjective genetic algorithm: NSGA-II. IEEE Transactions on Evolutionary Computation 6, 2 (2002), 182--197.Google ScholarDigital Library"",""Mark Jit and Marc Brisson. 2011. Modelling the Epidemiology of Infectious Diseases for Decision Analysis. PharmacoEconomics 29, 5 (may 2011), 371--386.Google ScholarCross Ref"",""Fumito Koike and Nobuo Morimoto. 2018. Supervised forecasting of the range expansion of novel non-indigenous organisms: Alien pest organisms and the 2009 H1N1 flu pandemic. Global Ecology and Biogeography (04 2018).Google Scholar"",""Ying Liu, Albert A. Gayle, Annelies Wilder-Smith, and Joacim Rocklöv. 2020. The reproductive number of COVID-19 is higher compared to SARS coronavirus. Journal of Travel Medicine 27, 2 (mar 2020), 1--4.Google ScholarCross Ref"",""Esteban Ortiz-Ospina Max Roser, Hannah Ritchie and Joe Hasell. 2020. Coronavirus Pandemic (COVID-19). Our World in Data (2020). https://ourworldindata.org/coronavirus.Google Scholar"",""Christoph Molnar. 2019. Interpretable Machine Learning.Google Scholar"",""Olav Titus Muurlink, Peter Stephenson, Mohammad Zahirul Islam, and Andrew W Taylor-Robinson. 2018. Long-term predictors of dengue outbreaks in Bangladesh: A data mining approach. Infectious Disease Modelling 3 (2018), 322--330.Google ScholarCross Ref"",""Gaurav Pandey, Poonam Chaudhary, Rajan Gupta, and Saibal Pal. 2020. SEIR and Regression Model based COVID-19 outbreak predictions in India. arXiv preprint (2020).Google Scholar"",""T. Smith, N. Maire, A. Ross, M. Penny, N. Chitnis, A. Schapira, A. Studer, B. Genton, C. Lengeler, F. Tediosi, and et al. 2008. Towards a comprehensive simulation model of malaria epidemiology and control. Parasitology 135, 13 (2008), 1507--1516.Google ScholarCross Ref"",""Nicholas Soures, David Chambers, Zachariah Carmichael, Anurag Daram, Dimpy P Shah, Kal Clark, Lloyd Potter, and Dhireesha Kudithipudi. 2020. SIRNet: Understanding Social Distancing Measures with Hybrid Neural Network Model for COVID-19 Infectious Spread. Technical Report. arXiv:2004.10376Google Scholar"",""Nicholas Soures, David Chambers, Zachariah Carmichael, Anurag Daram, Dimpy P. Shah, Kal Clark, Lloyd Potter, and Dhireesha Kudithipudi. 2020. SIRNet: Understanding Social Distancing Measures with Hybrid Neural Network Model for COVID-19 Infectious Spread.Google Scholar"",""M Vollmer, S Mishra, H Unwin, A Gandy, T Melan, V Bradley, H Zhu, H Coupland, I Hawryluk, M Hutchinson, et al. 2020. Report 20: A sub-national analysis of the rate of transmission of Covid-19 in Italy. (2020).Google Scholar"",""Michaela A C Vollmer, Swapnil Mishra, H Juliette T Unwin, Axel Gandy, et al. 2020. Report 20: Using mobility to estimate the transmission intensity of COVID-19 in Italy: A subnational analysis with future scenarios. Technical Report May. Imperial College COVID-19 Response Team. 35 pages.Google Scholar"",""World Health Organisation. 2020. a Coordinated Global Research Roadmap: 2019 Novel Coronavirus. Number March.Google Scholar"",""Zifeng Yang, Zhiqi Zeng, Ke Wang, Sook-San Wong, Wenhua Liang, Mark Zanin, Peng Liu, Xudong Cao, Zhongqiang Gao, Zhitong Mai, et al. 2020. Modified SEIR and AI prediction of the epidemics trend of COVID-19 in China under public health interventions. Journal of Thoracic Disease (2020).Google Scholar""]"
https://doi.org/10.1145/3394486.3412856,Understanding the Impact of the COVID-19 Pandemic on Transportation-related Behaviors with Human Mobility Data,"The constrained outbreak of COVID-19 in Mainland China has recently been regarded as a successful example of fighting this highly contagious virus. Both the short period (in about three months) of transmission and the sub-exponential increase of confirmed cases in Mainland China have proved that the Chinese authorities took effective epidemic prevention measures, such as case isolation, travel restrictions, closing recreational venues, and banning public gatherings. These measures can, of course, effectively control the spread of the COVID-19 pandemic. Meanwhile, they may dramatically change the human mobility patterns, such as the daily transportation-related behaviors of the public. To better understand the impact of COVID-19 on transportation-related behaviors and to provide more targeted anti-epidemic measures, we use the huge amount of human mobility data collected from Baidu Maps, a widely-used Web mapping service in China, to look into the detail reaction of the people there during the pandemic. To be specific, we conduct data-driven analysis on transportation-related behaviors during the pandemic from the perspectives of 1) means of transportation, 2) type of visited venues, 3) check-in time of venues, 4) preference on ""origin-destination'' distance, and 5) ""origin-transportation-destination'' patterns. For each topic, we also give our specific insights and policy-making suggestions. Given that the COVID-19 pandemic is still spreading in more than 200 overseas countries, infecting millions of people worldwide, the insights and suggestions provided here may help fight COVID-19.","[{""name"":""Jizhou Huang"",""id"":""/profile/99659140595""},{""name"":""Haifeng Wang"",""id"":""/profile/99659137977""},{""name"":""Miao Fan"",""id"":""/profile/81548359156""},{""name"":""An Zhuo"",""id"":""/profile/99659479819""},{""name"":""Yibo Sun"",""id"":""/profile/99659573469""},{""name"":""Ying Li"",""id"":""/profile/99659455657""},{""name"":""Jizhou Huang"",""id"":""/profile/99659140595""},{""name"":""Haifeng Wang"",""id"":""/profile/99659137977""},{""name"":""Miao Fan"",""id"":""/profile/81548359156""},{""name"":""An Zhuo"",""id"":""/profile/99659479819""},{""name"":""Yibo Sun"",""id"":""/profile/99659573469""},{""name"":""Ying Li"",""id"":""/profile/99659455657""}]","[""Matteo Chinazzi, Jessica T. Davis, Marco Ajelli, Corrado Gioannini, Maria Litvinova, Stefano Merler, Ana Pastore y Piontti, Kunpeng Mu, Luca Rossi, Kaiyuan Sun, Cécile Viboud, Xinyue Xiong, Hongjie Yu, M. Elizabeth Halloran, Ira M. Longini, and Alessandro Vespignani. 2020. The effect of travel restrictions on the spread of the 2019 novel coronavirus (COVID-19) outbreak. Science (2020). https://doi.org/10.1126/science.aba9757Google Scholar"",""David A. Drew, Long H. Nguyen, Claire J. Steves, Cristina Menni, Maxim Freydin, Thomas Varsavsky, Carole H. Sudre, M. Jorge Cardoso, Sebastien Ourselin, Jonathan Wolf, Tim D. Spector, and Andrew T. Chan. 2020. Rapid implementation of mobile technology for real-time epidemiology of COVID-19. Science, Vol. 368, 6497 (2020), 1362--1367. https://doi.org/10.1126/science.abc0473Google Scholar"",""Miao Fan, Jizhou Huang, An Zhuo, Ying Li, Ping Li, and Haifeng Wang. 2019. MONOPOLY: Learning to price public facilities for revaluing private properties with large-scale urban data. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management (Beijing, China) (CIKM 2019). Association for Computing Machinery, New York, NY, USA, 2655--2663. https://doi.org/10.1145/3357384.3357810Google ScholarDigital Library"",""Luca Ferretti, Chris Wymant, Michelle Kendall, Lele Zhao, Anel Nurtay, Lucie Abeler-Dörner, Michael Parker, David Bonsall, and Christophe Fraser. 2020. Quantifying SARS-CoV-2 transmission suggests epidemic control with digital contact tracing. Science (2020). https://doi.org/10.1126/science.abb6936Google Scholar"",""Jizhou Huang, Haifeng Wang, Miao Fan, An Zhuo, and Ying Li. 2020 a. Personalized prefix embedding for POI auto-completion in the search engine of Baidu Maps. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (Virtual Event, USA). https://doi.org/10.1145/3394486.3403318Google ScholarDigital Library"",""Jizhou Huang, Haifeng Wang, Haoyi Xiong, Miao Fan, An Zhuo, Ying Li, and Dejing Dou. 2020 b. Quantifying the economic impact of COVID-19 in Mainland China using human mobility data. arXiv preprint arXiv:2005.03010 (2020).Google Scholar"",""Stephen M. Kissler, Christine Tedijanto, Edward Goldstein, Yonatan H. Grad, and Marc Lipsitch. 2020. Projecting the transmission dynamics of SARS-CoV-2 through the postpandemic period. Science, Vol. 368, 6493 (2020), 860--868. https://doi.org/10.1126/science.abb5793Google Scholar"",""Moritz UG Kraemer, Chia-Hung Yang, Bernardo Gutierrez, Chieh-Hsi Wu, Brennan Klein, David M Pigott, Louis du Plessis, Nuno R Faria, Ruoran Li, William P Hanage, John S. Brownstein, Maylis Layan, Alessandro Vespignani, Huaiyu Tian, Christopher Dye, Oliver G. Pybus, and Samuel V. Scarpino. 2020. The effect of human mobility and control measures on the COVID-19 epidemic in China. Science (2020). https://doi.org/10.1126/science.abb4218Google Scholar"",""Ying Li, Jizhou Huang, Miao Fan, Jinyi Lei, Haifeng Wang, and Enhong Chen. 2020. Personalized query auto-completion for large-scale POI search at Baidu Maps. ACM Trans. Asian Low-Resour. Lang. Inf. Process., Vol. 19, 5, Article 70 (June 2020), 16 pages. https://doi.org/10.1145/3394137Google ScholarDigital Library"",""Yawen Li and Jong Gyu Park. 2019. Achieve a better shape of life: How entrepreneurship gears up life-time health. Academy of Management Proceedings, Vol. 2019, 1 (2019), 11834. https://doi.org/10.5465/AMBPP.2019.11834abstractGoogle ScholarCross Ref"",""Dianbo Liu, Leonardo Clemente, Canelle Poirier, Xiyu Ding, Matteo Chinazzi, Jessica T Davis, Alessandro Vespignani, and Mauricio Santillana. 2020. A machine learning methodology for real-time forecasting of the 2019-2020 COVID-19 outbreak using Internet searches, news alerts, and estimates from mechanistic models. arXiv preprint arXiv:2004.04019 (2020).Google Scholar"",""Xinjiang Lu, Zhiwen Yu, Leilei Sun, Chuanren Liu, Hui Xiong, and Chu Guan. 2016. Characterizing the life cycle of point of interests using human mobility patterns. In Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing. 1052--1063.Google ScholarDigital Library"",""Benjamin F. Maier and Dirk Brockmann. 2020. Effective containment explains subexponential growth in recent confirmed COVID-19 cases in China. Science (2020). https://doi.org/10.1126/science.abb4557Google Scholar"",""Anselmo Ramalho Pitombeira-Neto, Carlos Felipe Grangeiro Loureiro, and Luis Eduardo Carvalho. 2020. A dynamic hierarchical bayesian model for the estimation of day-to-day origin-destination flows in transportation networks. Networks and Spatial Economics (2020), 1--29.Google Scholar"",""Arni SR Srinivasa Rao and Jose A Vazquez. 2020. Identification of COVID-19 can be quicker through artificial intelligence framework using a mobile phone-based survey when cities and towns are under quarantine. Infection Control \u0026 Hospital Epidemiology (2020), 1--5.Google Scholar"",""Ahmet Riza Sahin, Aysegul Erdogan, Pelin Mutlu Agaoglu, Yeliz Dineri, Ahmet Yusuf Cakirci, Mahmut Egemen Senel, Ramazan Azim Okyay, and Ali Muhittin Tasdogan. 2020. 2019 novel coronavirus (COVID-19) outbreak: A review of the current literature. EJMO, Vol. 4, 1 (2020), 1--7.Google Scholar"",""Kate A Smith and Alan Ng. 2003. Web page clustering using a self-organizing map of user navigation patterns. Decision Support Systems, Vol. 35, 2 (2003), 245--256.Google ScholarDigital Library"",""Catrin Sohrabi, Zaid Alsafi, Niamh O'Neill, Mehdi Khan, Ahmed Kerwan, Ahmed Al-Jabir, Christos Iosifidis, and Riaz Agha. 2020. World Health Organization declares global emergency: A review of the 2019 novel coronavirus (COVID-19). International Journal of Surgery (London, England), Vol. 76 (Apr 2020), 71--76. https://doi.org/10.1016/j.ijsu.2020.02.034Google Scholar"",""Vital Surveillances. 2020. The epidemiological characteristics of an outbreak of 2019 novel coronavirus diseases (COVID-19)-China, 2020. China CDC Weekly, Vol. 2, 8 (2020), 113--122.Google ScholarCross Ref"",""Huaiyu Tian, Yonghong Liu, Yidan Li, Chieh-Hsi Wu, Bin Chen, Moritz U. G. Kraemer, Bingying Li, Jun Cai, Bo Xu, Qiqi Yang, Ben Wang, Peng Yang, Yujun Cui, Yimeng Song, Pai Zheng, Quanyi Wang, Ottar N. Bjornstad, Ruifu Yang, Bryan T. Grenfell, Oliver G. Pybus, and Christopher Dye. 2020. An investigation of transmission control measures during the first 50 days of the COVID-19 epidemic in China. Science (2020). https://doi.org/10.1126/science.abb6105Google Scholar"",""Huihui Wang, Xuemei Li, Tao Li, Shubing Zhang, Lianzi Wang, Xian Wu, and Jiaqing Liu. 2020. The genetic sequence, origin, and diagnosis of SARS-CoV-2. European Journal of Clinical Microbiology \u0026 Infectious Diseases (2020), 1.Google Scholar"",""Haoyi Xiong, Ji Liu, Jizhou Huang, Siyu Huang, Haozhe An, Qi Kang, Ying Li, Dejing Dou, and Haifeng Wang. 2020. Understanding the collective responses of populations to the COVID-19 pandemic in Mainland China. medRxiv (2020).Google Scholar""]"
https://doi.org/10.1145/3394486.3412859,Simulating the Impact of Hospital Capacity and Social Isolation to Minimize the Propagation of Infectious Diseases,"Infectious diseases can spread from an infected person to a susceptible person through direct or indirect physical contact, consequently controlling such types of spread is difficult. However, a proper decision at the initial stage can help control the disease's propagation before it turns into a pandemic. Social distancing and hospital capacity are considered among the most critical parameters to manage these types of conditions. In this paper, we used artificial agent-based simulation modeling to identify the importance of social distancing and hospitals' capacity in terms of the number of beds to shorten the length of an outbreak and reduce the total number of infections and deaths during an epidemic. After simulating the model based on different scenarios in a small artificial society, we learned that shorter social isolation activation delay has a higher impact on reducing the catastrophe. Increasing the hospital's treatment capacity, i.e., the number of isolation beds in the hospitals can become handy when social isolation cannot be activated shortly. The model can be considered a prototype to take proper steps based on the simulations on different parameter settings towards the control of an epidemic.","[{""name"":""Shaon Bhatta Shuvo"",""id"":""/profile/99659565818""},{""name"":""Bonaventure C. Molokwu"",""id"":""/profile/99659565424""},{""name"":""Ziad Kobti"",""id"":""/profile/81100327241""},{""name"":""Shaon Bhatta Shuvo"",""id"":""/profile/99659565818""},{""name"":""Bonaventure C. Molokwu"",""id"":""/profile/99659565424""},{""name"":""Ziad Kobti"",""id"":""/profile/81100327241""}]","[""Jürgen Hackl and Thibaut Dubernet. 2019. Epidemic Spreading in Urban Areas Using Agent-Based Transportation Models. Future Internet 11, 4 (2019), 92. DOI: https://doi.org/10.3390/fi11040092.Google ScholarCross Ref"",""William Ogilvy Kermack and Anderson Gray McKendrick. 1927. A contribution to the mathematical theory of epidemics. Proceedings of the Royal Society of London. Series A, Containing Papers of a Mathematical and Physical Character 115, 772 (August 1927), 700--721. DOI:http://dx.doi.org/10.1098/rspa.1927.0118Google Scholar"",""Elizabeth Sebastian and Priyanka Victor. 2018. An Approach to SIR Epi-demic Model using Markovian Retrial Queues. cm 2, 1 (2018), 89--96. DOI:https://doi.org/10.26524/jcm31Google Scholar"",""Jong-Shenq Guo, Amy Ai Ling Poh, and Masahiko Shimojo. 2019. The spread-ing speed of an SIR epidemic model with nonlocal dispersal. ASY (2019), 1--12. DOIhttps://doi.org/10.3233/asy-191584Google Scholar"",""Luciano Misici and Filippo Santarelli. 2013. Epidemic Propagation: An Automaton Model as the Continuous SIR Model. AM 04, 10 (2013), 84--89. DOI: https://doi.org/10.4236/am.2013.410a3011Google ScholarCross Ref"",""Min Zhu, Xiaofei Guo, and Zhigui Lin. 2017. The risk index for an SIR epidemic model and spatial spreading of the infectious disease. MBE 14, 5/6 (2017), 1565--1583. DOI: https://doi.org/10.3934/mbe.2017081Google ScholarCross Ref"",""Peter R. Odell. 1983. Book review: Bailey, N.T.J. 1975: The mathematical theory of infectious diseases and its application. London: Griffin. Progress in Human Geography 7, 3 (1983), 442--444. DOI:https://doi.org/10.1177/030913258300700313Google Scholar"",""A. Grabowski and R. Kosiński. 2008. The SIRS Model of Epidemic Spreading in Virtual Society. Acta Phys. Pol. A 114, 3 (September 2008), 589--596. DOI:https://doi.org/10.12693/aphyspola.114.589Google ScholarCross Ref"",""Alison Gray, Xuerong Mao, Daqing Jiang, and Yanan Zhao. 2015. The threshold of a stochastic SIRS epidemic model in a population with varying size. DCDS-B20, 4 (2015), 1277--1295. DOI: https://doi.org/10.3934/dcdsb.2015.20.1277Google Scholar"",""Enrique Frias-Martinez, Graham Williamson, and Vanessa Frias-Martinez. 2011.An Agent-Based Model of Epidemic Spread Using Human Mobility and Social Network Information. (2011). DOI: https://doi.org/10.1109/passat/socialcom.2011.142Google Scholar"",""Alberto d'Onofrio. 2005. On pulse vaccination strategy in the SIR epidemic model with vertical transmission. Applied Mathematics Letters 18, 7 (2005), 729--732. DOI: https://doi.org/10.1016/j.aml.2004.05.012Google ScholarCross Ref"",""Xinzhu Meng and Lansun Chen. 2008. The dynamics of a new SIR epidemic model concerning pulse vaccination strategy. Applied Mathematics and Computation 197, 2 (2008), 582--597. DOI:https://doi.org/10.1016/j.amc.2007.07.083Google ScholarCross Ref"",""Russell Connell, Peter Dawson, and Alex Dawson. 2009. Comparison of an Agent-Based Model of Disease Propagation with the Generalised SIR Epidemic Model. DSTO-TR-23 (2009), 1--22.Google Scholar"",""Özgür Özmen, James J Nutaro, Laura L Pullum, and Arvind Ramanathan.2016. Analyzing the impact of modeling choices and assumptions in compartmental epidemiological models. SIMULATION 92, 5 (2016), 459--472. DOI:https://doi.org/10.1177/0037549716640877Google ScholarDigital Library"",""Meike Will, Jürgen Groeneveld, Karin Frank, and Birgit Müller. 2020. Combining social network analysis and agent-based modelling to explore dynamics of human interaction: A review. SESMO 2, (March 2020), 16325. DOI: https://doi.org/10.18174/sesmo.2020a16325Google Scholar"",""Srinivasan Venkatramanan, Bryan Lewis, Jiangzhuo Chen, Dave Higdon, AnilVullikanti, and Madhav Marathe. 2018. Using data-driven agent-based models for forecasting emerging infectious diseases. 22, (January 2018), 43--49. DOI: https://doi.org/10.1016/j.epidem.2017.02.010Google Scholar"",""Duygu Balcan, Bruno Gonçalves, Hao Hu, José J. Ramasco, Vittoria Colizza, and Alessandro Vespignani. 2010. Modeling the spatial spread of infectious diseases: The Global Epidemic and Mobility computational model. Journal of Computational Science 1, 3 (2010), 132--145. DOI: https://doi.org/10.1016/j.jocs.2010.07.002Google ScholarCross Ref"",""Marco Ajelli, Bruno Gonçalves, Duygu Balcan, Vittoria Colizza, Hao Hu, José J Ramasco, Stefano Merler, and Alessandro Vespignani. 2010. Comparing large-scale computational approaches to epidemic modeling: Agent-based versus structured metapopulation models. BMC Infect Dis 10, 1 (2010). DOI: https://doi.org/10.1186/1471-2334-10-190Google Scholar"",""S. Waqar Jaffry and Jan Treur. 2008. Agent-Based And Population-BasedSimulation: A Comparative Case Study For Epidemics. (June 2008). DOI: https://doi.org/10.7148/2008-0123Google Scholar"",""Michael J North, Nicholson T Collier, Jonathan Ozik, Eric R Tatara, Charles M Macal, Mark Bragen, and Pam Sydelko. 2013. Complex adaptive systems modeling with Repast Simphony. Complex Adapt Syst Model 1, 1 (2013). DOI: https://doi.org/10.1186/2194-3206-1-3Google Scholar""]"
https://doi.org/10.1145/3394486.3412861,Effective Transfer Learning for Identifying Similar Questions: Matching User Questions to COVID-19 FAQs,"People increasingly search online for answers to their medical questions but the rate at which medical questions are asked online significantly exceeds the capacity of qualified people to answer them. This leaves many questions unanswered or inadequately answered. Many of these questions are not unique, and reliable identification of similar questions would enable more efficient and effective question answering schema. COVID-19 has only exacerbated this problem. Almost every government agency and healthcare organization has tried to meet the informational need of users by building online FAQs, but there is no way for people to ask their question and know if it is answered on one of these pages. While many research efforts have focused on the problem of general question similarity, these approaches do not generalize well to domains that require expert knowledge to determine semantic similarity, such as the medical domain. In this paper, we show how a double fine-tuning approach of pretraining a neural network on medical question-answer pairs followed by fine-tuning on medical question-question pairs is a particularly useful intermediate task for the ultimate goal of determining medical question similarity. While other pretraining tasks yield an accuracy below 78.7% on this task, our model achieves an accuracy of 82.6% with the same number of training examples, an accuracy of 80.0% with a much smaller training set, and an accuracy of 84.5% when the full corpus of medical question-answer data is used. We also describe a currently live system that uses the trained model to match user questions to COVID-related FAQs.","[{""name"":""Clara H. McCreery"",""id"":""/profile/99659573832""},{""name"":""Namit Katariya"",""id"":""/profile/81556286956""},{""name"":""Anitha Kannan"",""id"":""/profile/99659574130""},{""name"":""Manish Chablani"",""id"":""/profile/99659573772""},{""name"":""Xavier Amatriain"",""id"":""/profile/81548022860""},{""name"":""Clara H. McCreery"",""id"":""/profile/99659573832""},{""name"":""Namit Katariya"",""id"":""/profile/81556286956""},{""name"":""Anitha Kannan"",""id"":""/profile/99659574130""},{""name"":""Manish Chablani"",""id"":""/profile/99659573772""},{""name"":""Xavier Amatriain"",""id"":""/profile/81548022860""}]","[""2009. The Social Life of Health Information. https://www.pewresearch.org/ internet/2009/06/11/a-shifting-landscape/#fn-536-8Google Scholar"",""2019. Dr Google will see you now: Search giant wants to cash in on your medical queries. https://www.telegraph.co.uk/technology/2019/03/10/google-siftingone-billion-health-questions-dayGoogle Scholar"",""Asma Ben Abacha and Dina Demner-Fushman. 2016. Recognizing Question Entailment for Medical Question Answering.Google Scholar"",""Asma Ben Abacha and Dina Demner-Fushman. 2019. A Question-Entailment Approach to Question Answering. arxiv: cs.CL/1901.08079Google Scholar"",""AIcrowd. 2019. MEDIQA 2019 - Recognizing Question Entailment (RQE). https://www.aicrowd.com/challenges/mediqa-2019-recognizing-question-entailment-rqeGoogle Scholar"",""Iz Beltagy, Kyle Lo, and Arman Cohan. 2019. SciBERT: Pretrained Contextualized Embeddings for Scientific Text. arxiv: cs.CL/1903.10676Google Scholar"",""Dasha Bogdanova, C'icero dos Santos, Luciano Barbosa, and Bianca Zadrozny. 2015. Detecting Semantically Equivalent Questions in Online User Forums. In Proceedings of the Nineteenth Conference on Computational Natural Language Learning. Association for Computational Linguistics, Beijing, China, 123--131. https://doi.org/10.18653/v1/K15-1013Google ScholarCross Ref"",""Li Cai, Guangyou Zhou, Kang Liu, and Jun Zhao. 2011. Learning the latent topics for question retrieval in community qa. In Proceedings of 5th International Joint Conference on Natural Language Processing.Google Scholar"",""Yllias Chali and Rafat Islam. 2018. Question-Question Similarity in Online Forums. In Proceedings of the 10th Annual Meeting of the Forum for Information Retrieval Evaluation (FIRE'18). Association for Computing Machinery, 21--28.Google ScholarDigital Library"",""Kornel Csernai. 2017. Quora. https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-PairsGoogle Scholar"",""Arpita Das, Harish Yenala, Manoj Chinnakotla, and Manish Shrivastava. 2016. Together we stand: Siamese Networks for Similar Question Retrieval. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Association for Computational Linguistics, Berlin, Germany, 378--387.Google ScholarCross Ref"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arxiv: cs.CL/1810.04805Google Scholar"",""durakkerem. 2018. Medical Question Answer Datasets. https://github.com/durakkerem/Medical-Question-Answer-DatasetsGoogle Scholar"",""Kexin Huang, Jaan Altosaar, and Rajesh Ranganath. 2019. ClinicalBERT: Modeling Clinical Notes and Predicting Hospital Readmission. arxiv: cs.CL/1904.05342Google Scholar"",""Jiwoon Jeon, W. Croft, and Joon Lee. 2005. Finding similar questions in large question and answer archives. International Conference on Information and Knowledge Management, Proceedings, 84--90.Google ScholarDigital Library"",""Zongcheng Ji, Fei Xu, Bin Wang, and Ben He. 2012. Question-Answer Topic Model for Question Retrieval in Community Question Answering. In Proceedings of the 21st ACM International Conference on Information and Knowledge Management. Association for Computing Machinery, 2471--2474.Google ScholarDigital Library"",""Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So, and Jaewoo Kang. 2019. BioBERT: a pre-trained biomedical language representation model for biomedical text mining. arxiv: cs.CL/1901.08746Google Scholar"",""Tao Lei, Hrishikesh Joshi, Regina Barzilay, Tommi Jaakkola, Kateryna Tymoshenko, Alessandro Moschitti, and Lluís Màrquez. 2016. Semi-supervised Question Retrieval with Gated Convolutions. Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (2016). https://doi.org/10.18653/v1/n16-1153Google ScholarCross Ref"",""Yaliang Li, Liuyi Yao, Nan Du, Jing Gao, Qi Li, Chuishi Meng, Chenwei Zhang, and Wei Fan. 2018. Finding Similar Medical Questions from Question Answering Websites. arxiv: cs.AI/1810.05983Google Scholar"",""Xiaodong Liu, Pengcheng He, Weizhu Chen, and Jianfeng Gao. 2019. Multi-Task Deep Neural Networks for Natural Language Understanding. Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (2019). https://doi.org/10.18653/v1/p19-1441Google ScholarCross Ref"",""Lasse Regin Nielsen. 2017. Medical Question Answer Data. https://github.com/LasseRegin/medical-question-answer-dataGoogle Scholar"",""Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. Deep Contextualized Word Representations. https://doi.org/10.18653/v1/n18--1202Google Scholar"",""Jason Phang, Thibault Févry, and Samuel R. Bowman. 2018. Sentence Encoders on STILTs: Supplementary Training on Intermediate Labeled-data Tasks. arxiv: cs.CL/1811.01088Google Scholar"",""Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners. OpenAI Blog (2019).Google Scholar"",""Alexander Ratner, Stephen H. Bach, Henry Ehrenberg, Jason Fries, Sen Wu, and Christopher Ré. 2017. Snorkel. https://doi.org/10.14778/3157794.3157797Google Scholar"",""Alon Talmor and Jonathan Berant. 2019. MultiQA: An Empirical Investigation of Generalization and Transfer in Reading Comprehension. arxiv: cs.CL/1905.13453Google Scholar"",""Xiaobing Xue, Jiwoon Jeon, and W. Bruce Croft. 2008. Retrieval Models for Question and Answer Archives. In Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. Association for Computing Machinery, New York, NY, USA, 475--482.Google Scholar"",""Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, and Quoc V. Le. 2019. XLNet: Generalized Autoregressive Pretraining for Language Understanding. arxiv: cs.CL/1906.08237Google Scholar"",""Kai Zhang, Wei Wu, Haocheng Wu, Zhoujun Li, and Ming Zhou. 2014. Question Retrieval with High Quality Answers in Community Question Answering. In Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management. Association for Computing Machinery, 371--380.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3412864,Hi-COVIDNet: Deep Learning Approach to Predict Inbound COVID-19 Patients and Case Study in South Korea,"The escalating crisis of COVID-19 has put people all over the world in danger. Owing to the high contagion rate of the virus, COVID-19 cases continue to increase globally. To further suppress the threat of the COVID-19 pandemic and minimize its damage, it is imperative that each country monitors inbound travelers. Moreover, given that resources for quarantine are often limited, they must be carefully allocated. In this paper, to aid in such allocation by predicting the number of inbound COVID-19 cases, we propose Hi-COVIDNet, which takes advantage of the geographic hierarchy. Hi-COVIDNet is based on a neural network with two-level components, namely, country-level and continent-level encoders, which understand the complex relationships among foreign countries and derive their respective contagion risk to the destination country. An in-depth case study in South Korea with real-world COVID-19 datasets confirmed the effectiveness and practicality of Hi-COVIDNet.","[{""name"":""Minseok Kim"",""id"":""/profile/99659537007""},{""name"":""Junhyeok Kang"",""id"":""/profile/99659574601""},{""name"":""Doyoung Kim"",""id"":""/profile/99659573628""},{""name"":""Hwanjun Song"",""id"":""/profile/99659193503""},{""name"":""Hyangsuk Min"",""id"":""/profile/99659573847""},{""name"":""Youngeun Nam"",""id"":""/profile/99659572957""},{""name"":""Dongmin Park"",""id"":""/profile/99659536721""},{""name"":""Jae-Gil Lee"",""id"":""/profile/81351605693""},{""name"":""Minseok Kim"",""id"":""/profile/99659537007""},{""name"":""Junhyeok Kang"",""id"":""/profile/99659574601""},{""name"":""Doyoung Kim"",""id"":""/profile/99659573628""},{""name"":""Hwanjun Song"",""id"":""/profile/99659193503""},{""name"":""Hyangsuk Min"",""id"":""/profile/99659573847""},{""name"":""Youngeun Nam"",""id"":""/profile/99659572957""},{""name"":""Dongmin Park"",""id"":""/profile/99659536721""},{""name"":""Jae-Gil Lee"",""id"":""/profile/81351605693""}]","[""Benvenuto, D., Giovanetti, M., Vassallo, L., Angeletti, S., and Ciccozzi, M. Application of the ARIMA model on the COVID-2019 epidemic dataset. Data in Brief (2020), 105340.Google Scholar"",""Breiman, L. Random forests. Machine Learning 45, 1 (2001), 5--32.Google ScholarDigital Library"",""Chimmula, V. K. R., and Zhang, L. Time series forecasting of COVID-19 transmission in Canada using LS™ networks. Chaos, Solitons \u0026 Fractals (2020), 109864.Google Scholar"",""Contreras, J., Espinola, R., Nogales, F. J., and Conejo, A. J. ARIMA models to predict next-day electricity prices. IEEE Transactions on Power Systems 18, 3 (2003), 1014--1020.Google ScholarCross Ref"",""Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L. ImageNet: A large-scale hierarchical image database. In Proceedings of 2009 IEEE Conference on Computer Vision and Pattern Recognition (2009), pp. 248--255.Google ScholarCross Ref"",""Domany, E., van Hemmen, J. L., and Schulten, K. Models of neural networks III: Association, generalization, and representation. Springer, 1996.Google ScholarCross Ref"",""Hamer, W. B., Birr, T., Verreet, J.-A., Duttmann, R., and Klink, H. Spatio-temporal prediction of the epidemic spread of dangerous pathogens using machine learning methods. ISPRS International Journal of Geo-Information 9, 1 (2020), 44.Google ScholarCross Ref"",""Hochreiter, S., and Schmidhuber, J. Long short-term memory. Neural Computation 9, 8 (1997), 1735--1780.Google ScholarDigital Library"",""Ioffe, S., and Szegedy, C. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167 (2015).Google Scholar"",""Kingma, D. P., and Ba, J. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).Google Scholar"",""Krogh, A., and Hertz, J. A. A simple weight decay can improve generalization. In Proceedings of Advances in Neural Information Processing Systems (1992), pp. 950--957.Google Scholar"",""Kucharski, A. J., Russell, T. W., Diamond, C., Liu, Y., Edmunds, J., Funk, S., Eggo, R. M., Sun, F., Jit, M., Munday, J. D., et al. Early dynamics of transmission and control of COVID-19: A mathematical modelling study. The Lancet Infectious Diseases (2020).Google Scholar"",""LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P. Gradient-based learning applied to document recognition. Proceedings of the IEEE 86, 11 (1998), 2278--2324.Google ScholarCross Ref"",""Li, Y., Liang, M., Yin, X., Liu, X., Hao, M., Hu, Z., Wang, Y., and Jin, L. COVID-19 epidemic outside China: 34 founders and exponential growth. medRxiv (2020).Google Scholar"",""Litjens, G., Kooi, T., Bejnordi, B. E., Setio, A. A. A., Ciompi, F., Ghafoorian, M., Van Der Laak, J. A., Van Ginneken, B., and Sánchez, C. I. A survey on deep learning in medical image analysis. Medical Image Analysis 42 (2017), 60--88.Google ScholarCross Ref"",""Machado, G., Vilalta, C., Recamonde-Mendoza, M., Corzo, C., Torremorell, M., Perez, A., and VanderWaal, K. Identifying outbreaks of Porcine Epidemic Diarrhea virus through animal movements and spatial neighborhoods. Scientific Reports 9, 1 (2019), 1--12.Google ScholarCross Ref"",""McCann, B., Keskar, N. S., Xiong, C., and Socher, R. The natural language decathlon: Multitask learning as question answering. arXiv preprint arXiv:1806.08730 (2018).Google Scholar"",""McNeil, D. G. Coronavirus has become a pandemic, W.H.O. says. https://www.nytimes.com/2020/03/11/health/coronavirus-pandemic-who.html.Google Scholar"",""Mussumeci, E., and Coelho, F. C. Machine-learning forecasting for Dengue epidemics - Comparing LS™, random forest and lasso regression. medRxiv (2020).Google Scholar"",""Pal, R., Sekh, A. A., Kar, S., and Prasad, D. K. Neural network based country wise risk prediction of COVID-19. arXiv preprint arXiv:2004.00959 (2020).Google Scholar"",""Park, S. N. Cults and conservatives spread coronavirus in South Korea. https://foreignpolicy.com/2020/02/27/coronavirus-south-korea-cults-conservatives-china/.Google Scholar"",""Philemon, M. D., Ismail, Z., and Dare, J. A review of epidemic forecasting using artificial neural networks. International Journal of Epidemiologic Research 6, 3 (2019), 132--143.Google Scholar"",""Punn, N. S., Sonbhadra, S. K., and Agarwal, S. COVID-19 epidemic analysis using machine learning and deep learning algorithms. medRxiv (2020).Google Scholar"",""Shu, J., Xie, Q., Yi, L., Zhao, Q., Zhou, S., Xu, Z., and Meng, D. Meta-weight-net: Learning an explicit mapping for sample weighting. In Proceedings of Advances in Neural Information Processing Systems (2019), pp. 1917--1928.Google Scholar"",""Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. Dropout: A simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research 15, 1 (2014), 1929--1958.Google ScholarDigital Library"",""Uhlig, S., Nichani, K., Uhlig, C., and Simon, K. Modeling projections for COVID-19 pandemic by combining epidemiological, statistical, and neural network approaches. medRxiv (2020).Google Scholar"",""Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., and Polosukhin, I. Attention is all you need. In Proceedings of Advances in Neural Information Processing Systems (2017), pp. 5998--6008.Google Scholar"",""Wu, Y., Yang, Y., Nishiura, H., and Saitoh, M. Deep learning for epidemiological predictions. In Proceedings of 41st International ACM SIGIR Conference on Research and Development in Information Retrieval (2018), pp. 1085--1088.Google ScholarDigital Library"",""Yang, Z., Zeng, Z., Wang, K., Wong, S.-S., Liang, W., Zanin, M., Liu, P., Cao, X., Gao, Z., Mai, Z., et al. Modified SEIR and AI prediction of the epidemics trend of COVID-19 in China under public health interventions. Journal of Thoracic Disease 12, 3 (2020), 165.Google ScholarCross Ref"",""Zhai, P., Ding, Y., Wu, X., Long, J., Zhong, Y., and Li, Y. The epidemiology, diagnosis and treatment of COVID-19. International Journal of Antimicrobial Agents (2020), 105955.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3412865,Exploring Automatic Diagnosis of COVID-19 from Crowdsourced Respiratory Sound Data,"Audio signals generated by the human body (e.g., sighs, breathing, heart, digestion, vibration sounds) have routinely been used by clinicians as indicators to diagnose disease or assess disease progression. Until recently, such signals were usually collected through manual auscultation at scheduled visits. Research has now started to use digital technology to gather bodily sounds (e.g., from digital stethoscopes) for cardiovascular or respiratory examination, which could then be used for automatic analysis. Some initial work shows promise in detecting diagnostic signals of COVID-19 from voice and coughs. In this paper we describe our data analysis over a large-scale crowdsourced dataset of respiratory sounds collected to aid diagnosis of COVID-19. We use coughs and breathing to understand how discernible COVID-19 sounds are from those in asthma or healthy controls. Our results show that even a simple binary machine learning classifier is able to classify correctly healthy and COVID-19 sounds. We also show how we distinguish a user who tested positive for COVID-19 and has a cough from a healthy user with a cough, and users who tested positive for COVID-19 and have a cough from users with asthma and a cough. Our models achieve an AUC of above 80% across all tasks. These results are preliminary and only scratch the surface of the potential of this type of data and audio-based machine learning. This work opens the door to further investigation of how automatically analysed respiratory patterns could be used as pre-screening signals to aid COVID-19 diagnosis.","[{""name"":""Chloë Brown"",""id"":""/profile/81508694007""},{""name"":""Jagmohan Chauhan"",""id"":""/profile/81502763711""},{""name"":""Andreas Grammenos"",""id"":""/profile/99659254992""},{""name"":""Jing Han"",""id"":""/profile/99659574670""},{""name"":""Apinan Hasthanasombat"",""id"":""/profile/99659369284""},{""name"":""Dimitris Spathis"",""id"":""/profile/99658747701""},{""name"":""Tong Xia"",""id"":""/profile/99659574377""},{""name"":""Pietro Cicuta"",""id"":""/profile/99659573198""},{""name"":""Cecilia Mascolo"",""id"":""/profile/81100495716""},{""name"":""Chloë Brown"",""id"":""/profile/81508694007""},{""name"":""Jagmohan Chauhan"",""id"":""/profile/81502763711""},{""name"":""Andreas Grammenos"",""id"":""/profile/99659254992""},{""name"":""Jing Han"",""id"":""/profile/99659574670""},{""name"":""Apinan Hasthanasombat"",""id"":""/profile/99659369284""},{""name"":""Dimitris Spathis"",""id"":""/profile/99658747701""},{""name"":""Tong Xia"",""id"":""/profile/99659574377""},{""name"":""Pietro Cicuta"",""id"":""/profile/99659573198""},{""name"":""Cecilia Mascolo"",""id"":""/profile/81100495716""}]","[""2019. librosa.feature.delta. https://librosa.github.io/librosa/generated/librosa. feature.delta.html, note= Accessed: 2020-05-30.Google Scholar"",""2020. coughvid. https://coughvid.epfl.ch/about/, note= Accessed: 2020-05-30.Google Scholar"",""2020. Detect Now. https://detectnow.org/, note= Accessed: 2020-05-30.Google Scholar"",""Charles Bales, Muhammad Nabeel, Charles N. John, Usama Masood, Haneya N. Qureshi, Hasan Farooq, Iryna Posokhova, and Ali Imran. 2020. Can machine learning be used to recognize and diagnose coughs?arxiv: 2004.01495 [eess.AS] 10 pages.Google Scholar"",""Debrup Banerjee, Kazi Islam, Keyi Xue, Gang Mei, Lemin Xiao, Guangfan Zhang, Roger Xu, Cai Lei, Shuiwang Ji, and Jiang Li. 2019. A deep transfer learning approach for improved post-traumatic stress disorder diagnosis. Knowledge and Information Systems, Vol. 60, 3 (2019), 1693--1724.Google ScholarCross Ref"",""L Brabenec, J Mekyska, Z Galaz, and Irena Rektorova. 2017. Speech disorders in Parkinson's disease: Early diagnostics and effects of medication and brain stimulation. Journal of Neural Transmission, Vol. 124, 3 (2017), 303--334.Google ScholarCross Ref"",""Gavin C Cawley and Nicola LC Talbot. 2010. On over-fitting in model selection and subsequent selection bias in performance evaluation. Journal of Machine Learning Research, Vol. 11 (2010), 2079--2107.Google ScholarDigital Library"",""Yohan Chon, Nicholas D. Lane, Fan Li, Hojung Cha, and Feng Zhao. 2012. Automatically characterizing places with opportunistic crowdsensing using smartphones. In Proceedings of the ACM Conference on Ubiquitous Computing (UbiComp). Pittsburgh, Pennsylvania, 481--490.Google ScholarDigital Library"",""Steven Davis and Paul Mermelstein. 1980. Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences. IEEE Transactions on Acoustics, Speech, and Signal Processing, Vol. 28, 4 (1980), 357--366.Google ScholarCross Ref"",""Gauri Deshpande and Björn Schuller. 2020. An overview on audio, signal, speech, \u0026 language processing for COVID-19. arXiv preprint arXiv:2005.08579 (2020). 5 pages.Google Scholar"",""Daniel PW Ellis. 2007. Beat tracking by dynamic programming. Journal of New Music Research, Vol. 36, 1 (2007), 51--60.Google ScholarCross Ref"",""Betul Erdogdu Sakar, Gorkem Serbes, and C. Okan Sakar. 2017. Analyzing the effectiveness of vocal features in early telediagnosis of Parkinson's disease. PloS One, Vol. 12, 8 (Aug. 2017), 1--18. https://doi.org/10.1371/journal.pone.0182428Google Scholar"",""Maria Faurholt-Jepsen, Jonas Busk, Mads Frost, Maj Vinberg, Ellen M Christensen, Ole Winther, Jakob Eyvind Bardram, and Lars V Kessing. 2016. Voice analysis as an objective state marker in bipolar disorder. Translational Psychiatry, Vol. 6, 7 (2016), e856. 8 pages.Google ScholarCross Ref"",""Jing Han, Kun Qian, Meishu Song, Zijiang Yang, Zhao Ren, Shuo Liu, Juan Liu, Huaiyuan Zheng, Wei Ji, Tomoya Koike, Xiao Li, Zixing Zhang, Yoshiharu Yamamoto, and Björn Schuller. 2020. An early study on intelligent analysis of speech under COVID-19: Severity, sleep Quality, fatigue, and anxiety. arxiv: 2005.00096 [eess.AS] 5 pages.Google Scholar"",""S. Hershey, S. Chaudhuri, D. P. W. Ellis, J. F. Gemmeke, A. Jansen, R. C. Moore, M. Plakal, D. Platt, R. A. Saurous, B. Seybold , M. Slaney, R. J. Weiss, and K. Wilson. 2017. CNN architectures for large-scale audio classification. In Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). 131--135.Google Scholar"",""Yinghui Huang, Sijun Meng, Yi Zhang, et almbox. 2020. The respiratory sound features of COVID-19 patients fill gaps between clinical data and screening methods. medRxiv (2020). https://doi.org/10.1101/2020.04.07.20051060 12 pages.Google Scholar"",""Ali Imran, Iryna Posokhova, Haneya N. Qureshi, Usama Masood, Sajid Riaz, Kamran Ali, Charles N. John, Muhammad Nabeel, and Iftikhar Hussain. 2020. AI4COVID-19: AI enabled preliminary diagnosis for COVID-19 from cough samples via an App. arxiv: 2004.01275 [eess.AS] 11 pages.Google Scholar"",""Shih-Hong Li, Bor-Shing Lin, Chen-Han Tsai, Cheng-Ta Yang, and Bor-Shyh Lin. 2017. Design of wearable breathing sound monitoring system for real-time wheeze detection. Sensors, Vol. 17, 1 (Jan. 2017), 1--15.Google ScholarCross Ref"",""Elad Maor, Jaskanwal D Sara, Diana M Orbelo, Lilach O Lerman, Yoram Levanon, and Amir Lerman. 2018. Voice signal characteristics are independently associated with coronary artery disease. Mayo Clinic Proceedings, Vol. 93, 7 (2018), 840--847.Google ScholarCross Ref"",""Brian McFee, Colin Raffel, Dawen Liang, Daniel PW Ellis, Matt McVicar, Eric Battenberg, and Oriol Nieto. 2015. librosa: Audio and music signal analysis in python. In Proceedings of the 14th Python in Science Conference. Austin, TX, 18--24.Google ScholarCross Ref"",""Cristina Menni, Ana M Valdes, Maxim B Freidin, et almbox. 2020. Real-time tracking of self-reported symptoms to predict potential COVID-19. Nature Medicine, Vol. 10, 1038 (May 2020). 8 pages.Google Scholar"",""Rajalakshmi Nandakumar, Shyamnath Gollakota, and Nathaniel Watson. 2015. Contactless sleep apnea detection on smartphones. In Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services (MobiSys). Florence, Italy, 45--57.Google ScholarDigital Library"",""Dinko Oletic and Vedran Bilas. 2016. Energy-efficient respiratory sounds sensing for personal mobile asthma monitoring. IEEE Sensors Journal, Vol. 16, 23 (Dec. 2016), 8295--8303.Google Scholar"",""Renard Xaviero Adhi Pramono, Stuart Bowyer, and Esther Rodriguez-Villegas. 2017. Automatic adventitious respiratory sound analysis: A systematic review. PloS One, Vol. 12, 5 (May 2017). https://doi.org/10.1371/journal.pone.0177926 43 pages.Google Scholar"",""Renard Xaviero Adhi Pramono, Syed Anas Imtiaz, and Esther Rodriguez-Villegas. 2016. A cough-based algorithm for automatic diagnosis of pertussis. PloS One, Vol. 11, 9 (Sep. 2016). 20 pages.Google Scholar"",""Thomas Quatieri, Tanya Talkar, and Jeffrey Palmer. 2020. A Framework for Biomarkers of COVID-19 Based on Coordination of Speech-Production Subsystems. IEEE Open Journal of Engineering in Medicine and Biology (2020).Google Scholar"",""Kiran K Rachuri, Mirco Musolesi, Cecilia Mascolo, Peter J Rentfrow, Chris Longworth, and Andrius Aucinas. 2010. EmotionSense: A mobile phones based adaptive platform for experimental social psychology research. In Proceedings of the ACM Conference on Ubiquitous Computing (UbiComp). Copenhagen, Denmark, 281--290.Google ScholarDigital Library"",""Jan Schlüter and Thomas Grill. 2015. Exploring data augmentation for improved singing voice detection with neural networks. In Proceedings of the 16th International Society for Music Information Retrieval Conference (ISMIR). Malaga, Spain, 121--126.Google Scholar"",""Neeraj Sharma, Prashant Krishnan, Rohit Kumar, Shreyas Ramoji, Srikanth Raj Chetupalli, Nirmala R., Prasanta Kumar Ghosh, and Sriram Ganapathy. 2020. Coswara -- A database of breathing, cough, and voice sounds for COVID-19 diagnosis. arxiv: 2005.10548 [eess.AS] 5 pages.Google Scholar"",""Marc Weber Tobias. 2020. AI And Medical Diagnostics: Can A Smartphone App Detect Covid-19 From Speech Or A Cough? https://www.forbes.com/sites/marcwebertobias/2020/05/05/ai-and-medical-diagnostics-can-a-smartphone-app-detect-covid-19-from-speech-or-a-cough/ note=Accessed: 2020-07-16 .Google Scholar""]"
https://doi.org/10.1145/3394486.3412860,Understanding the Urban Pandemic Spreading of COVID-19 with Real World Mobility Data,"Facing the worldwide rapid spreading of COVID-19 pandemic, we need to understand its diffusion in the urban environments with heterogeneous population distribution and mobility. However, challenges exist in the choice of proper spatial resolution, integration of mobility data into epidemic modelling, as well as incorporation of unique characteristics of COVID-19.To address these challenges, we build a data-driven epidemic simulator with COVID-19 specific features, which incorporates real-world mobility data capturing the heterogeneity in urban environments. Based on the simulator, we conduct two series of experiments to: (1) estimate the efficacy of different mobility control policies on intervening the epidemic; and (2) study how the heterogeneity of urban mobility affect the spreading process. Extensive results not only highlight the effectiveness of fine-grained targeted mobility control policies, but also uncover different levels of impact of population density and mobility strength on the spreading process. With such capability and demonstrations, our open simulator contributes to a better understanding of the complex spreading process and smarter policies to prevent another pandemic.","[{""name"":""Qianyue Hao"",""id"":""/profile/99659574397""},{""name"":""Lin Chen"",""id"":""/profile/99659481022""},{""name"":""Fengli Xu"",""id"":""/profile/99658756914""},{""name"":""Yong Li"",""id"":""/profile/81453640533""},{""name"":""Qianyue Hao"",""id"":""/profile/99659574397""},{""name"":""Lin Chen"",""id"":""/profile/99659481022""},{""name"":""Fengli Xu"",""id"":""/profile/99658756914""},{""name"":""Yong Li"",""id"":""/profile/81453640533""}]","[""Linda J S Allen. 2017. A primer on stochastic epidemic models: Formulation, numerical simulation, and analysis. Infectious Disease Modelling (2017).Google Scholar"",""Duygu Balcan, Vittoria Colizza, Bruno Goncalves, Hao Hu, Jose J Ramasco, and Alessandro Vespignani. 2009a. Multiscale mobility networks and the spatial spreading of infectious diseases. Proceedings of the National Academy of Sciences of the United States of America (2009).Google ScholarCross Ref"",""Duygu Balcan, Hu Hao, Bruno Goncalves, Paolo Bajardi, Chiara Poletto, Jose J Ramasco, Daniela Paolotti, Nicola Perra, Michele Tizzoni, and Van Den Wouter Broeck. 2009b. Seasonal transmission potential and activity peaks of the new influenza A(H1N1): a Monte Carlo likelihood analysis based on human mobility. (2009).Google Scholar"",""Christopher L. Barrett, Keith R. Bisset, Stephen G. Eubank, Xizhou Feng, and Madhav V. Marathe. 2008. EpiSimdemics: An efficient algorithm for simulating the spread of infectious disease over large realistic social networks. In International Conference for High Performance Computing, Networking, Storage \u0026 Analysis.Google Scholar"",""Matteo Chinazzi, Jessica T Davis, Marco Ajelli, Corrado Gioannini, Maria Litvinova, Stefano Merler, Ana Pastore Y Piontti, Kunpeng Mu, Luca Rossi, Kaiyuan Sun, et almbox. 2020. The effect of travel restrictions on the spread of the 2019 novel coronavirus (COVID-19) outbreak. Science (2020).Google Scholar"",""Vittoria Colizza, Alain Barrat, Marc Barthelemy, and Alessandro Vespignani. 2006. The role of the airline transportation network in the prediction and predictability of global epidemics. Proceedings of the National Academy of Sciences of the United States of America (2006).Google ScholarCross Ref"",""S Eubank, H Guclu, Kumar Vsa, M. V. Marathe, A Srinivasan, and Z Toroczkai. 2004. Modelling disease outbreaks in realistic urban social networks. Nature (2004).Google Scholar"",""P. Giles. 1977. The Mathematical Theory of Infectious Diseases and Its Applications. Journal of the Operational Research Society (1977).Google Scholar"",""Joel Hellewell, Sam Abbott, Amy Gimma, Nikos I Bosse, Christopher I Jarvis, Timothy W Russell, James D Munday, Adam J Kucharski, W John Edmunds, Fiona Sun, Stefan Flasche, Billy J Quilty, Nicholas Davies, Yang Liu, Samuel Clifford, Petra Klepac, Mark Jit, Charlie Diamond, Hamish Gibbs, Kevin van Zandvoort, Sebastian Funk, and Rosalind M Eggo. 2020. Feasibility of controlling COVID-19 outbreaks by isolation of cases and contacts. The Lancet Global Health (2020).Google Scholar"",""W O Kermack and A G Mckendrick. 1927. A Contribution to the Mathematical Theory of Epidemics. Proceedings of The Royal Society A: Mathematical, Physical and Engineering Sciences (1927).Google Scholar"",""Moritz U G Kraemer, Chiahung Yang, Bernardo Gutierrez, Chiehhsi Wu, Brennan Klein, David M Pigott, Louis Du Plessis, Nuno Rodrigues Faria, Ruoran Li, William P Hanage, et almbox. 2020. The effect of human mobility and control measures on the COVID-19 epidemic in China. medRxiv (2020).Google Scholar"",""Fotios Petropoulos and Spyros Makridakis. 2020. Forecasting the novel coronavirus COVID-19. PLoS ONE (2020).Google Scholar"",""Filippo Simini, Marta C Gonzalez, Amos Maritan, and Albertlaszlo Barabasi. 2012. A universal model for mobility and migration patterns. Nature (2012).Google Scholar"",""Ashleigh R Tuite, Victoria Ng, Erin Rees, and David Fisman. 2020. Estimation of COVID-19 outbreak size in Italy. The Lancet Infectious Diseases (2020).Google Scholar"",""Van, Mieghem, Piet, Vespignani, Alessandro, Castellano, Claudio, Pastor-Satorras, and Romualdo. 2015. Epidemic processes in complex networks. Reviews of Modern Physics (2015).Google Scholar"",""Srinivasan Venkatramanan, Bryan Lewis, Jiangzhuo Chen, Dave Higdon, Anil Vullikanti, and Madhav Marathe. 2018. Using data-driven agent-based models for forecasting emerging infectious diseases. Epidemics (2018).Google Scholar"",""Yixuan Wang, Yuyi Wang, Yan Chen, and Qingsong Qin. 2020. Unique epidemiological and clinical features of the emerging 2019 novel coronavirus pneumonia (COVID-19) implicate special control measures. Journal of Medical Virology (2020).Google Scholar"",""Joseph T Wu, Kathy Leung, and Gabriel M Leung. 2020. Nowcasting and forecasting the potential domestic and international spread of the 2019-nCoV outbreak originating in Wuhan, China: a modelling study. The Lancet (2020).Google Scholar"",""Shi Zhao, Qianyin Lin, Jinjun Ran, Salihu S. Musa, Guangpu Yang, Weiming Wang, Yijun Lou, Daozhou Gao, Lin Yang, Daihai He, and Maggie H. Wang. 2020. Preliminary estimation of the basic reproduction number of novel coronavirus (2019-nCoV) in China, from 2019 to 2020: A data-driven analysis in the early phase of the outbreak. International Journal of Infectious Diseases (2020).Google Scholar""]"
https://doi.org/10.1145/3394486.3409586,"Fighting a Pandemic: Convergence of Expertise, Data Science and Policy",This panel will address the challenges and opportunities of using data science to fight a pandemic. Of particular interest are real-world cases where using data science helped the fight against the pandemic and cautionary tales of when it hindered that fight.,"[{""name"":""Tina Eliassi-Rad"",""id"":""/profile/81100597717""},{""name"":""Nitesh Chawla"",""id"":""/profile/81100002770""},{""name"":""Vittoria Colizza"",""id"":""/profile/99659574610""},{""name"":""Lauren Gardner"",""id"":""/profile/99659572995""},{""name"":""Marcel Salathé"",""id"":""/profile/81484657890""},{""name"":""Samuel Scarpino"",""id"":""/profile/99659574009""},{""name"":""Joseph T. Wu"",""id"":""/profile/99659575138""},{""name"":""Tina Eliassi-Rad"",""id"":""/profile/81100597717""},{""name"":""Nitesh Chawla"",""id"":""/profile/81100002770""},{""name"":""Vittoria Colizza"",""id"":""/profile/99659574610""},{""name"":""Lauren Gardner"",""id"":""/profile/99659572995""},{""name"":""Marcel Salathé"",""id"":""/profile/81484657890""},{""name"":""Samuel Scarpino"",""id"":""/profile/99659574009""},{""name"":""Joseph T. Wu"",""id"":""/profile/99659575138""}]",null
https://doi.org/10.1145/3394486.3406697,From Zero to AI Hero with Automated Machine Learning,"Automated ML is an emerging field in Machine Learning that helps developers and new data scientists with little data science knowledge build Machine Learning models and solutions without understanding the complexity of Learning Algorithm selection, and Hyper parameter tuning. With Azure Machine Learning's automated machine learning capability, given a dataset and a few configuration parameters, you will get a trained high quality machine learning model for the dataset that you can use for predictions. In this session, you will learn how to use Automated ML for productivity gains, empowering domain experts to build ML based solutions and scale to build several models with Azure Machine Learning's Automated ML.","[{""name"":""Aniththa Umamahesan"",""id"":""/profile/99659574445""},{""name"":""Deepak Mukunthu Iyappan Babu"",""id"":""/profile/99659574459""},{""name"":""Aniththa Umamahesan"",""id"":""/profile/99659574445""},{""name"":""Deepak Mukunthu Iyappan Babu"",""id"":""/profile/99659574459""}]","[""Learn more: https://aka.ms/automatedmldocsGoogle Scholar"",""Notebook Samples: https://aka.ms/automatedmlsamplesGoogle Scholar"",""Azure Machine Learning Studio: https://ml.azure.comGoogle Scholar"",""Blog Post: https://aka.ms/AutomatedMLGoogle Scholar""]"
https://doi.org/10.1145/3394486.3406698,Put Deep Learning to Work: Accelerate Deep Learning through Amazon SageMaker and ML Services,"Deploying deep learning (DL) projects are becoming increasingly more pervasive at enterprises and startups alike. At Amazon, Machine Learning University (MLU)-trained engineers are taking DL to every aspect of Amazon's businesses, beyond just Amazon Go, Alexa, and Robotics.In this workshop, Wenming Ye (AWS), Rachel Hu (AWS), and Miro Enev (Nvidia) offer a practical next step in DL learning with instructions, and hands-on labs using the latest Nvidia GPUs and AWS Inferentia. You will explore the current trends powering AI/DL adoption, powerful new GPU/AWS Inferentia accelerator instances, distributed training and inference optimization in neural networks.","[{""name"":""Wenming Ye"",""id"":""/profile/99659575203""},{""name"":""Rachel Hu"",""id"":""/profile/99659573242""},{""name"":""Miro Enev"",""id"":""/profile/81490693537""},{""name"":""Wenming Ye"",""id"":""/profile/99659575203""},{""name"":""Rachel Hu"",""id"":""/profile/99659573242""},{""name"":""Miro Enev"",""id"":""/profile/81490693537""}]",null
https://doi.org/10.1145/3394486.3406699,Building Forecasting Solutions Using Open-Source and Azure Machine Learning,"Time series forecasting is one of the most important topics in data science. Almost every business needs to predict the future in order to make better decisions and allocate resources more effectively. Examples of time series forecasting use cases are financial forecasting, demand forecasting in logistics for operational planning of assets, demand forecasting for Azure resources, and energy demand forecasting for campus buildings and data centers. The goal of this tutorial is to demonstrate state-of-the-art forecasting approaches to problems in retail and introduce a new repository focusing on best-practices in forecasting domain, along with a library of forecasting utilities [1].The tutorial will start with a quick overview of time series forecasting and traditional time series models to provide the audience with a clear background on the kind of problems that we aim to solve. We will also briefly explore the dataset to be used in all exercises.Next, we will run through several exercises to solve a forecasting problem in retail. We will start with a traditional statistical approach, e.g. ARIMA, using an auto-arima function in python [2]. Next, we will cover machine-learning based approaches to forecasting and cover various ways to featurize the time series dataset, then train a LightGBM model [6]. Finally, we will describe a deep-neural-net based approach, namely Dilated CNN, and train a Dilated CNN model on our data [7-8]. Using LightGBM and Dilated CNN - two efficient and state-of-the-art models, we can train the models quickly and achieve very high forecasting accuracies.In the last part of the tutorial, we will cover an example of hyper-parameter tuning in forecasting, and use HyperDrive in Azure Machine Learning service to achieve the task [3-5]. As a part of this exercise, we will also demonstrate how to deploy the trained model to Azure Container Instance (ACI) and test the deployed service.The repository also contains best-practice implementations in R language. Time permitting, we will cover common approaches to solving forecasting problems in R, ranging from simple regression models to more complex ones, such as Prophet package in R.","[{""name"":""Chenhui Hu"",""id"":""/profile/99659572936""},{""name"":""Vanja Paunic"",""id"":""/profile/81503680779""},{""name"":""Chenhui Hu"",""id"":""/profile/99659572936""},{""name"":""Vanja Paunic"",""id"":""/profile/81503680779""}]","[""Time series forecasting best practices and examples repository: https://github.com/microsoft/forecastingGoogle Scholar"",""Pyramid: Arima estimators for Python: http://alkaline-ml.com/pmdarima/0.9.0/index.htmlGoogle Scholar"",""Azure ML: https://docs.microsoft.com/en-us/azure/machine-learning/Google Scholar"",""Automated ML in Azure ML: https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-mlGoogle Scholar"",""Nicolo Fusi, Rishit Sheth, and Melih Elibol. 2018. Probabilistic Matrix Factorization for Automated Machine Learning. In Advances in neural information processing systems, 3348--3357.Google Scholar"",""LightGBM: https://github.com/Microsoft/LightGBMGoogle Scholar"",""Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. 2016. WaveNet: A Generative Model for Raw Audio. arXiv preprint arXiv:1609.03499 (2016).Google Scholar"",""Shaojie Bai, J. Zico Kolter, and Vladlen Koltun. 2018. An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling. arXiv preprint arXiv:1803.01271 (2018).Google Scholar""]"
https://doi.org/10.1145/3394486.3406700,How to Calibrate your Neural Network Classifier: Getting True Probabilities from a Classification Model,"Research in Machine Learning (ML) for classification tasks has been primarily guided by metrics that derive from a confusion matrix (e.g. accuracy, precision and recall). Several works have highlighted that this has lead to training practices that produce over-confident models and void the assumption that the model learns a probability distribution over the classification targets; this is referred to as miscalibration. Consequently, modern ML architectures struggle to perform in applications where a probabilistic forecaster is needed. Research efforts on calibration techniques have explored the possibility of recovering probability distributions from traditional architectures. This tutorial covers the key concepts required to understand the motivations behind calibration and aims at providing participants with the tools that they require assess the calibration of ML models and calibrate them when required.","[{""name"":""Natalia Culakova"",""id"":""/profile/99659574138""},{""name"":""Dan Murphy"",""id"":""/profile/99659575119""},{""name"":""Joao Gante"",""id"":""/profile/99659574340""},{""name"":""Carlos Ledezma"",""id"":""/profile/99659574101""},{""name"":""Vahan Hovhannisyan"",""id"":""/profile/99659574498""},{""name"":""Alan Mosca"",""id"":""/profile/99659266097""},{""name"":""Natalia Culakova"",""id"":""/profile/99659574138""},{""name"":""Dan Murphy"",""id"":""/profile/99659575119""},{""name"":""Joao Gante"",""id"":""/profile/99659574340""},{""name"":""Carlos Ledezma"",""id"":""/profile/99659574101""},{""name"":""Vahan Hovhannisyan"",""id"":""/profile/99659574498""},{""name"":""Alan Mosca"",""id"":""/profile/99659266097""}]","[""Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. 2017. On calibration of modern neural networks. arXiv preprint arXiv:1706.04599 (2017).Google Scholar"",""Andrey Malinin and Mark Gales. 2018. Predictive uncertainty estimation via prior networks. In Advances in Neural Information Processing Systems. 7047--7058.Google Scholar"",""Mahdi Pakdaman Naeini, Gregory Cooper, and Milos Hauskrecht. 2015. Obtaining well calibrated probabilities using bayesian binning. In Twenty-Ninth AAAI Conference on Artificial Intelligence.Google ScholarDigital Library"",""Alexandru Niculescu-Mizil and Rich Caruana. 2005. Predicting good probabilities with supervised learning. In Proceedings of the 22nd international conference on Machine learning. 625--632.Google ScholarDigital Library"",""John Platt et al. 1999. Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods. Advances in large margin classifiers 10, 3 (1999), 61--74.Google Scholar"",""Bianca Zadrozny and Charles Elkan. 2001. Obtaining calibrated probability estimates from decision trees and naive Bayesian classifiers. In Icml, Vol. 1. Citeseer, 609--616.Google Scholar"",""Bianca Zadrozny and Charles Elkan. 2002. Transforming classifier scores into accurate multiclass probability estimates. In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining. 694--699.Google ScholarDigital Library"",""Jize Zhang, Bhavya Kailkhura, and T Han. 2020. Mix-n-Match: Ensemble and Compositional Methods for Uncertainty Calibration in Deep Learning. arXiv preprint arXiv:2003.07329 (2020).Google Scholar""]"
https://doi.org/10.1145/3394486.3406701,Neural Structured Learning: Training Neural Networks with Structured Signals,"We present Neural Structured Learning (NSL) in TensorFlow [2], a new learning paradigm to train neural networks by leveraging structured signals in addition to feature inputs. Structure can be explicit as represented by a graph, or implicit, either induced by adversarial perturbation or inferred using techniques like embedding learning. NSL is open-sourced as part of the TensorFlow [3] ecosystem and is widely used in Google across many products and services. In this tutorial, we provide an overview of the NSL framework including various libraries, tools, and APIs as well as demonstrate the practical use of NSL in different applications. The NSL website is hosted at www.tensorflow.org/neural_structured_learning, which includes details about the theoretical foundations of the technology, extensive API documentation, and hands-on tutorials.","[{""name"":""Arjun Gopalan"",""id"":""/profile/99659573940""},{""name"":""Da-Cheng Juan"",""id"":""/profile/81414615257""},{""name"":""Cesar Ilharco Magalhaes"",""id"":""/profile/99659574820""},{""name"":""Chun-Sung Ferng"",""id"":""/profile/99659412869""},{""name"":""Allan Heydon"",""id"":""/profile/99659573096""},{""name"":""Chun-Ta Lu"",""id"":""/profile/99659477586""},{""name"":""Philip Pham"",""id"":""/profile/99659574238""},{""name"":""George Yu"",""id"":""/profile/99659573781""},{""name"":""Arjun Gopalan"",""id"":""/profile/99659573940""},{""name"":""Da-Cheng Juan"",""id"":""/profile/81414615257""},{""name"":""Cesar Ilharco Magalhaes"",""id"":""/profile/99659574820""},{""name"":""Chun-Sung Ferng"",""id"":""/profile/99659412869""},{""name"":""Allan Heydon"",""id"":""/profile/99659573096""},{""name"":""Chun-Ta Lu"",""id"":""/profile/99659477586""},{""name"":""Philip Pham"",""id"":""/profile/99659574238""},{""name"":""George Yu"",""id"":""/profile/99659573781""}]","[""2018. Graph Nets. https://github.com/deepmind/graph_netsGoogle Scholar"",""2019. Neural Structured Learning in TensorFlow. https://www.tensorflow.org/ neural_structured_learningGoogle Scholar"",""Martíin Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. 2016. Tensorflow: A system for large-scale machine learning. In 12th {USENIX} symposium on operating systems design and implementation ({OSDI} 16). 265--283.Google Scholar"",""Trapit Bansal, Da-Cheng Juan, Sujith Ravi, and Andrew McCallum. 2019. A2N: Attending to Neighbors for Knowledge Graph Inference. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.Google Scholar"",""Denis Baylor, Eric Breck, Heng-Tze Cheng, Noah Fiedel, Chuan Yu Foo, Zakaria Haque, Salem Haykal, Mustafa Ispir, Vihan Jain, Levent Koc, Chiu Yuen Koo, Lukasz Lew, Clemens Mewald, Akshay Naresh Modi, Neoklis Polyzotis, Sukriti Ramesh, Sudip Roy, Steven Euijong Whang, Martin Wicke, Jarek Wilkiewicz, Xin Zhang, and Martin Zinkevich. 2017. TFX: A TensorFlow-Based Production-Scale Machine Learning Platform. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 1387--1395.Google Scholar"",""Thang D. Bui, Sujith Ravi, and Vivek Ramavajjala. 2018. Neural Graph Learning: Training Neural Networks Using Graphs. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. 64--71.Google Scholar"",""Ian Goodfellow, Jonathon Shlens, and Christian Szegedy. 2015. Explaining and Harnessing Adversarial Examples. In International Conference on Learning Representations.Google Scholar"",""Da-Cheng Juan, Chun-Ta Lu, Zhen Li, Futang Peng, Aleksei Timofeev, Yi-Ting Chen, Yaxi Gao, Tom Duerig, Andrew Tomkins, and Sujith Ravi. 2020. Ultra Fine-Grained Image Semantic Embedding. In Proceedings of the 13th International Conference on Web Search and Data Mining. 277--285.Google Scholar"",""Takeru Miyato, Shin-Ichi Maeda, Masanori Koyama, and Shin Ishii. 2019. Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning. IEEE Transactions on Pattern Analysis and Machine Intelligence (2019), 1979--1993.Google Scholar"",""Otilia Stretcu, Krishnamurthy Viswanathan, Dana Movshovitz-Attias, Emmanouil Platanios, Sujith Ravi, and Andrew Tomkins. 2019. Graph Agreement Models for Semi-Supervised Learning. In Advances in Neural Information Processing Systems 32. Curran Associates, Inc., 8713--8723.Google Scholar"",""Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and Philip S. Yu. 2020. A Comprehensive Survey on Graph Neural Networks. IEEE Transactions on Neural Networks and Learning Systems (2020), 1--21.Google Scholar""]"
https://doi.org/10.1145/3394486.3406702,Accelerating and Expanding End-to-End Data Science Workflows with DL/ML Interoperability Using RAPIDS,"The lines between data science (DS), machine learning (ML), deep learning (DL), and data mining continue to be blurred and removed. This is great as it ushers in vast amounts of capabilities, but it brings increased complexity and a vast number of tools/techniques. It's not uncommon for DL engineers to use one set of tools for data extraction/cleaning and then pivot to another library for training their models. After training and inference, it's common to then move data yet again by another set of tools for post-processing. The RAPIDS suite of open source libraries not only provides a method to execute and accelerate these tasks using GPUs with familiar APIs, but it also provides interoperability with the broader open source community and DL tools while removing unnecessary serializations that slow down workflows. GPUs provide massive parallelization that DL has leveraged for some time, and RAPIDS provides the missing pieces that extend this computing power to more traditional yet important DS and ML tasks (e.g., ETL, modeling). Complete pipelines can be built that encompass everything, including ETL, feature engineering, ML/DL modeling, inference, and visualization, all while removing typical serialization costs and affording seamless interoperability between libraries. All experiments using RAPIDS can effortlessly be scheduled, logged and reviewed using existing public cloud options. Join our engineers and data scientists as they walk through a collection of DS and ML/DL engineering problems that show how RAPIDS running on Azure ML can be used for end-to-end, entirely GPU pipelines. This tutorial includes specifics on how to use RAPIDS for feature engineering, interoperability with common ML/DL packages, and creating GPU native visualizations using cuxfilter. The use cases presented here give attendees a hands-on approach to using RAPIDS components as part of a larger workflow, seamlessly integrating with other libraries (e.g., TensorFlow) and visualization packages.","[{""name"":""Bartley Richardson"",""id"":""/profile/99659574332""},{""name"":""Bradley Rees"",""id"":""/profile/81474681564""},{""name"":""Tom Drabas"",""id"":""/profile/99659574520""},{""name"":""Even Oldridge"",""id"":""/profile/99659311050""},{""name"":""David A. Bader"",""id"":""/profile/81482653534""},{""name"":""Rachel Allen"",""id"":""/profile/99659573231""},{""name"":""Bartley Richardson"",""id"":""/profile/99659574332""},{""name"":""Bradley Rees"",""id"":""/profile/81474681564""},{""name"":""Tom Drabas"",""id"":""/profile/99659574520""},{""name"":""Even Oldridge"",""id"":""/profile/99659311050""},{""name"":""David A. Bader"",""id"":""/profile/81482653534""},{""name"":""Rachel Allen"",""id"":""/profile/99659573231""}]","[""S. Rabhi, W. Sun, J. Perez, M. R. Kristensen, J. Liu, and E. Oldridge, 2019. \""Accelerating recommender system training 15x with RAPIDS.\"" In Proceedings of the Workshop on ACM Recommender System Challenge (RecSys Challenge '19). ACM Press, New York, NY, 1--5. DOI: https://doi.org/10.1145/3359555.3359564Google Scholar"",""W. McKinney, 2010. \""Data structures for statistical computing in Python.\"" In Proceedings of the 9th Python In Science Conference (SCIPY 2010). Vol. 445, pp. 51--56Google Scholar"",""L. McInnes, J. Healy, and J. Melville, 2018. \""UMAP: Uniform manifold approximation and projection for dimension reduction.\"" https://arxiv.org/abs/1802.03426Google Scholar"",""V. Poulin and F. Théberge, 2018. \""Ensemble clustering for graphs.\"" In International Conference on Complex Networks and their Applications. pp. 231--243.Google Scholar"",""A. Tripathy, F. Hohman, D. Chau, and O. Green, 2018. \""Scalable K-core decomposition for static graphs using a dynamic graph data structure.\"" In IEEE Proceedings of the International Conference on Big Data (BIG DATA). pp. 1134--1141.Google Scholar"",""RAPIDS, https://rapids.aiGoogle Scholar"",""cyBERT, https://medium.com/rapids-ai/cybert-28b35a4c81c4Google Scholar"",""DL recommender systems, https://medium.com/rapids-ai/accelerating-deep-learning-recommender-systems-by-15x-using-rapids-fastai-and-pytorch-b50b4d8568d1Google Scholar""]"
https://doi.org/10.1145/3394486.3406703,DeepSpeed: System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters,"Explore new techniques in Microsoft's open source library called DeepSpeed, which advances large model training by improving scale, speed, cost, and usability, unlocking the ability to train 100-billion-parameter models. DeepSpeed is compatible with PyTorch. One piece of our library, called ZeRO, is a new parallelized optimizer that greatly reduces the resources needed for model and data parallelism while massively increasing the number of parameters that can be trained. Researchers have used these breakthroughs to create Turing Natural Language Generation (Turing-NLG), which at the time of its release was the largest publicly known language model at 17 billion parameters. In addition we will also go over our latest transformer kernel advancements that led the DeepSpeed team to achieve the world fastest BERT pretraining record.The Zero Redundancy Optimizer (ZeRO) is a novel memory optimization technology for large-scale distributed deep learning. ZeRO can train deep learning models with over 100 billion parameters on the current generation of GPU clusters at three to five times the throughput of the current best system. It also presents a clear path to training models with trillions of parameters, demonstrating an unprecedented leap in deep learning system technology.DeepSpeed brings state-of-the-art training techniques, such as ZeRO, optimized kernels, distributed training, mixed precision, and checkpointing, through lightweight APIs compatible with PyTorch. With just a few lines of code changes to your PyTorch model, you can leverage DeepSpeed to address underlying performance challenges and boost the speed and scale of your training.","[{""name"":""Jeff Rasley"",""id"":""/profile/81470655390""},{""name"":""Samyam Rajbhandari"",""id"":""/profile/84459933557""},{""name"":""Olatunji Ruwase"",""id"":""/profile/81361607878""},{""name"":""Yuxiong He"",""id"":""/profile/81100331593""},{""name"":""Jeff Rasley"",""id"":""/profile/81470655390""},{""name"":""Samyam Rajbhandari"",""id"":""/profile/84459933557""},{""name"":""Olatunji Ruwase"",""id"":""/profile/81361607878""},{""name"":""Yuxiong He"",""id"":""/profile/81100331593""}]","[""Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-performance deep learning library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32, pages 8024--8035. Curran Associates, Inc., 2019.Google Scholar"",""Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen, David Garcia, Boris Ginsburg, Michael Houston, Oleksii Kuchaiev, Ganesh Venkatesh, and Hao Wu. Mixed precision training, 2017.Google Scholar"",""NVIDIA Tesla V100 GPU architecture. http://images.nvidia.com/content/volta-architecture/pdf/volta-architecture-whitepaper.pdf, 2017. [Online, accessed 22-April-2020].Google Scholar"",""Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, and Yuxiong He. ZeRO: Memory Optimizations Toward Training Trillion Parameter Models. arXiv:1910.02054, 2019.Google Scholar"",""Microsoft DeepSpeed achieves the fastest BERT training time. https://www.deepspeed.ai/news/2020/05/27/fastest-bert-training.html, 2020.Google Scholar"",""Shar Narasimhan. NVIDIA Clocks World's Fastest BERT Training Time... https://devblogs.nvidia.com/training-bert-with-gpus/, 2019. [Online; accessed 25-September-2019].Google Scholar""]"
https://doi.org/10.1145/3394486.3406704,Robust Deep Learning Methods for Anomaly Detection,"Anomaly detection is an important problem that has been well-studied within diverse research areas and application domains. A robust anomaly detection system identifies rare events and patterns in the absence of labelled data. The identified patterns provide crucial insights about both the fidelity of the data and deviations in the underlying data-generating process. For example a surveillance system designed to monitor the emergence of new epidemics will use a robust anomaly detection methods to separate spurious associations from genuine indicators of an epidemic with minimal lag time.The key concept in anomaly detection is the notion of ""robustness'', i.e., designing models and representations which are less-sensitive to small changes in the underlying data distribution. The canonical example is that the median is more robust than the mean as an estimator. The tutorial will primarily help researchers and developers design deep learning architectures and loss functions where the learnt representation behave more like the ""median'' rather than the ""mean.'' The tutorial will revisit well known unsupervised learning techniques in deep learning including autoencoders and generative adversarial networks (GANs) from the perspective of anomaly detection. This in turn will give the audience a more grounded perspective on unsupervised deep learning methods. All the methods will be introduced in a hands-on manner to demonstrate how high-level ideas and concepts get translated to practical real code.","[{""name"":""Raghavendra Chalapathy"",""id"":""/profile/99659574061""},{""name"":""Nguyen Lu Dang Khoa"",""id"":""/profile/81479652674""},{""name"":""Sanjay Chawla"",""id"":""/profile/81100002847""},{""name"":""Raghavendra Chalapathy"",""id"":""/profile/99659574061""},{""name"":""Nguyen Lu Dang Khoa"",""id"":""/profile/81479652674""},{""name"":""Sanjay Chawla"",""id"":""/profile/81100002847""}]","[""Charu C Aggarwal. 2015. Outlier analysis. In Data mining. Springer, 237--263.Google Scholar"",""Emmanuel Candés, Xiaodong Li, Yi Ma, and John Wright. 2010. Robust principal component analysis?: Recovering low-rank matrices from sparse errors. In Sensor Array and Multichannel Signal Processing Workshop (SAM), 2010 IEEE. IEEE, 201--204.Google ScholarCross Ref"",""Raghavendra Chalapathy and Sanjay Chawla. 2019. Deep learning for anomaly detection: A survey. arXiv preprint arXiv:1901.03407 (2019).Google Scholar"",""Raghavendra Chalapathy, Aditya Krishna Menon, and Sanjay Chawla. 2017. Robust, deep and inductive anomaly detection. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 36--51.Google ScholarCross Ref"",""Jun Kang Chow, Z Su, Jiaqi Wu, Pin Siang Tan, X Mao, and YH Wang. 2020. Anomaly detection of defects on concrete structures with the convolutional auto encoder. Advanced Engineering Informatics 45 (2020), 101105.Google ScholarCross Ref"",""Federico Di Mattia, Paolo Galeone, Michele De Simoni, and Emanuele Ghelfi. 2019. A survey on gans for anomaly detection. arXiv preprint arXiv:1906.11632 (2019).Google Scholar"",""Min Du, Feifei Li, Guineng Zheng, and Vivek Srikumar. 2017. Deeplog: Anomaly detection and diagnosis from system logs through deep learning. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. 1285--1298.Google ScholarDigital Library"",""Andrew J Larkoski, Ian Moult, and Benjamin Nachman. 2020. Jet substructure at the Large Hadron Collider: a review of recent advances in theory and machine learning. Physics Reports 841, 1--63.Google ScholarCross Ref"",""Christian Leibig, Vaneeda Allken, Murat Seçkin Ayhan, Philipp Berens, and Siegfried Wahl. 2017. Leveraging uncertainty information from deep neural networks for disease detection. Scientific reports 7, 1 (2017), 1--14.Google Scholar"",""Guansong Pang, Chunhua Shen, and Anton van den Hengel. 2019. Deep Anomaly Detection with Deviation Networks. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 353--362.Google Scholar"",""Evan Racah, Christopher Beckham, Tegan Maharaj, Samira Ebrahimi Kahou, Mr Prabhat, and Chris Pal. 2017. Extreme Weather: A large-scale climate data set for semi-supervised detection, localization, and understanding of extreme weather events. In Advances in Neural Information Processing Systems. 3402--3413.Google Scholar"",""Peter J. Rousseeuw and Annick M. Leroy. 2003. Robust Regression and Outlier Detection. John Wiley \u0026 Sons.Google Scholar"",""Lukas Ruff, Robert A. Vandermeulen, Nico Görnitz, Lucas Deecke, Shoaib A. Siddiqui, Alexander Binder, Emmanuel Müller, and Marius Kloft. 2018. Deep One-Class Classification. In Proceedings of the 35th International Conference on Machine Learning, Vol. 80. 4393--4402.Google Scholar"",""Kexin Nie Ruoying Wang. 2020. Deep learning for anomaly detection in hyper spectral imagery. WSDM Conference in Houston, Texas (2020).Google Scholar"",""Svante Wold, Kim Esbensen, and Paul Geladi. 1987. Principal component analysis. Chemometrics and intelligent laboratory systems 2, 1--3 (1987), 37--52.Google Scholar"",""Liang Xiong, Xi Chen, and Jeff Schneider. 2011. Direct robust matrix factorizatoin for anomaly detection. In 2011 IEEE 11th International Conference on Data Mining. IEEE, 844--853.Google ScholarDigital Library"",""Zhaohui Zhang, Xinxin Zhou, Xiaobo Zhang, Lizhi Wang, and Pengwei Wang. 2018. A model based on convolutional neural network for online transaction fraud detection. Security and Communication Networks 2018 (2018).Google Scholar"",""Chong Zhou and Randy C Paffenroth. 2017. Anomaly detection with robust deep autoencoders. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 665--674.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3406706,"Faster, Simpler, More Accurate: Practical Automated Machine Learning with Tabular, Text, and Image Data","Automated machine learning (AutoML) offers the promise of translating raw data into accurate predictions with just a few lines of code. Rather than relying on human time/effort and manual experimentation, models can be improved by simply letting the AutoML system run for more time. In this hands-on tutorial, we demonstrate fundamental techniques that enable powerful AutoML. We consider standard supervised learning tasks on various types of data including tables, text, images, as well as multi-modal data comprised of multiple types. Rather than technical descriptions of how individual ML models work, we emphasize how to best use models within an overall ML pipeline that takes in raw training data and outputs pre-dictions for test data. A major focus of our tutorial is on automating deep learning, a class of powerful techniques that are cumbersome to manage manually. Despite this, hardly any educational material describes their successful automation. Each topic covered in the tutorial is accompanied by a hands-on Jupyter notebook that implements best practices (which will be available on Github before and after the tutorial). Most of this code is adopted from AutoGluon (autogluon.mxnet.io), a recent AutoML toolkit for automated deep learning that is both state-of-the-art and easy-to-use.","[{""name"":""Jonas Mueller"",""id"":""/profile/99659574310""},{""name"":""Xingjian Shi"",""id"":""/profile/99659573621""},{""name"":""Alexander Smola"",""id"":""/profile/81461656449""},{""name"":""Jonas Mueller"",""id"":""/profile/99659574310""},{""name"":""Xingjian Shi"",""id"":""/profile/99659573621""},{""name"":""Alexander Smola"",""id"":""/profile/81461656449""}]","[""2019. AutoGluon: AutoML Toolkit for Deep Learning. https://github.com/ awslabs/autogluon/.Google Scholar"",""Sanjeev Arora, Yingyu Liang, and Tengyu Ma. 2017. A simple but tough-to-beat baseline for sentence embeddings. In ICLR.Google Scholar"",""Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. Enriching word vectors with subword information. Transactions of the Association for Computational Linguistics, Vol. 5 (2017), 135--146.Google ScholarCross Ref"",""CS231n. 2019. Transfer Learning. http://cs231n.github.io/transfer-learning/.Google Scholar"",""Ekin D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc V Le. 2019. Autoaugment: Learning augmentation strategies from data. In Proceedings of the IEEE conference on computer vision and pattern recognition. 113--123.Google ScholarCross Ref"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).Google Scholar"",""Thomas G Dietterich. 2000. Ensemble methods in machine learning. In International workshop on multiple classifier systems. Springer, 1--15.Google ScholarDigital Library"",""Anna Veronika Dorogush, Vasily Ershov, and Andrey Gulin. 2018. CatBoost: gradient boosting with categorical features support. arXiv preprint arXiv:1810.11363 (2018).Google Scholar"",""Nick Erickson, Jonas Mueller, Alexander Shirkov, Hang Zhang, Pedro Larroy, Mu Li, and Alexander Smola. 2020. AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data. arXiv preprint arXiv:2003.06505 (2020).Google Scholar"",""Rasool Fakoor, Jonas Mueller, Nick Erickson, Pratik Chaudhari, and Alexander J Smola. 2020. Fast, Accurate, and Simple Models for Tabular Data via Augmented Distillation. arXiv preprint arXiv:2006.14284 (2020).Google Scholar"",""Matthias Feurer, Jost Tobias Springenberg, and Frank Hutter. 2014. Using meta-learning to initialize bayesian optimization of hyperparameters. In International Conference on Meta-learning and Algorithm Selection, Vol. 1201. 3--10.Google Scholar"",""Cheng Guo and Felix Berkhahn. 2016. Entity Embeddings of Categorical Variables. arXiv preprint arXiv:1604.06737 (2016).Google Scholar"",""Jian Guo, He He, Tong He, Leonard Lausen, Mu Li, Haibin Lin, Xingjian Shi, Chenguang Wang, Junyuan Xie, Sheng Zha, et almbox. 2020. GluonCV and GluonNLP: Deep learning in computer vision and natural language processing. Journal of Machine Learning Research, Vol. 21, 23 (2020), 1--7.Google Scholar"",""Tong He, Zhi Zhang, Hang Zhang, Zhongyue Zhang, Junyuan Xie, and Mu Li. 2019 a. Bag of tricks for image classification with convolutional neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 558--567.Google ScholarCross Ref"",""Xin He, Kaiyong Zhao, and Xiaowen Chu. 2019 b. AutoML: A Survey of the State-of-the-Art. arXiv preprint arXiv:1908.00709 (2019).Google Scholar"",""Frank Hutter, Lars Kotthoff, and Joaquin Vanschoren. 2018. Automated Machine Learning: Methods, Systems, Challenges. https://www.automl.org/book/.Google Scholar"",""Haifeng Jin, Qingquan Song, and Xia Hu. 2019. Auto-Keras: An Efficient Neural Architecture Search System. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 1946--1956.Google ScholarDigital Library"",""Liam Li, Kevin Jamieson, Afshin Rostamizadeh, Ekaterina Gonina, Moritz Hardt, Benjamin Recht, and Ameet Talwalkar. 2018. Massively parallel hyperparameter tuning. arXiv preprint arXiv:1810.05934 (2018).Google Scholar"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems. 3111--3119.Google Scholar"",""F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011. Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, Vol. 12 (2011), 2825--2830.Google ScholarDigital Library"",""Hieu Pham, Melody Guan, Barret Zoph, Quoc Le, and Jeff Dean. 2018. Efficient Neural Architecture Search via Parameters Sharing. In Proceedings of the 35th International Conference on Machine Learning, Vol. 80. PMLR, 4095--4104.Google Scholar"",""Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P Adams, and Nando De Freitas. 2015. Taking the human out of the loop: A review of Bayesian optimization. Proc. IEEE, Vol. 104, 1 (2015), 148--175.Google ScholarCross Ref"",""Leslie N Smith. 2018. A disciplined approach to neural network hyper-parameters: Part 1-learning rate, batch size, momentum, and weight decay. arXiv preprint arXiv:1803.09820 (2018).Google Scholar"",""Yue Sun, Chongruo Wu, Zhongyue Zhang, Tong He, Jonas Mueller, and Hang Zhang. 2020. Image Classification on Kaggle using AutoGluon. https://medium.com/@zhanghang0704/image-classification-on-kaggle-using-autogluon-fc896e74d7e8.Google Scholar"",""Anh Truong, Austin Walters, Jeremy Goodsitt, Keegan Hines, Bayan Bruss, and Reza Farivar. 2019. Towards automated machine learning: Evaluation and comparison of AutoML approaches and tools. arXiv preprint arXiv:1908.05557 (2019).Google Scholar"",""Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola. 2019. Dive into Deep Learning. http://www.d2l.ai.Google Scholar"",""Marc-André Zöller and Marco F Huber. 2019. Benchmark and Survey of Automated Machine Learning Frameworks. arXiv preprint arXiv:1904.12054 (2019).Google Scholar""]"
https://doi.org/10.1145/3394486.3406707,Intelligible and Explainable Machine Learning: Best Practices and Practical Challenges,"Learning methods such as boosting and deep learning have made ML models harder to understand and interpret. This puts data scientists and ML developers in the position of often having to make a tradeoff between accuracy and intelligibility. Research in IML (Interpretable Machine Learning) and XAI (Explainable AI) focus on minimizing this trade-off by developing more accurate interpretable models and by developing new techniques to explain black-box models. Such models and techniques make it easier for data scientists, engineers and model users to debug models and achieve important objectives such as ensuring the fairness of ML decisions and the reliability and safety of AI systems. In this tutorial, we present an overview of various interpretability methods and provide a framework for thinking about how to choose the right explanation method for different real-world scenarios. We will focus on the application of XAI in practice through a variety of case studies from domains such as healthcare, finance, and bias and fairness. Finally, we will present open problems and research directions for the data mining and machine learning community. What audience will learn: When and how to use a variety of machine learning interpretability methods through case studies of real-world situations. The difference between glass-box and black-box explanation methods and when to use them. How to use open source interpretability toolkits that are now available","[{""name"":""Rich Caruana"",""id"":""/profile/81100100877""},{""name"":""Scott Lundberg"",""id"":""/profile/81442611983""},{""name"":""Marco Tulio Ribeiro"",""id"":""/profile/99659573959""},{""name"":""Harsha Nori"",""id"":""/profile/99659529621""},{""name"":""Samuel Jenkins"",""id"":""/profile/99659526706""},{""name"":""Rich Caruana"",""id"":""/profile/81100100877""},{""name"":""Scott Lundberg"",""id"":""/profile/81442611983""},{""name"":""Marco Tulio Ribeiro"",""id"":""/profile/99659573959""},{""name"":""Harsha Nori"",""id"":""/profile/99659529621""},{""name"":""Samuel Jenkins"",""id"":""/profile/99659526706""}]",null
https://doi.org/10.1145/3394486.3406708,Dealing with Bias and Fairness in Data Science Systems: A Practical Hands-on Tutorial,"Tackling issues of bias and fairness when building and deploying data science systems has received increased attention from the research community in recent years, yet a lot of the research has focused on theoretical aspects and very limited set of application areas and data sets. There is a lack of 1) practical training materials, 2) methodologies, and 3) tools for researchers and developers working on real-world algorithmic decision making system to deal with issues of bias and fairness. Today, treating bias and fairness as primary metrics of interest, and building, selecting, and validating models using those metrics is not standard practice for data scientists. In this hands-on tutorial we will try to bridge the gap between research and practice, by deep diving into algorithmic fairness, from metrics and definitions to practical case studies, including bias audits using the Aequitas toolkit (http://github.com/dssg/aequitas). By the end of this hands-on tutorial, the audience will be familiar with bias mitigation frameworks and tools to help them making decisions during a project based on intervention and deployment contexts in which their system will be used.","[{""name"":""Pedro Saleiro"",""id"":""/profile/81759039557""},{""name"":""Kit T. Rodolfa"",""id"":""/profile/99659493801""},{""name"":""Rayid Ghani"",""id"":""/profile/81100427240""},{""name"":""Pedro Saleiro"",""id"":""/profile/81759039557""},{""name"":""Kit T. Rodolfa"",""id"":""/profile/99659493801""},{""name"":""Rayid Ghani"",""id"":""/profile/81100427240""}]","[""Kit T. Rodolfa, Pedro Saleiro, and Rayid Ghani. Chapter 11: Bias and fairness. In Ian Foster, Rayid Ghani, Ron S Jarmin, Frauke Kreuter, and Julia Lane, editors, Big data and social science: A practical guide to methods and tools. crc Press, 2020.Google Scholar"",""Kit T Rodolfa, Erika Salomon, Lauren Haynes, Iván Higuera Mendieta, Jamie Larson, and Rayid Ghani. Case study: predictive fairness to reduce misdemeanor recidivism through social service interventions. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, pages 142--153, 2020.Google ScholarDigital Library"",""Pedro Saleiro, Benedict Kuester, Loren Hinkson, Jesse London, Abby Stevens, Ari Anisfeld, Kit T. Rodolfa, and Rayid Ghani. Aequitas: A Bias and Fairness Audit Toolkit. (2018), nov 2018.Google Scholar"",""Moritz Hardt, Eric Price, and Nathan Srebro. Equality of Opportunity in Supervised Learning. Advances in Neural Information Processing Systems, (Nips):1--22, 2016.Google Scholar"",""Solon Barocas and Andrew D. Selbst. Big Data's Disparate Impact. California Law Review, 104(3):671--732, 2016.Google Scholar"",""Shira Mitchell, Eric Potash, Solon Barocas, Alexander D'Amour, and Kristian Lum. Prediction-Based Decisions and Fairness: A Catalogue of Choices, Assumptions, and Definitions. nov 2018.Google Scholar"",""Alexandra Chouldechova, Diana Benavides-Prado, Oleksandr Fialko, and Rhema Vaithianathan. A case study of algorithm-assisted decision making in child maltreatment hotline screening decisions. In Conference on Fairness, Accountability and Transparency, pages 134--148, 2018.Google Scholar"",""Alexandra Chouldechova and Aaron Roth. The frontiers of fairness in machine learning. arXiv preprint arXiv:1810.08810, 2018.Google Scholar"",""Geoff Pleiss, Manish Raghavan, Felix Wu, Jon Kleinberg, and Kilian Q Weinberger. On Fairness and Calibration. In I Guyon, U V Luxburg, S Bengio, H Wallach, R Fergus, S Vishwanathan, and R Garnett, editors, Advances in Neural Information Processing Systems 30, pages 5680--5689. Curran Associates, Inc., 2017.Google Scholar"",""Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rodriguez, and Krishna P. Gummadi. Fairness constraints: Mechanisms for fair classification. Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, AISTATS 2017, 54, 2017.Google Scholar"",""Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rodriguez, and Krishna P. Gummadi. Fairness beyond disparate treatment \u0026 disparate impact: Learning classification without disparate mistreatment. 26th International World Wide Web Conference, WWW 2017, pages 1171--1180, 2017.Google ScholarDigital Library"",""Andrew Cotter, Maya Gupta, Heinrich Jiang, Nathan Srebro, Karthik Sridharan, Serena Wang, Blake Woodworth, and Seungil You. Training Well-Generalizing Classifiers for Fairness Metrics and Other Data-Dependent Constraints. In Proceedings of the 36th International Conference on Machine Learning, volume 97, pages 1397--1405, Long Beach, California, USA, jun 2019. PMLR.Google Scholar"",""Indre liobait ? e. Measuring discrimination in algorithmic decision making. Data Mining and Knowledge Discovery, 31(4):1060--1089, jul 2017.Google ScholarDigital Library"",""Sahil Verma and Julia Rubin. Fairness definitions explained. In Proceedings of the International Workshop on Software Fairness - FairWare '18, pages 1--7, New York, New York, USA, 2018. ACM Press.Google ScholarDigital Library"",""Alexandra Chouldechova. Fair Prediction with Disparate Impact: A Study of Bias in Recidivism Prediction Instruments. Big Data, 5(2):153--163, jun 2017.Google ScholarCross Ref"",""Jon Kleinberg, Himabindu Lakkaraju, Jure Leskovec, Jens Ludwig, and Sendhill Mullainathan. Human Decisions and Machine Predictions*. The Quarterly Journal of Economics, 133(January):237--293, aug 2017.Google Scholar"",""Chris Russell, Matt J Kusner, Joshua Loftus, and Ricardo Silva. When Worlds Collide: Integrating Different Counterfactual Assumptions in Fairness. In I Guyon, U V Luxburg, S Bengio, H Wallach, R Fergus, S Vishwanathan, and R Garnett, editors, Advances in Neural Information Processing Systems 30, pages 6414--6423. Curran Associates, Inc., 2017.Google Scholar"",""Matt J Kusner, Joshua Loftus, Chris Russell, and Ricardo Silva. Counterfactual Fairness. In I Guyon, U V Luxburg, S Bengio, H Wallach, R Fergus, S Vishwanathan, and R Garnett, editors, Advances in Neural Information Processing Systems 30, pages 4066--4076. Curran Associates, Inc., 2017.Google Scholar"",""Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. Machine bias. ProPublica, May, 23:2016, 2016.Google Scholar"",""Michael Feldman, Sorelle A. Friedler, John Moeller, Carlos Scheidegger, and Suresh Venkatasubramanian. Certifying and Removing Disparate Impact. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '15, pages 259--268, New York, New York, USA, 2015. ACM Press.Google ScholarDigital Library"",""Alekh Agarwal, Aliiia Beygelzimer, Miroslav Dudfk, John Langford, and Wallach Hanna. A reductions approach to fair classification. 35th International Conference on Machine Learning, ICML 2018, 1:102--119, 2018.Google Scholar"",""Yahav Bechavod and Katrina Ligett. Penalizing Unfairness in Binary Classification. jun 2017.Google Scholar"",""Naman Goel, Mohammad Yaghini, and Boi Faltings. Non-Discriminatory Machine Learning through Convex Fairness Criteria. In Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society - AIES '18, pages 116--116, New York, New York, USA, 2018. ACM Press.Google ScholarDigital Library"",""Blake Woodworth, Suriya Gunasekar, Mesrob I. Ohannessian, and Nathan Srebro. Learning Non-Discriminatory Predictors. In Satyen Kale and Ohad Shamir, editors, Proceedings of the 2017 Conference on Learning Theory, volume 65, pages 1920--1953, Amsterdam, Netherlands, jul 2017. PMLR.Google Scholar""]"
https://doi.org/10.1145/3394486.3406709,Deep Learning for Search and Recommender Systems in Practice,"In this talk, we will go over the components of personalized search and recommender systems and demonstrate the applications of various deep learning techniques along the way.Search and recommender systems are probably the most prevalent ML powered application across the industry. They share most of the components composition and provide a user a ranked list of items, while there is subtle difference that a search system typically acts passively with a clear user intention in terms of queries and a recommender system acts more proactively.Deep learning has been wildly successful in solving complex tasks such as image recognition, speech recognition, natural language processing and understanding, machine translation, etc. In the area of personalized recommender systems, deep learning has been showing tremendous impact in recent years.Search and recommender systems can be staged roughly in three phases: 1. User and query understanding, where a query or a user profile are processed so that the systems can use the processed information to 2. retrieve all the related items (high recall) and 3. rank the items by the order of the most relevance to the user's intent (high precision). Each phase has its unique challenges but deep learning has been ubiquitously pushing beyond the limit.After walking through the talk, we hope the audience would gain some first-hand experience building a personalized search/recommender system using deep learning techniques.","[{""name"":""Zhoutong Fu"",""id"":""/profile/99659575055""},{""name"":""Huiji Gao"",""id"":""/profile/99659451939""},{""name"":""Weiwei Guo"",""id"":""/profile/99659450897""},{""name"":""Sandeep Kumar Jha"",""id"":""/profile/99659565244""},{""name"":""Jun Jia"",""id"":""/profile/99659573787""},{""name"":""Xiaowei Liu"",""id"":""/profile/99659574119""},{""name"":""Bo Long"",""id"":""/profile/99659534038""},{""name"":""Jun Shi"",""id"":""/profile/99659451818""},{""name"":""Sida Wang"",""id"":""/profile/99659575226""},{""name"":""Mingzhou Zhou"",""id"":""/profile/99659573519""},{""name"":""Zhoutong Fu"",""id"":""/profile/99659575055""},{""name"":""Huiji Gao"",""id"":""/profile/99659451939""},{""name"":""Weiwei Guo"",""id"":""/profile/99659450897""},{""name"":""Sandeep Kumar Jha"",""id"":""/profile/99659565244""},{""name"":""Jun Jia"",""id"":""/profile/99659573787""},{""name"":""Xiaowei Liu"",""id"":""/profile/99659574119""},{""name"":""Bo Long"",""id"":""/profile/99659534038""},{""name"":""Jun Shi"",""id"":""/profile/99659451818""},{""name"":""Sida Wang"",""id"":""/profile/99659575226""},{""name"":""Mingzhou Zhou"",""id"":""/profile/99659573519""}]","[""Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Mane, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viegas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. 2016. TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems. arXiv:cs.DC/1603.04467Google Scholar"",""Deepak Agarwal, Bee-Chung Chen, Rupesh Gupta, Joshua Hartman, Qi He, Anand Iyer, Sumanth Kolar, Yiming Ma, Pannagadatta Shivaswamy, Ajit Singh, and Liang Zhang. 2014. Activity ranking in LinkedIn feed. Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (08 2014). https://doi.org/10.1145/2623330.2623362Google ScholarDigital Library"",""Deepak Agarwal, Liang Zhang, Bee-Chung Chen, Qi He, Zhenhao Hua, Guy Lebanon, Yiming Ma, Pannagadatta Shivaswamy, Hsiao-Ping Tseng, and Jaewon Yang. 2015. Personalizing Linked In Feed. 1651--1660. https://doi.org/10.1145/ 2783258.2788614Google Scholar"",""Trapit Bansal, David Belanger, and Andrew McCallum. 2016. Ask the gru: Multitask learning for deep text recommendations. In RecSys.Google Scholar"",""Leonid Boytsov, David Novak, Yury Malkov, and Eric Nyberg. 2016. Off the Beaten Path: Let's Replace Term-Based Retrieval with k-NN Search. In CIKM.Google Scholar"",""Christopher Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds, Nicole Hamilton, and Gregory Hullender. 2005. Learning to Rank using Gradient Descent. ICML 2005 - Proceedings of the 22nd International Conference on Machine Learning, 89--96. https://doi.org/10.1145/1102351.1102363Google ScholarDigital Library"",""Tianqi Chen and Carlos Guestrin. 2016. XGBoost: A Scalable Tree Boosting System. 785--794. https://doi.org/10.1145/2939672.2939785Google Scholar"",""Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, G.s Corrado, Wei Chai, Mustafa Ispir, Rohan Anil, Zakaria Haque, Lichan Hong, Vihan Jain, Xiaobing Liu, and Hemal Shah. 2016. Wide \u0026 Deep Learning for Recommender Systems. 7--10. https://doi.org/ 10.1145/2988450.2988454Google Scholar"",""Corinna Cortes and Vladimir Vapnik. 1995. Support Vector Network. Machine Learning 20 (09 1995), 273--297. https://doi.org/10.1007/BF00994018Google Scholar"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. In NAACL.Google Scholar"",""Nadia Fawaz, Saurabh Kataria, Benjamin Le, Liang Zhang, and Ganesh Venkataraman. 2017. Deep Learning for Personalized Search and Recommender Systems. In KDD.Google Scholar"",""Homa B. Hashemi, Amir Asiaee, and Reiner Kraft. 2016. Query Intent Detection using Convolutional Neural Networks. In International Conference on Web Search and Data Mining, Workshop on Query Understanding.Google Scholar"",""Baotian Hu, Zhengdong Lu, Hang Li,, and Qingcai Chen. 2014. Convolutional Neural Network Architectures for Matching Natural Language Sentences. In NIPS.Google Scholar"",""LinkedIn. 2020. Deep neural ranking framework with Text understanding. https: //github.com/linkedin/detextGoogle Scholar"",""Bhaskar Mitra, Fernando Diaz,, and Nick Craswell. 2017. Learning to match using local and distributed representations of text for web search. In WWW.Google Scholar"",""Yelong Shen, Xiaodong He, Jianfeng Gao, Li Deng, and Grégoire Mesnil. 2014. Learning deep structured semantic models for web search using clickthrough data. In WWW.Google Scholar"",""Yangyang Shi, Kaisheng Yao, Le Tian, and Daxin Jiang. 2016. Deep LSTM based feature mapping for query classification. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.Google ScholarCross Ref"",""Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In NIPS.Google Scholar"",""Jun Xu, Xiangnan He, and Hang Li. 2018. Deep Learning for Matching in Search and Recommendation. In SIGIR.Google Scholar"",""Hamed Zamani, Mostafa Dehghani,W. Bruce Croft, Erik Learned-Miller, and Jaap Kamps. 2018. From Neural Re-Ranking to Neural Ranking: Learning a Sparse Representation for Inverted Indexing. In CIKM.Google Scholar"",""Hamed Zamani, Bhaskar Mitra, Xia Song, Nick Craswell, and Saurabh Tiwary. 2018. Neural ranking models with multiple document fields. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining.Google ScholarDigital Library"",""XianXing Zhang, Yitong Zhou, Yiming Ma, Bee-Chung Chen, Liang Zhang, and Deepak Agarwal. 2016. GLMix: Generalized Linear Mixed Models For Large-Scale Response Prediction. 363--372. https://doi.org/10.1145/2939672.2939684Google Scholar""]"
https://doi.org/10.1145/3394486.3406710,Computer Vision: Deep Dive into Object Segmentation Approaches,"Image segmentation is the task of associating pixels in an image with their respective object class labels. It has a wide range of applications in many industries including healthcare, transportation, robotics, fashion, home improvement, and tourism. Many deep learning-based approaches have been developed for image-level object recognition and pixel-level scene understanding - with the latter requiring a much denser annotation of scenes with a large set of objects. This tutorial provides an end-to-end pipeline for performing image segmentation using the state-of-art deep learning approaches and public datasets. The hands-on session will provide instructions for dataset customization, transformation, and training, validating, and testing segmentation models. The goal of this tutorial is to provide participants with a strong understanding of building image segmentation models for downstream applications.","[{""name"":""Yuanbo Wang"",""id"":""/profile/99659574549""},{""name"":""Osama Sakhi"",""id"":""/profile/99659574819""},{""name"":""Ala Eddine Ayadi"",""id"":""/profile/99659573222""},{""name"":""Matthew Hagen"",""id"":""/profile/99659572934""},{""name"":""Estelle Afshar"",""id"":""/profile/99659573897""},{""name"":""Yuanbo Wang"",""id"":""/profile/99659574549""},{""name"":""Osama Sakhi"",""id"":""/profile/99659574819""},{""name"":""Ala Eddine Ayadi"",""id"":""/profile/99659573222""},{""name"":""Matthew Hagen"",""id"":""/profile/99659572934""},{""name"":""Estelle Afshar"",""id"":""/profile/99659573897""}]","[""Bolei Zhou, Hang Zhao, Xavier Puig, Tete Xiao, Sanja Fidler, Adela Barriuso, and Antonio Torralba. 2019. Semantic understanding of scenes through the ade20k dataset. International Journal of Computer Vision 127, no. 3, 302--321. DOI: https://doi.org/10.1007/s11263-018-1140-0Google ScholarDigital Library"",""Mark Everingham, Luc Van Gool, Christopher KI Williams, John Winn, and Andrew Zisserman. 2010. The pascal visual object classes (voc) challenge. International journal of computer vision 88, no. 2, 303--338. DOI: https://doi.org/10.1007/s11263-009-0275-4Google Scholar"",""Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. 2016. The cityscapes dataset for semantic urban scene understanding. In Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR ?16), 3213--3223.Google ScholarCross Ref"",""Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C. Lawrence Zitnick. 2014. Microsoft coco: Common objects in context. In European conference on computer vision, Springer, Cham. 740--755. DOI: https://doi.org/10.1007/978-3-319-10602-1_48.Google Scholar"",""Olaf Ronneberger, Philipp Fischer, and Thomas Brox. 2015. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computer-assisted intervention, Springer, Cham. 234--241. DOI: https://doi.org/10.1007/978-3-319-24574-4_28.Google ScholarCross Ref"",""Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. 2015. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR '17), 2881--2890.Google Scholar"",""Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick. 2017. Mask r-cnn. In Proceedings of the IEEE international conference on computer vision (CVPR '17), 2961--2969Google ScholarCross Ref"",""Zhaowei Cai and Nuno Vasconcelos. Cascade R-CNN: high quality object detection and instance segmentation. 2019. IEEE Transactions on Pattern Analysis and Machine Intelligence. DOI: 10.1109/TPAMI.2019.2956516.Google Scholar"",""Kai Chen, Jiaqi Wang, Jiangmiao Pang, Yuhang Cao, Yu Xiong, Xiaoxiao Li, Shuyang Sun et al. 2019. Mmdetection: Open mmlab detection toolbox and benchmark. arXiv preprint arXiv:1906.07155 (2019).Google Scholar""]"
https://doi.org/10.1145/3394486.3406711,In Search for a Cure: Recommendation With Knowledge Graph on CORD-19,"The whole globe has cranked up for coping with the COVID-19 situation. The hands-on tutorial targets at providing a comprehensive and pragmatic end-to-end walk-through for building an academic research paper recommender for the use case of COVID-19 related study, with the help of knowledge graph technology. The code examples that demonstrate the theories are reproducible and can hopefully provide value for researchers to build tools that support conducting research to find a cure to COVID-19.","[{""name"":""Iris Shen"",""id"":""/profile/99659574092""},{""name"":""Le Zhang"",""id"":""/profile/99659537577""},{""name"":""Jianxun Lian"",""id"":""/profile/99658981410""},{""name"":""Chieh-Han Wu"",""id"":""/profile/99659573871""},{""name"":""Miguel Gonzalez Fierro"",""id"":""/profile/99659573414""},{""name"":""Andreas Argyriou"",""id"":""/profile/99659535733""},{""name"":""Tao Wu"",""id"":""/profile/81310483109""},{""name"":""Iris Shen"",""id"":""/profile/99659574092""},{""name"":""Le Zhang"",""id"":""/profile/99659537577""},{""name"":""Jianxun Lian"",""id"":""/profile/99658981410""},{""name"":""Chieh-Han Wu"",""id"":""/profile/99659573871""},{""name"":""Miguel Gonzalez Fierro"",""id"":""/profile/99659573414""},{""name"":""Andreas Argyriou"",""id"":""/profile/99659535733""},{""name"":""Tao Wu"",""id"":""/profile/81310483109""}]","[""2020. CORD-19 Data set. https://pages.semanticscholar.org/coronavirus-researchGoogle Scholar"",""2020. Microsoft Academic Graph. https://docs.microsoft.com/enus/academic-services/graph/.Google Scholar"",""2020. Microsoft Academic Graph Research on COVID-19. https://github.com/microsoft/mag-covid19-research-examplesGoogle Scholar"",""2020. Understanding Documents By Using Semantics. https://www.microsoft.com/en-us/research/project/academic/articles/understanding-documents-by-using-semantics/Google Scholar"",""Andreas Argyriou, Miguel González-Fierro, and Le Zhang. 2020. Microsoft Recommenders: Best Practices for Production-Ready Recommendation Systems. In Companion Proceedings of the Web Conference 2020. 50--51.Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In Advances in neural information processing systems. 1024--1034.Google Scholar"",""Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and MengWang. 2020. LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation. arXiv preprint arXiv:2002.02126 (2020).Google Scholar"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. 701--710.Google ScholarDigital Library"",""Jie Tang and Yuxiao Dong. 2019. Representation Learning on Networks: Theories, Algorithms, and Applications. In Companion Proceedings of The 2019 World Wide Web Conference. 1321--1322.Google ScholarDigital Library"",""HongweiWang, Fuzheng Zhang, Xing Xie, and Minyi Guo. 2018. DKN: Deep knowledge-aware network for news recommendation. In Proceedings of the 2018 world wide web conference. 1835--1844.Google Scholar"",""Kuansan Wang, Zhihong Shen, Chiyuan Huang, Chieh-Han Wu, Yuxiao Dong, and Anshul Kanakia. 2020. Microsoft academic graph: When experts are not enough. Quantitative Science Studies 1, 1 (2020), 396--413.Google ScholarCross Ref"",""Kuansan Wang, Zhihong Shen, Chi-Yuan Huang, Chieh-Han Wu, Darrin Eide, Yuxiao Dong, Junjie Qian, Anshul Kanakia, Alvin Chen, and Richard Rogahn. 2019. A review of Microsoft academic services for science of science studies. Frontiers in Big Data 2 (2019), 45.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3406712,Scalable Graph Neural Networks with Deep Graph Library,"Learning from graph and relational data plays a major role in many applications including social network analysis, marketing, e-commerce, information retrieval, knowledge modeling, medical and biological sciences, engineering, and others. In the last few years, Graph Neural Networks (GNNs) have emerged as a promising new supervised learning framework capable of bringing the power of deep representation learning to graph and relational data. This ever-growing body of research has shown that GNNs achieve state-of-the-art performance for problems such as link prediction, fraud detection, target-ligand binding activity prediction, knowledge-graph completion, and product recommendations. In practice, many of the real-world graphs are very large. It is urgent to have scalable solutions to train GNN on large graphs efficiently.The objective of this tutorial is twofold. First, it will provide an overview of the theory behind GNNs, discuss the types of problems that GNNs are well suited for, and introduce some of the most widely used GNN model architectures and problems/applications that are designed to solve. Second, it will introduce the Deep Graph Library (DGL), a scalable GNN framework that simplifies the development of efficient GNN-based training and inference programs at a large scale. To make things concrete, the tutorial will cover state-of-the-art training methods to scale GNN to large graphs and provide hands-on sessions to show how to use DGL to perform scalable training in different settings (multi-GPU training and distributed training). This hands-on part will start with basic graph applications (e.g., node classification and link prediction) to set up the context and move on to train GNNs on large graphs. It will provide tutorials to demonstrate how to apply the techniques in DGL to train GNNs for real-world applications.","[{""name"":""Da Zheng"",""id"":""/profile/99659533790""},{""name"":""Minjie Wang"",""id"":""/profile/99659534279""},{""name"":""Quan Gan"",""id"":""/profile/99659538029""},{""name"":""Zheng Zhang"",""id"":""/profile/99659535130""},{""name"":""Geroge Karypis"",""id"":""/profile/81548023798""},{""name"":""Da Zheng"",""id"":""/profile/99659533790""},{""name"":""Minjie Wang"",""id"":""/profile/99659534279""},{""name"":""Quan Gan"",""id"":""/profile/99659538029""},{""name"":""Zheng Zhang"",""id"":""/profile/99659535130""},{""name"":""Geroge Karypis"",""id"":""/profile/81548023798""}]","[""Jianfei Chen, Jun Zhu, and Le Song. 2018. Stochastic Training of Graph Convolutional Networks with Variance Reduction. In Proceedings of the 35th International Conference on Machine Learning (Proceedings of Machine Learning Research, Vol. 80), Jennifer Dy and Andreas Krause (Eds.). PMLR, Stockholmsmässan, Stockholm Sweden, 942--950.Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive Representation Learning on Large Graphs. In Advances in Neural Information Processing Systems 30, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.). 1024--1034.Google ScholarDigital Library"",""Ziqi Liu, Chaochao Chen, Xinxing Yang, Jun Zhou, Xiaolong Li, and Le Song. 2018. Heterogeneous Graph Neural Networks for Malicious Account Detection. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management (Torino, Italy). Association for Computing Machinery, New York, NY, USA, 2077--2085.Google ScholarDigital Library"",""Minjie Wang, Lingfan Yu, Da Zheng, Quan Gan, Yu Gai, Zihao Ye, Mufei Li, Jinjing Zhou, Qi Huang, Chao Ma, Ziyue Huang, Qipeng Guo, Hao Zhang, Haibin Lin, Junbo Zhao, Jinyang Li, Alexander J Smola, and Zheng Zhang. 2019. Deep Graph Library: Towards Efficient and Scalable Deep Learning on Graphs. ICLR Workshop on Representation Learning on Graphs and Manifolds (2019). https://arxiv.org/abs/1909.01315Google Scholar"",""Marinka Zitnik Yuxiao Dong Hongyu Ren Bowen Liu Michele Catasta Jure Leskovec Weihua Hu, Matthias Fey. 2020. Open Graph Benchmark: Datasets for Machine Learning on Graphs. arXiv preprint arXiv:2005.00687 (2020).Google Scholar"",""Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L. Hamilton, and Jure Leskovec. 2018. Graph Convolutional Neural Networks for Web-Scale Recommender Systems. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining (London, United Kingdom) (KDD '18). Association for Computing Machinery, New York, NY, USA, 974--983.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3406713,Introduction to Computer Vision and Real Time Deep Learning-based Object Detection,"Computer vision (CV) is a field of artificial intelligence that trains computers to interpret and understand the visual world for a variety of exciting downstream tasks such as self-driving cars, checkout-less shopping, smart cities, cancer detection, and more. The field of CV has been revolutionized by deep learning over the last decade. This tutorial looks under the hood of modern day CV systems, and builds out some of these tech pipelines in a Jupyter Notebook using Python, OpenCV, Keras and Tensorflow. While the primary focus is on digital images from cameras and videos, this tutorial will also introduce 3D point clouds, and classification and segmentation algorithms for processing them.","[{""name"":""James G. Shanahan"",""id"":""/profile/81554131456""},{""name"":""Liang Dai"",""id"":""/profile/99659154824""},{""name"":""James G. Shanahan"",""id"":""/profile/81554131456""},{""name"":""Liang Dai"",""id"":""/profile/99659154824""}]","[""Salman Khan, Hossein Rahmani, Syed Afaq Ali Shah (2018), A Guide to Convolutional Neural Networks for Computer Vision, Morgan and Claypool.Google Scholar"",""Adrian Rosebrock (2018), Deep Learning for Computer Vision with Python, https://www.pyimagesearch.com/deep-learning-computer-vision-python-book/Google Scholar"",""Ian Goodfellow, Yoshua Bengio., Aaron Courville (2016). Deep learning, MIT press. PDF available online: https://www.deeplearningbook.org/Google Scholar"",""Shaoqing, Ren, Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun (2015). \""Faster R-CNN\"". Advances in Neural Information Processing Systems, https://arxiv.org/abs/1506.01497.Google Scholar"",""Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, Alexander C. Berg (October 2016). SSD: Single shot multibox detector. European Conference on Computer Vision. Lecture Notes in Computer Science. 9905. pp. 21--37, https://arxiv.org/abs/1512.02325.Google ScholarCross Ref"",""Alexey Bochkovskiy, Chien-Yao Wang, Hong-Yuan Mark Liao (2020). \""Yolov4: Optimal Speed and Accuracy of Object Detection\"". https://arxiv.org/abs/2004.10934Google Scholar"",""Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko, 2020, End-to-End Object Detection with Transformers, https://arxiv.org/abs/2005.12872Google Scholar"",""Szeliski, R. (2010). Computer vision: algorithms and applications. Springer Science \u0026 Business Media. PDF available online: http://szeliski.org/Book/drafts/SzeliskiBook_20100903_draft.pdfGoogle Scholar""]"
https://doi.org/10.1145/3394486.3406714,Building Recommender Systems with PyTorch,"In this tutorial we show how to build deep learning recommendation systems and resolve the associated interpretability, integrity and privacy challenges. We start with an overview of the PyTorch framework, features that it offers and a brief review of the evolution of recommendation models. We delineate their typical components and build a proxy deep learning recommendation model (DLRM) in PyTorch. Then, we discuss how to interpret recommendation system results as well as how to address the corresponding integrity and quality challenges.","[{""name"":""Dheevatsa Mudigere"",""id"":""/profile/81350569960""},{""name"":""Maxim Naumov"",""id"":""/profile/81435603596""},{""name"":""Joe Spisak"",""id"":""/profile/99658769129""},{""name"":""Geeta Chauhan"",""id"":""/profile/99659574720""},{""name"":""Narine Kokhlikyan"",""id"":""/profile/99659573126""},{""name"":""Amanpreet Singh"",""id"":""/profile/99659574875""},{""name"":""Vedanuj Goswami"",""id"":""/profile/99659574203""},{""name"":""Dheevatsa Mudigere"",""id"":""/profile/81350569960""},{""name"":""Maxim Naumov"",""id"":""/profile/81435603596""},{""name"":""Joe Spisak"",""id"":""/profile/99658769129""},{""name"":""Geeta Chauhan"",""id"":""/profile/99659574720""},{""name"":""Narine Kokhlikyan"",""id"":""/profile/99659573126""},{""name"":""Amanpreet Singh"",""id"":""/profile/99659574875""},{""name"":""Vedanuj Goswami"",""id"":""/profile/99659574203""}]",null
https://doi.org/10.1145/3394486.3406460,Causal Inference Meets Machine Learning,"Causal inference has numerous real-world applications in many domains such as health care, marketing, political science and online advertising. Treatment effect estimation, a fundamental problem in causal inference, has been extensively studied in statistics for decades. However, traditional treatment effect estimation methods may not well handle large-scale and high-dimensional heterogeneous data. In recent years, an emerging research direction has attracted increasing attention in the broad artificial intelligence field, which combines the advantages of traditional treatment effect estimation approaches (e.g., matching estimators) and advanced representation learning approaches (e.g., deep neural networks). In this tutorial, we will introduce both traditional and state-of-the-art representation learning algorithms for treatment effect estimation. Background about causal inference, counterfactuals and matching estimators will be covered as well. We will also showcase promising applications of these methods in different application domains.","[{""name"":""Peng Cui"",""id"":""/profile/81413596063""},{""name"":""Zheyan Shen"",""id"":""/profile/99659317832""},{""name"":""Sheng Li"",""id"":""/profile/84460527457""},{""name"":""Liuyi Yao"",""id"":""/profile/99659364150""},{""name"":""Yaliang Li"",""id"":""/profile/89758731057""},{""name"":""Zhixuan Chu"",""id"":""/profile/99659575060""},{""name"":""Jing Gao"",""id"":""/profile/81314494134""},{""name"":""Peng Cui"",""id"":""/profile/81413596063""},{""name"":""Zheyan Shen"",""id"":""/profile/99659317832""},{""name"":""Sheng Li"",""id"":""/profile/84460527457""},{""name"":""Liuyi Yao"",""id"":""/profile/99659364150""},{""name"":""Yaliang Li"",""id"":""/profile/89758731057""},{""name"":""Zhixuan Chu"",""id"":""/profile/99659575060""},{""name"":""Jing Gao"",""id"":""/profile/81314494134""}]",null
https://doi.org/10.1145/3394486.3406461,Fairness in Machine Learning for Healthcare,"The issue of bias and fairness in healthcare has been around for centuries. With the integration of AI in healthcare the potential to discriminate and perpetuate unfair and biased practices in healthcare increases many folds The tutorial focuses on the challenges, requirements and opportunities in the area of fairness in healthcare AI and the various nuances associated with it. The problem healthcare as a multi-faceted systems level problem that necessitates careful of different notions of fairness in healthcare to corresponding concepts in machine learning is elucidated via different real world examples.","[{""name"":""Muhammad Aurangzeb Ahmad"",""id"":""/profile/99659302377""},{""name"":""Arpit Patel"",""id"":""/profile/99659573820""},{""name"":""Carly Eckert"",""id"":""/profile/99659302505""},{""name"":""Vikas Kumar"",""id"":""/profile/99659574038""},{""name"":""Ankur Teredesai"",""id"":""/profile/81100145567""},{""name"":""Muhammad Aurangzeb Ahmad"",""id"":""/profile/99659302377""},{""name"":""Arpit Patel"",""id"":""/profile/99659573820""},{""name"":""Carly Eckert"",""id"":""/profile/99659302505""},{""name"":""Vikas Kumar"",""id"":""/profile/99659574038""},{""name"":""Ankur Teredesai"",""id"":""/profile/81100145567""}]","[""Larry Adelman. 2007. Unnatural causes: Is inequality making us sick? Preventing Chronic Disease , Vol. 4, 4 (2007).Google Scholar"",""Denis Agniel, Isaac S Kohane, and Griffin M Weber. 2018. Biases in electronic health record data due to processes within the healthcare system: retrospective observational study. Bmj , Vol. 361 (2018).Google ScholarCross Ref"",""Muhammad Aurangzeb Ahmad, Carly Eckert, and Ankur Teredesai. 2018. Interpretable machine learning in healthcare. In Proceedings of the 2018 ACM international conference on bioinformatics, computational biology, and health informatics. 559--560.Google ScholarDigital Library"",""Arlene S Bierman. 2007. Sex matters: gender disparities in quality and outcomes of care. Cmaj , Vol. 177, 12 (2007), 1520--1521.Google ScholarCross Ref"",""Reuben Binns. 2018. Fairness in machine learning: Lessons from political philosophy. In Conference on Fairness, Accountability and Transparency. 149--159.Google Scholar"",""Esther H Chen, Frances S Shofer, Anthony J Dean, Judd E Hollander, William G Baxt, Jennifer L Robey, Keara L Sease, and Angela M Mills. 2008. Gender disparity in analgesic treatment of emergency department patients with acute abdominal pain. Academic Emergency Medicine , Vol. 15, 5 (2008), 414--418.Google ScholarCross Ref"",""Robyn M Dawes, David Faust, and Paul E Meehl. 1989. Clinical versus actuarial judgment. Science , Vol. 243, 4899 (1989), 1668--1674.Google Scholar"",""Rebecca Dresser. 1992. Wanted single, white male for medical research. The Hastings Center Report , Vol. 22, 1 (1992), 24--29.Google ScholarCross Ref"",""Thomas R Fleming and David L DeMets. 1993. Monitoring of clinical trials: issues and recommendations. Controlled clinical trials , Vol. 14, 3 (1993), 183--197.Google Scholar"",""Sorelle A Friedler, Carlos Scheidegger, and Suresh Venkatasubramanian. 2016. On the (im) possibility of fairness. arXiv preprint arXiv:1609.07236 (2016).Google Scholar"",""Lydia T Liu, Sarah Dean, Esther Rolf, Max Simchowitz, and Moritz Hardt. 2018. Delayed impact of fair machine learning. arXiv preprint arXiv:1803.04383 (2018).Google Scholar"",""Joshua H Tamayo-Sarver, Susan W Hinze, Rita K Cydulka, and David W Baker. 2003. Racial and ethnic disparities in emergency department analgesic prescription. American journal of public health , Vol. 93, 12 (2003), 2067--2073.Google Scholar""]"
https://doi.org/10.1145/3394486.3406462,Learning from All Types of Experiences: A Unifying Machine Learning Perspective,"Contemporary Machine Learning and AI research has resulted in thousands of models (e.g., numerous deep networks, graphical models), learning paradigms (e.g., supervised, unsupervised, active, reinforcement, adversarial learning), optimization techniques (e.g., all kinds of optimization or stochastic sampling algorithms), not mentioning countless approximation heuristics, tuning tricks, and black-box oracles, plus combinations of all above. While pushing the field forward rapidly, these results also contributed to making ML/AI more like an alchemist's crafting workshop rather than a modern chemist's periodic table. It not only makes mastering existing ML techniques extremely difficult, but also makes standardized, reusable, repeatable, reliable, and explainable practice and further development of ML/AI products extremely costly, if possible at all.This tutorial presents a systematic, unified blueprint of ML, for both a refreshing holistic understanding of the diverse ML paradigms/algorithms, and guidance of operationalizing ML for creating problem solutions in a composable manner.The tutorial consists of three parts. The first part provides an overview of the current landscape of ML paradigms, with a focus on motivating a systematic perspective. The second part presents the blueprint from three aspects: objective function, optimization solver, and model architecture. We describe standardized formulations of the diverse objectives and algorithms, and a composable view of model structures. On this basis, the third part focuses on the operational side of ML. We describe principled module abstraction of ML building blocks. We show the abstraction enables efficient composition of ML solutions to problems in healthcare, manufacturing, vision/text generation.","[{""name"":""Zhiting Hu"",""id"":""/profile/82659069557""},{""name"":""Eric P. Xing"",""id"":""/profile/81758947157""},{""name"":""Zhiting Hu"",""id"":""/profile/82659069557""},{""name"":""Eric P. Xing"",""id"":""/profile/81758947157""}]","[""Martin Arjovsky, Soumith Chintala, and Léon Bottou. 2017. Wasserstein GAN. arXiv preprint arXiv:1701.07875 (2017).Google Scholar"",""Casey Chu, Jose Blanchet, and Peter Glynn. 2019. Probability Functional Descent: A Unifying Perspective on GANs, Variational Inference, and Reinforcement Learning. ICML (2019).Google Scholar"",""Farzan Farnia and David Tse. 2018. A convex duality framework for GANs. In NeurIPS.Google Scholar"",""Kuzman Ganchev, Jennifer Gillenwater, Ben Taskar, et almbox. 2010. Posterior regularization for structured latent variable models. JMLR (2010).Google Scholar"",""Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial nets. In NeurIPS.Google Scholar"",""Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531 (2015).Google Scholar"",""Geoffrey E Hinton, Peter Dayan, Brendan J Frey, and Radford M Neal. 1995. The “wake-sleep” algorithm for unsupervised neural networks. Science (1995).Google Scholar"",""Zhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard Hovy, and Eric Xing. 2016. Harnessing deep neural networks with logic rules. In ACL.Google Scholar"",""Zhiting Hu, Haoran Shi, Bowen Tan, Wentao Wang, Zichao Yang, Tiancheng Zhao, Junxian He, Lianhui Qin, Di Wang, Xuezhe Ma, et almbox. 2019 a. Texar: A modularized, versatile, and extensible toolkit for text generation. ACL (2019).Google Scholar"",""Zhiting Hu, Bowen Tan, Russ R Salakhutdinov, Tom M Mitchell, and Eric P Xing. 2019 b. Learning data manipulation for augmentation and weighting. In NeurIPS.Google Scholar"",""Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, and Eric P Xing. 2017. Toward controlled generation of text. In ICML.Google Scholar"",""Zhiting Hu, Zichao Yang, Ruslan Salakhutdinov, and Eric P Xing. 2018a. On Unifying Deep Generative Models. In ICLR.Google Scholar"",""Zhiting Hu, Zichao Yang, Russ R Salakhutdinov, Lianhui Qin, Xiaodan Liang, Haoye Dong, and Eric P Xing. 2018b. Deep generative models with learnable knowledge constraints. In NeurIPS.Google Scholar"",""Michael I Jordan, Zoubin Ghahramani, Tommi S Jaakkola, and Lawrence K Saul. 1999. An introduction to variational methods for graphical models. Machine learning (1999).Google Scholar"",""Diederik P Kingma and Max Welling. 2013. Auto-encoding variational Bayes. arXiv preprint arXiv:1312.6114 (2013).Google Scholar"",""Sergey Levine. 2018. Reinforcement learning and control as probabilistic inference: Tutorial and review. arXiv preprint arXiv:1805.00909 (2018).Google Scholar"",""Christy Y Li, Xiaodan Liang, Zhiting Hu, and Eric P Xing. 2019. Knowledge-driven encode, retrieve, paraphrase for medical image report generation. In AAAI.Google Scholar"",""Deepak Pathak, Pulkit Agrawal, Alexei A Efros, and Trevor Darrell. 2017. Curiosity-driven exploration by self-supervised prediction. In ICML.Google Scholar"",""Marc'Aurelio Ranzato, Sumit Chopra, Michael Auli, and Wojciech Zaremba. 2015. Sequence level training with recurrent neural networks. arXiv preprint arXiv:1511.06732 (2015).Google Scholar"",""Rajhans Samdani, Ming-Wei Chang, and Dan Roth. 2012. Unified expectation maximization. In NAACL.Google Scholar"",""Jürgen Schmidhuber. 1991. A possibility for implementing curiosity and boredom in model-building neural controllers. In Proc. of the international conference on simulation of adaptive behavior: From animals to animats.Google Scholar"",""Burr Settles. 2009. Active learning literature survey. Technical Report. University of Wisconsin-Madison Department of Computer Sciences.Google ScholarDigital Library"",""Richard S Sutton and Andrew G Barto. 2018. Reinforcement learning: An introduction. MIT press.Google Scholar"",""Bowen Tan, Zhiting Hu, Zichao Yang, Ruslan Salakhutdinov, and Eric Xing. 2018. Connecting the Dots Between MLE and RL for Sequence Prediction. arXiv preprint arXiv:1811.09740 (2018).Google Scholar"",""Yue Wu, Pan Zhou, Andrew Gordon Wilson, Eric P Xing, and Zhiting Hu. 2020. Improving GAN Training with Probability Ratio Clipping and Sample Reweighting. arXiv preprint arXiv:2006.06900 (2020).Google Scholar"",""Eric P Xing, Qirong Ho, Wei Dai, Jin Kyu Kim, Jinliang Wei, Seunghak Lee, Xun Zheng, Pengtao Xie, Abhimanu Kumar, and Yaoliang Yu. 2015. Petuum: A new platform for distributed machine learning on big data. IEEE Transactions on Big Data (2015).Google Scholar"",""Jun Zhu, Ning Chen, and Eric P Xing. 2014. Bayesian inference with posterior regularization and applications to infinite latent SVMs. JMLR (2014).Google Scholar""]"
https://doi.org/10.1145/3394486.3406463,Advances in Recommender Systems: From Multi-stakeholder Marketplaces to Automated RecSys,"The tutorial focuses on two major themes of recent advances in recommender systems: Part A: Recommendations in a Marketplace: Multi-sided marketplaces are steadily emerging as valuable ecosystems in many applications (e.g. Amazon, AirBnb, Uber), wherein the platforms have customers not only on the demand side (e.g. users), but also on the supply side (e.g. retailer). This tutorial focuses on designing search & recommendation frameworks that power such multi-stakeholder platforms. We discuss multi-objective ranking/recommendation techniques, discuss different ways in which stakeholders specify their objectives, highlight user specific characteristics (e.g. user receptivity) which could be leveraged when developing joint optimization modules and finally present a number of real world case-studies of such multi-stakeholder platforms.Part B: Automated Recommendation System: As the recommendation tasks are getting more diverse and the recommending models are growing more complicated, it is increasingly challenging to develop a proper recommendation system that can adapt well to a new recommendation task. In this tutorial, we focus on how automated machine learning (AutoML) techniques can benefit the design and usage of recommendation systems. Specifically, we start from a full scope describing what can be automated for recommendation systems. Then, we elaborate more on three important topics under such a scope, i.e., feature engineering, hyperparameter optimization/neural architecture search, and algorithm selection. The core issues and recent works under these topics will be introduced, summarized, and discussed. Finally, we finalize the tutorial with conclusions and some future directions.","[{""name"":""Rishabh Mehrotra"",""id"":""/profile/99658716949""},{""name"":""Ben Carterette"",""id"":""/profile/81100270582""},{""name"":""Yong Li"",""id"":""/profile/81453640533""},{""name"":""Quanming Yao"",""id"":""/profile/99658751754""},{""name"":""Chen Gao"",""id"":""/profile/99659218073""},{""name"":""James Kwok"",""id"":""/profile/81100525095""},{""name"":""Qiang Yang"",""id"":""/profile/81548761456""},{""name"":""Isabelle Guyon"",""id"":""/profile/81100372193""},{""name"":""Rishabh Mehrotra"",""id"":""/profile/99658716949""},{""name"":""Ben Carterette"",""id"":""/profile/81100270582""},{""name"":""Yong Li"",""id"":""/profile/81453640533""},{""name"":""Quanming Yao"",""id"":""/profile/99658751754""},{""name"":""Chen Gao"",""id"":""/profile/99659218073""},{""name"":""James Kwok"",""id"":""/profile/81100525095""},{""name"":""Qiang Yang"",""id"":""/profile/81548761456""},{""name"":""Isabelle Guyon"",""id"":""/profile/81100372193""}]","[""Yihong Chen, Bei Chen, Xiangnan He, Chen Gao, Yong Li, Jian-Guang Lou, and Yue Wang. 2019. ?Opt: Learn to Regularize Recommender Models in Finer Levels. In KDD. 978--986.Google Scholar"",""Yuanfei Luo, Mengshuo Wang, Hao Zhou, Quanming Yao, Wei-Wei Tu, Yuqiang Chen, Wenyuan Dai, and Qiang Yang. 2019. Autocross: Automatic feature crossing for tabular data in real-world applications. In KDD. 1936--1945.Google ScholarDigital Library"",""Rishabh Mehrotra and Benjamin Carterette. 2019. Recommendations in a marketplace. In RecSys. 580--581.Google Scholar"",""Rishabh Mehrotra, James McInerney, Hugues Bouchard, Mounia Lalmas, and Fernando Diaz. 2018. Towards a fair marketplace: Counterfactual evaluation of the trade-off between relevance, fairness \u0026 satisfaction in recommendation systems. In CIKM. 2243--2251.Google Scholar"",""Rishabh Mehrotra, Niannan Xue, and Mounia Lalmas. 2020. Bandit based Optimization of Multiple Objectives on a Music Streaming Platform. In KDD.Google Scholar"",""Quanming Yao, Xiangning Chen, James T Kwok, Yong Li, and Cho-Jui Hsieh. 2020 a. Efficient neural interaction function search for collaborative filtering. In WWW.Google Scholar"",""Quanming Yao, Ju Xu, Wei-Wei Tu, and Zhanxing Zhu. 2020 b. Efficient Neural Architecture Search via Proximal Iterations. In AAAI. 6664--6671.Google Scholar""]"
https://doi.org/10.1145/3394486.3406464,Physics Inspired Models in Artificial Intelligence,"Ideas originating in physics have informed progress in artificial intelligence and machine learning for many decades. However the pedigree of many such ideas is oft neglected in the Computer Science community. The tutorial focuses on current and past ideas from physics that have helped in furthering AI and machine learning. Recent advances in physics inspired ideas in AI are also explored especially how insights from physics may hold the promise of opening the black box of deep learning. Lastly, current and future trends in this area and outlines of a research agenda on how physics-inspired models can benefit AI machine learning is given.","[{""name"":""Muhammad Aurangzeb Ahmad"",""id"":""/profile/99659302377""},{""name"":""Şener Özönder"",""id"":""/profile/99659574010""},{""name"":""Muhammad Aurangzeb Ahmad"",""id"":""/profile/99659302377""},{""name"":""Şener Özönder"",""id"":""/profile/99659574010""}]","[""YASER Abu-Mostafa and J St Jacques. 1985. Information capacity of the Hopfield model. IEEE Transactions on Information Theory, Vol. 31, 4 (1985), 461--464.Google ScholarDigital Library"",""Giuseppe Carleo, Ignacio Cirac, Kyle Cranmer, Laurent Daudet, Maria Schuld, Naftali Tishby, Leslie Vogt-Maranto, and Lenka Zdeborová. 2019. Machine learning and the physical sciences. Reviews of Modern Physics, Vol. 91, 4 (2019), 045002.Google ScholarCross Ref"",""Aurelien Decelle, Florent Krzakala, Cristopher Moore, and Lenka Zdeborová. 2011. Asymptotic analysis of the stochastic block model for modular networks and its algorithmic applications. Physical Review E, Vol. 84, 6 (2011), 066106.Google ScholarCross Ref"",""Andreas Engel and Christian Van den Broeck. 2001. Statistical mechanics of learning. Cambridge University Press.Google Scholar"",""Santo Fortunato. 2010. Community detection in graphs. Physics reports, Vol. 486, 3--5 (2010), 75--174.Google Scholar"",""Sebastian Goldt, Madhu Advani, Andrew M Saxe, Florent Krzakala, and Lenka Zdeborová. 2019. Dynamics of stochastic gradient descent for two-layer neural networks in the teacher-student setup. In Advances in Neural Information Processing Systems. 6981--6991.Google Scholar"",""Diederik P Kingma and Max Welling. 2013. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 (2013).Google Scholar"",""Florent Krzakala, Cristopher Moore, Elchanan Mossel, Joe Neeman, Allan Sly, Lenka Zdeborová, and Pan Zhang. 2013. Spectral redemption in clustering sparse networks. Proceedings of the National Academy of Sciences, Vol. 110, 52 (2013), 20935--20940.Google ScholarCross Ref"",""Chunyuan Li, Changyou Chen, David E Carlson, and Lawrence Carin. 2016. Preconditioned Stochastic Gradient Langevin Dynamics for Deep Neural Networks.. In AAAI, Vol. 2. 4.Google Scholar"",""Pankaj Mehta and David J Schwab. 2014. An exact mapping between the variational renormalization group and deep learning. arXiv preprint arXiv:1410.3831 (2014).Google Scholar"",""Michael Schmidt and Hod Lipson. 2009. Distilling free-form natural laws from experimental data. science, Vol. 324, 5923 (2009), 81--85.Google Scholar"",""Ravid Shwartz-Ziv and Naftali Tishby. 2017. Opening the black box of deep neural networks via information. arXiv preprint arXiv:1703.00810 (2017).Google Scholar"",""Naftali Tishby, Fernando C Pereira, and William Bialek. 2000. The information bottleneck method. arXiv preprint physics/0004057 (2000).Google Scholar"",""Jérôme Tubiana, Simona Cocco, and Rémi Monasson. 2019. Learning protein constitutive motifs from sequence data. Elife, Vol. 8 (2019), e39397.Google ScholarCross Ref"",""Silviu-Marian Udrescu and Max Tegmark. 2020. AI Feynman: A physics-inspired method for symbolic regression. Science Advances, Vol. 6, 16 (2020), eaay2631.Google Scholar"",""Leslie G Valiant. 1984. A theory of the learnable. Commun. ACM, Vol. 27, 11 (1984), 1134--1142.Google ScholarDigital Library"",""Chuang Wang, Hong Hu, and Yue Lu. 2019. A Solvable High-Dimensional Model of GAN. In Advances in Neural Information Processing Systems. 13782--13791.Google Scholar""]"
https://doi.org/10.1145/3394486.3406465,Scientific Text Mining and Knowledge Graphs,"Unstructured scientific text, in various forms of textual artifacts, including manuscripts, publications, patents, and proposals, is used to store the tremendous wealth of knowledge discovered after weeks, months, and years, developing hypotheses, working in the lab or clinic, and analyzing results. A grand challenge on data mining research is to develop effective methods for transforming the scientific text into well-structured forms (e.g., ontology, taxonomy, knowledge graphs), so that machine intelligent systems can build on them for hypothesis generation and validation. In this tutorial, we provide a comprehensive overview on recent research and development in this direction. First, we introduce a series of text mining methods that extract phrases, entities, scientific concepts, relations, claims, and experimental evidence. Then we discuss methods that construct and learn from scientific knowledge graphs for accurate search, document classification, and exploratory analysis. Specifically, we focus on scalable, effective, weakly supervised methods that work on text in sciences (e.g., chemistry, biology).","[{""name"":""Meng Jiang"",""id"":""/profile/81472650328""},{""name"":""Jingbo Shang"",""id"":""/profile/99658714527""},{""name"":""Meng Jiang"",""id"":""/profile/81472650328""},{""name"":""Jingbo Shang"",""id"":""/profile/99658714527""}]","[""Iz Beltagy, Kyle Lo, and Arman Cohan. 2019. SciBERT: A pretrained language model for scientific text. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 3606--3611.Google ScholarCross Ref"",""Gene Ontology Consortium. 2017. Expansion of the Gene Ontology knowledgebase and resources. Nucleic acids research, Vol. 45, D1 (2017), D331--D338.Google Scholar"",""Patrick Ernst, Amy Siu, and Gerhard Weikum. 2015. Knowlife: a versatile approach for constructing a large knowledge graph for biomedical sciences. BMC bioinformatics, Vol. 16, 1 (2015), 157.Google Scholar"",""Meng Jiang, Jingbo Shang, Taylor Cassidy, Xiang Ren, Lance M Kaplan, Timothy P Hanratty, and Jiawei Han. 2017. Metapad: Meta pattern discovery from massive text corpora. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD). 877--886.Google ScholarDigital Library"",""Tianwen Jiang, Zhihan Zhang, Tong Zhao, Bing Qin, Ting Liu, Nitesh V Chawla, and Meng Jiang. 2019 a. CTGA: Graph-based Biomedical Literature Search. In Proceedings of the 2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). IEEE, 395--400.Google ScholarCross Ref"",""Tianwen Jiang, Tong Zhao, Bing Qin, Ting Liu, Nitesh Chawla, and Meng Jiang. 2019 b. Multi-Input Multi-Output Sequence Labeling for Joint Extraction of Fact and Condition Tuples from Scientific Text. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 302--312.Google ScholarCross Ref"",""Tianwen Jiang, Tong Zhao, Bing Qin, Ting Liu, Nitesh V Chawla, and Meng Jiang. 2019 c. The Role of \""Condition\"": A Novel Scientific Knowledge Graph Representation and Construction Model. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining (KDD). 1634--1642.Google ScholarDigital Library"",""Rik Koncel-Kedziorski, Dhanush Bekal, Yi Luan, Mirella Lapata, and Hannaneh Hajishirzi. 2019. Text generation from knowledge graphs with graph transformers. In NAACL.Google Scholar"",""Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So, and Jaewoo Kang. 2020. BioBERT: a pre-trained biomedical language representation model for biomedical text mining. Bioinformatics, Vol. 36, 4 (2020), 1234--1240.Google Scholar"",""Peiran Li, Fang Guo, and Jingbo Shang. 2020. User-Guided Aspect Classification for Domain-Specific Texts. arXiv preprint arXiv:2004.14555 (2020).Google Scholar"",""Jialu Liu, Jingbo Shang, and Jiawei Han. 2017. Phrase mining from massive text and its applications. Synthesis Lectures on Data Mining and Knowledge Discovery, Vol. 9, 1 (2017), 1--89.Google ScholarCross Ref"",""Yi Luan, Luheng He, Mari Ostendorf, and Hannaneh Hajishirzi. 2018. Multi-task identification of entities, relations, and coreference for scientific knowledge graph construction. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing and the 8th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP).Google ScholarCross Ref"",""Yi Luan, Mari Ostendorf, and Hannaneh Hajishirzi. 2017. Scientific information extraction with semi-supervised neural tagging. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing and the 7th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP).Google ScholarCross Ref"",""Dheeraj Mekala and Jingbo Shang. 2020. Contextualized Weak Supervision for Text Classification. In ACL.Google Scholar"",""Hoifung Poon and Pedro Domingos. 2010. Unsupervised ontology induction from text. In Proceedings of the 48th annual meeting of the Association for Computational Linguistics. Association for Computational Linguistics, 296--305.Google Scholar"",""Maya Rotmensch, Yoni Halpern, Abdulhakim Tlimat, Steven Horng, and David Sontag. 2017. Learning a health knowledge graph from electronic medical records. Scientific reports, Vol. 7, 1 (2017), 1--11.Google Scholar"",""Jingbo Shang, Jialu Liu, Meng Jiang, Xiang Ren, Clare R Voss, and Jiawei Han. 2018a. Automated phrase mining from massive text corpora. IEEE Transactions on Knowledge and Data Engineering (TKDE), Vol. 30, 10 (2018), 1825--1837.Google ScholarCross Ref"",""Jingbo Shang, Liyuan Liu, Xiang Ren, Xiaotao Gu, Teng Ren, and Jiawei Han. 2018b. Learning named entity tagger using domain-specific dictionary. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing and the 8th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP).Google ScholarCross Ref"",""Jingbo Shang, Xinyang Zhang, Liyuan Liu, Sha Li, and Jiawei Han. 2020. NetTaxo: Automated Topic Taxonomy Construction from Large-Scale Text-Rich Network. In The Web Conference (TheWebConf).Google Scholar"",""Jiaming Shen, Zhihong Shen, Chenyan Xiong, Chi Wang, Kuansan Wang, and Jiawei Han. 2020. TaxoExpan: Self-supervised Taxonomy Expansion with Position-Enhanced Graph Neural Network. In The Web Conference (TheWebConf).Google Scholar"",""Pingjie Tang, Meng Jiang, Ning Xia, Pitera J., Welser J., and Nitesh V Chawla. Multi-label Patent Categorization with Non-local Attention-based Graph Convolutional Network. In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI). AAAI.Google Scholar"",""Qingyun Wang, Lifu Huang, Zhiying Jiang, Kevin Knight, Heng Ji, Mohit Bansal, and Yi Luan. 2019 a. Paperrobot: Incremental draft generation of scientific ideas. In ACL.Google Scholar"",""Xuan Wang, Yu Zhang, Qi Li, Xiang Ren, Jingbo Shang, and Jiawei Han. 2019 c. Distantly Supervised Biomedical Named Entity Recognition with Dictionary Expansion. In 2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). IEEE, 496--503.Google Scholar"",""Zihan Wang, Jingbo Shang, Liyuan Liu, Lihao Lu, Jiacheng Liu, and Jiawei Han. 2019 b. CrossWeigh: Training Named Entity Tagger from Imperfect Annotations. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 5157--5166.Google ScholarCross Ref"",""Wenhao Yu, Zongze Li, Qingkai Zeng, and Meng Jiang. 2019. Tablepedia: Automating pdf table reading in an experimental evidence exploration and analytic system. In The World Wide Web Conference (WWW). 3615--3619.Google ScholarDigital Library"",""Wenhao Yu, Wei Peng, Yu Shu, Qingkai Zeng, and Meng Jiang. 2020 a. Experimental Evidence Extraction in Data Science with Hybrid Table Features and Ensemble Learning. In The Web Conference (TheWebConf).Google Scholar"",""Wenhao Yu, Lingfei Wu, Qingkai Zeng, Shu Tao, Yu Deng, and Meng Jiang. 2020 b. Crossing Variational Autoencoders for Answer Retrieval. In ACL.Google Scholar"",""Qingkai Zeng, Mengxia Yu, Wenhao Yu, Jinjun Xiong, Yiyu Shi, and Meng Jiang. 2019. Faceted hierarchy: A new graph type to organize scientific concepts and a construction method. In Proceedings of the Thirteenth Workshop on Graph-Based Methods for Natural Language Processing (TextGraphs-13). 140--150.Google ScholarCross Ref"",""Chao Zhang, Fangbo Tao, Xiusi Chen, Jiaming Shen, Meng Jiang, Brian Sadler, Michelle Vanni, and Jiawei Han. 2018. Taxogen: Constructing topical concept taxonomy by adaptive term embedding and clustering. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD).Google ScholarDigital Library"",""Yunyi Zhang, Jiaming Shen, Jingbo Shang, and Jiawei Han. 2020. Empower Entity Set Expansion via Language Model Probing. In ACL.Google Scholar""]"
https://doi.org/10.1145/3394486.3406466,Learning with Small Data,"In the era of big data, data-driven methods have become increasingly popular in various applications, such as image recognition, traffic signal control, fake news detection. The superior performance of these data-driven approaches relies on large-scale labeled training data, which are probably inaccessible in real-world applications, i.e., ""small (labeled) data"" challenge. Examples include predicting emergent events in a city, detecting emerging fake news, and forecasting the progression of conditions for rare diseases. In most scenarios, people care about these small data cases most and thus improving the learning effectiveness of machine learning algorithms with small labeled data has been a popular research topic.In this tutorial, we will review the trending state-of-the-art machine learning techniques for learning with small (labeled) data. These techniques are organized from two aspects: (1) providing a comprehensive review of recent studies about knowledge generalization, transfer, and sharing, where transfer learning, multi-task learning, and meta-learning are discussed. Particularly, we will focus more on meta-learning, which improves the model generalization ability and has been proven to be an effective approach recently; (2) introducing the cutting-edge techniques which focus on incorporating domain knowledge into machine learning models. Different from model-based knowledge transfer techniques, in real-world applications, domain knowledge (e.g., physical laws) provides us with a new angle to deal with the small data challenge. Specifically, domain knowledge can be used to optimize learning strategies and/or guide the model design. In data mining field, we believe that learning with small data is a trending topic with important social impact, which will attract both researchers and practitioners from academia and industry.","[{""name"":""Huaxiu Yao"",""id"":""/profile/99659287557""},{""name"":""Xiaowei Jia"",""id"":""/profile/99658654989""},{""name"":""Vipin Kumar"",""id"":""/profile/81452613746""},{""name"":""Zhenhui Li"",""id"":""/profile/82858874857""},{""name"":""Huaxiu Yao"",""id"":""/profile/99659287557""},{""name"":""Xiaowei Jia"",""id"":""/profile/99658654989""},{""name"":""Vipin Kumar"",""id"":""/profile/81452613746""},{""name"":""Zhenhui Li"",""id"":""/profile/82858874857""}]","[""Anurag Ajay, Jiajun Wu, Nima Fazeli, Maria Bauza, Leslie P Kaelbling, Joshua B Tenenbaum, and Alberto Rodriguez. 2018. Augmenting physical simulators with stochastic neural networks: Case study of planar pushing and bouncing. In IROS.Google Scholar"",""Y Ba, G Zhao, and A Kadambi. 2019. Blending diverse physical priors with neural networks. arXiv:1910.00201 (2019).Google Scholar"",""Hakan Bilen and Andrea Vedaldi. 2016. Integrated perception with recurrent multi-task neural networks. In NeurIPS. 235--243.Google Scholar"",""Avishek Joey Bose, Ankit Jain, Piero Molino, and William L Hamilton. 2019. Meta-Graph: Few shot Link Prediction via Meta Learning. arXiv preprint arXiv:1912.09867 (2019).Google Scholar"",""Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017. Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks. In ICML. 1126--1135.Google Scholar"",""Mingsheng Long, Yue Cao, Jianmin Wang, and Michael I Jordan. 2015. Learning transferable features with deep adaptation networks. In ICML.Google Scholar"",""Ishan Misra, Abhinav Shrivastava, Abhinav Gupta, and Martial Hebert. 2016. Cross-stitch networks for multi-task learning. In CVPR. 3994--4003.Google Scholar"",""Tsendsuren Munkhdalai, Xingdi Yuan, Soroush Mehri, and Adam Trischler. 2018. Rapid adaptation with conditionally shifted neurons. In ICML. 3661--3670.Google Scholar"",""Nikhil Muralidhar, Jie Bu, Ze Cao, Long He, Naren Ramakrishnan, Danesh Tafti, and Anuj Karpatne. 2019. Physics-guided Design and Learning of Neural Networks for Predicting Drag Force on Particle Suspensions in Moving Fluids. arXiv preprint arXiv:1911.04240 (2019).Google Scholar"",""L Ruthotto and E Haber. 2018. Deep neural networks motivated by partial differential equations. Journal of Mathematical Imaging and Vision (2018).Google Scholar"",""Jake Snell, Kevin Swersky, and Richard Zemel. 2017. Prototypical networks for few-shot learning. In NeurIPS. 4077--4087.Google Scholar"",""Gjorgji Strezoski, Nanne van Noord, and Marcel Worring. 2019. Many task learning with task routing. In ICCV. 1375--1384.Google Scholar"",""Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell. 2017. Adversarial discriminative domain adaptation. In CVPR.Google Scholar"",""Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et almbox. 2016. Matching networks for one shot learning. In NeurIPS. 3630--3638.Google Scholar"",""Huaxiu Yao, Yiding Liu, Ying Wei, Xianfeng Tang, and Zhenhui Li. 2019 a. Learning from Multiple Cities: A Meta-Learning Approach for Spatial-Temporal Prediction. In WWW. 2181--2191.Google Scholar"",""Huaxiu Yao, Ying Wei, Junzhou Huang, and Zhenhui Li. 2019 b. Hierarchically Structured Meta-learning. In ICML. 7045--7054.Google Scholar"",""Huaxiu Yao, Xian Wu, Zhiqiang Tao, Yaliang Li, Bolin Ding, Ruirui Li, and Zhenhui Li. 2020. Automated Relational Meta-learning. In ICLR.Google Scholar"",""Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson. 2014. How transferable are features in deep neural networks?. In NeurIPS. 3320--3328.Google Scholar"",""Xi Sheryl Zhang, Fengyi Tang, Hiroko H Dodge, Jiayu Zhou, and Fei Wang. 2019. Metapred: Meta-learning for clinical risk prediction with limited patient electronic health records. In KDD.Google Scholar""]"
https://doi.org/10.1145/3394486.3406467,"Adversarial Attacks and Defenses: Frontiers, Advances and Practice","Deep neural networks (DNN) have achieved unprecedented success in numerous machine learning tasks in various domains. However, the existence of adversarial examples leaves us a big hesitation when applying DNN models on safety-critical tasks such as autonomous vehicles and malware detection. These adversarial examples are intentionally crafted instances, either appearing in the train or test phase, which can fool the DNN models to make severe mistakes. Therefore, people are dedicated to devising more robust models to resist adversarial examples, but usually they are broken by new stronger attacks. This arms-race between adversarial attacks and defenses has been drawn increasing attention in recent years. In this tutorial, we provide a comprehensive overview on the frontiers and advances of adversarial attacks and their countermeasures. In particular, we give a detailed introduction of different types of attacks under different scenarios, including evasion and poisoning attacks, white-box and black box attacks. We will also discuss how the defending strategies develop to compete against these attacks, and how new attacks come out to break these defenses. Moreover, we will discuss the story of adversarial attacks and defenses in other data domains, especially in graph structured data. Then, we introduce DeepRobust, a Pytorch adversarial learning library which aims to build a comprehensive and easy-to-use platform to foster this research field. Finally, we summarize the tutorial with discussions on open issues and challenges about adversarial attacks and defenses. Via our tutorial, our audience can grip the main idea and key approaches of the game between adversarial attacks and defenses.","[{""name"":""Han Xu"",""id"":""/profile/99659574909""},{""name"":""Yaxin Li"",""id"":""/profile/99659575280""},{""name"":""Wei Jin"",""id"":""/profile/99659535601""},{""name"":""Jiliang Tang"",""id"":""/profile/81496640622""},{""name"":""Han Xu"",""id"":""/profile/99659574909""},{""name"":""Yaxin Li"",""id"":""/profile/99659575280""},{""name"":""Wei Jin"",""id"":""/profile/99659535601""},{""name"":""Jiliang Tang"",""id"":""/profile/81496640622""}]","[""Anish Athalye, Nicholas Carlini, and David Wagner. 2018. Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples. arXiv preprint arXiv:1802.00420 (2018).Google Scholar"",""Nicholas Carlini and David Wagner. 2017. Towards evaluating the robustness of neural networks. In 2017 ieee symposium on security and privacy (sp). IEEE, 39--57.Google Scholar"",""Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2014. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572 (2014).Google Scholar"",""Wei Jin, Yaxin Li, Han Xu, Yiqi Wang, and Jiliang Tang. 2020. Adversarial Attacks and Defenses on Graphs: A Review and Empirical Study. arXiv preprint arXiv:2003.00653 (2020).Google Scholar"",""Yaxin Li, Wei Jin, Han Xu, and Jiliang Tang. 2020. DeepRobust: A PyTorch Library for Adversarial Attacks and Defenses. arXiv preprint arXiv:2005.06149 (2020).Google Scholar"",""Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. 2013. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199 (2013).Google Scholar"",""Han Xu, Haochen Liu, Yao Ma, Deb Debayan, Anil Jain, and Hui Liu Ji-Liang Tang. 2020. Adversarial attacks and defenses in images, graphs and text: A review. International Journal of Automation and Computing (2020).Google Scholar""]"
https://doi.org/10.1145/3394486.3406468,"Multi-modal Information Extraction from Text, Semi-structured, and Tabular Data on the Web","How do we surface the large amount of information present in HTML documents on the Web, from news articles to Rotten Tomatoes pages to tables of sports scores? Such information can enable a variety of applications including knowledge base construction, question answering, recommendation, and more. In this tutorial, we present approaches for information extraction (IE) from Web data that can be differentiated along two key dimensions: 1) the diversity in data modality that is leveraged, e.g. text, visual, XML/HTML, and 2) the thrust to develop scalable approaches with zero to limited human supervision.","[{""name"":""Xin Luna Dong"",""id"":""/profile/99659531494""},{""name"":""Hannaneh Hajishirzi"",""id"":""/profile/81443598377""},{""name"":""Colin Lockard"",""id"":""/profile/99659290810""},{""name"":""Prashant Shiralkar"",""id"":""/profile/99659290508""},{""name"":""Xin Luna Dong"",""id"":""/profile/99659531494""},{""name"":""Hannaneh Hajishirzi"",""id"":""/profile/81443598377""},{""name"":""Colin Lockard"",""id"":""/profile/99659290810""},{""name"":""Prashant Shiralkar"",""id"":""/profile/99659290508""}]","[""Mirko Bronzi, Valter Crescenzi, Paolo Merialdo, and Paolo Papotti. 2013. Extraction and integration of partially overlapping web sources. PVLDB 6, 10 (2013), 805--816.Google ScholarDigital Library"",""Michael Cafarella, Alon Halevy, Hongrae Lee, Jayant Madhavan, Cong Yu, Daisy Zhe Wang, and Eugene Wu. 2018. Ten years of webtables. PVLDB 11, 12 (2018), 2140--2149.Google ScholarDigital Library"",""Pankaj Gulhane, Amit Madaan, Rupesh Mehta, Jeyashankher Ramamirtham, Rajeev Rastogi, Sandeep Satpal, Srinivasan H Sengamedu, Ashwin Tengli, and Charu Tiwari. 2011. Web-scale information extraction with vertex. In ICDM. IEEE, 1209--1220.Google Scholar"",""Anoop R. Katti, Christian Reisswig, Cordula Guder, Sebastian Brarda, Steffen Bickel, Johannes Höhne, and Jean Baptiste Faddoul. 2018. Chargrid: Towards Understanding 2D Documents. In EMNLP.Google Scholar"",""Colin Lockard, Xin Luna Dong, Arash Einolghozati, and Prashant Shiralkar. 2018. CERES: Distantly supervised relation extraction from the semi-structured web. PVLDB 11, 10 (2018), 1084--1096.Google ScholarDigital Library"",""Colin Lockard, Prashant Shiralkar, Xin Luna Dong, and Hannaneh Hajishirzi. 2020. ZeroShotCeres: Zero-Shot Relation Extraction from Semi-Structured Webpages. In ACL. Association for Computational Linguistics, Online, 8105--8117. https: //www.aclweb.org/anthology/2020.acl-main.721Google Scholar"",""Yi Luan, Dave Wadden, Luheng He, Amy Shah, Mari Ostendorf, and Hannaneh Hajishirzi. 2019. A general framework for information extraction using dynamic span graphs. In NAACL-HLT.Google Scholar"",""Yujie Qian, Enrico Santus, Zhijing Jin, Jiang Guo, and Regina Barzilay. 2018. GraphIE: A Graph-Based Framework for Information Extraction. In NAACL-HLT.Google Scholar"",""Sen Wu, Luke Hsiao, Xiao Cheng, Braden Hancock, Theodoros Rekatsinas, Philip Levis, and Christopher Ré. 2018. Fonduer: Knowledge Base Construction from Richly Formatted Data. SIGMOD 2018 (2018), 1301--1316.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3406469,Recent Advances on Graph Analytics and Its Applications in Healthcare,"Graph is a natural representation encoding both the features of the data samples and relationships among them. Analysis with graphs is a classic topic in data mining and many techniques have been proposed in the past. In recent years, because of the rapid development of data mining and knowledge discovery, many novel graph analytics algorithms have been proposed and successfully applied in a variety of areas. The goal of this tutorial is to summarize the graph analytics algorithms developed recently and how they have been applied in healthcare. In particular, our tutorial will cover both the technical advances and the application in healthcare. On the technical aspect, we will introduce deep network embedding techniques, graph neural networks, knowledge graph construction and inference, graph generative models and graph neural ordinary differential equation models. On the healthcare side, we will introduce how these methods can be applied in predictive modeling of clinical risks (e.g., chronic disease onset, in-hospital mortality, condition exacerbation, etc.) and disease subtyping with multi-modal patient data (e.g., electronic health records, medical image and multi-omics), knowledge discovery from biomedical literature and integration with data-driven models, as well as pharmaceutical research and development (e.g., de-novo chemical compound design and optimization, patient similarity for clinical trial recruitment and pharmacovigilance). We will conclude the whole tutorial with a set of potential issues and challenges such as interpretability, fairness and security. In particular, considering the global pandemic of COVID-19, we will also summarize the existing research that have already leveraged graph analytics to help with the understanding the mechanism, transmission, treatment and prevention of COVID-19, as well as point out the available resources and potential opportunities for future research.","[{""name"":""Fei Wang"",""id"":""/profile/99658710924""},{""name"":""Peng Cui"",""id"":""/profile/81413596063""},{""name"":""Jian Pei"",""id"":""/profile/81100323054""},{""name"":""Yangqiu Song"",""id"":""/profile/81317500799""},{""name"":""Chengxi Zang"",""id"":""/profile/99659060484""},{""name"":""Fei Wang"",""id"":""/profile/99658710924""},{""name"":""Peng Cui"",""id"":""/profile/81413596063""},{""name"":""Jian Pei"",""id"":""/profile/81100323054""},{""name"":""Yangqiu Song"",""id"":""/profile/81317500799""},{""name"":""Chengxi Zang"",""id"":""/profile/99659060484""}]","[""Bing Bai, Jian Liang, Guanhua Zhang, Hao Li, Kun Bai, and FeiWang. 2020. Why is Attention Not So Attentive? arXiv preprint arXiv:2006.05656 (2020).Google Scholar"",""Inci M Baytas, Cao Xiao, Fei Wang, Anil K Jain, and Jiayu Zhou. 2018. Heterogeneous Hyper-Network Embedding. In 2018 IEEE International Conference on Data Mining (ICDM). IEEE, 875--880.Google Scholar"",""Heng Chang, Yu Rong, Tingyang Xu, Wenbing Huang, Honglei Zhang, Peng Cui, Wenwu Zhu, and Junzhou Huang. 2019. The General Black-box Attack Method for Graph Neural Networks. arXiv preprint arXiv:1908.01297 (2019).Google Scholar"",""Hongliang Dai, Donghong Du, Xin Li, and Yangqiu Song. 2019. Improving Fine-grained Entity Typing with Entity Linking. arXiv preprint arXiv:1909.12079 (2019).Google Scholar"",""Mutian He, Yangqiu Song, Kun Xu, and Yu Dong. 2020. On the Role of Conceptualization in Commonsense Knowledge Graph Construction. arXiv preprint arXiv:2003.03239 (2020).Google Scholar"",""Jian Liang, Bing Bai, Yuren Cao, Kun Bai, and Fei Wang. 2020. Adversarial Infidelity Learning for Model Interpretation. arXiv preprint arXiv:2006.05379 (2020).Google Scholar"",""Jianxin Ma, Peng Cui, XiaoWang, andWenwu Zhu. 2018. Hierarchical taxonomy aware network embedding. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1920--1929.Google ScholarDigital Library"",""Chang Su, Jie Tong, Yongjun Zhu, Peng Cui, and Fei Wang. 2020. Network embedding in biomedical data science. Briefings in bioinformatics 21, 1 (2020), 182--197.Google Scholar"",""Mengying Sun, Fengyi Tang, Jinfeng Yi, FeiWang, and Jiayu Zhou. 2018. Identify susceptible locations in medical records via adversarial attacks on deep predictive models. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 793--801.Google ScholarDigital Library"",""Ke Tu, Peng Cui, Xiao Wang, Fei Wang, and Wenwu Zhu. 2018. Structural deep embedding for hyper-networks. In Thirty-Second AAAI Conference on Artificial Intelligence.Google Scholar"",""Xiang Yue, ZhenWang, Jingong Huang, Srinivasan Parthasarathy, Soheil Moosavinasab, Yungui Huang, Simon M Lin, Wen Zhang, Ping Zhang, and Huan Sun. 2020. Graph embedding on biomedical networks: methods, applications and evaluations. Bioinformatics 36, 4 (2020), 1241--1251.Google Scholar"",""Chengxi Zang, Peng Cui, Wenwu Zhu, and Fei Wang. 2019. Dynamical Origins of Distribution Functions. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 469--478.Google ScholarDigital Library"",""Chengxi Zang and Fei Wang. 2020. MoFlow: An Invertible Flow Model for Generating Molecular Graphs. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining.Google ScholarDigital Library"",""Chengxi Zang and Fei Wang. 2020. Neural Dynamics on Complex Networks. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining.Google ScholarDigital Library"",""Hongming Zhang, Xin Liu, Haojie Pan, Yangqiu Song, Cane Wing-Ki, et al. 2019. ASER: A Large-scale Eventuality Knowledge Graph. arXiv preprint arXiv:1905.00270 (2019).Google Scholar"",""Ziwei Zhang, Peng Cui, Xiao Wang, Jian Pei, Xuanrong Yao, and Wenwu Zhu. 2018. Arbitrary-order proximity preserved network embedding. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 2778--2786.Google ScholarDigital Library"",""Yongjun Zhu, Olivier Elemento, Jyotishman Pathak, and Fei Wang. 2019. Drug knowledge bases and their applications in biomedical informatics research. Briefings in bioinformatics 20, 4 (2019), 1308--1321.Google Scholar""]"
https://doi.org/10.1145/3394486.3406470,Tutorial on Human-Centered Explainability for Healthcare,"In recent years, the rapid advances in Artificial Intelligence (AI) techniques along with an ever-increasing availability of healthcare data have made many novel analyses possible. Significant successes have been observed in a wide range of tasks such as next diagnosis prediction, AKI prediction, adverse event predictions including mortality and unexpected hospital re-admissions. However, there has been limited adoption and use in the clinical practice of these methods due to their black-box nature. A significant amount of research is currently focused on making such methods more interpretable or to make post-hoc explanations more accessible. However, most of this work is done at a very low level and as a result, may not have a direct impact at the point-of-care. This tutorial will provide an overview of the landscape of different approaches that have been developed for explainability in healthcare. Specifically, we will present the problem of explainability as it pertains to various personas involved in healthcare viz. data scientists, clinical researchers, and clinicians. We will chart out the requirements for such personas and present an overview of the different approaches that can address such needs. We will also walk-through several use-cases for such approaches. In this process, we will provide a brief introduction to explainability, charting its different dimensions as well as covering some relevant interpretability methods spanning such dimensions. We will touch upon some practical guides for explainability and provide a brief survey of open source tools such as the IBM AI Explainability 360 Open Source Toolkit.","[{""name"":""Prithwish Chakraborty"",""id"":""/profile/99659574489""},{""name"":""Bum Chul Kwon"",""id"":""/profile/81416604999""},{""name"":""Sanjoy Dey"",""id"":""/profile/99659335360""},{""name"":""Amit Dhurandhar"",""id"":""/profile/81414621169""},{""name"":""Daniel Gruen"",""id"":""/profile/81100266978""},{""name"":""Kenney Ng"",""id"":""/profile/99658747284""},{""name"":""Daby Sow"",""id"":""/profile/81100081640""},{""name"":""Kush R. Varshney"",""id"":""/profile/81466641640""},{""name"":""Prithwish Chakraborty"",""id"":""/profile/99659574489""},{""name"":""Bum Chul Kwon"",""id"":""/profile/81416604999""},{""name"":""Sanjoy Dey"",""id"":""/profile/99659335360""},{""name"":""Amit Dhurandhar"",""id"":""/profile/81414621169""},{""name"":""Daniel Gruen"",""id"":""/profile/81100266978""},{""name"":""Kenney Ng"",""id"":""/profile/99658747284""},{""name"":""Daby Sow"",""id"":""/profile/81100081640""},{""name"":""Kush R. Varshney"",""id"":""/profile/81466641640""}]","[""Amina Adadi and Mohammed Berrada. 2018. Peeking inside the black-box: A survey on Explainable Artificial Intelligence (XAI). IEEE Access, Vol. 6 (2018), 52138--52160.Google ScholarCross Ref"",""Vijay Arya, Rachel K. E. Bellamy, Pin-Yu Chen, Amit Dhurandhar, Michael Hind, Samuel C. Hoffman, Stephanie Houde, Q. Vera Liao, Ronny Luss, Aleksandra Mojsilović, Sami Mourad, Pablo Pedemonte, Ramya Raghavendra, John Richards, Prasanna Sattigeri, Karthikeyan Shanmugam, Moninder Singh, Kush R. Varshney, Dennis Wei, and Yunfeng Zhang. 2019. One Explanation Does Not Fit All: A Toolkit and Taxonomy of AI Explainability Techniques. https://arxiv.org/abs/1909.03012Google Scholar"",""Hamsa Bastani, Osbert Bastani, and Carolyn Kim. 2018. Interpreting predictive models for human-in-the-loop analytics. arXiv preprint arXiv:1705.08504 (2018), 1--45.Google Scholar"",""Edward Choi, Mohammad Taha Bahadori, Jimeng Sun, Joshua Kulas, Andy Schuetz, and Walter Stewart. 2016. Retain: An interpretable predictive model for healthcare using reverse time attention mechanism. In Advances in Neural Information Processing Systems. 3504--3512.Google Scholar"",""Sarthak Jain and Byron C Wallace. 2019. Attention is not Explanation. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). 3543--3556.Google Scholar"",""Bum Chul Kwon, Min-Je Choi, Joanne Taery Kim, Edward Choi, Young Bin Kim, Soonwook Kwon, Jimeng Sun, and Jaegul Choo. 2019. Retainvis: Visual analytics with interpretable and interactive recurrent neural networks on electronic medical records. IEEE transactions on visualization and computer graphics, Vol. 25, 1 (2019), 299--309.Google Scholar"",""Scott M Lundberg and Su-In Lee. 2017. A unified approach to interpreting model predictions. In Advances in Neural Information Processing Systems. 4765--4774.Google Scholar"",""Shamim Nemati, Andre Holder, Fereshteh Razmi, Matthew D Stanley, Gari D Clifford, and Timothy G Buchman. 2018. An Interpretable Machine Learning Model for Accurate Prediction of Sepsis in the ICU. Critical care medicine, Vol. 46, 4 (2018), 547--553.Google Scholar"",""Alvin Rajkomar, Eyal Oren, Kai Chen, Andrew M Dai, Nissan Hajaj, Michaela Hardt, Peter J Liu, Xiaobing Liu, Jake Marcus, Mimi Sun, et almbox. 2018. Scalable and accurate deep learning with electronic health records. NPJ Digital Medicine, Vol. 1, 1 (2018), 18.Google ScholarCross Ref"",""Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. Why should i trust you?: Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. ACM, 1135--1144.Google ScholarDigital Library"",""Cynthia Rudin. 2019 a. Do Simpler Models Exist and How Can We Find Them?. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 1--2.Google ScholarDigital Library"",""Cynthia Rudin. 2019 b. Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead. Nature Machine Intelligence, Vol. 1, 5 (2019), 206.Google ScholarCross Ref"",""Huan Song, Deepta Rajan, Jayaraman J Thiagarajan, and Andreas Spanias. 2018. Attend and diagnose: Clinical time series analysis using attention models. In Thirty-Second AAAI Conference on Artificial Intelligence.Google Scholar"",""Nenad Tomavs ev, Xavier Glorot, Jack W Rae, Michal Zielinski, Harry Askham, Andre Saraiva, Anne Mottram, Clemens Meyer, Suman Ravuri, Ivan Protsyuk, et almbox. 2019. A clinically applicable approach to continuous prediction of future acute kidney injury. Nature, Vol. 572, 7767 (2019), 116.Google Scholar"",""Xiang Wang, David Sontag, and Fei Wang. 2014. Unsupervised learning of disease progression models. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 85--94.Google ScholarDigital Library"",""Sarah Wiegreffe and Yuval Pinter. 2019. Attention is not not Explanation. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 11--20.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3406471,Recent Advances in Multimodal Educational Data Mining in K-12 Education,"Recently we have seen a rapid rise in the amount of education data available through the digitization of education. This huge amount of education data usually exhibits in a mixture form of images, videos, speech, texts, etc. It is crucial to consider data from different modalities to build successful applications in AI in education (AIED). This tutorial targets AI researchers and practitioners who are interested in applying state-of-the-art multimodal machine learning techniques to tackle some of the hard-core AIED tasks. These include tasks such as automatic short answer grading, student assessment, class quality assurance, knowledge tracing, etc.In this tutorial, we will comprehensively review recent developments of applying multimodal learning approaches in AIED, with a focus on those classroom multimodal data. Beyond introducing the recent advances of computer vision, speech, natural language processing in education respectively, we will discuss how to combine data from different modalities and build AI driven educational applications on top of these data. More specifically, we will talk about (1) representation learning; (2) algorithmic assessment & evaluation; and (3) personalized feedback. Participants will learn about recent trends and emerging challenges in this topic, representative tools and learning resources to obtain ready-to-use models, and how related models and techniques benefit real-world AIED applications.","[{""name"":""Zitao Liu"",""id"":""/profile/99659371148""},{""name"":""Songfan Yang"",""id"":""/profile/99659311386""},{""name"":""Jiliang Tang"",""id"":""/profile/81496640622""},{""name"":""Neil Heffernan"",""id"":""/profile/81100550596""},{""name"":""Rose Luckin"",""id"":""/profile/81452612610""},{""name"":""Zitao Liu"",""id"":""/profile/99659371148""},{""name"":""Songfan Yang"",""id"":""/profile/99659311386""},{""name"":""Jiliang Tang"",""id"":""/profile/81496640622""},{""name"":""Neil Heffernan"",""id"":""/profile/81100550596""},{""name"":""Rose Luckin"",""id"":""/profile/81452612610""}]","[""Sumit Basu, Chuck Jacobs, and Lucy Vanderwende. 2013. Powergrading: a clustering approach to amplify human effort for short answer grading. Transactions of the Association for Computational Linguistics, Vol. 1 (2013), 391--402.Google ScholarCross Ref"",""Nathaniel Blanchard, Patrick J Donnelly, Andrew M Olney, Borhan Samei, Brooke Ward, Xiaoyi Sun, Sean Kelly, Martin Nystrand, and Sidney K D'Mello. 2016. Semi-Automatic Detection of Teacher Questions from Human-Transcripts of Audio in Live Classrooms. International Educational Data Mining Society (2016).Google Scholar"",""Jiahao Chen, Hang Li, Wenxin Wang, Wenbiao Ding, Gale Yan Huang, and Zitao Liu. 2019. A Multimodal Alerting System for Online Class Quality Assurance. In International Conference on Artificial Intelligence in Education. Springer, 381--385.Google ScholarCross Ref"",""A Ghosh, Neil Heffernan, and Andrew Lan. 2020. Context-aware attentive knowledge tracing. In Proceedings of the ACM SIGKDD Conference on Knowledge Discovery and Data Mining.Google ScholarDigital Library"",""Zhenya Huang, Yu Yin, Enhong Chen, Hui Xiong, Yu Su, Guoping Hu, et almbox. 2019. EKT: Exercise-aware Knowledge Tracing for Student Performance Prediction. IEEE Transactions on Knowledge and Data Engineering (2019).Google Scholar"",""Hang Li, Yu Kang, Wenbiao Ding, Song Yang, Songfan Yang, Gale Yan Huang, and Zitao Liu. 2020. Multimodal learning for classroom activity detection. In ICASSP 2020--2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 9234--9238.Google ScholarCross Ref"",""Tiaoqiao Liu, Wenbiao Ding, Zhiwei Wang, Jiliang Tang, Gale Yan Huang, and Zitao Liu. 2019. Automatic Short Answer Grading via Multiway Attention Networks. In International Conference on Artificial Intelligence in Education. Springer, 169--173.Google ScholarCross Ref"",""Michael Mohler, Razvan Bunescu, and Rada Mihalcea. 2011. Learning to grade short answer questions using semantic similarity measures and dependency graph alignments. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1. Association for Computational Linguistics, 752--762.Google ScholarDigital Library"",""Kritphong Mongkhonvanit, Klint Kanopka, and David Lang. 2019. Deep Knowledge Tracing and Engagement with MOOCs. In Proceedings of the 9th International Conference on Learning Analytics \u0026 Knowledge. 340--342.Google ScholarDigital Library"",""Koki Nagatani, Qian Zhang, Masahiro Sato, Yan-Ying Chen, Francine Chen, and Tomoko Ohkuma. 2019. Augmenting Knowledge Tracing by Considering Forgetting Behavior. In The World Wide Web Conference. 3101--3107.Google ScholarDigital Library"",""Jiquan Ngiam, Aditya Khosla, Mingyu Kim, Juhan Nam, Honglak Lee, Andrew Ng, et almbox. 2011. Multimodal Deep Learning. In The 28th International Conference on Machine Learning. ICML.Google Scholar"",""Yingwei Pan, Tao Mei, Ting Yao, Houqiang Li, and Yong Rui. 2016. Jointly modeling embedding and translation to bridge video and language. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 4594--4602.Google ScholarCross Ref"",""Chris Piech, Jonathan Bassen, Jonathan Huang, Surya Ganguli, Mehran Sahami, Leonidas J Guibas, and Jascha Sohl-Dickstein. 2015. Deep knowledge tracing. In Advances in Neural Information Processing Systems. 505--513.Google Scholar"",""Zhiwei Wang, Xiaoqin Feng, Jiliang Tang, Gale Yan Huang, and Zitao Liu. 2019. Deep Knowledge Tracing with Side Information. In International Conference on Artificial Intelligence in Education. Springer, 303--308.Google Scholar"",""Guowei Xu, Wenbiao Ding, Jiliang Tang, Songfan Yang, Gale Yan Huang, and Zitao Liu. 2019. Learning Effective Embeddings From Crowdsourced Labels: An Educational Case Study. In 2019 IEEE 35th International Conference on Data Engineering (ICDE). IEEE, 1922--1927.Google Scholar"",""Siyuan Zhao, Yaqiong Zhang, Xiaolu Xiong, Anthony Botelho, and Neil Heffernan. 2017. A memory-augmented neural model for automated grading. In Proceedings of the Fourth ACM Conference on [email protected] 189--192.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3406472,Tutorial on Online User Engagement: Metrics and Optimization,"User engagement plays a central role in companies operating online services, such as search engines, news portals, e-commerce sites, entertainment services, and social networks. A main challenge is to leverage collected knowledge about the daily online behavior of millions of users to understand what engages them short-term and more importantly long-term. Two critical steps of improving user engagement are metrics and their optimization. The most common way that engagement is measured is through various online metrics, acting as proxy measures of user engagement. This tutorial will review these metrics, their advantages and drawbacks, and their appropriateness to various types of online services. Once metrics are defined, how to optimize them will become the key issue. We will survey methodologies including machine learning models and experimental designs that are utilized to optimize these metrics via direct or indirect ways. As case studies, we will focus on four types of services, news, search, entertainment, and e-commerce.","[{""name"":""Liangjie Hong"",""id"":""/profile/81438595662""},{""name"":""Mounia Lalmas"",""id"":""/profile/81492641343""},{""name"":""Liangjie Hong"",""id"":""/profile/81438595662""},{""name"":""Mounia Lalmas"",""id"":""/profile/81492641343""}]","[""Nicola Barbieri, Fabrizio Silvestri, and Mounia Lalmas. 2016. Improving Post-Click User Engagement on Native Ads via Survival Analysis. In Proceedings of the 25th International Conference on World Wide Web, WWW 2016, Montreal, Canada, April 11 - 15, 2016. 761--770.Google ScholarDigital Library"",""Ting Chen, Yizhou Sun, Yue Shi, and Liangjie Hong. 2017. On Sampling Strategies for Neural Network-based Collaborative Filtering. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (Halifax, NS, Canada) (KDD '17). ACM, New York, NY, USA,pages 767--776.Google ScholarDigital Library"",""Paolo Dragone, Rishabh Mehrotra, and Mounia Lalmas. 2019. Deriving User- and Content-specific Rewards for Contextual Bandits. In The World Wide Web Conference, WWW 2019, San Francisco, CA, USA, May 13-17, 2019. ACM, 2680--2686.Google Scholar"",""Georges Dupret and Mounia Lalmas. 2013. Absence time and user engagement: evaluating ranking functions. In Sixth ACM International Conference on Web Search and Data Mining, WSDM 2013, Rome, Italy, February 4-8, 2013. 173--182.Google ScholarDigital Library"",""Dmitry Lagun and Mounia Lalmas. 2016. Understanding User Attention and Engagement in Online News Reading. In Proceedings of the Ninth ACM International Conference on Web Search and Data Mining, San Francisco, CA, USA, February 22--25, 2016. 113--122.Google ScholarDigital Library"",""Mounia Lalmas, Heather O'Brien, and Elad Yom-Tov. 2014. Measuring User Engagement. Synthesis Lectures on Information Concepts, Retrieval, and Services, Morgan \u0026 Claypool Publishers.Google Scholar"",""Janette Lehmann, Carlos Castillo, Mounia Lalmas, and Ricardo A. Baeza-Yates. 2017. Story-focused reading in online news and its potential for user engagement. JASIST, Vol. 68, 4 (2017), 869--883.Google Scholar"",""Janette Lehmann, Mounia Lalmas, Elad Yom-Tov, and Georges Dupret. 2012. Models of User Engagement. In User Modeling, Adaptation, and Personalization - 20th International Conference, UMAP 2012, Montreal, Canada, July 16-20, 2012. Proceedings. 164--175.Google Scholar"",""Janette Lehmann, Claudia Mü ller-Birn, David Laniado, Mounia Lalmas, and AndreasKaltenbrunner. 2014. Reader preferences and behavior on Wikipedia. In 25th ACM Conference on Hypertext and Social Media, HT '14, Santiago, Chile, September 1--4, 2014. pages88--97.Google ScholarDigital Library"",""Rishabh Mehrotra, James McInerney, Hugues Bouchard, Mounia Lalmas, and Fernando Diaz. 2018. Towards a Fair Marketplace: Counterfactual Evaluation of the trade-off between Relevance, Fairness \u0026 Satisfaction in Recommendation Systems. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management, CIKM 2018, Torino, Italy, October 22--26, 2018. pages2243--2251.Google ScholarDigital Library"",""Yue Ning, Yue Shi, Liangjie Hong, Huzefa Rangwala, and Naren Ramakrishnan. 2017. A Gradient-based Adaptive Learning Framework for Efficient Personal Recommendation. In Proceedings of the Eleventh ACM Conference on Recommender Systems (Como, Italy) (RecSys '17). ACM, New York, NY, USA, 23--31.Google ScholarDigital Library"",""Gabriele Tolomei, Mounia Lalmas, Ayman Farahat, and Andrew Haines. 2019. You must have clicked on this ad by mistake!Data-driven identification of accidental clicks on mobile ads with applications to advertiser cost discounting and click-through rate prediction. Int. J. Data Sci. Anal., Vol. 7, 1 (2019), pages53--66.Google ScholarCross Ref"",""Xing Yi, Liangjie Hong, Erheng Zhong, Nanthan Nan Liu, and Suju Rajan. 2014. Beyond Clicks: Dwell Time for Personalization. In Proceedings of the 8th ACM Conference on Recommender Systems (Foster City, Silicon Valley, California, USA) (RecSys '14). ACM, New York, NY, USA, 113--120.Google ScholarDigital Library"",""Qian Zhao, Yue Shi, and Liangjie Hong. 2017. GB-CENT: Gradient Boosted Categorical Embedding and Numerical Trees. In Proceedings of the 26th International Conference on World Wide Web (Perth, Australia)(WWW '17). International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, Switzerland, 1311--1319.Google Scholar"",""Ke Zhou, Miriam Redi, Andrew Haines, and Mounia Lalmas. 2016. Predicting Pre-click Quality for Native Advertisements. In Proceedings of the 25th International Conference on World Wide Web, WWW 2016, Montreal, Canada, April 11 - 15, 2016. ACM, 299--310.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3406473,Data Pricing -- From Economics to Data Science,"Data are invaluable. How can we assess the value of data objectively and quantitatively? Pricing data, or information goods in general, has been studied and practiced in dispersed areas and principles, such as economics, data management, data mining, electronic commerce, and marketing. In this tutorial, we present a unified and comprehensive overview of this important direction. We examine various motivations behind data pricing, understand the economics of data pricing, review the development and evolution of pricing models, and compare the proposals of marketplaces of data. We cover both digital products, such as ebooks and MP3 music, and data products, such as data sets, data queries and machine learning models. We also connect data pricing with the highly related areas, such as cloud service pricing, privacy pricing, and decentralized privacy preserving infrastructure like blockchains.","[{""name"":""Jian Pei"",""id"":""/profile/81100323054""},{""name"":""Jian Pei"",""id"":""/profile/81100323054""}]","[""Philip. Kotler. 2000. Marketing Management: the millennium edition. Pearson Custom Pub., Boston, MA.Google Scholar"",""Abhishek Nagaraj. 2016. The Private Impact of Public Information: Landsat Satellite Maps and Gold Exploration. Unpublished (07 2016). http://abhishekn.com/files/nagaraj_landsat2020.pdfGoogle Scholar"",""Stephanie van de Sandt, Sünje Dallmeier-Tiessen, Artemis Lavasa, and Vivien Petras. 2019. The Definition of Reuse. Data Science Journal, Vol. 18, 1 (2019), 22. https://doi.org/10.5334/dsj-2019-022Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3406474,"Deep Graph Learning: Foundations, Advances and Applications","Many real data come in the form of non-grid objects, i.e. graphs, from social networks to molecules. Adaptation of deep learning from grid-alike data (e.g. images) to graphs has recently received unprecedented attention from both machine learning and data mining communities, leading to a new cross-domain field---Deep Graph Learning (DGL). Instead of painstaking feature engineering, DGL aims to learn informative representations of graphs in an end-to-end manner. It has exhibited remarkable success in various tasks, such as node/graph classification, link prediction, etc.In this tutorial, we aim to provide a comprehensive introduction to deep graph learning. We first introduce the theoretical foundations on deep graph learning with a focus on describing various Graph Neural Network Models (GNNs). We then cover the key achievements of DGL in recent years. Specifically, we discuss the four topics: 1) training deep GNNs; 2) robustness of GNNs; 3) scalability of GNNs; and 4) self-supervised and unsupervised learning of GNNs. Finally, we will introduce the applications of DGL towards various domains, including but not limited to drug discovery, computer vision, medical image analysis, social network analysis, natural language processing and recommendation.","[{""name"":""Yu Rong"",""id"":""/profile/87658927957""},{""name"":""Tingyang Xu"",""id"":""/profile/99659534927""},{""name"":""Junzhou Huang"",""id"":""/profile/99659260108""},{""name"":""Wenbing Huang"",""id"":""/profile/99658750215""},{""name"":""Hong Cheng"",""id"":""/profile/81351596071""},{""name"":""Yao Ma"",""id"":""/profile/99659241966""},{""name"":""Yiqi Wang"",""id"":""/profile/99659538320""},{""name"":""Tyler Derr"",""id"":""/profile/99659218251""},{""name"":""Lingfei Wu"",""id"":""/profile/99659061651""},{""name"":""Tengfei Ma"",""id"":""/profile/99659338328""},{""name"":""Yu Rong"",""id"":""/profile/87658927957""},{""name"":""Tingyang Xu"",""id"":""/profile/99659534927""},{""name"":""Junzhou Huang"",""id"":""/profile/99659260108""},{""name"":""Wenbing Huang"",""id"":""/profile/99658750215""},{""name"":""Hong Cheng"",""id"":""/profile/81351596071""},{""name"":""Yao Ma"",""id"":""/profile/99659241966""},{""name"":""Yiqi Wang"",""id"":""/profile/99659538320""},{""name"":""Tyler Derr"",""id"":""/profile/99659218251""},{""name"":""Lingfei Wu"",""id"":""/profile/99659061651""},{""name"":""Tengfei Ma"",""id"":""/profile/99659338328""}]","[""Tian Bian, Xi Xiao, Tingyang Xu, Peilin Zhao, Wenbing Huang, Yu Rong, and Junzhou Huang. 2020. Rumor Detection on Social Media with Bi-Directional Graph Convolutional Networks. In AAAI.Google Scholar"",""Heng Chang, Yu Rong, Tingyang Xu, Wenbing Huang, Honglei Zhang, Peng Cui, Wenwu Zhu, and Junzhou Huang. 2020. A Restricted Black-Box Adversarial Framework Towards Attacking Graph Embedding Models.. In AAAI. 3389--3396.Google Scholar"",""Jie Chen, Tengfei Ma, and Cao Xiao. 2018. FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling. In ICLR.Google Scholar"",""Hanjun Dai, Hui Li, Tian Tian, Xin Huang, Lin Wang, Jun Zhu, and Le Song. 2018. Adversarial Attack on Graph Structured Data. ICML (2018), 1115--1124.Google Scholar"",""Tyler Derr, Yao Ma, and Jiliang Tang. 2018. Signed graph convolutional networks. In 2018 IEEE International Conference on Data Mining (ICDM). 929--934.Google ScholarCross Ref"",""Wenqi Fan, Yao Ma, Qing Li, Yuan He, Eric Zhao, Jiliang Tang, and Dawei Yin. 2019. Graph neural networks for social recommendation. In TheWebConf.Google Scholar"",""Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. 2017. Neural message passing for quantum chemistry. In ICML. 1263--1272.Google Scholar"",""Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In NeurIPS. 1025--1035.Google Scholar"",""Weihua Hu*, Bowen Liu*, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay Pande, and Jure Leskovec. 2020. Strategies for Pre-training Graph Neural Networks. In ICLR. https://openreview.net/forum?id=HJlWWJSFDHGoogle Scholar"",""Wenbing Huang, Tong Zhang, Yu Rong, and Junzhou Huang. 2018. Adaptive sampling towards fast graph representation learning. In NeurIPS. 4558--4567.Google Scholar"",""Wengong Jin, Regina Barzilay, and Tommi Jaakkola. 2018. Junction Tree Variational Autoencoder for Molecular Graph Generation. In ICML. 2323--2332.Google Scholar"",""Wei Jin, Tyler Derr, Haochen Liu, Yiqi Wang, Suhang Wang, Zitao Liu, and Jiliang Tang. 2020 a. Self-supervised Learning on Graphs: Deep Insights and New Direction. arXiv preprint arXiv:2006.10141 (2020).Google Scholar"",""Wei Jin, Yaxin Li, Han Xu, Yiqi Wang, and Jiliang Tang. 2020 b. Adversarial Attacks and Defenses on Graphs: A Review and Empirical Study. arXiv preprint arXiv:2003.00653 (2020).Google Scholar"",""Thomas N Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional networks. In ICLR.Google Scholar"",""Ruoyu Li, Sheng Wang, Feiyun Zhu, and Junzhou Huang. 2018a. Adaptive graph convolutional neural networks. In AAAI.Google Scholar"",""Ruoyu Li, Jiawen Yao, Xinliang Zhu, Yeqing Li, and Junzhou Huang. 2018b. Graph CNN for survival analysis on whole slide pathological images. In MICCAI.Google Scholar"",""Yao Ma, Ziyi Guo, Zhaochun Ren, Eric Zhao, Jiliang Tang, and Dawei Yin. 2020. Streaming graph neural networks. SIGIR (2020).Google Scholar"",""Yao Ma, Suhang Wang, Charu C Aggarwal, and Jiliang Tang. 2019. Graph convolutional networks with eigenpooling. In KDD. 723--731.Google Scholar"",""Kenta Oono and Taiji Suzuki. 2020. Graph neural networks exponentially lose expressive power for node classification. ICLR.Google Scholar"",""Zhen Peng, Wenbing Huang, Minnan Luo, Qinghua Zheng, Yu Rong, Tingyang Xu, and Junzhou Huang. 2020. Graph Representation Learning via Graphical Mutual Information Maximization. In TheWebConf. 259--270.Google Scholar"",""Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. 2014. Deepwalk: Online learning of social representations. In KDD. ACM.Google ScholarDigital Library"",""Yu Rong, Wenbing Huang, Tingyang Xu, and Junzhou Huang. 2020. DropEdge: Towards Deep Graph Convolutional Networks on Node Classification. In ICLR.Google Scholar"",""Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio. 2018. Graph Attention Networks. In ICLR.Google Scholar"",""Petar Velickovic, William Fedus, William L Hamilton, Pietro Liò, Yoshua Bengio, and R Devon Hjelm. 2019. Deep Graph Infomax. (2019).Google Scholar"",""Kun Xu, Lingfei Wu, Zhiguo Wang, Yansong Feng, Michael Witbrock, and Vadim Sheinin. 2018. Graph2seq: Graph to sequence learning with attention-based neural networks. arXiv preprint arXiv:1804.00823 (2018).Google Scholar"",""Hanqing Zeng, Hongkuan Zhou, Ajitesh Srivastava, Rajgopal Kannan, and Viktor Prasanna. 2019 b. Graphsaint: Graph sampling based inductive learning method. arXiv preprint arXiv:1907.04931 (2019).Google Scholar"",""Runhao Zeng, Wenbing Huang, Mingkui Tan, Yu Rong, Peilin Zhao, Junzhou Huang, and Chuang Gan. 2019 a. Graph Convolutional Networks for Temporal Action Localization. In ICCV.Google Scholar"",""Daniel Zügner, Amir Akbarnejad, and Stephan Günnemann. 2018. Adversarial Attacks on Neural Networks for Graph Data. In KDD. 2847--2856.Google Scholar""]"
https://doi.org/10.1145/3394486.3406475,Multi-modal Network Representation Learning,"In today's information and computational society, complex systems are often modeled as multi-modal networks associated with heterogeneous structural relation, unstructured attribute/content, temporal context, or their combinations. The abundant information in multi-modal network requires both a domain understanding and large exploratory search space when doing feature engineering for building customized intelligent solutions in response to different purposes. Therefore, automating the feature discovery through representation learning in multi-modal networks has become essential for many applications. In this tutorial, we systematically review the area of multi-modal network representation learning, including a series of recent methods and applications. These methods will be categorized and introduced in the perspectives of unsupervised, semi-supervised and supervised learning, with corresponding real applications respectively. In the end, we conclude the tutorial and raise open discussions. The authors of this tutorial are active and productive researchers in this area.","[{""name"":""Chuxu Zhang"",""id"":""/profile/99659260171""},{""name"":""Meng Jiang"",""id"":""/profile/81472650328""},{""name"":""Xiangliang Zhang"",""id"":""/profile/81436599318""},{""name"":""Yanfang Ye"",""id"":""/profile/99658737605""},{""name"":""Nitesh V. Chawla"",""id"":""/profile/81100002770""},{""name"":""Chuxu Zhang"",""id"":""/profile/99659260171""},{""name"":""Meng Jiang"",""id"":""/profile/81472650328""},{""name"":""Xiangliang Zhang"",""id"":""/profile/81436599318""},{""name"":""Yanfang Ye"",""id"":""/profile/99658737605""},{""name"":""Nitesh V. Chawla"",""id"":""/profile/81100002770""}]","[""Uchenna Akujuobi, Yufei Han, Qiannan Zhang, and Xiangliang Zhang. 2019. Collaborative Graph Walk for Semi-supervised Multi-Label Node Classification. In ICDM.Google Scholar"",""Basmah Altaf, Uchenna Akujuobi, Lu Yu, and Xiangliang Zhang. 2019. Dataset Recommendation via Variational Graph Autoencoder. In ICDM.Google Scholar"",""Xia Chen, Guoxian Yu, Jun Wang, Carlotta Domeniconi, Zhao Li, and Xiangliang Zhang. 2019 b. ActiveHNE: Active Heterogeneous Network Embedding. In IJCAI.Google Scholar"",""Yujun Chen, Yuanhong Wang, Yutao Zhang, Juhua Pu, and Xiangliang Zhang. 2019 a. AMENDER: an Attentive and Aggregate Multi-layered Network for Dataset Recommendation. In ICDM.Google Scholar"",""Yuxiao Dong, Nitesh V Chawla, and Ananthram Swami. 2017. metapath2vec: Scalable Representation Learning for Heterogeneous Networks. In KDD.Google Scholar"",""Yujie Fan, Shifu Hou, Yiming Zhang, Yanfang Ye, and Melih Abdulhayoglu. 2018a. Gotcha-Sly Malware! Scorpion A Metagraph2vec Based Malware Detection System. In KDD.Google Scholar"",""Yujie Fan, Yiming Zhang, Yanfang Ye, and Xin Li. 2018b. Automatic Opioid User Detection from Twitter: Transductive Ensemble Built on Different Meta-graph Based Similarities over Heterogeneous Information Network.. In IJCAI.Google Scholar"",""Huan Gui, Jialu Liu, Fangbo Tao, Meng Jiang, Brandon Norick, Lance Kaplan, and Jiawei Han. 2017. Embedding learning with events in heterogeneous information networks. TKDE (2017).Google Scholar"",""Shifu Hou, Yanfang Ye, Yangqiu Song, and Melih Abdulhayoglu. 2017. Hindroid: An intelligent android malware detection system based on structured heterogeneous information network. In KDD.Google ScholarDigital Library"",""Meng Jiang, Peng Cui, Fei Wang, Xinran Xu, Wenwu Zhu, and Shiqiang Yang. 2014. Fema: flexible evolutionary multi-faceted analysis for dynamic behavioral pattern discovery. In KDD.Google Scholar"",""Meng Jiang, Peng Cui, Nicholas Jing Yuan, Xing Xie, and Shiqiang Yang. 2016. Little is much: Bridging cross-platform behaviors through overlapped crowds. In AAAI.Google Scholar"",""Zaiqiao Meng, Shangsong Liang, Hongyan Bao, and Xiangliang Zhang. 2019. Co-Embedding Attributed Networks. In WSDM.Google Scholar"",""Shichao Pei, Lu Yu, Robert Hoehndorf, and Xiangliang Zhang. 2019 b. Semi-Supervised Entity Alignment via Knowledge Graph Embedding with Awareness of Degree Difference. In WWW.Google Scholar"",""Shichao Pei, Lu Yu, and Xiangliang Zhang. 2019 a. Improving Cross-lingual Entity Alignment via Optimal Transport. In IJCAI.Google Scholar"",""Daheng Wang, Meng Jiang, Qingkai Zeng, Zachary Eberhart, and Nitesh V Chawla. 2018. Multi-type itemset embedding for learning behavior success. In KDD.Google Scholar"",""Daheng Wang, Tianwen Jiang, Nitesh V Chawla, and Meng Jiang. 2019. TUBE: Embedding Behavior Outcomes for Predicting Success. In KDD.Google ScholarDigital Library"",""Daheng Wang, Tong Zhao, Tianwen Jiang, Nitesh V Chawla, and Meng Jiang. 2020. Evolutionary Graph Neural Networks. In Under Review.Google Scholar"",""Yanfang Ye, Shifu Hou, Lingwei Chen, Jingwei Lei, Wenqiang Wan, Jiabin Wang, Qi Xiong, and Fudong Shao. 2019. Out-of-sample node representation learning for heterogeneous graph in real-time android malware detection. In IJCAI.Google Scholar"",""Lu Yu, Chuxu Zhang, Shangsong Liang, and Xiangliang Zhang. 2019. Multi-Order Attentive Ranking Model for Sequential Recommendation. In AAAI.Google Scholar"",""Lu Yu, Chuxu Zhang, Shichao Pei, Guolei Sun, and Xiangliang Zhang. 2018. Walkranker: A unified pairwise ranking model with multiple relations for item recommendation. In AAAI.Google Scholar"",""Chuxu Zhang, Chao Huang, Lu Yu, Xiangliang Zhang, and Nitesh V Chawla. 2018a. Camel: Content-Aware and Meta-path Augmented Metric Learning for Author Identification.. In WWW.Google Scholar"",""Chuxu Zhang, Dongjin Song, Chao Huang, Ananthram Swami, and Nitesh V. Chawla. 2019 a. Heterogeneous Graph Neural Network. In KDD.Google Scholar"",""Chuxu Zhang, Ananthram Swami, and Nitesh V Chawla. 2019 b. SHNE: Representation Learning for Semantic-Associated Heterogeneous Networks. In WSDM.Google Scholar"",""Chuxu Zhang, Lu Yu, Yan Wang, Yan Wang, and Xiangliang Zhang. 2017. Collaborative User Network Embedding for Social Recommender Systems. In SDM.Google Scholar"",""Chuxu Zhang, Lu Yu, Xiangliang Zhang, and Nitesh V Chawla. 2018b. Task-Guided and Semantic-Aware Ranking for Academic Author-Paper Correlation Inference.. In IJCAI.Google Scholar"",""Tong Zhao, Chuchen Deng, Kaifeng Yu, Tianwen Jiang, Daheng Wang, and Meng Jiang. 2020. Learning with Bipartite Graph Anomaly Losses. In Under Review.Google Scholar""]"
https://doi.org/10.1145/3394486.3406476,Data Science for the Real Estate Industry,"World's major industries, such as Financial Services, Telecom, Advertising, Healthcare, Education, etc, have attracted the attention of the KDD community for decades. Hundreds of KDD papers have been published on topics related to these industries and dozens of workshops organized---some of which have become an integral part of the conference agenda (e.g. the Health Day). Somewhat unexpectedly, the KDD conference has barely addressed the real estate industry, despite its enormous size and prominence. The reason for that apparent mismatch is two-fold: (a) until recently, the real estate industry did not appreciate the value data science methods could add (with some exceptions, such as econometrics methods for creating real-estate price indices); (b) the Data Science community has not been aware of challenging real estate problems that are perfectly suited to its methods. This tutorial provides a step towards resolving this issue. We provide an introduction to real estate for data scientists, and outline a spectrum of data science problems, many of which are being tackled by new ""prop-tech"" companies, while some are yet to be approached. We present concrete examples from three of these companies (where the authors work): Airbnb -- the most popular short-term rental marketplace, Cherre -- a real estate data integration platform, and Compass -- the largest independent real estate brokerage in the U.S.","[{""name"":""Ron Bekkerman"",""id"":""/profile/81100647922""},{""name"":""Vanja Josifovski"",""id"":""/profile/81100209419""},{""name"":""Foster Provost"",""id"":""/profile/81100596683""},{""name"":""Ron Bekkerman"",""id"":""/profile/81100647922""},{""name"":""Vanja Josifovski"",""id"":""/profile/81100209419""},{""name"":""Foster Provost"",""id"":""/profile/81100596683""}]",null
https://doi.org/10.1145/3394486.3406477,Overview and Importance of Data Quality for Machine Learning Tasks,"It is well understood from literature that the performance of a machine learning (ML) model is upper bounded by the quality of the data. While researchers and practitioners have focused on improving the quality of models (such as neural architecture search and automated feature selection), there are limited efforts towards improving the data quality. One of the crucial requirements before consuming datasets for any application is to understand the dataset at hand and failure to do so can result in inaccurate analytics and unreliable decisions. Assessing the quality of the data across intelligently designed metrics and developing corresponding transformation operations to address the quality gaps helps to reduce the effort of a data scientist for iterative debugging of the ML pipeline to improve model performance. This tutorial highlights the importance of analysing data quality in terms of its value for machine learning applications. This tutorial surveys all the important data quality related approaches discussed in literature, focusing on the intuition behind them, highlighting their strengths and similarities, and illustrates their applicability to real-world problems. Finally we will discuss the interesting work IBM Research is doing in this space.","[{""name"":""Abhinav Jain"",""id"":""/profile/99659280539""},{""name"":""Hima Patel"",""id"":""/profile/99659575038""},{""name"":""Lokesh Nagalapatti"",""id"":""/profile/99659574011""},{""name"":""Nitin Gupta"",""id"":""/profile/99659281597""},{""name"":""Sameep Mehta"",""id"":""/profile/81100653723""},{""name"":""Shanmukha Guttula"",""id"":""/profile/99659573942""},{""name"":""Shashank Mujumdar"",""id"":""/profile/87259339257""},{""name"":""Shazia Afzal"",""id"":""/profile/81453650659""},{""name"":""Ruhi Sharma Mittal"",""id"":""/profile/99659574621""},{""name"":""Vitobha Munigala"",""id"":""/profile/99658736522""},{""name"":""Abhinav Jain"",""id"":""/profile/99659280539""},{""name"":""Hima Patel"",""id"":""/profile/99659575038""},{""name"":""Lokesh Nagalapatti"",""id"":""/profile/99659574011""},{""name"":""Nitin Gupta"",""id"":""/profile/99659281597""},{""name"":""Sameep Mehta"",""id"":""/profile/81100653723""},{""name"":""Shanmukha Guttula"",""id"":""/profile/99659573942""},{""name"":""Shashank Mujumdar"",""id"":""/profile/87259339257""},{""name"":""Shazia Afzal"",""id"":""/profile/81453650659""},{""name"":""Ruhi Sharma Mittal"",""id"":""/profile/99659574621""},{""name"":""Vitobha Munigala"",""id"":""/profile/99658736522""}]","[""Laure Berti-Equille. 2019. Learn2Clean: optimizing the sequence of tasks for web data preparation. In The World Wide Web Conference. 2580--2586.Google ScholarDigital Library"",""Eric Breck, Neoklis Polyzotis, Sudip Roy, Steven Whang, and Martin Zinkevich. 2019. Data Validation for Machine Learning. In Conference on Systems and Machine Learning (SysML).Google Scholar"",""Edward Collins, Nikolai Rozanov, and Bingbing Zhang. 2018. Evolutionary Data Measures: Understanding the Difficulty of Text Classification Tasks. arXiv preprint arXiv:1811.01910 (2018).Google Scholar"",""Bing Tian Dai, Nick Koudas, Beng Chin Ooi, Divesh Srivastava, and Suresh Venkatasubramanian. 2006. Rapid identification of column heterogeneity. In Sixth International Conference on Data Mining (ICDM'06). IEEE.Google ScholarDigital Library"",""Misha Denil and Thomas Trappenberg. 2010. Overlap versus Imbalance. In Advances in Artificial Intelligence,, Atefeh Farzindar and Vlado Kevs elj (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 220--231.Google Scholar"",""Jacob Devlin, Jonathan Uesato, Surya Bhupatiraju, Rishabh Singh, Abdel-rahman Mohamed, and Pushmeet Kohli. 2017. Robustfill: Neural program learning under noisy i/o. In Proceedings of the 34th International Conference on Machine Learning-Volume 70. 990--998.Google Scholar"",""Amirata Ghorbani and James Zou. 2019. Data shapley: Equitable valuation of data for machine learning. arXiv preprint arXiv:1904.02868 (2019).Google Scholar"",""Sumit Gulwani. 2011. Automating string processing in spreadsheets using input-output examples. ACM Sigplan Notices, Vol. 46, 1 (2011), 317--330.Google ScholarDigital Library"",""Shaojie Jiang, Pengjie Ren, Christof Monz, and Maarten de Rijke. 2019. Improving neural response diversity with frequency-aware cross-entropy loss. In The World Wide Web Conference. 2879--2885.Google ScholarDigital Library"",""Ramakrishnan Kannan, Hyenkyun Woo, Charu C Aggarwal, and Haesun Park. 2017. Outlier detection for text data. In Proceedings of the 2017 siam international conference on data mining. SIAM, 489--497.Google ScholarCross Ref"",""Cornelia Kiefer. 2019. Quality indicators for text data. BTW 2019--Workshopband (2019).Google Scholar"",""Stefan Larson, Anish Mahendran, Andrew Lee, Jonathan K Kummerfeld, Parker Hill, Michael A Laurenzano, Johann Hauswald, Lingjia Tang, and Jason Mars. 2019. Outlier Detection for Improved Data Quality and Diversity in Dialog Systems. arXiv preprint arXiv:1904.03122 (2019).Google Scholar"",""Michael Muller, Ingrid Lange, Dakuo Wang, David Piorkowski, Jason Tsay, Q Vera Liao, Casey Dugan, and Thomas Erickson. 2019. How Data Science Workers Work with Data: Discovery, Capture, Curation, Design, Creation. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. 1--15.Google ScholarDigital Library"",""Curtis G Northcutt, Lu Jiang, and Isaac L Chuang. 2019. Confident Learning: Estimating Uncertainty in Dataset Labels. arXiv preprint arXiv:1911.00068 (2019).Google Scholar"",""Paulo Oliveira, Fátima Rodrigues, Pedro Rangel Henriques, and Helena Galhardas. 2005. A Taxonomy of Data Quality Problems. Journal of Data and Information Quality - JDIQ (01 2005).Google Scholar"",""Nicole Peinelt, Maria Liakata, and Dong Nguyen. 2019. Aiming beyond the Obvious: Identifying Non-Obvious Cases in Semantic Similarity Datasets. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. 2792--2798.Google ScholarCross Ref"",""Erhard Rahm and Hong Hai Do. 2000. Data cleaning: Problems and current approaches. (2000).Google Scholar"",""Jinsung Yoon, Sercan O Arik, and Tomas Pfister. 2019. Data Valuation using Reinforcement Learning. arXiv preprint arXiv:1909.11671 (2019).Google Scholar""]"
https://doi.org/10.1145/3394486.3406478,Interpreting and Explaining Deep Neural Networks: A Perspective on Time Series Data,"Explainable and interpretable machine learning models and algorithms are important topics which have received growing attention from research, application and administration. Many complex Deep Neural Networks (DNNs) are often perceived as black-boxes. Researchers would like to be able to interpret what the DNN has learned in order to identify biases and failure models and improve models. In this tutorial, we will provide a comprehensive overview on methods to analyze deep neural networks and an insight how those interpretable and explainable methods help us understand time series data.","[{""name"":""Jaesik Choi"",""id"":""/profile/99659575129""},{""name"":""Jaesik Choi"",""id"":""/profile/99659575129""}]","[""Sebastian Bach, Alexander Binder, Grégoire Montavon, Frederick Klauschen, Klaus-Robert Müller, and Wojciech Samek. 2015. On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation. PloS one 10, 7 (2015), e0130140.Google ScholarCross Ref"",""David Bau, Bolei Zhou, Aditya Khosla, Aude Oliva, and Antonio Torralba. 2017. Network dissection: Quantifying interpretability of deep visual representations. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 6541--6549.Google ScholarCross Ref"",""David Bau, Jun-Yan Zhu, Hendrik Strobelt, Bolei Zhou, Joshua B Tenenbaum, William T Freeman, and Antonio Torralba. 2018. Gan dissection: Visualizing and understanding generative adversarial networks. arXiv:1811.10597 (2018).Google Scholar"",""Sohee Cho, Ginkyeng Lee, and Jaesik Choi. 2020. Interpretation of Deep Temporal Representations by Selective Visualization of Internally Activated Units. arXiv:2004.12538 (2020).Google Scholar"",""Yunseong Hwang, Anh Tong, and Jaesik Choi. 2016. Automatic Construction of Nonparametric Relational Regression Models for Multiple Time Series. In Proceedings of the International Conference on Machine Learning, Vol. 48. PMLR, 3030--3039.Google Scholar"",""Giyoung Jeon, Haedong Jeong, and Jaesik Choi. 2019. An Efficient Explorative Sampling Considering the Generative Boundaries of Deep Generative Neural Networks. arXiv:1912.05827 (2019).Google Scholar"",""Jacob Kauffmann, Malte Esders, Grégoire Montavon,Wojciech Samek, and Klaus- Robert Müller. 2019. From clustering to cluster explanations via neural networks. arXiv:1906.07633 (2019).Google Scholar"",""Sebastian Lapuschkin, Stephan Wäldchen, Alexander Binder, Grégoire Montavon, Wojciech Samek, and Klaus-Robert Müller. 2019. Unmasking clever hans predictors and assessing what machines really learn. Nature communications 10, 1 (2019), 1--8.Google Scholar"",""Hongzhi Li, Joseph G Ellis, Lei Zhang, and Shih-Fu Chang. 2018. Patternnet: Visual pattern mining with deep neural network. In Proceedings of the ACM on International Conference on Multimedia Retrieval. 291--299.Google ScholarDigital Library"",""Grégoire Montavon, Sebastian Lapuschkin, Alexander Binder, Wojciech Samek, and Klaus-Robert Müller. 2017. Explaining nonlinear classification decisions with deep taylor decomposition. Pattern Recognition 65 (2017), 211--222.Google ScholarDigital Library"",""Woo-Jeoung Nam, Shir Gur, Jaesik Choi, Lior Wolf, and Seong-Whan Lee. 2020. Relative Attributing Propagation: Interpreting the Comparative Contributions of Individual Units in Deep Neural Networks.. In Proceedings of the AAAI Conference on Artificial Intelligence. 2501--2508.Google Scholar"",""Boris N Oreshkin, Dmitri Carpov, Nicolas Chapados, and Yoshua Bengio. 2019. NBEATS: Neural basis expansion analysis for interpretable time series forecasting. arXiv:1905.10437 (2019).Google Scholar"",""Avanti Shrikumar, Peyton Greenside, and Anshul Kundaje. 2017. Learning important features through propagating activation differences. arXiv:1704.02685 (2017).Google Scholar"",""Jost Tobias Springenberg, Alexey Dosovitskiy, Thomas Brox, and Martin Riedmiller. 2014. Striving for simplicity: The all convolutional net. arXiv:1412.6806 (2014).Google Scholar"",""Christian Steinruecken, Emma Smith, David Janz, James Lloyd, and Zoubin Ghahramani. 2019. The automatic statistician. In Automated Machine Learning. Springer, Cham, 161--173.Google Scholar"",""Lexiang Ye and Eamonn Keogh. 2009. Time Series Shapelets: A New Primitive for Data Mining. In Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. Association for Computing Machinery, 947--956.Google ScholarDigital Library"",""Matthew D Zeiler and Rob Fergus. 2014. Visualizing and understanding convolutional networks. In Proceedings of the European conference on computer vision. Springer, 818--833.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3406479,Edge AI: Systems Design and ML for IoT Data Analytics,"With the explosion in Big Data, it is often forgotten that much of the data nowadays is generated at the edge. Specifically, a major source of data is users' endpoint devices like phones, smart watches, etc., that are connected to the internet, also known as the Internet-of-Things (IoT). This ""edge of data"" faces several new challenges related to hardware-constraints, privacy-aware learning, and distributed learning (both training as well as inference). So what systems and machine learning algorithms can we use to generate or exploit data at the edge? Can network science help us solve machine learning (ML) problems? Can IoT-devices help people who live with some form of disability and many others benefit from health monitoring?In this tutorial, we introduce the network science and ML techniques relevant to edge computing, discuss systems for ML (e.g., model compression, quantization, HW/SW co-design, etc.) and ML for systems design (e.g., run-time resource optimization, power management for training and inference on edge devices), and illustrate their impact in addressing concrete IoT applications.","[{""name"":""Radu Marculescu"",""id"":""/profile/81100467056""},{""name"":""Diana Marculescu"",""id"":""/profile/81100467087""},{""name"":""Umit Ogras"",""id"":""/profile/81100599235""},{""name"":""Radu Marculescu"",""id"":""/profile/81100467056""},{""name"":""Diana Marculescu"",""id"":""/profile/81100467087""},{""name"":""Umit Ogras"",""id"":""/profile/81100599235""}]","[""K. Bhardwaj, N. Suda, R. Marculescu, ?EdgeAI: A Vision for Deep Learning in IoT Era.\"" IEEE Design and Test, November 2019.Google Scholar"",""R. Kim, J.R. Doppa, P.P. Pande, D. Marculescu, and R. Marculescu, \""Machine Learning and Manycore Systems Design: A Serendipitous Symbiosis,\"" in IEEE Computer, July 2018.Google Scholar"",""K. Bhardwaj, W. Chen, R. Marculescu, \""New Directions in Distributed Deep Learning: Bringing the Network at Forefront of IoT Design.\"" To appear in Proceedings of Design Automation Conference (DAC), July 2020.Google Scholar"",""Konecny, J., McMahan, B., Ramage, D.: Federated optimization: Distributed optimization beyond the datacenter. arXiv preprint arXiv:1511.03575 (2015)Google Scholar"",""Konecny, J., McMahan, H.B., Yu, F.X., Richtarik, P., Suresh, A.T., Bacon, D.: Federated learning: Strategies for improving communication efficiency. arXiv preprint arXiv:1610.05492 (2016)Google Scholar"",""McMahan, H.B., Moore, E., Ramage, D., Hampson, S., et al.: Communication-efficient learning of deep networks from decentralized data. arXiv preprint arXiv:1602.05629 (2016)Google Scholar"",""Yang, Q., Liu, Y., Chen, T., Tong, Y.: Federated machine learning: Concept and applications. ACM Transactions on Intelligent Systems and Technology (TIST) 10(2), 12 (2019)Google Scholar"",""K. Bhardwaj, N. Suda, R. Marculescu, \""Dream Distillation: A Data-Independent Model Compression Framework.\"" ICML Workshop on On-Device Machine Learning and Compact Deep Neural Network Representations (ODML-CDNNR), Oral Presentation, June 2019.Google Scholar"",""K. Bhardwaj, C. Lin, A. Sartor, R. Marculescu, \""Memory-and communication-aware model compression for distributed deep learning inference on IoT.\"" ACM Transactions on Embedded Computing Systems (TECS) 18.5s (2019): 1--22., International Conference on Hardware Software Codesign and System Synthesis (CODES+ISSS), October 2019.Google Scholar"",""W. Choi, K. Duraisamy, R. Kim, J. Doppa, P. Pande, D. Marculescu, and R. Marculescu, \""On-Chip Communication Network for Efficient Training of Deep Convolutional Networks on Heterogeneous Manycore Systems,\"" IEEE Trans. on Computers, vol. 67, no. 5, pp. 672--686, 1 May 2018.Google ScholarCross Ref"",""E. Cai, D.C. Juan, D. Stamoulis, and D. Marculescu. \""NeuralPower: Predict and Deploy Energy-Efficient Convolutional Neural Networks.\"" In Asian Conference on Machine Learning, pp. 622--637. 2017.Google Scholar"",""T.-W. Chin, R. Ding, C. Zhang, and D. Marculescu, \""Towards Efficient Model Compression,\"" in Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Seattle, WA, June 2020.Google Scholar"",""Z. Chen, J. Zhang, R. Ding, and D. Marculescu, \""ViP: Virtual Pooling for Accelerating CNN-based Image Classification and Object Detection,\"" in Proc. IEEE Winter Conference on Applications of Computer Vision (WACV), Aspen, CO, March 2020.Google ScholarCross Ref"",""T.-C. Wu, R. Ding, and D. Marculescu, \""AdaScale: Towards Real-time Video Object Detection using Adaptive Scaling,\"" in Proc. Conference on Systems and Machine Learning (SysML), Palo Alto, CA, April 2019.Google Scholar"",""Z. Chen, R. Ding, T.-W. Chin, and D. Marculescu, \""Understanding the Impact of Label Granularity on CNN-based Image Classification,\"" in Proc. IEEE Intl. Workshop on Data Science and Big Data Analytics (DSBDA) in conjunction with IEEE Int. Conference on Data Mining (ICDM), Singapore, Nov. 2018.Google Scholar"",""R. Ding, T.-W. Chin, D. Marculescu, and Z. Liu, \""Regularizing Activation Distribution for Training Binarized Deep Networks,\"" in Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Long Beach, CA, June 2019.Google Scholar"",""R. Ding, Z. Liu, T.-W. Chin, D. Marculescu, and S. Blanton, \""Lightweight Quantized Deep Neural Networks for Fast and Accurate Inference,\"" in Proc. ACM/IEEE Design Automation Conference (DAC), Las Vegas, June 2019.Google Scholar"",""D. Stamoulis, R. Ding, D. Wang, D. Lymberopoulos, B. Priyantha, J. Liu, and D. Marculescu. \""Single-Path NAS: Designing Hardware-Efficient ConvNets in less than 4 Hours.\"" In European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases. 2019.Google Scholar"",""D. Arriba-Pérez, M. Caeiro-Rodríguez, and, J. M. Santos-Gago, \""Collection and processing of data from wrist wearable devices in heterogeneous and multiple-user scenarios,\"" Sensors, 16(9), 2016, 1538.Google ScholarCross Ref"",""G. Bhat, J. Park, and U. Y. Ogras, \""Near-Optimal Energy Allocation for Self-Powered Wearable Systems,\"" in Proc. Int. Conf. on Comput.-Aided Design, Nov. 2017, pp. 368--375.Google Scholar"",""G. Bhat, R. Deb, V. Chaurasia, H. Shill, and U. Y. Ogras, \""Online human activity recognition using low- power wearable devices,\"" International Conference on Computer-Aided Design (ICCAD), Nov. 2018, pp. 1--8).Google Scholar"",""G. Bhat, R. Deb, and U. Y. Ogras, \""OpenHealth: Open source platform for wearable health monitoring,\"" IEEE Design \u0026 Test, 2019, vol. 36, Issue: 5, Oct. 2019, doi: 10.1109/MDAT.2019.2906110.Google ScholarCross Ref"",""M. A. Case, H. A. Burwic, K. G. Volpp, and M. S. Patel, \""Accuracy of smartphone applications and wearable devices for tracking physical activity data,\"" Jama, 313(6), 2015, pp. 625--626.Google ScholarCross Ref"",""A.J. Espay et al. \""Technology in Parkinson's Disease: Challenges and Opportunities\"" Movement Disorders vol. 31 no. 9 pp. 1272--1282 2016.Google ScholarCross Ref"",""J. Park, H. Joshi, H. Lee, S. Kiaei, and U. Y. Ogras. \""Flexible PV-cell modeling for energy harvesting in wearable IoT applications,\"" ACM Trans. on Embedded Computing Systems (TECS) 16, no. 5s (2017): 1--20.Google Scholar"",""S. Sudevalayam and P. Kulkarni, \""Energy harvesting sensor nodes: Survey and implications,\"" IEEE Communications Surveys \u0026 Tutorials, vol. 13, no. 3, pp. 443--461, 2010.Google ScholarCross Ref"",""Y. Tuncel, G. Bhat, U. Y. Ogras, \""Special Session: Physically Flexible Devices for Health and Activity Monitoring: Challenges from Design to Test,\"" VLSI Test Symposium, April 2020.Google Scholar""]"
https://doi.org/10.1145/3394486.3406480,Data Sketching for Real Time Analytics: Theory and Practice,"Speed, cost, and scale. These are 3 of the biggest challenges in analyzing big data. While modern data systems continue to push the boundaries of scale, the problems of speed and cost are fundamentally tied to the size of data being scanned or processed. Processing thousands of queries that each access terabytes of data with sub-second latency remains infeasible. Data sketching techniques provide means to drastically reduce this size, allowing for real-time or interactive data analysis with reduced costs but with approximate answers.This tutorial covers a number of useful data sketching and sampling methods and demonstrate their use using the Apache DataSketches project. We focus particularly on common problems in analytic problems such as counting distinct items, quantiles, histograms, heavy hitters, and aggregations with large group bys. For these, we covers algorithms, techniques, and theory that can aid both practitioners and theorists in constructing sketches and designing systems that achieve desired error guarantees. For practitioners and implementers, we show how some of these sketches can be easily instantiated using the Apache Datasketches project.","[{""name"":""Daniel Ting"",""id"":""/profile/99658633750""},{""name"":""Jonathan Malkin"",""id"":""/profile/81319496669""},{""name"":""Lee Rhodes"",""id"":""/profile/99659220451""},{""name"":""Daniel Ting"",""id"":""/profile/99658633750""},{""name"":""Jonathan Malkin"",""id"":""/profile/81319496669""},{""name"":""Lee Rhodes"",""id"":""/profile/99659220451""}]","[""P. K. Agarwal, G. Cormode, Z. Huang, J. M. Phillips, Z. Wei, and K. Yi. Mergeable summaries. ACM Transactions on Database Systems, 38(4):26, 2013.Google ScholarDigital Library"",""N. Alon, Y. Matias, and M. Szegedy. The space complexity of approximating the frequency moments. Journal of Computer and System Sciences, 58(1):137--147, 1999.Google ScholarDigital Library"",""Apache. Datasketches (incubating). https://datasketches.apache.org, 2020.Google Scholar"",""Apache. Druid. https://druid.apache.org, 2020.Google Scholar"",""A. Broder and M. Mitzenmacher. Network applications of bloom filters: A survey. Internet mathematics, 1(4):485--509, 2004.Google ScholarCross Ref"",""E. Cohen. All-distances sketches, revisited: Hip estimators for massive graphs analysis. IEEE Transactions on Knowledge and Data Engineering, 27(9):2320--2334, 2015.Google ScholarCross Ref"",""E. Cohen. Stream sampling for frequency cap statistics. In KDD. ACM, 2015.Google ScholarDigital Library"",""E. Cohen, N. Duffield, H. Kaplan, C. Lund, and M. Thorup. Stream sampling for variance-optimal estimation of subset sums. In Proceedings of the twentieth annual ACM-SIAM symposium on Discrete algorithms, pages 1255--1264. SIAM, 2009.Google ScholarDigital Library"",""G. Cormode, M. Garofalakis, P. J. Haas, and C. Jermaine. Synopses for massive data: Samples, histograms, wavelets, sketches. Foundations and Trends in Databases, 4(1--3):1--294, 2012.Google Scholar"",""G. Cormode and S. Muthukrishnan. An improved data stream summary: the count-min sketch and its applications. Journal of Algorithms, 55(1):58--75, 2005.Google ScholarDigital Library"",""G. Cormode, V. Shkapenyuk, D. Srivastava, and B. Xu. Forward decay: A practical time decay model for streaming systems. In ICDE, pages 138--149. IEEE, 2009.Google ScholarDigital Library"",""G. Cormode and P. Veselý. Tight lower bound for comparison-based quantile summaries. 2019.Google Scholar"",""A. Dasgupta, K. J. Lang, L. Rhodes, and J. Thaler. A framework for estimating stream expression cardinalities. In ICDT, 2016.Google Scholar"",""N. Duffield, C. Lund, and M. Thorup. Priority sampling for estimation of arbitrary subset sums. Journal of the ACM (JACM), 54(6):32, 2007.Google Scholar"",""O. Ertl. New cardinality estimation algorithms for hyperloglog sketches. arXiv preprint arXiv:1702.01284, 2017.Google Scholar"",""B. Fan, D. G. Andersen, M. Kaminsky, and M. D. Mitzenmacher. Cuckoo filter: Practically better than bloom. In Proceedings of the 10th ACM International on Conference on emerging Networking Experiments and Technologies, pages 75--88, 2014.Google ScholarDigital Library"",""M. Ghashami, E. Liberty, and J. M. Phillips. Efficient frequent directions algorithm for sparse matrices. KDD, 2016.Google ScholarDigital Library"",""M. Greenwald and S. Khanna. Space-efficient online computation of quantile summaries. SIGMOD, 2001.Google ScholarDigital Library"",""Z. Karnin, K. Lang, and E. Liberty. Optimal quantile approximation in streams. In FOCS. IEEE, 2016.Google ScholarCross Ref"",""E. Liberty. Simple and deterministic matrix sketching. In KDD. ACM, 2013.Google ScholarDigital Library"",""G. S. Manku, S. Rajagopalan, and B. Lindsay. Random sampling techniques for space efficient online computation of order statistics of large datasets. SIGMOD, 1999.Google ScholarDigital Library"",""J. Misra and D. Gries. Finding repeated elements. Science of computer programming, 2(2):143--152, 1982.Google Scholar"",""A. Shrivastava, A. C. Konig, and M. Bilenko. Time adaptive sketches (ada-sketches) for summarizing data streams. In Proceedings of the 2016 International Conference on Management of Data, pages 1417--1432, 2016.Google ScholarDigital Library"",""M. Szegedy. The dlt priority sampling is essentially optimal. In STOC, pages 150--158. ACM, 2006.Google ScholarDigital Library"",""D. Ting. Streamed approximate counting of distinct elements: beating optimal batch methods. In KDD, 2014.Google ScholarDigital Library"",""D. Ting. Towards optimal cardinality estimation of unions and intersections with sketches. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 1195--1204. ACM, 2016.Google ScholarDigital Library"",""D. Ting. Count-min: Optimal estimation and tight error bounds using empirical error distributions. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining, pages 2319--2328. ACM, 2018.Google ScholarDigital Library"",""D. Ting. Data sketches for disaggregated subset sum and frequent item estimation. In Proceedings of the 2018 International Conference on Management of Data, pages 1129--1140. ACM, 2018.Google ScholarDigital Library"",""D. Ting and E. Brochu. Optimal subsampling with influence functions. In Advances in Neural Information Processing Systems, pages 3650--3659, 2018.Google Scholar"",""L. Wang, G. Luo, K. Yi, and G. Cormode. Quantiles over data streams: an experimental study. In SIGMOD, 2013.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3406481,Deep Learning for Anomaly Detection,"Anomaly detection has been widely studied and used in diverse applications. Building an effective anomaly detection system requires researchers and developers to learn complex structure from noisy data, identify dynamic anomaly patterns, and detect anomalies with limited labels. Recent advancements in deep learning techniques have greatly improved anomaly detection performance, in comparison with classical approaches, and have extended anomaly detection to a wide variety of applications. This tutorial will help the audience gain a comprehensive understanding of deep learning based anomaly detection techniques in various application domains. First, we give an overview of the anomaly detection problem, introducing the approaches taken before the deep model era and listing out the challenges they faced. Then we survey the state-of-the-art deep learning models that range from building block neural network structures such as MLP, CNN, and LSTM, to more complex structures such as autoencoder, generative models (VAE, GAN, Flow-based models), to deep one-class detection models, etc. In addition, we illustrate how techniques such as transfer learning and reinforcement learning can help amend the label sparsity issue in anomaly detection problems and how to collect and make the best use of user labels in practice. Second to last, we discuss real world use cases coming from and outside LinkedIn. The tutorial concludes with a discussion of future trends.","[{""name"":""Ruoying Wang"",""id"":""/profile/99659496260""},{""name"":""Kexin Nie"",""id"":""/profile/99659496551""},{""name"":""Yen-Jung Chang"",""id"":""/profile/99659573093""},{""name"":""Xinwei Gong"",""id"":""/profile/99659573002""},{""name"":""Tie Wang"",""id"":""/profile/99659496721""},{""name"":""Yang Yang"",""id"":""/profile/99658714896""},{""name"":""Bo Long"",""id"":""/profile/99659534038""},{""name"":""Ruoying Wang"",""id"":""/profile/99659496260""},{""name"":""Kexin Nie"",""id"":""/profile/99659496551""},{""name"":""Yen-Jung Chang"",""id"":""/profile/99659573093""},{""name"":""Xinwei Gong"",""id"":""/profile/99659573002""},{""name"":""Tie Wang"",""id"":""/profile/99659496721""},{""name"":""Yang Yang"",""id"":""/profile/99658714896""},{""name"":""Bo Long"",""id"":""/profile/99659534038""}]","[""Samet Akcay, Amir Atapour-Abarghouei, and Toby P Breckon. 2018. Ganomaly: Semi-supervised anomaly detection via adversarial training. In Asian Conference on Computer Vision. Springer, 622--637.Google Scholar"",""Jerone TA Andrews, Thomas Tanay, Edward J Morton, and Lewis D Griffin. 2016. Transfer representation-learning for anomaly detection. In Proc. ICML. 1--5.Google Scholar"",""Christoph Baur, Benedikt Wiestler, Shadi Albarqouni, and Nassir Navab. 2018. Deep autoencoding models for unsupervised anomaly segmentation in brain MR images. In International MICCAI Brainlesion Workshop. Springer, 161--169.Google Scholar"",""Hyunsun Choi and Eric Jang. 2018. Generative ensembles for robust anomaly detection. (2018).Google Scholar"",""Narendhar Gugulothu, Pankaj Malhotra, Lovekesh Vig, and Gautam Shroff. 2018. Sparse neural networks for anomaly detection in high-dimensional time series. In AI4IOT workshop in conjunction with ICML, IJCAI and ECAI.Google Scholar"",""Matthias Haselmann, Dieter P Gruber, and Paul Tabatabai. 2018. Anomaly detection using deep learning based image completion. In 2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA). IEEE, 1237--1242.Google ScholarCross Ref"",""Kyle Hundman, Valentino Constantinou, Christopher Laporte, Ian Colwell, and Tom Soderstrom. 2018. Detecting spacecraft anomalies using lstms and nonparametric dynamic thresholding. In Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery \u0026 data mining. 387--395.Google ScholarDigital Library"",""Dhruv Khattar, Jaipal Singh Goud, Manish Gupta, and Vasudeva Varma. 2019. Mvae: Multimodal variational autoencoder for fake news detection. In The World Wide Web Conference. 2915--2921.Google ScholarDigital Library"",""Swee Kiat Lim, Yi Loo, Ngoc-Trung Tran, Ngai-Man Cheung, Gemma Roig, and Yuval Elovici. 2018. Doping: Generative data augmentation for unsupervised anomaly detection with gan. In 2018 IEEE International Conference on Data Mining (ICDM). IEEE, 1122--1127.Google ScholarCross Ref"",""Pankaj Malhotra, Lovekesh Vig, Gautam Shroff, and Puneet Agarwal. 2015. Long short term memory networks for anomaly detection in time series. In Proceedings, Vol. 89. Presses universitaires de Louvain, 89--94.Google Scholar"",""Federico Di Mattia, Paolo Galeone, Michele De Simoni, and Emanuele Ghelfi. 2019. A Survey on GANs for Anomaly Detection. CoRR, Vol. abs/1906.11632 (2019). arxiv: 1906.11632 http://arxiv.org/abs/1906.11632Google Scholar"",""Ashish Mishra, Shiva Krishna Reddy, Anurag Mittal, and Hema A Murthy. 2018. A generative model for zero shot learning using conditional variational autoencoders. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops. 2188--2196.Google ScholarCross Ref"",""Min-hwan Oh and Garud Iyengar. 2019. Sequential Anomaly Detection using Inverse Reinforcement Learning. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 1480--1490.Google Scholar"",""Guansong Pang, Chunhua Shen, and Anton van den Hengel. 2019. Deep anomaly detection with deviation networks. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 353--362.Google Scholar"",""Dan Pelleg and Andrew W Moore. 2005. Active learning for anomaly and rare-category detection. In Advances in neural information processing systems. 1073--1080.Google Scholar"",""Manassés Ribeiro, André Eugênio Lazzaretti, and Heitor Silvério Lopes. 2018. A study of deep convolutional auto-encoders for anomaly detection in videos. Pattern Recognition Letters, Vol. 105 (2018), 13--22.Google ScholarDigital Library"",""Lukas Ruff, Robert Vandermeulen, Nico Goernitz, Lucas Deecke, Shoaib Ahmed Siddiqui, Alexander Binder, Emmanuel Müller, and Marius Kloft. 2018. Deep one-class classification. In International conference on machine learning. 4393--4402.Google Scholar"",""Lukas Ruff, Robert A Vandermeulen, Nico Görnitz, Alexander Binder, Emmanuel Müller, Klaus-Robert Müller, and Marius Kloft. 2019. Deep semi-supervised anomaly detection. arXiv preprint arXiv:1906.02694 (2019).Google Scholar"",""Thomas Schlegl, Philipp Seeböck, Sebastian M Waldstein, Ursula Schmidt-Erfurth, and Georg Langs. 2017. Unsupervised anomaly detection with generative adversarial networks to guide marker discovery. In International Conference on Information Processing in Medical Imaging. Springer, 146--157.Google ScholarCross Ref"",""Maximilian Schmidt and Marko Simic. 2019. Normalizing flows for novelty detection in industrial time series data. arXiv preprint arXiv:1906.06904 (2019).Google Scholar"",""Ya Su, Youjian Zhao, Chenhao Niu, Rong Liu, Wei Sun, and Dan Pei. 2019. Robust anomaly detection for multivariate time series through stochastic recurrent neural network. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 2828--2837.Google ScholarDigital Library"",""Terry T Um, Franz MJ Pfister, Daniel Pichler, Satoshi Endo, Muriel Lang, Sandra Hirche, Urban Fietzek, and Dana Kulić. 2017. Data augmentation of wearable sensor data for parkinson's disease monitoring using convolutional neural networks. In Proceedings of the 19th ACM International Conference on Multimodal Interaction. 216--220.Google ScholarDigital Library"",""Tailai Wen and Roy Keyes. 2019. Time series anomaly detection using convolutional neural networks and transfer learning. arXiv preprint arXiv:1905.13628 (2019).Google Scholar"",""Haowen Xu, Wenxiao Chen, Nengwen Zhao, Zeyan Li, Jiahao Bu, Zhihan Li, Ying Liu, Youjian Zhao, Dan Pei, Yang Feng, et almbox. 2018. Unsupervised anomaly detection via variational auto-encoder for seasonal kpis in web applications. In Proceedings of the 2018 World Wide Web Conference. International World Wide Web Conferences Steering Committee, 187--196.Google ScholarDigital Library"",""Houssam Zenati, Chuan Sheng Foo, Bruno Lecouat, Gaurav Manek, and Vijay Ramaseshan Chandrasekhar. 2018. Efficient gan-based anomaly detection. arXiv preprint arXiv:1802.06222 (2018).Google Scholar"",""Zilong Zhao, Sophie Cerf, Robert Birke, Bogdan Robu, Sara Bouchenak, Sonia Ben Mokhtar, and Lydia Y Chen. 2019. Robust anomaly detection on unreliable data. In 2019 49th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN). IEEE, 630--637.Google ScholarCross Ref"",""Chong Zhou and Randy C Paffenroth. 2017. Anomaly detection with robust deep autoencoders. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 665--674.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3406482,"Deep Learning for Industrial AI: Challenges, New Methods and Best Practices","Industrial AI is concerned with the application of Artificial Intelligence (AI), Machine Learning (ML) and related technologies towards addressing real-world use cases in industrial and societal domains. These uses cases can be broadly categorized into the horizontal areas of maintenance and repair, operations and supply chain, quality, safety, design, and end-to-end optimization - with applications in a variety of verticals. In the last few years, we have witnessed a growing interest in applying Deep Learning (DL) techniques to Industrial AI problems, ranging from using sequence models such as Long Short-Term Memory (LSTM) for predicting failures in equipment, to using Deep Reinforcement Learning (Deep RL) for scheduling and dispatching. Applying deep learning techniques to industrial applications imposes a set of unique challenges, which include, but are not limited to, (1) limited data, highly skewed class distribution and occurrence of rare classes such as failures, (2) multi-modal data (sensors, events, images, text, etc.) indexed over space and time (3) the need for explainable decisions, (4) a need to attain consistency between different but ""related"" models and between multiple generations of the same model, and (5) decision making to optimize business outcomes where the cost of a mistake could be very high. This tutorial presents an overview of these challenges, along with new methods and best practices to address them. Examples of these methods include using sequence DL models and Functional Neural Networks (FNNs) for modeling sensor and spatiotemporal measurements; using multi-task learning, graph models and ensemble learning for improving consistency of DL models; using deep RL for health indicator learning and dynamic dispatching; cost-based decision making for prognostics; and using GANs for generating senor data for prognostics. Finally, we will present some open problems in Industrial AI and how the research community can shape the future of the next industrial and societal revolution.","[{""name"":""Chetan Gupta"",""id"":""/profile/81350577724""},{""name"":""Ahmed Farahat"",""id"":""/profile/99659574716""},{""name"":""Chetan Gupta"",""id"":""/profile/81350577724""},{""name"":""Ahmed Farahat"",""id"":""/profile/99659574716""}]","[""Karan Aggarwal, Onur Atan, Ahmed K Farahat, Chi Zhang, Kosta Ristovski, and Chetan Gupta. 2018. Two birds with one network: Unifying failure event prediction and time-to-failure modeling. In 2018 IEEE International Conference on Big Data (Big Data). IEEE, 1308--1317.Google ScholarCross Ref"",""Aravind Chandramouli, Gopi Subramanian, Debasis Bal, SI Ao, C Douglas, WS Grundfest, and J Burgstone. 2013. Unsupervised extraction of part names from service logs. In Proceedings of the World Congress on Engineering and Computer Science, Vol. 2.Google Scholar"",""Sreerupa Das, Christopher D Hollander, and Suraiya Suliman. 2019. Automating Visual Inspection with Convolutional Neural Networks. In Annual Conference of the PHM Society, Vol. 11.Google Scholar"",""Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolutional neural networks on graphs with fast localized spectral filtering. In Advances in neural information processing systems. 3844--3852.Google Scholar"",""Wei Huang, Hamed Khorasgani, Chetan Gupta, Ahmed Farahat, and Shuai Zheng. 2018. Remaining useful life estimation for systems with abrupt failures. In Annual Conference of the PHM Society, Vol. 10.Google Scholar"",""Riashat Islam, Peter Henderson, Maziar Gomrokchi, and Doina Precup. 2017. Reproducibility of benchmarked deep reinforcement learning tasks for continuous control. arXiv preprint arXiv:1708.04133 (2017).Google Scholar"",""Hamed Khorasgani, Arman Hasanzadeh, Ahmed Farahat, and Chetan Gupta. 2019. Fault detection and isolation in industrial networks using graph convolutional neural networks. In 2019 IEEE International Conference on Prognostics and Health Management (ICPHM). IEEE, 1--7.Google ScholarCross Ref"",""Pankaj Malhotra, Vishnu TV, Anusha Ramakrishnan, Gaurangi Anand, Lovekesh Vig, Puneet Agarwal, and Gautam Shroff. 2016. Multi-sensor prognostics using an unsupervised health index based on LSTM encoder-decoder. In 1st ACM SIGKDD Workshop on Machine Learning for Prognostics and Health Management.Google Scholar"",""Prasad Patil and Giovanni Parmigiani. 2018. Training replicable predictors in multiple studies. Proceedings of the National Academy of Sciences, Vol. 115, 11 (2018).Google ScholarCross Ref"",""Fabrice Rossi, Brieuc Conan-Guez, and Francc ois Fleuret. 2002. Functional data analysis with multi layer perceptrons. In Proceedings of the 2002 International Joint Conference on Neural Networks. IJCNN'02 (Cat. No. 02CH37290), Vol. 3. IEEE, 2843--2848.Google ScholarCross Ref"",""Walid Shalaby, Adriano Arantes, Teresa GonzalezDiaz, and Chetan Gupta. 2020. Building chatbots from large scale domain-specific knowledge bases: challenges and opportunities. In 2020 IEEE international conference on prognostics and health management (ICPHM). IEEE.Google ScholarCross Ref"",""Stephan Spiegel, Fabian Mueller, Dorothea Weismann, and John Bird. 2018. Cost-sensitive learning for predictive maintenance. arXiv preprint arXiv:1809.10979 (2018).Google Scholar"",""Domen Tabernik, Samo vS ela, Jure Skvarvc, and Danijel Skovc aj. 2020. Segmentation-based deep-learning approach for surface-defect detection. Journal of Intelligent Manufacturing, Vol. 31, 3 (2020), 759--776.Google ScholarCross Ref"",""Qiyao Wang, Shuai Zheng, Ahmed Farahat, Susumu Serita, and Chetan Gupta. 2019 a. Remaining useful life estimation using functional data analysis. In 2019 IEEE International Conference on Prognostics and Health Management (ICPHM). IEEE, 1--8.Google ScholarCross Ref"",""Qiyao Wang, Shuai Zheng, Ahmed Farahat, Susumu Serita, Takashi Saeki, and Chetan Gupta. 2019 b. Multilayer perceptron for sparse functional data. In 2019 International Joint Conference on Neural Networks (IJCNN). IEEE, 1--10.Google ScholarCross Ref"",""Chi Zhang, Chetan Gupta, Ahmed Farahat, Kosta Ristovski, and Dipanjan Ghosh. 2018. Equipment health indicator learning using deep reinforcement learning. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 488--504.Google Scholar"",""Chi Zhang, Chetan Gupta, Seiji Joichi, Ahmed Farahat, and Huijuan Shao. 2019. Risk-Based Dynamic Pricing via Failure Prediction. In 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA). IEEE, 140--147.Google ScholarCross Ref"",""Shuai Zheng, Ahmed Farahat, and Chetan Gupta. 2019 a. Generative adversarial networks for failure prediction. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 621--637.Google Scholar"",""Shuai Zheng and Chetan Gupta. 2020 a. Discriminant Generative Adversarial Networks with its Application to Equipment Health Classification. In ICASSP 2020--2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 3067--3071.Google ScholarCross Ref"",""Shuai Zheng and Chetan Gupta. 2020 b. Trace Norm Generative Adversarial Networks for Sensor Generation and Feature Extraction. In ICASSP 2020--2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 3187--3191.Google Scholar"",""Shuai Zheng, Chetan Gupta, and Susumu Serita. 2019 b. Manufacturing Dispatching using Reinforcement and Transfer Learning. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 655--671.Google Scholar"",""Shuai Zheng, Kosta Ristovski, Ahmed Farahat, and Chetan Gupta. 2017. Long short-term memory network for remaining useful life estimation. In 2017 IEEE international conference on prognostics and health management (ICPHM). IEEE, 88--95.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3406483,Embedding-Driven Multi-Dimensional Topic Mining and Text Analysis,"People nowadays are immersed in a wealth of text data, ranging from news articles, to social media, academic publications, advertisements, and economic reports. A grand challenge of data mining is to develop effective, scalable and weakly-supervised methods for extracting actionable structures and knowledge from massive text data. Without requiring extensive and corpus-specific human annotations, these methods will satisfy people's diverse applications and needs for comprehending and making good use of large-scale corpora.In this tutorial, we will introduce recent advances in text embeddings and their applications to a wide range of text mining tasks that facilitate multi-dimensional analysis of massive text corpora. Specifically, we first overview a set of recently developed unsupervised and weakly-supervised text embedding methods including state-of-the-art context-free embeddings and pre-trained language models that serve as the fundamentals for downstream tasks. We then present several embedding-driven text mining techniques that are weakly-supervised, domain-independent, language-agnostic, effective and scalable for mining and discovering structured knowledge, in the form of multi-dimensional topics and multi-faceted taxonomies, from large-scale text corpora. We finally show that the topics and taxonomies so discovered will naturally form a multi-dimensional TextCube structure, which greatly enhances text exploration and analysis for various important applications, including text classification, retrieval and summarization. We will demonstrate on the most recent real-world datasets (including political news articles as well as scientific publications related to the coronavirus) how multi-dimensional analysis of massive text corpora can be conducted with the introduced embedding-driven text mining techniques.","[{""name"":""Yu Meng"",""id"":""/profile/99659316366""},{""name"":""Jiaxin Huang"",""id"":""/profile/99659536420""},{""name"":""Jiawei Han"",""id"":""/profile/81548005096""},{""name"":""Yu Meng"",""id"":""/profile/99659316366""},{""name"":""Jiaxin Huang"",""id"":""/profile/99659536420""},{""name"":""Jiawei Han"",""id"":""/profile/81548005096""}]","[""David M. Blei, Thomas L. Griffiths, Michael I. Jordan, and Joshua B. Tenenbaum. 2003 a. Hierarchical Topic Models and the Nested Chinese Restaurant Process. In NIPS.Google Scholar"",""David M. Blei and Jon D. McAuliffe. 2007. Supervised Topic Models. In NIPS.Google Scholar"",""David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003 b. Latent Dirichlet Allocation. In J. Mach. Learn. Res.Google Scholar"",""Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2016. Enriching Word Vectors with Subword Information. Transactions of the Association for Computational Linguistics, Vol. 5 (2016), 135--146.Google ScholarCross Ref"",""Xuan Cai and Wenjie Li. 2013. Ranking Through Clustering: An Integrated Approach to Multi-Document Summarization. IEEE Transactions on Audio, Speech, and Language Processing, Vol. 21 (2013), 1424--1433.Google ScholarDigital Library"",""Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In NAACL-HLT.Google Scholar"",""Jiaxin Huang, Yiqing Xie, Yu Meng, Jiaming Shen, Yunyi Zhang, and Jiawei Han. 2020 a. Guiding Corpus-based Set Expansion by Auxiliary Sets Generation and Co-Expansion. In WWW.Google Scholar"",""Jiaxin Huang, Yiqing Xie, Yu Meng, Yunyi Zhang, and Jiawei Han. 2020 b. CoRel: Seed-Guided Topical Taxonomy Construction by Concept Learning and Relation Transferring. In KDD.Google Scholar"",""Jagadeesh Jagarlamudi, Hal Daumé, and Raghavendra Udupa. 2012. Incorporating Lexical Priors into Topic Models. In EACL.Google Scholar"",""Chenliang Li, Weiran Xu, Si Li, and Sheng Gao. 2018. Guiding Generation for Abstractive Text Summarization Based on Key Information Guide Network. In NAACL-HLT.Google Scholar"",""Yu Meng, Jiaxin Huang, Guangyuan Wang, Zihan Wang, Chao Zhang, and Jiawei Han. 2020 a. Unsupervised Word Embedding Learning by Incorporating Local and Global Contexts. Frontiers in Big Data (2020).Google Scholar"",""Yu Meng, Jiaxin Huang, Guangyuan Wang, Zihan Wang, Chao Zhang, Yu Zhang, and Jiawei Han. 2020 b. Discriminative Topic Mining via Category-Name Guided Text Embedding. In WWW.Google Scholar"",""Yu Meng, Jiaxin Huang, Guangyuan Wang, Chao Zhang, Honglei Zhuang, Lance M. Kaplan, and Jiawei Han. 2019 a. Spherical Text Embedding. In NeurIPS.Google Scholar"",""Yu Meng, Jiaming Shen, Chao Zhang, and Jiawei Han. 2018. Weakly-Supervised Neural Text Classification. In CIKM.Google Scholar"",""Yu Meng, Jiaming Shen, Chao Zhang, and Jiawei Han. 2019 b. Weakly-Supervised Hierarchical Text Classification. In AAAI.Google Scholar"",""Yu Meng, Yunyi Zhang, Jiaxin Huang, Yu Zhang, Chao Zhang, and Jiawei Han. 2020 c. Hierarchical Topic Mining via Joint Spherical Tree and Text Embedding. In KDD.Google Scholar"",""Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S. Corrado, and Jeffrey Dean. 2013. Distributed Representations of Words and Phrases and their Compositionality. In NIPS.Google Scholar"",""David M. Mimno, Wei Li, and Andrew McCallum. 2007. Mixtures of hierarchical topics with Pachinko allocation. In ICML.Google Scholar"",""Maximilian Nickel and Douwe Kiela. 2017. Poincaré Embeddings for Learning Hierarchical Representations. In NIPS.Google Scholar"",""Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. Glove: Global Vectors for Word Representation. In EMNLP.Google Scholar"",""Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. Deep contextualized word representations. In NAACL-HLT.Google Scholar"",""Jiaming Shen, Zeqiu Wu, Dongming Lei, Jingbo Shang, Xiang Ren, and Jiawei Han. 2017. SetExpan: Corpus-Based Set Expansion via Context Feature Selection and Rank Ensemble. In ECMLPKDD.Google Scholar"",""Fangbo Tao, Chao Zhang, Xiusi Chen, Meng Jiang, Tim Hanratty, Lance M. Kaplan, and Jiawei Han. 2018. Doc2Cube: Allocating Documents to Text Cube Without Labeled Data. 2018 IEEE International Conference on Data Mining (ICDM) (2018), 1260--1265.Google ScholarCross Ref"",""Fangbo Tao, Honglei Zhuang, Chi Wang Yu, Qi Wang, Taylor Cassidy, Lance M. Kaplan, Clare R. Voss, and Jiawei Han. 2016. Multi-Dimensional, Phrase-Based Summarization in Text Cubes. IEEE Data Eng. Bull., Vol. 39 (2016), 74--84.Google Scholar"",""Alexandru Tifrea, Gary Bécigneul, and Octavian-Eugen Ganea. 2019. Poincaré GloVe: Hyperbolic Word Embeddings. In ICLR.Google Scholar"",""Zhilin Yang, Zihang Dai, Yiming Yang, Jaime G. Carbonell, Ruslan Salakhutdinov, and Quoc V. Le. 2019. XLNet: Generalized Autoregressive Pretraining for Language Understanding. In NeurIPS.Google Scholar"",""Chao Zhang, Fangbo Tao, Xiusi Chen, Jiaming Shen, Meng Jiang, Brian M. Sadler, Michelle T. Vanni, and Jiawei Han. 2018. TaxoGen: Constructing Topical Concept Taxonomy by Adaptive Term Embedding and Clustering. In KDD.Google Scholar"",""Yu Zhang, Yu Meng, Jiaxin Huang, Frank F. Xu, Xuan Wang, and Jiawei Han. 2020. Minimally Supervised Categorization of Text with Metadata. In SIGIR.Google Scholar"",""Yonghui Zhang, Yunqing Xia, Yi Liu, and Wenmin Wang. 2015. Clustering Sentences with Density Peaks for Multi-document Summarization. In HLT-NAACL.Google Scholar""]"
https://doi.org/10.1145/3394486.3406484,Learning by Exploration: New Challenges in Real-World Environments,"Learning is a predominant theme for any intelligent system, humans, or machines. Moving beyond the classical paradigm of learning from past experience, e.g., offline supervised learning from given labels, a learner needs to actively collect exploratory feedback to learn from the unknowns, i.e., learning through exploration. This tutorial will introduce the learning by exploration paradigm, which is the key ingredient in many interactive online learning problems, including the multi-armed bandit and, more generally, reinforcement learning problems.In this tutorial, we will first motivate the need for exploration in machine learning algorithms and highlight its importance in many real-world problems where online sequential decision making is involved. In real-world application scenarios, considerable challenges arise in such a learning problem, including sample complexity, costly and even outdated feedback, and ethical considerations of exploration (such as fairness and privacy). We will introduce several classical exploration strategies and then highlight the aforementioned three fundamental challenges in the learning from exploration paradigm and introduce the recent research development on addressing them, respectively.","[{""name"":""Qingyun Wu"",""id"":""/profile/99659048793""},{""name"":""Huazheng Wang"",""id"":""/profile/99659048949""},{""name"":""Hongning Wang"",""id"":""/profile/81466648782""},{""name"":""Qingyun Wu"",""id"":""/profile/99659048793""},{""name"":""Huazheng Wang"",""id"":""/profile/99659048949""},{""name"":""Hongning Wang"",""id"":""/profile/81466648782""}]","[""Y. Abbasi-yadkori, D. Pál, and C. Szepesvári. Improved algorithms for linear stochastic bandits. In NIPS, pages 2312--2320. 2011.Google ScholarDigital Library"",""S. Agrawal and N. Goyal. Thompson sampling for contextual bandits with linear payoffs. In International Conference on Machine Learning, pages 127--135, 2013.Google ScholarDigital Library"",""P. Auer. Using confidence bounds for exploitation-exploration trade-offs. Journal of Machine Learning Research, 3(Nov):397--422, 2002.Google Scholar"",""P. Auer, N. Cesa-Bianchi, and P. Fischer. Finite-time analysis of the multiarmed bandit problem. Mach. Learn., 47(2--3):235--256, May 2002.Google Scholar"",""Y. Cao, Z. Wen, B. Kveton, and Y. Xie. Nearly optimal adaptive procedure with change detection for piecewise-stationary bandit. arXiv preprint arXiv:1802.03692, 2018.Google Scholar"",""N. Cesa-Bianchi, C. Gentile, and G. Zappella. A gang of bandits. In Pro. NIPS, 2013.Google Scholar"",""Y. Chen, A. Cuellar, H. Luo, J. Modi, H. Nemlekar, and S. Nikolaidis. The fair contextual multi-armed bandit. In Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems, pages 1810--1812, 2020.Google ScholarDigital Library"",""Y. Chen, C.-W. Lee, H. Luo, and C.-Y. Wei. A new algorithm for non-stationary contextual bandits: Efficient, optimal, and parameter-free. In Conference on Learning Theory, 2019.Google Scholar"",""A. Garivier and E. Moulines. On upper-confidence bound policies for non-stationary bandit problems. In arXiv preprint arXiv:0805.3415 (2008).Google Scholar"",""C. Gentile, S. Li, P. Kar, A. Karatzoglou, G. Zappella, and E. Etrue. On context-dependent clustering of bandits. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages 1253--1262. JMLR. org, 2017.Google ScholarDigital Library"",""C. Gentile, S. Li, and G. Zappella. Online clustering of bandits. In Pro. of the 31st International Conference on Machine Learning (ICML-14), pages 757--765, 2014.Google Scholar"",""N. Hariri, B. Mobasher, and R. Burke. Adapting to user preference changes in interactive recommendation. In Proceedings of the 24th International Conference on Artificial Intelligence, IJCAI'15, pages 4268--4274. AAAI Press, 2015.Google ScholarDigital Library"",""M. Joseph, M. Kearns, J. H. Morgenstern, and A. Roth. Fairness in learning: Classic and contextual bandits. In Advances in Neural Information Processing Systems, pages 325--333, 2016.Google ScholarDigital Library"",""E. Kaufmann, N. Korda, and R. Munos. Thompson sampling: An asymptotically optimal finite-time analysis. In International conference on algorithmic learning theory, pages 199--213. Springer, 2012.Google ScholarDigital Library"",""B. Kveton, C. Szepesvari, M. Ghavamzadeh, and C. Boutilier. Perturbed-history exploration in stochastic linear bandits. arXiv preprint arXiv:1903.09132, 2019.Google Scholar"",""B. Kveton, C. Szepesvari, S. Vaswani, Z. Wen, T. Lattimore, and M. Ghavamzadeh. Garbage in, reward out: Bootstrapping exploration in multi-armed bandits. In International Conference on Machine Learning, pages 3601--3610, 2019.Google Scholar"",""J. Langford and T. Zhang. The epoch-greedy algorithm for contextual multi-armed bandits. In Proceedings of the 20th International Conference on Neural Information Processing Systems, NIPS'07, page 817--824, Red Hook, NY, USA, 2007. Curran Associates Inc.Google ScholarDigital Library"",""L. Li, W. Chu, J. Langford, and R. E. Schapire. A contextual-bandit approach to personalized news article recommendation. In Proceedings of 19th WWW, pages 661--670. ACM, 2010.Google ScholarDigital Library"",""S. Li, A. Karatzoglou, and C. Gentile. Collaborative filtering bandits. In Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval, pages 539--548, 2016.Google ScholarDigital Library"",""H. Luo, C.-Y. Wei, A. Agarwal, and J. Langford. Efficient contextual bandits in non-stationary worlds. In Conference On Learning Theory, pages 1739--1776, 2018.Google Scholar"",""Y. Russac, C. Vernade, and O. Cappé. Weighted linear bandits for non-stationary environments. In Advances in Neural Information Processing Systems, pages 12040--12049, 2019.Google Scholar"",""R. Shariff and O. Sheffet. Differentially private contextual linear bandits. In Advances in Neural Information Processing Systems, pages 4296--4306, 2018.Google Scholar"",""R. S. Sutton, A. G. Barto, et al. Introduction to reinforcement learning, volume 135. MIT press Cambridge, 1998.Google Scholar"",""H. Wang, S. Kim, E. McCord-Snook, Q. Wu, and H. Wang. Variance reduction in gradient exploration for online learning to rank. In 42nd ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR'19, pages 835--844. ACM, 2019.Google ScholarDigital Library"",""H. Wang, Q. Wu, and H. Wang. Learning hidden features for contextual bandits. In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management, pages 1633--1642, 2016.Google ScholarDigital Library"",""H. Wang, Q. Wu, and H. Wang. Factorization bandits for interactive recommendation. In Thirty-First AAAI Conference on Artificial Intelligence, 2017.Google ScholarDigital Library"",""Q. Wu, N. Iyer, and H. Wang. Learning contextual bandits in a collaborative environment. In SIGIR 2018.Google Scholar"",""Q. Wu, Z. Li, H. Wang, W. Chen, and H. Wang. Factorization bandits for online influence maximization. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining, pages 636--646, 2019.Google ScholarDigital Library"",""Q. Wu, H. Wang, Q. Gu, and H. Wang. Contextual bandits in a collaborative environment. In Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval, pages 529--538, 2016.Google ScholarDigital Library"",""Q. Wu, H. Wang, Y. Li, and H. Wang. Dynamic ensemble of contextual bandits to satisfy users' changing interests. In The World Wide Web Conference, WWW '19, pages 2080--2090, New York, NY, USA, 2019. ACM.Google ScholarDigital Library"",""C. Zhang, A. Agarwal, H. D. Iii, J. Langford, and S. Negahban. Warm-starting contextual bandits: Robustly combining supervised and bandit feedback. In K. Chaudhuri and R. Salakhutdinov, editors, Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pages 7335--7344, Long Beach, California, USA, 09-15 Jun 2019. PMLR.Google Scholar"",""J. Zhang and E. Bareinboim. Transfer learning in multi-armed bandit: a causal approach. In Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems, pages 1778--1780, 2017.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3406485,Image and Video Understanding for Recommendation and Spam Detection Systems,"Image and video-based content has become ever present in a variety of domains like news, entertainment and education. Users typically discover and engage with content via search and recommendation systems. It is also important to serve high quality data to users by filtering out irrelevant or harmful content. Thus, there is an increasing need to leverage the rich information in image and video content in order to power systems for search and recommendation. At the same time, the effectiveness and efficiency of these systems has been accelerated by the availability of large-scale labeled datasets and sophisticated deep learning-based models.This tutorial is aimed at providing an overview of image and video understanding, and their practical applications in the industry. We focus on deep learning-based state of the art techniques for image and video understanding. This includes tasks like image classification and segmentation, image-based content retrieval and video classification. We also focus on applications of these technologies to large-scale recommendation and low quality content detection systems. We present concrete examples from various LinkedIn production systems, and also discuss associated practical challenges.","[{""name"":""Aman Gupta"",""id"":""/profile/99659574797""},{""name"":""Sirjan Kafle"",""id"":""/profile/99659573687""},{""name"":""Di Wen"",""id"":""/profile/99659574809""},{""name"":""Dylan Wang"",""id"":""/profile/99659573914""},{""name"":""Sumit Srivastava"",""id"":""/profile/99659573881""},{""name"":""Suhit Sinha"",""id"":""/profile/99659575199""},{""name"":""Nikita Gupta"",""id"":""/profile/99659573377""},{""name"":""Bharat Jain"",""id"":""/profile/99659573765""},{""name"":""Ananth Sankar"",""id"":""/profile/99659574619""},{""name"":""Liang Zhang"",""id"":""/profile/87258839357""},{""name"":""Aman Gupta"",""id"":""/profile/99659574797""},{""name"":""Sirjan Kafle"",""id"":""/profile/99659573687""},{""name"":""Di Wen"",""id"":""/profile/99659574809""},{""name"":""Dylan Wang"",""id"":""/profile/99659573914""},{""name"":""Sumit Srivastava"",""id"":""/profile/99659573881""},{""name"":""Suhit Sinha"",""id"":""/profile/99659575199""},{""name"":""Nikita Gupta"",""id"":""/profile/99659573377""},{""name"":""Bharat Jain"",""id"":""/profile/99659573765""},{""name"":""Ananth Sankar"",""id"":""/profile/99659574619""},{""name"":""Liang Zhang"",""id"":""/profile/87258839357""}]","[""Sami Abu-El-Haija, Nisarg Kothari, Joonseok Lee, Paul Natsev, George Toderici, Balakrishnan Varadarajan, and Sudheendra Vijayanarasimhan. 2016. YouTube- 8M: A Large-Scale Video Classification Benchmark. CoRR abs/1609.08675 (2016). arXiv:1609.08675 http://arxiv.org/abs/1609.08675Google Scholar"",""Relja Arandjelovic, Petr Gronat, Akihiko Torii, Tomas Pajdla, and Josef Sivic. 2016. NetVLAD: CNN architecture for weakly supervised place recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 5297--5307.Google ScholarCross Ref"",""William Chan, Navdeep Jaitly, Quoc Le, and Oriol Vinyals. 2016. Listen, attend and spell: A neural network for large vocabulary conversational speech recognition. In 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 4960--4964.Google ScholarCross Ref"",""Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick. 2017. Mask r-cnn. In Proceedings of the IEEE international conference on computer vision. 2961--2969.Google ScholarCross Ref"",""Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural Computation 9, 8 (1997), 1735--1780.Google ScholarDigital Library"",""Joonseok Lee, Sami Abu-El-Haija, Balakrishnan Varadarajan, and Apostol (Paul) Natsev. 2018. Collaborative Deep Metric Learning for Video Understanding. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. ACM, 481--490.Google ScholarDigital Library"",""David G Lowe. 1999. Object recognition from local scale-invariant features. In Proceedings of the seventh IEEE international conference on computer vision, Vol. 2. Ieee, 1150--1157.Google ScholarDigital Library"",""Antoine Miech, Ivan Laptev, and Josef Sivic. 2017. Learnable pooling with Context Gating for video classification. CoRR abs/1706.06905 (2017). arXiv:1706.06905 http://arxiv.org/abs/1706.06905Google Scholar"",""Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. 2015. Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks. In Advances in Neural Information Processing Systems 28, C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett (Eds.). Curran Associates, Inc., 91--99. http://papers.nips.cc/paper/ 5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks. pdfGoogle ScholarDigital Library"",""David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. 1985. Learning internal representations by error propagation. Technical Report. California Univ San Diego La Jolla Inst for Cognitive Science.Google Scholar"",""Karen Simonyan and Andrew Zisserman. 2014. Two-stream convolutional networks for action recognition in videos. In Advances in neural information processing systems. 568--576.Google Scholar"",""Khurram Soomro, Amir Roshan Zamir, and Mubarak Shah. 2012. UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild. CoRR abs/1212.0402 (2012). arXiv:1212.0402 http://arxiv.org/abs/1212.0402Google Scholar"",""Nitish Srivastava, Elman Mansimov, and Ruslan Salakhudinov. 2015. Unsupervised learning of video representations using LSTMs. In International Conference on Machine Learning. 843--852.Google ScholarDigital Library"",""Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. 2016. Rethinking the Inception Architecture for Computer Vision. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2818--2826.Google ScholarCross Ref"",""Du Tran, Lubomir Bourdev, Rob Fergus, Lorenzo Torresani, and Manohar Paluri. 2015. Learning spatiotemporal features with 3D convolutional networks. In Proceedings of the IEEE International Conference on Computer Vision (ICCV). 4489--4497.Google ScholarDigital Library""]"
https://doi.org/10.1145/3394486.3406486,Data-Driven Never-Ending Learning Question Answering Systems,"This tutorial focuses on how to build Question Answering (QA) syetems based on the Never-Ending Learning (NEL) approach. NEL systems can be roughly described as computer systems that learn over time to become better in solving a specific task. Different NEL approaches have been proposed and applied in different tasks and domains. Recent advances encourage us to keep addressing the problem of how to build computer systems that can take advantage of NEL principles. Considering that it is not always so straightforward to have NEL principles applied to ML models, this tutorial guides the audience (with hands-on examples and supporting theory, algorithms and models) on how to model a system in a NEL fashion and intends to help KDD community to become familiar with such approaches. Question Answering is chosen as application domain mainly because of the relevance of the topic (QA) for KDD and AI communities in general.","[{""name"":""Estevam Hruschka"",""id"":""/profile/81350590099""},{""name"":""Estevam Hruschka"",""id"":""/profile/81350590099""}]",null
https://doi.org/10.1145/3394486.3411063,How Can Computer Science Education Address Inequities,"The 2019 global pandemic and the social protests in support of Black Lives Matter has made it clear that society has yet to eradicate systemic racism. Can computing education help? Academics, particularly in STEM fields, are often shielded from these conversations as we think they belong in a social science classroom. The effect of the pandemic and the protests has made it abundantly clear that we can no longer be apathetic about systemic issues that impact equity in society. Based on personal experience and on years of participation in Broadening Participation in Computing (BPC) efforts, the author suggests actions that CS departments can do to fight inequity. These can be classified into several broad categories: (a) provide more support and opportunities to students from underrepresented groups, (b) encourage faculty to become active participants in addressing inequity, (c) update the computing curriculum to be more inclusive and culturally responsive, and (d) evolve the departmental infrastructure to manage diversity, equity and inclusion.","[{""name"":""Manuel A. Pérez-Quiñones"",""id"":""/profile/81100175306""},{""name"":""Manuel A. Pérez-Quiñones"",""id"":""/profile/81100175306""}]",null
https://doi.org/10.1145/3394486.3411064,"Diversity and Inclusion, a Perspective from a Four Years MSI Faculty Member","This presentation provides information on the path taken by a faculty member at a Minority Serving Institution (MSI). She presents the difficulties and opportunities that have been presented to her and, as a role model she has managed to improve the quality of life of her students. Knowing the distribution of the population in computer areas (by race, gender, and other characteristics) is relevant to be able to introduce the concept of diversity, equality, and inclusion and to establish basic strategies to improve these characteristics in the work and study environments for minority populations.On the other hand, it is important to know the types of bias and how this issue has been addressed (successfully and unsuccessfully) in companies related to computing and the impact it generates on diversity, inclusion, and equity.Finally, we will briefly mention how the issue of diversity, inclusion, and bias impacts research results, particularly in data science.","[{""name"":""Eliana Valenzuela-Andrade"",""id"":""/profile/99659573262""},{""name"":""Eliana Valenzuela-Andrade"",""id"":""/profile/99659573262""}]",null
https://doi.org/10.1145/3394486.3411065,CoRE Lab - An Effort to Engage College Hispanic Students in STEM,"According to PCAST 2012 report [1], from 2012 to 2021 the number in STEM graduates must be increased by 1 million in order to meet the nation's workforce needed. By 2018, the Hispanic community comprised only the six percent of the US workforce in STEM [2]. This scenario presents a continuous challenge for Hispanic Serving Institutions (HIS).The Computing Research and Engineering Lab (CoRE Lab) was created as an initiative to attend the lack of engagement of Computer Engineering Students at Inter American University of Puerto Rico - Bayamon campus, an HSI.We at CoRE Lab used the participation of students at STEM related competitions as a hook to create a coworking space to engage students. The space turned challenges into opportunities to develop students' skills and increase their engagement. First, a relatively big number of students (25+) working in the same physical space was used to develop leadership skills; leaders were assigned to different sub teams according to the requirements of the different projects. Second, students from different levels converging at CoRE Lab presented a diversity challenge. This was turned into the opportunity to practice mentoring between students. Third, engineering students working at one or two projects presented a time management challenge. This situation was used to develop time management skills. Students were required to create schedules and to generate periodical reports on their progress. In addition, and with the support of the Computing Alliance of Hispanic Serving Institutions (CAHSI), the CoRE Lab space was the ideal space to implement an evidence-based practice Peer-Led-Team Learning (PLTL) with success.Finally, a key factor in the success of CoRE Lab was the dynamic of the interaction in the group. The space was recognized by the students as Their space, adding a sense of belonging to the space. It is recognized as a place where students can work on their projects, study, and share while improving their academic and professional skills.The success of this effort can be seen through different factors after three years of the first project: first, the number of students participating in extracurricular projects went from six to twenty seven; second, the number of students participating in summer internships went from seven to seventeen; third, the full implementation of the PLTL program for CS1 was consolidate with eight totally volunteer students and impacting over fifty computer engineering freshmen in the last academic year.","[{""name"":""Wilson E. Lozano-Rolon"",""id"":""/profile/99659574861""},{""name"":""Wilson E. Lozano-Rolon"",""id"":""/profile/99659574861""}]","[""President's Council of Advisors on Science and Technology, Engage to excel: producing one million additional college graduates with degrees in science, technology, engineering, and mathematics (Executive Office of the President of the United States, 2012).Google Scholar"",""National Academies of Sciences, Engineering, and Medicine. (2019). Minority serving institutions: America's underutilized resource for strengthening the STEM workforce. National Academies Press.Google Scholar""]"
https://doi.org/10.1145/3394486.3411066,Support for Diverse Students,This talk is intended to motivate diverse students in their study of computer science and engineering. Prof. Jiménez discusses the path he took to become a computer science professor. He describes his efforts promoting women and under-represented minorities in computer science and engineering. He ends with some advice to diverse students.,"[{""name"":""Daniel A. Jiménez"",""id"":""/profile/81100242990""},{""name"":""Daniel A. Jiménez"",""id"":""/profile/81100242990""}]",null
https://doi.org/10.1145/3394486.3411067,Broadening Participation in Technology Policy,"Those who work in politics and policy are often unprepared to address the issues that current technology developments have created. A glaring example is the congressional hearings with Facebook where Congress Members asked embarrassingly fundamental questions and were not able to get to the heart of the issue. Many congress people do not have technology advisor on staff to assist in addressing technical issues. Not only does Congress not have technology experts on staff, but the few who are involved are not from underrepresented minority communities. This makes it even more difficult to adequately address issues that more directly impact communities of color including predictive policing, voter suppression, and facial recognition.The PhDx fellowship program was created by the Media Democracy Fund to bridge this gap. Underrepresented PhD students in STEM fields spend multiple summers working in various technology policy outlets including Upturn, Free Press, and the Leadership Conference on Civil Rights. In this talk, I will discuss my experience in the program, how it helped me to understand the various career paths I could take in the policy realm with a technical degree, and how I have been able to make a meaningful impact in the field for my community.","[{""name"":""Brianna B. Posadas"",""id"":""/profile/99659574056""},{""name"":""Brianna B. Posadas"",""id"":""/profile/99659574056""}]",null
https://doi.org/10.1145/3394486.3411068,"The Dark Side of Machine Learning Algorithms: How and Why They Can Leverage Bias, and What Can Be Done to Pursue Algorithmic Fairness","Machine learning and access to big data are revolutionizing the way many industries operate, providing analytics and automation to many aspects of real-world practical tasks that were previously thought to be necessarily manual. With the pervasiveness of artificial intelligence and machine learning over the past decade, and their epidemic spread in a variety of applications, algorithmic fairness has become a prominent open research problem. For instance, machine learning is used in courts to assess the probability that a defendant recommits a crime; in the medical domain to assist with diagnosis or predict predisposition to certain diseases; in social welfare systems; and autonomous vehicles. The decision making processes in these real-world applications have a direct effect on people's lives, and can cause harm to society if the machine learning algorithms deployed are not designed with considerations to fairness.The ability to collect and analyze large datasets for problems in many domains brings forward the danger of implicit data bias, which could be harmful. Data, especially big data, is often heterogeneous, generated by different subgroups with their owncharacteristics and behaviors. Furthermore, data collection strategies vary vastly across domains, and labelling of examples is performed by human annotators, thus causing the labelling process to amplify inherent biases the annotators might harbor. A model learned on biased data may not only lead to unfair and inaccurate predictions, but also significantly disadvantage certain subgroups, and lead to unfairness in downstream learning tasks. There aremultiple ways in which discriminatory bias can seep into data: for example, in medical domains, there are many instances in whichthe data used are skewed toward certain populations-which canhave dangerous consequences for the underrepresented communities [1]. Another example are large-scale datasets widely used in machine learning tasks, like ImageNet and Open Images: [2] shows that these datasets suffer from representation bias, and advocates for the need to incorporate geo-diversity and inclusion. Yet another example are the popular face recognition and generation datasets like CelebA and Flickr-Faces-HQ, where the ethnic and racial breakdown of example faces shows significant representation bias, evident in downstream tasks like face reconstruction from an obfuscated image [8].In order to be able to fight discriminatory use of machine learning algorithms that leverage such biases, one needs to first define the notion of algorithmic fairness. Broadly, fairness is the absence of any prejudice or favoritism towards an individual or a group based on their intrinsic or acquired traits in the context of decision making [3]. Fairness definitions fall under three broad types: individual fairness (whereby similar predictions are given to similar individuals [4, 5]), group fairness (whereby different groups are treated equally [4, 5]), and subgroup fairness (whereby a group fairness constraint is being selected, and the task is to determine whether the constraint holds over a large collection of subgroups [6, 7]). In this talk, I will discuss a formal definition of these fairness constraints, examine the ways in which machine learning algorithms can amplify representation bias, and discuss how bias in both the example set and label set of popular datasets has been misused in a discriminatory manner. I will touch upon the issues of ethics and accountability, and present open research directions for tackling algorithmic fairness at the representation level.","[{""name"":""Mariya I. Vasileva"",""id"":""/profile/99659573898""},{""name"":""Mariya I. Vasileva"",""id"":""/profile/99659573898""}]","[""Arjun K. Manrai, Birgit H. Funke, Heidi L. Rehm, Morten S. Olesen, Bradley A. Maron, Peter Szolovits, David M. Margulies, Joseph Loscalzo, and Isaac S. Kohane. 2016. Genetic Misdiagnoses and the Potential for Health Disparities. New England Journal of Medicine 375, 7 (2016), 655--665. PMID: 27532831.Google ScholarCross Ref"",""Shreya Shankar, Yoni Halpern, Eric Breck, James Atwood, Jimbo Wilson, and D Sculley. 2017. No Classification without Representation: Assessing Geodiversity Issues in Open Data Sets for the Developing World. stat 1050 (2017), 22.Google Scholar"",""Nripsuta Ani Saxena, Karen Huang, Evan DeFilippis, Goran Radanovic, David C Parkes, and Yang Liu. 2019. How Do Fairness Definitions Fare? Examining Public Attitudes Towards Algorithmic Definitions of Fairness. In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society. ACM, 99--106.Google ScholarDigital Library"",""Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. 2012. Fairness Through Awareness. In Proceedings of the 3rd Innovations in Theoretical Computer Science Conference (ITCS '12). ACM, New York, NY, USA, 214--226.Google ScholarDigital Library"",""Matt J Kusner, Joshua Loftus, Chris Russell, and Ricardo Silva. 2017. Counterfactual Fairness. In Advances in Neural Information Processing Systems 30, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.). Curran Associates, Inc., 4066--4076.Google ScholarDigital Library"",""Michael Kearns, Seth Neel, Aaron Roth, and Zhiwei Steven Wu. 2018. Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness. In International Conference on Machine Learning. 2569--2577.Google Scholar"",""Michael Kearns, Seth Neel, Aaron Roth, and Zhiwei Steven Wu. 2019. An empirical study of rich subgroup fairness for machine learning. In Proceedings of the Conference on Fairness, Accountability, and Transparency. ACM, 100--109.Google ScholarDigital Library"",""Sachit Menon, Alex Damian, McCourt Hu, Nikhil Ravi, and Cynthia Rudin. 2020. PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR).Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3411069,Accessible Online Meetings and Presentations,"In our current situation, conferences, classes, and meetings are moving online. What steps can you take to ensure that your activities are welcoming to a diverse audience, including people with disabilities? This presentation will look at proactive strategies you can take to ensure that your meetings and presentations are accessible to a wide audience. We'll talk about communication with participants, preparation, presentation materials, technology, and accommodations.","[{""name"":""Brianna Blaser"",""id"":""/profile/99658690219""},{""name"":""Brianna Blaser"",""id"":""/profile/99658690219""}]",null
https://doi.org/10.1145/3394486.3411070,"Perspectives on Broadening Participation in STEM Careers across Academia, Government, and Industry","Bias, defined as prejudice for or against something/someone, is a central component of our understanding of everyday life. In particular, the technology that you interact with daily and the teams that you work with help to inform your biases. For minority populations in technology, often being the lone representative for diverging perspectives, the inclusion of potentially harmful bias in technology projects is easily discernable, even if it has proven near impossible to resist.The ethical use of data has been given more attention lately for good cause. Interpretations driven from unethical handling of data can have far-reaching consequences. The other component is ensuring participation from data science research inception. The shaping of how questions are asked informs the data and methods used to answer those questions but also defines the manifestation of bias in our research. Unfortunately, the participation of ethnic and gender minorities is not enthusiastically considered across professional workspaces. This is especially true for an entry-level position that requires a leap of faith when hiring individuals from diverse backgrounds. While there are gaping holes throughout the progression of STEM professionals' careers (e.g. promotion to senior-level positions), a glaring need is an improved approach to providing opportunities to early-career technologists from diverse backgrounds.How do we develop a pipeline that promotes ethnic and gender diversity in STEM fields? Various initiatives have sought to lessen the gap between the white/Asian male domination in technology and other groups. Professional/social organizations that seek to assemble similar subsets of the larger technology workforce have become a popular networking resource. Also, boot camp-style programs that seek to engage pre-professional groups with technical skills (i.e. girls who code) actively train participants within STEM. An additional step that is needed, however, is for young career professionals to be given the very first opportunity to enter the technology workspace. The influx of increasingly diverse populations with equally diverse perspectives on technology and its application/interpretation will improve our ability to build inclusive artificial intelligence while also challenging persistent bias within technology.The need for high-level technologists to bring along early career professionals has never been clearer. An initiative is being developed to encourage small businesses to improve their hiring practices for ethnic and gender minorities. This is being done through mentorship that extends from an academic environment into a professional setting. Ensuring that all technology teams are inclusive and diverse. Having young professionals available from a contract perspective allows for their access to efforts that allow them to continue to build their professional portfolio. This is an ongoing effort that is being prototyped in the Washington DC area for a small business that serves academic, governmental, and industry.","[{""name"":""Hasan Jackson"",""id"":""/profile/99659573602""},{""name"":""Hasan Jackson"",""id"":""/profile/99659573602""}]",null
https://doi.org/10.1145/3394486.3411071,The Illusion of Inclusion: Large Scale Genomic Data Sovereignty and Indigenous Populations,"Raw genomic data has emerged as a top global commodity in the the past several years. This shift is so new that data science experts are still evaluating what such information is worth in a global market. In 2018, the direct-to-consumer genetic-testing company 23andMe sold access to its database containing digital sequence information from approximately 5 million people to GlaxoSmithKline for 300 million dollars. Clearly there is a growing market for these products and like a goldrush, organizations are seeking to find rare samples to package up for analysis and reward. Indigenous peoples are legitimately concerned about the potential for commodification of drugs derived from research on their genomes, and as a consequence, they are sometimes reluctant to participate in genomics research. All of Us, a program of federally funded investigators are interested in recruiting participants from native groups, but given the fraught history of genetic studies involving Indigenous peoples - including examples such as the Havasupai v. Arizona State University, in which the tribe successfully sued the university for improperly using its members' blood samples - tribal communities continue to be wary about participating in the federal government's newest endeavor. Here I contextualize data sovereignty issues and identify strategies to create equity in federal government genomic data collection efforts.","[{""name"":""Keolu Fox"",""id"":""/profile/99659574307""},{""name"":""Keolu Fox"",""id"":""/profile/99659574307""}]",null
https://doi.org/10.1145/3394486.3411072,Models of Data Governance and Advancing Indigenous Genomic Data Sovereignty,"While there has been considerable deliberation about ownership and stewardship of genomic data, as of yet, there does not exist a singular framework that encapsulates the current and future trajectory of how these data governance models can exist for Indigenous communities. We succinctly describe two case studies in the Akimel O'odham (Pima) communities that demonstrate the spectrum of data governance structures, in which tribal members have no input to complete control of data collection and usage. We describe (1) tribal-trust relationships, (2) non-tribal partnerships, and (3) tribally-driven models in context of an Indigenous people whose genomic and health data have been widely misused and exploited by outside researchers and the new narrative in which the O'odham have begun re-asserting their sovereignty in data domains.We demonstrate various strategies or models that communities and researchers can use to discuss data governance for their own best practices, institutions, and community members.","[{""name"":""Krystal S. Tsosie"",""id"":""/profile/99659574233""},{""name"":""Krystal S. Tsosie"",""id"":""/profile/99659574233""}]","[""Native BioData Consortium http://nativebio.org/Google Scholar""]"
https://doi.org/10.1145/3394486.3411074,No Computation without Representation: Avoiding Data and Algorithm Biases through Diversity,"The emergence and growth of research on issues of ethics in Artificial Intelligence, and in particular algorithmic fairness, has roots in an essential observation that structural inequalities in our society are reflected in the data used to train predictive models and in the design of objective functions. While research aiming to mitigate these issues is inherently interdisciplinary, the design of unbiased algorithms and fair socio-technical systems are key desired outcomes which depend on practitioners from the fields of data science and computing. However, these computing fields broadly also suffer from the same under-representation issues that are found in the datasets we analyze. This disconnect affects the design of both the desired outcomes and metrics by which we measure success. If the ethical AI research community accepts this, we tacitly endorse the status quo and contradict the goals of non-discrimination and equity which work on algorithmic fairness, accountability, and transparency seeks to address.Therefore, we advocate in this work for diversifying computing as a core priority of the field and our efforts to achieve ethical AI practices. We draw connections between the lack of diversity within academic and professional computing fields and the type and breadth of the biases encountered in datasets, machine learning models, problem formulations, and the interpretation of results. Examining the current fairness/ethics in AI literature, we highlight cases where this lack of diverse perspectives has been foundational to the inequity in the treatments of underrepresented and protected group data.We also look to other professional communities, such as in the law and health domains, where disparities have been reduced both in the educational diversity of trainees and among their professional practices. We use these lessons to develop a set of key recommendations that provide concrete steps for the computing community to increased diversity: 1) building collaborations with minority serving institutions, 2) prioritizing research collaboration between the ethics in AI community and underrepresented/interdisciplinary groups, and 3) providing enhanced mentorship to trainees at research conferences.","[{""name"":""Caitlin Kuhlman"",""id"":""/profile/99659298059""},{""name"":""Latifa Jackson"",""id"":""/profile/99659574066""},{""name"":""Rumi Chunara"",""id"":""/profile/83458958557""},{""name"":""Caitlin Kuhlman"",""id"":""/profile/99659298059""},{""name"":""Latifa Jackson"",""id"":""/profile/99659574066""},{""name"":""Rumi Chunara"",""id"":""/profile/83458958557""}]",null
https://doi.org/10.1145/3394486.3411075,Mutually Beneficial Collaborations to Broaden Participation of Hispanics in Data Science,"Representation of Hispanics, especially Hispanic women, is notoriously low in data science programs in higher education and in the tech industry. The engagement of undergraduate students in research, often and early in their path towards degree completion, has been championed as one of the principal reforms necessary to increase the number of capable professionals in STEM. The benefits attributed to undergraduate research experiences have been reported to disproportionately benefit individuals from groups that have been historically underrepresented in STEM. The IDI-BD2K (Increasing Diversity in Interdisciplinary Big Data to Knowledge) Program funded by the NIH at the University of Puerto Rico Río Piedras (UPRRP) was designed to bridge the increasing digital and data divide at the university. The college's population is 98 percent Hispanic and yet there is no formal data science program. There also exists a gender imbalance in computing at the College of Natural Sciences at the UPRRP. Over 60 percent of the undergraduate students in Biology are women. However, the percentage of women in Computer Science hovers around 15 percent. The IDI-BD2K was created to address both these concerns and increase the participation of Hispanics in interdisciplinary computational and quantitative research. In this talk, I will highlight the need for mutually beneficial university collaborations to reduce the digital and data divide, create greater awareness of the growing disparities and increase the number of future faculty with experience teaching diverse students.","[{""name"":""Patricia Ordóñez Franco"",""id"":""/profile/99658757014""},{""name"":""Patricia Ordóñez Franco"",""id"":""/profile/99658757014""}]","[""DuBow, W. \u0026 Pruitt, A.S., 2019 Update, NCWIT Scorecard: The Status of Women in Technology. Boulder, CO: NCWIT, www.ncwit.org/scorecardGoogle Scholar"",""Rayome, A.D., 2018, Five Eye-opening statistics about Minorities in Tech. Retrieved July 20, 2020 from https://www.techrepublic.com/article/5-eye-opening-statistics-about-minorities-in-tech/Google Scholar"",""The Carnegie Classification of Institutions of Higher Education (n.d.). About Carnegie Classification. Retrieved July 20, 2020 from http://carnegieclassifications.iu.edu/.Google Scholar"",""Top 20 doctorate-granting institutions ranked by number of minority U.S. citizen and permanent resident doctorate recipients, by race and ethnicity of recipient: 5-year total, 2008--12, Doctorate Recipients from U.S. Universities: 2012 Data Tables, Table 9. Retrieved July 20, 2020 from https://ncses.nsf.gov/pubs/nsf19301/related-resources.Google Scholar"",""Top 20 doctorate-granting institutions ranked by number of minority U.S. citizen and permanent resident doctorate recipients, by ethnicity and race of recipient: 5-year total, 2013--17, NSF Science and Engineering Doctorate Awards, Table 9. Retrieved July 20, 2020 from https://ncses.nsf.gov/pubs/nsf19301/data.Google Scholar""]"
https://doi.org/10.1145/3394486.3411076,Bringing Inclusive Diversity to Data Science: Opportunities and Challenges,"As data science research continues to expand into a variety of applied fields, the need for talented and diverse individuals has been widely acknowledged. Despite this acknowledgement, data science lags behind other STEM disciplines in achieving a diverse workforce. Through work we have undertaken in the past as part of the Broadening Participation in Data Mining workshop (BPDM) and our work with ACM SIGKDD, we seek to build a better workforce that is positioned to address the data science problems of the next hundred years. A significant barrier to trainee long-term career success is their limited ability of underrepresented trainees to demonstrate their analytical abilities and sophisticated inferential talents to address key data issues in our community. In this talk we will present an overview of the goals of the Diversity and Inclusion track and share our vision for how we bridge this diversity divide that our society and our data science workforce needs right now. We are interested in how diversity is encountered across ethnic, gender, and ability identities. To this end we have prepared an exciting new program activities to facilitate broader conversations in the data science field that cover not only technical ideas but innovative thinking in what the future of data science can look like if we diversify the group of contributors and enlarge those included.","[{""name"":""Heriberto Acosta Maestre"",""id"":""/profile/99659573460""},{""name"":""Heriberto Acosta Maestre"",""id"":""/profile/99659573460""}]",null
https://doi.org/10.1145/3394486.3411077,The Data Science Mentoring Fire Next Time: Innovative Strategies for Mentoring in Data Science,"As data mining research and applications continue to expand in to a variety of fields such as medicine, finance, security, etc., the need for talented and diverse individuals is clearly felt. This is particularly the case as Big Data initiatives have taken off in the federal, private and academic sectors, providing a wealth of opportunities, nationally and internationally. The Broadening Participation in Data Mining (BPDM) workshop was created more than 7 years ago with the goal of fostering mentorship, guidance, and connections for minority and underrepresented groups in the data science and machine learning community, while also enriching technical aptitude and exposure for a group of talented students. To date it has impacted the lives of more than 330 underrepresented trainees in data science. We provide a venue to connect talented students with innovative researchers in industry, academia, professional societies, and government. Our mission is to facilitate meaningful, lasting relationships between BPDM participants to ultimately increase diversity in data mining. This most recent workshop took place at Howard University in Washington, DC in February 2019. Here we report on the mentoring strategies that we undertook at the 2019 BPDM and how those were received.","[{""name"":""Latifa Jackson"",""id"":""/profile/99659574066""},{""name"":""Heriberto Acosta Maestre"",""id"":""/profile/99659574216""},{""name"":""Latifa Jackson"",""id"":""/profile/99659574066""},{""name"":""Heriberto Acosta Maestre"",""id"":""/profile/99659574216""}]","[""Jenna Cullinane. 2009. Diversifying the STEM Pipeline: The Model Replication Institutions Program. Institute for Higher Education Policy.ERIC: ED508104. 2009-Dec. https://files.eric.ed.gov/fulltext/ED508104.pdfGoogle Scholar"",""Dunbar, J., Prioleau, D., and Gilbert, J. (2019). CS Motivation for Black/African American Middle School Students, 2019 Research on Equity and Sustained Participation in Engineering, Computing, and Technology (RESPECT), Minneapolis, MN, 2019,pp. 55--59.Google Scholar"",""Alvarez, Alvin and Blume, Arthur and Cervantes, Joseph and Thomas, Lisa. (2009). Tapping the Wisdom Tradition: Essential Elements to Mentoring Students of Color. Professional Psychology: Research and Practice. 40. 181--188. 10.1037/a0012256.Google ScholarCross Ref"",""Trujillo, G., Aguinaldo, P. G., Anderson, C., Bustamante, J., Gelsinger, D. R., Pastor, M., et al. (2015). Near-peer STEM mentoring offers unexpected benefits for mentors from traditionally underrepresented backgrounds. Perspectives on undergraduate research and mentoring: PURM, 4(1).Google Scholar"",""Jackson Latifa, Kuhlman Caitlin, Jackson Fatimah, Fox P. Keolu. 2019. Including Vulnerable Populations in the Assessment of Data From Vulnerable Populations, Frontiers in Big Data (2) https://www.frontiersin.org/article/10.3389/fdata.2019.00019Google Scholar"",""Blaser, B.,Ladner, R.E., and Burgstahler, S. (2018). \""Including Disability in Diversity\"". 2018 Research on Equity and Sustained Participation in Engineering, Computing, and Technology (RESPECT), Baltimore, MD, pp.1--4. 10.1109/RESPECT.2018.8491717.Google Scholar"",""Anna Parkman. (2016) The Imposter Phenomenon in Higher Education: Incidence and Impact. Journal of Higher Education Theory and Practice. 16(1):55--60.Google Scholar"",""Huff, E. W., and Gosha, K. (2018, February). Awareness and Readiness for Graduate School of African American Male Computer Science Students. In 2018 Research on Equity and Sustained Participation in Engineering, Computing, and Technology (RESPECT) (pp. 1--6). IEEE.Google Scholar"",""F. Stukes, H. Chen and T. Tidwell, \""Applying the Engagement, Capacity and Continuity Trilogy for Computing Undergraduates at Johnson C. Smith University,\"" 2018 Research on Equity and Sustained Participation in Engineering, Computing, and Technology (RESPECT), Baltimore, MD, 2018, pp. 1--4. doi: 10.1109/RESPECT.2018.8491711Google Scholar"",""A. Solomon, D. Moon, A. L. Roberts and J. E. Gilbert, \""Not Just Black and Not Just a Woman: Black Women Belonging in Computing,\"" 2018 Research on Equity and Sustained Participation in Engineering, Computing, and Technology (RESPECT), Baltimore, MD, 2018, pp. 1--5.doi: 10.1109/RESPECT.2018.8491700Google Scholar"",""Chesler, Naomi and Mark Chesler. 2002.Gender-Informed Mentoring Strategies for Women Engineering Scholars: On Establishing a Caring Community. Journal of Engineering Education 91(1):49--55. https://doi.org/10.1002/j.2168-9830.2002.tb00672.xGoogle ScholarCross Ref"",""Thomas, K., Willis, L. and Davis, J. (2007), \""Mentoring minority graduate students: issues and strategies for institutions, faculty, and students\"", Equal Opportunities International, Vol. 26 No. 3, pp. 178--192. https://doi.org/10.1108/02610150710735471Google ScholarCross Ref"",""J. O. Thomas, N. Joseph, A. Williams, C. Crum and J. Burge, \""Speaking Truth to Power: Exploring the Intersectional Experiences of Black Women in Computing,\"" 2018 Research on Equity and Sustained Participation in Engineering, Computing, and Technology (RESPECT), Minneapolis, MN, 2018, pp. 1--8. doi: 10.1109/RESPECT.2018.8491718Google Scholar"",""Packard, B. W.-L. (2004). Mentoring and Retention in College Science: Reflections on the Sophomore Year. Journal of College Student Retention: Research, Theory and Practice, 6(3), 289--300. https://doi.org/10.2190/RUKP-XGVY-8LG0-75VHGoogle ScholarCross Ref"",""Montgomery, B. L. (2017). Mapping a Mentoring Roadmap and Developing a Supportive Network for Strategic Career Advancement. SAGE Open. https://doi.org/10.1177/2158244017710288Google Scholar"",""Woloshyn, V., Savage, M., Ratkovic, S., Hands, C. and Martinovic, D. (2019), \""Exploring professors' experiences supporting graduate student well-being in Ontario faculties of education\"", International Journal of Mentoring and Coaching in Education, Vol. 8 No. 4, pp. 397--411. https://doi.org/10.1108/IJMCE-02-2019-0028Google ScholarCross Ref"",""Rorrer, A., Barnes, T., Payton, J., and Zuo, Huifang (2019). Challenges and Opportunities in Evaluating Broadening Participation in Computing: The STARS Evaluation Cohort Model, 2019 Research on Equity and Sustained Participation in Engineering, Computing, and Technology (RESPECT), Minneapolis, MN, 2019, pp. 101--105Google Scholar"",""M. Mejias, K. Jean-Pierre, L. Burge and G. Washington, \""Culturally Relevant CS Pedagogy - Theory and Practice,\"" 2018 Research on Equity and Sustained Participation in Engineering, Computing, andhttps://www.overleaf.com/project/5f17911c939f110001f03766 Technology (RESPECT), Baltimore, MD, 2018, pp. 1--5.doi: 10.1109/RESPECT.2018.8491699Google Scholar"",""J. Denner and S. Bean, \""The Role of Relationships in Engaging Latino/a High School Students in Computer Science,\"" 2018 Research on Equity and Sustained Participation in Engineering, Computing, and Technology (RESPECT), Baltimore, MD, 2018, pp. 1--5.doi: 10.1109/RESPECT.2018.8491715Google Scholar"",""Du, W. (2019). Promoting Sense of Belonging and Interest in Geosciences among Undergraduate Women through Mentoring (Doctoral dissertation, West Virginia University).Google Scholar"",""Russell, L. (2017). Can learning communities boost success of women and minorities in STEM? Evidence from the Massachusetts Institute of Technology. Economics of Education Review, 61, pp. 98--111.Google ScholarCross Ref""]"
https://doi.org/10.1145/3394486.3409548,Preserving Integrity in Online Social Media,"Online social networks provide a platform for sharing information and free expression. However, these networks are also used for malicious purposes, such as distributing misinformation and hate speech, selling illegal drugs, and coordinating sex trafficking or child exploitation. Keeping users on these platforms safe from such harm, known as the problem of Integrity, is a major focus for social media companies. This talk, coming from the perspective of addressing many of these challenges at Facebook, highlights some of the recent progress made in the area of integrity and some of the challenges that lie ahead.","[{""name"":""Alon Halevy"",""id"":""/profile/81100063551""},{""name"":""Alon Halevy"",""id"":""/profile/81100063551""}]",null
https://doi.org/10.1145/3394486.3409549,Straddling the Boundary between Contribution and Solution Driven Science,"Advancing the state of the art in the context of products and services used by hundreds of millions of customers poses challenges that go beyond those associated with advancing the state of the art in customer-free settings. In this talk, I will highlight some of these challenges and discuss approaches to overcoming them in the context of two Amazon services: Amazon Translate and Alexa.","[{""name"":""Daniel Marcu"",""id"":""/profile/81100459689""},{""name"":""Daniel Marcu"",""id"":""/profile/81100459689""}]",null
https://doi.org/10.1145/3394486.3409551,Artificial Intelligence for Healthcare,"We discuss the current and future impact of artificial intelligence (AI) technologies on healthcare. We consider four hierarchical levels of healthcare data generation and processing of increasing complexity and wider implications. At the imaging scanner and instrument level, AI aims at improving, simplifying, and standardizing data acquisition and preparation. We present examples of systems for AI-driven automatic patient iso-centering before a computed tomography scan, deep learning-based image reconstruction, and creation of optimized and standardized visualizations, for example, automatic rib-unfolding. At the reading and reporting levels, AI focuses on the detection and characterization of abnormalities and on automatic measurements in images. We introduce multiple AI systems for the brain, heart, lung, prostate, and musculoskeletal disease. The third level is exemplified by the integrated nature of the clinical data in a patient-specific manner. The AI algorithms at this level focus on risk prediction and stratification, as opposed to merely detecting, measuring, and quantifying images. An AI-based approach for individualizing radiation dose in lung stereotactic body radiotherapy is discussed. The digital twin is presented as a concept of individualized computational modeling of human physiology. Finally, at the cohort and population analysis levels, the focus of AI shifts from clinical decision-making to operational decisions and process optimization.","[{""name"":""Dorin Comaniciu"",""id"":""/profile/81100469663""},{""name"":""Dorin Comaniciu"",""id"":""/profile/81100469663""}]",null
https://doi.org/10.1145/3394486.3409553,Using Machine Learning to Detect Cancer Early,"GRAIL's mission is to detect cancer early, when it can be cured. Building a classifier that can detect cancer early in a clinical setting is a complicated endeavor with unique challenges: data acquisition and stabilization can take years; cancer status (labels) can be ambiguous, noisy, and changing; sequencing data can be enormous and presents scaling issues. Because the cancer early detection machine learning classifier is being built in the context of a clinical trial environment, an extra level of rigor and planning is required.Through the Circulating Cell-free Genome Atlas study, GRAIL has collected blood samples from >15,000 patients with and without cancer on which to train and validate the classifier. Results on a validation set show that the GRAIL classifier can detect >50 cancers with >99% specificity. The correct tissue of origin can be identified approximately 90% of the time.","[{""name"":""Jan Schellenberger"",""id"":""/profile/81487654457""},{""name"":""Jan Schellenberger"",""id"":""/profile/81487654457""}]",null
https://doi.org/10.1145/3394486.3409555,Build the State-of-the-Art Machine Learning Technology for the Crypto Economy,"Coinbase's mission is ""to create an open financial system for the world"". This presentation serves as an overview of our efforts in building the state-of-the-art machine learning technology for the fast-evolving crypto economy, which follows a prototype, productization, and experimentation development cycle. On the machine learning side, it covers topics around proper train/validation setup, maintaining a fast iteration cycle using a custom-built AutoML framework (called ""EasyML""), a deep learning Transformers-based sequence based model and how to incorporate timing into it, how to combine gradient boosting trees with deep learning using linear blending, as well as model interpretability, evaluation, and experimentation. On the machine learning platform side, we will dive into the internals of Nostradamus, our in-house-built framework that manages model life-cycle, and Feature Store, our self-serve feature management, computation and serving framework.","[{""name"":""Michael Li"",""id"":""/profile/99659574161""},{""name"":""Catalin Tiseanu"",""id"":""/profile/99659573867""},{""name"":""Burkay Gur"",""id"":""/profile/99659573462""},{""name"":""Michael Li"",""id"":""/profile/99659574161""},{""name"":""Catalin Tiseanu"",""id"":""/profile/99659573867""},{""name"":""Burkay Gur"",""id"":""/profile/99659573462""}]",null
https://doi.org/10.1145/3394486.3409556,How AI Can Help Build Resiliency for Small Businesses in a Global Economic Crisis,"In the midst of COVID-19, a global economic crisis is threatening the livelihoods of small business owners everywhere. In ordinary times, 50 percent of small businesses go out of business in the first 5 years. In today's extraordinary times, nearly 7.5 million (~25 percent) of small businesses in the U.S. alone have been at risk of closing permanently in a matter of months (Source: Main Street America's Small Business Survey 2020).Among the all-time top contributing factors to survival? Cash flow management and access to capital.Whether in the midst of a pandemic or a devastating life event, business owners are more likely to survive if they can 1) efficiently manage the inflow and outflow of cash, 2) understand their cash position to qualify for government aid and/or loans with flexible borrowing terms, and 3) use financial insights to map out revenue and spending scenarios.In this talk, Nhung Ho, Director of Data Science for Intuit's Small Business and Self-Employed Group, will describe how Intuit AI has applied artificial intelligence and large-scale machine learning to help small businesses around the world to overcome the challenges of cash flow forecasting and capital access to build financial resilience in turbulent times.","[{""name"":""Nhung Ho"",""id"":""/profile/99659574990""},{""name"":""Nhung Ho"",""id"":""/profile/99659574990""}]",null
https://doi.org/10.1145/3394486.3409557,Toward Responsible AI by Planning to Fail,"The potential for AI technologies to enhance human capabilities and improve our lives is of little debate; yet, neither is their potential to cause harm and social disruption. While preventing or minimizing AI biases and harms is justifiably the subject of intense study in academic, industrial and even legal communities, an approach centered on acknowledging and planning for AI-based failures has the potential to shed new light on how to develop and deploy responsible AI-based systems.In this talk, I will discuss the sociotechnical nature of several inherent and unavoidable AI failures and why it is important for the industry to systematically and proactively identify, assess, and mitigate harms caused by such failures in our AI-based products and services. I will then present Microsoft's recently released Guidelines for Human-AI Interaction and how we've been using them at Microsoft to help teams think through and prepare for different types of AI failures.","[{""name"":""Saleema Amershi"",""id"":""/profile/81323487634""},{""name"":""Saleema Amershi"",""id"":""/profile/81323487634""}]",null
https://doi.org/10.1145/3394486.3409558,Multimodal Machine Learning for Video and Image Analysis,"In this talk, we will first discuss multimodal ML for video content analysis. Videos typically have data in multiple modalities like audio, video, and text (captions). Understanding and modeling the interaction between different modalities is key for video analysis tasks like categorization, object detection, activity recognition, etc. However, data modalities are not always correlated -- so, learning when modalities are correlated and using that to guide the influence of one modality on the other is crucial. Another salient feature of videos is the coherence between successive frames due to continuity of video and audio, a property that we refer to as temporal coherence. We show how using non-linear guided cross-modal signals and temporal coherence can improve the performance of multimodal ML models for video analysis tasks like categorization. We also created a hierarchical taxonomy of categories internally. Our experiments on the large-scale YouTube-8M dataset show how our approach significantly outperforms state-of-the-art multimodal ML model for video categorization using our taxonomy, as well as generalizes well to an internal dataset of video segments from actual TV programs. The next part of the talk will briefly discuss our work on explainability of multimodal ML models. We will conclude the talk by outlining other multimodal ML applications like incremental object detection and visual dialog, and discuss potential applications of multimodal ML to various domains.","[{""name"":""Shalini Ghosh"",""id"":""/profile/99659573004""},{""name"":""Shalini Ghosh"",""id"":""/profile/99659573004""}]",null
https://doi.org/10.1145/3394486.3409559,Lessons from Archives: Strategies for Collecting Sociocultural Data in Machine Learning,"A growing body of work shows that many problems in fairness, accountability, transparency, and ethics in machine learning systems are rooted in decisions surrounding the data collection and annotation process. We argue that a new specialization should be formed within machine learning that is focused on methodologies for data collection and annotation: efforts that require institutional frameworks and procedures. Specifically for sociocultural data, parallels can be drawn from archives and libraries. Archives are the longest standing communal effort to gather human information and archive scholars have already developed the language and procedures to address and discuss many challenges pertaining to data collection such as consent, power, inclusivity, transparency, and ethics privacy. We discuss these five key approaches in document collection practices in archives that can inform data collection in sociocultural machine learning.","[{""name"":""Timnit Gebru"",""id"":""/profile/99658665531""},{""name"":""Timnit Gebru"",""id"":""/profile/99658665531""}]",null
https://doi.org/10.1145/3394486.3409560,Unleashing the Power of Subjective Data: Managing Experiences as First-Class Citizens,"Subjective data refers to data that contains opinions and experiences. Such data is ubiquitous in product reviews, tweets, and discussion forums in social media. Consumers today spend considerable time sifting through subjective data to make informed decisions about purchases. At Megagon Labs, we are building technologies to synthesize knowledge from subjective data and to facilitate searching over them.In this talk, I will overview some of the technologies we have developed in the directions of subjective data preparation and integration, experience discovery and search, subjective knowledge representation, and data analytics and exploration.","[{""name"":""Wang-Chiew Tan"",""id"":""/profile/99659538818""},{""name"":""Wang-Chiew Tan"",""id"":""/profile/99659538818""}]",null
https://doi.org/10.1145/3394486.3409562,Innovating with Language AI,"Understanding human language in real world scenarios involves not just natural language processing but also speech, vision, knowledge graphs, user modeling, and other AI techniques. Doing this at Google scale involves planetary-scale cloud computing as well as tiny-scale edge computing. I'll share a behind-the-scenes look at how Google uses Language AI to power its billion-user products, and discuss some of the newer approaches we are developing to make sense of human language. I'll end with our vision to democratize AI and how you can use Google AI in your own work.","[{""name"":""Ashwin Ram"",""id"":""/profile/81502663777""},{""name"":""Ashwin Ram"",""id"":""/profile/81502663777""}]",null
https://doi.org/10.1145/3394486.3409565,Data Paucity and Low Resource Scenarios: Challenges and Opportunities,"In an era of unstructured data abundance, you would think that we have solved our data requirements for building robust systems for language processing. However, this is not the case if we think on a global scale with over 7000 languages where only a handful have digital resources. Systems at scale with good performance typically require annotated resources that cover the genres and domain divides. Moreover, the existence of a handful of resources in some languages is a reflection of the digital disparity in various societies leading to inadvertent biases in systems. In this talk I will show some solutions for low resource scenarios, both cross domain and genres as well as cross lingually.I will talk about handling data paucity from the angle of devising principled metrics for data selection. Summarizing data samples by quantitative measures has a long history, with descriptive statistics being a case in point. However, as natural language processing methods flourish, there are still insufficient characteristic metrics to describe a collection of texts in terms of the words, sentences, or paragraphs they comprise. In this work, we propose metrics of diversity, density, and homogeneity that quantitatively measure the dispersion, sparsity, and uniformity of a text collection. We conduct a series of simulations to verify that each metric holds desired properties and resonates with human intuitions. Experiments on real-world datasets demonstrate that the proposed characteristic metrics are highly correlated with text classification performance of a renowned model, BERT, which could inspire future applications. We specifically look at the problem of Intent classification (IC) as well as sentiment analysis.From the modeling side, for low resource scenarios for genres and domains, we investigate some techniques for few shot learning for the problems of intent classification (IC) and the sequence learning models for slot filling (SF) which are both core components in dialogue systems for task oriented chatbots. Current IC/SF models perform poorly when the number of training examples per class is small. We propose a new few-shot learning task, few-shot IC/SF, to study and improve the performance of IC and SF models on classes not seen at training time in ultra low re